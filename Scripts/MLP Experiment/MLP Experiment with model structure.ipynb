{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import seaborn as sns\n",
    "from random import seed\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import  MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, LSTM, BatchNormalization\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras import callbacks\n",
    "from keras import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate Dataset\n",
    "#Airfoil Self-Noise\n",
    "df_airfoil=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Airfoil_self_noise.csv')\n",
    "\n",
    "#Automobile\n",
    "df_automobile=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Automobile_data.txt')\n",
    "\n",
    "#Autompg\n",
    "df_autompg=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Auto-mpg.csv')\n",
    "\n",
    "#ChallengerUSA\n",
    "df_challenger=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Challenger USA Space Shuttle O-Ring.csv')\n",
    "\n",
    "#Combine Cycle Power\n",
    "df_combine=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Combine Cycle Power Plant.csv')\n",
    "\n",
    "#Computer Hardware\n",
    "df_computer=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Computer Hardware.csv')\n",
    "\n",
    "#Concrete Compressive Strength\n",
    "df_concrete_compressive_strength=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Concrete Compressive Strength.csv')\n",
    "\n",
    "#Concrete Slump Test\n",
    "df_concrete1=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Concrete Slump Test.csv')\n",
    "df_concrete2=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Concrete Slump Test.csv')\n",
    "df_concrete3=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Concrete Slump Test.csv')\n",
    "\n",
    "#Energy Efficiency\n",
    "df_energy1=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Energy Efficiency.csv')\n",
    "df_energy2=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Energy Efficiency.csv')\n",
    "\n",
    "#Fertility Diagnosis\n",
    "df_fertility=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\fertility_Diagnosis.csv')\n",
    "\n",
    "#Forest Fires\n",
    "df_forest=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\forestfires.csv')\n",
    "\n",
    "#Housing\n",
    "df_housing=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Housing.csv')\n",
    "\n",
    "#Istanbul Stock Exchange\n",
    "df_istanbul=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Istanbul Stock Exchange.csv')\n",
    "\n",
    "#WDBC\n",
    "df_wdbc=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\wdbc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:66: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#remove Nan columns of df_energy1\n",
    "df_energy1=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Energy Efficiency.csv')\n",
    "df_energy1.drop(df_energy1.columns[11],inplace=True, axis = 1)\n",
    "df_energy1.drop(df_energy1.columns[10],inplace=True, axis = 1)\n",
    "\n",
    "#remove Nan columns of df_energy2\n",
    "df_energy2=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Energy Efficiency.csv')\n",
    "df_energy2.drop(df_energy2.columns[11],inplace=True, axis = 1)\n",
    "df_energy2.drop(df_energy2.columns[10],inplace=True, axis = 1)\n",
    "\n",
    "#remove question marks\n",
    "#df_automobile\n",
    "imp= Imputer(missing_values=\"NaN\", strategy=\"mean\")\n",
    "df_automobile=df_automobile.replace(\"?\", np.NaN)\n",
    "df_automobile['num-of-doors'] = df_automobile['num-of-doors'].fillna(\"four\")\n",
    "for i in df_automobile.columns:\n",
    "    if df_automobile[i].isnull().sum()>0:\n",
    "        df_automobile[i]=imp.fit_transform(df_automobile[[i]])\n",
    "#df_automobile = df_automobile[(df_automobile.astype(str) != '?').all(axis=1)]\n",
    "#df_automobile.reset_index(drop=True, inplace=True)\n",
    "df_automobile = df_automobile.drop(['engine-location'], axis=1)\n",
    "#df_autompg\n",
    "df_autompg = df_autompg[(df_autompg.astype(str) != '?').all(axis=1)]\n",
    "df_autompg.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#convert string to number\n",
    "le=LabelEncoder()\n",
    "#df_automobile\n",
    "string_automobile=df_automobile[['make','fuel-type','aspiration','num-of-doors', 'body-style', 'drive-wheels', 'engine-type', 'num-of-cylinders', 'fuel-system']]\n",
    "df_automobile[['make','fuel-type','aspiration','num-of-doors', 'body-style', 'drive-wheels', 'engine-type', 'num-of-cylinders', 'fuel-system']]=string_automobile.apply(le.fit_transform)\n",
    "encoder=df_automobile[['make','fuel-type','aspiration','num-of-doors', 'body-style', 'drive-wheels', 'engine-type', 'num-of-cylinders', 'fuel-system']].astype(np.int64)\n",
    "df_automobile[['make','fuel-type','aspiration','num-of-doors', 'body-style', 'drive-wheels', 'engine-type', 'num-of-cylinders', 'fuel-system']]=encoder\n",
    "a=df_automobile[['normalized-losses','horsepower','price']].astype(np.int64)\n",
    "b=df_automobile[['bore','stroke','peak-rpm']].astype(float)\n",
    "df_automobile[['normalized-losses','horsepower','price']]=a\n",
    "df_automobile[['bore','stroke','peak-rpm']]=b\n",
    "#df_computer\n",
    "string_computer=df_computer[['Vendor','Model']]\n",
    "df_computer[['Vendor','Model']]=string_computer.apply(le.fit_transform)\n",
    "df_computer[['Vendor','Model']]=df_computer[['Vendor','Model']].astype(np.int64)\n",
    "\n",
    "#dropna spesific column & special preprocessing\n",
    "#df_forest\n",
    "df_forest=df_forest[(df_forest['area'].astype(int) != 0)] \n",
    "df_forest.reset_index(drop=True, inplace=True)\n",
    "num_features=10\n",
    "dimension=(num_features+1)*9+10\n",
    "population_size=(2*dimension+1)*2\n",
    "df_forest=df_forest[:population_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_data1(df,num_features):\n",
    "    dimension=(num_features+1)*9+10\n",
    "    population_size=(2*dimension+1)*2\n",
    "    df=df.dropna()\n",
    "    df=df[:population_size]\n",
    "    df\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection(df):\n",
    "    cor=df.corr()\n",
    "    plt.figure(figsize=(100,50))\n",
    "    sns.set(font_scale=3)\n",
    "    sns.heatmap(cor, annot=True, cmap=plt.cm.Blues)\n",
    "    plt.show()\n",
    "    return cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split1(x, y):\n",
    "    x_train, x_test, y_train, y_test= train_test_split(x, y, test_size=0.15, random_state=42)\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_data2(df):\n",
    "    train_size = 0.85*len(df)\n",
    "    train_size = int(train_size)\n",
    "    df_train = df[:train_size]\n",
    "    df_test = df[train_size:]\n",
    "    print(len(df_test))\n",
    "    print(len(df_train))\n",
    "    validation_size=len(df_test)/len(df_train)\n",
    "    print(validation_size)\n",
    "    return df_train, df_test, validation_size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#df_airfoil=preprocessing_data1(df_airfoil,5)\n",
    "#df_automobile=preprocessing_data1(df_automobile,22)\n",
    "#df_autompg=preprocessing_data1(df_autompg,7)\n",
    "#df_challenger=preprocessing_data1(df_challenger,3)\n",
    "#df_combine=preprocessing_data1(df_combine,4)\n",
    "#df_computer=preprocessing_data1(df_computer,9)\n",
    "#df_concrete_compressive_strength=preprocessing_data1(df_concrete_compressive_strength,8)\n",
    "#df_concrete1=preprocessing_data1(df_concrete1,7)\n",
    "#df_concrete2=preprocessing_data1(df_concrete2,7)\n",
    "#df_concrete3=preprocessing_data1(df_concrete3,7)\n",
    "#df_energy1=preprocessing_data1(df_energy1,8)\n",
    "#df_energy2=preprocessing_data1(df_energy2,8)\n",
    "\n",
    "#df_fertility=preprocessing_data1(df_fertility,9)\n",
    "for i in df_fertility:\n",
    "    df_fertility.Diagnosis[df_fertility.Diagnosis == 'N'] = 1\n",
    "    df_fertility.Diagnosis[df_fertility.Diagnosis == 'O'] = 2\n",
    "df_fertility['Diagnosis']=df_fertility['Diagnosis'].astype(np.int64)\n",
    "\n",
    "#df_forest=preprocessing_data1(df_forest,10)\n",
    "#df_housing=preprocessing_data1(df_housing,13)\n",
    "\n",
    "#df_istanbul=preprocessing_data1(df_istanbul,7)\n",
    "new_header = df_istanbul.iloc[0]\n",
    "df_istanbul = df_istanbul[1:]\n",
    "df_istanbul.columns = new_header\n",
    "df_istanbul[['ISE1','ISE2','SP','DAX','FTSE','NIKKEI','BOVESPA','EU','EM']]=df_istanbul[['ISE1','ISE2','SP','DAX','FTSE','NIKKEI','BOVESPA','EU','EM']].astype(np.float64)\n",
    "\n",
    "\n",
    "#df_wdbc=preprocessing_data1(df_wdbc,10)\n",
    "df_wdbc.drop(df_wdbc.columns[0], axis=1, inplace = True)\n",
    "df_wdbc.columns=['id','diagnosis','radius_mean','texture_mean','perimeter_mean','area_mean','smoothness_mean','compactness_mean','concavity_mean','concave points_mean','symmetry_mean','fractal_dimension_mean','radius_se','texture_se','perimeter_se','area_se','smoothness_se','compactness_se','concavity_se','concave points_se','symmetry_se','fractal_dimension_se','radius_worst','texture_worst','perimeter_worst','area_worst','smoothness_worst','compactness_worst','concavity_worst','concave points_worst','symmetry_worst','fractal_dimension_worst']\n",
    "for i in df_wdbc:\n",
    "    df_wdbc.diagnosis[df_wdbc.diagnosis == 'M'] = 1\n",
    "    df_wdbc.diagnosis[df_wdbc.diagnosis == 'B'] = 2\n",
    "df_wdbc['diagnosis']=df_wdbc['diagnosis'].astype(np.object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Frequency  Angle of Attack  Chord length  Free-stream velocity  \\\n",
      "0        800              0.0        0.3048                  71.3   \n",
      "1       1000              0.0        0.3048                  71.3   \n",
      "2       1250              0.0        0.3048                  71.3   \n",
      "3       1600              0.0        0.3048                  71.3   \n",
      "4       2000              0.0        0.3048                  71.3   \n",
      "\n",
      "   Suction side displacement thickness  Scaled sound pressure level  \n",
      "0                             0.002663                      126.201  \n",
      "1                             0.002663                      125.201  \n",
      "2                             0.002663                      125.951  \n",
      "3                             0.002663                      127.591  \n",
      "4                             0.002663                      127.461  \n",
      "    Mpg  Cylinders  Displacement Horsepower  Weight  Acceleration  Model Year  \\\n",
      "0  18.0          8         307.0        130    3504          12.0          70   \n",
      "1  15.0          8         350.0        165    3693          11.5          70   \n",
      "2  18.0          8         318.0        150    3436          11.0          70   \n",
      "3  16.0          8         304.0        150    3433          12.0          70   \n",
      "4  17.0          8         302.0        140    3449          10.5          70   \n",
      "\n",
      "   Origin                   Car Name  \n",
      "0       1  chevrolet chevelle malibu  \n",
      "1       1          buick skylark 320  \n",
      "2       1         plymouth satellite  \n",
      "3       1              amc rebel sst  \n",
      "4       1                ford torino  \n",
      "   symboling  normalized-losses  make  fuel-type  aspiration  num-of-doors  \\\n",
      "0          3                122     0          1           0             1   \n",
      "1          3                122     0          1           0             1   \n",
      "2          1                122     0          1           0             1   \n",
      "3          2                164     1          1           0             0   \n",
      "4          2                164     1          1           0             0   \n",
      "\n",
      "   body-style  drive-wheels  wheel-base  length  ...  engine-size  \\\n",
      "0           0             2        88.6   168.8  ...          130   \n",
      "1           0             2        88.6   168.8  ...          130   \n",
      "2           2             2        94.5   171.2  ...          152   \n",
      "3           3             1        99.8   176.6  ...          109   \n",
      "4           3             0        99.4   176.6  ...          136   \n",
      "\n",
      "   fuel-system  bore  stroke  compression-ratio  horsepower  peak-rpm  \\\n",
      "0            5  3.47    2.68                9.0         111    5000.0   \n",
      "1            5  3.47    2.68                9.0         111    5000.0   \n",
      "2            5  2.68    3.47                9.0         154    5000.0   \n",
      "3            5  3.19    3.40               10.0         102    5500.0   \n",
      "4            5  3.19    3.40                8.0         115    5500.0   \n",
      "\n",
      "   city-mpg  highway-mpg  price  \n",
      "0        21           27  13495  \n",
      "1        21           27  16500  \n",
      "2        19           26  16500  \n",
      "3        24           30  13950  \n",
      "4        18           22  17450  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "   Number of O-rings  Thermal Distress  Launch Temperature  \\\n",
      "0                  6                 0                  66   \n",
      "1                  6                 1                  70   \n",
      "2                  6                 0                  69   \n",
      "3                  6                 0                  68   \n",
      "4                  6                 0                  67   \n",
      "\n",
      "   Leak-Check Pressure  Temporal Order of Flight  \n",
      "0                   50                         1  \n",
      "1                   50                         2  \n",
      "2                   50                         3  \n",
      "3                   50                         4  \n",
      "4                   50                         5  \n"
     ]
    }
   ],
   "source": [
    "print(df_airfoil.head())\n",
    "print(df_autompg.head())\n",
    "print(df_automobile.head())\n",
    "print(df_challenger.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:62: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#Train and Test 17 datasets\n",
    "#Airfoil\n",
    "x_airfoil = df_airfoil.drop(['Scaled sound pressure level'], axis = 1)\n",
    "y_airfoil = df_airfoil['Scaled sound pressure level']\n",
    "#y_airfoil = np.reshape(y_airfoil.values, (-1,1))\n",
    "#Forest\n",
    "x_forest = df_forest.drop(['month','day','area'], axis = 1)\n",
    "y_forest = df_forest['area']\n",
    "y_forest = np.reshape(y_forest.values, (-1,1))\n",
    "#Housing\n",
    "x_housing = df_housing.drop(['MEDV'], axis = 1)\n",
    "y_housing = df_housing['MEDV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_airfoil, x_test_airfoil, y_train_airfoil, y_test_airfoil = train_test_split1(x_airfoil, y_airfoil)\n",
    "x_train_forest, x_test_forest, y_train_forest, y_test_forest = train_test_split1(x_forest, y_forest)\n",
    "x_train_housing, x_test_housing, y_train_housing, y_test_housing = train_test_split1(x_housing, y_housing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_scaler(X_train, x_test):\n",
    "    sc=StandardScaler()\n",
    "    X_train=X_train.values\n",
    "    x_test=x_test.values\n",
    "    X_scale_train=sc.fit(X_train)\n",
    "    #x_scale_test=sc.fit(x_test)\n",
    "    X_train=X_scale_train.transform(X_train)\n",
    "    x_test=X_scale_train.transform(x_test)\n",
    "    return X_train, x_test, X_scale_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_scaler_forest(X_train, x_test, Y_train, y_test):\n",
    "    minmax_x=MinMaxScaler()\n",
    "    minmax_y=MinMaxScaler()\n",
    "    X_train=X_train.values\n",
    "    x_test=x_test.values\n",
    "    X_scale_train=minmax_x.fit(X_train)\n",
    "    #X_scale_val=min_max.fit(X_val)\n",
    "    #x_scale_test=min_max.fit(x_test)\n",
    "    Y_scale_train=minmax_y.fit(Y_train)\n",
    "    #Y_scale_val=min_max.fit(Y_val)\n",
    "    #y_scale_test=min_max.fit(y_test)\n",
    "    X_train=X_scale_train.transform(X_train)\n",
    "    x_test=X_scale_train.transform(x_test)\n",
    "    Y_train=Y_scale_train.transform(Y_train)\n",
    "    y_test=Y_scale_train.transform(y_test)\n",
    "    return X_train, x_test, Y_train, y_test, X_scale_train, Y_scale_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimizer list\n",
    "adam0 = optimizers.Adam(lr=0.1)\n",
    "adam1 = optimizers.Adam(lr=0.001)\n",
    "adam2 = optimizers.Adam(lr=0.01)\n",
    "adam3 = optimizers.Adam(lr=0.0001)\n",
    "adam4 = optimizers.Adam(lr=0.00001)\n",
    "sgd = optimizers.SGD(lr=0.00001, decay=1e-4, momentum=0.9, nesterov=True)\n",
    "RMSprop= optimizers.RMSprop(lr=0.01,rho=0.9)\n",
    "adagrad = optimizers.Adagrad(lr=0.01)\n",
    "adadelta = optimizers.Adadelta(lr=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_model_structure_regression_1(X_train, X_val, Y_train, Y_val, adam, size, epochs):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units = 5, input_dim = (X_train.shape[1])))\n",
    "    model.add(Activation('tanh'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(units = 5))\n",
    "    model.add(Activation('linear'))\n",
    "    model.add(Dense(units = 1))\n",
    "    model.compile(optimizer = adam , loss = 'mse')\n",
    "    model.summary()\n",
    "    history=model.fit(X_train,Y_train, batch_size=size,epochs=epochs, validation_data=(X_val, Y_val), shuffle=True)\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_model_structure_regression_2(X_train, X_val, Y_train, Y_val, adam, size, epochs):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units = 5, input_dim = (X_train.shape[1])))\n",
    "    model.add(Activation('tanh'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(units = 10))\n",
    "    model.add(Activation('linear'))\n",
    "    model.add(Dense(units = 1))\n",
    "    model.compile(optimizer = adam , loss = 'mse')\n",
    "    model.summary()\n",
    "    history=model.fit(X_train,Y_train, batch_size=size,epochs=epochs, validation_data=(X_val, Y_val), shuffle=True)\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_model_structure_regression_3(X_train, X_val, Y_train, Y_val, adam, size, epochs):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units = 5, input_dim = (X_train.shape[1])))\n",
    "    model.add(Activation('tanh'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(units = 15))\n",
    "    model.add(Activation('linear'))\n",
    "    model.add(Dense(units = 1))\n",
    "    model.compile(optimizer = adam , loss = 'mse')\n",
    "    model.summary()\n",
    "    history=model.fit(X_train,Y_train, batch_size=size,epochs=epochs, validation_data=(X_val, Y_val), shuffle=True)\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_model_structure_regression_4(X_train, X_val, Y_train, Y_val, adam, size, epochs):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units = 10, input_dim = (X_train.shape[1])))\n",
    "    model.add(Activation('tanh'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(units = 5))\n",
    "    model.add(Activation('linear'))\n",
    "    model.add(Dense(units = 1))\n",
    "    model.compile(optimizer = adam , loss = 'mse')\n",
    "    model.summary()\n",
    "    history=model.fit(X_train,Y_train, batch_size=size,epochs=epochs, validation_data=(X_val, Y_val), shuffle=True)\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_model_structure_regression_5(X_train, X_val, Y_train, Y_val, adam, size, epochs):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units = 10, input_dim = (X_train.shape[1])))\n",
    "    model.add(Activation('tanh'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(units = 10))\n",
    "    model.add(Activation('linear'))\n",
    "    model.add(Dense(units = 1))\n",
    "    model.compile(optimizer = adam , loss = 'mse')\n",
    "    model.summary()\n",
    "    history=model.fit(X_train,Y_train, batch_size=size,epochs=epochs, validation_data=(X_val, Y_val), shuffle=True)\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_model_structure_regression_6(X_train, X_val, Y_train, Y_val, adam, size, epochs):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units = 10, input_dim = (X_train.shape[1])))\n",
    "    model.add(Activation('tanh'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(units = 15))\n",
    "    model.add(Activation('linear'))\n",
    "    model.add(Dense(units = 1))\n",
    "    model.compile(optimizer = adam , loss = 'mse')\n",
    "    model.summary()\n",
    "    history=model.fit(X_train,Y_train, batch_size=size,epochs=epochs, validation_data=(X_val, Y_val), shuffle=True)\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_airfoil, x_test_airfoil, x_scale_train_airfoil=standard_scaler(x_train_airfoil, x_test_airfoil)\n",
    "#_train_airfoil, x_test_airfoil, y_train_airfoil, y_test_airfoil, x_scale_train_airfoil, y_scale_train_airfoil=min_max_scaler_forest(x_train_airfoil, x_test_airfoil, y_train_airfoil, y_test_airfoil)\n",
    "x_train_forest, x_test_forest, y_train_forest, y_test_forest, x_scale_train_forest, y_scale_train_forest=min_max_scaler_forest(x_train_forest, x_test_forest, y_train_forest, y_test_forest)\n",
    "x_train_housing, x_test_housing, X_scale_train_housing=standard_scaler(x_train_housing, x_test_housing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 66\n",
      "Trainable params: 66\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 1052 samples, validate on 225 samples\n",
      "Epoch 1/1000\n",
      "1052/1052 [==============================] - 0s 420us/step - loss: 15300.5599 - val_loss: 14829.5093\n",
      "Epoch 2/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 13217.2963 - val_loss: 10889.3645\n",
      "Epoch 3/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7597.0211 - val_loss: 4040.7034\n",
      "Epoch 4/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 1852.1999 - val_loss: 424.2663\n",
      "Epoch 5/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 127.8954 - val_loss: 33.1919\n",
      "Epoch 6/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 29.6427 - val_loss: 26.7763\n",
      "Epoch 7/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 24.1814 - val_loss: 25.2121\n",
      "Epoch 8/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 22.6465 - val_loss: 24.7431\n",
      "Epoch 9/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.3906 - val_loss: 25.0170\n",
      "Epoch 10/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.1723 - val_loss: 24.7501\n",
      "Epoch 11/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 22.0621 - val_loss: 25.0706\n",
      "Epoch 12/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.0388 - val_loss: 24.9047\n",
      "Epoch 13/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 22.0531 - val_loss: 25.5881\n",
      "Epoch 14/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.1306 - val_loss: 25.2693\n",
      "Epoch 15/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.9967 - val_loss: 25.2552\n",
      "Epoch 16/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.0007 - val_loss: 25.5715\n",
      "Epoch 17/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.0402 - val_loss: 25.0350\n",
      "Epoch 18/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 22.1134 - val_loss: 25.4534\n",
      "Epoch 19/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 22.1650 - val_loss: 25.7702\n",
      "Epoch 20/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.1864 - val_loss: 25.4197\n",
      "Epoch 21/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 22.1496 - val_loss: 25.2700\n",
      "Epoch 22/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.9635 - val_loss: 25.3955\n",
      "Epoch 23/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 21.9678 - val_loss: 25.3095\n",
      "Epoch 24/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 22.0198 - val_loss: 25.4171\n",
      "Epoch 25/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 22.0051 - val_loss: 25.5366\n",
      "Epoch 26/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.7546 - val_loss: 25.3012\n",
      "Epoch 27/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 22.2960 - val_loss: 25.0621\n",
      "Epoch 28/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.8714 - val_loss: 26.1905\n",
      "Epoch 29/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 21.7658 - val_loss: 25.0342\n",
      "Epoch 30/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.9028 - val_loss: 25.3060\n",
      "Epoch 31/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 22.0845 - val_loss: 25.6728\n",
      "Epoch 32/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.5861 - val_loss: 26.4712\n",
      "Epoch 33/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 22.1429 - val_loss: 25.7422\n",
      "Epoch 34/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.1908 - val_loss: 25.3798\n",
      "Epoch 35/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 22.1180 - val_loss: 26.0195\n",
      "Epoch 36/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.0905 - val_loss: 26.1581\n",
      "Epoch 37/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 22.1534 - val_loss: 25.0220\n",
      "Epoch 38/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 22.1283 - val_loss: 25.3136\n",
      "Epoch 39/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 22.0819 - val_loss: 25.7454\n",
      "Epoch 40/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.2036 - val_loss: 25.4430\n",
      "Epoch 41/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.1762 - val_loss: 25.1395\n",
      "Epoch 42/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.9243 - val_loss: 25.8036\n",
      "Epoch 43/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 21.9413 - val_loss: 25.2322\n",
      "Epoch 44/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.1045 - val_loss: 25.5953\n",
      "Epoch 45/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.0181 - val_loss: 25.3867\n",
      "Epoch 46/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.9480 - val_loss: 26.6161\n",
      "Epoch 47/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 21.7358 - val_loss: 25.0954\n",
      "Epoch 48/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.4439 - val_loss: 25.5248\n",
      "Epoch 49/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 22.0657 - val_loss: 26.3966\n",
      "Epoch 50/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.1089 - val_loss: 25.8925\n",
      "Epoch 51/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.4520 - val_loss: 26.2405\n",
      "Epoch 52/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.6763 - val_loss: 25.4868\n",
      "Epoch 53/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.1999 - val_loss: 26.4126\n",
      "Epoch 54/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 21.9321 - val_loss: 25.3487\n",
      "Epoch 55/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.3311 - val_loss: 25.9293\n",
      "Epoch 56/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.2531 - val_loss: 25.2295\n",
      "Epoch 57/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.9100 - val_loss: 26.1296\n",
      "Epoch 58/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.9738 - val_loss: 25.9934\n",
      "Epoch 59/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 21.9657 - val_loss: 25.8508\n",
      "Epoch 60/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.8656 - val_loss: 26.6788\n",
      "Epoch 61/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.5613 - val_loss: 27.5429\n",
      "Epoch 62/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.5854 - val_loss: 26.5647\n",
      "Epoch 63/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.9846 - val_loss: 26.6376\n",
      "Epoch 64/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.5420 - val_loss: 26.5999\n",
      "Epoch 65/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - ETA: 0s - loss: 22.59 - 0s 99us/step - loss: 22.3230 - val_loss: 25.4991\n",
      "Epoch 66/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 21.8059 - val_loss: 26.6292\n",
      "Epoch 67/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 22.0500 - val_loss: 25.9013\n",
      "Epoch 68/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 21.8269 - val_loss: 26.8217\n",
      "Epoch 69/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 22.0763 - val_loss: 25.3539\n",
      "Epoch 70/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 21.6827 - val_loss: 25.7999\n",
      "Epoch 71/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 22.1656 - val_loss: 25.7877\n",
      "Epoch 72/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 22.2649 - val_loss: 25.8903\n",
      "Epoch 73/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 22.0316 - val_loss: 26.1558\n",
      "Epoch 74/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.9121 - val_loss: 25.4739\n",
      "Epoch 75/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.9791 - val_loss: 26.7042\n",
      "Epoch 76/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.8596 - val_loss: 26.6393\n",
      "Epoch 77/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.3806 - val_loss: 25.7081\n",
      "Epoch 78/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.0328 - val_loss: 25.8857\n",
      "Epoch 79/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.5230 - val_loss: 25.8914\n",
      "Epoch 80/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.7851 - val_loss: 26.2365\n",
      "Epoch 81/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.0875 - val_loss: 25.6878\n",
      "Epoch 82/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.2561 - val_loss: 25.8830\n",
      "Epoch 83/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.8357 - val_loss: 26.1116\n",
      "Epoch 84/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.8990 - val_loss: 26.3518\n",
      "Epoch 85/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.2767 - val_loss: 26.8051\n",
      "Epoch 86/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.2395 - val_loss: 27.1232\n",
      "Epoch 87/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 22.1928 - val_loss: 25.3781\n",
      "Epoch 88/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.8677 - val_loss: 28.0356\n",
      "Epoch 89/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.9194 - val_loss: 26.0364\n",
      "Epoch 90/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.1035 - val_loss: 25.5249\n",
      "Epoch 91/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.1293 - val_loss: 26.8998\n",
      "Epoch 92/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.1852 - val_loss: 26.1185\n",
      "Epoch 93/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.1794 - val_loss: 25.5599\n",
      "Epoch 94/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.5180 - val_loss: 27.1963\n",
      "Epoch 95/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.0723 - val_loss: 25.5242\n",
      "Epoch 96/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 22.2525 - val_loss: 25.6987\n",
      "Epoch 97/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.4176 - val_loss: 25.8229\n",
      "Epoch 98/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.0443 - val_loss: 26.0929\n",
      "Epoch 99/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.2169 - val_loss: 26.0672\n",
      "Epoch 100/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 22.2822 - val_loss: 26.1789\n",
      "Epoch 101/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.1758 - val_loss: 26.4588\n",
      "Epoch 102/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.7587 - val_loss: 26.1433\n",
      "Epoch 103/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.2080 - val_loss: 27.7218\n",
      "Epoch 104/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 22.1162 - val_loss: 27.6128\n",
      "Epoch 105/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.9260 - val_loss: 26.4481\n",
      "Epoch 106/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.9712 - val_loss: 26.4039\n",
      "Epoch 107/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.0374 - val_loss: 25.8950\n",
      "Epoch 108/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.9310 - val_loss: 27.3830\n",
      "Epoch 109/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.8341 - val_loss: 25.9733\n",
      "Epoch 110/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.4230 - val_loss: 25.6239\n",
      "Epoch 111/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.5362 - val_loss: 27.9939\n",
      "Epoch 112/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.2289 - val_loss: 26.6890\n",
      "Epoch 113/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.4990 - val_loss: 26.0618\n",
      "Epoch 114/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.9252 - val_loss: 25.7438\n",
      "Epoch 115/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.2414 - val_loss: 26.9742\n",
      "Epoch 116/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.1999 - val_loss: 25.7099\n",
      "Epoch 117/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.0460 - val_loss: 26.3006\n",
      "Epoch 118/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.8409 - val_loss: 26.3743\n",
      "Epoch 119/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.2930 - val_loss: 26.2691\n",
      "Epoch 120/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.3246 - val_loss: 25.5166\n",
      "Epoch 121/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.0123 - val_loss: 25.4843\n",
      "Epoch 122/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.4180 - val_loss: 26.7487\n",
      "Epoch 123/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.3932 - val_loss: 25.5234\n",
      "Epoch 124/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.4818 - val_loss: 25.7450\n",
      "Epoch 125/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.1402 - val_loss: 26.1724\n",
      "Epoch 126/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.2059 - val_loss: 26.1559\n",
      "Epoch 127/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.7307 - val_loss: 26.0857\n",
      "Epoch 128/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.9412 - val_loss: 25.4589\n",
      "Epoch 129/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.2089 - val_loss: 26.5114\n",
      "Epoch 130/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.2865 - val_loss: 28.8192\n",
      "Epoch 131/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 22.0681 - val_loss: 25.6662\n",
      "Epoch 132/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.6301 - val_loss: 27.6685\n",
      "Epoch 133/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.2596 - val_loss: 25.2241\n",
      "Epoch 134/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.0763 - val_loss: 25.7941\n",
      "Epoch 135/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.0156 - val_loss: 25.6129\n",
      "Epoch 136/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.9838 - val_loss: 26.1599\n",
      "Epoch 137/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.8229 - val_loss: 26.0836\n",
      "Epoch 138/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 22.0509 - val_loss: 26.9748\n",
      "Epoch 139/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 22.8199 - val_loss: 26.1354\n",
      "Epoch 140/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.2677 - val_loss: 25.8430\n",
      "Epoch 141/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.8317 - val_loss: 26.6002\n",
      "Epoch 142/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 21.6546 - val_loss: 25.6552\n",
      "Epoch 143/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.2914 - val_loss: 27.5697\n",
      "Epoch 144/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 21.7588 - val_loss: 25.4374\n",
      "Epoch 145/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.8464 - val_loss: 25.9204\n",
      "Epoch 146/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.3988 - val_loss: 26.5469\n",
      "Epoch 147/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.1447 - val_loss: 25.5635\n",
      "Epoch 148/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.1722 - val_loss: 26.2826\n",
      "Epoch 149/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.9449 - val_loss: 27.3198\n",
      "Epoch 150/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 22.2975 - val_loss: 25.2038\n",
      "Epoch 151/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.0189 - val_loss: 25.5105\n",
      "Epoch 152/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 22.4300 - val_loss: 25.8954\n",
      "Epoch 153/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.9188 - val_loss: 25.3022\n",
      "Epoch 154/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 22.1022 - val_loss: 25.6844\n",
      "Epoch 155/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.4426 - val_loss: 25.6624\n",
      "Epoch 156/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.8321 - val_loss: 25.5347\n",
      "Epoch 157/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.9969 - val_loss: 29.3100\n",
      "Epoch 158/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.6397 - val_loss: 27.0602\n",
      "Epoch 159/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.7505 - val_loss: 27.8030\n",
      "Epoch 160/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.0286 - val_loss: 25.9443\n",
      "Epoch 161/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.6310 - val_loss: 25.6482\n",
      "Epoch 162/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.6178 - val_loss: 25.3989\n",
      "Epoch 163/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.2982 - val_loss: 25.7461\n",
      "Epoch 164/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.0346 - val_loss: 25.3906\n",
      "Epoch 165/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.7575 - val_loss: 25.1275\n",
      "Epoch 166/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.2991 - val_loss: 26.6751\n",
      "Epoch 167/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.0270 - val_loss: 25.4658\n",
      "Epoch 168/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.1218 - val_loss: 25.2680\n",
      "Epoch 169/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 21.3845 - val_loss: 25.0782\n",
      "Epoch 170/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.3083 - val_loss: 27.4865\n",
      "Epoch 171/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 20.9789 - val_loss: 24.8248\n",
      "Epoch 172/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 20.5092 - val_loss: 25.2246\n",
      "Epoch 173/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 20.9898 - val_loss: 24.9551\n",
      "Epoch 174/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 20.9300 - val_loss: 25.3803\n",
      "Epoch 175/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 20.9017 - val_loss: 25.7777\n",
      "Epoch 176/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 20.8879 - val_loss: 24.3479\n",
      "Epoch 177/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 20.6464 - val_loss: 24.1316\n",
      "Epoch 178/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 20.2554 - val_loss: 24.1742\n",
      "Epoch 179/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 20.8770 - val_loss: 24.5790\n",
      "Epoch 180/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 20.2904 - val_loss: 24.0484\n",
      "Epoch 181/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 20.2791 - val_loss: 25.5264\n",
      "Epoch 182/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 20.4145 - val_loss: 24.6893\n",
      "Epoch 183/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 20.8326 - val_loss: 25.0256\n",
      "Epoch 184/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 19.9941 - val_loss: 24.6066\n",
      "Epoch 185/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 19.6675 - val_loss: 24.1314\n",
      "Epoch 186/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 19.4589 - val_loss: 24.3002\n",
      "Epoch 187/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 19.3515 - val_loss: 23.5076\n",
      "Epoch 188/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 19.5919 - val_loss: 24.4650\n",
      "Epoch 189/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.8880 - val_loss: 23.9599\n",
      "Epoch 190/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 19.2016 - val_loss: 23.9871\n",
      "Epoch 191/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 19.4948 - val_loss: 22.7674\n",
      "Epoch 192/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.5458 - val_loss: 22.2013\n",
      "Epoch 193/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 19.0211 - val_loss: 22.1455\n",
      "Epoch 194/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.0429 - val_loss: 22.1101\n",
      "Epoch 195/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.1077 - val_loss: 26.6918\n",
      "Epoch 196/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.3459 - val_loss: 22.2828\n",
      "Epoch 197/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.9101 - val_loss: 22.2582\n",
      "Epoch 198/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.0005 - val_loss: 23.4191\n",
      "Epoch 199/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.7415 - val_loss: 21.5521\n",
      "Epoch 200/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 17.7209 - val_loss: 20.8834\n",
      "Epoch 201/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.0142 - val_loss: 20.8320\n",
      "Epoch 202/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.5382 - val_loss: 21.5514\n",
      "Epoch 203/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.6430 - val_loss: 22.2108\n",
      "Epoch 204/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.6699 - val_loss: 22.9788\n",
      "Epoch 205/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.6105 - val_loss: 21.2495\n",
      "Epoch 206/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.2940 - val_loss: 21.9049\n",
      "Epoch 207/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 18.1099 - val_loss: 21.8348\n",
      "Epoch 208/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 17.5436 - val_loss: 20.0562\n",
      "Epoch 209/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.6214 - val_loss: 25.8158\n",
      "Epoch 210/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.7735 - val_loss: 19.7726\n",
      "Epoch 211/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 16.8194 - val_loss: 19.9773\n",
      "Epoch 212/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.3408 - val_loss: 20.5298\n",
      "Epoch 213/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.6019 - val_loss: 19.6360\n",
      "Epoch 214/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 16.8479 - val_loss: 20.0840\n",
      "Epoch 215/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 95us/step - loss: 17.4034 - val_loss: 21.0010\n",
      "Epoch 216/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 16.9459 - val_loss: 19.6376\n",
      "Epoch 217/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.1787 - val_loss: 19.9228\n",
      "Epoch 218/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.3325 - val_loss: 20.8439\n",
      "Epoch 219/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 16.7546 - val_loss: 22.3299\n",
      "Epoch 220/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 17.6438 - val_loss: 19.8830\n",
      "Epoch 221/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 16.5753 - val_loss: 19.1888\n",
      "Epoch 222/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 16.7364 - val_loss: 18.7288\n",
      "Epoch 223/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 16.6339 - val_loss: 19.0879\n",
      "Epoch 224/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 16.2285 - val_loss: 19.7864\n",
      "Epoch 225/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 16.1933 - val_loss: 17.8502\n",
      "Epoch 226/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 15.7500 - val_loss: 18.6226\n",
      "Epoch 227/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 16.4766 - val_loss: 18.3112\n",
      "Epoch 228/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 16.4840 - val_loss: 17.7133\n",
      "Epoch 229/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 16.0946 - val_loss: 22.0780\n",
      "Epoch 230/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 16.4721 - val_loss: 18.5655\n",
      "Epoch 231/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 16.0719 - val_loss: 18.1576\n",
      "Epoch 232/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 15.9031 - val_loss: 17.6952\n",
      "Epoch 233/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 15.8516 - val_loss: 19.0291\n",
      "Epoch 234/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 15.5119 - val_loss: 17.5472\n",
      "Epoch 235/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 16.0757 - val_loss: 19.1886\n",
      "Epoch 236/1000\n",
      "1052/1052 [==============================] - 0s 110us/step - loss: 16.1422 - val_loss: 17.6126\n",
      "Epoch 237/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 15.4531 - val_loss: 17.8007\n",
      "Epoch 238/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 15.4618 - val_loss: 18.6147\n",
      "Epoch 239/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 16.0829 - val_loss: 17.7347\n",
      "Epoch 240/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 15.3513 - val_loss: 19.3233\n",
      "Epoch 241/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 15.8475 - val_loss: 17.7608\n",
      "Epoch 242/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 15.1735 - val_loss: 18.3331\n",
      "Epoch 243/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 15.5134 - val_loss: 17.6659\n",
      "Epoch 244/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.9173 - val_loss: 19.0185\n",
      "Epoch 245/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 15.3600 - val_loss: 17.2903\n",
      "Epoch 246/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 15.2464 - val_loss: 18.3515\n",
      "Epoch 247/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.9174 - val_loss: 17.6994\n",
      "Epoch 248/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.6768 - val_loss: 17.7997\n",
      "Epoch 249/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.7342 - val_loss: 17.3927\n",
      "Epoch 250/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 14.8208 - val_loss: 18.0307\n",
      "Epoch 251/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.8403 - val_loss: 17.8643\n",
      "Epoch 252/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 14.8533 - val_loss: 20.0118\n",
      "Epoch 253/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.7478 - val_loss: 17.3116\n",
      "Epoch 254/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 15.0320 - val_loss: 18.5839\n",
      "Epoch 255/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 14.3538 - val_loss: 16.1728\n",
      "Epoch 256/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 14.1640 - val_loss: 19.1260\n",
      "Epoch 257/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 14.0770 - val_loss: 16.5967\n",
      "Epoch 258/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 14.2306 - val_loss: 18.2309\n",
      "Epoch 259/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 15.0489 - val_loss: 17.7578\n",
      "Epoch 260/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.9862 - val_loss: 16.9883\n",
      "Epoch 261/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.8967 - val_loss: 16.6156\n",
      "Epoch 262/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 13.7476 - val_loss: 16.8333\n",
      "Epoch 263/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 13.6141 - val_loss: 17.6054\n",
      "Epoch 264/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 13.7255 - val_loss: 17.6342\n",
      "Epoch 265/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.1972 - val_loss: 17.4310\n",
      "Epoch 266/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 13.7965 - val_loss: 16.1141\n",
      "Epoch 267/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 14.1658 - val_loss: 18.4792\n",
      "Epoch 268/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.2533 - val_loss: 16.5855\n",
      "Epoch 269/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 14.4671 - val_loss: 16.9677\n",
      "Epoch 270/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.8672 - val_loss: 16.1886\n",
      "Epoch 271/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 13.3621 - val_loss: 15.3683\n",
      "Epoch 272/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 13.1722 - val_loss: 16.8004\n",
      "Epoch 273/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.3559 - val_loss: 15.7882\n",
      "Epoch 274/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.6875 - val_loss: 16.1129\n",
      "Epoch 275/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.0507 - val_loss: 18.1528\n",
      "Epoch 276/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 12.7759 - val_loss: 17.6712\n",
      "Epoch 277/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 12.7514 - val_loss: 15.3464\n",
      "Epoch 278/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.7052 - val_loss: 17.8295\n",
      "Epoch 279/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.9706 - val_loss: 15.1118\n",
      "Epoch 280/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.4599 - val_loss: 15.1576\n",
      "Epoch 281/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 13.1948 - val_loss: 17.3170\n",
      "Epoch 282/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 12.5789 - val_loss: 15.0064\n",
      "Epoch 283/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 12.3217 - val_loss: 15.6134\n",
      "Epoch 284/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.3477 - val_loss: 16.8052\n",
      "Epoch 285/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 12.4190 - val_loss: 14.3820\n",
      "Epoch 286/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.2972 - val_loss: 16.5045\n",
      "Epoch 287/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 12.0184 - val_loss: 14.7099\n",
      "Epoch 288/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.9979 - val_loss: 16.4913\n",
      "Epoch 289/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 12.1465 - val_loss: 15.0371\n",
      "Epoch 290/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.6304 - val_loss: 16.4099\n",
      "Epoch 291/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.5893 - val_loss: 17.0453\n",
      "Epoch 292/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 12.5930 - val_loss: 17.6723\n",
      "Epoch 293/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.9700 - val_loss: 17.3829\n",
      "Epoch 294/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.2073 - val_loss: 15.2575\n",
      "Epoch 295/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.7678 - val_loss: 13.9837\n",
      "Epoch 296/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.7409 - val_loss: 14.6992\n",
      "Epoch 297/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.2474 - val_loss: 14.5869\n",
      "Epoch 298/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.3091 - val_loss: 13.6820\n",
      "Epoch 299/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 11.4763 - val_loss: 13.4851\n",
      "Epoch 300/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.7888 - val_loss: 14.3914\n",
      "Epoch 301/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.1996 - val_loss: 14.8103\n",
      "Epoch 302/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.4707 - val_loss: 14.5052\n",
      "Epoch 303/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 11.2661 - val_loss: 13.4383\n",
      "Epoch 304/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 11.9877 - val_loss: 14.0171\n",
      "Epoch 305/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.1151 - val_loss: 13.3005\n",
      "Epoch 306/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.5207 - val_loss: 14.2787\n",
      "Epoch 307/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.5075 - val_loss: 16.0985\n",
      "Epoch 308/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.1497 - val_loss: 13.7083\n",
      "Epoch 309/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 10.8133 - val_loss: 13.2532\n",
      "Epoch 310/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.6449 - val_loss: 13.8501\n",
      "Epoch 311/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.1403 - val_loss: 14.1780\n",
      "Epoch 312/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.6550 - val_loss: 12.7309\n",
      "Epoch 313/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.6751 - val_loss: 13.0485\n",
      "Epoch 314/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 10.4509 - val_loss: 15.0170\n",
      "Epoch 315/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.6479 - val_loss: 13.4325\n",
      "Epoch 316/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.4531 - val_loss: 13.8624\n",
      "Epoch 317/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.8909 - val_loss: 15.1895\n",
      "Epoch 318/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.7773 - val_loss: 12.5480\n",
      "Epoch 319/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 10.6085 - val_loss: 12.3280\n",
      "Epoch 320/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.9441 - val_loss: 12.1172\n",
      "Epoch 321/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 10.5370 - val_loss: 12.6390\n",
      "Epoch 322/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.2862 - val_loss: 13.0349\n",
      "Epoch 323/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.3740 - val_loss: 13.8629\n",
      "Epoch 324/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 10.2924 - val_loss: 14.3699\n",
      "Epoch 325/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.7670 - val_loss: 12.5659\n",
      "Epoch 326/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 10.0530 - val_loss: 12.3794\n",
      "Epoch 327/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.9892 - val_loss: 13.2008\n",
      "Epoch 328/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.9414 - val_loss: 11.8537\n",
      "Epoch 329/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.9468 - val_loss: 14.4830\n",
      "Epoch 330/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.3075 - val_loss: 12.7788\n",
      "Epoch 331/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 10.7453 - val_loss: 12.8599\n",
      "Epoch 332/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 10.1393 - val_loss: 12.3157\n",
      "Epoch 333/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.9884 - val_loss: 12.9196\n",
      "Epoch 334/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.7704 - val_loss: 13.0033\n",
      "Epoch 335/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.7277 - val_loss: 11.9666\n",
      "Epoch 336/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.8748 - val_loss: 12.1383\n",
      "Epoch 337/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 9.4812 - val_loss: 12.2228\n",
      "Epoch 338/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.8978 - val_loss: 12.3949\n",
      "Epoch 339/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.6450 - val_loss: 12.5421\n",
      "Epoch 340/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.8011 - val_loss: 11.6628\n",
      "Epoch 341/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 9.5549 - val_loss: 12.0749\n",
      "Epoch 342/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.4295 - val_loss: 12.5074\n",
      "Epoch 343/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.6935 - val_loss: 12.7055\n",
      "Epoch 344/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.0568 - val_loss: 11.7920\n",
      "Epoch 345/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2257 - val_loss: 14.0843\n",
      "Epoch 346/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.3932 - val_loss: 11.4387\n",
      "Epoch 347/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.4206 - val_loss: 11.6257\n",
      "Epoch 348/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.8123 - val_loss: 13.4841\n",
      "Epoch 349/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.9075 - val_loss: 12.2336\n",
      "Epoch 350/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.6760 - val_loss: 13.9160\n",
      "Epoch 351/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.5334 - val_loss: 11.7325\n",
      "Epoch 352/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1530 - val_loss: 13.4686\n",
      "Epoch 353/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.4410 - val_loss: 11.6756\n",
      "Epoch 354/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.0765 - val_loss: 12.4771\n",
      "Epoch 355/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 10.1204 - val_loss: 12.1396\n",
      "Epoch 356/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 9.4299 - val_loss: 11.5117\n",
      "Epoch 357/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.5122 - val_loss: 11.4626\n",
      "Epoch 358/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.9578 - val_loss: 10.9402\n",
      "Epoch 359/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2658 - val_loss: 11.7974\n",
      "Epoch 360/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.1035 - val_loss: 12.1204\n",
      "Epoch 361/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.3289 - val_loss: 11.0806\n",
      "Epoch 362/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9537 - val_loss: 12.8740\n",
      "Epoch 363/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.2437 - val_loss: 11.5818\n",
      "Epoch 364/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.0425 - val_loss: 11.8063\n",
      "Epoch 365/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 98us/step - loss: 9.1916 - val_loss: 11.4398\n",
      "Epoch 366/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1102 - val_loss: 11.7826\n",
      "Epoch 367/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.2983 - val_loss: 13.6353\n",
      "Epoch 368/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.0482 - val_loss: 11.2827\n",
      "Epoch 369/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 9.4119 - val_loss: 12.6844\n",
      "Epoch 370/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.6829 - val_loss: 11.6362\n",
      "Epoch 371/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.8859 - val_loss: 11.3968\n",
      "Epoch 372/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2511 - val_loss: 11.0712\n",
      "Epoch 373/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.8979 - val_loss: 11.0069\n",
      "Epoch 374/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.7715 - val_loss: 10.7891\n",
      "Epoch 375/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1343 - val_loss: 11.3694\n",
      "Epoch 376/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2506 - val_loss: 11.6643\n",
      "Epoch 377/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0577 - val_loss: 12.7512\n",
      "Epoch 378/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.0111 - val_loss: 12.3673\n",
      "Epoch 379/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0520 - val_loss: 11.1550\n",
      "Epoch 380/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0110 - val_loss: 11.7014\n",
      "Epoch 381/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.9542 - val_loss: 11.2660\n",
      "Epoch 382/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9838 - val_loss: 11.0497\n",
      "Epoch 383/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9563 - val_loss: 11.2862\n",
      "Epoch 384/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.8363 - val_loss: 11.0004\n",
      "Epoch 385/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.9476 - val_loss: 12.8154\n",
      "Epoch 386/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9569 - val_loss: 12.1593\n",
      "Epoch 387/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.0928 - val_loss: 10.8183\n",
      "Epoch 388/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.9766 - val_loss: 13.8738\n",
      "Epoch 389/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.3865 - val_loss: 11.0415\n",
      "Epoch 390/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9970 - val_loss: 10.7800\n",
      "Epoch 391/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6326 - val_loss: 10.8942\n",
      "Epoch 392/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.8529 - val_loss: 15.1110\n",
      "Epoch 393/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1426 - val_loss: 10.9443\n",
      "Epoch 394/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7832 - val_loss: 10.6499\n",
      "Epoch 395/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9629 - val_loss: 11.6897\n",
      "Epoch 396/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2414 - val_loss: 11.6412\n",
      "Epoch 397/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5941 - val_loss: 10.6648\n",
      "Epoch 398/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.0202 - val_loss: 10.8479\n",
      "Epoch 399/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 9.2574 - val_loss: 13.1945\n",
      "Epoch 400/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 9.0409 - val_loss: 11.2996\n",
      "Epoch 401/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.8063 - val_loss: 11.2599\n",
      "Epoch 402/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.4691 - val_loss: 10.5634\n",
      "Epoch 403/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.2742 - val_loss: 10.2901\n",
      "Epoch 404/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 9.0722 - val_loss: 12.5365\n",
      "Epoch 405/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.8831 - val_loss: 10.8355\n",
      "Epoch 406/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.6418 - val_loss: 11.0793\n",
      "Epoch 407/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.7724 - val_loss: 10.2808\n",
      "Epoch 408/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8196 - val_loss: 10.7955\n",
      "Epoch 409/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9675 - val_loss: 11.4808\n",
      "Epoch 410/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6460 - val_loss: 11.9474\n",
      "Epoch 411/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.7252 - val_loss: 10.5189\n",
      "Epoch 412/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8145 - val_loss: 12.7635\n",
      "Epoch 413/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1605 - val_loss: 11.0482\n",
      "Epoch 414/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6686 - val_loss: 10.2438\n",
      "Epoch 415/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5438 - val_loss: 11.2117\n",
      "Epoch 416/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6295 - val_loss: 10.8650\n",
      "Epoch 417/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6635 - val_loss: 10.3172\n",
      "Epoch 418/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.6164 - val_loss: 10.2666\n",
      "Epoch 419/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9541 - val_loss: 10.7868\n",
      "Epoch 420/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4661 - val_loss: 10.4331\n",
      "Epoch 421/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5346 - val_loss: 10.6353\n",
      "Epoch 422/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1321 - val_loss: 10.9975\n",
      "Epoch 423/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7547 - val_loss: 11.1966\n",
      "Epoch 424/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.7971 - val_loss: 10.6236\n",
      "Epoch 425/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5790 - val_loss: 10.8351\n",
      "Epoch 426/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1622 - val_loss: 10.8705\n",
      "Epoch 427/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8393 - val_loss: 10.7781\n",
      "Epoch 428/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.5772 - val_loss: 12.0641\n",
      "Epoch 429/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.6431 - val_loss: 10.5414\n",
      "Epoch 430/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6976 - val_loss: 10.2641\n",
      "Epoch 431/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6105 - val_loss: 11.3138\n",
      "Epoch 432/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.6445 - val_loss: 10.3796\n",
      "Epoch 433/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8028 - val_loss: 10.5946\n",
      "Epoch 434/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5450 - val_loss: 10.9031\n",
      "Epoch 435/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6232 - val_loss: 10.2885\n",
      "Epoch 436/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8353 - val_loss: 10.3893\n",
      "Epoch 437/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5503 - val_loss: 10.5664\n",
      "Epoch 438/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6600 - val_loss: 10.5216\n",
      "Epoch 439/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.1015 - val_loss: 11.1707\n",
      "Epoch 440/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7972 - val_loss: 11.9758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 441/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.4543 - val_loss: 10.8837\n",
      "Epoch 442/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5488 - val_loss: 10.8761\n",
      "Epoch 443/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5261 - val_loss: 11.0741\n",
      "Epoch 444/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4758 - val_loss: 10.4154\n",
      "Epoch 445/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5721 - val_loss: 11.3610\n",
      "Epoch 446/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.9611 - val_loss: 10.0119\n",
      "Epoch 447/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6824 - val_loss: 12.2901\n",
      "Epoch 448/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7255 - val_loss: 10.2684\n",
      "Epoch 449/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8390 - val_loss: 10.7644\n",
      "Epoch 450/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5686 - val_loss: 10.1386\n",
      "Epoch 451/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4942 - val_loss: 10.0163\n",
      "Epoch 452/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8035 - val_loss: 10.6360\n",
      "Epoch 453/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6196 - val_loss: 10.0883\n",
      "Epoch 454/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4543 - val_loss: 10.7808\n",
      "Epoch 455/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9880 - val_loss: 11.4080\n",
      "Epoch 456/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6032 - val_loss: 10.6058\n",
      "Epoch 457/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5008 - val_loss: 10.5776\n",
      "Epoch 458/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8903 - val_loss: 10.2927\n",
      "Epoch 459/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8749 - val_loss: 10.1789\n",
      "Epoch 460/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6234 - val_loss: 10.8209\n",
      "Epoch 461/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5665 - val_loss: 10.4030\n",
      "Epoch 462/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5301 - val_loss: 10.0455\n",
      "Epoch 463/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.5123 - val_loss: 10.3704\n",
      "Epoch 464/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7727 - val_loss: 10.8402\n",
      "Epoch 465/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5366 - val_loss: 10.0765\n",
      "Epoch 466/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5279 - val_loss: 10.7450\n",
      "Epoch 467/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5595 - val_loss: 10.4103\n",
      "Epoch 468/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.9672 - val_loss: 12.0847\n",
      "Epoch 469/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5513 - val_loss: 11.6479\n",
      "Epoch 470/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8141 - val_loss: 10.6421\n",
      "Epoch 471/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9084 - val_loss: 11.1893\n",
      "Epoch 472/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.7609 - val_loss: 11.4423\n",
      "Epoch 473/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.7540 - val_loss: 10.9477\n",
      "Epoch 474/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8547 - val_loss: 10.2423\n",
      "Epoch 475/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8268 - val_loss: 12.0348\n",
      "Epoch 476/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8334 - val_loss: 10.1477\n",
      "Epoch 477/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.7092 - val_loss: 10.2214\n",
      "Epoch 478/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.5061 - val_loss: 10.5091\n",
      "Epoch 479/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3972 - val_loss: 10.7347\n",
      "Epoch 480/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1055 - val_loss: 13.5338\n",
      "Epoch 481/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.4181 - val_loss: 10.2274\n",
      "Epoch 482/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6129 - val_loss: 10.0623\n",
      "Epoch 483/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.4102 - val_loss: 10.9673\n",
      "Epoch 484/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4714 - val_loss: 10.5957\n",
      "Epoch 485/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6549 - val_loss: 10.1792\n",
      "Epoch 486/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7162 - val_loss: 11.7595\n",
      "Epoch 487/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8155 - val_loss: 10.7125\n",
      "Epoch 488/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.4703 - val_loss: 11.8793\n",
      "Epoch 489/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4589 - val_loss: 13.0624\n",
      "Epoch 490/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.3257 - val_loss: 9.9016\n",
      "Epoch 491/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3681 - val_loss: 9.8697\n",
      "Epoch 492/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5295 - val_loss: 10.0909\n",
      "Epoch 493/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3701 - val_loss: 10.2074\n",
      "Epoch 494/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2805 - val_loss: 12.1314\n",
      "Epoch 495/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.6883 - val_loss: 10.2838\n",
      "Epoch 496/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6158 - val_loss: 10.0320\n",
      "Epoch 497/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5843 - val_loss: 10.7111\n",
      "Epoch 498/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6382 - val_loss: 9.7844\n",
      "Epoch 499/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9193 - val_loss: 10.4730\n",
      "Epoch 500/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.7059 - val_loss: 11.1078\n",
      "Epoch 501/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6210 - val_loss: 9.8493\n",
      "Epoch 502/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5718 - val_loss: 10.2017\n",
      "Epoch 503/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6883 - val_loss: 11.2869\n",
      "Epoch 504/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5748 - val_loss: 11.3582\n",
      "Epoch 505/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5776 - val_loss: 10.2893\n",
      "Epoch 506/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8966 - val_loss: 10.0835\n",
      "Epoch 507/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5770 - val_loss: 10.3956\n",
      "Epoch 508/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1988 - val_loss: 9.7082\n",
      "Epoch 509/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7223 - val_loss: 11.4122\n",
      "Epoch 510/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.5612 - val_loss: 10.3673\n",
      "Epoch 511/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5300 - val_loss: 10.7623\n",
      "Epoch 512/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3890 - val_loss: 10.0756\n",
      "Epoch 513/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3328 - val_loss: 10.9475\n",
      "Epoch 514/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4378 - val_loss: 10.1725\n",
      "Epoch 515/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5581 - val_loss: 10.0103\n",
      "Epoch 516/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3605 - val_loss: 9.7374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 517/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1945 - val_loss: 10.5516\n",
      "Epoch 518/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3383 - val_loss: 10.7151\n",
      "Epoch 519/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5788 - val_loss: 10.2698\n",
      "Epoch 520/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5592 - val_loss: 9.8783\n",
      "Epoch 521/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4627 - val_loss: 10.7476\n",
      "Epoch 522/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4425 - val_loss: 10.0406\n",
      "Epoch 523/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8826 - val_loss: 10.0009\n",
      "Epoch 524/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6022 - val_loss: 10.4154\n",
      "Epoch 525/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6490 - val_loss: 9.7367\n",
      "Epoch 526/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.5872 - val_loss: 10.6471\n",
      "Epoch 527/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5195 - val_loss: 9.9071\n",
      "Epoch 528/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5818 - val_loss: 9.8299\n",
      "Epoch 529/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5108 - val_loss: 9.7955\n",
      "Epoch 530/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2039 - val_loss: 11.0417\n",
      "Epoch 531/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3242 - val_loss: 9.7295\n",
      "Epoch 532/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5533 - val_loss: 10.0439\n",
      "Epoch 533/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2690 - val_loss: 10.5004\n",
      "Epoch 534/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2802 - val_loss: 9.7737\n",
      "Epoch 535/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5468 - val_loss: 10.0563\n",
      "Epoch 536/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3787 - val_loss: 9.9162\n",
      "Epoch 537/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.6381 - val_loss: 11.1254\n",
      "Epoch 538/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5516 - val_loss: 9.8407\n",
      "Epoch 539/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.4195 - val_loss: 9.9688\n",
      "Epoch 540/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.2696 - val_loss: 10.0089\n",
      "Epoch 541/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2731 - val_loss: 9.7680\n",
      "Epoch 542/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3435 - val_loss: 10.0744\n",
      "Epoch 543/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4979 - val_loss: 9.8606\n",
      "Epoch 544/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8715 - val_loss: 10.2388\n",
      "Epoch 545/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2603 - val_loss: 10.0082\n",
      "Epoch 546/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9502 - val_loss: 10.0333\n",
      "Epoch 547/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5417 - val_loss: 9.9532\n",
      "Epoch 548/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.1558 - val_loss: 9.6468\n",
      "Epoch 549/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6813 - val_loss: 11.3820\n",
      "Epoch 550/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5190 - val_loss: 9.9173\n",
      "Epoch 551/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5605 - val_loss: 9.8225\n",
      "Epoch 552/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6289 - val_loss: 10.1593\n",
      "Epoch 553/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2892 - val_loss: 10.2476\n",
      "Epoch 554/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4603 - val_loss: 9.9697\n",
      "Epoch 555/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2980 - val_loss: 10.4332\n",
      "Epoch 556/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.3192 - val_loss: 10.3412\n",
      "Epoch 557/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.2988 - val_loss: 11.5713\n",
      "Epoch 558/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.4371 - val_loss: 11.5044\n",
      "Epoch 559/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3851 - val_loss: 9.8982\n",
      "Epoch 560/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5359 - val_loss: 10.5418\n",
      "Epoch 561/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4148 - val_loss: 9.6731\n",
      "Epoch 562/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1390 - val_loss: 10.1949\n",
      "Epoch 563/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.3469 - val_loss: 10.4227\n",
      "Epoch 564/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3589 - val_loss: 9.4670\n",
      "Epoch 565/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3889 - val_loss: 10.5725\n",
      "Epoch 566/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.7144 - val_loss: 9.7265\n",
      "Epoch 567/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 8.3583 - val_loss: 11.1029\n",
      "Epoch 568/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.5400 - val_loss: 9.4838\n",
      "Epoch 569/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.2735 - val_loss: 11.4180\n",
      "Epoch 570/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.6632 - val_loss: 11.5358\n",
      "Epoch 571/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.2485 - val_loss: 11.1275\n",
      "Epoch 572/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.5058 - val_loss: 9.6363\n",
      "Epoch 573/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.5046 - val_loss: 9.9934\n",
      "Epoch 574/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.3828 - val_loss: 10.6276\n",
      "Epoch 575/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4134 - val_loss: 10.3210\n",
      "Epoch 576/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3465 - val_loss: 10.4104\n",
      "Epoch 577/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1407 - val_loss: 9.6435\n",
      "Epoch 578/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5161 - val_loss: 10.0953\n",
      "Epoch 579/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.4431 - val_loss: 11.0513\n",
      "Epoch 580/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.7282 - val_loss: 9.8996\n",
      "Epoch 581/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3289 - val_loss: 11.0606\n",
      "Epoch 582/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2394 - val_loss: 10.0586\n",
      "Epoch 583/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2412 - val_loss: 10.1173\n",
      "Epoch 584/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4308 - val_loss: 9.6859\n",
      "Epoch 585/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.7225 - val_loss: 11.3577\n",
      "Epoch 586/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3375 - val_loss: 9.6501\n",
      "Epoch 587/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7304 - val_loss: 11.7249\n",
      "Epoch 588/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4448 - val_loss: 9.9880\n",
      "Epoch 589/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3030 - val_loss: 10.9749\n",
      "Epoch 590/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5398 - val_loss: 9.8302\n",
      "Epoch 591/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7402 - val_loss: 10.3590\n",
      "Epoch 592/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5796 - val_loss: 9.8638\n",
      "Epoch 593/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2584 - val_loss: 9.5629\n",
      "Epoch 594/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2523 - val_loss: 11.5094\n",
      "Epoch 595/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.3405 - val_loss: 9.6602\n",
      "Epoch 596/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1999 - val_loss: 11.2769\n",
      "Epoch 597/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.3859 - val_loss: 10.5817\n",
      "Epoch 598/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6766 - val_loss: 9.8540\n",
      "Epoch 599/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9456 - val_loss: 10.4575\n",
      "Epoch 600/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3046 - val_loss: 10.1441\n",
      "Epoch 601/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6811 - val_loss: 10.2384\n",
      "Epoch 602/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4472 - val_loss: 9.4873\n",
      "Epoch 603/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5010 - val_loss: 10.0307\n",
      "Epoch 604/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5849 - val_loss: 12.6163\n",
      "Epoch 605/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2680 - val_loss: 9.6245\n",
      "Epoch 606/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3694 - val_loss: 9.9947\n",
      "Epoch 607/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5330 - val_loss: 9.3817\n",
      "Epoch 608/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3373 - val_loss: 9.6659\n",
      "Epoch 609/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5060 - val_loss: 9.4415\n",
      "Epoch 610/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4420 - val_loss: 9.9092\n",
      "Epoch 611/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.3558 - val_loss: 10.2857\n",
      "Epoch 612/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6191 - val_loss: 9.6511\n",
      "Epoch 613/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3778 - val_loss: 9.7813\n",
      "Epoch 614/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.4221 - val_loss: 9.5543\n",
      "Epoch 615/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3330 - val_loss: 9.8124\n",
      "Epoch 616/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5392 - val_loss: 10.2036\n",
      "Epoch 617/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4962 - val_loss: 10.6983\n",
      "Epoch 618/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5023 - val_loss: 10.6593\n",
      "Epoch 619/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.2946 - val_loss: 9.8818\n",
      "Epoch 620/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2324 - val_loss: 9.9307\n",
      "Epoch 621/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7009 - val_loss: 11.7046\n",
      "Epoch 622/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4103 - val_loss: 11.0345\n",
      "Epoch 623/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.6264 - val_loss: 10.2602\n",
      "Epoch 624/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3957 - val_loss: 9.7362\n",
      "Epoch 625/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3664 - val_loss: 9.6979\n",
      "Epoch 626/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.5859 - val_loss: 9.5226\n",
      "Epoch 627/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2475 - val_loss: 10.1734\n",
      "Epoch 628/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.8894 - val_loss: 9.4222\n",
      "Epoch 629/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.5453 - val_loss: 10.2331\n",
      "Epoch 630/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.7415 - val_loss: 10.6852\n",
      "Epoch 631/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5248 - val_loss: 10.0795\n",
      "Epoch 632/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3695 - val_loss: 9.4528\n",
      "Epoch 633/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7474 - val_loss: 9.7300\n",
      "Epoch 634/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6206 - val_loss: 10.3781\n",
      "Epoch 635/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8537 - val_loss: 9.5418\n",
      "Epoch 636/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4262 - val_loss: 12.3601\n",
      "Epoch 637/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9084 - val_loss: 10.3513\n",
      "Epoch 638/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1292 - val_loss: 9.6312\n",
      "Epoch 639/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1216 - val_loss: 10.4624\n",
      "Epoch 640/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4893 - val_loss: 10.0714\n",
      "Epoch 641/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5477 - val_loss: 12.9962\n",
      "Epoch 642/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4816 - val_loss: 10.3824\n",
      "Epoch 643/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2333 - val_loss: 9.6936\n",
      "Epoch 644/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5744 - val_loss: 9.7817\n",
      "Epoch 645/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6738 - val_loss: 9.4193\n",
      "Epoch 646/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3628 - val_loss: 10.1854\n",
      "Epoch 647/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.4327 - val_loss: 9.7477\n",
      "Epoch 648/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1820 - val_loss: 9.8203\n",
      "Epoch 649/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0567 - val_loss: 9.5546\n",
      "Epoch 650/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1488 - val_loss: 10.5505\n",
      "Epoch 651/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1983 - val_loss: 9.3687\n",
      "Epoch 652/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3597 - val_loss: 9.5423\n",
      "Epoch 653/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3024 - val_loss: 10.4154\n",
      "Epoch 654/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.2951 - val_loss: 9.8289\n",
      "Epoch 655/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.1748 - val_loss: 11.6902\n",
      "Epoch 656/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4045 - val_loss: 10.8789\n",
      "Epoch 657/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2298 - val_loss: 9.5881\n",
      "Epoch 658/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6278 - val_loss: 9.5130\n",
      "Epoch 659/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.5033 - val_loss: 9.2452\n",
      "Epoch 660/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6310 - val_loss: 10.1841\n",
      "Epoch 661/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3591 - val_loss: 9.5826\n",
      "Epoch 662/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5424 - val_loss: 9.8708\n",
      "Epoch 663/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.5221 - val_loss: 10.0995\n",
      "Epoch 664/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4178 - val_loss: 11.3708\n",
      "Epoch 665/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4537 - val_loss: 9.5135\n",
      "Epoch 666/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1928 - val_loss: 10.0229\n",
      "Epoch 667/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2777 - val_loss: 10.2662\n",
      "Epoch 668/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8407 - val_loss: 10.0179\n",
      "Epoch 669/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.4326 - val_loss: 9.2384\n",
      "Epoch 670/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2600 - val_loss: 10.9320\n",
      "Epoch 671/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3009 - val_loss: 9.5271\n",
      "Epoch 672/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3803 - val_loss: 10.0978\n",
      "Epoch 673/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5437 - val_loss: 10.4323\n",
      "Epoch 674/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.2896 - val_loss: 10.0702\n",
      "Epoch 675/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.5159 - val_loss: 9.5269\n",
      "Epoch 676/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6605 - val_loss: 9.6269\n",
      "Epoch 677/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2493 - val_loss: 10.0399\n",
      "Epoch 678/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1023 - val_loss: 9.3859\n",
      "Epoch 679/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3840 - val_loss: 9.5122\n",
      "Epoch 680/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2560 - val_loss: 9.4196\n",
      "Epoch 681/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7621 - val_loss: 11.1049\n",
      "Epoch 682/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2874 - val_loss: 12.0636\n",
      "Epoch 683/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5208 - val_loss: 9.9503\n",
      "Epoch 684/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.5065 - val_loss: 9.8783\n",
      "Epoch 685/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2784 - val_loss: 10.6307\n",
      "Epoch 686/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1745 - val_loss: 11.5090\n",
      "Epoch 687/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4381 - val_loss: 9.9964\n",
      "Epoch 688/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1031 - val_loss: 9.4722\n",
      "Epoch 689/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.2291 - val_loss: 9.7688\n",
      "Epoch 690/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1758 - val_loss: 10.7469\n",
      "Epoch 691/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1081 - val_loss: 10.2218\n",
      "Epoch 692/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4953 - val_loss: 10.4005\n",
      "Epoch 693/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6585 - val_loss: 9.5739\n",
      "Epoch 694/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2476 - val_loss: 9.5009\n",
      "Epoch 695/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7090 - val_loss: 11.2314\n",
      "Epoch 696/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2295 - val_loss: 9.5028\n",
      "Epoch 697/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.2623 - val_loss: 11.2862\n",
      "Epoch 698/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.4334 - val_loss: 10.5368\n",
      "Epoch 699/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3749 - val_loss: 10.1075\n",
      "Epoch 700/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7144 - val_loss: 9.5609\n",
      "Epoch 701/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.7983 - val_loss: 9.9031\n",
      "Epoch 702/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3926 - val_loss: 9.4889\n",
      "Epoch 703/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1905 - val_loss: 9.2549\n",
      "Epoch 704/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2255 - val_loss: 10.1213\n",
      "Epoch 705/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.1948 - val_loss: 9.4078\n",
      "Epoch 706/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2142 - val_loss: 9.6204\n",
      "Epoch 707/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1336 - val_loss: 10.4269\n",
      "Epoch 708/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8899 - val_loss: 9.8395\n",
      "Epoch 709/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5493 - val_loss: 10.0539\n",
      "Epoch 710/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1571 - val_loss: 9.5291\n",
      "Epoch 711/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.4471 - val_loss: 9.5930\n",
      "Epoch 712/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.1833 - val_loss: 10.0257\n",
      "Epoch 713/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5026 - val_loss: 10.8140\n",
      "Epoch 714/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.3477 - val_loss: 10.1188\n",
      "Epoch 715/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4523 - val_loss: 10.4467\n",
      "Epoch 716/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3882 - val_loss: 9.6229\n",
      "Epoch 717/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2741 - val_loss: 10.2701\n",
      "Epoch 718/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2102 - val_loss: 10.3894\n",
      "Epoch 719/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2860 - val_loss: 10.5297\n",
      "Epoch 720/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2884 - val_loss: 9.4898\n",
      "Epoch 721/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1340 - val_loss: 10.2247\n",
      "Epoch 722/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3025 - val_loss: 9.2625\n",
      "Epoch 723/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3971 - val_loss: 9.5343\n",
      "Epoch 724/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.2833 - val_loss: 10.1296\n",
      "Epoch 725/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0864 - val_loss: 9.4999\n",
      "Epoch 726/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0748 - val_loss: 10.3727\n",
      "Epoch 727/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3156 - val_loss: 9.3248\n",
      "Epoch 728/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2154 - val_loss: 9.2893\n",
      "Epoch 729/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.4259 - val_loss: 10.3302\n",
      "Epoch 730/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1137 - val_loss: 9.1423\n",
      "Epoch 731/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2446 - val_loss: 11.6909\n",
      "Epoch 732/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.2123 - val_loss: 9.2573\n",
      "Epoch 733/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4064 - val_loss: 10.4850\n",
      "Epoch 734/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.5054 - val_loss: 9.2992\n",
      "Epoch 735/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.4019 - val_loss: 9.6473\n",
      "Epoch 736/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.4261 - val_loss: 9.4946\n",
      "Epoch 737/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.0647 - val_loss: 9.8853\n",
      "Epoch 738/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.3960 - val_loss: 10.1215\n",
      "Epoch 739/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.7329 - val_loss: 9.2869\n",
      "Epoch 740/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.2084 - val_loss: 10.7281\n",
      "Epoch 741/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5246 - val_loss: 11.0011\n",
      "Epoch 742/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.7317 - val_loss: 9.7394\n",
      "Epoch 743/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.2502 - val_loss: 9.7440\n",
      "Epoch 744/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3244 - val_loss: 10.8741\n",
      "Epoch 745/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0458 - val_loss: 9.6115\n",
      "Epoch 746/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5742 - val_loss: 9.4098\n",
      "Epoch 747/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1140 - val_loss: 9.4041\n",
      "Epoch 748/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3337 - val_loss: 12.1390\n",
      "Epoch 749/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.3147 - val_loss: 9.4832\n",
      "Epoch 750/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.9935 - val_loss: 9.4288\n",
      "Epoch 751/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3496 - val_loss: 9.5936\n",
      "Epoch 752/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.0852 - val_loss: 10.0055\n",
      "Epoch 753/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0012 - val_loss: 9.6810\n",
      "Epoch 754/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2900 - val_loss: 9.6225\n",
      "Epoch 755/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3890 - val_loss: 12.3481\n",
      "Epoch 756/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5736 - val_loss: 9.2936\n",
      "Epoch 757/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.1724 - val_loss: 9.3804\n",
      "Epoch 758/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3732 - val_loss: 9.3623\n",
      "Epoch 759/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2175 - val_loss: 10.0281\n",
      "Epoch 760/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3180 - val_loss: 9.8388\n",
      "Epoch 761/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2553 - val_loss: 9.4248\n",
      "Epoch 762/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3931 - val_loss: 9.5702\n",
      "Epoch 763/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.2829 - val_loss: 10.8959\n",
      "Epoch 764/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7450 - val_loss: 9.3530\n",
      "Epoch 765/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4850 - val_loss: 9.3209\n",
      "Epoch 766/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2236 - val_loss: 9.9312\n",
      "Epoch 767/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1101 - val_loss: 9.2747\n",
      "Epoch 768/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.0435 - val_loss: 9.4477\n",
      "Epoch 769/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3062 - val_loss: 9.7772\n",
      "Epoch 770/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2290 - val_loss: 10.0728\n",
      "Epoch 771/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0826 - val_loss: 9.8659\n",
      "Epoch 772/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2341 - val_loss: 9.3014\n",
      "Epoch 773/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.1467 - val_loss: 11.3649\n",
      "Epoch 774/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.1795 - val_loss: 9.7402\n",
      "Epoch 775/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1044 - val_loss: 10.0212\n",
      "Epoch 776/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5646 - val_loss: 11.1252\n",
      "Epoch 777/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1372 - val_loss: 9.7481\n",
      "Epoch 778/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2657 - val_loss: 10.5332\n",
      "Epoch 779/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2708 - val_loss: 11.2949\n",
      "Epoch 780/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.8744 - val_loss: 9.8713\n",
      "Epoch 781/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5020 - val_loss: 10.1904\n",
      "Epoch 782/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.0089 - val_loss: 9.9859\n",
      "Epoch 783/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3930 - val_loss: 9.8342\n",
      "Epoch 784/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4900 - val_loss: 9.2836\n",
      "Epoch 785/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.5228 - val_loss: 10.3171\n",
      "Epoch 786/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3102 - val_loss: 9.4546\n",
      "Epoch 787/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2395 - val_loss: 9.5193\n",
      "Epoch 788/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3918 - val_loss: 9.3427\n",
      "Epoch 789/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1016 - val_loss: 11.3151\n",
      "Epoch 790/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3127 - val_loss: 10.1006\n",
      "Epoch 791/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.2084 - val_loss: 9.9738\n",
      "Epoch 792/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2834 - val_loss: 9.5422\n",
      "Epoch 793/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1028 - val_loss: 9.4688\n",
      "Epoch 794/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2318 - val_loss: 10.0641\n",
      "Epoch 795/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.4622 - val_loss: 9.8918\n",
      "Epoch 796/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7902 - val_loss: 9.6250\n",
      "Epoch 797/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2787 - val_loss: 10.5998\n",
      "Epoch 798/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.4986 - val_loss: 9.1973\n",
      "Epoch 799/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1455 - val_loss: 9.7583\n",
      "Epoch 800/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4009 - val_loss: 11.0922\n",
      "Epoch 801/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3322 - val_loss: 10.1943\n",
      "Epoch 802/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4118 - val_loss: 10.2541\n",
      "Epoch 803/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5716 - val_loss: 11.6542\n",
      "Epoch 804/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.1171 - val_loss: 11.3622\n",
      "Epoch 805/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1292 - val_loss: 9.3309\n",
      "Epoch 806/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4774 - val_loss: 9.3330\n",
      "Epoch 807/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1313 - val_loss: 10.6639\n",
      "Epoch 808/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3870 - val_loss: 9.2222\n",
      "Epoch 809/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4842 - val_loss: 9.6912\n",
      "Epoch 810/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5803 - val_loss: 9.5980\n",
      "Epoch 811/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.0562 - val_loss: 9.5126\n",
      "Epoch 812/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1779 - val_loss: 9.1136\n",
      "Epoch 813/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4338 - val_loss: 9.2514\n",
      "Epoch 814/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3920 - val_loss: 9.9804\n",
      "Epoch 815/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3388 - val_loss: 10.0010\n",
      "Epoch 816/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3922 - val_loss: 10.1171\n",
      "Epoch 817/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2814 - val_loss: 9.5291\n",
      "Epoch 818/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8411 - val_loss: 10.1431\n",
      "Epoch 819/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0851 - val_loss: 9.2032\n",
      "Epoch 820/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.9413 - val_loss: 10.4913\n",
      "Epoch 821/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7631 - val_loss: 9.0475\n",
      "Epoch 822/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.4896 - val_loss: 9.6195\n",
      "Epoch 823/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6362 - val_loss: 9.5736\n",
      "Epoch 824/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1466 - val_loss: 10.1280\n",
      "Epoch 825/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.9394 - val_loss: 10.0055\n",
      "Epoch 826/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1927 - val_loss: 9.0814\n",
      "Epoch 827/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3923 - val_loss: 11.4951\n",
      "Epoch 828/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4012 - val_loss: 10.6890\n",
      "Epoch 829/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0855 - val_loss: 9.9488\n",
      "Epoch 830/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1490 - val_loss: 9.3401\n",
      "Epoch 831/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9826 - val_loss: 10.4299\n",
      "Epoch 832/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.5162 - val_loss: 9.3403\n",
      "Epoch 833/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3985 - val_loss: 10.3308\n",
      "Epoch 834/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6271 - val_loss: 9.2855\n",
      "Epoch 835/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3270 - val_loss: 9.9127\n",
      "Epoch 836/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1605 - val_loss: 13.2755\n",
      "Epoch 837/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4986 - val_loss: 12.1324\n",
      "Epoch 838/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4381 - val_loss: 12.0109\n",
      "Epoch 839/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.0630 - val_loss: 9.0871\n",
      "Epoch 840/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1286 - val_loss: 10.7297\n",
      "Epoch 841/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0549 - val_loss: 9.4289\n",
      "Epoch 842/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2943 - val_loss: 9.7731\n",
      "Epoch 843/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0692 - val_loss: 9.8296\n",
      "Epoch 844/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4215 - val_loss: 9.6020\n",
      "Epoch 845/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9187 - val_loss: 10.2633\n",
      "Epoch 846/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3132 - val_loss: 9.9118\n",
      "Epoch 847/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2182 - val_loss: 10.3403\n",
      "Epoch 848/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3297 - val_loss: 9.7526\n",
      "Epoch 849/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1579 - val_loss: 9.0029\n",
      "Epoch 850/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.3356 - val_loss: 10.9177\n",
      "Epoch 851/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2292 - val_loss: 9.9494\n",
      "Epoch 852/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0981 - val_loss: 9.6187\n",
      "Epoch 853/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3605 - val_loss: 9.4722\n",
      "Epoch 854/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3057 - val_loss: 12.8025\n",
      "Epoch 855/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6740 - val_loss: 9.4530\n",
      "Epoch 856/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1935 - val_loss: 9.5797\n",
      "Epoch 857/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1022 - val_loss: 9.4758\n",
      "Epoch 858/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.9936 - val_loss: 9.7856\n",
      "Epoch 859/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1016 - val_loss: 10.2659\n",
      "Epoch 860/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2408 - val_loss: 9.7491\n",
      "Epoch 861/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4071 - val_loss: 11.0718\n",
      "Epoch 862/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 8.5865 - 0s 89us/step - loss: 8.4738 - val_loss: 10.0246\n",
      "Epoch 863/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1214 - val_loss: 9.5683\n",
      "Epoch 864/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.4646 - val_loss: 9.3537\n",
      "Epoch 865/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1591 - val_loss: 9.4412\n",
      "Epoch 866/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1143 - val_loss: 9.3993\n",
      "Epoch 867/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.0686 - val_loss: 9.1309\n",
      "Epoch 868/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1822 - val_loss: 9.9264\n",
      "Epoch 869/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5833 - val_loss: 9.1732\n",
      "Epoch 870/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2709 - val_loss: 9.2823\n",
      "Epoch 871/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1919 - val_loss: 11.2107\n",
      "Epoch 872/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4248 - val_loss: 9.6683\n",
      "Epoch 873/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.2543 - val_loss: 9.2226\n",
      "Epoch 874/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0248 - val_loss: 9.1765\n",
      "Epoch 875/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2583 - val_loss: 9.1898\n",
      "Epoch 876/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2622 - val_loss: 10.0524\n",
      "Epoch 877/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4776 - val_loss: 9.9611\n",
      "Epoch 878/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4041 - val_loss: 9.5555\n",
      "Epoch 879/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.4124 - val_loss: 9.8016\n",
      "Epoch 880/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7052 - val_loss: 10.4200\n",
      "Epoch 881/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1298 - val_loss: 9.7540\n",
      "Epoch 882/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0255 - val_loss: 9.4207\n",
      "Epoch 883/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.0607 - val_loss: 9.7280\n",
      "Epoch 884/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1988 - val_loss: 9.9151\n",
      "Epoch 885/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.9572 - val_loss: 10.1507\n",
      "Epoch 886/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1145 - val_loss: 9.1406\n",
      "Epoch 887/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8612 - val_loss: 9.3165\n",
      "Epoch 888/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0543 - val_loss: 10.0039\n",
      "Epoch 889/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3266 - val_loss: 11.5206\n",
      "Epoch 890/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1626 - val_loss: 9.6143\n",
      "Epoch 891/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1167 - val_loss: 9.5583\n",
      "Epoch 892/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.8869 - val_loss: 10.1324\n",
      "Epoch 893/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0556 - val_loss: 9.9813\n",
      "Epoch 894/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0473 - val_loss: 9.7312\n",
      "Epoch 895/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.9358 - val_loss: 10.3034\n",
      "Epoch 896/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0166 - val_loss: 9.6955\n",
      "Epoch 897/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0425 - val_loss: 9.1376\n",
      "Epoch 898/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1817 - val_loss: 9.3813\n",
      "Epoch 899/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5021 - val_loss: 9.1349\n",
      "Epoch 900/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1693 - val_loss: 9.4929\n",
      "Epoch 901/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0874 - val_loss: 9.7685\n",
      "Epoch 902/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1316 - val_loss: 9.0599\n",
      "Epoch 903/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 8.0588 - val_loss: 9.5443\n",
      "Epoch 904/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 8.1139 - val_loss: 9.9959\n",
      "Epoch 905/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.1310 - val_loss: 9.2721\n",
      "Epoch 906/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.1283 - val_loss: 9.2916\n",
      "Epoch 907/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.0923 - val_loss: 8.9726\n",
      "Epoch 908/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.0681 - val_loss: 9.5475\n",
      "Epoch 909/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.2869 - val_loss: 9.3589\n",
      "Epoch 910/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.9855 - val_loss: 9.7600\n",
      "Epoch 911/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2502 - val_loss: 8.9843\n",
      "Epoch 912/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5008 - val_loss: 10.1594\n",
      "Epoch 913/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2356 - val_loss: 9.4375\n",
      "Epoch 914/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9067 - val_loss: 12.9657\n",
      "Epoch 915/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3102 - val_loss: 9.8981\n",
      "Epoch 916/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.4424 - val_loss: 10.4860\n",
      "Epoch 917/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4925 - val_loss: 13.0269\n",
      "Epoch 918/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4136 - val_loss: 9.5719\n",
      "Epoch 919/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.0822 - val_loss: 9.9348\n",
      "Epoch 920/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1875 - val_loss: 9.0386\n",
      "Epoch 921/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1472 - val_loss: 9.9083\n",
      "Epoch 922/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.3470 - val_loss: 11.1140\n",
      "Epoch 923/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2067 - val_loss: 10.0994\n",
      "Epoch 924/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2146 - val_loss: 9.7809\n",
      "Epoch 925/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.0607 - val_loss: 9.3488\n",
      "Epoch 926/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3781 - val_loss: 9.2638\n",
      "Epoch 927/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4029 - val_loss: 10.4871\n",
      "Epoch 928/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.0339 - val_loss: 10.4956\n",
      "Epoch 929/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1551 - val_loss: 9.5623\n",
      "Epoch 930/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3587 - val_loss: 9.4757\n",
      "Epoch 931/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.0049 - val_loss: 10.3924\n",
      "Epoch 932/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.2560 - val_loss: 10.1337\n",
      "Epoch 933/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8296 - val_loss: 10.1357\n",
      "Epoch 934/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3578 - val_loss: 9.2402\n",
      "Epoch 935/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.1809 - val_loss: 10.7692\n",
      "Epoch 936/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8329 - val_loss: 9.6214\n",
      "Epoch 937/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8182 - val_loss: 11.1464\n",
      "Epoch 938/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.0524 - val_loss: 9.0934\n",
      "Epoch 939/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.1845 - val_loss: 10.5513\n",
      "Epoch 940/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.0641 - val_loss: 11.6974\n",
      "Epoch 941/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3233 - val_loss: 10.3661\n",
      "Epoch 942/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2363 - val_loss: 9.4377\n",
      "Epoch 943/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3016 - val_loss: 9.7397\n",
      "Epoch 944/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1854 - val_loss: 9.5520\n",
      "Epoch 945/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.9293 - val_loss: 9.2253\n",
      "Epoch 946/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.2151 - val_loss: 8.9511\n",
      "Epoch 947/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4855 - val_loss: 11.6420\n",
      "Epoch 948/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6330 - val_loss: 9.7383\n",
      "Epoch 949/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4013 - val_loss: 9.2843\n",
      "Epoch 950/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1267 - val_loss: 9.8956\n",
      "Epoch 951/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.9669 - val_loss: 9.7309\n",
      "Epoch 952/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4685 - val_loss: 10.2734\n",
      "Epoch 953/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.1387 - val_loss: 9.3575\n",
      "Epoch 954/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0614 - val_loss: 9.1733\n",
      "Epoch 955/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0871 - val_loss: 9.3888\n",
      "Epoch 956/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0292 - val_loss: 9.4373\n",
      "Epoch 957/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1695 - val_loss: 9.1529\n",
      "Epoch 958/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2121 - val_loss: 10.9882\n",
      "Epoch 959/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0466 - val_loss: 9.2872\n",
      "Epoch 960/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.0776 - val_loss: 9.9625\n",
      "Epoch 961/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.9762 - val_loss: 9.8062\n",
      "Epoch 962/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3415 - val_loss: 8.9908\n",
      "Epoch 963/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2677 - val_loss: 9.3375\n",
      "Epoch 964/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.1893 - val_loss: 10.5090\n",
      "Epoch 965/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3699 - val_loss: 10.1118\n",
      "Epoch 966/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4145 - val_loss: 9.0347\n",
      "Epoch 967/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2995 - val_loss: 9.7983\n",
      "Epoch 968/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0827 - val_loss: 8.9898\n",
      "Epoch 969/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4961 - val_loss: 9.1407\n",
      "Epoch 970/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.1618 - val_loss: 9.4568\n",
      "Epoch 971/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9564 - val_loss: 9.7880\n",
      "Epoch 972/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.8049 - val_loss: 9.5547\n",
      "Epoch 973/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.0903 - val_loss: 9.2901\n",
      "Epoch 974/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.1138 - val_loss: 10.1355\n",
      "Epoch 975/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2020 - val_loss: 9.1402\n",
      "Epoch 976/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.4492 - val_loss: 9.1899\n",
      "Epoch 977/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3800 - val_loss: 9.6453\n",
      "Epoch 978/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1900 - val_loss: 9.1440\n",
      "Epoch 979/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.2333 - val_loss: 9.1861\n",
      "Epoch 980/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.9249 - val_loss: 9.6971\n",
      "Epoch 981/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1542 - val_loss: 9.5726\n",
      "Epoch 982/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0762 - val_loss: 9.5184\n",
      "Epoch 983/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.9934 - val_loss: 9.1028\n",
      "Epoch 984/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1567 - val_loss: 9.3941\n",
      "Epoch 985/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4426 - val_loss: 9.5719\n",
      "Epoch 986/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.2110 - val_loss: 9.3982\n",
      "Epoch 987/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1624 - val_loss: 9.2289\n",
      "Epoch 988/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0321 - val_loss: 9.1473\n",
      "Epoch 989/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.2875 - val_loss: 9.5045\n",
      "Epoch 990/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3502 - val_loss: 10.2499\n",
      "Epoch 991/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5171 - val_loss: 10.0129\n",
      "Epoch 992/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3057 - val_loss: 10.7940\n",
      "Epoch 993/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6653 - val_loss: 9.3546\n",
      "Epoch 994/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7325 - val_loss: 9.8707\n",
      "Epoch 995/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.4146 - val_loss: 9.5104\n",
      "Epoch 996/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.0223 - val_loss: 10.8024\n",
      "Epoch 997/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4563 - val_loss: 10.3445\n",
      "Epoch 998/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6307 - val_loss: 9.8266\n",
      "Epoch 999/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2704 - val_loss: 9.4808\n",
      "Epoch 1000/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.0996 - val_loss: 9.8113\n",
      "7.8311638030330695\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-1.8719815 , -0.70353127, -0.16644102, -3.2435915 ,  3.8360088 ],\n",
       "        [ 0.48370406, -1.4035313 , -0.18981631,  0.09060076, -0.21139403],\n",
       "        [ 0.4033324 , -1.5788172 , -0.28289875, -0.00454685,  0.7078572 ],\n",
       "        [ 0.02927194,  0.25109854,  0.1316003 ,  0.05463107, -0.1432545 ],\n",
       "        [-0.32422116,  0.29048452, -0.18447773, -2.4228208 ,  0.328253  ]],\n",
       "       dtype=float32),\n",
       " array([-1.2950469, -0.7019617,  1.530619 , -4.7311363,  4.774982 ],\n",
       "       dtype=float32),\n",
       " array([[ 1.008399  , -0.21073602,  0.88689995, -0.7137894 , -1.2686211 ],\n",
       "        [ 1.0261103 ,  0.00938091,  0.88590646, -0.49040246,  0.12281685],\n",
       "        [ 2.8317869 , -3.0264223 ,  2.5568082 , -2.7092123 , -3.0915775 ],\n",
       "        [-2.7250457 ,  1.6903435 , -2.6647012 ,  2.1479414 ,  2.1384213 ],\n",
       "        [ 2.9609253 , -2.2491028 ,  3.0956051 , -3.271654  , -2.986916  ]],\n",
       "       dtype=float32),\n",
       " array([ 2.3604026, -2.4299738,  2.2260025, -2.3108332, -2.3956265],\n",
       "       dtype=float32),\n",
       " array([[ 2.4715276],\n",
       "        [-2.5361001],\n",
       "        [ 2.9442945],\n",
       "        [-2.728408 ],\n",
       "        [-2.4598036]], dtype=float32),\n",
       " array([2.0677269], dtype=float32)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_airfoil, history_airfoil=NN_model_structure_regression_1(X_train_airfoil, X_val_airfoil, Y_train_airfoil, Y_val_airfoil, adam2, 32, 1000)\n",
    "model_airfoil.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_airfoil.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_airfoil_structure1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 101\n",
      "Trainable params: 101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1052 samples, validate on 225 samples\n",
      "Epoch 1/1000\n",
      "1052/1052 [==============================] - 0s 194us/step - loss: 7402.1613 - val_loss: 523.9694\n",
      "Epoch 2/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 169.7698 - val_loss: 51.8719\n",
      "Epoch 3/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 40.4323 - val_loss: 33.7123\n",
      "Epoch 4/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 30.6864 - val_loss: 29.5366\n",
      "Epoch 5/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 27.1370 - val_loss: 29.5167\n",
      "Epoch 6/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 25.7019 - val_loss: 28.0666\n",
      "Epoch 7/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 24.9415 - val_loss: 28.5261\n",
      "Epoch 8/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 24.4938 - val_loss: 28.0879\n",
      "Epoch 9/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 24.7806 - val_loss: 27.6809\n",
      "Epoch 10/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 24.1837 - val_loss: 28.3404\n",
      "Epoch 11/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 24.0575 - val_loss: 27.8557\n",
      "Epoch 12/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 23.6700 - val_loss: 27.3165\n",
      "Epoch 13/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 23.4978 - val_loss: 27.4859\n",
      "Epoch 14/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 23.4993 - val_loss: 27.3327\n",
      "Epoch 15/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 24.0640 - val_loss: 28.0241\n",
      "Epoch 16/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 23.3225 - val_loss: 27.2693\n",
      "Epoch 17/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 23.0959 - val_loss: 27.2993\n",
      "Epoch 18/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 23.1570 - val_loss: 27.3684\n",
      "Epoch 19/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 22.8572 - val_loss: 26.8560\n",
      "Epoch 20/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 22.9227 - val_loss: 26.2696\n",
      "Epoch 21/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 22.6792 - val_loss: 27.1399\n",
      "Epoch 22/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 22.8117 - val_loss: 26.3459\n",
      "Epoch 23/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 23.2008 - val_loss: 26.9434\n",
      "Epoch 24/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 22.9374 - val_loss: 26.7161\n",
      "Epoch 25/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.6522 - val_loss: 27.3063\n",
      "Epoch 26/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.6367 - val_loss: 26.5352\n",
      "Epoch 27/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 22.2993 - val_loss: 26.1389\n",
      "Epoch 28/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.7798 - val_loss: 26.6633\n",
      "Epoch 29/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 22.0077 - val_loss: 26.0098\n",
      "Epoch 30/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 22.2968 - val_loss: 25.8110\n",
      "Epoch 31/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.0742 - val_loss: 25.9901\n",
      "Epoch 32/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.8868 - val_loss: 25.9644\n",
      "Epoch 33/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.2048 - val_loss: 26.7438\n",
      "Epoch 34/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 22.0638 - val_loss: 25.8890\n",
      "Epoch 35/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 21.8074 - val_loss: 25.3519\n",
      "Epoch 36/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.7048 - val_loss: 25.6337\n",
      "Epoch 37/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.6361 - val_loss: 25.9778\n",
      "Epoch 38/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.5446 - val_loss: 25.3303\n",
      "Epoch 39/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.4794 - val_loss: 26.4223\n",
      "Epoch 40/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.7694 - val_loss: 25.9049\n",
      "Epoch 41/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.3246 - val_loss: 25.8177\n",
      "Epoch 42/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.1270 - val_loss: 25.3439\n",
      "Epoch 43/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.2835 - val_loss: 25.0703\n",
      "Epoch 44/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 21.2953 - val_loss: 25.1977\n",
      "Epoch 45/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.0312 - val_loss: 25.3080\n",
      "Epoch 46/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.1161 - val_loss: 25.2804\n",
      "Epoch 47/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 20.9210 - val_loss: 26.4694\n",
      "Epoch 48/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 20.6741 - val_loss: 24.9572\n",
      "Epoch 49/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 20.4518 - val_loss: 24.7540\n",
      "Epoch 50/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 20.0472 - val_loss: 24.4150\n",
      "Epoch 51/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 20.0409 - val_loss: 24.7875\n",
      "Epoch 52/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 19.9276 - val_loss: 24.2501\n",
      "Epoch 53/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 19.9348 - val_loss: 24.4790\n",
      "Epoch 54/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 19.5033 - val_loss: 24.0512\n",
      "Epoch 55/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 19.6012 - val_loss: 23.9524\n",
      "Epoch 56/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 19.1187 - val_loss: 24.6332\n",
      "Epoch 57/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 19.1573 - val_loss: 23.9047\n",
      "Epoch 58/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.9156 - val_loss: 23.9846\n",
      "Epoch 59/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 19.3484 - val_loss: 24.0933\n",
      "Epoch 60/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.4409 - val_loss: 25.1216\n",
      "Epoch 61/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.6838 - val_loss: 24.0263\n",
      "Epoch 62/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.6829 - val_loss: 24.3637\n",
      "Epoch 63/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 18.3210 - val_loss: 22.8294\n",
      "Epoch 64/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.0582 - val_loss: 23.2429\n",
      "Epoch 65/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 18.1546 - val_loss: 23.4606\n",
      "Epoch 66/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 18.0774 - val_loss: 22.1219\n",
      "Epoch 67/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.1922 - val_loss: 24.3840\n",
      "Epoch 68/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 17.7318 - val_loss: 22.1198\n",
      "Epoch 69/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 17.7113 - val_loss: 21.4852\n",
      "Epoch 70/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 17.5641 - val_loss: 21.3769\n",
      "Epoch 71/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.7261 - val_loss: 21.6010\n",
      "Epoch 72/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.4887 - val_loss: 20.9944\n",
      "Epoch 73/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.6381 - val_loss: 21.1731\n",
      "Epoch 74/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.8148 - val_loss: 21.1669\n",
      "Epoch 75/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.2396 - val_loss: 21.0965\n",
      "Epoch 76/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 16.9172 - val_loss: 20.1459\n",
      "Epoch 77/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.1537 - val_loss: 21.0831\n",
      "Epoch 78/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.2042 - val_loss: 20.4310\n",
      "Epoch 79/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 16.8558 - val_loss: 20.2436\n",
      "Epoch 80/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.3185 - val_loss: 20.2103\n",
      "Epoch 81/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 17.2986 - val_loss: 19.7101\n",
      "Epoch 82/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.0217 - val_loss: 19.4665\n",
      "Epoch 83/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.5435 - val_loss: 21.2722\n",
      "Epoch 84/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.1762 - val_loss: 19.3435\n",
      "Epoch 85/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 16.6534 - val_loss: 19.5289\n",
      "Epoch 86/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 16.9348 - val_loss: 20.1991\n",
      "Epoch 87/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 16.7196 - val_loss: 20.0111\n",
      "Epoch 88/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 16.6636 - val_loss: 20.9171\n",
      "Epoch 89/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.8557 - val_loss: 21.4895\n",
      "Epoch 90/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 16.5403 - val_loss: 18.7246\n",
      "Epoch 91/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 16.4773 - val_loss: 19.7918\n",
      "Epoch 92/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 15.9167 - val_loss: 20.1785\n",
      "Epoch 93/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 16.1958 - val_loss: 18.4754\n",
      "Epoch 94/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 15.8999 - val_loss: 18.8240\n",
      "Epoch 95/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 16.0270 - val_loss: 18.0568\n",
      "Epoch 96/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 15.9569 - val_loss: 19.6571\n",
      "Epoch 97/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 15.6926 - val_loss: 18.7084\n",
      "Epoch 98/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 15.7854 - val_loss: 18.1552\n",
      "Epoch 99/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 15.8927 - val_loss: 19.3744\n",
      "Epoch 100/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 16.2704 - val_loss: 19.0990\n",
      "Epoch 101/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 15.7660 - val_loss: 18.3812\n",
      "Epoch 102/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 15.8345 - val_loss: 18.4767\n",
      "Epoch 103/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 15.9106 - val_loss: 19.3579\n",
      "Epoch 104/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 15.6415 - val_loss: 18.5670\n",
      "Epoch 105/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 15.1796 - val_loss: 19.1226\n",
      "Epoch 106/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 15.2709 - val_loss: 18.0048\n",
      "Epoch 107/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 15.5690 - val_loss: 19.9075\n",
      "Epoch 108/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 15.7084 - val_loss: 17.5424\n",
      "Epoch 109/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 15.0213 - val_loss: 18.0857\n",
      "Epoch 110/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.9094 - val_loss: 18.5175\n",
      "Epoch 111/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 15.2960 - val_loss: 22.3283\n",
      "Epoch 112/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 15.4058 - val_loss: 18.5595\n",
      "Epoch 113/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.8149 - val_loss: 17.4736\n",
      "Epoch 114/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 14.7033 - val_loss: 19.0131\n",
      "Epoch 115/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.8717 - val_loss: 18.2925\n",
      "Epoch 116/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 15.1711 - val_loss: 17.7394\n",
      "Epoch 117/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.9908 - val_loss: 18.3560\n",
      "Epoch 118/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.5735 - val_loss: 17.5511\n",
      "Epoch 119/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.5341 - val_loss: 17.5051\n",
      "Epoch 120/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.6988 - val_loss: 18.5975\n",
      "Epoch 121/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.5906 - val_loss: 17.3511\n",
      "Epoch 122/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 14.7118 - val_loss: 17.2816\n",
      "Epoch 123/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.3904 - val_loss: 17.3826\n",
      "Epoch 124/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.1475 - val_loss: 17.7096\n",
      "Epoch 125/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.8730 - val_loss: 17.6822\n",
      "Epoch 126/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.4292 - val_loss: 16.6956\n",
      "Epoch 127/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.8704 - val_loss: 19.6560\n",
      "Epoch 128/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.4500 - val_loss: 16.9729\n",
      "Epoch 129/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.2123 - val_loss: 19.2932\n",
      "Epoch 130/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.3431 - val_loss: 17.0692\n",
      "Epoch 131/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.0976 - val_loss: 17.6292\n",
      "Epoch 132/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.6868 - val_loss: 16.4896\n",
      "Epoch 133/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.6387 - val_loss: 17.8059\n",
      "Epoch 134/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.2554 - val_loss: 17.6626\n",
      "Epoch 135/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.9086 - val_loss: 16.8431\n",
      "Epoch 136/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.3157 - val_loss: 17.0677\n",
      "Epoch 137/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.4055 - val_loss: 16.8701\n",
      "Epoch 138/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.8751 - val_loss: 16.6189\n",
      "Epoch 139/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.9826 - val_loss: 16.8203\n",
      "Epoch 140/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.5362 - val_loss: 16.9916\n",
      "Epoch 141/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.6193 - val_loss: 16.3936\n",
      "Epoch 142/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.9953 - val_loss: 20.0843\n",
      "Epoch 143/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.0715 - val_loss: 17.1309\n",
      "Epoch 144/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.8072 - val_loss: 16.2433\n",
      "Epoch 145/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.7294 - val_loss: 19.1461\n",
      "Epoch 146/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.9211 - val_loss: 15.9019\n",
      "Epoch 147/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.1660 - val_loss: 16.7504\n",
      "Epoch 148/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.0064 - val_loss: 17.4371\n",
      "Epoch 149/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.1112 - val_loss: 15.8562\n",
      "Epoch 150/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.1961 - val_loss: 15.7545\n",
      "Epoch 151/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.8090 - val_loss: 15.9677\n",
      "Epoch 152/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.9261 - val_loss: 16.2417\n",
      "Epoch 153/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.1934 - val_loss: 18.8161\n",
      "Epoch 154/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.0054 - val_loss: 18.3773\n",
      "Epoch 155/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 12.8024 - val_loss: 16.8294\n",
      "Epoch 156/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 13.0081 - val_loss: 15.7819\n",
      "Epoch 157/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.0663 - val_loss: 17.6590\n",
      "Epoch 158/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.3757 - val_loss: 15.7240\n",
      "Epoch 159/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.6544 - val_loss: 16.7082\n",
      "Epoch 160/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.7879 - val_loss: 15.3752\n",
      "Epoch 161/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.5823 - val_loss: 18.7140\n",
      "Epoch 162/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 13.7996 - val_loss: 15.8372\n",
      "Epoch 163/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 13.1342 - val_loss: 17.2622\n",
      "Epoch 164/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.3843 - val_loss: 16.3125\n",
      "Epoch 165/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.2968 - val_loss: 15.5396\n",
      "Epoch 166/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.7429 - val_loss: 16.1688\n",
      "Epoch 167/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.4429 - val_loss: 14.8207\n",
      "Epoch 168/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 12.8287 - val_loss: 15.6883\n",
      "Epoch 169/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 13.7568 - val_loss: 23.2822\n",
      "Epoch 170/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.0718 - val_loss: 14.6854\n",
      "Epoch 171/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.7709 - val_loss: 17.0865\n",
      "Epoch 172/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 12.3405 - val_loss: 14.6658\n",
      "Epoch 173/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 12.0146 - val_loss: 15.5179\n",
      "Epoch 174/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.1174 - val_loss: 17.3742\n",
      "Epoch 175/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.2475 - val_loss: 15.7708\n",
      "Epoch 176/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.6190 - val_loss: 14.1783\n",
      "Epoch 177/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 11.6531 - val_loss: 14.1569\n",
      "Epoch 178/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.7456 - val_loss: 15.3571\n",
      "Epoch 179/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.9958 - val_loss: 14.4379\n",
      "Epoch 180/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 13.0076 - val_loss: 14.3931\n",
      "Epoch 181/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.5657 - val_loss: 15.6200\n",
      "Epoch 182/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.6023 - val_loss: 14.6694\n",
      "Epoch 183/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.8477 - val_loss: 14.1030\n",
      "Epoch 184/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.2894 - val_loss: 14.4115\n",
      "Epoch 185/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.6357 - val_loss: 15.1106\n",
      "Epoch 186/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.0042 - val_loss: 13.6214\n",
      "Epoch 187/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.1055 - val_loss: 14.4060\n",
      "Epoch 188/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.4906 - val_loss: 15.4245\n",
      "Epoch 189/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.0570 - val_loss: 13.5217\n",
      "Epoch 190/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.0631 - val_loss: 13.6168\n",
      "Epoch 191/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.3941 - val_loss: 14.4421\n",
      "Epoch 192/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.7619 - val_loss: 14.0873\n",
      "Epoch 193/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.8884 - val_loss: 14.0736\n",
      "Epoch 194/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.1548 - val_loss: 14.1308\n",
      "Epoch 195/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.6826 - val_loss: 14.1131\n",
      "Epoch 196/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.7519 - val_loss: 13.1789\n",
      "Epoch 197/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.7108 - val_loss: 13.9736\n",
      "Epoch 198/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.9073 - val_loss: 14.6188\n",
      "Epoch 199/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.0865 - val_loss: 13.1855\n",
      "Epoch 200/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.9950 - val_loss: 13.5284\n",
      "Epoch 201/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.2952 - val_loss: 15.3854\n",
      "Epoch 202/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.6169 - val_loss: 14.6671\n",
      "Epoch 203/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.6091 - val_loss: 12.9546\n",
      "Epoch 204/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.9933 - val_loss: 16.1820\n",
      "Epoch 205/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 11.6596 - val_loss: 14.9286\n",
      "Epoch 206/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 11.1789 - val_loss: 15.3216\n",
      "Epoch 207/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.0019 - val_loss: 13.8542\n",
      "Epoch 208/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.1010 - val_loss: 13.0309\n",
      "Epoch 209/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 10.7589 - val_loss: 14.5616\n",
      "Epoch 210/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.5905 - val_loss: 13.3453\n",
      "Epoch 211/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.0863 - val_loss: 15.3597\n",
      "Epoch 212/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.1702 - val_loss: 14.6071\n",
      "Epoch 213/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.4574 - val_loss: 14.1952\n",
      "Epoch 214/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 10.9900 - val_loss: 14.5176\n",
      "Epoch 215/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.0669 - val_loss: 12.8462\n",
      "Epoch 216/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.5321 - val_loss: 12.4681\n",
      "Epoch 217/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.3784 - val_loss: 13.2675\n",
      "Epoch 218/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.6999 - val_loss: 16.5702\n",
      "Epoch 219/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.3149 - val_loss: 12.8785\n",
      "Epoch 220/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.1636 - val_loss: 13.3541\n",
      "Epoch 221/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.9366 - val_loss: 12.9735\n",
      "Epoch 222/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 10.7069 - val_loss: 14.3181\n",
      "Epoch 223/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.2770 - val_loss: 13.1054\n",
      "Epoch 224/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.5570 - val_loss: 13.7235\n",
      "Epoch 225/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 10.4632 - val_loss: 13.0668\n",
      "Epoch 226/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.6024 - val_loss: 14.2826\n",
      "Epoch 227/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.7094 - val_loss: 12.8941\n",
      "Epoch 228/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.2741 - val_loss: 12.8520\n",
      "Epoch 229/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 10.6509 - val_loss: 13.3269\n",
      "Epoch 230/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 10.3130 - val_loss: 12.3226\n",
      "Epoch 231/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 10.7157 - val_loss: 16.7730\n",
      "Epoch 232/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 10.7987 - val_loss: 12.9808\n",
      "Epoch 233/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 11.1909 - val_loss: 13.1788\n",
      "Epoch 234/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 10.5185 - val_loss: 13.7791\n",
      "Epoch 235/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 10.2363 - val_loss: 12.1476\n",
      "Epoch 236/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 10.1602 - val_loss: 12.8822\n",
      "Epoch 237/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.9935 - val_loss: 12.3864\n",
      "Epoch 238/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.6937 - val_loss: 11.9254\n",
      "Epoch 239/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.0497 - val_loss: 12.1984\n",
      "Epoch 240/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.9794 - val_loss: 12.5624\n",
      "Epoch 241/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.0622 - val_loss: 12.2958\n",
      "Epoch 242/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.4294 - val_loss: 13.4017\n",
      "Epoch 243/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.5438 - val_loss: 12.3101\n",
      "Epoch 244/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 10.1723 - val_loss: 13.1046\n",
      "Epoch 245/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.1418 - val_loss: 13.5003\n",
      "Epoch 246/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.0235 - val_loss: 12.5972\n",
      "Epoch 247/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.1287 - val_loss: 12.5166\n",
      "Epoch 248/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.5423 - val_loss: 12.2740\n",
      "Epoch 249/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.7130 - val_loss: 15.4561\n",
      "Epoch 250/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.5414 - val_loss: 11.7596\n",
      "Epoch 251/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.1091 - val_loss: 12.7848\n",
      "Epoch 252/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.7204 - val_loss: 12.5290\n",
      "Epoch 253/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.1656 - val_loss: 13.0666\n",
      "Epoch 254/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.0857 - val_loss: 12.5027\n",
      "Epoch 255/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.9855 - val_loss: 11.7702\n",
      "Epoch 256/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 10.6727 - val_loss: 12.0425\n",
      "Epoch 257/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.1265 - val_loss: 12.9169\n",
      "Epoch 258/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.7127 - val_loss: 11.5920\n",
      "Epoch 259/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.9197 - val_loss: 11.3790\n",
      "Epoch 260/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.5689 - val_loss: 11.9128\n",
      "Epoch 261/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.6067 - val_loss: 12.0615\n",
      "Epoch 262/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 10.0476 - val_loss: 11.6330\n",
      "Epoch 263/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.2522 - val_loss: 11.4477\n",
      "Epoch 264/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.4640 - val_loss: 12.7264\n",
      "Epoch 265/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.9703 - val_loss: 13.1757\n",
      "Epoch 266/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.7743 - val_loss: 12.5357\n",
      "Epoch 267/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.7763 - val_loss: 12.5409\n",
      "Epoch 268/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.2370 - val_loss: 14.6784\n",
      "Epoch 269/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.3509 - val_loss: 11.9594\n",
      "Epoch 270/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.7998 - val_loss: 13.7989\n",
      "Epoch 271/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.5459 - val_loss: 11.5270\n",
      "Epoch 272/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.7684 - val_loss: 12.3985\n",
      "Epoch 273/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.9079 - val_loss: 13.3181\n",
      "Epoch 274/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.2336 - val_loss: 12.4634\n",
      "Epoch 275/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.9091 - val_loss: 11.5931\n",
      "Epoch 276/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.5959 - val_loss: 12.8934\n",
      "Epoch 277/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.1743 - val_loss: 12.5020\n",
      "Epoch 278/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.5029 - val_loss: 13.0158\n",
      "Epoch 279/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.1778 - val_loss: 13.4371\n",
      "Epoch 280/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.6583 - val_loss: 12.9185\n",
      "Epoch 281/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.6908 - val_loss: 13.4996\n",
      "Epoch 282/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.5610 - val_loss: 11.4831\n",
      "Epoch 283/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.9652 - val_loss: 12.6738\n",
      "Epoch 284/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.5325 - val_loss: 11.4163\n",
      "Epoch 285/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.6395 - val_loss: 15.3381\n",
      "Epoch 286/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.0943 - val_loss: 11.4457\n",
      "Epoch 287/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.5932 - val_loss: 11.5344\n",
      "Epoch 288/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.5144 - val_loss: 12.4296\n",
      "Epoch 289/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.9446 - val_loss: 11.9623\n",
      "Epoch 290/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.5893 - val_loss: 11.4900\n",
      "Epoch 291/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.8209 - val_loss: 11.4917\n",
      "Epoch 292/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.0889 - val_loss: 13.8353\n",
      "Epoch 293/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.5851 - val_loss: 12.1468\n",
      "Epoch 294/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.4894 - val_loss: 11.6071\n",
      "Epoch 295/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.3850 - val_loss: 12.1052\n",
      "Epoch 296/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.5755 - val_loss: 11.1720\n",
      "Epoch 297/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.9872 - val_loss: 13.8236\n",
      "Epoch 298/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.8590 - val_loss: 11.4579\n",
      "Epoch 299/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.4398 - val_loss: 12.5584\n",
      "Epoch 300/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.9092 - val_loss: 12.2883\n",
      "Epoch 301/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.4629 - val_loss: 11.8378\n",
      "Epoch 302/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.7544 - val_loss: 11.0876\n",
      "Epoch 303/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.3799 - val_loss: 11.3192\n",
      "Epoch 304/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.3481 - val_loss: 12.4683\n",
      "Epoch 305/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.3399 - val_loss: 12.4031\n",
      "Epoch 306/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.9452 - val_loss: 11.0959\n",
      "Epoch 307/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.9604 - val_loss: 12.7382\n",
      "Epoch 308/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0441 - val_loss: 11.0390\n",
      "Epoch 309/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1440 - val_loss: 11.1196\n",
      "Epoch 310/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.3149 - val_loss: 12.1227\n",
      "Epoch 311/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.3646 - val_loss: 11.8631\n",
      "Epoch 312/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.1309 - val_loss: 11.3927\n",
      "Epoch 313/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.3103 - val_loss: 10.8104\n",
      "Epoch 314/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0548 - val_loss: 11.8248\n",
      "Epoch 315/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.2111 - val_loss: 11.1611\n",
      "Epoch 316/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.0175 - val_loss: 11.4748\n",
      "Epoch 317/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9858 - val_loss: 11.5357\n",
      "Epoch 318/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1601 - val_loss: 14.8521\n",
      "Epoch 319/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.2946 - val_loss: 10.8511\n",
      "Epoch 320/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.1378 - val_loss: 11.0934\n",
      "Epoch 321/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8745 - val_loss: 12.1158\n",
      "Epoch 322/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.6613 - val_loss: 11.4780\n",
      "Epoch 323/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.6376 - val_loss: 10.8436\n",
      "Epoch 324/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0269 - val_loss: 11.0154\n",
      "Epoch 325/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.7449 - val_loss: 13.1211\n",
      "Epoch 326/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.3865 - val_loss: 10.5530\n",
      "Epoch 327/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9208 - val_loss: 10.8706\n",
      "Epoch 328/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8798 - val_loss: 11.4634\n",
      "Epoch 329/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.4882 - val_loss: 15.3735\n",
      "Epoch 330/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.7854 - val_loss: 11.2529\n",
      "Epoch 331/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.7954 - val_loss: 11.0073\n",
      "Epoch 332/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.4109 - val_loss: 11.5031\n",
      "Epoch 333/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9269 - val_loss: 11.3848\n",
      "Epoch 334/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9252 - val_loss: 10.9809\n",
      "Epoch 335/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8330 - val_loss: 13.3181\n",
      "Epoch 336/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0194 - val_loss: 11.0750\n",
      "Epoch 337/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.7592 - val_loss: 10.8326\n",
      "Epoch 338/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9940 - val_loss: 10.5441\n",
      "Epoch 339/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5739 - val_loss: 10.4613\n",
      "Epoch 340/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.7170 - val_loss: 10.5738\n",
      "Epoch 341/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.0196 - val_loss: 10.9002\n",
      "Epoch 342/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2144 - val_loss: 12.3915\n",
      "Epoch 343/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.5270 - val_loss: 10.9454\n",
      "Epoch 344/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.8858 - val_loss: 11.4716\n",
      "Epoch 345/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.7957 - val_loss: 11.6621\n",
      "Epoch 346/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.9031 - val_loss: 11.1284\n",
      "Epoch 347/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.3271 - val_loss: 11.5296\n",
      "Epoch 348/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1423 - val_loss: 12.2260\n",
      "Epoch 349/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.7327 - val_loss: 10.4516\n",
      "Epoch 350/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0753 - val_loss: 11.8878\n",
      "Epoch 351/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.5637 - val_loss: 10.5073\n",
      "Epoch 352/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0786 - val_loss: 10.4195\n",
      "Epoch 353/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0763 - val_loss: 11.5704\n",
      "Epoch 354/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.1610 - val_loss: 11.1575\n",
      "Epoch 355/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.4495 - val_loss: 11.0608\n",
      "Epoch 356/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1149 - val_loss: 10.9977\n",
      "Epoch 357/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7307 - val_loss: 10.3829\n",
      "Epoch 358/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5891 - val_loss: 10.5146\n",
      "Epoch 359/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8046 - val_loss: 12.4760\n",
      "Epoch 360/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8827 - val_loss: 11.4463\n",
      "Epoch 361/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9555 - val_loss: 11.0320\n",
      "Epoch 362/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6222 - val_loss: 11.4283\n",
      "Epoch 363/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.5586 - val_loss: 10.4927\n",
      "Epoch 364/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1910 - val_loss: 11.3922\n",
      "Epoch 365/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.8873 - val_loss: 10.6762\n",
      "Epoch 366/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.9200 - val_loss: 10.0921\n",
      "Epoch 367/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9762 - val_loss: 11.0700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 368/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4387 - val_loss: 10.7616\n",
      "Epoch 369/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7400 - val_loss: 10.2635\n",
      "Epoch 370/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.8496 - val_loss: 11.8528\n",
      "Epoch 371/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7406 - val_loss: 10.6022\n",
      "Epoch 372/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.6181 - val_loss: 10.3138\n",
      "Epoch 373/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.8977 - val_loss: 10.1131\n",
      "Epoch 374/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.5952 - val_loss: 10.1328\n",
      "Epoch 375/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.4433 - val_loss: 10.5299\n",
      "Epoch 376/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.3142 - val_loss: 14.2315\n",
      "Epoch 377/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.2065 - val_loss: 10.9639\n",
      "Epoch 378/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.3180 - val_loss: 11.6132\n",
      "Epoch 379/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1880 - val_loss: 9.9698\n",
      "Epoch 380/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.6288 - val_loss: 10.8062\n",
      "Epoch 381/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7585 - val_loss: 11.3912\n",
      "Epoch 382/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.4426 - val_loss: 10.5678\n",
      "Epoch 383/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.9412 - val_loss: 10.9786\n",
      "Epoch 384/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4339 - val_loss: 10.9645\n",
      "Epoch 385/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6842 - val_loss: 10.8060\n",
      "Epoch 386/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.8796 - val_loss: 10.5985\n",
      "Epoch 387/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.1378 - val_loss: 10.4486\n",
      "Epoch 388/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7895 - val_loss: 10.1290\n",
      "Epoch 389/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4900 - val_loss: 10.1182\n",
      "Epoch 390/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6131 - val_loss: 11.2688\n",
      "Epoch 391/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.1782 - val_loss: 10.5836\n",
      "Epoch 392/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.8748 - val_loss: 12.3135\n",
      "Epoch 393/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6569 - val_loss: 11.2752\n",
      "Epoch 394/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.4366 - val_loss: 11.5309\n",
      "Epoch 395/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6424 - val_loss: 10.3748\n",
      "Epoch 396/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.6591 - val_loss: 10.2247\n",
      "Epoch 397/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 8.7086 - val_loss: 11.0091\n",
      "Epoch 398/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.4516 - val_loss: 10.0023\n",
      "Epoch 399/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.5672 - val_loss: 9.9726\n",
      "Epoch 400/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.5433 - val_loss: 9.7381\n",
      "Epoch 401/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.4300 - val_loss: 11.6549\n",
      "Epoch 402/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.6737 - val_loss: 10.4829\n",
      "Epoch 403/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.2676 - val_loss: 10.3217\n",
      "Epoch 404/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.4912 - val_loss: 10.4908\n",
      "Epoch 405/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8061 - val_loss: 9.8693\n",
      "Epoch 406/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4028 - val_loss: 10.5248\n",
      "Epoch 407/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6224 - val_loss: 11.7375\n",
      "Epoch 408/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0510 - val_loss: 10.6927\n",
      "Epoch 409/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8641 - val_loss: 9.9717\n",
      "Epoch 410/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6010 - val_loss: 10.5856\n",
      "Epoch 411/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7548 - val_loss: 9.7812\n",
      "Epoch 412/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2215 - val_loss: 10.0758\n",
      "Epoch 413/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8475 - val_loss: 12.7757\n",
      "Epoch 414/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.0795 - val_loss: 10.4284\n",
      "Epoch 415/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9982 - val_loss: 9.8224\n",
      "Epoch 416/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8402 - val_loss: 11.5478\n",
      "Epoch 417/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5826 - val_loss: 10.2331\n",
      "Epoch 418/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4913 - val_loss: 10.0575\n",
      "Epoch 419/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7608 - val_loss: 11.0267\n",
      "Epoch 420/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.7015 - val_loss: 11.7146\n",
      "Epoch 421/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8421 - val_loss: 9.9204\n",
      "Epoch 422/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5786 - val_loss: 11.5375\n",
      "Epoch 423/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.4688 - val_loss: 10.2171\n",
      "Epoch 424/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8181 - val_loss: 15.1302\n",
      "Epoch 425/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.7040 - val_loss: 10.3728\n",
      "Epoch 426/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2772 - val_loss: 9.7918\n",
      "Epoch 427/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.2895 - val_loss: 10.5832\n",
      "Epoch 428/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3095 - val_loss: 10.2040\n",
      "Epoch 429/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 9.0006 - val_loss: 11.6855\n",
      "Epoch 430/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5778 - val_loss: 9.8992\n",
      "Epoch 431/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5082 - val_loss: 12.1049\n",
      "Epoch 432/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.9298 - val_loss: 9.9935\n",
      "Epoch 433/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.6176 - val_loss: 10.1460\n",
      "Epoch 434/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2903 - val_loss: 10.7644\n",
      "Epoch 435/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.6147 - val_loss: 10.1614\n",
      "Epoch 436/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.4590 - val_loss: 10.0915\n",
      "Epoch 437/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3244 - val_loss: 9.8839\n",
      "Epoch 438/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3724 - val_loss: 10.2442\n",
      "Epoch 439/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.2673 - val_loss: 10.5113\n",
      "Epoch 440/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4293 - val_loss: 9.8138\n",
      "Epoch 441/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.5882 - val_loss: 10.2038\n",
      "Epoch 442/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3461 - val_loss: 11.5453\n",
      "Epoch 443/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7586 - val_loss: 9.8782\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 444/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.4777 - val_loss: 10.0237\n",
      "Epoch 445/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.6883 - val_loss: 9.7809\n",
      "Epoch 446/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4367 - val_loss: 10.4180\n",
      "Epoch 447/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3806 - val_loss: 10.2408\n",
      "Epoch 448/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.8658 - val_loss: 10.5291\n",
      "Epoch 449/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.7273 - val_loss: 9.6915\n",
      "Epoch 450/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6328 - val_loss: 10.9763\n",
      "Epoch 451/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4780 - val_loss: 10.0483\n",
      "Epoch 452/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3007 - val_loss: 9.6921\n",
      "Epoch 453/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3579 - val_loss: 9.6116\n",
      "Epoch 454/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.7678 - val_loss: 10.6104\n",
      "Epoch 455/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6406 - val_loss: 12.6963\n",
      "Epoch 456/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9776 - val_loss: 10.2383\n",
      "Epoch 457/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6471 - val_loss: 10.2094\n",
      "Epoch 458/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3125 - val_loss: 10.3683\n",
      "Epoch 459/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.0096 - val_loss: 10.0242\n",
      "Epoch 460/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3060 - val_loss: 10.7339\n",
      "Epoch 461/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.7442 - val_loss: 11.0816\n",
      "Epoch 462/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.5233 - val_loss: 9.7845\n",
      "Epoch 463/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1677 - val_loss: 11.4851\n",
      "Epoch 464/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7774 - val_loss: 9.8316\n",
      "Epoch 465/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3775 - val_loss: 9.9249\n",
      "Epoch 466/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2092 - val_loss: 9.7370\n",
      "Epoch 467/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0160 - val_loss: 10.2161\n",
      "Epoch 468/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4180 - val_loss: 10.5665\n",
      "Epoch 469/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4252 - val_loss: 9.9118\n",
      "Epoch 470/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.5807 - val_loss: 9.9437\n",
      "Epoch 471/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7272 - val_loss: 10.6150\n",
      "Epoch 472/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.4209 - val_loss: 10.5382\n",
      "Epoch 473/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5153 - val_loss: 10.7325\n",
      "Epoch 474/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 8.9695 - val_loss: 10.2228\n",
      "Epoch 475/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 8.5753 - val_loss: 9.5364\n",
      "Epoch 476/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9330 - val_loss: 9.8589\n",
      "Epoch 477/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6922 - val_loss: 9.7582\n",
      "Epoch 478/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3680 - val_loss: 10.2862\n",
      "Epoch 479/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.2631 - val_loss: 9.7734\n",
      "Epoch 480/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5447 - val_loss: 11.8058\n",
      "Epoch 481/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.9421 - val_loss: 10.3777\n",
      "Epoch 482/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4085 - val_loss: 9.8362\n",
      "Epoch 483/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8402 - val_loss: 10.0404\n",
      "Epoch 484/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0555 - val_loss: 12.5237\n",
      "Epoch 485/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5698 - val_loss: 10.2675\n",
      "Epoch 486/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6311 - val_loss: 9.6896\n",
      "Epoch 487/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.5697 - val_loss: 10.2239\n",
      "Epoch 488/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5373 - val_loss: 9.5925\n",
      "Epoch 489/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.1799 - val_loss: 11.6800\n",
      "Epoch 490/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2362 - val_loss: 9.9497\n",
      "Epoch 491/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.6849 - val_loss: 9.8790\n",
      "Epoch 492/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2700 - val_loss: 10.3938\n",
      "Epoch 493/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3582 - val_loss: 10.2027\n",
      "Epoch 494/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6861 - val_loss: 11.3831\n",
      "Epoch 495/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.5727 - val_loss: 10.6683\n",
      "Epoch 496/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2220 - val_loss: 10.0136\n",
      "Epoch 497/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.8942 - val_loss: 12.4590\n",
      "Epoch 498/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.3145 - val_loss: 9.7453\n",
      "Epoch 499/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7823 - val_loss: 11.4506\n",
      "Epoch 500/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7164 - val_loss: 9.8270\n",
      "Epoch 501/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.5889 - val_loss: 11.8370\n",
      "Epoch 502/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.5442 - val_loss: 9.6438\n",
      "Epoch 503/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.3681 - val_loss: 9.8138\n",
      "Epoch 504/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.3289 - val_loss: 9.5602\n",
      "Epoch 505/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8207 - val_loss: 10.1234\n",
      "Epoch 506/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3229 - val_loss: 9.8727\n",
      "Epoch 507/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3120 - val_loss: 11.8161\n",
      "Epoch 508/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.8053 - val_loss: 9.5392\n",
      "Epoch 509/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.3827 - val_loss: 10.0866\n",
      "Epoch 510/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.3976 - val_loss: 10.3810\n",
      "Epoch 511/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.5407 - val_loss: 10.8590\n",
      "Epoch 512/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2376 - val_loss: 9.9126\n",
      "Epoch 513/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2930 - val_loss: 10.0665\n",
      "Epoch 514/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.3261 - val_loss: 11.3542\n",
      "Epoch 515/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.8229 - val_loss: 9.7035\n",
      "Epoch 516/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4754 - val_loss: 9.7464\n",
      "Epoch 517/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.2500 - val_loss: 10.4459\n",
      "Epoch 518/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4477 - val_loss: 10.9256\n",
      "Epoch 519/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1728 - val_loss: 9.5109\n",
      "Epoch 520/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2860 - val_loss: 10.9810\n",
      "Epoch 521/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.0729 - val_loss: 9.6007\n",
      "Epoch 522/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3439 - val_loss: 9.4525\n",
      "Epoch 523/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3230 - val_loss: 10.5800\n",
      "Epoch 524/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.0229 - val_loss: 12.5287\n",
      "Epoch 525/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.4029 - val_loss: 9.7482\n",
      "Epoch 526/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.0984 - val_loss: 12.4106\n",
      "Epoch 527/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3074 - val_loss: 10.1462\n",
      "Epoch 528/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4472 - val_loss: 9.6132\n",
      "Epoch 529/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.2484 - val_loss: 10.0461\n",
      "Epoch 530/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.4568 - val_loss: 10.5199\n",
      "Epoch 531/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4065 - val_loss: 10.9730\n",
      "Epoch 532/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4897 - val_loss: 10.7063\n",
      "Epoch 533/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6284 - val_loss: 9.9794\n",
      "Epoch 534/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5811 - val_loss: 11.2812\n",
      "Epoch 535/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.3153 - val_loss: 10.5898\n",
      "Epoch 536/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.2248 - val_loss: 9.7093\n",
      "Epoch 537/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2804 - val_loss: 9.6929\n",
      "Epoch 538/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.9362 - val_loss: 10.1662\n",
      "Epoch 539/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5252 - val_loss: 10.5014\n",
      "Epoch 540/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5338 - val_loss: 11.3026\n",
      "Epoch 541/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3879 - val_loss: 9.5896\n",
      "Epoch 542/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0950 - val_loss: 10.8038\n",
      "Epoch 543/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.1897 - val_loss: 9.5507\n",
      "Epoch 544/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.4781 - val_loss: 11.9515\n",
      "Epoch 545/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.9828 - val_loss: 10.0358\n",
      "Epoch 546/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6766 - val_loss: 11.3314\n",
      "Epoch 547/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3314 - val_loss: 10.2785\n",
      "Epoch 548/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.1060 - val_loss: 9.7193\n",
      "Epoch 549/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 8.3907 - val_loss: 10.0856\n",
      "Epoch 550/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.1443 - val_loss: 10.6294\n",
      "Epoch 551/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1494 - val_loss: 11.2082\n",
      "Epoch 552/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9844 - val_loss: 10.5902\n",
      "Epoch 553/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3745 - val_loss: 10.8275\n",
      "Epoch 554/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5301 - val_loss: 9.7726\n",
      "Epoch 555/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.2696 - val_loss: 10.3922\n",
      "Epoch 556/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.2206 - val_loss: 9.7404\n",
      "Epoch 557/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1896 - val_loss: 9.6881\n",
      "Epoch 558/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2675 - val_loss: 10.9363\n",
      "Epoch 559/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5396 - val_loss: 9.3523\n",
      "Epoch 560/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3227 - val_loss: 9.7116\n",
      "Epoch 561/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.2238 - val_loss: 11.0860\n",
      "Epoch 562/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 8.3998 - val_loss: 9.5647\n",
      "Epoch 563/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 8.2697 - val_loss: 9.8102\n",
      "Epoch 564/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 8.2598 - val_loss: 9.7233\n",
      "Epoch 565/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.2283 - val_loss: 10.5504\n",
      "Epoch 566/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.2419 - val_loss: 9.7232\n",
      "Epoch 567/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.4029 - val_loss: 9.7315\n",
      "Epoch 568/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.5622 - val_loss: 9.5133\n",
      "Epoch 569/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 8.1877 - val_loss: 11.4992\n",
      "Epoch 570/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.4593 - val_loss: 9.9531\n",
      "Epoch 571/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4150 - val_loss: 10.3588\n",
      "Epoch 572/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4866 - val_loss: 9.3878\n",
      "Epoch 573/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2606 - val_loss: 9.8351\n",
      "Epoch 574/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7023 - val_loss: 12.4346\n",
      "Epoch 575/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8791 - val_loss: 11.6596\n",
      "Epoch 576/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3304 - val_loss: 9.2313\n",
      "Epoch 577/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7167 - val_loss: 12.4560\n",
      "Epoch 578/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6597 - val_loss: 9.6668\n",
      "Epoch 579/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5000 - val_loss: 10.1019\n",
      "Epoch 580/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.3656 - val_loss: 10.1789\n",
      "Epoch 581/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1390 - val_loss: 9.5590\n",
      "Epoch 582/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2598 - val_loss: 9.8840\n",
      "Epoch 583/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.8084 - val_loss: 9.6757\n",
      "Epoch 584/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3349 - val_loss: 10.6938\n",
      "Epoch 585/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.2504 - val_loss: 9.7580\n",
      "Epoch 586/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.1311 - val_loss: 9.2880\n",
      "Epoch 587/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.3855 - val_loss: 10.8791\n",
      "Epoch 588/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.1600 - val_loss: 9.5676\n",
      "Epoch 589/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.0032 - val_loss: 10.5512\n",
      "Epoch 590/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3560 - val_loss: 9.3761\n",
      "Epoch 591/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3542 - val_loss: 10.0750\n",
      "Epoch 592/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5031 - val_loss: 9.8349\n",
      "Epoch 593/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5328 - val_loss: 9.8831\n",
      "Epoch 594/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4046 - val_loss: 9.8814\n",
      "Epoch 595/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.7690 - val_loss: 11.2969\n",
      "Epoch 596/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.2855 - val_loss: 9.9622\n",
      "Epoch 597/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.2116 - val_loss: 9.7220\n",
      "Epoch 598/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4109 - val_loss: 9.6631\n",
      "Epoch 599/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.5082 - val_loss: 10.2257\n",
      "Epoch 600/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4455 - val_loss: 10.4868\n",
      "Epoch 601/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.5562 - val_loss: 9.9009\n",
      "Epoch 602/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2368 - val_loss: 9.9081\n",
      "Epoch 603/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3273 - val_loss: 9.7003\n",
      "Epoch 604/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6267 - val_loss: 9.8312\n",
      "Epoch 605/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.5014 - val_loss: 10.2508\n",
      "Epoch 606/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5068 - val_loss: 10.1776\n",
      "Epoch 607/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.0465 - val_loss: 10.1595\n",
      "Epoch 608/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.1595 - val_loss: 10.0355\n",
      "Epoch 609/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3235 - val_loss: 9.4544\n",
      "Epoch 610/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.7070 - val_loss: 12.1165\n",
      "Epoch 611/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.3795 - val_loss: 9.9444\n",
      "Epoch 612/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.1578 - val_loss: 10.0182\n",
      "Epoch 613/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3123 - val_loss: 10.2392\n",
      "Epoch 614/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0254 - val_loss: 9.1256\n",
      "Epoch 615/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2894 - val_loss: 9.7595\n",
      "Epoch 616/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2458 - val_loss: 9.8137\n",
      "Epoch 617/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.3725 - val_loss: 10.2862\n",
      "Epoch 618/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.2888 - val_loss: 10.1467\n",
      "Epoch 619/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.1625 - val_loss: 9.6766\n",
      "Epoch 620/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.0348 - val_loss: 10.1779\n",
      "Epoch 621/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1810 - val_loss: 9.7016\n",
      "Epoch 622/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.4943 - val_loss: 9.9642\n",
      "Epoch 623/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4144 - val_loss: 9.1859\n",
      "Epoch 624/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 7.9282 - 0s 95us/step - loss: 8.1690 - val_loss: 9.5981\n",
      "Epoch 625/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.1519 - val_loss: 9.9252\n",
      "Epoch 626/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5532 - val_loss: 9.3117\n",
      "Epoch 627/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.4085 - val_loss: 10.2465\n",
      "Epoch 628/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6347 - val_loss: 10.2448\n",
      "Epoch 629/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1296 - val_loss: 10.2676\n",
      "Epoch 630/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7734 - val_loss: 10.0567\n",
      "Epoch 631/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4692 - val_loss: 9.3890\n",
      "Epoch 632/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.4479 - val_loss: 9.7550\n",
      "Epoch 633/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.4000 - val_loss: 11.4764\n",
      "Epoch 634/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.5066 - val_loss: 9.9065\n",
      "Epoch 635/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3032 - val_loss: 9.9896\n",
      "Epoch 636/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.0607 - val_loss: 9.4158\n",
      "Epoch 637/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3273 - val_loss: 10.1173\n",
      "Epoch 638/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2434 - val_loss: 9.4198\n",
      "Epoch 639/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9648 - val_loss: 11.2644\n",
      "Epoch 640/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3692 - val_loss: 10.3734\n",
      "Epoch 641/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4461 - val_loss: 11.2041\n",
      "Epoch 642/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.1650 - val_loss: 10.8135\n",
      "Epoch 643/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.1739 - val_loss: 12.2781\n",
      "Epoch 644/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7743 - val_loss: 11.3742\n",
      "Epoch 645/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.6336 - val_loss: 10.4392\n",
      "Epoch 646/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.6715 - val_loss: 10.7353\n",
      "Epoch 647/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3461 - val_loss: 10.5594\n",
      "Epoch 648/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3266 - val_loss: 9.9197\n",
      "Epoch 649/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0998 - val_loss: 10.2564\n",
      "Epoch 650/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1698 - val_loss: 9.4467\n",
      "Epoch 651/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.2203 - val_loss: 12.4047\n",
      "Epoch 652/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5972 - val_loss: 9.5132\n",
      "Epoch 653/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1252 - val_loss: 9.6935\n",
      "Epoch 654/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.3049 - val_loss: 9.7764\n",
      "Epoch 655/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6894 - val_loss: 10.7485\n",
      "Epoch 656/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.2873 - val_loss: 9.6818\n",
      "Epoch 657/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.7832 - val_loss: 10.6338\n",
      "Epoch 658/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.5612 - val_loss: 10.6604\n",
      "Epoch 659/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4597 - val_loss: 9.1528\n",
      "Epoch 660/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6405 - val_loss: 9.6655\n",
      "Epoch 661/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2409 - val_loss: 9.5454\n",
      "Epoch 662/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.3378 - val_loss: 9.6350\n",
      "Epoch 663/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.0499 - val_loss: 9.9606\n",
      "Epoch 664/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.4772 - val_loss: 10.8114\n",
      "Epoch 665/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.8221 - val_loss: 9.8516\n",
      "Epoch 666/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.3599 - val_loss: 9.5536\n",
      "Epoch 667/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1889 - val_loss: 10.7230\n",
      "Epoch 668/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4738 - val_loss: 10.4012\n",
      "Epoch 669/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1615 - val_loss: 9.6250\n",
      "Epoch 670/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.2615 - val_loss: 9.1588\n",
      "Epoch 671/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4660 - val_loss: 9.5331\n",
      "Epoch 672/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1925 - val_loss: 11.8293\n",
      "Epoch 673/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.4683 - val_loss: 9.8904\n",
      "Epoch 674/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.4462 - val_loss: 9.6691\n",
      "Epoch 675/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.4160 - val_loss: 10.3770\n",
      "Epoch 676/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4117 - val_loss: 9.7589\n",
      "Epoch 677/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1670 - val_loss: 9.9016\n",
      "Epoch 678/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3287 - val_loss: 9.5697\n",
      "Epoch 679/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2269 - val_loss: 9.6787\n",
      "Epoch 680/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.9985 - val_loss: 9.2151\n",
      "Epoch 681/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1828 - val_loss: 10.5986\n",
      "Epoch 682/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2576 - val_loss: 9.5360\n",
      "Epoch 683/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2375 - val_loss: 9.2456\n",
      "Epoch 684/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.3778 - val_loss: 10.1347\n",
      "Epoch 685/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5255 - val_loss: 10.7161\n",
      "Epoch 686/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2476 - val_loss: 10.2861\n",
      "Epoch 687/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.4556 - val_loss: 9.4158\n",
      "Epoch 688/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4910 - val_loss: 12.6457\n",
      "Epoch 689/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6519 - val_loss: 10.7876\n",
      "Epoch 690/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.8156 - val_loss: 9.3906\n",
      "Epoch 691/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.1790 - val_loss: 9.6536\n",
      "Epoch 692/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.1540 - val_loss: 10.0388\n",
      "Epoch 693/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3388 - val_loss: 9.4417\n",
      "Epoch 694/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4524 - val_loss: 10.0293\n",
      "Epoch 695/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.1964 - val_loss: 9.1219\n",
      "Epoch 696/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3722 - val_loss: 9.3126\n",
      "Epoch 697/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.1347 - val_loss: 9.2867\n",
      "Epoch 698/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.1460 - val_loss: 10.4237\n",
      "Epoch 699/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3655 - val_loss: 9.9983\n",
      "Epoch 700/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.9132 - val_loss: 10.6538\n",
      "Epoch 701/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.3557 - val_loss: 9.4761\n",
      "Epoch 702/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.5006 - val_loss: 11.0811\n",
      "Epoch 703/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7442 - val_loss: 9.3270\n",
      "Epoch 704/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6327 - val_loss: 9.9387\n",
      "Epoch 705/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4813 - val_loss: 9.1822\n",
      "Epoch 706/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7561 - val_loss: 11.3067\n",
      "Epoch 707/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8472 - val_loss: 9.6127\n",
      "Epoch 708/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.3610 - val_loss: 9.8292\n",
      "Epoch 709/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.0251 - val_loss: 10.2693\n",
      "Epoch 710/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2079 - val_loss: 10.4083\n",
      "Epoch 711/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.1087 - val_loss: 9.3364\n",
      "Epoch 712/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.3586 - val_loss: 10.7618\n",
      "Epoch 713/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1667 - val_loss: 11.2388\n",
      "Epoch 714/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1660 - val_loss: 9.5162\n",
      "Epoch 715/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1983 - val_loss: 10.0300\n",
      "Epoch 716/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.5604 - val_loss: 12.5222\n",
      "Epoch 717/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.6131 - val_loss: 10.0482\n",
      "Epoch 718/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7543 - val_loss: 9.1836\n",
      "Epoch 719/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0912 - val_loss: 10.0775\n",
      "Epoch 720/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1119 - val_loss: 9.1814\n",
      "Epoch 721/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.3685 - val_loss: 9.5619\n",
      "Epoch 722/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.1568 - val_loss: 11.3704\n",
      "Epoch 723/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6982 - val_loss: 9.4826\n",
      "Epoch 724/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1154 - val_loss: 9.3365\n",
      "Epoch 725/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3539 - val_loss: 9.3573\n",
      "Epoch 726/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4121 - val_loss: 10.0371\n",
      "Epoch 727/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.3425 - val_loss: 9.2289\n",
      "Epoch 728/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 8.5506 - val_loss: 12.6306\n",
      "Epoch 729/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.9471 - val_loss: 10.1271\n",
      "Epoch 730/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.0902 - val_loss: 9.9257\n",
      "Epoch 731/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.1600 - val_loss: 9.5530\n",
      "Epoch 732/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.2174 - val_loss: 9.1657\n",
      "Epoch 733/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.1800 - val_loss: 9.4577\n",
      "Epoch 734/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.1974 - val_loss: 9.4680\n",
      "Epoch 735/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.2705 - val_loss: 9.8744\n",
      "Epoch 736/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2537 - val_loss: 8.9711\n",
      "Epoch 737/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.9628 - val_loss: 9.2105\n",
      "Epoch 738/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2374 - val_loss: 10.0378\n",
      "Epoch 739/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1102 - val_loss: 9.7404\n",
      "Epoch 740/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0934 - val_loss: 9.8286\n",
      "Epoch 741/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1096 - val_loss: 9.1390\n",
      "Epoch 742/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.1065 - val_loss: 10.1304\n",
      "Epoch 743/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.3603 - val_loss: 9.1489\n",
      "Epoch 744/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.2341 - val_loss: 10.1758\n",
      "Epoch 745/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1896 - val_loss: 8.9394\n",
      "Epoch 746/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4768 - val_loss: 9.8205\n",
      "Epoch 747/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.0512 - val_loss: 12.1593\n",
      "Epoch 748/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.1261 - val_loss: 11.0006\n",
      "Epoch 749/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.5345 - val_loss: 9.0996\n",
      "Epoch 750/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.2448 - val_loss: 10.3756\n",
      "Epoch 751/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.0584 - val_loss: 9.7419\n",
      "Epoch 752/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.1113 - val_loss: 9.7386\n",
      "Epoch 753/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7643 - val_loss: 11.4554\n",
      "Epoch 754/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.2647 - val_loss: 9.3126\n",
      "Epoch 755/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1013 - val_loss: 9.5845\n",
      "Epoch 756/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6110 - val_loss: 9.3527\n",
      "Epoch 757/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.2602 - val_loss: 9.5968\n",
      "Epoch 758/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5826 - val_loss: 9.5760\n",
      "Epoch 759/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2732 - val_loss: 10.5700\n",
      "Epoch 760/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.5755 - val_loss: 9.8278\n",
      "Epoch 761/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.5042 - val_loss: 9.8762\n",
      "Epoch 762/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0673 - val_loss: 9.5243\n",
      "Epoch 763/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.5171 - val_loss: 9.9734\n",
      "Epoch 764/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.0843 - val_loss: 9.6897\n",
      "Epoch 765/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3445 - val_loss: 10.2028\n",
      "Epoch 766/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1923 - val_loss: 9.4914\n",
      "Epoch 767/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2613 - val_loss: 9.4346\n",
      "Epoch 768/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1409 - val_loss: 10.7823\n",
      "Epoch 769/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8585 - val_loss: 9.6047\n",
      "Epoch 770/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.0807 - val_loss: 9.5232\n",
      "Epoch 771/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.1703 - val_loss: 9.9449\n",
      "Epoch 772/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9748 - val_loss: 9.1377\n",
      "Epoch 773/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.0934 - val_loss: 8.9292\n",
      "Epoch 774/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3883 - val_loss: 9.4238\n",
      "Epoch 775/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.4701 - val_loss: 10.4986\n",
      "Epoch 776/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1241 - val_loss: 9.0895\n",
      "Epoch 777/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.0778 - val_loss: 9.4478\n",
      "Epoch 778/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.1981 - val_loss: 9.8183\n",
      "Epoch 779/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0703 - val_loss: 9.0347\n",
      "Epoch 780/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.9902 - val_loss: 9.5512\n",
      "Epoch 781/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2475 - val_loss: 9.1671\n",
      "Epoch 782/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2181 - val_loss: 10.9522\n",
      "Epoch 783/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3745 - val_loss: 11.0231\n",
      "Epoch 784/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.2937 - val_loss: 10.3195\n",
      "Epoch 785/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4219 - val_loss: 10.6318\n",
      "Epoch 786/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4788 - val_loss: 10.7771\n",
      "Epoch 787/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2534 - val_loss: 9.0581\n",
      "Epoch 788/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.7273 - val_loss: 9.1253\n",
      "Epoch 789/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.9854 - val_loss: 9.3447\n",
      "Epoch 790/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.2080 - val_loss: 9.1993\n",
      "Epoch 791/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.7041 - val_loss: 9.1484\n",
      "Epoch 792/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0963 - val_loss: 9.8061\n",
      "Epoch 793/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2958 - val_loss: 9.7122\n",
      "Epoch 794/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3049 - val_loss: 10.0195\n",
      "Epoch 795/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1896 - val_loss: 10.3309\n",
      "Epoch 796/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4676 - val_loss: 10.1668\n",
      "Epoch 797/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2467 - val_loss: 10.1975\n",
      "Epoch 798/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.8938 - val_loss: 9.4750\n",
      "Epoch 799/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.1065 - val_loss: 9.9074\n",
      "Epoch 800/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3554 - val_loss: 9.5982\n",
      "Epoch 801/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2273 - val_loss: 9.6992\n",
      "Epoch 802/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1675 - val_loss: 9.6103\n",
      "Epoch 803/1000\n",
      "1052/1052 [==============================] - 0s 111us/step - loss: 8.1780 - val_loss: 9.2011\n",
      "Epoch 804/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3096 - val_loss: 9.4380\n",
      "Epoch 805/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.5810 - val_loss: 9.1624\n",
      "Epoch 806/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.8032 - val_loss: 9.9513\n",
      "Epoch 807/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2831 - val_loss: 9.3606\n",
      "Epoch 808/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1397 - val_loss: 10.0412\n",
      "Epoch 809/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2494 - val_loss: 9.3968\n",
      "Epoch 810/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.1583 - val_loss: 9.1032\n",
      "Epoch 811/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2246 - val_loss: 10.2382\n",
      "Epoch 812/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6330 - val_loss: 9.3836\n",
      "Epoch 813/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1138 - val_loss: 9.0902\n",
      "Epoch 814/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.0381 - val_loss: 10.0733\n",
      "Epoch 815/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.4099 - val_loss: 9.8965\n",
      "Epoch 816/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4175 - val_loss: 10.2933\n",
      "Epoch 817/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0189 - val_loss: 9.2414\n",
      "Epoch 818/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1034 - val_loss: 9.1109\n",
      "Epoch 819/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3893 - val_loss: 9.1088\n",
      "Epoch 820/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.3739 - val_loss: 10.2030\n",
      "Epoch 821/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.8650 - val_loss: 9.9220\n",
      "Epoch 822/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4386 - val_loss: 9.2766\n",
      "Epoch 823/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5374 - val_loss: 10.8904\n",
      "Epoch 824/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.7212 - val_loss: 9.2532\n",
      "Epoch 825/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3675 - val_loss: 10.3145\n",
      "Epoch 826/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2724 - val_loss: 9.6759\n",
      "Epoch 827/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3623 - val_loss: 9.4245\n",
      "Epoch 828/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2957 - val_loss: 11.5659\n",
      "Epoch 829/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4656 - val_loss: 11.1549\n",
      "Epoch 830/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6683 - val_loss: 9.7876\n",
      "Epoch 831/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2815 - val_loss: 9.8867\n",
      "Epoch 832/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2457 - val_loss: 9.1952\n",
      "Epoch 833/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0464 - val_loss: 9.5764\n",
      "Epoch 834/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2036 - val_loss: 9.3469\n",
      "Epoch 835/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2773 - val_loss: 9.1478\n",
      "Epoch 836/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.0637 - val_loss: 9.5340\n",
      "Epoch 837/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5933 - val_loss: 9.1153\n",
      "Epoch 838/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8050 - val_loss: 11.5528\n",
      "Epoch 839/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4277 - val_loss: 9.5692\n",
      "Epoch 840/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6759 - val_loss: 9.9735\n",
      "Epoch 841/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3872 - val_loss: 9.5634\n",
      "Epoch 842/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.7947 - val_loss: 10.2743\n",
      "Epoch 843/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.1998 - val_loss: 9.4193\n",
      "Epoch 844/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.3999 - val_loss: 9.2353\n",
      "Epoch 845/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1799 - val_loss: 9.2454\n",
      "Epoch 846/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0785 - val_loss: 9.6349\n",
      "Epoch 847/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.2508 - val_loss: 9.7451\n",
      "Epoch 848/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.0262 - val_loss: 10.5997\n",
      "Epoch 849/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2621 - val_loss: 9.7861\n",
      "Epoch 850/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1849 - val_loss: 9.3810\n",
      "Epoch 851/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4547 - val_loss: 11.5475\n",
      "Epoch 852/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3143 - val_loss: 9.5066\n",
      "Epoch 853/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4801 - val_loss: 9.1584\n",
      "Epoch 854/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.5391 - val_loss: 9.8862\n",
      "Epoch 855/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3551 - val_loss: 10.7676\n",
      "Epoch 856/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6472 - val_loss: 9.1438\n",
      "Epoch 857/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5418 - val_loss: 9.4177\n",
      "Epoch 858/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0874 - val_loss: 9.2048\n",
      "Epoch 859/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.1199 - val_loss: 9.0073\n",
      "Epoch 860/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.8271 - val_loss: 9.1648\n",
      "Epoch 861/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.0728 - val_loss: 9.3738\n",
      "Epoch 862/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5314 - val_loss: 9.1916\n",
      "Epoch 863/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.0252 - val_loss: 9.1947\n",
      "Epoch 864/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2050 - val_loss: 9.7951\n",
      "Epoch 865/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3901 - val_loss: 9.9100\n",
      "Epoch 866/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.9121 - val_loss: 10.1189\n",
      "Epoch 867/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2486 - val_loss: 8.8463\n",
      "Epoch 868/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.9576 - val_loss: 9.7333\n",
      "Epoch 869/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.1200 - val_loss: 9.2382\n",
      "Epoch 870/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.0523 - val_loss: 11.5933\n",
      "Epoch 871/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.0380 - val_loss: 9.2030\n",
      "Epoch 872/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1407 - val_loss: 9.2304\n",
      "Epoch 873/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.9368 - val_loss: 9.4000\n",
      "Epoch 874/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.1367 - val_loss: 8.8301\n",
      "Epoch 875/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.8743 - val_loss: 9.2580\n",
      "Epoch 876/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5029 - val_loss: 10.4023\n",
      "Epoch 877/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.4144 - val_loss: 11.4391\n",
      "Epoch 878/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1815 - val_loss: 10.4295\n",
      "Epoch 879/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3268 - val_loss: 9.7019\n",
      "Epoch 880/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1835 - val_loss: 10.2947\n",
      "Epoch 881/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0253 - val_loss: 8.7856\n",
      "Epoch 882/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.5080 - val_loss: 10.4259\n",
      "Epoch 883/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 8.161 - 0s 90us/step - loss: 8.0132 - val_loss: 9.1391\n",
      "Epoch 884/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2226 - val_loss: 9.0963\n",
      "Epoch 885/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2174 - val_loss: 10.6040\n",
      "Epoch 886/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1135 - val_loss: 9.2372\n",
      "Epoch 887/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.9806 - val_loss: 9.0738\n",
      "Epoch 888/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3358 - val_loss: 8.8722\n",
      "Epoch 889/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1821 - val_loss: 9.0498\n",
      "Epoch 890/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.2209 - val_loss: 11.2798\n",
      "Epoch 891/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.0767 - val_loss: 9.2666\n",
      "Epoch 892/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.3944 - val_loss: 12.2835\n",
      "Epoch 893/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.2111 - val_loss: 8.8570\n",
      "Epoch 894/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 7.9823 - val_loss: 8.8096\n",
      "Epoch 895/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 8.0793 - val_loss: 9.4742\n",
      "Epoch 896/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.3573 - val_loss: 9.2752\n",
      "Epoch 897/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 8.0889 - val_loss: 9.2538\n",
      "Epoch 898/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.1512 - val_loss: 12.9001\n",
      "Epoch 899/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.6684 - val_loss: 10.4153\n",
      "Epoch 900/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.0152 - val_loss: 9.0421\n",
      "Epoch 901/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1395 - val_loss: 9.2669\n",
      "Epoch 902/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.0737 - val_loss: 9.6211\n",
      "Epoch 903/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0670 - val_loss: 9.2715\n",
      "Epoch 904/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2234 - val_loss: 8.9192\n",
      "Epoch 905/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.0899 - val_loss: 9.5180\n",
      "Epoch 906/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3098 - val_loss: 10.1674\n",
      "Epoch 907/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4566 - val_loss: 9.0527\n",
      "Epoch 908/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.4176 - val_loss: 9.4128\n",
      "Epoch 909/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3249 - val_loss: 10.4064\n",
      "Epoch 910/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.8329 - val_loss: 9.1760\n",
      "Epoch 911/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5710 - val_loss: 10.2315\n",
      "Epoch 912/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2930 - val_loss: 9.9432\n",
      "Epoch 913/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9598 - val_loss: 9.3143\n",
      "Epoch 914/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.0252 - val_loss: 9.1463\n",
      "Epoch 915/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1651 - val_loss: 10.1322\n",
      "Epoch 916/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4326 - val_loss: 9.7388\n",
      "Epoch 917/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.0547 - val_loss: 10.4675\n",
      "Epoch 918/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0360 - val_loss: 9.7189\n",
      "Epoch 919/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.9857 - val_loss: 11.1849\n",
      "Epoch 920/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.4815 - val_loss: 8.9858\n",
      "Epoch 921/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0528 - val_loss: 10.1324\n",
      "Epoch 922/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0792 - val_loss: 9.4905\n",
      "Epoch 923/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3230 - val_loss: 9.3558\n",
      "Epoch 924/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.1204 - val_loss: 8.9839\n",
      "Epoch 925/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.0825 - val_loss: 9.8334\n",
      "Epoch 926/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.0470 - val_loss: 8.9511\n",
      "Epoch 927/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.5242 - val_loss: 11.6849\n",
      "Epoch 928/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.5262 - val_loss: 9.3560\n",
      "Epoch 929/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.8595 - val_loss: 9.5830\n",
      "Epoch 930/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1650 - val_loss: 8.9095\n",
      "Epoch 931/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.9669 - val_loss: 9.8111\n",
      "Epoch 932/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1918 - val_loss: 9.7192\n",
      "Epoch 933/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9583 - val_loss: 9.6224\n",
      "Epoch 934/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.9620 - val_loss: 9.1576\n",
      "Epoch 935/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.4570 - val_loss: 10.7982\n",
      "Epoch 936/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.2364 - val_loss: 8.9558\n",
      "Epoch 937/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.9908 - val_loss: 10.4758\n",
      "Epoch 938/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1975 - val_loss: 10.0068\n",
      "Epoch 939/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.1454 - val_loss: 10.2506\n",
      "Epoch 940/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.5757 - val_loss: 9.2099\n",
      "Epoch 941/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.1460 - val_loss: 9.1011\n",
      "Epoch 942/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3215 - val_loss: 9.3423\n",
      "Epoch 943/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.9674 - val_loss: 9.6109\n",
      "Epoch 944/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.0640 - val_loss: 9.2321\n",
      "Epoch 945/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1732 - val_loss: 9.8352\n",
      "Epoch 946/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.0738 - val_loss: 8.8661\n",
      "Epoch 947/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.1794 - val_loss: 10.4530\n",
      "Epoch 948/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4321 - val_loss: 9.9739\n",
      "Epoch 949/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4188 - val_loss: 8.7647\n",
      "Epoch 950/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.0208 - val_loss: 9.2454\n",
      "Epoch 951/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2445 - val_loss: 10.4151\n",
      "Epoch 952/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4963 - val_loss: 9.5860\n",
      "Epoch 953/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2143 - val_loss: 9.8965\n",
      "Epoch 954/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3224 - val_loss: 10.1390\n",
      "Epoch 955/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.9664 - val_loss: 9.5976\n",
      "Epoch 956/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3514 - val_loss: 8.9402\n",
      "Epoch 957/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1816 - val_loss: 10.7522\n",
      "Epoch 958/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.2186 - val_loss: 8.9513\n",
      "Epoch 959/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.9280 - val_loss: 9.3885\n",
      "Epoch 960/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.1344 - val_loss: 9.8902\n",
      "Epoch 961/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1963 - val_loss: 10.0187\n",
      "Epoch 962/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1065 - val_loss: 8.9618\n",
      "Epoch 963/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2672 - val_loss: 8.9080\n",
      "Epoch 964/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.9479 - val_loss: 9.4880\n",
      "Epoch 965/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.8464 - val_loss: 10.0182\n",
      "Epoch 966/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2706 - val_loss: 9.4312\n",
      "Epoch 967/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1936 - val_loss: 9.4343\n",
      "Epoch 968/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2534 - val_loss: 10.0522\n",
      "Epoch 969/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.7991 - val_loss: 11.3249\n",
      "Epoch 970/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5301 - val_loss: 11.5436\n",
      "Epoch 971/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3330 - val_loss: 9.3227\n",
      "Epoch 972/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5757 - val_loss: 10.6647\n",
      "Epoch 973/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.7805 - val_loss: 9.5480\n",
      "Epoch 974/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.2919 - val_loss: 9.8950\n",
      "Epoch 975/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.5451 - val_loss: 9.4337\n",
      "Epoch 976/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.0465 - val_loss: 8.9928\n",
      "Epoch 977/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3903 - val_loss: 9.3542\n",
      "Epoch 978/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.1370 - val_loss: 12.1327\n",
      "Epoch 979/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2981 - val_loss: 9.0360\n",
      "Epoch 980/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.0715 - val_loss: 9.0579\n",
      "Epoch 981/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2762 - val_loss: 10.2796\n",
      "Epoch 982/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2880 - val_loss: 10.4505\n",
      "Epoch 983/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3943 - val_loss: 9.8672\n",
      "Epoch 984/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.2878 - val_loss: 10.2656\n",
      "Epoch 985/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.0955 - val_loss: 9.7280\n",
      "Epoch 986/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.0464 - val_loss: 9.7935\n",
      "Epoch 987/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9572 - val_loss: 9.6638\n",
      "Epoch 988/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1116 - val_loss: 9.0723\n",
      "Epoch 989/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.1263 - val_loss: 10.0428\n",
      "Epoch 990/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6692 - val_loss: 10.3962\n",
      "Epoch 991/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8206 - val_loss: 10.6243\n",
      "Epoch 992/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.6550 - val_loss: 9.6995\n",
      "Epoch 993/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.9309 - val_loss: 11.0940\n",
      "Epoch 994/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.0675 - val_loss: 9.7416\n",
      "Epoch 995/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2950 - val_loss: 9.5128\n",
      "Epoch 996/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.9549 - val_loss: 9.4133\n",
      "Epoch 997/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.0299 - val_loss: 9.8417\n",
      "Epoch 998/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3087 - val_loss: 11.5039\n",
      "Epoch 999/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.0035 - val_loss: 9.2465\n",
      "Epoch 1000/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9992 - val_loss: 9.4607\n",
      "8.59667706489563\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.18546297,  0.7904468 , -3.3235636 , -1.8288312 , -4.0985484 ],\n",
       "        [-0.16851097,  1.5531429 ,  0.09846704,  0.52501965,  0.21355905],\n",
       "        [-0.29885468,  1.7086195 ,  0.01912374,  0.42133436, -0.73038805],\n",
       "        [ 0.11626258, -0.2721323 ,  0.05982428,  0.01913126,  0.17582665],\n",
       "        [-0.17599642, -0.40401977, -2.4137888 , -0.30316097, -0.3241332 ]],\n",
       "       dtype=float32),\n",
       " array([ 1.2750512,  0.6981047, -4.891635 , -1.3011069, -5.030824 ],\n",
       "       dtype=float32),\n",
       " array([[-1.8419304 , -1.5128286 ,  1.5209936 , -1.8290058 ,  1.5132009 ,\n",
       "         -1.224721  ,  1.4473449 ,  1.5925415 ,  1.4079596 , -0.82628655],\n",
       "        [ 0.3778976 ,  0.6369942 ,  0.31025425,  0.40834126, -0.4209189 ,\n",
       "          0.22520089, -0.5094401 , -0.09394934, -0.2854539 ,  0.47769466],\n",
       "        [ 2.1376326 ,  1.6746633 , -2.3704526 ,  1.3334824 , -1.5715615 ,\n",
       "          2.2088645 , -2.043277  , -1.6855069 , -1.335016  ,  2.203931  ],\n",
       "        [-0.52063954, -0.78502256,  1.0060669 , -0.44593796,  0.7134199 ,\n",
       "         -0.08538195,  0.65609056,  0.52835387,  0.5733653 , -0.63733774],\n",
       "        [ 1.5329696 ,  2.1467624 , -2.0041964 ,  1.5151341 , -1.8702115 ,\n",
       "          1.5191977 , -1.9681158 , -2.0155363 , -2.475219  ,  2.4621706 ]],\n",
       "       dtype=float32),\n",
       " array([-2.3001208, -2.30551  ,  2.3181734, -2.2837522,  1.681552 ,\n",
       "        -2.2610497,  2.3374915,  2.1669488,  2.3019307, -2.293857 ],\n",
       "       dtype=float32),\n",
       " array([[-1.8223562],\n",
       "        [-1.8515605],\n",
       "        [ 1.9547944],\n",
       "        [-1.7578503],\n",
       "        [ 1.3605707],\n",
       "        [-1.6844583],\n",
       "        [ 2.204521 ],\n",
       "        [ 1.5865823],\n",
       "        [ 1.997327 ],\n",
       "        [-1.8140743]], dtype=float32),\n",
       " array([2.5187972], dtype=float32)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_airfoil, history_airfoil=NN_model_structure_regression_2(X_train_airfoil, X_val_airfoil, Y_train_airfoil, Y_val_airfoil, adam2, 32, 1000)\n",
    "model_airfoil.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_airfoil.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_airfoil_structure2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 15)                90        \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 136\n",
      "Trainable params: 136\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1052 samples, validate on 225 samples\n",
      "Epoch 1/1000\n",
      "1052/1052 [==============================] - 0s 212us/step - loss: 7207.6563 - val_loss: 203.6307\n",
      "Epoch 2/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 156.6200 - val_loss: 62.1897\n",
      "Epoch 3/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 34.4578 - val_loss: 34.0873\n",
      "Epoch 4/1000\n",
      "1052/1052 [==============================] - 0s 109us/step - loss: 25.8461 - val_loss: 29.8629\n",
      "Epoch 5/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 23.8992 - val_loss: 28.5741\n",
      "Epoch 6/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.4196 - val_loss: 27.1452\n",
      "Epoch 7/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.5540 - val_loss: 28.1089\n",
      "Epoch 8/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.0713 - val_loss: 26.1257\n",
      "Epoch 9/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 20.4833 - val_loss: 25.6550\n",
      "Epoch 10/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 19.8567 - val_loss: 25.4705\n",
      "Epoch 11/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 19.5608 - val_loss: 25.2787\n",
      "Epoch 12/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 19.5050 - val_loss: 25.8749\n",
      "Epoch 13/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 19.3483 - val_loss: 24.6991\n",
      "Epoch 14/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 19.0056 - val_loss: 24.2544\n",
      "Epoch 15/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.7515 - val_loss: 24.3647\n",
      "Epoch 16/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 18.6516 - val_loss: 24.4753\n",
      "Epoch 17/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 18.5493 - val_loss: 24.2855\n",
      "Epoch 18/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 18.4875 - val_loss: 23.8205\n",
      "Epoch 19/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 18.3787 - val_loss: 23.7197\n",
      "Epoch 20/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 18.2956 - val_loss: 23.4618\n",
      "Epoch 21/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.4558 - val_loss: 25.2120\n",
      "Epoch 22/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 18.5782 - val_loss: 23.3081\n",
      "Epoch 23/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.0463 - val_loss: 23.5056\n",
      "Epoch 24/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 18.0236 - val_loss: 24.1038\n",
      "Epoch 25/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.2444 - val_loss: 23.1653\n",
      "Epoch 26/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 18.0927 - val_loss: 23.4855\n",
      "Epoch 27/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 17.8558 - val_loss: 22.8056\n",
      "Epoch 28/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 17.8694 - val_loss: 23.4196\n",
      "Epoch 29/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 17.8958 - val_loss: 22.8442\n",
      "Epoch 30/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 17.8612 - val_loss: 22.6487\n",
      "Epoch 31/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 17.6601 - val_loss: 22.7631\n",
      "Epoch 32/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 17.7256 - val_loss: 22.4605\n",
      "Epoch 33/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.6671 - val_loss: 22.2951\n",
      "Epoch 34/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 17.5882 - val_loss: 22.3972\n",
      "Epoch 35/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.5862 - val_loss: 22.5209\n",
      "Epoch 36/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 17.7072 - val_loss: 21.9823\n",
      "Epoch 37/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 17.6270 - val_loss: 22.3325\n",
      "Epoch 38/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 17.5410 - val_loss: 21.6033\n",
      "Epoch 39/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 17.3747 - val_loss: 21.5527\n",
      "Epoch 40/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.4176 - val_loss: 21.6568\n",
      "Epoch 41/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 17.3177 - val_loss: 21.6389\n",
      "Epoch 42/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.2654 - val_loss: 21.5322\n",
      "Epoch 43/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.2171 - val_loss: 21.0962\n",
      "Epoch 44/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 17.3246 - val_loss: 20.9414\n",
      "Epoch 45/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.0831 - val_loss: 20.8738\n",
      "Epoch 46/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.2245 - val_loss: 21.1218\n",
      "Epoch 47/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.0037 - val_loss: 20.8828\n",
      "Epoch 48/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.0321 - val_loss: 20.5695\n",
      "Epoch 49/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 17.0689 - val_loss: 20.7289\n",
      "Epoch 50/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 17.3868 - val_loss: 20.7551\n",
      "Epoch 51/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 16.9400 - val_loss: 20.5597\n",
      "Epoch 52/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 16.8326 - val_loss: 20.9000\n",
      "Epoch 53/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 16.8874 - val_loss: 20.6196\n",
      "Epoch 54/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 16.8890 - val_loss: 19.8300\n",
      "Epoch 55/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 16.7856 - val_loss: 20.4186\n",
      "Epoch 56/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 16.6913 - val_loss: 20.0060\n",
      "Epoch 57/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 16.8628 - val_loss: 20.1069\n",
      "Epoch 58/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 16.6876 - val_loss: 20.1965\n",
      "Epoch 59/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 16.7034 - val_loss: 19.7858\n",
      "Epoch 60/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 16.4519 - val_loss: 19.7770\n",
      "Epoch 61/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 16.4494 - val_loss: 19.3193\n",
      "Epoch 62/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 16.8444 - val_loss: 20.5822\n",
      "Epoch 63/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 16.4377 - val_loss: 19.5921\n",
      "Epoch 64/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 16.3410 - val_loss: 19.3507\n",
      "Epoch 65/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 16.5971 - val_loss: 19.2690\n",
      "Epoch 66/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 16.5443 - val_loss: 19.0055\n",
      "Epoch 67/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 100us/step - loss: 16.1449 - val_loss: 18.9845\n",
      "Epoch 68/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 16.2901 - val_loss: 18.8770\n",
      "Epoch 69/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 16.0071 - val_loss: 20.3350\n",
      "Epoch 70/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 16.4295 - val_loss: 19.1770\n",
      "Epoch 71/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 15.9162 - val_loss: 20.1480\n",
      "Epoch 72/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 16.2334 - val_loss: 19.1652\n",
      "Epoch 73/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 15.7977 - val_loss: 19.4801\n",
      "Epoch 74/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 16.2564 - val_loss: 18.3747\n",
      "Epoch 75/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 16.2504 - val_loss: 19.4634\n",
      "Epoch 76/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 15.8444 - val_loss: 18.3215\n",
      "Epoch 77/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 15.9303 - val_loss: 18.2560\n",
      "Epoch 78/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 15.7377 - val_loss: 19.2034\n",
      "Epoch 79/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 15.9391 - val_loss: 19.1732\n",
      "Epoch 80/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 15.5456 - val_loss: 18.7619\n",
      "Epoch 81/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 15.7499 - val_loss: 19.1137\n",
      "Epoch 82/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 15.6244 - val_loss: 18.9209\n",
      "Epoch 83/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 15.5929 - val_loss: 18.3135\n",
      "Epoch 84/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 15.9669 - val_loss: 18.2115\n",
      "Epoch 85/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 15.4636 - val_loss: 19.0076\n",
      "Epoch 86/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 15.2779 - val_loss: 19.5148\n",
      "Epoch 87/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 15.3473 - val_loss: 20.5116\n",
      "Epoch 88/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 15.3299 - val_loss: 19.5501\n",
      "Epoch 89/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 15.4741 - val_loss: 18.5190\n",
      "Epoch 90/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 15.2121 - val_loss: 18.1216\n",
      "Epoch 91/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 15.6179 - val_loss: 19.2448\n",
      "Epoch 92/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 16.2483 - val_loss: 17.9410\n",
      "Epoch 93/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 15.4211 - val_loss: 17.7173\n",
      "Epoch 94/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.9667 - val_loss: 17.6886\n",
      "Epoch 95/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.8152 - val_loss: 17.8636\n",
      "Epoch 96/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.9545 - val_loss: 19.2586\n",
      "Epoch 97/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 15.5516 - val_loss: 17.7650\n",
      "Epoch 98/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.9621 - val_loss: 18.6503\n",
      "Epoch 99/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 15.5573 - val_loss: 19.1985\n",
      "Epoch 100/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 15.2091 - val_loss: 19.4369\n",
      "Epoch 101/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 14.4940 - val_loss: 20.2629\n",
      "Epoch 102/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.9228 - val_loss: 19.2745\n",
      "Epoch 103/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 14.7167 - val_loss: 17.4392\n",
      "Epoch 104/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.7402 - val_loss: 17.5855\n",
      "Epoch 105/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.9528 - val_loss: 17.4126\n",
      "Epoch 106/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.3031 - val_loss: 17.2425\n",
      "Epoch 107/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 14.2397 - val_loss: 18.0476\n",
      "Epoch 108/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.6085 - val_loss: 18.3517\n",
      "Epoch 109/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.1961 - val_loss: 18.6140\n",
      "Epoch 110/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.5580 - val_loss: 17.6334\n",
      "Epoch 111/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.5864 - val_loss: 18.5457\n",
      "Epoch 112/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.1258 - val_loss: 17.7121\n",
      "Epoch 113/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 14.0969 - val_loss: 16.9152\n",
      "Epoch 114/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 13.9873 - val_loss: 18.0988\n",
      "Epoch 115/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.2060 - val_loss: 17.1670\n",
      "Epoch 116/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.0948 - val_loss: 16.5049\n",
      "Epoch 117/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.3904 - val_loss: 17.3005\n",
      "Epoch 118/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 14.8276 - val_loss: 20.7122\n",
      "Epoch 119/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 16.2532 - val_loss: 17.1486\n",
      "Epoch 120/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.7044 - val_loss: 17.9668\n",
      "Epoch 121/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 13.6653 - val_loss: 19.2333\n",
      "Epoch 122/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.4103 - val_loss: 18.7975\n",
      "Epoch 123/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.8764 - val_loss: 16.9727\n",
      "Epoch 124/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.8082 - val_loss: 17.0101\n",
      "Epoch 125/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 13.6186 - val_loss: 16.9574\n",
      "Epoch 126/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.6445 - val_loss: 19.0518\n",
      "Epoch 127/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 15.5629 - val_loss: 17.2454\n",
      "Epoch 128/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 14.4168 - val_loss: 16.4066\n",
      "Epoch 129/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.1022 - val_loss: 16.7169\n",
      "Epoch 130/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.3973 - val_loss: 18.8738\n",
      "Epoch 131/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 13.1896 - val_loss: 17.1733\n",
      "Epoch 132/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 13.9420 - val_loss: 18.3529\n",
      "Epoch 133/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 13.6454 - val_loss: 15.5922\n",
      "Epoch 134/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.5889 - val_loss: 16.7149\n",
      "Epoch 135/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 13.2510 - val_loss: 18.6768\n",
      "Epoch 136/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.8266 - val_loss: 16.0408\n",
      "Epoch 137/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 13.0298 - val_loss: 17.0281\n",
      "Epoch 138/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 12.6019 - val_loss: 16.9349\n",
      "Epoch 139/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 12.4397 - val_loss: 16.2542\n",
      "Epoch 140/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 12.8830 - val_loss: 16.7995\n",
      "Epoch 141/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 13.0525 - val_loss: 15.2378\n",
      "Epoch 142/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 13.1293 - val_loss: 15.3117\n",
      "Epoch 143/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.6403 - val_loss: 16.3518\n",
      "Epoch 144/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.8020 - val_loss: 16.4358\n",
      "Epoch 145/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 12.6918 - val_loss: 15.3925\n",
      "Epoch 146/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 12.6851 - val_loss: 15.1333\n",
      "Epoch 147/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.3518 - val_loss: 15.0580\n",
      "Epoch 148/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.3987 - val_loss: 18.0655\n",
      "Epoch 149/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.2182 - val_loss: 14.9318\n",
      "Epoch 150/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 12.1906 - val_loss: 14.5985\n",
      "Epoch 151/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.4315 - val_loss: 15.5707\n",
      "Epoch 152/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.0643 - val_loss: 15.2209\n",
      "Epoch 153/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.7618 - val_loss: 17.5243\n",
      "Epoch 154/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 12.0559 - val_loss: 15.1401\n",
      "Epoch 155/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.9770 - val_loss: 14.8481\n",
      "Epoch 156/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.0417 - val_loss: 14.2554\n",
      "Epoch 157/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 12.3043 - val_loss: 14.4997\n",
      "Epoch 158/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.7064 - val_loss: 15.5937\n",
      "Epoch 159/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.0580 - val_loss: 20.0667\n",
      "Epoch 160/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 13.2680 - val_loss: 14.6775\n",
      "Epoch 161/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.7809 - val_loss: 13.8623\n",
      "Epoch 162/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.9966 - val_loss: 16.0379\n",
      "Epoch 163/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.3826 - val_loss: 17.0084\n",
      "Epoch 164/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 12.3291 - val_loss: 14.2671\n",
      "Epoch 165/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 11.5271 - val_loss: 15.0501\n",
      "Epoch 166/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 12.1856 - val_loss: 15.1358\n",
      "Epoch 167/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.4098 - val_loss: 15.8861\n",
      "Epoch 168/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.1554 - val_loss: 14.1831\n",
      "Epoch 169/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.8072 - val_loss: 13.3050\n",
      "Epoch 170/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 11.6373 - val_loss: 15.5053\n",
      "Epoch 171/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.2786 - val_loss: 16.1318\n",
      "Epoch 172/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.4948 - val_loss: 15.1913\n",
      "Epoch 173/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.3740 - val_loss: 14.0514\n",
      "Epoch 174/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 11.3340 - val_loss: 13.2963\n",
      "Epoch 175/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 11.2062 - val_loss: 13.3394\n",
      "Epoch 176/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 12.0265 - val_loss: 14.1575\n",
      "Epoch 177/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.3141 - val_loss: 14.7525\n",
      "Epoch 178/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.5236 - val_loss: 14.4111\n",
      "Epoch 179/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.2869 - val_loss: 14.7219\n",
      "Epoch 180/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.0965 - val_loss: 13.4684\n",
      "Epoch 181/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 10.4829 - val_loss: 12.9831\n",
      "Epoch 182/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.4953 - val_loss: 20.0169\n",
      "Epoch 183/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.2542 - val_loss: 14.6145\n",
      "Epoch 184/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.5988 - val_loss: 14.2084\n",
      "Epoch 185/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.0615 - val_loss: 12.9450\n",
      "Epoch 186/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.1366 - val_loss: 13.6197\n",
      "Epoch 187/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.4930 - val_loss: 13.3627\n",
      "Epoch 188/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.6789 - val_loss: 12.6661\n",
      "Epoch 189/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.7269 - val_loss: 13.2987\n",
      "Epoch 190/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 10.8736 - val_loss: 14.4613\n",
      "Epoch 191/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 10.77 - 0s 92us/step - loss: 10.5929 - val_loss: 14.9133\n",
      "Epoch 192/1000\n",
      "1052/1052 [==============================] - 0s 108us/step - loss: 11.3986 - val_loss: 14.5510\n",
      "Epoch 193/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.9035 - val_loss: 14.7363\n",
      "Epoch 194/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.3573 - val_loss: 12.6925\n",
      "Epoch 195/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 10.3367 - val_loss: 13.4007\n",
      "Epoch 196/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.6885 - val_loss: 13.7991\n",
      "Epoch 197/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 11.2918 - val_loss: 13.9558\n",
      "Epoch 198/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 10.0173 - val_loss: 13.0525\n",
      "Epoch 199/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.5809 - val_loss: 13.5974\n",
      "Epoch 200/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.4683 - val_loss: 12.7563\n",
      "Epoch 201/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 10.0893 - val_loss: 13.3489\n",
      "Epoch 202/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.9923 - val_loss: 15.1781\n",
      "Epoch 203/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 10.6028 - val_loss: 12.6204\n",
      "Epoch 204/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.0409 - val_loss: 13.2734\n",
      "Epoch 205/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 12.1708 - val_loss: 12.0994\n",
      "Epoch 206/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.4376 - val_loss: 14.7455\n",
      "Epoch 207/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.6374 - val_loss: 12.6674\n",
      "Epoch 208/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.9989 - val_loss: 13.4710\n",
      "Epoch 209/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.5200 - val_loss: 12.1428\n",
      "Epoch 210/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.0658 - val_loss: 12.0502\n",
      "Epoch 211/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 10.6901 - val_loss: 11.9961\n",
      "Epoch 212/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.8008 - val_loss: 12.8822\n",
      "Epoch 213/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.6927 - val_loss: 11.7562\n",
      "Epoch 214/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 9.9470 - val_loss: 13.3856\n",
      "Epoch 215/1000\n",
      "1052/1052 [==============================] - 0s 113us/step - loss: 9.9550 - val_loss: 14.1981\n",
      "Epoch 216/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 10.0534 - val_loss: 11.9590\n",
      "Epoch 217/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 98us/step - loss: 9.7769 - val_loss: 13.3076\n",
      "Epoch 218/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 10.3259 - val_loss: 11.7477\n",
      "Epoch 219/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 9.9939 - val_loss: 12.1894\n",
      "Epoch 220/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.9577 - val_loss: 11.7005\n",
      "Epoch 221/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.5709 - val_loss: 11.5609\n",
      "Epoch 222/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 9.4632 - val_loss: 12.3245\n",
      "Epoch 223/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.6972 - val_loss: 12.0770\n",
      "Epoch 224/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.7613 - val_loss: 12.5407\n",
      "Epoch 225/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.7109 - val_loss: 12.1488\n",
      "Epoch 226/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.6418 - val_loss: 12.6514\n",
      "Epoch 227/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.7336 - val_loss: 11.6893\n",
      "Epoch 228/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.4794 - val_loss: 11.5729\n",
      "Epoch 229/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.9024 - val_loss: 11.8363\n",
      "Epoch 230/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.5320 - val_loss: 12.2847\n",
      "Epoch 231/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 10.2757 - val_loss: 14.5239\n",
      "Epoch 232/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 10.0318 - val_loss: 11.5957\n",
      "Epoch 233/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.2281 - val_loss: 11.2615\n",
      "Epoch 234/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.7255 - val_loss: 12.1224\n",
      "Epoch 235/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.1489 - val_loss: 11.8391\n",
      "Epoch 236/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.6364 - val_loss: 11.4566\n",
      "Epoch 237/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.4225 - val_loss: 12.5221\n",
      "Epoch 238/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.5881 - val_loss: 12.3855\n",
      "Epoch 239/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.0818 - val_loss: 12.5028\n",
      "Epoch 240/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.9991 - val_loss: 12.2401\n",
      "Epoch 241/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.7295 - val_loss: 12.6258\n",
      "Epoch 242/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.9687 - val_loss: 12.0450\n",
      "Epoch 243/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.6429 - val_loss: 11.1361\n",
      "Epoch 244/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.3436 - val_loss: 12.1924\n",
      "Epoch 245/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.7271 - val_loss: 11.8057\n",
      "Epoch 246/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.5924 - val_loss: 11.6354\n",
      "Epoch 247/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.5026 - val_loss: 11.5426\n",
      "Epoch 248/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.5741 - val_loss: 11.6006\n",
      "Epoch 249/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.8088 - val_loss: 12.3322\n",
      "Epoch 250/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.9399 - val_loss: 11.1203\n",
      "Epoch 251/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.3423 - val_loss: 11.3039\n",
      "Epoch 252/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.4551 - val_loss: 11.4527\n",
      "Epoch 253/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.9004 - val_loss: 11.4969\n",
      "Epoch 254/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.5219 - val_loss: 11.1293\n",
      "Epoch 255/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.3439 - val_loss: 12.0082\n",
      "Epoch 256/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.2938 - val_loss: 11.5100\n",
      "Epoch 257/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.3472 - val_loss: 11.8365\n",
      "Epoch 258/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.3285 - val_loss: 11.4488\n",
      "Epoch 259/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.5856 - val_loss: 11.2440\n",
      "Epoch 260/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.7619 - val_loss: 11.9644\n",
      "Epoch 261/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.5673 - val_loss: 12.1154\n",
      "Epoch 262/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.9714 - val_loss: 11.9368\n",
      "Epoch 263/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.1186 - val_loss: 12.7855\n",
      "Epoch 264/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.5714 - val_loss: 13.0053\n",
      "Epoch 265/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 10.4723 - val_loss: 13.9169\n",
      "Epoch 266/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.6063 - val_loss: 11.6523\n",
      "Epoch 267/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1734 - val_loss: 13.0688\n",
      "Epoch 268/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.6608 - val_loss: 11.6914\n",
      "Epoch 269/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.1224 - val_loss: 11.1580\n",
      "Epoch 270/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.4159 - val_loss: 13.1855\n",
      "Epoch 271/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.4675 - val_loss: 11.4440\n",
      "Epoch 272/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.5252 - val_loss: 12.0945\n",
      "Epoch 273/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.8534 - val_loss: 11.8270\n",
      "Epoch 274/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.5380 - val_loss: 11.9185\n",
      "Epoch 275/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.3556 - val_loss: 10.9497\n",
      "Epoch 276/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.3264 - val_loss: 11.6329\n",
      "Epoch 277/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.6627 - val_loss: 11.7827\n",
      "Epoch 278/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.3197 - val_loss: 11.6139\n",
      "Epoch 279/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.8041 - val_loss: 12.1533\n",
      "Epoch 280/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.6226 - val_loss: 11.8538\n",
      "Epoch 281/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.5302 - val_loss: 11.3374\n",
      "Epoch 282/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.4593 - val_loss: 11.5383\n",
      "Epoch 283/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.9046 - val_loss: 14.9890\n",
      "Epoch 284/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.0061 - val_loss: 11.1644\n",
      "Epoch 285/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2596 - val_loss: 11.1132\n",
      "Epoch 286/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.4400 - val_loss: 11.4444\n",
      "Epoch 287/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.5663 - val_loss: 11.7208\n",
      "Epoch 288/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.6376 - val_loss: 11.0195\n",
      "Epoch 289/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.6058 - val_loss: 11.5393\n",
      "Epoch 290/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.0647 - val_loss: 12.6149\n",
      "Epoch 291/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.8382 - val_loss: 11.5960\n",
      "Epoch 292/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.5056 - val_loss: 12.6582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 293/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.4254 - val_loss: 11.4166\n",
      "Epoch 294/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.7734 - val_loss: 14.9185\n",
      "Epoch 295/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.6127 - val_loss: 10.9819\n",
      "Epoch 296/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.3019 - val_loss: 11.4079\n",
      "Epoch 297/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.3741 - val_loss: 11.5974\n",
      "Epoch 298/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.0845 - val_loss: 12.1620\n",
      "Epoch 299/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.3250 - val_loss: 11.6837\n",
      "Epoch 300/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0481 - val_loss: 13.4119\n",
      "Epoch 301/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.3682 - val_loss: 11.7626\n",
      "Epoch 302/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.5294 - val_loss: 11.3024\n",
      "Epoch 303/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.3564 - val_loss: 11.3028\n",
      "Epoch 304/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.9928 - val_loss: 13.8580\n",
      "Epoch 305/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2665 - val_loss: 11.2800\n",
      "Epoch 306/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.1975 - val_loss: 13.7570\n",
      "Epoch 307/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.2810 - val_loss: 14.7431\n",
      "Epoch 308/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.4708 - val_loss: 10.8819\n",
      "Epoch 309/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.3493 - val_loss: 11.6761\n",
      "Epoch 310/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.3373 - val_loss: 11.0767\n",
      "Epoch 311/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.5282 - val_loss: 12.7015\n",
      "Epoch 312/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.2827 - val_loss: 12.0634\n",
      "Epoch 313/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.0374 - val_loss: 14.2725\n",
      "Epoch 314/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.4194 - val_loss: 12.2048\n",
      "Epoch 315/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.4383 - val_loss: 11.9472\n",
      "Epoch 316/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.4556 - val_loss: 11.7199\n",
      "Epoch 317/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.3194 - val_loss: 11.7615\n",
      "Epoch 318/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.4175 - val_loss: 11.0149\n",
      "Epoch 319/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.3501 - val_loss: 11.3662\n",
      "Epoch 320/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.3655 - val_loss: 11.0368\n",
      "Epoch 321/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.3632 - val_loss: 12.3832\n",
      "Epoch 322/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.5809 - val_loss: 11.9041\n",
      "Epoch 323/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.3442 - val_loss: 11.8861\n",
      "Epoch 324/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.4484 - val_loss: 11.4905\n",
      "Epoch 325/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.6219 - val_loss: 11.0886\n",
      "Epoch 326/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.1403 - val_loss: 12.2214\n",
      "Epoch 327/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.9619 - val_loss: 11.3294\n",
      "Epoch 328/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.8309 - val_loss: 12.0665\n",
      "Epoch 329/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.5260 - val_loss: 11.5307\n",
      "Epoch 330/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2711 - val_loss: 12.0903\n",
      "Epoch 331/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.3525 - val_loss: 13.1815\n",
      "Epoch 332/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.8914 - val_loss: 13.1869\n",
      "Epoch 333/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.1704 - val_loss: 11.4699\n",
      "Epoch 334/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.2928 - val_loss: 13.0306\n",
      "Epoch 335/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.1268 - val_loss: 10.9425\n",
      "Epoch 336/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.4795 - val_loss: 10.9066\n",
      "Epoch 337/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.5761 - val_loss: 12.6360\n",
      "Epoch 338/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.8013 - val_loss: 11.9322\n",
      "Epoch 339/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.3301 - val_loss: 12.0257\n",
      "Epoch 340/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.1567 - val_loss: 11.0455\n",
      "Epoch 341/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.4945 - val_loss: 10.7852\n",
      "Epoch 342/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.1518 - val_loss: 11.1387\n",
      "Epoch 343/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.1361 - val_loss: 11.2048\n",
      "Epoch 344/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.2147 - val_loss: 11.5688\n",
      "Epoch 345/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.5106 - val_loss: 10.8068\n",
      "Epoch 346/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9541 - val_loss: 10.9340\n",
      "Epoch 347/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.2439 - val_loss: 11.2714\n",
      "Epoch 348/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.6080 - val_loss: 11.3394\n",
      "Epoch 349/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1336 - val_loss: 12.5017\n",
      "Epoch 350/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.5402 - val_loss: 11.0915\n",
      "Epoch 351/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8152 - val_loss: 12.3558\n",
      "Epoch 352/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.7614 - val_loss: 11.3693\n",
      "Epoch 353/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.6916 - val_loss: 12.2197\n",
      "Epoch 354/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.6532 - val_loss: 11.1020\n",
      "Epoch 355/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.1470 - val_loss: 12.1780\n",
      "Epoch 356/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0235 - val_loss: 11.4619\n",
      "Epoch 357/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.1566 - val_loss: 11.1257\n",
      "Epoch 358/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8390 - val_loss: 11.2962\n",
      "Epoch 359/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.6167 - val_loss: 11.5244\n",
      "Epoch 360/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.9650 - val_loss: 11.6182\n",
      "Epoch 361/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9657 - val_loss: 11.1126\n",
      "Epoch 362/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.2807 - val_loss: 13.3887\n",
      "Epoch 363/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.4116 - val_loss: 11.0254\n",
      "Epoch 364/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.5074 - val_loss: 13.5702\n",
      "Epoch 365/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.8273 - val_loss: 13.7855\n",
      "Epoch 366/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.5805 - val_loss: 11.1670\n",
      "Epoch 367/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9451 - val_loss: 11.1702\n",
      "Epoch 368/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.2004 - val_loss: 11.5689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 369/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.4094 - val_loss: 11.7924\n",
      "Epoch 370/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.3429 - val_loss: 11.7430\n",
      "Epoch 371/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0191 - val_loss: 12.0111\n",
      "Epoch 372/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0683 - val_loss: 11.5161\n",
      "Epoch 373/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0501 - val_loss: 11.6607\n",
      "Epoch 374/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8901 - val_loss: 11.1681\n",
      "Epoch 375/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0141 - val_loss: 11.0007\n",
      "Epoch 376/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0050 - val_loss: 10.9485\n",
      "Epoch 377/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9778 - val_loss: 11.7894\n",
      "Epoch 378/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1626 - val_loss: 11.4838\n",
      "Epoch 379/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 9.2824 - val_loss: 11.9089\n",
      "Epoch 380/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 9.1976 - val_loss: 11.3675\n",
      "Epoch 381/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.4706 - val_loss: 11.0979\n",
      "Epoch 382/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 9.0843 - val_loss: 11.3848\n",
      "Epoch 383/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.5966 - val_loss: 11.1419\n",
      "Epoch 384/1000\n",
      "1052/1052 [==============================] - 0s 119us/step - loss: 9.8142 - val_loss: 12.5717\n",
      "Epoch 385/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.6399 - val_loss: 11.1382\n",
      "Epoch 386/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.2511 - val_loss: 11.4009\n",
      "Epoch 387/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 9.2473 - val_loss: 11.0502\n",
      "Epoch 388/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 10.0064 - val_loss: 12.8876\n",
      "Epoch 389/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.2293 - val_loss: 11.1194\n",
      "Epoch 390/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.4347 - val_loss: 11.6080\n",
      "Epoch 391/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.4622 - val_loss: 10.9847\n",
      "Epoch 392/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1290 - val_loss: 10.8886\n",
      "Epoch 393/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.2211 - val_loss: 13.0035\n",
      "Epoch 394/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9203 - val_loss: 10.7373\n",
      "Epoch 395/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 9.7039 - val_loss: 11.0814\n",
      "Epoch 396/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.2240 - val_loss: 10.9214\n",
      "Epoch 397/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.3475 - val_loss: 11.6594\n",
      "Epoch 398/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.4146 - val_loss: 10.9273\n",
      "Epoch 399/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.7214 - val_loss: 11.3011\n",
      "Epoch 400/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.8544 - val_loss: 11.4178\n",
      "Epoch 401/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.8407 - val_loss: 12.8641\n",
      "Epoch 402/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.3261 - val_loss: 11.8313\n",
      "Epoch 403/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.5286 - val_loss: 11.1615\n",
      "Epoch 404/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1289 - val_loss: 10.8699\n",
      "Epoch 405/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.2957 - val_loss: 12.0528\n",
      "Epoch 406/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.4495 - val_loss: 11.7248\n",
      "Epoch 407/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.3931 - val_loss: 11.6186\n",
      "Epoch 408/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9990 - val_loss: 11.6778\n",
      "Epoch 409/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.3994 - val_loss: 11.0239\n",
      "Epoch 410/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9382 - val_loss: 11.0213\n",
      "Epoch 411/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1009 - val_loss: 11.2772\n",
      "Epoch 412/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.1939 - val_loss: 10.8156\n",
      "Epoch 413/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.2573 - val_loss: 11.2354\n",
      "Epoch 414/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.8646 - val_loss: 12.5178\n",
      "Epoch 415/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.0030 - val_loss: 11.6800\n",
      "Epoch 416/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.4127 - val_loss: 12.0326\n",
      "Epoch 417/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.4989 - val_loss: 11.8876\n",
      "Epoch 418/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.3492 - val_loss: 10.7109\n",
      "Epoch 419/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.2128 - val_loss: 11.0486\n",
      "Epoch 420/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2209 - val_loss: 11.3322\n",
      "Epoch 421/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1188 - val_loss: 11.8456\n",
      "Epoch 422/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.5148 - val_loss: 11.2633\n",
      "Epoch 423/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.3090 - val_loss: 11.1325\n",
      "Epoch 424/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.3286 - val_loss: 11.1830\n",
      "Epoch 425/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.2982 - val_loss: 11.7548\n",
      "Epoch 426/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.5972 - val_loss: 12.3077\n",
      "Epoch 427/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.5428 - val_loss: 11.5006\n",
      "Epoch 428/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.7190 - val_loss: 11.3286\n",
      "Epoch 429/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1787 - val_loss: 11.7374\n",
      "Epoch 430/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.5788 - val_loss: 11.2053\n",
      "Epoch 431/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.3640 - val_loss: 11.4752\n",
      "Epoch 432/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.3345 - val_loss: 10.9022\n",
      "Epoch 433/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.3990 - val_loss: 10.8175\n",
      "Epoch 434/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8047 - val_loss: 10.9862\n",
      "Epoch 435/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.3669 - val_loss: 10.9574\n",
      "Epoch 436/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.7761 - val_loss: 10.7788\n",
      "Epoch 437/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.3294 - val_loss: 11.0517\n",
      "Epoch 438/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 9.0485 - val_loss: 10.7191\n",
      "Epoch 439/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.0163 - val_loss: 11.1884\n",
      "Epoch 440/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0956 - val_loss: 11.9263\n",
      "Epoch 441/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1507 - val_loss: 12.2827\n",
      "Epoch 442/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9299 - val_loss: 10.5897\n",
      "Epoch 443/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9353 - val_loss: 10.7160\n",
      "Epoch 444/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.4873 - val_loss: 11.0300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 445/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0604 - val_loss: 14.3579\n",
      "Epoch 446/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0547 - val_loss: 11.0941\n",
      "Epoch 447/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.3700 - val_loss: 12.1064\n",
      "Epoch 448/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9624 - val_loss: 11.3414\n",
      "Epoch 449/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.4694 - val_loss: 10.7455\n",
      "Epoch 450/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9674 - val_loss: 11.4328\n",
      "Epoch 451/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.9677 - val_loss: 10.7664\n",
      "Epoch 452/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9695 - val_loss: 10.8752\n",
      "Epoch 453/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.2784 - val_loss: 11.0737\n",
      "Epoch 454/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2622 - val_loss: 11.6922\n",
      "Epoch 455/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.5159 - val_loss: 11.7253\n",
      "Epoch 456/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.3428 - val_loss: 11.0223\n",
      "Epoch 457/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0456 - val_loss: 11.1050\n",
      "Epoch 458/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9702 - val_loss: 10.8996\n",
      "Epoch 459/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9051 - val_loss: 11.5067\n",
      "Epoch 460/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.2580 - val_loss: 11.2906\n",
      "Epoch 461/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1174 - val_loss: 12.7745\n",
      "Epoch 462/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.5288 - val_loss: 12.3119\n",
      "Epoch 463/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.4405 - val_loss: 11.3939\n",
      "Epoch 464/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8290 - val_loss: 11.0046\n",
      "Epoch 465/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9640 - val_loss: 11.3204\n",
      "Epoch 466/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0175 - val_loss: 10.8113\n",
      "Epoch 467/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.1604 - val_loss: 10.9478\n",
      "Epoch 468/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0421 - val_loss: 12.1042\n",
      "Epoch 469/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 9.5638 - val_loss: 11.2636\n",
      "Epoch 470/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.9775 - val_loss: 11.0030\n",
      "Epoch 471/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2928 - val_loss: 11.5716\n",
      "Epoch 472/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.3551 - val_loss: 11.3705\n",
      "Epoch 473/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.7625 - val_loss: 12.3799\n",
      "Epoch 474/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.2483 - val_loss: 13.1563\n",
      "Epoch 475/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.8572 - val_loss: 11.4907\n",
      "Epoch 476/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.0223 - val_loss: 12.2302\n",
      "Epoch 477/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.0765 - val_loss: 11.7403\n",
      "Epoch 478/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.0664 - val_loss: 11.3433\n",
      "Epoch 479/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1357 - val_loss: 11.2305\n",
      "Epoch 480/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.4570 - val_loss: 10.6122\n",
      "Epoch 481/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9917 - val_loss: 11.6497\n",
      "Epoch 482/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1376 - val_loss: 11.1426\n",
      "Epoch 483/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9811 - val_loss: 10.9205\n",
      "Epoch 484/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9390 - val_loss: 12.0817\n",
      "Epoch 485/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.2273 - val_loss: 11.5269\n",
      "Epoch 486/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.0673 - val_loss: 12.2387\n",
      "Epoch 487/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.3721 - val_loss: 15.0995\n",
      "Epoch 488/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.0558 - val_loss: 11.8485\n",
      "Epoch 489/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.6616 - val_loss: 11.6682\n",
      "Epoch 490/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.3135 - val_loss: 13.2785\n",
      "Epoch 491/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.4641 - val_loss: 11.0239\n",
      "Epoch 492/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.9820 - val_loss: 13.2576\n",
      "Epoch 493/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.1169 - val_loss: 11.6898\n",
      "Epoch 494/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.5718 - val_loss: 12.0106\n",
      "Epoch 495/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.3419 - val_loss: 12.2898\n",
      "Epoch 496/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.1774 - val_loss: 11.1110\n",
      "Epoch 497/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1622 - val_loss: 11.0317\n",
      "Epoch 498/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.3038 - val_loss: 13.2356\n",
      "Epoch 499/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.3939 - val_loss: 10.9338\n",
      "Epoch 500/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.7853 - val_loss: 11.3206\n",
      "Epoch 501/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.4381 - val_loss: 11.5833\n",
      "Epoch 502/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.5029 - val_loss: 12.3212\n",
      "Epoch 503/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.4527 - val_loss: 10.9079\n",
      "Epoch 504/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.3392 - val_loss: 11.7270\n",
      "Epoch 505/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.0549 - val_loss: 10.7391\n",
      "Epoch 506/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.2662 - val_loss: 13.0866\n",
      "Epoch 507/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.3877 - val_loss: 11.8629\n",
      "Epoch 508/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 9.1379 - val_loss: 11.1879\n",
      "Epoch 509/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0624 - val_loss: 10.9799\n",
      "Epoch 510/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9730 - val_loss: 12.2713\n",
      "Epoch 511/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.2044 - val_loss: 12.9082\n",
      "Epoch 512/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.0785 - val_loss: 10.6716\n",
      "Epoch 513/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.1961 - val_loss: 11.1571\n",
      "Epoch 514/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0809 - val_loss: 10.7521\n",
      "Epoch 515/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9694 - val_loss: 12.0010\n",
      "Epoch 516/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.2323 - val_loss: 10.9697\n",
      "Epoch 517/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.8449 - val_loss: 10.7050\n",
      "Epoch 518/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0855 - val_loss: 11.6523\n",
      "Epoch 519/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8667 - val_loss: 11.5713\n",
      "Epoch 520/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1818 - val_loss: 10.9032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 521/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.0702 - val_loss: 10.7934\n",
      "Epoch 522/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.3541 - val_loss: 10.9796\n",
      "Epoch 523/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.6046 - val_loss: 11.1049\n",
      "Epoch 524/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.2992 - val_loss: 10.6976\n",
      "Epoch 525/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.3867 - val_loss: 12.9563\n",
      "Epoch 526/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.1899 - val_loss: 11.8639\n",
      "Epoch 527/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1412 - val_loss: 11.3826\n",
      "Epoch 528/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.5342 - val_loss: 12.4819\n",
      "Epoch 529/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.3582 - val_loss: 11.0430\n",
      "Epoch 530/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9045 - val_loss: 11.9776\n",
      "Epoch 531/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.3648 - val_loss: 10.8449\n",
      "Epoch 532/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.0850 - val_loss: 10.6641\n",
      "Epoch 533/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.9561 - val_loss: 11.5260\n",
      "Epoch 534/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.7757 - val_loss: 12.1291\n",
      "Epoch 535/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.4575 - val_loss: 11.1614\n",
      "Epoch 536/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0238 - val_loss: 10.6779\n",
      "Epoch 537/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8684 - val_loss: 11.2004\n",
      "Epoch 538/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1803 - val_loss: 12.8981\n",
      "Epoch 539/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1697 - val_loss: 10.8783\n",
      "Epoch 540/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0359 - val_loss: 12.2357\n",
      "Epoch 541/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.9205 - val_loss: 11.3458\n",
      "Epoch 542/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1194 - val_loss: 10.9546\n",
      "Epoch 543/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0337 - val_loss: 11.0007\n",
      "Epoch 544/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 9.4832 - val_loss: 12.0772\n",
      "Epoch 545/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 9.1784 - val_loss: 11.7541\n",
      "Epoch 546/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 9.0515 - val_loss: 10.7484\n",
      "Epoch 547/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.8223 - val_loss: 10.8078\n",
      "Epoch 548/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.9291 - val_loss: 11.9574\n",
      "Epoch 549/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 9.0167 - val_loss: 12.7861\n",
      "Epoch 550/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.1984 - val_loss: 11.3288\n",
      "Epoch 551/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 9.0734 - val_loss: 10.9316\n",
      "Epoch 552/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.3203 - val_loss: 11.2765\n",
      "Epoch 553/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8398 - val_loss: 11.1254\n",
      "Epoch 554/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.1662 - val_loss: 10.8858\n",
      "Epoch 555/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0896 - val_loss: 11.1162\n",
      "Epoch 556/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.5759 - val_loss: 10.7690\n",
      "Epoch 557/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9017 - val_loss: 11.0877\n",
      "Epoch 558/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.1778 - val_loss: 11.2612\n",
      "Epoch 559/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.5289 - val_loss: 11.9670\n",
      "Epoch 560/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0545 - val_loss: 11.1020\n",
      "Epoch 561/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.3411 - val_loss: 14.6603\n",
      "Epoch 562/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.3165 - val_loss: 11.3783\n",
      "Epoch 563/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0196 - val_loss: 11.2490\n",
      "Epoch 564/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.0205 - val_loss: 11.6745\n",
      "Epoch 565/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.3102 - val_loss: 11.5850\n",
      "Epoch 566/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.7197 - val_loss: 11.2444\n",
      "Epoch 567/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.9545 - val_loss: 11.6081\n",
      "Epoch 568/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0477 - val_loss: 15.1505\n",
      "Epoch 569/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9104 - val_loss: 11.0497\n",
      "Epoch 570/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0307 - val_loss: 11.1347\n",
      "Epoch 571/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.3685 - val_loss: 11.8661\n",
      "Epoch 572/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8096 - val_loss: 10.9131\n",
      "Epoch 573/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7637 - val_loss: 12.4798\n",
      "Epoch 574/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.3814 - val_loss: 11.7959\n",
      "Epoch 575/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.8200 - val_loss: 10.5599\n",
      "Epoch 576/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2447 - val_loss: 10.5994\n",
      "Epoch 577/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.8760 - val_loss: 11.4547\n",
      "Epoch 578/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.5604 - val_loss: 11.2613\n",
      "Epoch 579/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.1299 - val_loss: 10.8129\n",
      "Epoch 580/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8901 - val_loss: 11.0182\n",
      "Epoch 581/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1428 - val_loss: 10.7156\n",
      "Epoch 582/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0098 - val_loss: 11.3820\n",
      "Epoch 583/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.0134 - val_loss: 10.7528\n",
      "Epoch 584/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1956 - val_loss: 11.1098\n",
      "Epoch 585/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7944 - val_loss: 10.7225\n",
      "Epoch 586/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.5421 - val_loss: 12.0242\n",
      "Epoch 587/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.1014 - val_loss: 12.5249\n",
      "Epoch 588/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.7477 - val_loss: 11.5030\n",
      "Epoch 589/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.8963 - val_loss: 10.6072\n",
      "Epoch 590/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.2894 - val_loss: 11.3183\n",
      "Epoch 591/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.0409 - val_loss: 11.6453\n",
      "Epoch 592/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0276 - val_loss: 10.7434\n",
      "Epoch 593/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.4432 - val_loss: 10.9404\n",
      "Epoch 594/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.8042 - val_loss: 11.6176\n",
      "Epoch 595/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8031 - val_loss: 11.9064\n",
      "Epoch 596/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.8039 - val_loss: 13.1555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 597/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0218 - val_loss: 11.1761\n",
      "Epoch 598/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1889 - val_loss: 10.8229\n",
      "Epoch 599/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.7417 - val_loss: 11.5018\n",
      "Epoch 600/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.6721 - val_loss: 11.8134\n",
      "Epoch 601/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1896 - val_loss: 10.9195\n",
      "Epoch 602/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9137 - val_loss: 10.6236\n",
      "Epoch 603/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.3736 - val_loss: 10.8035\n",
      "Epoch 604/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1113 - val_loss: 11.3341\n",
      "Epoch 605/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1665 - val_loss: 11.7661\n",
      "Epoch 606/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.9804 - val_loss: 11.5141\n",
      "Epoch 607/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0138 - val_loss: 12.4140\n",
      "Epoch 608/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9227 - val_loss: 10.9941\n",
      "Epoch 609/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.8586 - val_loss: 10.8792\n",
      "Epoch 610/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9643 - val_loss: 10.9264\n",
      "Epoch 611/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1195 - val_loss: 10.5962\n",
      "Epoch 612/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1649 - val_loss: 10.8899\n",
      "Epoch 613/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7989 - val_loss: 11.3157\n",
      "Epoch 614/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.0523 - val_loss: 11.2931\n",
      "Epoch 615/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1919 - val_loss: 10.6523\n",
      "Epoch 616/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9767 - val_loss: 11.7304\n",
      "Epoch 617/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.0510 - val_loss: 11.0255\n",
      "Epoch 618/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8431 - val_loss: 10.9082\n",
      "Epoch 619/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.7912 - val_loss: 11.5252\n",
      "Epoch 620/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8460 - val_loss: 10.7998\n",
      "Epoch 621/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1475 - val_loss: 11.3782\n",
      "Epoch 622/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.0587 - val_loss: 11.3718\n",
      "Epoch 623/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.2708 - val_loss: 11.0693\n",
      "Epoch 624/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1764 - val_loss: 11.5619\n",
      "Epoch 625/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.3884 - val_loss: 11.2303\n",
      "Epoch 626/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.4426 - val_loss: 15.5521\n",
      "Epoch 627/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 10.6276 - val_loss: 12.0905\n",
      "Epoch 628/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.6117 - val_loss: 10.8303\n",
      "Epoch 629/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0291 - val_loss: 12.0354\n",
      "Epoch 630/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.9522 - val_loss: 11.2314\n",
      "Epoch 631/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.0796 - val_loss: 10.8182\n",
      "Epoch 632/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.9106 - val_loss: 10.6931\n",
      "Epoch 633/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.9593 - val_loss: 11.2272\n",
      "Epoch 634/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.7663 - val_loss: 10.7692\n",
      "Epoch 635/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9772 - val_loss: 12.9407\n",
      "Epoch 636/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.1059 - val_loss: 11.4714\n",
      "Epoch 637/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.9302 - val_loss: 10.5196\n",
      "Epoch 638/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.8334 - val_loss: 11.9145\n",
      "Epoch 639/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.1060 - val_loss: 11.0190\n",
      "Epoch 640/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9576 - val_loss: 10.9398\n",
      "Epoch 641/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8398 - val_loss: 12.4108\n",
      "Epoch 642/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.4788 - val_loss: 12.6940\n",
      "Epoch 643/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.2485 - val_loss: 11.4920\n",
      "Epoch 644/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.2208 - val_loss: 11.6476\n",
      "Epoch 645/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.4641 - val_loss: 10.9046\n",
      "Epoch 646/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.3846 - val_loss: 11.0604\n",
      "Epoch 647/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.2224 - val_loss: 10.9167\n",
      "Epoch 648/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1416 - val_loss: 11.0012\n",
      "Epoch 649/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.2285 - val_loss: 11.1036\n",
      "Epoch 650/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.1936 - val_loss: 12.1275\n",
      "Epoch 651/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2875 - val_loss: 10.6965\n",
      "Epoch 652/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.3796 - val_loss: 10.8525\n",
      "Epoch 653/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.7399 - val_loss: 10.6930\n",
      "Epoch 654/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.5634 - val_loss: 11.2161\n",
      "Epoch 655/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.6989 - val_loss: 12.1433\n",
      "Epoch 656/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.6326 - val_loss: 10.7626\n",
      "Epoch 657/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2011 - val_loss: 10.7702\n",
      "Epoch 658/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.9389 - val_loss: 11.2839\n",
      "Epoch 659/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0442 - val_loss: 11.3854\n",
      "Epoch 660/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.7597 - val_loss: 11.4048\n",
      "Epoch 661/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.4024 - val_loss: 12.1996\n",
      "Epoch 662/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0423 - val_loss: 11.0684\n",
      "Epoch 663/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.3289 - val_loss: 14.1710\n",
      "Epoch 664/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.1058 - val_loss: 11.6901\n",
      "Epoch 665/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.8290 - val_loss: 10.5322\n",
      "Epoch 666/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8888 - val_loss: 11.3449\n",
      "Epoch 667/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.8788 - val_loss: 11.1705\n",
      "Epoch 668/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.7240 - val_loss: 13.6532\n",
      "Epoch 669/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.4038 - val_loss: 11.0968\n",
      "Epoch 670/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9964 - val_loss: 12.1395\n",
      "Epoch 671/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1404 - val_loss: 10.9763\n",
      "Epoch 672/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.6492 - val_loss: 11.3480\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 673/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0334 - val_loss: 10.7736\n",
      "Epoch 674/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0537 - val_loss: 11.0144\n",
      "Epoch 675/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.9133 - val_loss: 11.2568\n",
      "Epoch 676/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.3801 - val_loss: 11.3767\n",
      "Epoch 677/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.3382 - val_loss: 10.8689\n",
      "Epoch 678/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1795 - val_loss: 11.1917\n",
      "Epoch 679/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.1103 - val_loss: 11.3584\n",
      "Epoch 680/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.1646 - val_loss: 11.4151\n",
      "Epoch 681/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9090 - val_loss: 10.8473\n",
      "Epoch 682/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.0537 - val_loss: 12.0076\n",
      "Epoch 683/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.4453 - val_loss: 11.0007\n",
      "Epoch 684/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0750 - val_loss: 11.1975\n",
      "Epoch 685/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9681 - val_loss: 10.7690\n",
      "Epoch 686/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.0479 - val_loss: 10.7615\n",
      "Epoch 687/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.2673 - val_loss: 10.9183\n",
      "Epoch 688/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.9003 - val_loss: 11.8451\n",
      "Epoch 689/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.3102 - val_loss: 11.8342\n",
      "Epoch 690/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9099 - val_loss: 10.7878\n",
      "Epoch 691/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.1803 - val_loss: 11.2948\n",
      "Epoch 692/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.9221 - val_loss: 10.5755\n",
      "Epoch 693/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0462 - val_loss: 10.5485\n",
      "Epoch 694/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9905 - val_loss: 10.6370\n",
      "Epoch 695/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.3585 - val_loss: 12.1056\n",
      "Epoch 696/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.9087 - val_loss: 11.2402\n",
      "Epoch 697/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.1420 - val_loss: 11.4835\n",
      "Epoch 698/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.4525 - val_loss: 11.2081\n",
      "Epoch 699/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.6931 - val_loss: 11.0009\n",
      "Epoch 700/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.0602 - val_loss: 11.4727\n",
      "Epoch 701/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8880 - val_loss: 10.7687\n",
      "Epoch 702/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2188 - val_loss: 11.1395\n",
      "Epoch 703/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.8285 - val_loss: 10.6915\n",
      "Epoch 704/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.3110 - val_loss: 14.7446\n",
      "Epoch 705/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.1134 - val_loss: 11.3429\n",
      "Epoch 706/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0646 - val_loss: 11.1452\n",
      "Epoch 707/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9532 - val_loss: 10.9536\n",
      "Epoch 708/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.7693 - val_loss: 12.5506\n",
      "Epoch 709/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.9733 - val_loss: 10.4554\n",
      "Epoch 710/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.8380 - val_loss: 10.7205\n",
      "Epoch 711/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.9099 - val_loss: 12.0831\n",
      "Epoch 712/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 9.2837 - val_loss: 11.7502\n",
      "Epoch 713/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 9.2615 - val_loss: 11.3210\n",
      "Epoch 714/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 9.2620 - val_loss: 12.2691\n",
      "Epoch 715/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1496 - val_loss: 11.2549\n",
      "Epoch 716/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.2516 - val_loss: 11.4181\n",
      "Epoch 717/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 9.0654 - val_loss: 11.2477\n",
      "Epoch 718/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.9711 - val_loss: 10.4596\n",
      "Epoch 719/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.5270 - val_loss: 10.9125\n",
      "Epoch 720/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.1619 - val_loss: 13.1305\n",
      "Epoch 721/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 8.9192 - val_loss: 10.5251\n",
      "Epoch 722/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.8189 - val_loss: 10.8079\n",
      "Epoch 723/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8436 - val_loss: 12.5499\n",
      "Epoch 724/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0750 - val_loss: 10.7262\n",
      "Epoch 725/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.5209 - val_loss: 11.9955\n",
      "Epoch 726/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9170 - val_loss: 10.9793\n",
      "Epoch 727/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0461 - val_loss: 11.8042\n",
      "Epoch 728/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9392 - val_loss: 11.3811\n",
      "Epoch 729/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8098 - val_loss: 11.1001\n",
      "Epoch 730/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.1838 - val_loss: 11.5016\n",
      "Epoch 731/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.0033 - val_loss: 11.0106\n",
      "Epoch 732/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7067 - val_loss: 10.4623\n",
      "Epoch 733/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.8653 - val_loss: 10.9932\n",
      "Epoch 734/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.8988 - val_loss: 11.3664\n",
      "Epoch 735/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.3427 - val_loss: 11.2063\n",
      "Epoch 736/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2475 - val_loss: 10.8178\n",
      "Epoch 737/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8180 - val_loss: 12.3478\n",
      "Epoch 738/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1954 - val_loss: 10.7272\n",
      "Epoch 739/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.9289 - val_loss: 11.1199\n",
      "Epoch 740/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2987 - val_loss: 12.8041\n",
      "Epoch 741/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.5269 - val_loss: 11.7949\n",
      "Epoch 742/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.1928 - val_loss: 11.7542\n",
      "Epoch 743/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.9900 - val_loss: 10.7188\n",
      "Epoch 744/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1282 - val_loss: 10.9284\n",
      "Epoch 745/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.1251 - val_loss: 11.9916\n",
      "Epoch 746/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0213 - val_loss: 10.9947\n",
      "Epoch 747/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9292 - val_loss: 10.6361\n",
      "Epoch 748/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.8464 - val_loss: 11.2215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 749/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9110 - val_loss: 11.3645\n",
      "Epoch 750/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7052 - val_loss: 11.3074\n",
      "Epoch 751/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0927 - val_loss: 11.3592\n",
      "Epoch 752/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.4836 - val_loss: 11.4185\n",
      "Epoch 753/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8665 - val_loss: 10.9181\n",
      "Epoch 754/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9833 - val_loss: 10.5688\n",
      "Epoch 755/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0309 - val_loss: 11.1466\n",
      "Epoch 756/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.4727 - val_loss: 11.7891\n",
      "Epoch 757/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.4166 - val_loss: 11.7515\n",
      "Epoch 758/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6380 - val_loss: 12.1783\n",
      "Epoch 759/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9498 - val_loss: 10.7850\n",
      "Epoch 760/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2701 - val_loss: 11.0889\n",
      "Epoch 761/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.6955 - val_loss: 10.5165\n",
      "Epoch 762/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5986 - val_loss: 11.4669\n",
      "Epoch 763/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.8476 - val_loss: 10.5163\n",
      "Epoch 764/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0790 - val_loss: 11.3019\n",
      "Epoch 765/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.3716 - val_loss: 10.5037\n",
      "Epoch 766/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9655 - val_loss: 10.5700\n",
      "Epoch 767/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9773 - val_loss: 11.0226\n",
      "Epoch 768/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.4061 - val_loss: 11.0724\n",
      "Epoch 769/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0594 - val_loss: 11.7952\n",
      "Epoch 770/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.2235 - val_loss: 10.4853\n",
      "Epoch 771/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9668 - val_loss: 10.7456\n",
      "Epoch 772/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8681 - val_loss: 10.8979\n",
      "Epoch 773/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.1988 - val_loss: 10.3505\n",
      "Epoch 774/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0073 - val_loss: 11.0334\n",
      "Epoch 775/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7269 - val_loss: 10.5302\n",
      "Epoch 776/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.9185 - val_loss: 10.6799\n",
      "Epoch 777/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.2853 - val_loss: 12.3451\n",
      "Epoch 778/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 8.7712 - val_loss: 10.7043\n",
      "Epoch 779/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 9.2055 - val_loss: 12.6491\n",
      "Epoch 780/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2960 - val_loss: 10.9092\n",
      "Epoch 781/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9110 - val_loss: 10.9282\n",
      "Epoch 782/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.3458 - val_loss: 11.2632\n",
      "Epoch 783/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.2216 - val_loss: 10.6597\n",
      "Epoch 784/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1085 - val_loss: 11.9517\n",
      "Epoch 785/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1789 - val_loss: 11.4967\n",
      "Epoch 786/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0496 - val_loss: 11.3351\n",
      "Epoch 787/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8939 - val_loss: 10.7750\n",
      "Epoch 788/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9500 - val_loss: 10.6719\n",
      "Epoch 789/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9163 - val_loss: 10.7635\n",
      "Epoch 790/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8269 - val_loss: 10.7656\n",
      "Epoch 791/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8510 - val_loss: 10.5663\n",
      "Epoch 792/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8532 - val_loss: 11.4404\n",
      "Epoch 793/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.9592 - val_loss: 11.7188\n",
      "Epoch 794/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.5202 - val_loss: 10.3781\n",
      "Epoch 795/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4973 - val_loss: 13.4545\n",
      "Epoch 796/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.2101 - val_loss: 10.2891\n",
      "Epoch 797/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2499 - val_loss: 11.9747\n",
      "Epoch 798/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.0122 - val_loss: 11.6342\n",
      "Epoch 799/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.1377 - val_loss: 11.4307\n",
      "Epoch 800/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9890 - val_loss: 10.2375\n",
      "Epoch 801/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9023 - val_loss: 11.2098\n",
      "Epoch 802/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 8.881 - 0s 92us/step - loss: 9.2507 - val_loss: 11.0135\n",
      "Epoch 803/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.8695 - val_loss: 10.5676\n",
      "Epoch 804/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.5259 - val_loss: 12.1119\n",
      "Epoch 805/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1565 - val_loss: 11.2612\n",
      "Epoch 806/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.3156 - val_loss: 10.9724\n",
      "Epoch 807/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.9330 - val_loss: 11.0517\n",
      "Epoch 808/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.2247 - val_loss: 11.7933\n",
      "Epoch 809/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.8869 - val_loss: 11.1665\n",
      "Epoch 810/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.8238 - val_loss: 10.7693\n",
      "Epoch 811/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.6902 - val_loss: 11.5245\n",
      "Epoch 812/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 9.2280 - val_loss: 12.7627\n",
      "Epoch 813/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.4434 - val_loss: 10.5925\n",
      "Epoch 814/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.2686 - val_loss: 10.7128\n",
      "Epoch 815/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 9.5323 - val_loss: 11.5158\n",
      "Epoch 816/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.3932 - val_loss: 12.1187\n",
      "Epoch 817/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7456 - val_loss: 10.7743\n",
      "Epoch 818/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.9627 - val_loss: 12.0904\n",
      "Epoch 819/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.9152 - val_loss: 11.1145\n",
      "Epoch 820/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.0256 - val_loss: 10.8821\n",
      "Epoch 821/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9736 - val_loss: 11.0984\n",
      "Epoch 822/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.9827 - val_loss: 10.6009\n",
      "Epoch 823/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.8961 - val_loss: 10.8132\n",
      "Epoch 824/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0249 - val_loss: 10.3088\n",
      "Epoch 825/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.1909 - val_loss: 11.0475\n",
      "Epoch 826/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.8783 - val_loss: 11.1297\n",
      "Epoch 827/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.1173 - val_loss: 11.1650\n",
      "Epoch 828/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.1128 - val_loss: 10.2411\n",
      "Epoch 829/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 9.1868 - val_loss: 10.9423\n",
      "Epoch 830/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.5873 - val_loss: 10.5459\n",
      "Epoch 831/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.4695 - val_loss: 11.6956\n",
      "Epoch 832/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.3462 - val_loss: 10.7265\n",
      "Epoch 833/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8190 - val_loss: 12.1769\n",
      "Epoch 834/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.4863 - val_loss: 10.8892\n",
      "Epoch 835/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.4063 - val_loss: 10.9285\n",
      "Epoch 836/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.8898 - val_loss: 10.5615\n",
      "Epoch 837/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6801 - val_loss: 10.9335\n",
      "Epoch 838/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.8053 - val_loss: 10.5880\n",
      "Epoch 839/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.7441 - val_loss: 11.8839\n",
      "Epoch 840/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.2409 - val_loss: 10.2450\n",
      "Epoch 841/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.2513 - val_loss: 11.1883\n",
      "Epoch 842/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6264 - val_loss: 12.3544\n",
      "Epoch 843/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9074 - val_loss: 10.4425\n",
      "Epoch 844/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.6606 - val_loss: 10.9930\n",
      "Epoch 845/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9143 - val_loss: 10.6000\n",
      "Epoch 846/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9956 - val_loss: 11.0812\n",
      "Epoch 847/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.7913 - val_loss: 11.1586\n",
      "Epoch 848/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7045 - val_loss: 13.3495\n",
      "Epoch 849/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.7932 - val_loss: 10.3047\n",
      "Epoch 850/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7324 - val_loss: 11.9544\n",
      "Epoch 851/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.9627 - val_loss: 12.1047\n",
      "Epoch 852/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.2403 - val_loss: 13.8375\n",
      "Epoch 853/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.0256 - val_loss: 10.5662\n",
      "Epoch 854/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6425 - val_loss: 10.3677\n",
      "Epoch 855/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.8660 - val_loss: 10.8347\n",
      "Epoch 856/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.5063 - val_loss: 10.9251\n",
      "Epoch 857/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.7849 - val_loss: 10.5912\n",
      "Epoch 858/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7627 - val_loss: 12.3391\n",
      "Epoch 859/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9461 - val_loss: 12.3165\n",
      "Epoch 860/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.8145 - val_loss: 12.6070\n",
      "Epoch 861/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.8747 - val_loss: 10.2519\n",
      "Epoch 862/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6790 - val_loss: 10.5724\n",
      "Epoch 863/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.0968 - val_loss: 11.5732\n",
      "Epoch 864/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.2482 - val_loss: 12.1170\n",
      "Epoch 865/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0565 - val_loss: 11.1836\n",
      "Epoch 866/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.8859 - val_loss: 10.3502\n",
      "Epoch 867/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.1353 - val_loss: 12.6865\n",
      "Epoch 868/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.4501 - val_loss: 11.6851\n",
      "Epoch 869/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8985 - val_loss: 10.6408\n",
      "Epoch 870/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8555 - val_loss: 10.3215\n",
      "Epoch 871/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9094 - val_loss: 10.5332\n",
      "Epoch 872/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.2292 - val_loss: 11.0292\n",
      "Epoch 873/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.0879 - val_loss: 10.4103\n",
      "Epoch 874/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.1963 - val_loss: 10.8942\n",
      "Epoch 875/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 8.8675 - val_loss: 10.5906\n",
      "Epoch 876/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.8609 - val_loss: 13.0426\n",
      "Epoch 877/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.5941 - val_loss: 10.3417\n",
      "Epoch 878/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0689 - val_loss: 10.2743\n",
      "Epoch 879/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.5843 - val_loss: 10.8527\n",
      "Epoch 880/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 9.0040 - val_loss: 11.9573\n",
      "Epoch 881/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 9.0953 - val_loss: 11.0244\n",
      "Epoch 882/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.7936 - val_loss: 10.7235\n",
      "Epoch 883/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.8846 - val_loss: 10.6108\n",
      "Epoch 884/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.3246 - val_loss: 11.2660\n",
      "Epoch 885/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7214 - val_loss: 10.8089\n",
      "Epoch 886/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9255 - val_loss: 10.6389\n",
      "Epoch 887/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0750 - val_loss: 10.6881\n",
      "Epoch 888/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.0957 - val_loss: 10.9932\n",
      "Epoch 889/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.6859 - val_loss: 12.7435\n",
      "Epoch 890/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.5756 - val_loss: 11.0167\n",
      "Epoch 891/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.0253 - val_loss: 10.4669\n",
      "Epoch 892/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.7977 - val_loss: 12.4699\n",
      "Epoch 893/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.2524 - val_loss: 13.1956\n",
      "Epoch 894/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8366 - val_loss: 10.5493\n",
      "Epoch 895/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6738 - val_loss: 10.3160\n",
      "Epoch 896/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8825 - val_loss: 10.4116\n",
      "Epoch 897/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0493 - val_loss: 10.2874\n",
      "Epoch 898/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5032 - val_loss: 10.5429\n",
      "Epoch 899/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.6805 - val_loss: 10.9375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 900/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.8095 - val_loss: 10.5084\n",
      "Epoch 901/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.0477 - val_loss: 12.6898\n",
      "Epoch 902/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0080 - val_loss: 10.4480\n",
      "Epoch 903/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.9375 - val_loss: 10.3488\n",
      "Epoch 904/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.7186 - val_loss: 10.6517\n",
      "Epoch 905/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.4470 - val_loss: 11.4753\n",
      "Epoch 906/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.2210 - val_loss: 10.0972\n",
      "Epoch 907/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9275 - val_loss: 10.4636\n",
      "Epoch 908/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7002 - val_loss: 10.3119\n",
      "Epoch 909/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.6541 - val_loss: 11.1375\n",
      "Epoch 910/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9231 - val_loss: 10.0018\n",
      "Epoch 911/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.9594 - val_loss: 11.4254\n",
      "Epoch 912/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.2483 - val_loss: 10.2403\n",
      "Epoch 913/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2765 - val_loss: 10.4102\n",
      "Epoch 914/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1204 - val_loss: 10.2818\n",
      "Epoch 915/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7065 - val_loss: 10.9744\n",
      "Epoch 916/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9848 - val_loss: 11.6433\n",
      "Epoch 917/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1799 - val_loss: 11.0197\n",
      "Epoch 918/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.7112 - val_loss: 10.7912\n",
      "Epoch 919/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.9583 - val_loss: 11.1371\n",
      "Epoch 920/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1374 - val_loss: 10.5910\n",
      "Epoch 921/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6455 - val_loss: 10.5383\n",
      "Epoch 922/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6186 - val_loss: 10.3592\n",
      "Epoch 923/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.6945 - val_loss: 10.8470\n",
      "Epoch 924/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0405 - val_loss: 10.0650\n",
      "Epoch 925/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.3296 - val_loss: 10.4085\n",
      "Epoch 926/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.9852 - val_loss: 10.2564\n",
      "Epoch 927/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8632 - val_loss: 12.5439\n",
      "Epoch 928/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.4523 - val_loss: 10.2153\n",
      "Epoch 929/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6892 - val_loss: 10.4902\n",
      "Epoch 930/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5096 - val_loss: 9.8415\n",
      "Epoch 931/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.6378 - val_loss: 11.5737\n",
      "Epoch 932/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8337 - val_loss: 11.0331\n",
      "Epoch 933/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.1612 - val_loss: 10.0887\n",
      "Epoch 934/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.8778 - val_loss: 9.8828\n",
      "Epoch 935/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9731 - val_loss: 10.7430\n",
      "Epoch 936/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7555 - val_loss: 10.9502\n",
      "Epoch 937/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.7656 - val_loss: 9.8444\n",
      "Epoch 938/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7159 - val_loss: 10.5659\n",
      "Epoch 939/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2015 - val_loss: 10.3162\n",
      "Epoch 940/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.9634 - val_loss: 10.8408\n",
      "Epoch 941/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.5635 - val_loss: 9.9506\n",
      "Epoch 942/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7529 - val_loss: 10.1518\n",
      "Epoch 943/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8775 - val_loss: 10.1328\n",
      "Epoch 944/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.2423 - val_loss: 11.1744\n",
      "Epoch 945/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.0608 - val_loss: 10.0770\n",
      "Epoch 946/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1656 - val_loss: 10.2907\n",
      "Epoch 947/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.3201 - val_loss: 13.6751\n",
      "Epoch 948/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9617 - val_loss: 10.2786\n",
      "Epoch 949/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.8441 - val_loss: 9.8980\n",
      "Epoch 950/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.3065 - val_loss: 10.6108\n",
      "Epoch 951/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8945 - val_loss: 10.5800\n",
      "Epoch 952/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8860 - val_loss: 12.0302\n",
      "Epoch 953/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.1170 - val_loss: 10.1227\n",
      "Epoch 954/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.6665 - val_loss: 10.9150\n",
      "Epoch 955/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7930 - val_loss: 10.3543\n",
      "Epoch 956/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.8652 - val_loss: 10.1378\n",
      "Epoch 957/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7418 - val_loss: 11.0302\n",
      "Epoch 958/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.0193 - val_loss: 10.7964\n",
      "Epoch 959/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.2569 - val_loss: 11.0154\n",
      "Epoch 960/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.6644 - val_loss: 10.0940\n",
      "Epoch 961/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.6732 - val_loss: 10.3991\n",
      "Epoch 962/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.2252 - val_loss: 10.2245\n",
      "Epoch 963/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.8837 - val_loss: 10.7691\n",
      "Epoch 964/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.9596 - val_loss: 10.2174\n",
      "Epoch 965/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.7356 - val_loss: 11.1254\n",
      "Epoch 966/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.1026 - val_loss: 10.9541\n",
      "Epoch 967/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.7525 - val_loss: 11.4566\n",
      "Epoch 968/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9289 - val_loss: 10.0871\n",
      "Epoch 969/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.9662 - val_loss: 11.0366\n",
      "Epoch 970/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.7725 - val_loss: 10.2105\n",
      "Epoch 971/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.3429 - val_loss: 10.8374\n",
      "Epoch 972/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.0662 - val_loss: 10.7425\n",
      "Epoch 973/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.7578 - val_loss: 10.3648\n",
      "Epoch 974/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4660 - val_loss: 10.9002\n",
      "Epoch 975/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.5364 - val_loss: 10.0851\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 976/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8376 - val_loss: 11.6870\n",
      "Epoch 977/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.4478 - val_loss: 11.5478\n",
      "Epoch 978/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.9876 - val_loss: 9.9819\n",
      "Epoch 979/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9660 - val_loss: 11.0166\n",
      "Epoch 980/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.7270 - val_loss: 10.0814\n",
      "Epoch 981/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.7277 - val_loss: 13.3384\n",
      "Epoch 982/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.8121 - val_loss: 11.3445\n",
      "Epoch 983/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.8993 - val_loss: 13.0884\n",
      "Epoch 984/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.2503 - val_loss: 10.2963\n",
      "Epoch 985/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7767 - val_loss: 10.1864\n",
      "Epoch 986/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0269 - val_loss: 11.1557\n",
      "Epoch 987/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1297 - val_loss: 12.6199\n",
      "Epoch 988/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.6146 - val_loss: 12.1068\n",
      "Epoch 989/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.2828 - val_loss: 10.6447\n",
      "Epoch 990/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8313 - val_loss: 11.1694\n",
      "Epoch 991/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.1843 - val_loss: 11.6952\n",
      "Epoch 992/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.4753 - val_loss: 12.1296\n",
      "Epoch 993/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0238 - val_loss: 9.9418\n",
      "Epoch 994/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.7641 - val_loss: 10.0917\n",
      "Epoch 995/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7180 - val_loss: 10.6975\n",
      "Epoch 996/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1300 - val_loss: 11.3776\n",
      "Epoch 997/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.0085 - val_loss: 11.1223\n",
      "Epoch 998/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.7007 - val_loss: 10.6340\n",
      "Epoch 999/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8862 - val_loss: 10.3530\n",
      "Epoch 1000/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.0061 - val_loss: 10.9169\n",
      "9.445503993899422\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 1.0931299 , -1.585217  , -3.9492984 ,  3.9457076 ,  0.19601813],\n",
       "        [ 0.12917024,  0.35905984,  0.10197406, -0.33409247,  0.24781229],\n",
       "        [ 0.37755013,  0.28027803,  0.08867396,  0.55243546,  0.36083567],\n",
       "        [-0.11255839,  0.0767654 ,  0.06075545, -0.14741232, -0.09606807],\n",
       "        [ 1.0199596 , -0.16196637, -2.5203693 ,  0.45489472,  0.18659346]],\n",
       "       dtype=float32),\n",
       " array([ 2.9997742 , -1.2472988 , -5.1978593 ,  4.852621  ,  0.20463541],\n",
       "       dtype=float32),\n",
       " array([[ 0.9666616 , -1.0472397 , -0.6948292 , -1.3029972 , -1.4338678 ,\n",
       "          0.9804574 , -1.5279957 ,  1.792749  , -1.4773501 ,  1.2949092 ,\n",
       "         -1.4363718 , -1.6399841 ,  1.9651166 ,  1.5586802 ,  1.4115549 ],\n",
       "        [ 0.7631275 , -0.84795517, -1.1737648 , -0.3553791 , -0.7445736 ,\n",
       "          0.36059582, -0.9292283 ,  0.29607624, -1.1318733 ,  0.33572406,\n",
       "         -0.48424637, -0.5592855 ,  0.17047863,  0.6634464 ,  0.6935452 ],\n",
       "        [-1.0797013 ,  0.7789473 ,  0.32452092,  0.7525826 ,  1.2515891 ,\n",
       "         -0.4002018 ,  1.0667975 , -1.1044543 ,  0.8553883 , -0.6755074 ,\n",
       "          0.6145355 ,  1.1622236 , -0.92347544, -1.2650198 , -1.4480749 ],\n",
       "        [ 1.5500246 , -2.0872939 , -1.6116809 , -1.1802857 , -1.6565425 ,\n",
       "          2.0170624 , -1.8101437 ,  1.5675236 , -1.5129107 ,  1.6694757 ,\n",
       "         -1.2935584 , -1.8014466 ,  2.2272694 ,  1.8317101 ,  1.8129452 ],\n",
       "        [-1.0069261 ,  0.98251575,  0.46458837,  0.63350564,  0.7571714 ,\n",
       "         -0.4334968 ,  0.91391796, -1.1302685 ,  0.45068315, -0.8159649 ,\n",
       "          1.0004789 ,  0.6969324 , -0.8243684 , -1.2781734 , -0.68940485]],\n",
       "       dtype=float32),\n",
       " array([ 1.9887121, -2.0147934, -1.8676195, -1.8747067, -2.0289314,\n",
       "         1.8873341, -2.0706043,  2.0487604, -2.0032315,  1.9614927,\n",
       "        -1.4780072, -1.984177 ,  2.0645685,  2.0197296,  2.0245466],\n",
       "       dtype=float32),\n",
       " array([[ 1.4673126],\n",
       "        [-1.5809772],\n",
       "        [-1.0940835],\n",
       "        [-1.1937855],\n",
       "        [-1.6522629],\n",
       "        [ 1.2677456],\n",
       "        [-1.9068565],\n",
       "        [ 1.768646 ],\n",
       "        [-1.5013758],\n",
       "        [ 1.399988 ],\n",
       "        [-1.0175933],\n",
       "        [-1.4880898],\n",
       "        [ 1.8528183],\n",
       "        [ 1.5800604],\n",
       "        [ 1.6319681]], dtype=float32),\n",
       " array([2.2661436], dtype=float32)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_airfoil, history_airfoil, evaluate_airfoil=NN_model_structure_regression_3(X_train_airfoil, X_val_airfoil, Y_train_airfoil, Y_val_airfoil, adam2, 32, 1000)\n",
    "model_airfoil.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_airfoil.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_airfoil_structure3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 121\n",
      "Trainable params: 121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1052 samples, validate on 225 samples\n",
      "Epoch 1/1000\n",
      "1052/1052 [==============================] - 0s 225us/step - loss: 8002.9220 - val_loss: 1023.9490\n",
      "Epoch 2/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 182.1084 - val_loss: 41.2525\n",
      "Epoch 3/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 24.4177 - val_loss: 24.3102\n",
      "Epoch 4/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 19.4333 - val_loss: 23.7156\n",
      "Epoch 5/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.9064 - val_loss: 23.7789\n",
      "Epoch 6/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 18.4629 - val_loss: 23.3404\n",
      "Epoch 7/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 18.2472 - val_loss: 23.3535\n",
      "Epoch 8/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 17.9411 - val_loss: 22.8895\n",
      "Epoch 9/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 17.9329 - val_loss: 22.6163\n",
      "Epoch 10/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.6381 - val_loss: 22.3606\n",
      "Epoch 11/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.5691 - val_loss: 22.2155\n",
      "Epoch 12/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.3901 - val_loss: 22.2324\n",
      "Epoch 13/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 17.2019 - val_loss: 22.3754\n",
      "Epoch 14/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 17.2566 - val_loss: 22.1297\n",
      "Epoch 15/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 17.1833 - val_loss: 22.4653\n",
      "Epoch 16/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 17.2075 - val_loss: 21.2347\n",
      "Epoch 17/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 16.9308 - val_loss: 20.9724\n",
      "Epoch 18/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 16.8457 - val_loss: 21.0994\n",
      "Epoch 19/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 16.7166 - val_loss: 21.3338\n",
      "Epoch 20/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 16.5319 - val_loss: 20.8379\n",
      "Epoch 21/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 16.4869 - val_loss: 20.9142\n",
      "Epoch 22/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 16.4078 - val_loss: 20.1548\n",
      "Epoch 23/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 16.2923 - val_loss: 20.0880\n",
      "Epoch 24/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 16.3634 - val_loss: 19.8434\n",
      "Epoch 25/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 16.3279 - val_loss: 19.7124\n",
      "Epoch 26/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 16.0946 - val_loss: 20.0441\n",
      "Epoch 27/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 15.9595 - val_loss: 20.0166\n",
      "Epoch 28/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 16.0481 - val_loss: 19.3783\n",
      "Epoch 29/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 15.8648 - val_loss: 20.7069\n",
      "Epoch 30/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 16.0150 - val_loss: 19.7160\n",
      "Epoch 31/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 16.2397 - val_loss: 19.5573\n",
      "Epoch 32/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 15.7188 - val_loss: 18.7971\n",
      "Epoch 33/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 15.8266 - val_loss: 19.2717\n",
      "Epoch 34/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 15.4669 - val_loss: 19.4758\n",
      "Epoch 35/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 15.6114 - val_loss: 19.2223\n",
      "Epoch 36/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 15.5911 - val_loss: 19.4015\n",
      "Epoch 37/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 15.2573 - val_loss: 18.3967\n",
      "Epoch 38/1000\n",
      "1052/1052 [==============================] - 0s 117us/step - loss: 15.2738 - val_loss: 18.7902\n",
      "Epoch 39/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 15.2567 - val_loss: 18.7059\n",
      "Epoch 40/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 15.0232 - val_loss: 18.1692\n",
      "Epoch 41/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 15.0927 - val_loss: 18.3142\n",
      "Epoch 42/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 15.0857 - val_loss: 19.2123\n",
      "Epoch 43/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 15.0255 - val_loss: 18.9591\n",
      "Epoch 44/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 15.2640 - val_loss: 17.9706\n",
      "Epoch 45/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 14.9840 - val_loss: 18.0508\n",
      "Epoch 46/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 14.8569 - val_loss: 17.6949\n",
      "Epoch 47/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 15.4331 - val_loss: 17.6951\n",
      "Epoch 48/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 15.0390 - val_loss: 20.9958\n",
      "Epoch 49/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 15.0971 - val_loss: 17.9906\n",
      "Epoch 50/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.7300 - val_loss: 17.8855\n",
      "Epoch 51/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 14.6701 - val_loss: 17.7468\n",
      "Epoch 52/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 14.5856 - val_loss: 17.3439\n",
      "Epoch 53/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 14.5318 - val_loss: 18.0870\n",
      "Epoch 54/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 14.7652 - val_loss: 18.6779\n",
      "Epoch 55/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 14.5101 - val_loss: 17.4645\n",
      "Epoch 56/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 14.4209 - val_loss: 17.9171\n",
      "Epoch 57/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.3044 - val_loss: 17.3134\n",
      "Epoch 58/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 14.4556 - val_loss: 18.1341\n",
      "Epoch 59/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 14.2905 - val_loss: 17.8902\n",
      "Epoch 60/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 14.3096 - val_loss: 18.0043\n",
      "Epoch 61/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 14.2349 - val_loss: 18.7225\n",
      "Epoch 62/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 14.0273 - val_loss: 17.0017\n",
      "Epoch 63/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 14.6583 - val_loss: 17.0133\n",
      "Epoch 64/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 14.2818 - val_loss: 19.1187\n",
      "Epoch 65/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 14.0521 - val_loss: 17.0784\n",
      "Epoch 66/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 14.4591 - val_loss: 20.0338\n",
      "Epoch 67/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 82us/step - loss: 14.3804 - val_loss: 18.0672\n",
      "Epoch 68/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 14.1201 - val_loss: 17.3613\n",
      "Epoch 69/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 14.1783 - val_loss: 16.7310\n",
      "Epoch 70/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 14.0839 - val_loss: 17.7336\n",
      "Epoch 71/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 13.8637 - val_loss: 17.3969\n",
      "Epoch 72/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 14.0784 - val_loss: 16.5746\n",
      "Epoch 73/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 13.6191 - val_loss: 17.1502\n",
      "Epoch 74/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 13.5566 - val_loss: 16.8024\n",
      "Epoch 75/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 13.6440 - val_loss: 18.0250\n",
      "Epoch 76/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 13.8300 - val_loss: 17.3239\n",
      "Epoch 77/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.4392 - val_loss: 16.9268\n",
      "Epoch 78/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 13.6238 - val_loss: 17.7751\n",
      "Epoch 79/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 14.0256 - val_loss: 18.8272\n",
      "Epoch 80/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 13.5976 - val_loss: 16.9011\n",
      "Epoch 81/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 13.8238 - val_loss: 17.5649\n",
      "Epoch 82/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 13.7575 - val_loss: 17.6370\n",
      "Epoch 83/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 13.4291 - val_loss: 17.2368\n",
      "Epoch 84/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 13.3039 - val_loss: 16.1940\n",
      "Epoch 85/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 13.2119 - val_loss: 17.1657\n",
      "Epoch 86/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.0768 - val_loss: 16.1825\n",
      "Epoch 87/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.1262 - val_loss: 17.0688\n",
      "Epoch 88/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 13.0209 - val_loss: 16.2459\n",
      "Epoch 89/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 13.0222 - val_loss: 17.0145\n",
      "Epoch 90/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 13.1808 - val_loss: 17.0641\n",
      "Epoch 91/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 12.8170 - val_loss: 16.8186\n",
      "Epoch 92/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 12.7207 - val_loss: 16.1901\n",
      "Epoch 93/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 13.5427 - val_loss: 16.5515\n",
      "Epoch 94/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 13.2883 - val_loss: 15.6242\n",
      "Epoch 95/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 12.6861 - val_loss: 15.7355\n",
      "Epoch 96/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 12.4761 - val_loss: 16.3910\n",
      "Epoch 97/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 12.2341 - val_loss: 15.7336\n",
      "Epoch 98/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.1909 - val_loss: 14.8260\n",
      "Epoch 99/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 12.4194 - val_loss: 14.6933\n",
      "Epoch 100/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 11.9052 - val_loss: 15.4421\n",
      "Epoch 101/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 12.2794 - val_loss: 16.2438\n",
      "Epoch 102/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.7198 - val_loss: 15.7655\n",
      "Epoch 103/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.6391 - val_loss: 14.8019\n",
      "Epoch 104/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.5670 - val_loss: 14.0572\n",
      "Epoch 105/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.4240 - val_loss: 15.2346\n",
      "Epoch 106/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.3295 - val_loss: 14.8396\n",
      "Epoch 107/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.1293 - val_loss: 14.1821\n",
      "Epoch 108/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.9914 - val_loss: 14.4348\n",
      "Epoch 109/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 11.4503 - val_loss: 13.5401\n",
      "Epoch 110/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.9354 - val_loss: 14.8017\n",
      "Epoch 111/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.8288 - val_loss: 14.6552\n",
      "Epoch 112/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 10.9772 - val_loss: 13.1396\n",
      "Epoch 113/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.2888 - val_loss: 13.6686\n",
      "Epoch 114/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 10.4924 - val_loss: 13.1521\n",
      "Epoch 115/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 10.3386 - val_loss: 12.9481\n",
      "Epoch 116/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 10.0294 - val_loss: 12.0386\n",
      "Epoch 117/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.8161 - val_loss: 12.4288\n",
      "Epoch 118/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 9.7213 - val_loss: 12.3545\n",
      "Epoch 119/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 9.7838 - val_loss: 12.3033\n",
      "Epoch 120/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.6021 - val_loss: 12.8802\n",
      "Epoch 121/1000\n",
      "1052/1052 [==============================] - 0s 129us/step - loss: 9.7865 - val_loss: 12.3139\n",
      "Epoch 122/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 9.8783 - val_loss: 12.1725\n",
      "Epoch 123/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.7679 - val_loss: 12.2281\n",
      "Epoch 124/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.6485 - val_loss: 11.4475\n",
      "Epoch 125/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.6188 - val_loss: 12.8874\n",
      "Epoch 126/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.8834 - val_loss: 13.1393\n",
      "Epoch 127/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.5653 - val_loss: 11.5346\n",
      "Epoch 128/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.6032 - val_loss: 11.8738\n",
      "Epoch 129/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.4588 - val_loss: 13.4081\n",
      "Epoch 130/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.8441 - val_loss: 10.7829\n",
      "Epoch 131/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.3195 - val_loss: 11.2526\n",
      "Epoch 132/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.2538 - val_loss: 11.7663\n",
      "Epoch 133/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.8310 - val_loss: 12.1405\n",
      "Epoch 134/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.0467 - val_loss: 11.6816\n",
      "Epoch 135/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.1936 - val_loss: 11.8055\n",
      "Epoch 136/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.2173 - val_loss: 11.9519\n",
      "Epoch 137/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.9558 - val_loss: 10.6582\n",
      "Epoch 138/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.0373 - val_loss: 11.2092\n",
      "Epoch 139/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.2703 - val_loss: 12.1189\n",
      "Epoch 140/1000\n",
      "1052/1052 [==============================] - 0s 113us/step - loss: 9.1578 - val_loss: 10.8798\n",
      "Epoch 141/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.2729 - val_loss: 13.2532\n",
      "Epoch 142/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 9.2249 - val_loss: 10.6553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 143/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.0729 - val_loss: 12.4312\n",
      "Epoch 144/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1621 - val_loss: 10.5930\n",
      "Epoch 145/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0799 - val_loss: 10.7473\n",
      "Epoch 146/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.3186 - val_loss: 11.1146\n",
      "Epoch 147/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.3807 - val_loss: 11.0279\n",
      "Epoch 148/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9779 - val_loss: 10.8111\n",
      "Epoch 149/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1414 - val_loss: 11.9914\n",
      "Epoch 150/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.8785 - val_loss: 11.5685\n",
      "Epoch 151/1000\n",
      "1052/1052 [==============================] - 0s 109us/step - loss: 8.9546 - val_loss: 10.8310\n",
      "Epoch 152/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.1758 - val_loss: 11.8992\n",
      "Epoch 153/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.7565 - val_loss: 10.5923\n",
      "Epoch 154/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9024 - val_loss: 12.1980\n",
      "Epoch 155/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.1362 - val_loss: 11.0477\n",
      "Epoch 156/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.5871 - val_loss: 10.7346\n",
      "Epoch 157/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8266 - val_loss: 10.8977\n",
      "Epoch 158/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8127 - val_loss: 11.3119\n",
      "Epoch 159/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8015 - val_loss: 10.5185\n",
      "Epoch 160/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.4668 - val_loss: 11.2118\n",
      "Epoch 161/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.8432 - val_loss: 11.3495\n",
      "Epoch 162/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.4251 - val_loss: 10.5570\n",
      "Epoch 163/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.9175 - val_loss: 10.5321\n",
      "Epoch 164/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.9704 - val_loss: 10.3455\n",
      "Epoch 165/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.0332 - val_loss: 10.4772\n",
      "Epoch 166/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.9315 - val_loss: 10.4538\n",
      "Epoch 167/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8724 - val_loss: 10.7328\n",
      "Epoch 168/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7618 - val_loss: 11.5662\n",
      "Epoch 169/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.7788 - val_loss: 10.3879\n",
      "Epoch 170/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.6960 - val_loss: 10.8993\n",
      "Epoch 171/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8194 - val_loss: 10.5335\n",
      "Epoch 172/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9304 - val_loss: 10.3160\n",
      "Epoch 173/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.8464 - val_loss: 10.7393\n",
      "Epoch 174/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.4070 - val_loss: 10.2720\n",
      "Epoch 175/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.7495 - val_loss: 10.2359\n",
      "Epoch 176/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.0211 - val_loss: 10.8836\n",
      "Epoch 177/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.8952 - val_loss: 10.5300\n",
      "Epoch 178/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.6428 - val_loss: 10.5062\n",
      "Epoch 179/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.7875 - val_loss: 11.3268\n",
      "Epoch 180/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8841 - val_loss: 12.0791\n",
      "Epoch 181/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.7272 - val_loss: 10.5621\n",
      "Epoch 182/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.8767 - val_loss: 10.0757\n",
      "Epoch 183/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.2713 - val_loss: 10.6772\n",
      "Epoch 184/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.8587 - val_loss: 10.5173\n",
      "Epoch 185/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.9435 - val_loss: 10.7355\n",
      "Epoch 186/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.8345 - val_loss: 10.0800\n",
      "Epoch 187/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.0596 - val_loss: 10.4733\n",
      "Epoch 188/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.5790 - val_loss: 11.4570\n",
      "Epoch 189/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.0289 - val_loss: 10.1963\n",
      "Epoch 190/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.5844 - val_loss: 10.7472\n",
      "Epoch 191/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.8233 - val_loss: 12.4367\n",
      "Epoch 192/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.5957 - val_loss: 10.5708\n",
      "Epoch 193/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.6280 - val_loss: 14.8027\n",
      "Epoch 194/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.3633 - val_loss: 9.9558\n",
      "Epoch 195/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 8.7985 - val_loss: 11.9984\n",
      "Epoch 196/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5774 - val_loss: 10.5321\n",
      "Epoch 197/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9306 - val_loss: 13.0726\n",
      "Epoch 198/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.5416 - val_loss: 10.5105\n",
      "Epoch 199/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.5982 - val_loss: 10.3190\n",
      "Epoch 200/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5791 - val_loss: 10.2447\n",
      "Epoch 201/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.8921 - val_loss: 10.6648\n",
      "Epoch 202/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.8244 - val_loss: 9.8129\n",
      "Epoch 203/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.8263 - val_loss: 11.0234\n",
      "Epoch 204/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.4738 - val_loss: 10.1709\n",
      "Epoch 205/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.7455 - val_loss: 11.6056\n",
      "Epoch 206/1000\n",
      "1052/1052 [==============================] - 0s 116us/step - loss: 8.4530 - val_loss: 10.4458\n",
      "Epoch 207/1000\n",
      "1052/1052 [==============================] - 0s 112us/step - loss: 8.3939 - val_loss: 10.3407\n",
      "Epoch 208/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.5414 - val_loss: 9.9942\n",
      "Epoch 209/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.6450 - val_loss: 10.5708\n",
      "Epoch 210/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.9727 - val_loss: 10.5217\n",
      "Epoch 211/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 9.0680 - val_loss: 10.2236\n",
      "Epoch 212/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 9.1604 - val_loss: 10.0061\n",
      "Epoch 213/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.9025 - val_loss: 10.5005\n",
      "Epoch 214/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5745 - val_loss: 10.0880\n",
      "Epoch 215/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.4390 - val_loss: 11.1886\n",
      "Epoch 216/1000\n",
      "1052/1052 [==============================] - 0s 109us/step - loss: 8.7977 - val_loss: 10.9744\n",
      "Epoch 217/1000\n",
      "1052/1052 [==============================] - 0s 112us/step - loss: 8.5248 - val_loss: 10.1916\n",
      "Epoch 218/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 8.8354 - val_loss: 12.3153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 219/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 8.7184 - val_loss: 10.6647\n",
      "Epoch 220/1000\n",
      "1052/1052 [==============================] - 0s 112us/step - loss: 8.9236 - val_loss: 10.4144\n",
      "Epoch 221/1000\n",
      "1052/1052 [==============================] - 0s 108us/step - loss: 8.5249 - val_loss: 9.9768\n",
      "Epoch 222/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.5238 - val_loss: 10.1948\n",
      "Epoch 223/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.1126 - val_loss: 11.0944\n",
      "Epoch 224/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.8688 - val_loss: 13.5153\n",
      "Epoch 225/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.8995 - val_loss: 10.8430\n",
      "Epoch 226/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.4065 - val_loss: 10.8108\n",
      "Epoch 227/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.6734 - val_loss: 10.1903\n",
      "Epoch 228/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.3181 - val_loss: 10.3162\n",
      "Epoch 229/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3335 - val_loss: 10.9889\n",
      "Epoch 230/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.7708 - val_loss: 10.5433\n",
      "Epoch 231/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.7467 - val_loss: 11.9456\n",
      "Epoch 232/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.6516 - val_loss: 10.7226\n",
      "Epoch 233/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.2374 - val_loss: 10.3430\n",
      "Epoch 234/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.3522 - val_loss: 9.8041\n",
      "Epoch 235/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.5723 - val_loss: 10.0887\n",
      "Epoch 236/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 8.4870 - val_loss: 10.0601\n",
      "Epoch 237/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.3350 - val_loss: 10.2637\n",
      "Epoch 238/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.9950 - val_loss: 10.3721\n",
      "Epoch 239/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.4119 - val_loss: 9.8009\n",
      "Epoch 240/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.5816 - val_loss: 10.2163\n",
      "Epoch 241/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 8.6386 - val_loss: 10.3881\n",
      "Epoch 242/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.9059 - val_loss: 10.0848\n",
      "Epoch 243/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.7559 - val_loss: 10.5283\n",
      "Epoch 244/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.4588 - val_loss: 10.6056\n",
      "Epoch 245/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.5618 - val_loss: 10.3972\n",
      "Epoch 246/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.5915 - val_loss: 9.8663\n",
      "Epoch 247/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 8.5540 - val_loss: 10.4803\n",
      "Epoch 248/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6015 - val_loss: 10.3263\n",
      "Epoch 249/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.5621 - val_loss: 10.8453\n",
      "Epoch 250/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.6441 - val_loss: 11.2071\n",
      "Epoch 251/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3200 - val_loss: 10.3069\n",
      "Epoch 252/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.5956 - val_loss: 10.0375\n",
      "Epoch 253/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.4223 - val_loss: 11.5069\n",
      "Epoch 254/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.5065 - val_loss: 9.8960\n",
      "Epoch 255/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.1521 - val_loss: 10.8297\n",
      "Epoch 256/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.3005 - val_loss: 10.3607\n",
      "Epoch 257/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.4495 - val_loss: 10.0726\n",
      "Epoch 258/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.4240 - val_loss: 9.7779\n",
      "Epoch 259/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.6114 - val_loss: 10.3196\n",
      "Epoch 260/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.7619 - val_loss: 9.9703\n",
      "Epoch 261/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.7309 - val_loss: 9.6303\n",
      "Epoch 262/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.8677 - val_loss: 12.2361\n",
      "Epoch 263/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.9374 - val_loss: 9.9557\n",
      "Epoch 264/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.7261 - val_loss: 10.2263\n",
      "Epoch 265/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.5131 - val_loss: 10.6577\n",
      "Epoch 266/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.2685 - val_loss: 11.0367\n",
      "Epoch 267/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.3495 - val_loss: 9.6370\n",
      "Epoch 268/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3696 - val_loss: 10.2141\n",
      "Epoch 269/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.3151 - val_loss: 12.0619\n",
      "Epoch 270/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.6872 - val_loss: 9.8680\n",
      "Epoch 271/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3836 - val_loss: 10.1383\n",
      "Epoch 272/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4709 - val_loss: 9.8618\n",
      "Epoch 273/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 8.6958 - val_loss: 11.2207\n",
      "Epoch 274/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.6179 - val_loss: 9.9807\n",
      "Epoch 275/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0716 - val_loss: 13.1452\n",
      "Epoch 276/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.6362 - val_loss: 10.3657\n",
      "Epoch 277/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.6162 - val_loss: 9.6847\n",
      "Epoch 278/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.4193 - val_loss: 9.9797\n",
      "Epoch 279/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2408 - val_loss: 9.6346\n",
      "Epoch 280/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.5943 - val_loss: 9.6108\n",
      "Epoch 281/1000\n",
      "1052/1052 [==============================] - 0s 131us/step - loss: 8.6531 - val_loss: 11.1269\n",
      "Epoch 282/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.4835 - val_loss: 10.1458\n",
      "Epoch 283/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6389 - val_loss: 10.1761\n",
      "Epoch 284/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.2274 - val_loss: 9.7182\n",
      "Epoch 285/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3273 - val_loss: 9.7346\n",
      "Epoch 286/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.4555 - val_loss: 12.4807\n",
      "Epoch 287/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.6365 - val_loss: 9.9332\n",
      "Epoch 288/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.6198 - val_loss: 12.1097\n",
      "Epoch 289/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.5419 - val_loss: 9.8776\n",
      "Epoch 290/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.3398 - val_loss: 9.5491\n",
      "Epoch 291/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.2779 - val_loss: 11.9840\n",
      "Epoch 292/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.3751 - val_loss: 9.5744\n",
      "Epoch 293/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.3997 - val_loss: 10.2052\n",
      "Epoch 294/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.3957 - val_loss: 9.7405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 295/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.5310 - val_loss: 9.8326\n",
      "Epoch 296/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.2539 - val_loss: 9.6591\n",
      "Epoch 297/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.2931 - val_loss: 9.8446\n",
      "Epoch 298/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3745 - val_loss: 9.5716\n",
      "Epoch 299/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4157 - val_loss: 10.6942\n",
      "Epoch 300/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.5186 - val_loss: 10.0832\n",
      "Epoch 301/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6915 - val_loss: 9.7847\n",
      "Epoch 302/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4709 - val_loss: 9.4126\n",
      "Epoch 303/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3723 - val_loss: 9.5738\n",
      "Epoch 304/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4840 - val_loss: 9.8484\n",
      "Epoch 305/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4921 - val_loss: 9.8335\n",
      "Epoch 306/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6959 - val_loss: 11.4611\n",
      "Epoch 307/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.0401 - val_loss: 9.6209\n",
      "Epoch 308/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3874 - val_loss: 9.9142\n",
      "Epoch 309/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1856 - val_loss: 10.0782\n",
      "Epoch 310/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2055 - val_loss: 11.0958\n",
      "Epoch 311/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.0690 - val_loss: 9.5478\n",
      "Epoch 312/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.2666 - val_loss: 11.8025\n",
      "Epoch 313/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6853 - val_loss: 10.3664\n",
      "Epoch 314/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2633 - val_loss: 9.6563\n",
      "Epoch 315/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5849 - val_loss: 9.8970\n",
      "Epoch 316/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.2816 - val_loss: 9.8422\n",
      "Epoch 317/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.0715 - val_loss: 9.7819\n",
      "Epoch 318/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4866 - val_loss: 9.6976\n",
      "Epoch 319/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7084 - val_loss: 9.9511\n",
      "Epoch 320/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2258 - val_loss: 10.7605\n",
      "Epoch 321/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6027 - val_loss: 9.7238\n",
      "Epoch 322/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 8.1747 - val_loss: 10.3378\n",
      "Epoch 323/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3134 - val_loss: 14.0926\n",
      "Epoch 324/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.9139 - val_loss: 10.0040\n",
      "Epoch 325/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.0332 - val_loss: 9.7272\n",
      "Epoch 326/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4608 - val_loss: 10.0628\n",
      "Epoch 327/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4076 - val_loss: 10.0953\n",
      "Epoch 328/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0965 - val_loss: 9.8129\n",
      "Epoch 329/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 8.4629 - val_loss: 10.7075\n",
      "Epoch 330/1000\n",
      "1052/1052 [==============================] - 0s 112us/step - loss: 8.6290 - val_loss: 10.1054\n",
      "Epoch 331/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 8.2798 - val_loss: 9.5308\n",
      "Epoch 332/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 8.1209 - val_loss: 10.7420\n",
      "Epoch 333/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.9087 - val_loss: 9.9496\n",
      "Epoch 334/1000\n",
      "1052/1052 [==============================] - 0s 108us/step - loss: 8.1815 - val_loss: 9.4351\n",
      "Epoch 335/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 8.1905 - val_loss: 10.6014\n",
      "Epoch 336/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 8.5855 - val_loss: 9.8421\n",
      "Epoch 337/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.5282 - val_loss: 10.4072\n",
      "Epoch 338/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 7.9687 - val_loss: 9.6751\n",
      "Epoch 339/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 8.2932 - val_loss: 9.3868\n",
      "Epoch 340/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.0917 - val_loss: 10.0972\n",
      "Epoch 341/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.5354 - val_loss: 10.5999\n",
      "Epoch 342/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 9.5004 - val_loss: 9.9143\n",
      "Epoch 343/1000\n",
      "1052/1052 [==============================] - 0s 108us/step - loss: 8.4354 - val_loss: 9.4402\n",
      "Epoch 344/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.4079 - val_loss: 11.2297\n",
      "Epoch 345/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.3848 - val_loss: 9.6813\n",
      "Epoch 346/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3518 - val_loss: 9.8116\n",
      "Epoch 347/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.0853 - val_loss: 9.4633\n",
      "Epoch 348/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.2966 - val_loss: 9.3001\n",
      "Epoch 349/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.3974 - val_loss: 10.0737\n",
      "Epoch 350/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.1226 - val_loss: 9.5067\n",
      "Epoch 351/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.4430 - val_loss: 9.9590\n",
      "Epoch 352/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.2049 - val_loss: 10.6206\n",
      "Epoch 353/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1817 - val_loss: 10.3987\n",
      "Epoch 354/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.2876 - val_loss: 10.3197\n",
      "Epoch 355/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.1006 - val_loss: 9.5600\n",
      "Epoch 356/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.4653 - val_loss: 9.9927\n",
      "Epoch 357/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2826 - val_loss: 9.3653\n",
      "Epoch 358/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.4864 - val_loss: 9.6378\n",
      "Epoch 359/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.9638 - val_loss: 10.8685\n",
      "Epoch 360/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.7556 - val_loss: 12.3915\n",
      "Epoch 361/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.2229 - val_loss: 9.7768\n",
      "Epoch 362/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.1110 - val_loss: 9.2390\n",
      "Epoch 363/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.1640 - val_loss: 9.3914\n",
      "Epoch 364/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 8.1129 - val_loss: 9.9734\n",
      "Epoch 365/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 8.2166 - val_loss: 9.6181\n",
      "Epoch 366/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 8.2148 - val_loss: 9.1772\n",
      "Epoch 367/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 8.0771 - val_loss: 10.3899\n",
      "Epoch 368/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 8.0644 - val_loss: 9.8366\n",
      "Epoch 369/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 7.9851 - val_loss: 9.1301\n",
      "Epoch 370/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 8.1262 - val_loss: 9.8372\n",
      "Epoch 371/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 112us/step - loss: 8.2635 - val_loss: 11.1417\n",
      "Epoch 372/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.4503 - val_loss: 9.0964\n",
      "Epoch 373/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0516 - val_loss: 10.6620\n",
      "Epoch 374/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0398 - val_loss: 9.8152\n",
      "Epoch 375/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2245 - val_loss: 9.4609\n",
      "Epoch 376/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1062 - val_loss: 10.2417\n",
      "Epoch 377/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1483 - val_loss: 9.1426\n",
      "Epoch 378/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.3539 - val_loss: 12.5244\n",
      "Epoch 379/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.6031 - val_loss: 9.6052\n",
      "Epoch 380/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2448 - val_loss: 9.9182\n",
      "Epoch 381/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3664 - val_loss: 11.2127\n",
      "Epoch 382/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.2235 - val_loss: 9.3019\n",
      "Epoch 383/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.1350 - val_loss: 9.4140\n",
      "Epoch 384/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.1050 - val_loss: 11.9502\n",
      "Epoch 385/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.9395 - val_loss: 9.8630\n",
      "Epoch 386/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.1361 - val_loss: 9.9905\n",
      "Epoch 387/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.2404 - val_loss: 10.4886\n",
      "Epoch 388/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.2445 - val_loss: 9.2363\n",
      "Epoch 389/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.0416 - val_loss: 10.3593\n",
      "Epoch 390/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.2488 - val_loss: 9.9566\n",
      "Epoch 391/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.1772 - val_loss: 9.9528\n",
      "Epoch 392/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.8301 - val_loss: 9.0328\n",
      "Epoch 393/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.3002 - val_loss: 9.4175\n",
      "Epoch 394/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.6729 - val_loss: 10.0121\n",
      "Epoch 395/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.2442 - val_loss: 9.2951\n",
      "Epoch 396/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.0679 - val_loss: 9.5951\n",
      "Epoch 397/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.0122 - val_loss: 9.8123\n",
      "Epoch 398/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.0562 - val_loss: 10.2113\n",
      "Epoch 399/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.0071 - val_loss: 9.8699\n",
      "Epoch 400/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.0227 - val_loss: 9.5246\n",
      "Epoch 401/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.3483 - val_loss: 9.9428\n",
      "Epoch 402/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.9119 - val_loss: 9.2007\n",
      "Epoch 403/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 7.8760 - val_loss: 9.4892\n",
      "Epoch 404/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.2056 - val_loss: 9.0917\n",
      "Epoch 405/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.3676 - val_loss: 11.4711\n",
      "Epoch 406/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6205 - val_loss: 9.3323\n",
      "Epoch 407/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.3237 - val_loss: 12.7051\n",
      "Epoch 408/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.3608 - val_loss: 11.7680\n",
      "Epoch 409/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.0969 - val_loss: 9.6991\n",
      "Epoch 410/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.0209 - val_loss: 9.1654\n",
      "Epoch 411/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.9760 - val_loss: 9.0108\n",
      "Epoch 412/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.0728 - val_loss: 9.4821\n",
      "Epoch 413/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.4361 - val_loss: 13.3386\n",
      "Epoch 414/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.1438 - val_loss: 9.5678\n",
      "Epoch 415/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.1291 - val_loss: 10.0392\n",
      "Epoch 416/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.1492 - val_loss: 9.1734\n",
      "Epoch 417/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.0298 - val_loss: 9.5170\n",
      "Epoch 418/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.2090 - val_loss: 8.9987\n",
      "Epoch 419/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.0557 - val_loss: 10.1287\n",
      "Epoch 420/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 7.9927 - val_loss: 9.8256\n",
      "Epoch 421/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.3005 - val_loss: 9.6440\n",
      "Epoch 422/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2117 - val_loss: 9.3637\n",
      "Epoch 423/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.0828 - val_loss: 9.0937\n",
      "Epoch 424/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 7.9057 - val_loss: 9.8789\n",
      "Epoch 425/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.2651 - val_loss: 9.0888\n",
      "Epoch 426/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0921 - val_loss: 10.4059\n",
      "Epoch 427/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3211 - val_loss: 11.3172\n",
      "Epoch 428/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.0322 - val_loss: 9.1778\n",
      "Epoch 429/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3269 - val_loss: 9.1843\n",
      "Epoch 430/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1178 - val_loss: 9.3743\n",
      "Epoch 431/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3761 - val_loss: 10.7639\n",
      "Epoch 432/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9576 - val_loss: 9.5317\n",
      "Epoch 433/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.1042 - val_loss: 10.2793\n",
      "Epoch 434/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.8792 - val_loss: 9.5077\n",
      "Epoch 435/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.0409 - val_loss: 9.5377\n",
      "Epoch 436/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1673 - val_loss: 9.1810\n",
      "Epoch 437/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1884 - val_loss: 9.0262\n",
      "Epoch 438/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2584 - val_loss: 9.0989\n",
      "Epoch 439/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.4393 - val_loss: 10.9841\n",
      "Epoch 440/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0158 - val_loss: 9.7048\n",
      "Epoch 441/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1516 - val_loss: 9.4311\n",
      "Epoch 442/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.9038 - val_loss: 8.9967\n",
      "Epoch 443/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0475 - val_loss: 9.8998\n",
      "Epoch 444/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.8263 - val_loss: 9.2004\n",
      "Epoch 445/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2453 - val_loss: 11.4142\n",
      "Epoch 446/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.2570 - val_loss: 9.2011\n",
      "Epoch 447/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9585 - val_loss: 9.5487\n",
      "Epoch 448/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0247 - val_loss: 10.6696\n",
      "Epoch 449/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3984 - val_loss: 9.5101\n",
      "Epoch 450/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.0086 - val_loss: 8.9085\n",
      "Epoch 451/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.0059 - val_loss: 10.0875\n",
      "Epoch 452/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0574 - val_loss: 9.6226\n",
      "Epoch 453/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0198 - val_loss: 10.0039\n",
      "Epoch 454/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0597 - val_loss: 9.9530\n",
      "Epoch 455/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0000 - val_loss: 9.1482\n",
      "Epoch 456/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.2234 - val_loss: 9.3183\n",
      "Epoch 457/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9054 - val_loss: 9.7864\n",
      "Epoch 458/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0896 - val_loss: 9.6553\n",
      "Epoch 459/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5363 - val_loss: 9.6103\n",
      "Epoch 460/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0905 - val_loss: 9.2919\n",
      "Epoch 461/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0734 - val_loss: 9.2023\n",
      "Epoch 462/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0751 - val_loss: 9.5026\n",
      "Epoch 463/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1284 - val_loss: 9.4344\n",
      "Epoch 464/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.0248 - val_loss: 9.9217\n",
      "Epoch 465/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.9386 - val_loss: 8.9745\n",
      "Epoch 466/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8907 - val_loss: 9.0672\n",
      "Epoch 467/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0766 - val_loss: 9.2279\n",
      "Epoch 468/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8552 - val_loss: 9.0077\n",
      "Epoch 469/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.3326 - val_loss: 9.2851\n",
      "Epoch 470/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3410 - val_loss: 9.7909\n",
      "Epoch 471/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.8046 - val_loss: 9.2487\n",
      "Epoch 472/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0164 - val_loss: 9.0581\n",
      "Epoch 473/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2654 - val_loss: 8.9209\n",
      "Epoch 474/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0769 - val_loss: 10.5063\n",
      "Epoch 475/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1642 - val_loss: 9.0867\n",
      "Epoch 476/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0594 - val_loss: 11.0442\n",
      "Epoch 477/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1930 - val_loss: 9.0339\n",
      "Epoch 478/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 7.8528 - val_loss: 8.9288\n",
      "Epoch 479/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.1146 - val_loss: 9.5072\n",
      "Epoch 480/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1633 - val_loss: 9.0346\n",
      "Epoch 481/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.0278 - val_loss: 8.9981\n",
      "Epoch 482/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.8659 - val_loss: 9.6435\n",
      "Epoch 483/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.1173 - val_loss: 11.0505\n",
      "Epoch 484/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.1638 - val_loss: 9.2530\n",
      "Epoch 485/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.9071 - val_loss: 9.6987\n",
      "Epoch 486/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.2502 - val_loss: 9.1353\n",
      "Epoch 487/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.6880 - val_loss: 9.1917\n",
      "Epoch 488/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1225 - val_loss: 10.1900\n",
      "Epoch 489/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9408 - val_loss: 10.5182\n",
      "Epoch 490/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3309 - val_loss: 9.4363\n",
      "Epoch 491/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.8771 - val_loss: 10.2440\n",
      "Epoch 492/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 8.0617 - 0s 85us/step - loss: 8.1518 - val_loss: 9.4292\n",
      "Epoch 493/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.7690 - val_loss: 9.1632\n",
      "Epoch 494/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.9197 - val_loss: 10.6281\n",
      "Epoch 495/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1427 - val_loss: 8.8706\n",
      "Epoch 496/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8423 - val_loss: 12.7675\n",
      "Epoch 497/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.4967 - val_loss: 9.6063\n",
      "Epoch 498/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.8764 - val_loss: 9.4733\n",
      "Epoch 499/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.7397 - val_loss: 9.4448\n",
      "Epoch 500/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2370 - val_loss: 9.6602\n",
      "Epoch 501/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.0536 - val_loss: 9.6557\n",
      "Epoch 502/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0366 - val_loss: 9.2585\n",
      "Epoch 503/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9462 - val_loss: 9.4865\n",
      "Epoch 504/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.8228 - val_loss: 9.1181\n",
      "Epoch 505/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 7.8327 - val_loss: 9.0082\n",
      "Epoch 506/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.9127 - val_loss: 9.4108\n",
      "Epoch 507/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.9671 - val_loss: 9.4626\n",
      "Epoch 508/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.9765 - val_loss: 8.8926\n",
      "Epoch 509/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.7853 - val_loss: 9.1379\n",
      "Epoch 510/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.7594 - val_loss: 9.0949\n",
      "Epoch 511/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.9149 - val_loss: 10.2548\n",
      "Epoch 512/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.7741 - val_loss: 10.5993\n",
      "Epoch 513/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.2808 - val_loss: 9.0922\n",
      "Epoch 514/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.1962 - val_loss: 9.0735\n",
      "Epoch 515/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.0160 - val_loss: 9.1612\n",
      "Epoch 516/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2341 - val_loss: 10.4604\n",
      "Epoch 517/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.1451 - val_loss: 9.3489\n",
      "Epoch 518/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3683 - val_loss: 9.2390\n",
      "Epoch 519/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1595 - val_loss: 9.0048\n",
      "Epoch 520/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9287 - val_loss: 9.2097\n",
      "Epoch 521/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1826 - val_loss: 9.7752\n",
      "Epoch 522/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.9964 - val_loss: 9.3337\n",
      "Epoch 523/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.7514 - val_loss: 9.6520\n",
      "Epoch 524/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3968 - val_loss: 9.9563\n",
      "Epoch 525/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.9991 - val_loss: 8.9780\n",
      "Epoch 526/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.7554 - val_loss: 8.7223\n",
      "Epoch 527/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.1524 - val_loss: 9.9406\n",
      "Epoch 528/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.4722 - val_loss: 9.9015\n",
      "Epoch 529/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 7.6802 - val_loss: 9.4208\n",
      "Epoch 530/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.3813 - val_loss: 9.7059\n",
      "Epoch 531/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.9373 - val_loss: 8.9476\n",
      "Epoch 532/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.2386 - val_loss: 10.3392\n",
      "Epoch 533/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.2755 - val_loss: 9.5439\n",
      "Epoch 534/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.7641 - val_loss: 9.0932\n",
      "Epoch 535/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 7.9594 - val_loss: 8.8238\n",
      "Epoch 536/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.9611 - val_loss: 9.2381\n",
      "Epoch 537/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.0950 - val_loss: 10.7998\n",
      "Epoch 538/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.0098 - val_loss: 9.8036\n",
      "Epoch 539/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.9097 - val_loss: 9.4560\n",
      "Epoch 540/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.0009 - val_loss: 9.2373\n",
      "Epoch 541/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3108 - val_loss: 9.0941\n",
      "Epoch 542/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1910 - val_loss: 10.1998\n",
      "Epoch 543/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.9580 - val_loss: 9.7655\n",
      "Epoch 544/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0028 - val_loss: 9.3008\n",
      "Epoch 545/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9120 - val_loss: 9.9161\n",
      "Epoch 546/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.8636 - val_loss: 9.1547\n",
      "Epoch 547/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.9227 - val_loss: 8.8794\n",
      "Epoch 548/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5268 - val_loss: 9.0184\n",
      "Epoch 549/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.2208 - val_loss: 8.8356\n",
      "Epoch 550/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9816 - val_loss: 9.9366\n",
      "Epoch 551/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2848 - val_loss: 11.5920\n",
      "Epoch 552/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.9099 - val_loss: 9.0240\n",
      "Epoch 553/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.8788 - val_loss: 9.0584\n",
      "Epoch 554/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0776 - val_loss: 9.5842\n",
      "Epoch 555/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1872 - val_loss: 11.2499\n",
      "Epoch 556/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.9126 - val_loss: 9.0593\n",
      "Epoch 557/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.8097 - val_loss: 9.5544\n",
      "Epoch 558/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.6611 - val_loss: 9.2404\n",
      "Epoch 559/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8513 - val_loss: 8.8119\n",
      "Epoch 560/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.0311 - val_loss: 9.0133\n",
      "Epoch 561/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9817 - val_loss: 9.2331\n",
      "Epoch 562/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3602 - val_loss: 8.9122\n",
      "Epoch 563/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0143 - val_loss: 10.5741\n",
      "Epoch 564/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.8298 - val_loss: 8.9958\n",
      "Epoch 565/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.9249 - val_loss: 9.2454\n",
      "Epoch 566/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0497 - val_loss: 9.1893\n",
      "Epoch 567/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1187 - val_loss: 8.7724\n",
      "Epoch 568/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.6079 - val_loss: 9.8580\n",
      "Epoch 569/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.8630 - val_loss: 9.0859\n",
      "Epoch 570/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1906 - val_loss: 11.1213\n",
      "Epoch 571/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0643 - val_loss: 9.2658\n",
      "Epoch 572/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.7623 - val_loss: 9.7148\n",
      "Epoch 573/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3313 - val_loss: 8.9100\n",
      "Epoch 574/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.6631 - val_loss: 8.9345\n",
      "Epoch 575/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.8156 - val_loss: 9.2660\n",
      "Epoch 576/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.7742 - val_loss: 9.1716\n",
      "Epoch 577/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.8067 - val_loss: 9.5653\n",
      "Epoch 578/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.7806 - val_loss: 8.9312\n",
      "Epoch 579/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.7626 - val_loss: 9.5203\n",
      "Epoch 580/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.7815 - val_loss: 9.0205\n",
      "Epoch 581/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.8320 - val_loss: 10.4201\n",
      "Epoch 582/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0416 - val_loss: 8.9298\n",
      "Epoch 583/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3251 - val_loss: 9.9490\n",
      "Epoch 584/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.5784 - val_loss: 10.5111\n",
      "Epoch 585/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0163 - val_loss: 8.6789\n",
      "Epoch 586/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.9619 - val_loss: 9.8220\n",
      "Epoch 587/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.9308 - val_loss: 8.7960\n",
      "Epoch 588/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.7295 - val_loss: 9.2175\n",
      "Epoch 589/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.9429 - val_loss: 8.9691\n",
      "Epoch 590/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.6764 - val_loss: 10.1457\n",
      "Epoch 591/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.7438 - val_loss: 8.8521\n",
      "Epoch 592/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2053 - val_loss: 9.2820\n",
      "Epoch 593/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1139 - val_loss: 8.9368\n",
      "Epoch 594/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5641 - val_loss: 9.9382\n",
      "Epoch 595/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3646 - val_loss: 9.6788\n",
      "Epoch 596/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0473 - val_loss: 9.3607\n",
      "Epoch 597/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.7971 - val_loss: 8.7356\n",
      "Epoch 598/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2960 - val_loss: 9.0164\n",
      "Epoch 599/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.7749 - val_loss: 9.6825\n",
      "Epoch 600/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9214 - val_loss: 8.6911\n",
      "Epoch 601/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0264 - val_loss: 10.5601\n",
      "Epoch 602/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.8131 - val_loss: 9.0279\n",
      "Epoch 603/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9270 - val_loss: 9.4244\n",
      "Epoch 604/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 8.508 - 0s 89us/step - loss: 8.0246 - val_loss: 9.7773\n",
      "Epoch 605/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.7569 - val_loss: 9.0719\n",
      "Epoch 606/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2239 - val_loss: 9.1220\n",
      "Epoch 607/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9767 - val_loss: 8.9613\n",
      "Epoch 608/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.7564 - val_loss: 9.6484\n",
      "Epoch 609/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9557 - val_loss: 8.8486\n",
      "Epoch 610/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.7860 - val_loss: 10.1303\n",
      "Epoch 611/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0773 - val_loss: 9.0002\n",
      "Epoch 612/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9391 - val_loss: 9.0517\n",
      "Epoch 613/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9976 - val_loss: 9.0373\n",
      "Epoch 614/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.8130 - val_loss: 11.0559\n",
      "Epoch 615/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.8238 - val_loss: 8.6103\n",
      "Epoch 616/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3221 - val_loss: 8.7888\n",
      "Epoch 617/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.9750 - val_loss: 9.3148\n",
      "Epoch 618/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8440 - val_loss: 10.3592\n",
      "Epoch 619/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.0532 - val_loss: 9.4367\n",
      "Epoch 620/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.0831 - val_loss: 8.8657\n",
      "Epoch 621/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.0144 - val_loss: 9.7072\n",
      "Epoch 622/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3010 - val_loss: 9.1533\n",
      "Epoch 623/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2965 - val_loss: 10.0795\n",
      "Epoch 624/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.4494 - val_loss: 9.4569\n",
      "Epoch 625/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.6987 - val_loss: 9.8510\n",
      "Epoch 626/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.6734 - val_loss: 9.2811\n",
      "Epoch 627/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8573 - val_loss: 9.7927\n",
      "Epoch 628/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2273 - val_loss: 10.0496\n",
      "Epoch 629/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9860 - val_loss: 9.5365\n",
      "Epoch 630/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.0105 - val_loss: 9.4703\n",
      "Epoch 631/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.7486 - val_loss: 9.0191\n",
      "Epoch 632/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8989 - val_loss: 9.1177\n",
      "Epoch 633/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3731 - val_loss: 8.9982\n",
      "Epoch 634/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.8391 - val_loss: 9.1726\n",
      "Epoch 635/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.7619 - val_loss: 8.9372\n",
      "Epoch 636/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.7660 - val_loss: 9.4828\n",
      "Epoch 637/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0158 - val_loss: 8.8420\n",
      "Epoch 638/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.8591 - val_loss: 9.1043\n",
      "Epoch 639/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.8782 - val_loss: 9.0238\n",
      "Epoch 640/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.6949 - val_loss: 9.1103\n",
      "Epoch 641/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.8938 - val_loss: 9.0556\n",
      "Epoch 642/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.8519 - val_loss: 8.9426\n",
      "Epoch 643/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.9034 - val_loss: 8.7177\n",
      "Epoch 644/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3547 - val_loss: 9.4191\n",
      "Epoch 645/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.6494 - val_loss: 10.1222\n",
      "Epoch 646/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.6972 - val_loss: 8.9418\n",
      "Epoch 647/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2866 - val_loss: 11.3660\n",
      "Epoch 648/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5128 - val_loss: 9.8217\n",
      "Epoch 649/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1521 - val_loss: 9.0125\n",
      "Epoch 650/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8618 - val_loss: 9.2462\n",
      "Epoch 651/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.7954 - val_loss: 9.4550\n",
      "Epoch 652/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.5649 - val_loss: 8.9097\n",
      "Epoch 653/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4959 - val_loss: 8.8948\n",
      "Epoch 654/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.2384 - val_loss: 9.4062\n",
      "Epoch 655/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.7804 - val_loss: 8.6372\n",
      "Epoch 656/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.6685 - val_loss: 9.2758\n",
      "Epoch 657/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.7110 - val_loss: 8.7773\n",
      "Epoch 658/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.6564 - val_loss: 8.8980\n",
      "Epoch 659/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.8684 - val_loss: 9.9716\n",
      "Epoch 660/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.9296 - val_loss: 9.0817\n",
      "Epoch 661/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.8598 - val_loss: 9.0889\n",
      "Epoch 662/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.6155 - val_loss: 8.6846\n",
      "Epoch 663/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.6524 - val_loss: 9.0229\n",
      "Epoch 664/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.8251 - val_loss: 9.6203\n",
      "Epoch 665/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.7922 - val_loss: 9.0070\n",
      "Epoch 666/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2798 - val_loss: 9.8227\n",
      "Epoch 667/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.4501 - val_loss: 8.9968\n",
      "Epoch 668/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3440 - val_loss: 8.9817\n",
      "Epoch 669/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8115 - val_loss: 8.8620\n",
      "Epoch 670/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2506 - val_loss: 8.5664\n",
      "Epoch 671/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.5137 - val_loss: 9.3801\n",
      "Epoch 672/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.6683 - val_loss: 10.0220\n",
      "Epoch 673/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1540 - val_loss: 8.9067\n",
      "Epoch 674/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.7755 - val_loss: 9.5431\n",
      "Epoch 675/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.7202 - val_loss: 8.5801\n",
      "Epoch 676/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.9749 - val_loss: 8.7844\n",
      "Epoch 677/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9492 - val_loss: 10.7833\n",
      "Epoch 678/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2882 - val_loss: 8.4685\n",
      "Epoch 679/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.8930 - val_loss: 9.6401\n",
      "Epoch 680/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.7980 - val_loss: 8.9192\n",
      "Epoch 681/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8383 - val_loss: 9.2368\n",
      "Epoch 682/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8163 - val_loss: 11.2127\n",
      "Epoch 683/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1790 - val_loss: 8.8122\n",
      "Epoch 684/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.5879 - val_loss: 9.6438\n",
      "Epoch 685/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.9662 - val_loss: 9.9581\n",
      "Epoch 686/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.7700 - val_loss: 10.5668\n",
      "Epoch 687/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0134 - val_loss: 8.8506\n",
      "Epoch 688/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3490 - val_loss: 9.0099\n",
      "Epoch 689/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1007 - val_loss: 10.7559\n",
      "Epoch 690/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0500 - val_loss: 8.8264\n",
      "Epoch 691/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.6032 - val_loss: 9.1685\n",
      "Epoch 692/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.9488 - val_loss: 8.9722\n",
      "Epoch 693/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0062 - val_loss: 8.6932\n",
      "Epoch 694/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0497 - val_loss: 9.0766\n",
      "Epoch 695/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0774 - val_loss: 8.9021\n",
      "Epoch 696/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.8974 - val_loss: 8.8768\n",
      "Epoch 697/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.9192 - val_loss: 9.2564\n",
      "Epoch 698/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.3946 - val_loss: 9.0746\n",
      "Epoch 699/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.9583 - val_loss: 9.3125\n",
      "Epoch 700/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9490 - val_loss: 8.9488\n",
      "Epoch 701/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1941 - val_loss: 9.3041\n",
      "Epoch 702/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.7196 - val_loss: 9.2510\n",
      "Epoch 703/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 7.6604 - val_loss: 9.2610\n",
      "Epoch 704/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.9744 - val_loss: 9.1011\n",
      "Epoch 705/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.8890 - val_loss: 8.9096\n",
      "Epoch 706/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.7657 - val_loss: 8.7689\n",
      "Epoch 707/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.6282 - val_loss: 9.2232\n",
      "Epoch 708/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 7.6636 - val_loss: 8.8698\n",
      "Epoch 709/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.0443 - val_loss: 9.2941\n",
      "Epoch 710/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 7.9312 - val_loss: 8.9082\n",
      "Epoch 711/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.7636 - val_loss: 8.9518\n",
      "Epoch 712/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.8296 - val_loss: 8.9127\n",
      "Epoch 713/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8100 - val_loss: 10.6928\n",
      "Epoch 714/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.8553 - val_loss: 10.2521\n",
      "Epoch 715/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.0807 - val_loss: 9.0846\n",
      "Epoch 716/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8629 - val_loss: 8.9769\n",
      "Epoch 717/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7063 - val_loss: 8.7751\n",
      "Epoch 718/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3433 - val_loss: 8.8857\n",
      "Epoch 719/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.7043 - val_loss: 8.6179\n",
      "Epoch 720/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.7799 - val_loss: 9.0427\n",
      "Epoch 721/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.8987 - val_loss: 8.9602\n",
      "Epoch 722/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.2057 - val_loss: 8.9000\n",
      "Epoch 723/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.7425 - val_loss: 8.6333\n",
      "Epoch 724/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.7146 - val_loss: 8.8392\n",
      "Epoch 725/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9286 - val_loss: 9.3850\n",
      "Epoch 726/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.7550 - val_loss: 8.6712\n",
      "Epoch 727/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.5770 - val_loss: 9.2684\n",
      "Epoch 728/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.7564 - val_loss: 10.4911\n",
      "Epoch 729/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.9880 - val_loss: 8.7217\n",
      "Epoch 730/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8573 - val_loss: 9.0872\n",
      "Epoch 731/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.9394 - val_loss: 9.2019\n",
      "Epoch 732/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.9376 - val_loss: 9.9897\n",
      "Epoch 733/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.8408 - val_loss: 9.0544\n",
      "Epoch 734/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.7655 - val_loss: 9.3831\n",
      "Epoch 735/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.8418 - val_loss: 9.6056\n",
      "Epoch 736/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2657 - val_loss: 9.8788\n",
      "Epoch 737/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.7028 - val_loss: 8.6439\n",
      "Epoch 738/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.7364 - val_loss: 9.1137\n",
      "Epoch 739/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.6985 - val_loss: 9.2658\n",
      "Epoch 740/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.1325 - val_loss: 8.9752\n",
      "Epoch 741/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0625 - val_loss: 9.3275\n",
      "Epoch 742/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.7382 - val_loss: 8.7471\n",
      "Epoch 743/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.6793 - val_loss: 8.7757\n",
      "Epoch 744/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.9304 - val_loss: 9.8908\n",
      "Epoch 745/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0058 - val_loss: 9.1045\n",
      "Epoch 746/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1874 - val_loss: 8.8439\n",
      "Epoch 747/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.6437 - val_loss: 9.3015\n",
      "Epoch 748/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.8521 - val_loss: 9.4879\n",
      "Epoch 749/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.5575 - val_loss: 9.3864\n",
      "Epoch 750/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.6310 - val_loss: 9.1529\n",
      "Epoch 751/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.8184 - val_loss: 8.9504\n",
      "Epoch 752/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.9052 - val_loss: 8.7615\n",
      "Epoch 753/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.6713 - val_loss: 9.1835\n",
      "Epoch 754/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.7623 - val_loss: 9.0568\n",
      "Epoch 755/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.5915 - val_loss: 9.1846\n",
      "Epoch 756/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0441 - val_loss: 9.8764\n",
      "Epoch 757/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.7294 - val_loss: 9.1036\n",
      "Epoch 758/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.7772 - val_loss: 8.7457\n",
      "Epoch 759/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.7191 - val_loss: 11.2869\n",
      "Epoch 760/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.4893 - val_loss: 8.7351\n",
      "Epoch 761/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.7376 - val_loss: 9.1307\n",
      "Epoch 762/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8643 - val_loss: 9.0838\n",
      "Epoch 763/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.9959 - val_loss: 9.0289\n",
      "Epoch 764/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 7.7183 - val_loss: 8.7385\n",
      "Epoch 765/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0348 - val_loss: 8.6876\n",
      "Epoch 766/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.7888 - val_loss: 9.5129\n",
      "Epoch 767/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2000 - val_loss: 9.3182\n",
      "Epoch 768/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.8878 - val_loss: 9.0555\n",
      "Epoch 769/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.7209 - val_loss: 8.6753\n",
      "Epoch 770/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.6122 - val_loss: 9.5689\n",
      "Epoch 771/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1632 - val_loss: 9.1636\n",
      "Epoch 772/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.9439 - val_loss: 9.0055\n",
      "Epoch 773/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4745 - val_loss: 10.2974\n",
      "Epoch 774/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8272 - val_loss: 9.6768\n",
      "Epoch 775/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.9542 - val_loss: 9.2014\n",
      "Epoch 776/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.6044 - val_loss: 8.7751\n",
      "Epoch 777/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9382 - val_loss: 9.5714\n",
      "Epoch 778/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0244 - val_loss: 9.1312\n",
      "Epoch 779/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.6482 - val_loss: 8.9592\n",
      "Epoch 780/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.6581 - val_loss: 8.8966\n",
      "Epoch 781/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.7156 - val_loss: 8.8586\n",
      "Epoch 782/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0235 - val_loss: 10.0292\n",
      "Epoch 783/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.6038 - val_loss: 8.9615\n",
      "Epoch 784/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.7107 - val_loss: 10.2587\n",
      "Epoch 785/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.0820 - val_loss: 8.7353\n",
      "Epoch 786/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.7605 - val_loss: 8.8001\n",
      "Epoch 787/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.5666 - val_loss: 8.8596\n",
      "Epoch 788/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.7245 - val_loss: 9.5562\n",
      "Epoch 789/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.4960 - val_loss: 8.9074\n",
      "Epoch 790/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.4544 - val_loss: 11.0145\n",
      "Epoch 791/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.0247 - val_loss: 9.0110\n",
      "Epoch 792/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.6250 - val_loss: 9.1745\n",
      "Epoch 793/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.8294 - val_loss: 8.5740\n",
      "Epoch 794/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.5333 - val_loss: 8.7727\n",
      "Epoch 795/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9662 - val_loss: 9.9294\n",
      "Epoch 796/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.6247 - val_loss: 8.9143\n",
      "Epoch 797/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.5775 - val_loss: 9.1927\n",
      "Epoch 798/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.9971 - val_loss: 10.4793\n",
      "Epoch 799/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.7670 - val_loss: 9.4359\n",
      "Epoch 800/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.5479 - val_loss: 9.1318\n",
      "Epoch 801/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.6416 - val_loss: 8.9932\n",
      "Epoch 802/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.7277 - val_loss: 8.7308\n",
      "Epoch 803/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9630 - val_loss: 8.9583\n",
      "Epoch 804/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.5810 - val_loss: 9.1996\n",
      "Epoch 805/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.5279 - val_loss: 9.3139\n",
      "Epoch 806/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.5570 - val_loss: 10.1543\n",
      "Epoch 807/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.0199 - val_loss: 8.8291\n",
      "Epoch 808/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0118 - val_loss: 8.7801\n",
      "Epoch 809/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.6227 - val_loss: 8.8817\n",
      "Epoch 810/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.3546 - val_loss: 9.5207\n",
      "Epoch 811/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.5389 - val_loss: 9.0464\n",
      "Epoch 812/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.4511 - val_loss: 9.0498\n",
      "Epoch 813/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.7775 - val_loss: 11.6079\n",
      "Epoch 814/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7326 - val_loss: 9.1769\n",
      "Epoch 815/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.7966 - val_loss: 8.7885\n",
      "Epoch 816/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1438 - val_loss: 9.0168\n",
      "Epoch 817/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1688 - val_loss: 8.8354\n",
      "Epoch 818/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.7113 - val_loss: 9.1458\n",
      "Epoch 819/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.6628 - val_loss: 9.3130\n",
      "Epoch 820/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.5135 - val_loss: 8.9461\n",
      "Epoch 821/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8255 - val_loss: 10.9009\n",
      "Epoch 822/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.6102 - val_loss: 9.0952\n",
      "Epoch 823/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0849 - val_loss: 8.5920\n",
      "Epoch 824/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.7594 - val_loss: 8.9695\n",
      "Epoch 825/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2007 - val_loss: 9.1404\n",
      "Epoch 826/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.7587 - val_loss: 9.6084\n",
      "Epoch 827/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.6674 - val_loss: 9.1671\n",
      "Epoch 828/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.7190 - val_loss: 9.0825\n",
      "Epoch 829/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.8503 - val_loss: 9.0636\n",
      "Epoch 830/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.5332 - val_loss: 9.1399\n",
      "Epoch 831/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.6514 - val_loss: 10.0493\n",
      "Epoch 832/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 7.7191 - val_loss: 9.1991\n",
      "Epoch 833/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.9555 - val_loss: 10.2217\n",
      "Epoch 834/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.9382 - val_loss: 8.9880\n",
      "Epoch 835/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.7960 - val_loss: 8.8901\n",
      "Epoch 836/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.7065 - val_loss: 8.8825\n",
      "Epoch 837/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.7736 - val_loss: 9.3654\n",
      "Epoch 838/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.8385 - val_loss: 8.5773\n",
      "Epoch 839/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.8957 - val_loss: 10.0039\n",
      "Epoch 840/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.5869 - val_loss: 9.1033\n",
      "Epoch 841/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.8177 - val_loss: 9.3443\n",
      "Epoch 842/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.7404 - val_loss: 10.1046\n",
      "Epoch 843/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.7422 - val_loss: 8.6495\n",
      "Epoch 844/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.5137 - val_loss: 8.9195\n",
      "Epoch 845/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9856 - val_loss: 9.8832\n",
      "Epoch 846/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.0451 - val_loss: 9.1317\n",
      "Epoch 847/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.8214 - val_loss: 8.6185\n",
      "Epoch 848/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.5622 - val_loss: 10.2962\n",
      "Epoch 849/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.5944 - val_loss: 11.0594\n",
      "Epoch 850/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.6777 - val_loss: 10.4060\n",
      "Epoch 851/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.9946 - val_loss: 9.2924\n",
      "Epoch 852/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.6126 - val_loss: 9.7347\n",
      "Epoch 853/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9575 - val_loss: 9.7821\n",
      "Epoch 854/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.6081 - val_loss: 9.6481\n",
      "Epoch 855/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.6998 - val_loss: 9.0825\n",
      "Epoch 856/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.5380 - val_loss: 8.7271\n",
      "Epoch 857/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.6166 - val_loss: 8.8503\n",
      "Epoch 858/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.6077 - val_loss: 9.1862\n",
      "Epoch 859/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.4232 - val_loss: 9.7192\n",
      "Epoch 860/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.5550 - val_loss: 9.1535\n",
      "Epoch 861/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.7073 - val_loss: 8.9480\n",
      "Epoch 862/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.5951 - val_loss: 9.0121\n",
      "Epoch 863/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.7597 - val_loss: 9.6379\n",
      "Epoch 864/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.8116 - val_loss: 9.2161\n",
      "Epoch 865/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.6311 - val_loss: 9.2542\n",
      "Epoch 866/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.8599 - val_loss: 8.7831\n",
      "Epoch 867/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.7620 - val_loss: 8.6342\n",
      "Epoch 868/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2296 - val_loss: 8.8078\n",
      "Epoch 869/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.5327 - val_loss: 8.8175\n",
      "Epoch 870/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.7394 - val_loss: 9.6110\n",
      "Epoch 871/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.1416 - val_loss: 9.4460\n",
      "Epoch 872/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8396 - val_loss: 8.5983\n",
      "Epoch 873/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.5418 - val_loss: 8.6062\n",
      "Epoch 874/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.4740 - val_loss: 9.2065\n",
      "Epoch 875/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8998 - val_loss: 10.5361\n",
      "Epoch 876/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.7173 - val_loss: 8.6359\n",
      "Epoch 877/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.7527 - val_loss: 9.0759\n",
      "Epoch 878/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 7.7153 - val_loss: 8.6235\n",
      "Epoch 879/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 7.8261 - val_loss: 9.5741\n",
      "Epoch 880/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.4779 - val_loss: 8.8537\n",
      "Epoch 881/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 7.5728 - val_loss: 9.6191\n",
      "Epoch 882/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 7.5582 - val_loss: 8.8144\n",
      "Epoch 883/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.4570 - val_loss: 9.9568\n",
      "Epoch 884/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 7.6686 - val_loss: 8.6239\n",
      "Epoch 885/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.4918 - val_loss: 9.3535\n",
      "Epoch 886/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.6058 - val_loss: 8.6681\n",
      "Epoch 887/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.6371 - val_loss: 9.3473\n",
      "Epoch 888/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.9054 - val_loss: 8.6841\n",
      "Epoch 889/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.6614 - val_loss: 9.2301\n",
      "Epoch 890/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.5862 - val_loss: 10.6199\n",
      "Epoch 891/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.6263 - val_loss: 9.2946\n",
      "Epoch 892/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.5681 - val_loss: 10.6342\n",
      "Epoch 893/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.4090 - val_loss: 9.5934\n",
      "Epoch 894/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8335 - val_loss: 9.1411\n",
      "Epoch 895/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.4530 - val_loss: 8.8107\n",
      "Epoch 896/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.4599 - val_loss: 11.2064\n",
      "Epoch 897/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 7.5166 - val_loss: 9.3865\n",
      "Epoch 898/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8098 - val_loss: 8.8977\n",
      "Epoch 899/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.5795 - val_loss: 8.5732\n",
      "Epoch 900/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.7167 - val_loss: 9.1498\n",
      "Epoch 901/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.6537 - val_loss: 9.1393\n",
      "Epoch 902/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.5863 - val_loss: 8.9352\n",
      "Epoch 903/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.2534 - val_loss: 10.2450\n",
      "Epoch 904/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2424 - val_loss: 8.7607\n",
      "Epoch 905/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.7600 - val_loss: 10.0107\n",
      "Epoch 906/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0708 - val_loss: 10.7881\n",
      "Epoch 907/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9670 - val_loss: 8.7380\n",
      "Epoch 908/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.5272 - val_loss: 9.5739\n",
      "Epoch 909/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.7635 - val_loss: 8.8243\n",
      "Epoch 910/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.5730 - val_loss: 9.5838\n",
      "Epoch 911/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.6113 - val_loss: 8.9978\n",
      "Epoch 912/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.6893 - val_loss: 9.0461\n",
      "Epoch 913/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.5547 - val_loss: 9.2048\n",
      "Epoch 914/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.4817 - val_loss: 8.8543\n",
      "Epoch 915/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.8709 - val_loss: 8.8801\n",
      "Epoch 916/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.3201 - val_loss: 9.2972\n",
      "Epoch 917/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.5115 - val_loss: 9.9358\n",
      "Epoch 918/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.4613 - val_loss: 8.9791\n",
      "Epoch 919/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.4217 - val_loss: 8.7880\n",
      "Epoch 920/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.4324 - val_loss: 9.8708\n",
      "Epoch 921/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.6411 - val_loss: 11.9357\n",
      "Epoch 922/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0738 - val_loss: 8.8194\n",
      "Epoch 923/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.6325 - val_loss: 9.0977\n",
      "Epoch 924/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.7325 - val_loss: 9.0597\n",
      "Epoch 925/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.3010 - val_loss: 10.4883\n",
      "Epoch 926/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.7126 - val_loss: 10.6978\n",
      "Epoch 927/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.7242 - val_loss: 9.4051\n",
      "Epoch 928/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.7758 - val_loss: 9.4051\n",
      "Epoch 929/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.5725 - val_loss: 9.2250\n",
      "Epoch 930/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.4480 - val_loss: 8.9434\n",
      "Epoch 931/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.3987 - val_loss: 8.9754\n",
      "Epoch 932/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.4709 - val_loss: 10.7531\n",
      "Epoch 933/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.8329 - val_loss: 8.7258\n",
      "Epoch 934/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2383 - val_loss: 10.1508\n",
      "Epoch 935/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 7.8315 - val_loss: 9.4449\n",
      "Epoch 936/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.8029 - val_loss: 9.1402\n",
      "Epoch 937/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.4197 - val_loss: 8.7426\n",
      "Epoch 938/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.3210 - val_loss: 8.5240\n",
      "Epoch 939/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.6775 - val_loss: 8.3197\n",
      "Epoch 940/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.8300 - val_loss: 8.5610\n",
      "Epoch 941/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.7319 - val_loss: 8.6005\n",
      "Epoch 942/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.7328 - val_loss: 8.4060\n",
      "Epoch 943/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.4553 - val_loss: 9.0019\n",
      "Epoch 944/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.7949 - val_loss: 8.8497\n",
      "Epoch 945/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.8503 - val_loss: 9.4170\n",
      "Epoch 946/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.4500 - val_loss: 8.4707\n",
      "Epoch 947/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.3867 - val_loss: 9.4964\n",
      "Epoch 948/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.4476 - val_loss: 8.4470\n",
      "Epoch 949/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.4324 - val_loss: 8.4324\n",
      "Epoch 950/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.1811 - val_loss: 8.2249\n",
      "Epoch 951/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.4766 - val_loss: 8.5913\n",
      "Epoch 952/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.4075 - val_loss: 8.3923\n",
      "Epoch 953/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.2416 - val_loss: 8.5975\n",
      "Epoch 954/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.2506 - val_loss: 8.6376\n",
      "Epoch 955/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.2751 - val_loss: 9.0568\n",
      "Epoch 956/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.2056 - val_loss: 8.9332\n",
      "Epoch 957/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.1571 - val_loss: 8.2772\n",
      "Epoch 958/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.9635 - val_loss: 8.5390\n",
      "Epoch 959/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.6191 - val_loss: 9.1138\n",
      "Epoch 960/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.2624 - val_loss: 8.7890\n",
      "Epoch 961/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.3199 - val_loss: 8.6283\n",
      "Epoch 962/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.1743 - val_loss: 10.0703\n",
      "Epoch 963/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.6222 - val_loss: 9.1182\n",
      "Epoch 964/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.4895 - val_loss: 8.4177\n",
      "Epoch 965/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.4375 - val_loss: 9.2297\n",
      "Epoch 966/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.2979 - val_loss: 9.8273\n",
      "Epoch 967/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.3137 - val_loss: 8.2809\n",
      "Epoch 968/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.2810 - val_loss: 9.3695\n",
      "Epoch 969/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.6296 - val_loss: 10.1713\n",
      "Epoch 970/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.2908 - val_loss: 8.4370\n",
      "Epoch 971/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.3296 - val_loss: 8.7614\n",
      "Epoch 972/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.2870 - val_loss: 8.4098\n",
      "Epoch 973/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.2052 - val_loss: 9.2711\n",
      "Epoch 974/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.1396 - val_loss: 8.9906\n",
      "Epoch 975/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9653 - val_loss: 8.6460\n",
      "Epoch 976/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.5513 - val_loss: 9.7101\n",
      "Epoch 977/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.0861 - val_loss: 8.8955\n",
      "Epoch 978/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.0099 - val_loss: 8.4637\n",
      "Epoch 979/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.3215 - val_loss: 8.8990\n",
      "Epoch 980/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.3472 - val_loss: 9.2289\n",
      "Epoch 981/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.1532 - val_loss: 8.5461\n",
      "Epoch 982/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.3344 - val_loss: 8.5550\n",
      "Epoch 983/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.1760 - val_loss: 9.0634\n",
      "Epoch 984/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.0448 - val_loss: 8.4419\n",
      "Epoch 985/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.3134 - val_loss: 8.8617\n",
      "Epoch 986/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.1824 - val_loss: 9.7055\n",
      "Epoch 987/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.7728 - val_loss: 8.5778\n",
      "Epoch 988/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.4204 - val_loss: 8.6988\n",
      "Epoch 989/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.5993 - val_loss: 8.5631\n",
      "Epoch 990/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.5153 - val_loss: 10.3022\n",
      "Epoch 991/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.4005 - val_loss: 9.3901\n",
      "Epoch 992/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.2747 - val_loss: 8.7569\n",
      "Epoch 993/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.2587 - val_loss: 9.2176\n",
      "Epoch 994/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.4713 - val_loss: 8.8520\n",
      "Epoch 995/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.9674 - val_loss: 8.6297\n",
      "Epoch 996/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.1279 - val_loss: 8.4995\n",
      "Epoch 997/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.1562 - val_loss: 8.7024\n",
      "Epoch 998/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.2291 - val_loss: 8.4784\n",
      "Epoch 999/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.1912 - val_loss: 8.6947\n",
      "Epoch 1000/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.0611 - val_loss: 8.8992\n",
      "6.827561796238992\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 3.6629193e+00, -4.1821408e+00,  1.4003548e-01,  5.6738055e-01,\n",
       "          4.7731609e+00,  1.0522735e+00,  1.9782355e-01,  2.3614011e+00,\n",
       "         -2.7242017e-01,  5.6141192e-01],\n",
       "        [ 1.3846671e-05, -3.6451843e-01,  2.6113147e-01,  5.8864814e-01,\n",
       "         -2.3233098e-01,  1.7336996e-01,  2.8004992e-01, -8.6592466e-02,\n",
       "         -7.0145893e-01,  1.2971787e+00],\n",
       "        [ 9.3188393e-01,  8.5571177e-02,  4.3465877e-01,  7.6537108e-01,\n",
       "          1.3316897e+00,  4.5016477e-01,  4.4844222e-01,  2.0404369e-02,\n",
       "         -1.3066533e+00,  1.9121230e+00],\n",
       "        [-2.1175379e-01, -4.2004141e-04, -1.1489381e+00, -9.5486480e-01,\n",
       "         -1.7560390e-01, -3.1677046e-01, -1.0787916e+00, -1.1977392e-01,\n",
       "          1.9373344e-01,  4.0366974e-01],\n",
       "        [ 3.6936569e+00, -6.8076414e-01,  3.3399972e-01,  3.8299090e-01,\n",
       "          1.9922523e-01,  5.9273535e-01,  3.3361945e-01,  2.2483425e-01,\n",
       "         -8.8575995e-01,  6.5999871e-01]], dtype=float32),\n",
       " array([ 4.919988  , -4.6014085 , -3.986003  , -3.9095767 ,  6.0710077 ,\n",
       "        -0.87414455, -4.0636415 ,  1.3256567 , -1.513431  , -5.4250054 ],\n",
       "       dtype=float32),\n",
       " array([[-0.33313408, -1.0006797 ,  1.0380346 , -1.2628639 , -1.0032979 ],\n",
       "        [ 1.0932913 ,  0.8252456 , -1.581965  ,  2.030129  ,  1.6224072 ],\n",
       "        [ 1.7609662 ,  1.8885027 , -1.9824035 ,  1.978075  ,  1.374216  ],\n",
       "        [ 1.9082662 ,  1.8299227 , -2.117888  ,  1.9721591 ,  1.771829  ],\n",
       "        [-2.355268  , -2.7603745 ,  2.718895  , -3.4024358 , -2.29974   ],\n",
       "        [ 0.51559323,  0.7307444 , -0.28808585,  0.3706626 ,  0.32258627],\n",
       "        [ 2.0861862 ,  1.6226875 , -1.728341  ,  2.1230273 ,  2.2933528 ],\n",
       "        [ 0.6487674 ,  1.0153191 , -1.0668491 ,  1.3721563 ,  0.93922883],\n",
       "        [-0.44102994, -0.41913575,  0.7630592 , -1.0291175 , -1.3446558 ],\n",
       "        [ 1.1746536 ,  1.2213235 , -1.7081895 ,  1.733404  ,  1.5707412 ]],\n",
       "       dtype=float32),\n",
       " array([-1.9700551, -2.0030415,  2.127339 , -2.1290557, -2.059028 ],\n",
       "       dtype=float32),\n",
       " array([[-1.4718524],\n",
       "        [-1.525283 ],\n",
       "        [ 2.2313364],\n",
       "        [-2.1825747],\n",
       "        [-1.6394832]], dtype=float32),\n",
       " array([2.3493428], dtype=float32)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_airfoil, history_airfoil=NN_model_structure_regression_4(X_train_airfoil, X_val_airfoil, Y_train_airfoil, Y_val_airfoil, adam2, 32, 1000)\n",
    "model_airfoil.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_airfoil.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_airfoil_structure4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 181\n",
      "Trainable params: 181\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1052 samples, validate on 225 samples\n",
      "Epoch 1/1000\n",
      "1052/1052 [==============================] - 0s 240us/step - loss: 6333.6885 - val_loss: 551.0037\n",
      "Epoch 2/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 187.0582 - val_loss: 58.7735\n",
      "Epoch 3/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 42.4710 - val_loss: 33.2267\n",
      "Epoch 4/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 32.7578 - val_loss: 30.7272\n",
      "Epoch 5/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 29.2920 - val_loss: 29.4815\n",
      "Epoch 6/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 27.4452 - val_loss: 29.5638\n",
      "Epoch 7/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 25.3712 - val_loss: 27.4481\n",
      "Epoch 8/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 23.8086 - val_loss: 26.1991\n",
      "Epoch 9/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 22.3277 - val_loss: 26.8070\n",
      "Epoch 10/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.8391 - val_loss: 25.7594\n",
      "Epoch 11/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 21.0249 - val_loss: 24.6923\n",
      "Epoch 12/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 20.5965 - val_loss: 24.2806\n",
      "Epoch 13/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 20.0570 - val_loss: 23.4283\n",
      "Epoch 14/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 19.6567 - val_loss: 22.9049\n",
      "Epoch 15/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 19.2331 - val_loss: 22.8774\n",
      "Epoch 16/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.8662 - val_loss: 22.8647\n",
      "Epoch 17/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.6143 - val_loss: 22.5610\n",
      "Epoch 18/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 18.2929 - val_loss: 21.7464\n",
      "Epoch 19/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.9824 - val_loss: 21.7696\n",
      "Epoch 20/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.9497 - val_loss: 21.9921\n",
      "Epoch 21/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.7938 - val_loss: 21.4538\n",
      "Epoch 22/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.3833 - val_loss: 20.7415\n",
      "Epoch 23/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.2417 - val_loss: 20.7862\n",
      "Epoch 24/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.1527 - val_loss: 20.4618\n",
      "Epoch 25/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.0456 - val_loss: 20.3170\n",
      "Epoch 26/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.1764 - val_loss: 20.5181\n",
      "Epoch 27/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 16.7723 - val_loss: 20.3505\n",
      "Epoch 28/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 16.6813 - val_loss: 20.1624\n",
      "Epoch 29/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 16.5982 - val_loss: 19.9956\n",
      "Epoch 30/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 16.8377 - val_loss: 19.7868\n",
      "Epoch 31/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 16.4569 - val_loss: 19.6650\n",
      "Epoch 32/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 16.1436 - val_loss: 18.9123\n",
      "Epoch 33/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 16.3799 - val_loss: 19.9531\n",
      "Epoch 34/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 16.0402 - val_loss: 18.7915\n",
      "Epoch 35/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 16.2404 - val_loss: 18.9103\n",
      "Epoch 36/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 15.8083 - val_loss: 20.0693\n",
      "Epoch 37/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 16.1076 - val_loss: 18.8142\n",
      "Epoch 38/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 15.6416 - val_loss: 19.2203\n",
      "Epoch 39/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 15.5033 - val_loss: 18.1177\n",
      "Epoch 40/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 15.5028 - val_loss: 18.4609\n",
      "Epoch 41/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 15.6073 - val_loss: 18.1652\n",
      "Epoch 42/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 15.6523 - val_loss: 18.6124\n",
      "Epoch 43/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 15.6068 - val_loss: 18.3058\n",
      "Epoch 44/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 15.2111 - val_loss: 17.5924\n",
      "Epoch 45/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 15.2768 - val_loss: 19.2689\n",
      "Epoch 46/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 15.1032 - val_loss: 17.5689\n",
      "Epoch 47/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 14.9639 - val_loss: 19.1393\n",
      "Epoch 48/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 14.9491 - val_loss: 18.5342\n",
      "Epoch 49/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 15.1593 - val_loss: 19.0380\n",
      "Epoch 50/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.7292 - val_loss: 17.6303\n",
      "Epoch 51/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.5988 - val_loss: 17.7572\n",
      "Epoch 52/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 14.4660 - val_loss: 17.7982\n",
      "Epoch 53/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.3527 - val_loss: 17.3611\n",
      "Epoch 54/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 14.4304 - val_loss: 16.8192\n",
      "Epoch 55/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.4319 - val_loss: 17.5434\n",
      "Epoch 56/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 14.9236 - val_loss: 17.1859\n",
      "Epoch 57/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.9322 - val_loss: 17.1189\n",
      "Epoch 58/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 14.3941 - val_loss: 17.2035\n",
      "Epoch 59/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.1678 - val_loss: 17.0877\n",
      "Epoch 60/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.9707 - val_loss: 17.2149\n",
      "Epoch 61/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.0535 - val_loss: 17.5740\n",
      "Epoch 62/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.1047 - val_loss: 18.5994\n",
      "Epoch 63/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.4480 - val_loss: 16.8371\n",
      "Epoch 64/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.1648 - val_loss: 16.8813\n",
      "Epoch 65/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.6551 - val_loss: 16.3736\n",
      "Epoch 66/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.9823 - val_loss: 17.9901\n",
      "Epoch 67/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.9949 - val_loss: 16.9277\n",
      "Epoch 68/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.7669 - val_loss: 16.7215\n",
      "Epoch 69/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.7395 - val_loss: 17.2666\n",
      "Epoch 70/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.3479 - val_loss: 16.3929\n",
      "Epoch 71/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.5503 - val_loss: 18.8789\n",
      "Epoch 72/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.2037 - val_loss: 16.5703\n",
      "Epoch 73/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.6478 - val_loss: 17.1923\n",
      "Epoch 74/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.4984 - val_loss: 16.2088\n",
      "Epoch 75/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.3331 - val_loss: 17.6439\n",
      "Epoch 76/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.6541 - val_loss: 16.7647\n",
      "Epoch 77/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.4873 - val_loss: 15.9992\n",
      "Epoch 78/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 13.1608 - val_loss: 16.2130\n",
      "Epoch 79/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.4284 - val_loss: 16.6478\n",
      "Epoch 80/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.2956 - val_loss: 16.7804\n",
      "Epoch 81/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.0802 - val_loss: 15.9601\n",
      "Epoch 82/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.8607 - val_loss: 15.8466\n",
      "Epoch 83/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 13.4429 - val_loss: 15.8193\n",
      "Epoch 84/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.7570 - val_loss: 16.7171\n",
      "Epoch 85/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.1603 - val_loss: 17.1562\n",
      "Epoch 86/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.2096 - val_loss: 17.8702\n",
      "Epoch 87/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.8527 - val_loss: 17.5049\n",
      "Epoch 88/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.8424 - val_loss: 15.9060\n",
      "Epoch 89/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.0007 - val_loss: 16.2487\n",
      "Epoch 90/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.7110 - val_loss: 16.5800\n",
      "Epoch 91/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.7714 - val_loss: 17.4496\n",
      "Epoch 92/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.3508 - val_loss: 16.3886\n",
      "Epoch 93/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.3764 - val_loss: 17.1960\n",
      "Epoch 94/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.6373 - val_loss: 16.9412\n",
      "Epoch 95/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.1407 - val_loss: 17.2399\n",
      "Epoch 96/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 12.2166 - val_loss: 16.6253\n",
      "Epoch 97/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.3887 - val_loss: 16.2245\n",
      "Epoch 98/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 12.5983 - val_loss: 16.7687\n",
      "Epoch 99/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.2057 - val_loss: 19.7280\n",
      "Epoch 100/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.6854 - val_loss: 15.8643\n",
      "Epoch 101/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.2097 - val_loss: 16.8211\n",
      "Epoch 102/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 12.0586 - val_loss: 16.1951\n",
      "Epoch 103/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.2637 - val_loss: 16.5231\n",
      "Epoch 104/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.9684 - val_loss: 16.5081\n",
      "Epoch 105/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.2353 - val_loss: 16.0598\n",
      "Epoch 106/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 12.1936 - val_loss: 16.1522\n",
      "Epoch 107/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.9545 - val_loss: 17.1376\n",
      "Epoch 108/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 12.3904 - val_loss: 17.1194\n",
      "Epoch 109/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.0122 - val_loss: 15.5753\n",
      "Epoch 110/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.1377 - val_loss: 16.4937\n",
      "Epoch 111/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 12.2937 - val_loss: 16.2548\n",
      "Epoch 112/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.2738 - val_loss: 17.8324\n",
      "Epoch 113/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.2780 - val_loss: 15.8850\n",
      "Epoch 114/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.6220 - val_loss: 15.5891\n",
      "Epoch 115/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.4554 - val_loss: 14.8590\n",
      "Epoch 116/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.4016 - val_loss: 16.1060\n",
      "Epoch 117/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 12.0237 - val_loss: 15.3102\n",
      "Epoch 118/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.9072 - val_loss: 14.5661\n",
      "Epoch 119/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.2755 - val_loss: 14.7983\n",
      "Epoch 120/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 12.0398 - val_loss: 20.9413\n",
      "Epoch 121/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 12.1106 - val_loss: 16.5730\n",
      "Epoch 122/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.0043 - val_loss: 15.6651\n",
      "Epoch 123/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 11.5869 - val_loss: 15.4575\n",
      "Epoch 124/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.6486 - val_loss: 14.4531\n",
      "Epoch 125/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.4674 - val_loss: 14.5958\n",
      "Epoch 126/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.6431 - val_loss: 15.4613\n",
      "Epoch 127/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.0983 - val_loss: 19.1082\n",
      "Epoch 128/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.6266 - val_loss: 14.2102\n",
      "Epoch 129/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.2370 - val_loss: 15.4168\n",
      "Epoch 130/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 12.4609 - val_loss: 19.7934\n",
      "Epoch 131/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.2488 - val_loss: 16.5871\n",
      "Epoch 132/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.9534 - val_loss: 14.7355\n",
      "Epoch 133/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.6138 - val_loss: 14.1487\n",
      "Epoch 134/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 10.8516 - val_loss: 15.6255\n",
      "Epoch 135/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.3377 - val_loss: 14.9534\n",
      "Epoch 136/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.9129 - val_loss: 14.5338\n",
      "Epoch 137/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.9189 - val_loss: 13.9636\n",
      "Epoch 138/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.2336 - val_loss: 14.1269\n",
      "Epoch 139/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.8470 - val_loss: 15.2193\n",
      "Epoch 140/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.9235 - val_loss: 14.0476\n",
      "Epoch 141/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.7160 - val_loss: 14.2855\n",
      "Epoch 142/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 10.7153 - val_loss: 14.5235\n",
      "Epoch 143/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.7820 - val_loss: 15.8269\n",
      "Epoch 144/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.3036 - val_loss: 13.4942\n",
      "Epoch 145/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.9606 - val_loss: 15.6504\n",
      "Epoch 146/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.3100 - val_loss: 15.3916\n",
      "Epoch 147/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.0549 - val_loss: 12.9387\n",
      "Epoch 148/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.7431 - val_loss: 14.4527\n",
      "Epoch 149/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.6468 - val_loss: 14.1621\n",
      "Epoch 150/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.2805 - val_loss: 14.7285\n",
      "Epoch 151/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.1826 - val_loss: 13.4828\n",
      "Epoch 152/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 10.4082 - val_loss: 13.1843\n",
      "Epoch 153/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.6650 - val_loss: 13.2886\n",
      "Epoch 154/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.8068 - val_loss: 12.4277\n",
      "Epoch 155/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.3889 - val_loss: 12.4014\n",
      "Epoch 156/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.0967 - val_loss: 12.4621\n",
      "Epoch 157/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.2081 - val_loss: 12.5826\n",
      "Epoch 158/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.2253 - val_loss: 13.8126\n",
      "Epoch 159/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.0122 - val_loss: 13.1561\n",
      "Epoch 160/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.1737 - val_loss: 12.5830\n",
      "Epoch 161/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.4696 - val_loss: 13.2090\n",
      "Epoch 162/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.3087 - val_loss: 13.3932\n",
      "Epoch 163/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.8984 - val_loss: 12.1833\n",
      "Epoch 164/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 10.4023 - val_loss: 13.6060\n",
      "Epoch 165/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.7429 - val_loss: 13.1221\n",
      "Epoch 166/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.0127 - val_loss: 12.8556\n",
      "Epoch 167/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 10.2566 - val_loss: 11.8614\n",
      "Epoch 168/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.8719 - val_loss: 11.6760\n",
      "Epoch 169/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.3400 - val_loss: 11.7090\n",
      "Epoch 170/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.5081 - val_loss: 11.6325\n",
      "Epoch 171/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.5500 - val_loss: 12.9908\n",
      "Epoch 172/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.6590 - val_loss: 11.6808\n",
      "Epoch 173/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.6322 - val_loss: 12.6913\n",
      "Epoch 174/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.7494 - val_loss: 11.2185\n",
      "Epoch 175/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.6212 - val_loss: 12.0300\n",
      "Epoch 176/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.2430 - val_loss: 14.5327\n",
      "Epoch 177/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.3383 - val_loss: 13.7935\n",
      "Epoch 178/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.1488 - val_loss: 11.7544\n",
      "Epoch 179/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.6998 - val_loss: 13.6839\n",
      "Epoch 180/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.4484 - val_loss: 11.9305\n",
      "Epoch 181/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.9904 - val_loss: 11.9681\n",
      "Epoch 182/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.9904 - val_loss: 11.8847\n",
      "Epoch 183/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.2766 - val_loss: 11.2728\n",
      "Epoch 184/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.1833 - val_loss: 11.5232\n",
      "Epoch 185/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.4215 - val_loss: 12.3586\n",
      "Epoch 186/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.5580 - val_loss: 11.1756\n",
      "Epoch 187/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.4513 - val_loss: 10.9629\n",
      "Epoch 188/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.2472 - val_loss: 13.8150\n",
      "Epoch 189/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.9032 - val_loss: 12.2020\n",
      "Epoch 190/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.2877 - val_loss: 12.0631\n",
      "Epoch 191/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.5926 - val_loss: 11.6271\n",
      "Epoch 192/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.5529 - val_loss: 13.1003\n",
      "Epoch 193/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.6219 - val_loss: 13.0797\n",
      "Epoch 194/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.4116 - val_loss: 11.6138\n",
      "Epoch 195/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.9833 - val_loss: 12.5064\n",
      "Epoch 196/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.7133 - val_loss: 11.1874\n",
      "Epoch 197/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.0950 - val_loss: 12.4966\n",
      "Epoch 198/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.7202 - val_loss: 11.4653\n",
      "Epoch 199/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.7636 - val_loss: 11.2309\n",
      "Epoch 200/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.4991 - val_loss: 11.3851\n",
      "Epoch 201/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.3089 - val_loss: 10.6030\n",
      "Epoch 202/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2976 - val_loss: 11.0992\n",
      "Epoch 203/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.6423 - val_loss: 11.4743\n",
      "Epoch 204/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.4128 - val_loss: 11.0224\n",
      "Epoch 205/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.6673 - val_loss: 11.0157\n",
      "Epoch 206/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.8101 - val_loss: 11.0536\n",
      "Epoch 207/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1762 - val_loss: 11.0916\n",
      "Epoch 208/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.9811 - val_loss: 12.8467\n",
      "Epoch 209/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2448 - val_loss: 14.9802\n",
      "Epoch 210/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.5838 - val_loss: 11.3478\n",
      "Epoch 211/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.4418 - val_loss: 12.6932\n",
      "Epoch 212/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.9648 - val_loss: 11.3943\n",
      "Epoch 213/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 9.7506 - val_loss: 11.2244\n",
      "Epoch 214/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 8.7235 - val_loss: 10.8177\n",
      "Epoch 215/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.2175 - val_loss: 11.0404\n",
      "Epoch 216/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 9.7578 - val_loss: 12.4244\n",
      "Epoch 217/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.4965 - val_loss: 11.9099\n",
      "Epoch 218/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 9.0958 - val_loss: 12.5061\n",
      "Epoch 219/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.1619 - val_loss: 11.3471\n",
      "Epoch 220/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.9929 - val_loss: 10.5916\n",
      "Epoch 221/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 9.2964 - val_loss: 10.5999\n",
      "Epoch 222/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.0030 - val_loss: 10.8517\n",
      "Epoch 223/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0695 - val_loss: 10.3595\n",
      "Epoch 224/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0601 - val_loss: 14.0655\n",
      "Epoch 225/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.5330 - val_loss: 11.4674\n",
      "Epoch 226/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6869 - val_loss: 10.7854\n",
      "Epoch 227/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.2417 - val_loss: 10.7273\n",
      "Epoch 228/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.3510 - val_loss: 11.9854\n",
      "Epoch 229/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.3517 - val_loss: 10.9531\n",
      "Epoch 230/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.4731 - val_loss: 10.6263\n",
      "Epoch 231/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.8467 - val_loss: 11.2538\n",
      "Epoch 232/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.0503 - val_loss: 11.0536\n",
      "Epoch 233/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0167 - val_loss: 12.6021\n",
      "Epoch 234/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9151 - val_loss: 11.9175\n",
      "Epoch 235/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.9696 - val_loss: 11.6330\n",
      "Epoch 236/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0092 - val_loss: 10.9680\n",
      "Epoch 237/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7527 - val_loss: 10.3150\n",
      "Epoch 238/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2090 - val_loss: 11.7614\n",
      "Epoch 239/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.9931 - val_loss: 11.8745\n",
      "Epoch 240/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.6812 - val_loss: 11.8203\n",
      "Epoch 241/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 10.1633 - val_loss: 11.0828\n",
      "Epoch 242/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.7349 - val_loss: 11.1000\n",
      "Epoch 243/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6910 - val_loss: 12.0255\n",
      "Epoch 244/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.1091 - val_loss: 11.1360\n",
      "Epoch 245/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 9.3620 - val_loss: 11.0181\n",
      "Epoch 246/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2746 - val_loss: 10.6925\n",
      "Epoch 247/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8145 - val_loss: 11.3559\n",
      "Epoch 248/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8865 - val_loss: 10.6700\n",
      "Epoch 249/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.0988 - val_loss: 10.7940\n",
      "Epoch 250/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7138 - val_loss: 10.7678\n",
      "Epoch 251/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6562 - val_loss: 10.6991\n",
      "Epoch 252/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7399 - val_loss: 10.1272\n",
      "Epoch 253/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.2433 - val_loss: 11.0794\n",
      "Epoch 254/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6949 - val_loss: 11.4438\n",
      "Epoch 255/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.3654 - val_loss: 10.5864\n",
      "Epoch 256/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.5910 - val_loss: 10.3597\n",
      "Epoch 257/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8424 - val_loss: 10.1888\n",
      "Epoch 258/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7422 - val_loss: 11.5619\n",
      "Epoch 259/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.2578 - val_loss: 10.4644\n",
      "Epoch 260/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2237 - val_loss: 9.7805\n",
      "Epoch 261/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7390 - val_loss: 10.0057\n",
      "Epoch 262/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3535 - val_loss: 9.9654\n",
      "Epoch 263/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7199 - val_loss: 11.0260\n",
      "Epoch 264/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2479 - val_loss: 11.4297\n",
      "Epoch 265/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3169 - val_loss: 10.6054\n",
      "Epoch 266/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.7128 - val_loss: 9.6470\n",
      "Epoch 267/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1753 - val_loss: 10.8842\n",
      "Epoch 268/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7744 - val_loss: 11.5313\n",
      "Epoch 269/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3160 - val_loss: 9.6851\n",
      "Epoch 270/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.6878 - val_loss: 10.5452\n",
      "Epoch 271/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.8613 - val_loss: 9.9314\n",
      "Epoch 272/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.5609 - val_loss: 9.7943\n",
      "Epoch 273/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.2984 - val_loss: 9.6573\n",
      "Epoch 274/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.8721 - val_loss: 8.8101\n",
      "Epoch 275/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.6097 - val_loss: 9.1362\n",
      "Epoch 276/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.3574 - val_loss: 9.7424\n",
      "Epoch 277/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 7.6291 - val_loss: 8.6535\n",
      "Epoch 278/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.9351 - val_loss: 9.0595\n",
      "Epoch 279/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3562 - val_loss: 9.1647\n",
      "Epoch 280/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.6316 - val_loss: 9.5840\n",
      "Epoch 281/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.5381 - val_loss: 8.5292\n",
      "Epoch 282/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.1481 - val_loss: 8.8371\n",
      "Epoch 283/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.0470 - val_loss: 9.3819\n",
      "Epoch 284/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.4674 - val_loss: 8.6384\n",
      "Epoch 285/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.2801 - val_loss: 10.0104\n",
      "Epoch 286/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.4432 - val_loss: 8.0376\n",
      "Epoch 287/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2097 - val_loss: 9.5495\n",
      "Epoch 288/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.1833 - val_loss: 8.2216\n",
      "Epoch 289/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.1557 - val_loss: 9.1088\n",
      "Epoch 290/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.1165 - val_loss: 9.5238\n",
      "Epoch 291/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.2178 - val_loss: 8.4932\n",
      "Epoch 292/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.2873 - val_loss: 7.8563\n",
      "Epoch 293/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.0517 - val_loss: 8.0664\n",
      "Epoch 294/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.0128 - val_loss: 8.4395\n",
      "Epoch 295/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.0073 - val_loss: 8.3492\n",
      "Epoch 296/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.8925 - val_loss: 8.2708\n",
      "Epoch 297/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.9149 - val_loss: 9.2355\n",
      "Epoch 298/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.3543 - val_loss: 8.1757\n",
      "Epoch 299/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.1434 - val_loss: 7.6893\n",
      "Epoch 300/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.1799 - val_loss: 8.1685\n",
      "Epoch 301/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.7147 - val_loss: 8.0553\n",
      "Epoch 302/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.0035 - val_loss: 8.6198\n",
      "Epoch 303/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.4628 - val_loss: 10.0259\n",
      "Epoch 304/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.3923 - val_loss: 7.5989\n",
      "Epoch 305/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.6761 - val_loss: 7.6473\n",
      "Epoch 306/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.8484 - val_loss: 8.2078\n",
      "Epoch 307/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.9524 - val_loss: 7.9163\n",
      "Epoch 308/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.1105 - val_loss: 7.6748\n",
      "Epoch 309/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.9525 - val_loss: 8.4689\n",
      "Epoch 310/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.0165 - val_loss: 7.6151\n",
      "Epoch 311/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.7235 - val_loss: 8.0891\n",
      "Epoch 312/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.8285 - val_loss: 8.0534\n",
      "Epoch 313/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.8576 - val_loss: 8.0186\n",
      "Epoch 314/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.8485 - val_loss: 8.0921\n",
      "Epoch 315/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.6106 - val_loss: 8.6328\n",
      "Epoch 316/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.1647 - val_loss: 8.2383\n",
      "Epoch 317/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.6320 - val_loss: 10.0574\n",
      "Epoch 318/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.2374 - val_loss: 7.7719\n",
      "Epoch 319/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.7321 - val_loss: 7.8649\n",
      "Epoch 320/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.8425 - val_loss: 8.2787\n",
      "Epoch 321/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.4566 - val_loss: 7.8927\n",
      "Epoch 322/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.1436 - val_loss: 7.6878\n",
      "Epoch 323/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.9465 - val_loss: 7.9109\n",
      "Epoch 324/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.8789 - val_loss: 8.9250\n",
      "Epoch 325/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.9919 - val_loss: 8.6113\n",
      "Epoch 326/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.8728 - val_loss: 8.2702\n",
      "Epoch 327/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.0144 - val_loss: 10.1433\n",
      "Epoch 328/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.3705 - val_loss: 8.5180\n",
      "Epoch 329/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.1597 - val_loss: 8.1542\n",
      "Epoch 330/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.6294 - val_loss: 7.3214\n",
      "Epoch 331/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.8066 - val_loss: 7.9139\n",
      "Epoch 332/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.9635 - val_loss: 8.3312\n",
      "Epoch 333/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.1023 - val_loss: 8.8156\n",
      "Epoch 334/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.7243 - val_loss: 8.8659\n",
      "Epoch 335/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.1687 - val_loss: 8.6805\n",
      "Epoch 336/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.7615 - val_loss: 7.2758\n",
      "Epoch 337/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.0161 - val_loss: 7.6378\n",
      "Epoch 338/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.5554 - val_loss: 9.6648\n",
      "Epoch 339/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.0423 - val_loss: 7.8506\n",
      "Epoch 340/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.9330 - val_loss: 7.5281\n",
      "Epoch 341/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.4228 - val_loss: 7.8790\n",
      "Epoch 342/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.0868 - val_loss: 8.5530\n",
      "Epoch 343/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.0318 - val_loss: 7.4320\n",
      "Epoch 344/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.2216 - val_loss: 7.7887\n",
      "Epoch 345/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.0039 - val_loss: 7.2785\n",
      "Epoch 346/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.8157 - val_loss: 8.1695\n",
      "Epoch 347/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.6816 - val_loss: 8.1349\n",
      "Epoch 348/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.4127 - val_loss: 7.2610\n",
      "Epoch 349/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.1108 - val_loss: 8.2113\n",
      "Epoch 350/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.6711 - val_loss: 7.8429\n",
      "Epoch 351/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.6543 - val_loss: 7.4616\n",
      "Epoch 352/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.7079 - val_loss: 7.6925\n",
      "Epoch 353/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.7501 - val_loss: 7.3159\n",
      "Epoch 354/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.4363 - val_loss: 8.0864\n",
      "Epoch 355/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.3931 - val_loss: 7.0177\n",
      "Epoch 356/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.5955 - val_loss: 7.5453\n",
      "Epoch 357/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.6697 - val_loss: 7.9227\n",
      "Epoch 358/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.7635 - val_loss: 7.3869\n",
      "Epoch 359/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.8269 - val_loss: 9.2097\n",
      "Epoch 360/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.7339 - val_loss: 7.4849\n",
      "Epoch 361/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.8698 - val_loss: 7.0781\n",
      "Epoch 362/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.8196 - val_loss: 7.5910\n",
      "Epoch 363/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.5798 - val_loss: 7.0743\n",
      "Epoch 364/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.3923 - val_loss: 7.0386\n",
      "Epoch 365/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.5359 - val_loss: 7.4741\n",
      "Epoch 366/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.7496 - val_loss: 7.5727\n",
      "Epoch 367/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.9154 - val_loss: 7.3627\n",
      "Epoch 368/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.7666 - val_loss: 7.6363\n",
      "Epoch 369/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.0496 - val_loss: 7.5110\n",
      "Epoch 370/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.5038 - val_loss: 7.5899\n",
      "Epoch 371/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.7578 - val_loss: 7.0897\n",
      "Epoch 372/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.5727 - val_loss: 8.7963\n",
      "Epoch 373/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.8030 - val_loss: 7.8483\n",
      "Epoch 374/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.4255 - val_loss: 9.2579\n",
      "Epoch 375/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.7593 - val_loss: 7.4403\n",
      "Epoch 376/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.3510 - val_loss: 8.8760\n",
      "Epoch 377/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 6.9074 - val_loss: 8.8336\n",
      "Epoch 378/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.4578 - val_loss: 8.2588\n",
      "Epoch 379/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.4992 - val_loss: 7.9200\n",
      "Epoch 380/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.1475 - val_loss: 7.2943\n",
      "Epoch 381/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.6734 - val_loss: 8.6975\n",
      "Epoch 382/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.7480 - val_loss: 8.5207\n",
      "Epoch 383/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.6556 - val_loss: 7.6039\n",
      "Epoch 384/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.8843 - val_loss: 9.7670\n",
      "Epoch 385/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.1181 - val_loss: 8.5039\n",
      "Epoch 386/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.4130 - val_loss: 7.1685\n",
      "Epoch 387/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 6.3710 - val_loss: 7.2028\n",
      "Epoch 388/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 6.5186 - val_loss: 7.6150\n",
      "Epoch 389/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 6.6471 - val_loss: 8.8903\n",
      "Epoch 390/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 6.8352 - val_loss: 7.4355\n",
      "Epoch 391/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 7.1640 - val_loss: 7.1106\n",
      "Epoch 392/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 6.6305 - val_loss: 7.2172\n",
      "Epoch 393/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 6.1839 - val_loss: 7.5723\n",
      "Epoch 394/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 6.1642 - val_loss: 6.9834\n",
      "Epoch 395/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.3629 - val_loss: 8.0974\n",
      "Epoch 396/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.3889 - val_loss: 7.2134\n",
      "Epoch 397/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.7759 - val_loss: 8.9022\n",
      "Epoch 398/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.8724 - val_loss: 6.6626\n",
      "Epoch 399/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.0665 - val_loss: 7.0083\n",
      "Epoch 400/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.5902 - val_loss: 7.7745\n",
      "Epoch 401/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.8586 - val_loss: 8.3038\n",
      "Epoch 402/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.6460 - val_loss: 7.4935\n",
      "Epoch 403/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.4824 - val_loss: 8.9691\n",
      "Epoch 404/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 6.7028 - val_loss: 7.3511\n",
      "Epoch 405/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 6.3501 - val_loss: 6.6573\n",
      "Epoch 406/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.2805 - val_loss: 7.2043\n",
      "Epoch 407/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.4220 - val_loss: 7.2934\n",
      "Epoch 408/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.8667 - val_loss: 6.8846\n",
      "Epoch 409/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.6356 - val_loss: 7.6740\n",
      "Epoch 410/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.2206 - val_loss: 6.7344\n",
      "Epoch 411/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.6133 - val_loss: 7.2203\n",
      "Epoch 412/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.3782 - val_loss: 6.9253\n",
      "Epoch 413/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.1978 - val_loss: 7.0372\n",
      "Epoch 414/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.2473 - val_loss: 7.8003\n",
      "Epoch 415/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.5764 - val_loss: 6.8820\n",
      "Epoch 416/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.2088 - val_loss: 7.5047\n",
      "Epoch 417/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.5239 - val_loss: 7.2462\n",
      "Epoch 418/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 6.5951 - val_loss: 6.9578\n",
      "Epoch 419/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 6.6485 - val_loss: 7.1815\n",
      "Epoch 420/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.5901 - val_loss: 7.2613\n",
      "Epoch 421/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 6.5459 - val_loss: 6.6237\n",
      "Epoch 422/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.1215 - val_loss: 6.8396\n",
      "Epoch 423/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.2864 - val_loss: 7.2118\n",
      "Epoch 424/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.4545 - val_loss: 6.8215\n",
      "Epoch 425/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 6.5669 - val_loss: 6.9883\n",
      "Epoch 426/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 6.5864 - val_loss: 7.5194\n",
      "Epoch 427/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 6.3119 - val_loss: 7.1501\n",
      "Epoch 428/1000\n",
      "1052/1052 [==============================] - 0s 108us/step - loss: 6.7769 - val_loss: 8.0904\n",
      "Epoch 429/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.3842 - val_loss: 6.9791\n",
      "Epoch 430/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 6.1469 - val_loss: 6.5641\n",
      "Epoch 431/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 6.9662 - val_loss: 7.0788\n",
      "Epoch 432/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.8690 - val_loss: 6.7465\n",
      "Epoch 433/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 6.4004 - val_loss: 6.2279\n",
      "Epoch 434/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 6.1478 - val_loss: 7.2412\n",
      "Epoch 435/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.5223 - val_loss: 6.4868\n",
      "Epoch 436/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 6.2344 - val_loss: 7.7838\n",
      "Epoch 437/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 6.3654 - val_loss: 6.5513\n",
      "Epoch 438/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 7.0997 - val_loss: 6.7055\n",
      "Epoch 439/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 7.8003 - val_loss: 6.8068\n",
      "Epoch 440/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.2127 - val_loss: 7.0765\n",
      "Epoch 441/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 6.2779 - val_loss: 6.9959\n",
      "Epoch 442/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.5209 - val_loss: 7.1331\n",
      "Epoch 443/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 6.4675 - val_loss: 6.6087\n",
      "Epoch 444/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.1057 - val_loss: 7.1457\n",
      "Epoch 445/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.4433 - val_loss: 6.9253\n",
      "Epoch 446/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.2348 - val_loss: 6.9579\n",
      "Epoch 447/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.2652 - val_loss: 6.7599\n",
      "Epoch 448/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.3374 - val_loss: 6.7362\n",
      "Epoch 449/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.6026 - val_loss: 6.5895\n",
      "Epoch 450/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.1393 - val_loss: 7.1969\n",
      "Epoch 451/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.1376 - val_loss: 6.3070\n",
      "Epoch 452/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.3108 - val_loss: 7.4087\n",
      "Epoch 453/1000\n",
      "1052/1052 [==============================] - 0s 119us/step - loss: 7.2622 - val_loss: 8.9318\n",
      "Epoch 454/1000\n",
      "1052/1052 [==============================] - 0s 113us/step - loss: 6.5353 - val_loss: 8.3830\n",
      "Epoch 455/1000\n",
      "1052/1052 [==============================] - 0s 112us/step - loss: 6.2308 - val_loss: 6.5465\n",
      "Epoch 456/1000\n",
      "1052/1052 [==============================] - 0s 108us/step - loss: 6.2098 - val_loss: 6.7421\n",
      "Epoch 457/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.4011 - val_loss: 6.6246\n",
      "Epoch 458/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.4477 - val_loss: 7.1388\n",
      "Epoch 459/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.7744 - val_loss: 7.5128\n",
      "Epoch 460/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 6.3607 - val_loss: 8.8864\n",
      "Epoch 461/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.3213 - val_loss: 6.4698\n",
      "Epoch 462/1000\n",
      "1052/1052 [==============================] - 0s 109us/step - loss: 6.2950 - val_loss: 7.3875\n",
      "Epoch 463/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 6.6770 - val_loss: 7.1882\n",
      "Epoch 464/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 6.4943 - val_loss: 6.8195\n",
      "Epoch 465/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.2478 - val_loss: 6.8549\n",
      "Epoch 466/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.6632 - val_loss: 6.7841\n",
      "Epoch 467/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.1933 - val_loss: 7.2125\n",
      "Epoch 468/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 6.6886 - val_loss: 6.6310\n",
      "Epoch 469/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.3009 - val_loss: 6.1929\n",
      "Epoch 470/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.1753 - val_loss: 6.3780\n",
      "Epoch 471/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 6.3896 - val_loss: 7.3581\n",
      "Epoch 472/1000\n",
      "1052/1052 [==============================] - 0s 108us/step - loss: 6.4149 - val_loss: 7.2579\n",
      "Epoch 473/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.2641 - val_loss: 6.8293\n",
      "Epoch 474/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 6.1902 - val_loss: 7.7849\n",
      "Epoch 475/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 6.1371 - val_loss: 7.1905\n",
      "Epoch 476/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 6.1132 - val_loss: 6.6623\n",
      "Epoch 477/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.8577 - val_loss: 6.4436\n",
      "Epoch 478/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.2206 - val_loss: 6.4978\n",
      "Epoch 479/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.2604 - val_loss: 6.5419\n",
      "Epoch 480/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.6692 - val_loss: 7.7388\n",
      "Epoch 481/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.1761 - val_loss: 6.3695\n",
      "Epoch 482/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 6.0764 - val_loss: 8.4637\n",
      "Epoch 483/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 6.7700 - val_loss: 6.4953\n",
      "Epoch 484/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.0666 - val_loss: 6.2979\n",
      "Epoch 485/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.2911 - val_loss: 6.6914\n",
      "Epoch 486/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.1855 - val_loss: 6.5619\n",
      "Epoch 487/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.9875 - val_loss: 6.5281\n",
      "Epoch 488/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.2044 - val_loss: 6.9619\n",
      "Epoch 489/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.1260 - val_loss: 6.3845\n",
      "Epoch 490/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.2240 - val_loss: 6.3520\n",
      "Epoch 491/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.9385 - val_loss: 7.1767\n",
      "Epoch 492/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.6636 - val_loss: 8.4092\n",
      "Epoch 493/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.5817 - val_loss: 6.6337\n",
      "Epoch 494/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.1439 - val_loss: 6.5640\n",
      "Epoch 495/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.3886 - val_loss: 6.6427\n",
      "Epoch 496/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 6.0106 - val_loss: 7.7259\n",
      "Epoch 497/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.5377 - val_loss: 6.4538\n",
      "Epoch 498/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 6.0225 - val_loss: 7.1508\n",
      "Epoch 499/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.4786 - val_loss: 7.6652\n",
      "Epoch 500/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.8753 - val_loss: 6.9350\n",
      "Epoch 501/1000\n",
      "1052/1052 [==============================] - 0s 119us/step - loss: 6.1515 - val_loss: 7.0893\n",
      "Epoch 502/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 6.2415 - val_loss: 6.4342\n",
      "Epoch 503/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.1432 - val_loss: 7.1351\n",
      "Epoch 504/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.8880 - val_loss: 6.1976\n",
      "Epoch 505/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.9078 - val_loss: 6.6005\n",
      "Epoch 506/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 6.6028 - val_loss: 6.0313\n",
      "Epoch 507/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 6.251 - 0s 93us/step - loss: 6.0925 - val_loss: 6.5737\n",
      "Epoch 508/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 6.2444 - val_loss: 7.5789\n",
      "Epoch 509/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 6.1925 - val_loss: 6.6181\n",
      "Epoch 510/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 5.8440 - val_loss: 7.0815\n",
      "Epoch 511/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 6.0784 - val_loss: 7.5702\n",
      "Epoch 512/1000\n",
      "1052/1052 [==============================] - 0s 111us/step - loss: 6.3674 - val_loss: 7.2525\n",
      "Epoch 513/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 5.8025 - val_loss: 6.2228\n",
      "Epoch 514/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.8836 - val_loss: 7.4655\n",
      "Epoch 515/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 6.1707 - val_loss: 7.5340\n",
      "Epoch 516/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.7482 - val_loss: 6.3774\n",
      "Epoch 517/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.5539 - val_loss: 6.6550\n",
      "Epoch 518/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.1023 - val_loss: 6.4955\n",
      "Epoch 519/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.2089 - val_loss: 5.8910\n",
      "Epoch 520/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 5.9430 - val_loss: 6.3921\n",
      "Epoch 521/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 103us/step - loss: 5.9817 - val_loss: 6.1282\n",
      "Epoch 522/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 5.9538 - val_loss: 7.2494\n",
      "Epoch 523/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.1012 - val_loss: 6.7864\n",
      "Epoch 524/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 5.8613 - val_loss: 6.3980\n",
      "Epoch 525/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 5.9027 - val_loss: 6.5703\n",
      "Epoch 526/1000\n",
      "1052/1052 [==============================] - 0s 114us/step - loss: 6.5907 - val_loss: 9.7176\n",
      "Epoch 527/1000\n",
      "1052/1052 [==============================] - 0s 110us/step - loss: 6.0362 - val_loss: 7.0352\n",
      "Epoch 528/1000\n",
      "1052/1052 [==============================] - 0s 110us/step - loss: 5.9950 - val_loss: 6.5171\n",
      "Epoch 529/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 6.0777 - val_loss: 6.4024\n",
      "Epoch 530/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.9450 - val_loss: 7.0059\n",
      "Epoch 531/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.1384 - val_loss: 6.6076\n",
      "Epoch 532/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.0054 - val_loss: 6.7838\n",
      "Epoch 533/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.0577 - val_loss: 6.2629\n",
      "Epoch 534/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 6.0405 - val_loss: 6.7318\n",
      "Epoch 535/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 6.3318 - val_loss: 9.7942\n",
      "Epoch 536/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.6335 - val_loss: 8.8831\n",
      "Epoch 537/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 6.5664 - val_loss: 8.8036\n",
      "Epoch 538/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 6.5493 - val_loss: 6.7687\n",
      "Epoch 539/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 6.5677 - val_loss: 6.7195\n",
      "Epoch 540/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 5.9505 - val_loss: 7.5301\n",
      "Epoch 541/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 6.3566 - val_loss: 8.1198\n",
      "Epoch 542/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.3910 - val_loss: 7.0347\n",
      "Epoch 543/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 6.2303 - val_loss: 6.2384\n",
      "Epoch 544/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 6.3656 - val_loss: 6.6439\n",
      "Epoch 545/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 6.1299 - val_loss: 6.9021\n",
      "Epoch 546/1000\n",
      "1052/1052 [==============================] - 0s 145us/step - loss: 6.1899 - val_loss: 6.6180\n",
      "Epoch 547/1000\n",
      "1052/1052 [==============================] - 0s 124us/step - loss: 6.0833 - val_loss: 7.6932\n",
      "Epoch 548/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 5.8071 - val_loss: 6.7021\n",
      "Epoch 549/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 5.9331 - val_loss: 6.4870\n",
      "Epoch 550/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 5.9079 - val_loss: 6.8398\n",
      "Epoch 551/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 6.0048 - val_loss: 6.1827\n",
      "Epoch 552/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 6.0347 - val_loss: 6.6235\n",
      "Epoch 553/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 6.0210 - val_loss: 6.8243\n",
      "Epoch 554/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 5.8773 - val_loss: 6.6383\n",
      "Epoch 555/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.1280 - val_loss: 7.0428\n",
      "Epoch 556/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.0685 - val_loss: 6.0948\n",
      "Epoch 557/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.9420 - val_loss: 6.2119\n",
      "Epoch 558/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 5.693 - 0s 91us/step - loss: 6.1931 - val_loss: 6.1602\n",
      "Epoch 559/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 5.9274 - val_loss: 6.3557\n",
      "Epoch 560/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.0226 - val_loss: 6.2859\n",
      "Epoch 561/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.9609 - val_loss: 6.5139\n",
      "Epoch 562/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.8790 - val_loss: 6.3767\n",
      "Epoch 563/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.7889 - val_loss: 6.6848\n",
      "Epoch 564/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.0505 - val_loss: 6.1755\n",
      "Epoch 565/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 6.0800 - val_loss: 6.5692\n",
      "Epoch 566/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.8358 - val_loss: 6.5636\n",
      "Epoch 567/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.5940 - val_loss: 8.3374\n",
      "Epoch 568/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.5790 - val_loss: 10.6594\n",
      "Epoch 569/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 6.7278 - val_loss: 7.2803\n",
      "Epoch 570/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 6.6564 - val_loss: 8.2557\n",
      "Epoch 571/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.0223 - val_loss: 7.5469\n",
      "Epoch 572/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 6.2941 - val_loss: 7.1928\n",
      "Epoch 573/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.0910 - val_loss: 6.2893\n",
      "Epoch 574/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.4325 - val_loss: 6.3989\n",
      "Epoch 575/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 5.8607 - val_loss: 6.0385\n",
      "Epoch 576/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.7564 - val_loss: 7.4364\n",
      "Epoch 577/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 6.0022 - val_loss: 5.9808\n",
      "Epoch 578/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.9662 - val_loss: 6.7160\n",
      "Epoch 579/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 6.1467 - val_loss: 6.6464\n",
      "Epoch 580/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.9090 - val_loss: 6.4160\n",
      "Epoch 581/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 5.9447 - val_loss: 6.7069\n",
      "Epoch 582/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 5.8002 - val_loss: 6.7953\n",
      "Epoch 583/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 6.1321 - val_loss: 6.2396\n",
      "Epoch 584/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.8518 - val_loss: 6.1623\n",
      "Epoch 585/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.0433 - val_loss: 5.9310\n",
      "Epoch 586/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 6.2970 - val_loss: 6.7462\n",
      "Epoch 587/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.8957 - val_loss: 6.1213\n",
      "Epoch 588/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.8341 - val_loss: 6.0471\n",
      "Epoch 589/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.8780 - val_loss: 6.0331\n",
      "Epoch 590/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.7231 - val_loss: 7.1933\n",
      "Epoch 591/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.8301 - val_loss: 6.5768\n",
      "Epoch 592/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.9483 - val_loss: 6.7352\n",
      "Epoch 593/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 6.2883 - val_loss: 6.1961\n",
      "Epoch 594/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 6.4843 - val_loss: 5.9537\n",
      "Epoch 595/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.7933 - val_loss: 6.1709\n",
      "Epoch 596/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.7566 - val_loss: 8.0169\n",
      "Epoch 597/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 6.1183 - val_loss: 6.4351\n",
      "Epoch 598/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 6.0349 - val_loss: 6.6204\n",
      "Epoch 599/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 6.0522 - val_loss: 5.8580\n",
      "Epoch 600/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 5.9817 - val_loss: 7.6618\n",
      "Epoch 601/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.1543 - val_loss: 6.8261\n",
      "Epoch 602/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.2483 - val_loss: 7.1169\n",
      "Epoch 603/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.9227 - val_loss: 5.9293\n",
      "Epoch 604/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 5.8498 - val_loss: 6.3472\n",
      "Epoch 605/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.8328 - val_loss: 6.7310\n",
      "Epoch 606/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.1598 - val_loss: 5.9788\n",
      "Epoch 607/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.0160 - val_loss: 6.6363\n",
      "Epoch 608/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.2321 - val_loss: 5.9998\n",
      "Epoch 609/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.8462 - val_loss: 6.5963\n",
      "Epoch 610/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 6.1245 - val_loss: 6.8589\n",
      "Epoch 611/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 6.0625 - val_loss: 6.0382\n",
      "Epoch 612/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 5.6521 - val_loss: 6.0606\n",
      "Epoch 613/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.7982 - val_loss: 6.8308\n",
      "Epoch 614/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 6.1517 - val_loss: 6.0952\n",
      "Epoch 615/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 6.2560 - val_loss: 6.3175\n",
      "Epoch 616/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 5.8545 - val_loss: 7.1759\n",
      "Epoch 617/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.4487 - val_loss: 6.1749\n",
      "Epoch 618/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 6.0605 - val_loss: 5.7780\n",
      "Epoch 619/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 5.9257 - val_loss: 5.8788\n",
      "Epoch 620/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 6.1533 - val_loss: 6.4360\n",
      "Epoch 621/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.0346 - val_loss: 6.0191\n",
      "Epoch 622/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.9548 - val_loss: 6.2867\n",
      "Epoch 623/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 5.8767 - val_loss: 7.3403\n",
      "Epoch 624/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 5.9044 - val_loss: 6.5950\n",
      "Epoch 625/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.7265 - val_loss: 5.6772\n",
      "Epoch 626/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.7909 - val_loss: 6.5639\n",
      "Epoch 627/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.4598 - val_loss: 6.8055\n",
      "Epoch 628/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 6.0060 - val_loss: 6.1440\n",
      "Epoch 629/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 5.8549 - val_loss: 6.6921\n",
      "Epoch 630/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 5.7226 - val_loss: 6.0483\n",
      "Epoch 631/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 5.6791 - val_loss: 5.5944\n",
      "Epoch 632/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.7357 - val_loss: 6.0935\n",
      "Epoch 633/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.8701 - val_loss: 5.9814\n",
      "Epoch 634/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.9447 - val_loss: 6.1924\n",
      "Epoch 635/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.7918 - val_loss: 5.6995\n",
      "Epoch 636/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.8293 - val_loss: 6.3164\n",
      "Epoch 637/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.6642 - val_loss: 6.3595\n",
      "Epoch 638/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.7777 - val_loss: 6.3924\n",
      "Epoch 639/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.9542 - val_loss: 5.7599\n",
      "Epoch 640/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.7645 - val_loss: 6.4752\n",
      "Epoch 641/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.6251 - val_loss: 6.3222\n",
      "Epoch 642/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.9660 - val_loss: 6.1363\n",
      "Epoch 643/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.7855 - val_loss: 6.2331\n",
      "Epoch 644/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.1701 - val_loss: 6.1702\n",
      "Epoch 645/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.5627 - val_loss: 6.5333\n",
      "Epoch 646/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.4150 - val_loss: 10.7625\n",
      "Epoch 647/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.8336 - val_loss: 7.1685\n",
      "Epoch 648/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.6976 - val_loss: 7.3047\n",
      "Epoch 649/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.3282 - val_loss: 5.9591\n",
      "Epoch 650/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.3004 - val_loss: 6.8915\n",
      "Epoch 651/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.7705 - val_loss: 5.8757\n",
      "Epoch 652/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.6378 - val_loss: 6.0823\n",
      "Epoch 653/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.7692 - val_loss: 6.2823\n",
      "Epoch 654/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.5145 - val_loss: 6.5609\n",
      "Epoch 655/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.9351 - val_loss: 5.7123\n",
      "Epoch 656/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.9126 - val_loss: 6.7820\n",
      "Epoch 657/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.8939 - val_loss: 5.9810\n",
      "Epoch 658/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.7465 - val_loss: 5.8093\n",
      "Epoch 659/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.7775 - val_loss: 5.9529\n",
      "Epoch 660/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.7242 - val_loss: 6.2488\n",
      "Epoch 661/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.8303 - val_loss: 5.8269\n",
      "Epoch 662/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 6.0549 - val_loss: 6.1078\n",
      "Epoch 663/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.0534 - val_loss: 6.2745\n",
      "Epoch 664/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.0144 - val_loss: 5.6090\n",
      "Epoch 665/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.9227 - val_loss: 6.3069\n",
      "Epoch 666/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.9083 - val_loss: 5.8037\n",
      "Epoch 667/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.5811 - val_loss: 6.2684\n",
      "Epoch 668/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.8719 - val_loss: 7.5530\n",
      "Epoch 669/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.1300 - val_loss: 5.8559\n",
      "Epoch 670/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.8231 - val_loss: 6.2683\n",
      "Epoch 671/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.7641 - val_loss: 6.1974\n",
      "Epoch 672/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6833 - val_loss: 5.9564\n",
      "Epoch 673/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.9410 - val_loss: 6.1929\n",
      "Epoch 674/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.8229 - val_loss: 6.0715\n",
      "Epoch 675/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.5587 - val_loss: 5.9616\n",
      "Epoch 676/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6247 - val_loss: 6.0870\n",
      "Epoch 677/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6747 - val_loss: 7.9747\n",
      "Epoch 678/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.6010 - val_loss: 5.9551\n",
      "Epoch 679/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.0820 - val_loss: 7.0287\n",
      "Epoch 680/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.0568 - val_loss: 6.4650\n",
      "Epoch 681/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 6.6820 - val_loss: 7.1205\n",
      "Epoch 682/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.1849 - val_loss: 6.1544\n",
      "Epoch 683/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.8653 - val_loss: 5.8482\n",
      "Epoch 684/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.8924 - val_loss: 7.4465\n",
      "Epoch 685/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6728 - val_loss: 6.2388\n",
      "Epoch 686/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.9090 - val_loss: 6.7095\n",
      "Epoch 687/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6272 - val_loss: 6.0713\n",
      "Epoch 688/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 5.6563 - val_loss: 6.0540\n",
      "Epoch 689/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 6.1324 - val_loss: 5.7371\n",
      "Epoch 690/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.8612 - val_loss: 6.3616\n",
      "Epoch 691/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.1188 - val_loss: 6.0821\n",
      "Epoch 692/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.9772 - val_loss: 6.2400\n",
      "Epoch 693/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.9997 - val_loss: 7.3727\n",
      "Epoch 694/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.3063 - val_loss: 5.7468\n",
      "Epoch 695/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.1070 - val_loss: 6.4735\n",
      "Epoch 696/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.1286 - val_loss: 6.2339\n",
      "Epoch 697/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.5050 - val_loss: 5.6697\n",
      "Epoch 698/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.6205 - val_loss: 5.7786\n",
      "Epoch 699/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.0585 - val_loss: 5.9798\n",
      "Epoch 700/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.0177 - val_loss: 5.7464\n",
      "Epoch 701/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.9535 - val_loss: 7.0125\n",
      "Epoch 702/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.8155 - val_loss: 5.9564\n",
      "Epoch 703/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.5334 - val_loss: 5.5666\n",
      "Epoch 704/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.9244 - val_loss: 6.2108\n",
      "Epoch 705/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6614 - val_loss: 6.7539\n",
      "Epoch 706/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.7561 - val_loss: 5.8801\n",
      "Epoch 707/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.5481 - val_loss: 6.2681\n",
      "Epoch 708/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.8588 - val_loss: 6.5077\n",
      "Epoch 709/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.5422 - val_loss: 6.3654\n",
      "Epoch 710/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.9250 - val_loss: 6.0869\n",
      "Epoch 711/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 5.6474 - val_loss: 6.8968\n",
      "Epoch 712/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 5.7849 - val_loss: 5.7345\n",
      "Epoch 713/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 5.6373 - val_loss: 6.3760\n",
      "Epoch 714/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 5.4728 - val_loss: 6.1127\n",
      "Epoch 715/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 5.7497 - val_loss: 6.4782\n",
      "Epoch 716/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 5.8449 - val_loss: 6.4052\n",
      "Epoch 717/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 5.9364 - val_loss: 7.7698\n",
      "Epoch 718/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.8575 - val_loss: 5.7595\n",
      "Epoch 719/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.9713 - val_loss: 6.7419\n",
      "Epoch 720/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.8351 - val_loss: 5.7188\n",
      "Epoch 721/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.7126 - val_loss: 6.6413\n",
      "Epoch 722/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.5998 - val_loss: 5.7533\n",
      "Epoch 723/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.7907 - val_loss: 5.9619\n",
      "Epoch 724/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.7336 - val_loss: 6.4083\n",
      "Epoch 725/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.9124 - val_loss: 5.7470\n",
      "Epoch 726/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6256 - val_loss: 6.0840\n",
      "Epoch 727/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.7250 - val_loss: 6.1759\n",
      "Epoch 728/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.7752 - val_loss: 5.7552\n",
      "Epoch 729/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.6808 - val_loss: 6.9694\n",
      "Epoch 730/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.6519 - val_loss: 6.1424\n",
      "Epoch 731/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.4824 - val_loss: 6.1803\n",
      "Epoch 732/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.8242 - val_loss: 5.8724\n",
      "Epoch 733/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.2617 - val_loss: 6.5188\n",
      "Epoch 734/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.5154 - val_loss: 8.1133\n",
      "Epoch 735/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.2845 - val_loss: 7.1526\n",
      "Epoch 736/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.6103 - val_loss: 6.0505\n",
      "Epoch 737/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.8382 - val_loss: 6.0046\n",
      "Epoch 738/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.6492 - val_loss: 5.5336\n",
      "Epoch 739/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.5745 - val_loss: 6.7735\n",
      "Epoch 740/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.7475 - val_loss: 6.1644\n",
      "Epoch 741/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.8573 - val_loss: 9.1089\n",
      "Epoch 742/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.2363 - val_loss: 5.9842\n",
      "Epoch 743/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.3880 - val_loss: 6.2524\n",
      "Epoch 744/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6584 - val_loss: 7.3391\n",
      "Epoch 745/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.0035 - val_loss: 6.5057\n",
      "Epoch 746/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.8450 - val_loss: 8.3137\n",
      "Epoch 747/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.5473 - val_loss: 6.1958\n",
      "Epoch 748/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.7241 - val_loss: 7.3071\n",
      "Epoch 749/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.8620 - val_loss: 5.9196\n",
      "Epoch 750/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.7787 - val_loss: 6.0676\n",
      "Epoch 751/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.0196 - val_loss: 6.7565\n",
      "Epoch 752/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.8808 - val_loss: 6.2967\n",
      "Epoch 753/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.7184 - val_loss: 5.9832\n",
      "Epoch 754/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.6508 - val_loss: 6.7057\n",
      "Epoch 755/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6885 - val_loss: 5.9209\n",
      "Epoch 756/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.7811 - val_loss: 5.6695\n",
      "Epoch 757/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.9197 - val_loss: 7.1355\n",
      "Epoch 758/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.7865 - val_loss: 5.9757\n",
      "Epoch 759/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.9166 - val_loss: 5.4755\n",
      "Epoch 760/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.7195 - val_loss: 5.9598\n",
      "Epoch 761/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.7424 - val_loss: 9.8505\n",
      "Epoch 762/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.9868 - val_loss: 6.1063\n",
      "Epoch 763/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.9765 - val_loss: 6.1211\n",
      "Epoch 764/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.7909 - val_loss: 6.4791\n",
      "Epoch 765/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.1121 - val_loss: 6.1724\n",
      "Epoch 766/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6612 - val_loss: 6.3596\n",
      "Epoch 767/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.8535 - val_loss: 5.8643\n",
      "Epoch 768/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.4594 - val_loss: 6.8522\n",
      "Epoch 769/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.6633 - val_loss: 6.0738\n",
      "Epoch 770/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.6037 - val_loss: 6.2094\n",
      "Epoch 771/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.8067 - val_loss: 5.4430\n",
      "Epoch 772/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.5042 - val_loss: 5.6190\n",
      "Epoch 773/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.3803 - val_loss: 5.4345\n",
      "Epoch 774/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6848 - val_loss: 5.6254\n",
      "Epoch 775/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.5626 - val_loss: 5.7965\n",
      "Epoch 776/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.7465 - val_loss: 6.5803\n",
      "Epoch 777/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.5527 - val_loss: 5.4586\n",
      "Epoch 778/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6147 - val_loss: 5.5767\n",
      "Epoch 779/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.6369 - val_loss: 5.6918\n",
      "Epoch 780/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.7557 - val_loss: 5.4817\n",
      "Epoch 781/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6913 - val_loss: 6.1258\n",
      "Epoch 782/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.4731 - val_loss: 5.6136\n",
      "Epoch 783/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.7455 - val_loss: 5.6599\n",
      "Epoch 784/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.8178 - val_loss: 5.6429\n",
      "Epoch 785/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.5968 - val_loss: 5.5497\n",
      "Epoch 786/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.4341 - val_loss: 5.6828\n",
      "Epoch 787/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6955 - val_loss: 6.1895\n",
      "Epoch 788/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.7382 - val_loss: 5.8739\n",
      "Epoch 789/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.0442 - val_loss: 5.9321\n",
      "Epoch 790/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.5845 - val_loss: 5.5356\n",
      "Epoch 791/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.4881 - val_loss: 5.5450\n",
      "Epoch 792/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.8420 - val_loss: 5.6575\n",
      "Epoch 793/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.8765 - val_loss: 6.0475\n",
      "Epoch 794/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.9557 - val_loss: 5.9585\n",
      "Epoch 795/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6880 - val_loss: 6.3343\n",
      "Epoch 796/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.7252 - val_loss: 6.3605\n",
      "Epoch 797/1000\n",
      "1052/1052 [==============================] - 0s 119us/step - loss: 5.5624 - val_loss: 5.9856\n",
      "Epoch 798/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.6279 - val_loss: 5.8959\n",
      "Epoch 799/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.5512 - val_loss: 5.8190\n",
      "Epoch 800/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6264 - val_loss: 5.5140\n",
      "Epoch 801/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.4903 - val_loss: 7.1066\n",
      "Epoch 802/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.5553 - val_loss: 6.3693\n",
      "Epoch 803/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 5.8411 - val_loss: 5.3888\n",
      "Epoch 804/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.4441 - val_loss: 5.5768\n",
      "Epoch 805/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.6417 - val_loss: 5.9698\n",
      "Epoch 806/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.0394 - val_loss: 6.2700\n",
      "Epoch 807/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.8139 - val_loss: 6.0962\n",
      "Epoch 808/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.4162 - val_loss: 6.2167\n",
      "Epoch 809/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.0768 - val_loss: 5.8944\n",
      "Epoch 810/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.4835 - val_loss: 6.1868\n",
      "Epoch 811/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.5055 - val_loss: 5.6721\n",
      "Epoch 812/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6322 - val_loss: 5.4920\n",
      "Epoch 813/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.4977 - val_loss: 5.4627\n",
      "Epoch 814/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.5839 - val_loss: 6.4353\n",
      "Epoch 815/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.5377 - val_loss: 6.5940\n",
      "Epoch 816/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.6012 - val_loss: 5.5428\n",
      "Epoch 817/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.9619 - val_loss: 6.7294\n",
      "Epoch 818/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.9444 - val_loss: 6.4288\n",
      "Epoch 819/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.8317 - val_loss: 7.3624\n",
      "Epoch 820/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.6318 - val_loss: 5.8759\n",
      "Epoch 821/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.5961 - val_loss: 5.9565\n",
      "Epoch 822/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.4822 - val_loss: 5.3365\n",
      "Epoch 823/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.7131 - val_loss: 6.4291\n",
      "Epoch 824/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.5735 - val_loss: 5.6044\n",
      "Epoch 825/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.7952 - val_loss: 6.3428\n",
      "Epoch 826/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.5813 - val_loss: 5.9974\n",
      "Epoch 827/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.4520 - val_loss: 5.8833\n",
      "Epoch 828/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.2847 - val_loss: 5.2145\n",
      "Epoch 829/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.6017 - val_loss: 5.9852\n",
      "Epoch 830/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.5959 - val_loss: 6.8105\n",
      "Epoch 831/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.6951 - val_loss: 5.8493\n",
      "Epoch 832/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 5.5401 - val_loss: 6.2510\n",
      "Epoch 833/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.7025 - val_loss: 5.7217\n",
      "Epoch 834/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.4994 - val_loss: 5.4494\n",
      "Epoch 835/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.9726 - val_loss: 6.1690\n",
      "Epoch 836/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.1189 - val_loss: 5.8528\n",
      "Epoch 837/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.3885 - val_loss: 5.6796\n",
      "Epoch 838/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.4010 - val_loss: 6.2738\n",
      "Epoch 839/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.4657 - val_loss: 5.5710\n",
      "Epoch 840/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6991 - val_loss: 6.2563\n",
      "Epoch 841/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.7747 - val_loss: 6.6760\n",
      "Epoch 842/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.5502 - val_loss: 5.8954\n",
      "Epoch 843/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.7166 - val_loss: 5.5500\n",
      "Epoch 844/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.6520 - val_loss: 5.4413\n",
      "Epoch 845/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.7926 - val_loss: 6.9514\n",
      "Epoch 846/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.5656 - val_loss: 5.3550\n",
      "Epoch 847/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.5528 - val_loss: 5.7584\n",
      "Epoch 848/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.5721 - val_loss: 6.1863\n",
      "Epoch 849/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.6217 - val_loss: 5.8169\n",
      "Epoch 850/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.5152 - val_loss: 6.3677\n",
      "Epoch 851/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.7883 - val_loss: 5.7060\n",
      "Epoch 852/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 5.3696 - val_loss: 6.1289\n",
      "Epoch 853/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.7775 - val_loss: 5.9973\n",
      "Epoch 854/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.3003 - val_loss: 5.4982\n",
      "Epoch 855/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.3840 - val_loss: 5.5244\n",
      "Epoch 856/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.7865 - val_loss: 5.4456\n",
      "Epoch 857/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.9359 - val_loss: 5.8736\n",
      "Epoch 858/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.9411 - val_loss: 5.4183\n",
      "Epoch 859/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.5564 - val_loss: 5.2522\n",
      "Epoch 860/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.8422 - val_loss: 5.9522\n",
      "Epoch 861/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.3510 - val_loss: 6.1908\n",
      "Epoch 862/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.7319 - val_loss: 6.6870\n",
      "Epoch 863/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.9514 - val_loss: 5.9176\n",
      "Epoch 864/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.6838 - val_loss: 5.7758\n",
      "Epoch 865/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.4499 - val_loss: 6.0311\n",
      "Epoch 866/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.4391 - val_loss: 5.3268\n",
      "Epoch 867/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.4572 - val_loss: 6.4113\n",
      "Epoch 868/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 5.7741 - val_loss: 6.7981\n",
      "Epoch 869/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.3633 - val_loss: 5.2182\n",
      "Epoch 870/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.5347 - val_loss: 5.6902\n",
      "Epoch 871/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6965 - val_loss: 5.8501\n",
      "Epoch 872/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.8120 - val_loss: 5.6485\n",
      "Epoch 873/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.5767 - val_loss: 5.4940\n",
      "Epoch 874/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.4578 - val_loss: 5.5078\n",
      "Epoch 875/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.4023 - val_loss: 5.6934\n",
      "Epoch 876/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.8877 - val_loss: 6.2723\n",
      "Epoch 877/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.7516 - val_loss: 5.6095\n",
      "Epoch 878/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.6081 - val_loss: 5.4272\n",
      "Epoch 879/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.5707 - val_loss: 5.9041\n",
      "Epoch 880/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.6691 - val_loss: 6.7552\n",
      "Epoch 881/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.6286 - val_loss: 6.2159\n",
      "Epoch 882/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.7231 - val_loss: 5.9319\n",
      "Epoch 883/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 6.2145 - val_loss: 5.6298\n",
      "Epoch 884/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 5.6571 - val_loss: 5.7121\n",
      "Epoch 885/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 5.5146 - val_loss: 5.4202\n",
      "Epoch 886/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 5.8142 - val_loss: 5.9040\n",
      "Epoch 887/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 5.6372 - val_loss: 5.3595\n",
      "Epoch 888/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 5.4869 - val_loss: 5.9357\n",
      "Epoch 889/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 5.6900 - val_loss: 6.9269\n",
      "Epoch 890/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 6.0884 - val_loss: 5.7857\n",
      "Epoch 891/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.8083 - val_loss: 5.3316\n",
      "Epoch 892/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.7883 - val_loss: 6.0106\n",
      "Epoch 893/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.5430 - val_loss: 5.5519\n",
      "Epoch 894/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.8258 - val_loss: 5.6111\n",
      "Epoch 895/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.8224 - val_loss: 5.4184\n",
      "Epoch 896/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.7893 - val_loss: 6.0913\n",
      "Epoch 897/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.4693 - val_loss: 5.2352\n",
      "Epoch 898/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.4513 - val_loss: 7.2747\n",
      "Epoch 899/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.7122 - val_loss: 5.3645\n",
      "Epoch 900/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.6766 - val_loss: 5.5248\n",
      "Epoch 901/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.8377 - val_loss: 5.4528\n",
      "Epoch 902/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.3816 - val_loss: 5.6572\n",
      "Epoch 903/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.2738 - val_loss: 5.5599\n",
      "Epoch 904/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.4827 - val_loss: 5.4949\n",
      "Epoch 905/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.6794 - val_loss: 7.7306\n",
      "Epoch 906/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.0127 - val_loss: 5.3750\n",
      "Epoch 907/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.7391 - val_loss: 5.3757\n",
      "Epoch 908/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.3480 - val_loss: 5.9563\n",
      "Epoch 909/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.7575 - val_loss: 5.7492\n",
      "Epoch 910/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.2564 - val_loss: 6.2572\n",
      "Epoch 911/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.7219 - val_loss: 5.6780\n",
      "Epoch 912/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.8570 - val_loss: 6.3153\n",
      "Epoch 913/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.6917 - val_loss: 5.4319\n",
      "Epoch 914/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.4121 - val_loss: 5.0857\n",
      "Epoch 915/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.4374 - val_loss: 5.4221\n",
      "Epoch 916/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.4393 - val_loss: 5.5923\n",
      "Epoch 917/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.5025 - val_loss: 7.0204\n",
      "Epoch 918/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.5973 - val_loss: 6.4978\n",
      "Epoch 919/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.6929 - val_loss: 8.0784\n",
      "Epoch 920/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.8255 - val_loss: 5.7063\n",
      "Epoch 921/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.4565 - val_loss: 6.0248\n",
      "Epoch 922/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.8102 - val_loss: 5.8704\n",
      "Epoch 923/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.4041 - val_loss: 5.3608\n",
      "Epoch 924/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6184 - val_loss: 5.6901\n",
      "Epoch 925/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.6633 - val_loss: 6.0761\n",
      "Epoch 926/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.6653 - val_loss: 6.6523\n",
      "Epoch 927/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 5.3827 - val_loss: 5.9360\n",
      "Epoch 928/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.4731 - val_loss: 5.6305\n",
      "Epoch 929/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 5.3871 - val_loss: 5.4480\n",
      "Epoch 930/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.5133 - val_loss: 5.7092\n",
      "Epoch 931/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.0008 - val_loss: 5.3494\n",
      "Epoch 932/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 5.2629 - val_loss: 5.2508\n",
      "Epoch 933/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.2527 - val_loss: 5.7627\n",
      "Epoch 934/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.6329 - val_loss: 5.3052\n",
      "Epoch 935/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.4872 - val_loss: 5.8235\n",
      "Epoch 936/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.5173 - val_loss: 7.2679\n",
      "Epoch 937/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.8722 - val_loss: 8.0728\n",
      "Epoch 938/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.0119 - val_loss: 6.0381\n",
      "Epoch 939/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.5380 - val_loss: 5.8574\n",
      "Epoch 940/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.1136 - val_loss: 5.8335\n",
      "Epoch 941/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.8516 - val_loss: 7.6665\n",
      "Epoch 942/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.6327 - val_loss: 5.4744\n",
      "Epoch 943/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.4413 - val_loss: 5.5129\n",
      "Epoch 944/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.5394 - val_loss: 6.0938\n",
      "Epoch 945/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.2760 - val_loss: 5.5542\n",
      "Epoch 946/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.3691 - val_loss: 6.8588\n",
      "Epoch 947/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.8450 - val_loss: 5.4932\n",
      "Epoch 948/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.5060 - val_loss: 5.6825\n",
      "Epoch 949/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.4146 - val_loss: 5.4255\n",
      "Epoch 950/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.4194 - val_loss: 5.1225\n",
      "Epoch 951/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.4805 - val_loss: 5.3342\n",
      "Epoch 952/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.8598 - val_loss: 5.2217\n",
      "Epoch 953/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6560 - val_loss: 5.3286\n",
      "Epoch 954/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.3342 - val_loss: 5.4119\n",
      "Epoch 955/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.8789 - val_loss: 5.7613\n",
      "Epoch 956/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.7129 - val_loss: 6.6456\n",
      "Epoch 957/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.6870 - val_loss: 6.0301\n",
      "Epoch 958/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.7555 - val_loss: 5.9755\n",
      "Epoch 959/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.9975 - val_loss: 6.8233\n",
      "Epoch 960/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.0294 - val_loss: 5.7137\n",
      "Epoch 961/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.4340 - val_loss: 5.7894\n",
      "Epoch 962/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6311 - val_loss: 5.9296\n",
      "Epoch 963/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.3936 - val_loss: 5.9526\n",
      "Epoch 964/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.4751 - val_loss: 5.3370\n",
      "Epoch 965/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.1402 - val_loss: 5.9222\n",
      "Epoch 966/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.5349 - val_loss: 5.3504\n",
      "Epoch 967/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.5187 - val_loss: 5.2399\n",
      "Epoch 968/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.3445 - val_loss: 5.5167\n",
      "Epoch 969/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.4990 - val_loss: 5.8809\n",
      "Epoch 970/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.5073 - val_loss: 5.9676\n",
      "Epoch 971/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.8203 - val_loss: 8.8515\n",
      "Epoch 972/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6645 - val_loss: 7.2377\n",
      "Epoch 973/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.0037 - val_loss: 5.4631\n",
      "Epoch 974/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.4671 - val_loss: 5.3675\n",
      "Epoch 975/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.5675 - val_loss: 5.5601\n",
      "Epoch 976/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.4996 - val_loss: 5.6686\n",
      "Epoch 977/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.3796 - val_loss: 5.7502\n",
      "Epoch 978/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.7186 - val_loss: 7.8630\n",
      "Epoch 979/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.7949 - val_loss: 5.6389\n",
      "Epoch 980/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.6462 - val_loss: 5.3292\n",
      "Epoch 981/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.9208 - val_loss: 5.9430\n",
      "Epoch 982/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6447 - val_loss: 5.6682\n",
      "Epoch 983/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.5594 - val_loss: 8.0321\n",
      "Epoch 984/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6945 - val_loss: 5.3313\n",
      "Epoch 985/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.3905 - val_loss: 5.7165\n",
      "Epoch 986/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.6415 - val_loss: 5.8892\n",
      "Epoch 987/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.3651 - val_loss: 6.5408\n",
      "Epoch 988/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.3671 - val_loss: 5.5022\n",
      "Epoch 989/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.4908 - val_loss: 5.5487\n",
      "Epoch 990/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.8164 - val_loss: 6.2282\n",
      "Epoch 991/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.6874 - val_loss: 7.0422\n",
      "Epoch 992/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.6171 - val_loss: 5.8782\n",
      "Epoch 993/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.3359 - val_loss: 5.7210\n",
      "Epoch 994/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.4963 - val_loss: 5.3596\n",
      "Epoch 995/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.3196 - val_loss: 5.5598\n",
      "Epoch 996/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.3822 - val_loss: 6.2279\n",
      "Epoch 997/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.2989 - val_loss: 7.5121\n",
      "Epoch 998/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.8182 - val_loss: 6.2191\n",
      "Epoch 999/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.8091 - val_loss: 6.0688\n",
      "Epoch 1000/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.3692 - val_loss: 5.2384\n",
      "5.286310259219819\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 4.3261294 , -3.7740855 ,  0.50674176,  0.25428903,  0.6039649 ,\n",
       "          0.83112895,  1.094137  ,  0.29862598,  2.818076  ,  4.31269   ],\n",
       "        [-0.13249727,  0.09763704,  0.9974108 ,  0.5220274 ,  0.4422099 ,\n",
       "          0.4903943 ,  1.0849491 , -0.26379034, -0.1421228 ,  0.5473261 ],\n",
       "        [-0.08075162, -1.5269315 ,  1.9977796 ,  1.669946  , -0.47504622,\n",
       "          0.6857303 ,  0.39374834,  0.43975317,  0.06284396,  2.2318997 ],\n",
       "        [-0.01838448,  0.15533598,  0.06709491, -0.14209753,  0.30370143,\n",
       "         -1.1516814 , -0.41768652, -0.18161424, -0.07926843, -0.19530301],\n",
       "        [ 2.199923  ,  0.13998659,  0.5756548 , -0.19102582,  0.93045783,\n",
       "          1.1241857 ,  1.124133  ,  2.243338  ,  0.2018554 ,  0.5573553 ]],\n",
       "       dtype=float32),\n",
       " array([ 5.1362696 , -5.7474537 , -5.304455  ,  1.1318691 , -5.1424193 ,\n",
       "        -3.1003447 ,  0.34960106,  3.4770808 ,  1.6631205 ,  4.400375  ],\n",
       "       dtype=float32),\n",
       " array([[-1.4864577 ,  1.9812807 ,  2.1445858 , -1.1233878 , -1.3825037 ,\n",
       "         -1.6110325 , -1.7277061 , -2.4107125 ,  1.3444688 , -2.3180308 ],\n",
       "        [ 2.5735452 , -2.2406766 , -2.6905544 ,  1.2294877 ,  1.8114591 ,\n",
       "          2.3158712 ,  1.7383713 ,  1.9852685 , -2.672867  ,  2.4193013 ],\n",
       "        [ 1.5436594 , -1.1863555 , -1.5659966 ,  0.7091249 ,  0.71172047,\n",
       "          1.0421091 ,  0.47460127,  1.3791218 , -1.4292821 ,  1.5114535 ],\n",
       "        [ 0.2502901 , -0.34758464, -1.1305135 ,  0.6943502 ,  0.8625691 ,\n",
       "          0.1147908 ,  1.0014116 ,  0.9816853 , -0.17531458,  0.5054944 ],\n",
       "        [ 1.5856751 , -0.860469  , -1.6123482 ,  0.06135586,  1.4103625 ,\n",
       "          0.5707581 ,  0.28799444,  1.516501  , -1.2824168 ,  1.6204557 ],\n",
       "        [ 0.19804284, -0.02700624, -0.83284175, -0.9166026 , -0.16277336,\n",
       "         -0.27965462, -0.2408566 ,  0.70870656, -0.32713285,  0.46307454],\n",
       "        [ 0.43576762,  0.18400918, -0.16374148,  0.45859376,  0.5188323 ,\n",
       "          0.13825414, -0.04024832,  0.80441344, -0.6448557 ,  0.64079326],\n",
       "        [-1.5208609 ,  1.5076553 ,  1.5402956 , -0.3154106 , -0.952393  ,\n",
       "         -1.364478  , -0.48726666, -1.1292533 ,  1.813311  , -1.3753875 ],\n",
       "        [ 0.95061934, -1.1496745 , -0.6383165 ,  0.7064219 ,  0.5244684 ,\n",
       "          0.59555614,  0.84038466,  0.67856646, -1.040093  ,  1.0946397 ],\n",
       "        [ 0.06606498,  1.0247853 ,  1.0389578 ,  0.39714438, -0.9839458 ,\n",
       "         -0.47726256,  0.26118544, -0.40545914,  0.77384484, -0.55623686]],\n",
       "       dtype=float32),\n",
       " array([-1.6993397,  1.7169657,  1.8271617, -1.186349 , -1.7293091,\n",
       "        -1.554078 , -1.3327576, -1.8314754,  1.8004122, -1.8508729],\n",
       "       dtype=float32),\n",
       " array([[-1.2855016 ],\n",
       "        [ 1.3900607 ],\n",
       "        [ 1.7257222 ],\n",
       "        [-0.3455813 ],\n",
       "        [-1.248727  ],\n",
       "        [-0.9926868 ],\n",
       "        [-0.61257076],\n",
       "        [-1.7443802 ],\n",
       "        [ 1.5666957 ],\n",
       "        [-1.873249  ]], dtype=float32),\n",
       " array([2.0981565], dtype=float32)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_airfoil, history_airfoil=NN_model_structure_regression_5(X_train_airfoil, X_val_airfoil, Y_train_airfoil, Y_val_airfoil, adam2, 32, 1000)\n",
    "model_airfoil.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_airfoil.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_airfoil_structure5.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 15)                165       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 241\n",
      "Trainable params: 241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1052 samples, validate on 225 samples\n",
      "Epoch 1/1000\n",
      "1052/1052 [==============================] - 0s 253us/step - loss: 6195.0826 - val_loss: 735.4124\n",
      "Epoch 2/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 142.1548 - val_loss: 30.4169\n",
      "Epoch 3/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 31.0060 - val_loss: 28.7922\n",
      "Epoch 4/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 25.7335 - val_loss: 26.2218\n",
      "Epoch 5/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 23.9111 - val_loss: 25.2856\n",
      "Epoch 6/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 23.0792 - val_loss: 24.8366\n",
      "Epoch 7/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 22.2808 - val_loss: 24.7658\n",
      "Epoch 8/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 21.6510 - val_loss: 24.4875\n",
      "Epoch 9/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 20.9708 - val_loss: 23.8359\n",
      "Epoch 10/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 20.5042 - val_loss: 24.0143\n",
      "Epoch 11/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 20.1602 - val_loss: 23.1460\n",
      "Epoch 12/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 19.5294 - val_loss: 22.7102\n",
      "Epoch 13/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.9075 - val_loss: 23.4297\n",
      "Epoch 14/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.8019 - val_loss: 23.3548\n",
      "Epoch 15/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.4977 - val_loss: 22.6061\n",
      "Epoch 16/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.1474 - val_loss: 21.8899\n",
      "Epoch 17/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.6893 - val_loss: 21.9881\n",
      "Epoch 18/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.3261 - val_loss: 21.9865\n",
      "Epoch 19/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.1633 - val_loss: 23.4254\n",
      "Epoch 20/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.3040 - val_loss: 21.1556\n",
      "Epoch 21/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 16.7449 - val_loss: 21.2216\n",
      "Epoch 22/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 16.5224 - val_loss: 20.7015\n",
      "Epoch 23/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 16.3267 - val_loss: 20.4433\n",
      "Epoch 24/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 16.0207 - val_loss: 20.0441\n",
      "Epoch 25/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 15.9670 - val_loss: 20.0622\n",
      "Epoch 26/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 15.9018 - val_loss: 19.5839\n",
      "Epoch 27/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 15.7630 - val_loss: 19.5555\n",
      "Epoch 28/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 15.6035 - val_loss: 19.1297\n",
      "Epoch 29/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 15.5541 - val_loss: 18.8398\n",
      "Epoch 30/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 15.0753 - val_loss: 20.2438\n",
      "Epoch 31/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 15.3000 - val_loss: 18.5164\n",
      "Epoch 32/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.9432 - val_loss: 18.9492\n",
      "Epoch 33/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 15.0172 - val_loss: 18.0225\n",
      "Epoch 34/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.7737 - val_loss: 17.6862\n",
      "Epoch 35/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.6656 - val_loss: 17.9271\n",
      "Epoch 36/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.6481 - val_loss: 17.5917\n",
      "Epoch 37/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.5600 - val_loss: 18.9684\n",
      "Epoch 38/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.3063 - val_loss: 17.2137\n",
      "Epoch 39/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.1443 - val_loss: 18.0970\n",
      "Epoch 40/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.3411 - val_loss: 18.1429\n",
      "Epoch 41/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.1481 - val_loss: 17.1898\n",
      "Epoch 42/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.1422 - val_loss: 17.1466\n",
      "Epoch 43/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.8736 - val_loss: 17.0196\n",
      "Epoch 44/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.1386 - val_loss: 16.2671\n",
      "Epoch 45/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 13.7118 - val_loss: 16.6054\n",
      "Epoch 46/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 13.9671 - val_loss: 16.9660\n",
      "Epoch 47/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 13.5065 - val_loss: 16.5094\n",
      "Epoch 48/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 13.2067 - val_loss: 15.9485\n",
      "Epoch 49/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 13.0222 - val_loss: 16.2386\n",
      "Epoch 50/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 13.0981 - val_loss: 16.5616\n",
      "Epoch 51/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 13.0542 - val_loss: 16.5697\n",
      "Epoch 52/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 12.9680 - val_loss: 15.5618\n",
      "Epoch 53/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 12.8392 - val_loss: 16.1984\n",
      "Epoch 54/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.9892 - val_loss: 15.8328\n",
      "Epoch 55/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.8336 - val_loss: 16.5670\n",
      "Epoch 56/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.8835 - val_loss: 15.6756\n",
      "Epoch 57/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.8056 - val_loss: 15.2219\n",
      "Epoch 58/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 12.7798 - val_loss: 15.1359\n",
      "Epoch 59/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 12.6818 - val_loss: 14.8476\n",
      "Epoch 60/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.2752 - val_loss: 15.0645\n",
      "Epoch 61/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.5404 - val_loss: 16.2534\n",
      "Epoch 62/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.1717 - val_loss: 15.5319\n",
      "Epoch 63/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.3603 - val_loss: 17.6651\n",
      "Epoch 64/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.9243 - val_loss: 15.1592\n",
      "Epoch 65/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.6308 - val_loss: 14.4559\n",
      "Epoch 66/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.2352 - val_loss: 14.5231\n",
      "Epoch 67/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 85us/step - loss: 12.3259 - val_loss: 14.4633\n",
      "Epoch 68/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.3567 - val_loss: 15.0813\n",
      "Epoch 69/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.1084 - val_loss: 14.5853\n",
      "Epoch 70/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.0842 - val_loss: 14.2448\n",
      "Epoch 71/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.1357 - val_loss: 14.4968\n",
      "Epoch 72/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.7939 - val_loss: 15.6207\n",
      "Epoch 73/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.4061 - val_loss: 15.8255\n",
      "Epoch 74/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.7720 - val_loss: 14.4477\n",
      "Epoch 75/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.9288 - val_loss: 13.9776\n",
      "Epoch 76/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.6237 - val_loss: 13.9908\n",
      "Epoch 77/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.6663 - val_loss: 15.1623\n",
      "Epoch 78/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.4732 - val_loss: 14.7819\n",
      "Epoch 79/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.8535 - val_loss: 14.1671\n",
      "Epoch 80/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.9029 - val_loss: 16.9568\n",
      "Epoch 81/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 12.1477 - val_loss: 14.0809\n",
      "Epoch 82/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.6639 - val_loss: 13.5651\n",
      "Epoch 83/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 11.6633 - val_loss: 13.6592\n",
      "Epoch 84/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.7742 - val_loss: 13.8786\n",
      "Epoch 85/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.3925 - val_loss: 14.1020\n",
      "Epoch 86/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.6974 - val_loss: 14.7604\n",
      "Epoch 87/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.5025 - val_loss: 13.8222\n",
      "Epoch 88/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.2314 - val_loss: 13.4279\n",
      "Epoch 89/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.6983 - val_loss: 14.0867\n",
      "Epoch 90/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.4413 - val_loss: 13.6989\n",
      "Epoch 91/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.6869 - val_loss: 14.2115\n",
      "Epoch 92/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.5367 - val_loss: 14.9390\n",
      "Epoch 93/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.6076 - val_loss: 15.2582\n",
      "Epoch 94/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.5474 - val_loss: 14.1586\n",
      "Epoch 95/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.9660 - val_loss: 13.6558\n",
      "Epoch 96/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 11.6090 - val_loss: 13.5424\n",
      "Epoch 97/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.7772 - val_loss: 13.4353\n",
      "Epoch 98/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.4075 - val_loss: 14.2561\n",
      "Epoch 99/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.1412 - val_loss: 14.4945\n",
      "Epoch 100/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 11.0819 - val_loss: 13.4004\n",
      "Epoch 101/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.1127 - val_loss: 13.0085\n",
      "Epoch 102/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.7641 - val_loss: 15.5567\n",
      "Epoch 103/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.8947 - val_loss: 14.9748\n",
      "Epoch 104/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.6081 - val_loss: 13.4205\n",
      "Epoch 105/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.1982 - val_loss: 14.1310\n",
      "Epoch 106/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.5133 - val_loss: 15.0475\n",
      "Epoch 107/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.7353 - val_loss: 13.2585\n",
      "Epoch 108/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 11.0776 - val_loss: 12.6393\n",
      "Epoch 109/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.5014 - val_loss: 12.9876\n",
      "Epoch 110/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.1700 - val_loss: 13.4571\n",
      "Epoch 111/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.5465 - val_loss: 12.8482\n",
      "Epoch 112/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.3024 - val_loss: 13.9522\n",
      "Epoch 113/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.4387 - val_loss: 12.8394\n",
      "Epoch 114/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.9313 - val_loss: 12.9945\n",
      "Epoch 115/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.8615 - val_loss: 13.4452\n",
      "Epoch 116/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.9539 - val_loss: 14.1301\n",
      "Epoch 117/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.0186 - val_loss: 12.9193\n",
      "Epoch 118/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.0461 - val_loss: 15.1178\n",
      "Epoch 119/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.4848 - val_loss: 12.5264\n",
      "Epoch 120/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.0367 - val_loss: 13.5537\n",
      "Epoch 121/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.8614 - val_loss: 13.2444\n",
      "Epoch 122/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.1200 - val_loss: 12.9198\n",
      "Epoch 123/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.2274 - val_loss: 14.1424\n",
      "Epoch 124/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.4400 - val_loss: 17.9434\n",
      "Epoch 125/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.6575 - val_loss: 13.9330\n",
      "Epoch 126/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 11.1170 - val_loss: 14.9807\n",
      "Epoch 127/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.7423 - val_loss: 12.3899\n",
      "Epoch 128/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.9979 - val_loss: 13.3951\n",
      "Epoch 129/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.9199 - val_loss: 13.2309\n",
      "Epoch 130/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.8206 - val_loss: 13.0015\n",
      "Epoch 131/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.4427 - val_loss: 14.7955\n",
      "Epoch 132/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.5670 - val_loss: 13.2278\n",
      "Epoch 133/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.0701 - val_loss: 14.3121\n",
      "Epoch 134/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.0269 - val_loss: 13.4815\n",
      "Epoch 135/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.7577 - val_loss: 12.9097\n",
      "Epoch 136/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.1075 - val_loss: 14.4210\n",
      "Epoch 137/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.3677 - val_loss: 12.7376\n",
      "Epoch 138/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.5874 - val_loss: 12.0101\n",
      "Epoch 139/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.5554 - val_loss: 14.2764\n",
      "Epoch 140/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.7203 - val_loss: 12.6378\n",
      "Epoch 141/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.2317 - val_loss: 12.4980\n",
      "Epoch 142/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 10.5012 - val_loss: 13.1919\n",
      "Epoch 143/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.0096 - val_loss: 12.5435\n",
      "Epoch 144/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 11.3266 - val_loss: 12.8553\n",
      "Epoch 145/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.7417 - val_loss: 15.3553\n",
      "Epoch 146/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.8089 - val_loss: 13.6682\n",
      "Epoch 147/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.4557 - val_loss: 12.0881\n",
      "Epoch 148/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.5831 - val_loss: 13.8332\n",
      "Epoch 149/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.0339 - val_loss: 12.0274\n",
      "Epoch 150/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.6034 - val_loss: 13.3781\n",
      "Epoch 151/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.7543 - val_loss: 16.1114\n",
      "Epoch 152/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 10.6354 - val_loss: 12.9293\n",
      "Epoch 153/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.3577 - val_loss: 12.1810\n",
      "Epoch 154/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.7013 - val_loss: 12.2496\n",
      "Epoch 155/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.6118 - val_loss: 12.8739\n",
      "Epoch 156/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.4429 - val_loss: 13.2043\n",
      "Epoch 157/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.9084 - val_loss: 12.3404\n",
      "Epoch 158/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.3287 - val_loss: 12.4032\n",
      "Epoch 159/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.3515 - val_loss: 14.5148\n",
      "Epoch 160/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.0776 - val_loss: 11.8851\n",
      "Epoch 161/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.0717 - val_loss: 12.5225\n",
      "Epoch 162/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.8492 - val_loss: 11.8845\n",
      "Epoch 163/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.9014 - val_loss: 12.2085\n",
      "Epoch 164/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.6693 - val_loss: 14.0156\n",
      "Epoch 165/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.9483 - val_loss: 13.9733\n",
      "Epoch 166/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.2622 - val_loss: 12.3751\n",
      "Epoch 167/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.0842 - val_loss: 13.4728\n",
      "Epoch 168/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.1424 - val_loss: 13.0205\n",
      "Epoch 169/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.5154 - val_loss: 13.4126\n",
      "Epoch 170/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.6328 - val_loss: 14.6991\n",
      "Epoch 171/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.8406 - val_loss: 11.8880\n",
      "Epoch 172/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.3528 - val_loss: 12.4835\n",
      "Epoch 173/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.0907 - val_loss: 12.8548\n",
      "Epoch 174/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.9375 - val_loss: 12.2712\n",
      "Epoch 175/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.9776 - val_loss: 13.1593\n",
      "Epoch 176/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.3807 - val_loss: 12.3975\n",
      "Epoch 177/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.7475 - val_loss: 12.7543\n",
      "Epoch 178/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.4575 - val_loss: 15.2911\n",
      "Epoch 179/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.1106 - val_loss: 13.0519\n",
      "Epoch 180/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.5354 - val_loss: 11.8350\n",
      "Epoch 181/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.8502 - val_loss: 11.8885\n",
      "Epoch 182/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.8055 - val_loss: 11.5312\n",
      "Epoch 183/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.6033 - val_loss: 13.8015\n",
      "Epoch 184/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.4322 - val_loss: 12.2024\n",
      "Epoch 185/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.6614 - val_loss: 12.2429\n",
      "Epoch 186/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.9929 - val_loss: 11.7394\n",
      "Epoch 187/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.6698 - val_loss: 11.5228\n",
      "Epoch 188/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.7102 - val_loss: 10.9630\n",
      "Epoch 189/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.8383 - val_loss: 11.4871\n",
      "Epoch 190/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.8393 - val_loss: 13.1864\n",
      "Epoch 191/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.4139 - val_loss: 11.9351\n",
      "Epoch 192/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.1969 - val_loss: 12.3015\n",
      "Epoch 193/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.8424 - val_loss: 11.5389\n",
      "Epoch 194/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.2698 - val_loss: 11.9045\n",
      "Epoch 195/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.4460 - val_loss: 12.0804\n",
      "Epoch 196/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.8283 - val_loss: 15.0196\n",
      "Epoch 197/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.6325 - val_loss: 11.5462\n",
      "Epoch 198/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.4111 - val_loss: 11.0927\n",
      "Epoch 199/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.1909 - val_loss: 10.7950\n",
      "Epoch 200/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1339 - val_loss: 10.5142\n",
      "Epoch 201/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.6459 - val_loss: 10.4493\n",
      "Epoch 202/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.9445 - val_loss: 10.9659\n",
      "Epoch 203/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9363 - val_loss: 14.2681\n",
      "Epoch 204/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.3171 - val_loss: 10.4877\n",
      "Epoch 205/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.2529 - val_loss: 10.2683\n",
      "Epoch 206/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7413 - val_loss: 11.4846\n",
      "Epoch 207/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.5941 - val_loss: 11.2090\n",
      "Epoch 208/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1906 - val_loss: 10.0483\n",
      "Epoch 209/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6616 - val_loss: 10.8956\n",
      "Epoch 210/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.0623 - val_loss: 10.7080\n",
      "Epoch 211/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9188 - val_loss: 11.5059\n",
      "Epoch 212/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.7819 - val_loss: 10.4712\n",
      "Epoch 213/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.8655 - val_loss: 9.9285\n",
      "Epoch 214/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1803 - val_loss: 9.8459\n",
      "Epoch 215/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.9058 - val_loss: 9.0774\n",
      "Epoch 216/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 8.2375 - val_loss: 9.9283\n",
      "Epoch 217/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.7888 - val_loss: 9.8952\n",
      "Epoch 218/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.5362 - val_loss: 9.2846\n",
      "Epoch 219/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.6397 - val_loss: 10.5439\n",
      "Epoch 220/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.8926 - val_loss: 9.2809\n",
      "Epoch 221/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.0022 - val_loss: 11.7729\n",
      "Epoch 222/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.7029 - val_loss: 9.1327\n",
      "Epoch 223/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 7.7970 - val_loss: 8.9732\n",
      "Epoch 224/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1609 - val_loss: 10.1266\n",
      "Epoch 225/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.6332 - val_loss: 10.0987\n",
      "Epoch 226/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.4372 - val_loss: 9.5981\n",
      "Epoch 227/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.7562 - val_loss: 9.0918\n",
      "Epoch 228/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.6288 - val_loss: 9.6360\n",
      "Epoch 229/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.4184 - val_loss: 9.3579\n",
      "Epoch 230/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.5522 - val_loss: 8.9801\n",
      "Epoch 231/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.6550 - val_loss: 8.7828\n",
      "Epoch 232/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.5581 - val_loss: 10.6722\n",
      "Epoch 233/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.9364 - val_loss: 8.9092\n",
      "Epoch 234/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2300 - val_loss: 10.1327\n",
      "Epoch 235/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.6978 - val_loss: 9.0738\n",
      "Epoch 236/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.5120 - val_loss: 9.0888\n",
      "Epoch 237/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.8394 - val_loss: 8.9823\n",
      "Epoch 238/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.4647 - val_loss: 8.4433\n",
      "Epoch 239/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.2089 - val_loss: 9.2860\n",
      "Epoch 240/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.2805 - val_loss: 8.2387\n",
      "Epoch 241/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.7047 - val_loss: 9.8415\n",
      "Epoch 242/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.7519 - val_loss: 9.2910\n",
      "Epoch 243/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.1844 - val_loss: 8.8361\n",
      "Epoch 244/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2037 - val_loss: 8.1845\n",
      "Epoch 245/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.4219 - val_loss: 12.0440\n",
      "Epoch 246/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.4265 - val_loss: 8.3564\n",
      "Epoch 247/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.1512 - val_loss: 8.7214\n",
      "Epoch 248/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.4164 - val_loss: 10.1784\n",
      "Epoch 249/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.2347 - val_loss: 8.4093\n",
      "Epoch 250/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6312 - val_loss: 8.5151\n",
      "Epoch 251/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.6559 - val_loss: 9.5467\n",
      "Epoch 252/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.5725 - val_loss: 8.4794\n",
      "Epoch 253/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.3366 - val_loss: 9.2509\n",
      "Epoch 254/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9764 - val_loss: 13.2342\n",
      "Epoch 255/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4703 - val_loss: 9.4827\n",
      "Epoch 256/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 8.428 - 0s 86us/step - loss: 7.7683 - val_loss: 9.8734\n",
      "Epoch 257/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9762 - val_loss: 10.7669\n",
      "Epoch 258/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.2720 - val_loss: 9.1991\n",
      "Epoch 259/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.1817 - val_loss: 8.9976\n",
      "Epoch 260/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.4039 - val_loss: 8.5027\n",
      "Epoch 261/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.3226 - val_loss: 9.5845\n",
      "Epoch 262/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.5066 - val_loss: 8.5412\n",
      "Epoch 263/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.0029 - val_loss: 8.2280\n",
      "Epoch 264/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.2279 - val_loss: 9.6835\n",
      "Epoch 265/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.2180 - val_loss: 9.4263\n",
      "Epoch 266/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.3358 - val_loss: 10.6927\n",
      "Epoch 267/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.5855 - val_loss: 8.0673\n",
      "Epoch 268/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.5168 - val_loss: 8.0834\n",
      "Epoch 269/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.4869 - val_loss: 11.5977\n",
      "Epoch 270/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.6420 - val_loss: 8.1493\n",
      "Epoch 271/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.5465 - val_loss: 10.5719\n",
      "Epoch 272/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.0844 - val_loss: 8.7405\n",
      "Epoch 273/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.1373 - val_loss: 9.4479\n",
      "Epoch 274/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.6898 - val_loss: 9.4282\n",
      "Epoch 275/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.1003 - val_loss: 8.2865\n",
      "Epoch 276/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.3063 - val_loss: 9.2603\n",
      "Epoch 277/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.5160 - val_loss: 8.4654\n",
      "Epoch 278/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.2818 - val_loss: 9.2906\n",
      "Epoch 279/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.2556 - val_loss: 7.9720\n",
      "Epoch 280/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.2763 - val_loss: 8.2041\n",
      "Epoch 281/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.2199 - val_loss: 9.7989\n",
      "Epoch 282/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.9619 - val_loss: 8.4789\n",
      "Epoch 283/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.0120 - val_loss: 8.0403\n",
      "Epoch 284/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.7969 - val_loss: 8.5176\n",
      "Epoch 285/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.1663 - val_loss: 8.7593\n",
      "Epoch 286/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.8723 - val_loss: 9.0571\n",
      "Epoch 287/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.0665 - val_loss: 8.5926\n",
      "Epoch 288/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.9308 - val_loss: 8.3675\n",
      "Epoch 289/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.7277 - val_loss: 8.0454\n",
      "Epoch 290/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.9882 - val_loss: 8.8463\n",
      "Epoch 291/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.0555 - val_loss: 8.6761\n",
      "Epoch 292/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.4586 - val_loss: 11.6107\n",
      "Epoch 293/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.5122 - val_loss: 8.2350\n",
      "Epoch 294/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.0717 - val_loss: 8.1382\n",
      "Epoch 295/1000\n",
      "1052/1052 [==============================] - 0s 110us/step - loss: 6.8594 - val_loss: 8.4048\n",
      "Epoch 296/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.0309 - val_loss: 7.8976\n",
      "Epoch 297/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.1995 - val_loss: 10.2516\n",
      "Epoch 298/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.2519 - val_loss: 8.3587\n",
      "Epoch 299/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.1064 - val_loss: 8.7939\n",
      "Epoch 300/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.7919 - val_loss: 8.6948\n",
      "Epoch 301/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.1179 - val_loss: 9.2951\n",
      "Epoch 302/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.4395 - val_loss: 11.6958\n",
      "Epoch 303/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.9146 - val_loss: 9.1036\n",
      "Epoch 304/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.7037 - val_loss: 10.0803\n",
      "Epoch 305/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.2011 - val_loss: 8.6854\n",
      "Epoch 306/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.0404 - val_loss: 9.6521\n",
      "Epoch 307/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.1928 - val_loss: 9.1223\n",
      "Epoch 308/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8415 - val_loss: 8.6207\n",
      "Epoch 309/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.5466 - val_loss: 11.4122\n",
      "Epoch 310/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.4545 - val_loss: 8.6233\n",
      "Epoch 311/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.2305 - val_loss: 8.6203\n",
      "Epoch 312/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.9526 - val_loss: 8.3331\n",
      "Epoch 313/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.8536 - val_loss: 7.7699\n",
      "Epoch 314/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.0411 - val_loss: 10.2532\n",
      "Epoch 315/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.1896 - val_loss: 8.0100\n",
      "Epoch 316/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.2897 - val_loss: 8.7666\n",
      "Epoch 317/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.9121 - val_loss: 9.2216\n",
      "Epoch 318/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.7489 - val_loss: 7.7175\n",
      "Epoch 319/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.1759 - val_loss: 10.6608\n",
      "Epoch 320/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.2151 - val_loss: 8.1844\n",
      "Epoch 321/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.3779 - val_loss: 9.3075\n",
      "Epoch 322/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.8392 - val_loss: 9.0863\n",
      "Epoch 323/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.4331 - val_loss: 8.3771\n",
      "Epoch 324/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.8060 - val_loss: 8.4120\n",
      "Epoch 325/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.3302 - val_loss: 11.5053\n",
      "Epoch 326/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.4426 - val_loss: 8.4188\n",
      "Epoch 327/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.8764 - val_loss: 7.9020\n",
      "Epoch 328/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.7820 - val_loss: 7.6295\n",
      "Epoch 329/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.5608 - val_loss: 8.6101\n",
      "Epoch 330/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.9027 - val_loss: 9.4075\n",
      "Epoch 331/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.3042 - val_loss: 9.0862\n",
      "Epoch 332/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.7791 - val_loss: 7.9518\n",
      "Epoch 333/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.0619 - val_loss: 8.3578\n",
      "Epoch 334/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.7305 - val_loss: 9.3003\n",
      "Epoch 335/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.0990 - val_loss: 8.9607\n",
      "Epoch 336/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.2059 - val_loss: 7.7935\n",
      "Epoch 337/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.9568 - val_loss: 7.9494\n",
      "Epoch 338/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9983 - val_loss: 10.9607\n",
      "Epoch 339/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.6812 - val_loss: 8.2673\n",
      "Epoch 340/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.1778 - val_loss: 7.9418\n",
      "Epoch 341/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.8157 - val_loss: 8.8398\n",
      "Epoch 342/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.9834 - val_loss: 7.6976\n",
      "Epoch 343/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.6168 - val_loss: 7.8838\n",
      "Epoch 344/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.3846 - val_loss: 8.6959\n",
      "Epoch 345/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.8144 - val_loss: 7.9145\n",
      "Epoch 346/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.0958 - val_loss: 9.8165\n",
      "Epoch 347/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.0754 - val_loss: 8.2537\n",
      "Epoch 348/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.3027 - val_loss: 8.9385\n",
      "Epoch 349/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.8202 - val_loss: 8.0721\n",
      "Epoch 350/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.6855 - val_loss: 8.5120\n",
      "Epoch 351/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.3398 - val_loss: 8.1460\n",
      "Epoch 352/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.7370 - val_loss: 8.4784\n",
      "Epoch 353/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.0417 - val_loss: 7.6458\n",
      "Epoch 354/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.8936 - val_loss: 7.8848\n",
      "Epoch 355/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.8478 - val_loss: 8.7200\n",
      "Epoch 356/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.6894 - val_loss: 7.7303\n",
      "Epoch 357/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.9567 - val_loss: 8.1169\n",
      "Epoch 358/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.0421 - val_loss: 7.9136\n",
      "Epoch 359/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.9551 - val_loss: 9.4143\n",
      "Epoch 360/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.1908 - val_loss: 8.2986\n",
      "Epoch 361/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.8118 - val_loss: 10.0341\n",
      "Epoch 362/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.0588 - val_loss: 7.6969\n",
      "Epoch 363/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.9551 - val_loss: 9.2725\n",
      "Epoch 364/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3637 - val_loss: 10.2227\n",
      "Epoch 365/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.6737 - val_loss: 9.0788\n",
      "Epoch 366/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.6816 - val_loss: 8.7055\n",
      "Epoch 367/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.8842 - val_loss: 8.3097\n",
      "Epoch 368/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.2279 - val_loss: 7.7818\n",
      "Epoch 369/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.8053 - val_loss: 9.3501\n",
      "Epoch 370/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.2140 - val_loss: 7.7702\n",
      "Epoch 371/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.5279 - val_loss: 8.1768\n",
      "Epoch 372/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.5956 - val_loss: 8.9734\n",
      "Epoch 373/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.5551 - val_loss: 8.0972\n",
      "Epoch 374/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.0025 - val_loss: 9.4913\n",
      "Epoch 375/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.1024 - val_loss: 8.0706\n",
      "Epoch 376/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.1468 - val_loss: 7.8312\n",
      "Epoch 377/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.1179 - val_loss: 8.1446\n",
      "Epoch 378/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.6786 - val_loss: 7.9966\n",
      "Epoch 379/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.5904 - val_loss: 8.2568\n",
      "Epoch 380/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.0134 - val_loss: 9.4754\n",
      "Epoch 381/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.5445 - val_loss: 7.6658\n",
      "Epoch 382/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.7075 - val_loss: 9.5047\n",
      "Epoch 383/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.4073 - val_loss: 8.3394\n",
      "Epoch 384/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.1377 - val_loss: 8.9863\n",
      "Epoch 385/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.0837 - val_loss: 7.8052\n",
      "Epoch 386/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 6.8427 - val_loss: 8.4913\n",
      "Epoch 387/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 7.1838 - val_loss: 7.6993\n",
      "Epoch 388/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 7.1732 - val_loss: 7.6792\n",
      "Epoch 389/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 7.0079 - val_loss: 7.8290\n",
      "Epoch 390/1000\n",
      "1052/1052 [==============================] - 0s 118us/step - loss: 6.8393 - val_loss: 8.2500\n",
      "Epoch 391/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 6.7881 - val_loss: 8.5004\n",
      "Epoch 392/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.7209 - val_loss: 8.0695\n",
      "Epoch 393/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 6.7003 - val_loss: 9.8951\n",
      "Epoch 394/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.6281 - val_loss: 8.0396\n",
      "Epoch 395/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.6068 - val_loss: 7.7344\n",
      "Epoch 396/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.7156 - val_loss: 8.4842\n",
      "Epoch 397/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.6820 - val_loss: 7.8429\n",
      "Epoch 398/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.1756 - val_loss: 7.6949\n",
      "Epoch 399/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.5486 - val_loss: 9.4958\n",
      "Epoch 400/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.9155 - val_loss: 7.4962\n",
      "Epoch 401/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.5902 - val_loss: 8.5711\n",
      "Epoch 402/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.6824 - val_loss: 7.3285\n",
      "Epoch 403/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 6.7899 - val_loss: 8.8726\n",
      "Epoch 404/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.6294 - val_loss: 10.5973\n",
      "Epoch 405/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.1638 - val_loss: 7.5368\n",
      "Epoch 406/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9333 - val_loss: 11.3773\n",
      "Epoch 407/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.8021 - val_loss: 7.7926\n",
      "Epoch 408/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.5849 - val_loss: 8.6352\n",
      "Epoch 409/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.9461 - val_loss: 7.9784\n",
      "Epoch 410/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.1720 - val_loss: 7.6448\n",
      "Epoch 411/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.3999 - val_loss: 8.4513\n",
      "Epoch 412/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.8325 - val_loss: 8.6353\n",
      "Epoch 413/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.7763 - val_loss: 8.0526\n",
      "Epoch 414/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.6475 - val_loss: 7.5444\n",
      "Epoch 415/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.6678 - val_loss: 9.8220\n",
      "Epoch 416/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.1291 - val_loss: 7.9010\n",
      "Epoch 417/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.4603 - val_loss: 7.7274\n",
      "Epoch 418/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.1139 - val_loss: 8.0877\n",
      "Epoch 419/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.8845 - val_loss: 7.4427\n",
      "Epoch 420/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.7130 - val_loss: 8.0142\n",
      "Epoch 421/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.5994 - val_loss: 7.6435\n",
      "Epoch 422/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.0239 - val_loss: 7.4005\n",
      "Epoch 423/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.7094 - val_loss: 8.2346\n",
      "Epoch 424/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.6712 - val_loss: 8.0451\n",
      "Epoch 425/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.6521 - val_loss: 8.3452\n",
      "Epoch 426/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.6844 - val_loss: 11.6687\n",
      "Epoch 427/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.2022 - val_loss: 8.8510\n",
      "Epoch 428/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.9909 - val_loss: 8.8654\n",
      "Epoch 429/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.5190 - val_loss: 9.1228\n",
      "Epoch 430/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.5782 - val_loss: 7.4249\n",
      "Epoch 431/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.6462 - val_loss: 8.4147\n",
      "Epoch 432/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.6081 - val_loss: 7.8824\n",
      "Epoch 433/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.6989 - val_loss: 8.2697\n",
      "Epoch 434/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.5634 - val_loss: 7.4876\n",
      "Epoch 435/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.5481 - val_loss: 8.8499\n",
      "Epoch 436/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 6.5163 - val_loss: 7.2054\n",
      "Epoch 437/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.8355 - val_loss: 8.2548\n",
      "Epoch 438/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.9368 - val_loss: 9.3953\n",
      "Epoch 439/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.2458 - val_loss: 8.2733\n",
      "Epoch 440/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.2397 - val_loss: 10.6906\n",
      "Epoch 441/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.8455 - val_loss: 10.4738\n",
      "Epoch 442/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.8176 - val_loss: 9.7497\n",
      "Epoch 443/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.8629 - val_loss: 7.4489\n",
      "Epoch 444/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.5915 - val_loss: 8.1907\n",
      "Epoch 445/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.9585 - val_loss: 8.8955\n",
      "Epoch 446/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.9403 - val_loss: 7.5183\n",
      "Epoch 447/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.3946 - val_loss: 7.4875\n",
      "Epoch 448/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.7974 - val_loss: 7.5579\n",
      "Epoch 449/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.5039 - val_loss: 8.1884\n",
      "Epoch 450/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.6373 - val_loss: 7.5147\n",
      "Epoch 451/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.7738 - val_loss: 9.3748\n",
      "Epoch 452/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.0522 - val_loss: 8.4304\n",
      "Epoch 453/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.3710 - val_loss: 8.4027\n",
      "Epoch 454/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.6907 - val_loss: 9.5304\n",
      "Epoch 455/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.6823 - val_loss: 10.5850\n",
      "Epoch 456/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.0512 - val_loss: 8.2146\n",
      "Epoch 457/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.9167 - val_loss: 8.6770\n",
      "Epoch 458/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.7746 - val_loss: 7.2359\n",
      "Epoch 459/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.4029 - val_loss: 7.5688\n",
      "Epoch 460/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.0975 - val_loss: 7.2804\n",
      "Epoch 461/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.7973 - val_loss: 7.5187\n",
      "Epoch 462/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.6746 - val_loss: 7.6608\n",
      "Epoch 463/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.5943 - val_loss: 7.7284\n",
      "Epoch 464/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.5125 - val_loss: 8.4727\n",
      "Epoch 465/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.2486 - val_loss: 7.8500\n",
      "Epoch 466/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.2424 - val_loss: 7.6684\n",
      "Epoch 467/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.0260 - val_loss: 7.4478\n",
      "Epoch 468/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.6227 - val_loss: 8.4643\n",
      "Epoch 469/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.6200 - val_loss: 7.9604\n",
      "Epoch 470/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.6820 - val_loss: 7.2733\n",
      "Epoch 471/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.3322 - val_loss: 9.5233\n",
      "Epoch 472/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.7991 - val_loss: 7.6727\n",
      "Epoch 473/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.4142 - val_loss: 7.0433\n",
      "Epoch 474/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.2563 - val_loss: 7.7420\n",
      "Epoch 475/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.6045 - val_loss: 9.2330\n",
      "Epoch 476/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.9051 - val_loss: 8.2285\n",
      "Epoch 477/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.2813 - val_loss: 8.1778\n",
      "Epoch 478/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.1523 - val_loss: 7.2313\n",
      "Epoch 479/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.9447 - val_loss: 7.4248\n",
      "Epoch 480/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.4778 - val_loss: 7.2951\n",
      "Epoch 481/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 6.7904 - val_loss: 7.7818\n",
      "Epoch 482/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.5534 - val_loss: 7.5941\n",
      "Epoch 483/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.4260 - val_loss: 7.6632\n",
      "Epoch 484/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.3928 - val_loss: 6.9413\n",
      "Epoch 485/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.3870 - val_loss: 10.1637\n",
      "Epoch 486/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.3882 - val_loss: 7.3042\n",
      "Epoch 487/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.3026 - val_loss: 7.4893\n",
      "Epoch 488/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.9604 - val_loss: 10.3451\n",
      "Epoch 489/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.5730 - val_loss: 8.4220\n",
      "Epoch 490/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.3826 - val_loss: 7.0919\n",
      "Epoch 491/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.2311 - val_loss: 7.2241\n",
      "Epoch 492/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.5183 - val_loss: 7.9230\n",
      "Epoch 493/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.5151 - val_loss: 7.1193\n",
      "Epoch 494/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.3067 - val_loss: 7.0852\n",
      "Epoch 495/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.2553 - val_loss: 7.2657\n",
      "Epoch 496/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.0972 - val_loss: 6.9177\n",
      "Epoch 497/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.3124 - val_loss: 8.0141\n",
      "Epoch 498/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.6033 - val_loss: 7.4943\n",
      "Epoch 499/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.3806 - val_loss: 7.3171\n",
      "Epoch 500/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.2910 - val_loss: 6.7516\n",
      "Epoch 501/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.1574 - val_loss: 7.3709\n",
      "Epoch 502/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.5004 - val_loss: 7.2109\n",
      "Epoch 503/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.4569 - val_loss: 7.6411\n",
      "Epoch 504/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.4177 - val_loss: 7.6101\n",
      "Epoch 505/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.5600 - val_loss: 8.4681\n",
      "Epoch 506/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.3240 - val_loss: 6.9817\n",
      "Epoch 507/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.2603 - val_loss: 7.6800\n",
      "Epoch 508/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.9536 - val_loss: 7.7241\n",
      "Epoch 509/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.3741 - val_loss: 6.7813\n",
      "Epoch 510/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.2539 - val_loss: 7.8443\n",
      "Epoch 511/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.1453 - val_loss: 7.2396\n",
      "Epoch 512/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 6.7116 - val_loss: 10.1213\n",
      "Epoch 513/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.7457 - val_loss: 8.2678\n",
      "Epoch 514/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.0740 - val_loss: 7.1198\n",
      "Epoch 515/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.4612 - val_loss: 7.2498\n",
      "Epoch 516/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.3475 - val_loss: 7.1543\n",
      "Epoch 517/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.6934 - val_loss: 7.8431\n",
      "Epoch 518/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.1060 - val_loss: 8.0748\n",
      "Epoch 519/1000\n",
      "1052/1052 [==============================] - 0s 129us/step - loss: 6.1616 - val_loss: 6.6784\n",
      "Epoch 520/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 6.2650 - val_loss: 8.4596\n",
      "Epoch 521/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.8783 - val_loss: 8.1269\n",
      "Epoch 522/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.2680 - val_loss: 8.5662\n",
      "Epoch 523/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.0316 - val_loss: 7.1819\n",
      "Epoch 524/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.9556 - val_loss: 6.7772\n",
      "Epoch 525/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.2259 - val_loss: 7.0454\n",
      "Epoch 526/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.0866 - val_loss: 8.0402\n",
      "Epoch 527/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.2686 - val_loss: 6.7834\n",
      "Epoch 528/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.3442 - val_loss: 6.9158\n",
      "Epoch 529/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.7605 - val_loss: 7.3311\n",
      "Epoch 530/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.5669 - val_loss: 6.6099\n",
      "Epoch 531/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.5506 - val_loss: 6.8629\n",
      "Epoch 532/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.3605 - val_loss: 7.9394\n",
      "Epoch 533/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.5867 - val_loss: 8.2361\n",
      "Epoch 534/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.6946 - val_loss: 6.9248\n",
      "Epoch 535/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.2101 - val_loss: 7.6631\n",
      "Epoch 536/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.2349 - val_loss: 7.4345\n",
      "Epoch 537/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.1896 - val_loss: 6.7009\n",
      "Epoch 538/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.1502 - val_loss: 6.5176\n",
      "Epoch 539/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.4428 - val_loss: 6.7356\n",
      "Epoch 540/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.0783 - val_loss: 8.0216\n",
      "Epoch 541/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.7151 - val_loss: 7.0933\n",
      "Epoch 542/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.1757 - val_loss: 6.5725\n",
      "Epoch 543/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.0364 - val_loss: 7.5077\n",
      "Epoch 544/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.2730 - val_loss: 6.7132\n",
      "Epoch 545/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.5002 - val_loss: 6.5977\n",
      "Epoch 546/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.2662 - val_loss: 8.2649\n",
      "Epoch 547/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.1028 - val_loss: 6.9992\n",
      "Epoch 548/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.1296 - val_loss: 6.4282\n",
      "Epoch 549/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.2524 - val_loss: 6.6439\n",
      "Epoch 550/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.9329 - val_loss: 8.4634\n",
      "Epoch 551/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.5853 - val_loss: 7.9416\n",
      "Epoch 552/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.3124 - val_loss: 7.5773\n",
      "Epoch 553/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.2501 - val_loss: 6.9155\n",
      "Epoch 554/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.0665 - val_loss: 10.5955\n",
      "Epoch 555/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 6.6575 - val_loss: 10.5475\n",
      "Epoch 556/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 6.8579 - val_loss: 7.2434\n",
      "Epoch 557/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 6.9125 - val_loss: 6.4070\n",
      "Epoch 558/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 5.9957 - val_loss: 6.7933\n",
      "Epoch 559/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 6.3328 - val_loss: 6.9857\n",
      "Epoch 560/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 5.8723 - val_loss: 7.0305\n",
      "Epoch 561/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 5.9347 - val_loss: 6.6581\n",
      "Epoch 562/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 5.5770 - 0s 101us/step - loss: 6.1334 - val_loss: 7.1758\n",
      "Epoch 563/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 5.6865 - val_loss: 6.3176\n",
      "Epoch 564/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.8792 - val_loss: 6.5684\n",
      "Epoch 565/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.1119 - val_loss: 6.7479\n",
      "Epoch 566/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.0076 - val_loss: 7.2614\n",
      "Epoch 567/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.6142 - val_loss: 6.6084\n",
      "Epoch 568/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.8637 - val_loss: 6.8530\n",
      "Epoch 569/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.9953 - val_loss: 6.5668\n",
      "Epoch 570/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.1666 - val_loss: 7.9683\n",
      "Epoch 571/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.1492 - val_loss: 6.7473\n",
      "Epoch 572/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.0610 - val_loss: 7.5419\n",
      "Epoch 573/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.6729 - val_loss: 7.4091\n",
      "Epoch 574/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.1424 - val_loss: 6.5738\n",
      "Epoch 575/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.0787 - val_loss: 9.5528\n",
      "Epoch 576/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.2574 - val_loss: 6.9775\n",
      "Epoch 577/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.5572 - val_loss: 6.8158\n",
      "Epoch 578/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.2751 - val_loss: 6.3699\n",
      "Epoch 579/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.0086 - val_loss: 6.2446\n",
      "Epoch 580/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.8518 - val_loss: 7.1359\n",
      "Epoch 581/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.5229 - val_loss: 7.9621\n",
      "Epoch 582/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.2388 - val_loss: 6.7973\n",
      "Epoch 583/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.5257 - val_loss: 6.7580\n",
      "Epoch 584/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.3902 - val_loss: 7.1950\n",
      "Epoch 585/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.0104 - val_loss: 6.4164\n",
      "Epoch 586/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.2840 - val_loss: 7.2659\n",
      "Epoch 587/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.7113 - val_loss: 6.5296\n",
      "Epoch 588/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.2554 - val_loss: 6.3144\n",
      "Epoch 589/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.5871 - val_loss: 7.4965\n",
      "Epoch 590/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.3055 - val_loss: 7.2935\n",
      "Epoch 591/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.5306 - val_loss: 8.2705\n",
      "Epoch 592/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.5046 - val_loss: 6.7648\n",
      "Epoch 593/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.9540 - val_loss: 6.5839\n",
      "Epoch 594/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.2190 - val_loss: 6.3366\n",
      "Epoch 595/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.2152 - val_loss: 6.7088\n",
      "Epoch 596/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.7893 - val_loss: 6.5200\n",
      "Epoch 597/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.1082 - val_loss: 6.9372\n",
      "Epoch 598/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.2383 - val_loss: 7.2127\n",
      "Epoch 599/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.0889 - val_loss: 6.8893\n",
      "Epoch 600/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.0602 - val_loss: 8.0662\n",
      "Epoch 601/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.2859 - val_loss: 7.1518\n",
      "Epoch 602/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.0240 - val_loss: 6.5471\n",
      "Epoch 603/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.1134 - val_loss: 7.2418\n",
      "Epoch 604/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.0321 - val_loss: 8.0327\n",
      "Epoch 605/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.3596 - val_loss: 6.8115\n",
      "Epoch 606/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.8221 - val_loss: 6.8080\n",
      "Epoch 607/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.2610 - val_loss: 6.3742\n",
      "Epoch 608/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.9723 - val_loss: 6.4252\n",
      "Epoch 609/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.9561 - val_loss: 7.0952\n",
      "Epoch 610/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.8849 - val_loss: 8.2279\n",
      "Epoch 611/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.9474 - val_loss: 6.6692\n",
      "Epoch 612/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.8768 - val_loss: 6.7256\n",
      "Epoch 613/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.8207 - val_loss: 6.8648\n",
      "Epoch 614/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.4125 - val_loss: 8.4019\n",
      "Epoch 615/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.7867 - val_loss: 6.9846\n",
      "Epoch 616/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.4240 - val_loss: 6.9092\n",
      "Epoch 617/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 6.6368 - val_loss: 6.8584\n",
      "Epoch 618/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.4979 - val_loss: 9.4087\n",
      "Epoch 619/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.2333 - val_loss: 6.0594\n",
      "Epoch 620/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.7373 - val_loss: 6.8402\n",
      "Epoch 621/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.7436 - val_loss: 6.1360\n",
      "Epoch 622/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.8784 - val_loss: 6.5826\n",
      "Epoch 623/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.7781 - val_loss: 6.4761\n",
      "Epoch 624/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.9784 - val_loss: 6.4834\n",
      "Epoch 625/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.8844 - val_loss: 6.7666\n",
      "Epoch 626/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.1646 - val_loss: 6.1238\n",
      "Epoch 627/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.9548 - val_loss: 7.1533\n",
      "Epoch 628/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.8803 - val_loss: 6.3428\n",
      "Epoch 629/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.8371 - val_loss: 6.1579\n",
      "Epoch 630/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.0972 - val_loss: 7.0060\n",
      "Epoch 631/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.7520 - val_loss: 7.7601\n",
      "Epoch 632/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.1452 - val_loss: 6.3945\n",
      "Epoch 633/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.3475 - val_loss: 6.6323\n",
      "Epoch 634/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.8001 - val_loss: 6.3472\n",
      "Epoch 635/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.8054 - val_loss: 6.7587\n",
      "Epoch 636/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.7453 - val_loss: 6.1265\n",
      "Epoch 637/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.7317 - val_loss: 7.2516\n",
      "Epoch 638/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.0789 - val_loss: 7.6134\n",
      "Epoch 639/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.7360 - val_loss: 7.4438\n",
      "Epoch 640/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.5436 - val_loss: 7.8870\n",
      "Epoch 641/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.9011 - val_loss: 6.6770\n",
      "Epoch 642/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.9670 - val_loss: 6.3071\n",
      "Epoch 643/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.0412 - val_loss: 7.4420\n",
      "Epoch 644/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.5365 - val_loss: 6.7424\n",
      "Epoch 645/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.1681 - val_loss: 6.7390\n",
      "Epoch 646/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.3002 - val_loss: 6.9970\n",
      "Epoch 647/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.7492 - val_loss: 6.1039\n",
      "Epoch 648/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.9514 - val_loss: 7.8177\n",
      "Epoch 649/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.9155 - val_loss: 6.3588\n",
      "Epoch 650/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.7077 - val_loss: 7.8899\n",
      "Epoch 651/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.1527 - val_loss: 6.2120\n",
      "Epoch 652/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.3482 - val_loss: 7.8719\n",
      "Epoch 653/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.8103 - val_loss: 6.7182\n",
      "Epoch 654/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.1722 - val_loss: 6.9310\n",
      "Epoch 655/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.9593 - val_loss: 7.1107\n",
      "Epoch 656/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.9528 - val_loss: 7.1969\n",
      "Epoch 657/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.8468 - val_loss: 6.2605\n",
      "Epoch 658/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 6.1153 - val_loss: 9.6744\n",
      "Epoch 659/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.4029 - val_loss: 6.9284\n",
      "Epoch 660/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.4083 - val_loss: 7.8294\n",
      "Epoch 661/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.3162 - val_loss: 6.9196\n",
      "Epoch 662/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.3211 - val_loss: 7.0752\n",
      "Epoch 663/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.4064 - val_loss: 5.9657\n",
      "Epoch 664/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.6138 - val_loss: 6.3140\n",
      "Epoch 665/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.3364 - val_loss: 6.8241\n",
      "Epoch 666/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.1584 - val_loss: 6.8558\n",
      "Epoch 667/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.0527 - val_loss: 8.1228\n",
      "Epoch 668/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.0846 - val_loss: 6.4579\n",
      "Epoch 669/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.1418 - val_loss: 7.0501\n",
      "Epoch 670/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.9697 - val_loss: 5.8997\n",
      "Epoch 671/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.8062 - val_loss: 6.6786\n",
      "Epoch 672/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.9557 - val_loss: 6.6197\n",
      "Epoch 673/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.4331 - val_loss: 7.5378\n",
      "Epoch 674/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.0023 - val_loss: 5.8340\n",
      "Epoch 675/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.2404 - val_loss: 7.7130\n",
      "Epoch 676/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.8938 - val_loss: 6.7603\n",
      "Epoch 677/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.0911 - val_loss: 5.8853\n",
      "Epoch 678/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.8312 - val_loss: 6.1512\n",
      "Epoch 679/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6740 - val_loss: 8.7376\n",
      "Epoch 680/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.7648 - val_loss: 5.7841\n",
      "Epoch 681/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6924 - val_loss: 5.9831\n",
      "Epoch 682/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.9259 - val_loss: 7.5480\n",
      "Epoch 683/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.1196 - val_loss: 6.9995\n",
      "Epoch 684/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.0352 - val_loss: 6.3581\n",
      "Epoch 685/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.7478 - val_loss: 6.4933\n",
      "Epoch 686/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6475 - val_loss: 6.1277\n",
      "Epoch 687/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.5933 - val_loss: 7.3732\n",
      "Epoch 688/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.9077 - val_loss: 6.3653\n",
      "Epoch 689/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6005 - val_loss: 8.1460\n",
      "Epoch 690/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 6.0492 - val_loss: 7.5764\n",
      "Epoch 691/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.5678 - val_loss: 6.4118\n",
      "Epoch 692/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.7091 - val_loss: 7.3438\n",
      "Epoch 693/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.7224 - val_loss: 6.8115\n",
      "Epoch 694/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.8350 - val_loss: 5.8966\n",
      "Epoch 695/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.7360 - val_loss: 6.5289\n",
      "Epoch 696/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.5795 - val_loss: 6.7817\n",
      "Epoch 697/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.8800 - val_loss: 6.1225\n",
      "Epoch 698/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.9052 - val_loss: 6.3657\n",
      "Epoch 699/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.6735 - val_loss: 5.9073\n",
      "Epoch 700/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.8741 - val_loss: 6.6073\n",
      "Epoch 701/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.8289 - val_loss: 7.2828\n",
      "Epoch 702/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.7382 - val_loss: 6.1314\n",
      "Epoch 703/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.8694 - val_loss: 7.5924\n",
      "Epoch 704/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.6865 - val_loss: 6.4608\n",
      "Epoch 705/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.6943 - val_loss: 6.0819\n",
      "Epoch 706/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.7748 - val_loss: 6.3316\n",
      "Epoch 707/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.1585 - val_loss: 7.8778\n",
      "Epoch 708/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.0470 - val_loss: 6.8288\n",
      "Epoch 709/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.9857 - val_loss: 6.1854\n",
      "Epoch 710/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.5984 - val_loss: 6.2064\n",
      "Epoch 711/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.8608 - val_loss: 6.0216\n",
      "Epoch 712/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6978 - val_loss: 9.5470\n",
      "Epoch 713/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.2496 - val_loss: 7.3944\n",
      "Epoch 714/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.1980 - val_loss: 8.7824\n",
      "Epoch 715/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.9560 - val_loss: 7.3836\n",
      "Epoch 716/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.4727 - val_loss: 6.2136\n",
      "Epoch 717/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.2746 - val_loss: 6.7031\n",
      "Epoch 718/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.1570 - val_loss: 6.1463\n",
      "Epoch 719/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.9747 - val_loss: 6.5482\n",
      "Epoch 720/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.8842 - val_loss: 8.0725\n",
      "Epoch 721/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.6151 - val_loss: 6.8776\n",
      "Epoch 722/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.1152 - val_loss: 6.5482\n",
      "Epoch 723/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.7514 - val_loss: 6.7267\n",
      "Epoch 724/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.7511 - val_loss: 6.3764\n",
      "Epoch 725/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 6.0130 - val_loss: 7.8947\n",
      "Epoch 726/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 6.2037 - val_loss: 5.7703\n",
      "Epoch 727/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 6.1790 - val_loss: 7.2212\n",
      "Epoch 728/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 6.2226 - val_loss: 7.6783\n",
      "Epoch 729/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 5.9075 - val_loss: 6.9280\n",
      "Epoch 730/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 5.5775 - val_loss: 6.0681\n",
      "Epoch 731/1000\n",
      "1052/1052 [==============================] - 0s 115us/step - loss: 6.1043 - val_loss: 7.7933\n",
      "Epoch 732/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 5.8166 - val_loss: 6.9102\n",
      "Epoch 733/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 6.0116 - val_loss: 5.8981\n",
      "Epoch 734/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.9050 - val_loss: 6.3037\n",
      "Epoch 735/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.7428 - val_loss: 5.9074\n",
      "Epoch 736/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.0075 - val_loss: 7.0056\n",
      "Epoch 737/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.9742 - val_loss: 6.1039\n",
      "Epoch 738/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.9530 - val_loss: 6.1385\n",
      "Epoch 739/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.3432 - val_loss: 7.2151\n",
      "Epoch 740/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.8096 - val_loss: 7.0705\n",
      "Epoch 741/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.8769 - val_loss: 6.3554\n",
      "Epoch 742/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.9520 - val_loss: 6.1560\n",
      "Epoch 743/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.6175 - val_loss: 6.4369\n",
      "Epoch 744/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.2046 - val_loss: 5.6908\n",
      "Epoch 745/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.5576 - val_loss: 6.3746\n",
      "Epoch 746/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.7036 - val_loss: 5.9268\n",
      "Epoch 747/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.9429 - val_loss: 6.1893\n",
      "Epoch 748/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.9271 - val_loss: 5.9166\n",
      "Epoch 749/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.0603 - val_loss: 6.8693\n",
      "Epoch 750/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6002 - val_loss: 6.0443\n",
      "Epoch 751/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.6462 - val_loss: 7.2339\n",
      "Epoch 752/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.7068 - val_loss: 5.6757\n",
      "Epoch 753/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.1949 - val_loss: 6.5350\n",
      "Epoch 754/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.2385 - val_loss: 7.8163\n",
      "Epoch 755/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.9810 - val_loss: 5.9092\n",
      "Epoch 756/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.1272 - val_loss: 6.1650\n",
      "Epoch 757/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.8965 - val_loss: 6.2057\n",
      "Epoch 758/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.5384 - val_loss: 6.5574\n",
      "Epoch 759/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 6.5249 - val_loss: 6.1939\n",
      "Epoch 760/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 5.8345 - val_loss: 5.7132\n",
      "Epoch 761/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.7580 - val_loss: 6.2942\n",
      "Epoch 762/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.7746 - val_loss: 6.3584\n",
      "Epoch 763/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.7872 - val_loss: 6.7393\n",
      "Epoch 764/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.7433 - val_loss: 6.4595\n",
      "Epoch 765/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.8910 - val_loss: 6.3044\n",
      "Epoch 766/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.7215 - val_loss: 5.7187\n",
      "Epoch 767/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6370 - val_loss: 6.1508\n",
      "Epoch 768/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.8016 - val_loss: 6.1587\n",
      "Epoch 769/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.2223 - val_loss: 6.8108\n",
      "Epoch 770/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.9565 - val_loss: 6.5543\n",
      "Epoch 771/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 5.6811 - val_loss: 7.4338\n",
      "Epoch 772/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.8992 - val_loss: 6.7808\n",
      "Epoch 773/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.7538 - val_loss: 6.1974\n",
      "Epoch 774/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.8460 - val_loss: 5.8151\n",
      "Epoch 775/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.6794 - val_loss: 6.0007\n",
      "Epoch 776/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.6868 - val_loss: 7.4956\n",
      "Epoch 777/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.4238 - val_loss: 5.7377\n",
      "Epoch 778/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.9843 - val_loss: 5.9565\n",
      "Epoch 779/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.6849 - val_loss: 6.4084\n",
      "Epoch 780/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 5.8761 - val_loss: 5.9362\n",
      "Epoch 781/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 6.0337 - val_loss: 5.9975\n",
      "Epoch 782/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.6280 - val_loss: 6.6893\n",
      "Epoch 783/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.0972 - val_loss: 8.3017\n",
      "Epoch 784/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.8003 - val_loss: 5.8932\n",
      "Epoch 785/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 5.5759 - val_loss: 6.1051\n",
      "Epoch 786/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 5.9204 - val_loss: 6.2603\n",
      "Epoch 787/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.8300 - val_loss: 7.8153\n",
      "Epoch 788/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 5.9175 - val_loss: 6.5855\n",
      "Epoch 789/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 5.7580 - val_loss: 6.4276\n",
      "Epoch 790/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.8441 - val_loss: 6.3471\n",
      "Epoch 791/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.0711 - val_loss: 7.6463\n",
      "Epoch 792/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.7336 - val_loss: 5.6428\n",
      "Epoch 793/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 5.6899 - val_loss: 6.7358\n",
      "Epoch 794/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 5.9022 - val_loss: 7.3720\n",
      "Epoch 795/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.7923 - val_loss: 6.2235\n",
      "Epoch 796/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 6.0278 - val_loss: 6.8565\n",
      "Epoch 797/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 5.7126 - val_loss: 5.9325\n",
      "Epoch 798/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 5.6477 - val_loss: 6.1560\n",
      "Epoch 799/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.2572 - val_loss: 6.1571\n",
      "Epoch 800/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.9214 - val_loss: 6.6734\n",
      "Epoch 801/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 5.5105 - val_loss: 5.7756\n",
      "Epoch 802/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 5.5846 - val_loss: 5.5963\n",
      "Epoch 803/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 5.5429 - val_loss: 6.5661\n",
      "Epoch 804/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 5.7444 - val_loss: 6.1307\n",
      "Epoch 805/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 6.1677 - val_loss: 6.6262\n",
      "Epoch 806/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.7267 - val_loss: 6.3083\n",
      "Epoch 807/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 5.7890 - val_loss: 5.6871\n",
      "Epoch 808/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 5.6372 - val_loss: 5.5953\n",
      "Epoch 809/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 5.6884 - val_loss: 7.2757\n",
      "Epoch 810/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.7940 - val_loss: 6.0333\n",
      "Epoch 811/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 5.5228 - val_loss: 5.7851\n",
      "Epoch 812/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.0029 - val_loss: 7.8195\n",
      "Epoch 813/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.2314 - val_loss: 6.8622\n",
      "Epoch 814/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.1028 - val_loss: 6.1050\n",
      "Epoch 815/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 5.9964 - val_loss: 6.0069\n",
      "Epoch 816/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.7924 - val_loss: 6.4548\n",
      "Epoch 817/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 5.5566 - val_loss: 6.2655\n",
      "Epoch 818/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 5.6661 - val_loss: 6.7535\n",
      "Epoch 819/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.7109 - val_loss: 5.7142\n",
      "Epoch 820/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.6747 - val_loss: 6.1479\n",
      "Epoch 821/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.6233 - val_loss: 6.6135\n",
      "Epoch 822/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.8370 - val_loss: 7.4696\n",
      "Epoch 823/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.2980 - val_loss: 6.5433\n",
      "Epoch 824/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.2100 - val_loss: 6.6289\n",
      "Epoch 825/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.5481 - val_loss: 5.6837\n",
      "Epoch 826/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.5340 - val_loss: 6.3850\n",
      "Epoch 827/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.4927 - val_loss: 6.0895\n",
      "Epoch 828/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.8835 - val_loss: 9.6062\n",
      "Epoch 829/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.1143 - val_loss: 6.5686\n",
      "Epoch 830/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.7006 - val_loss: 5.8648\n",
      "Epoch 831/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.4694 - val_loss: 6.5738\n",
      "Epoch 832/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.8952 - val_loss: 5.8583\n",
      "Epoch 833/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.8961 - val_loss: 6.5583\n",
      "Epoch 834/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.6522 - val_loss: 6.3503\n",
      "Epoch 835/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.5908 - val_loss: 5.9230\n",
      "Epoch 836/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.6997 - val_loss: 5.7542\n",
      "Epoch 837/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6009 - val_loss: 6.6425\n",
      "Epoch 838/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.8985 - val_loss: 6.5620\n",
      "Epoch 839/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.5210 - val_loss: 5.8246\n",
      "Epoch 840/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.8675 - val_loss: 7.0520\n",
      "Epoch 841/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.8712 - val_loss: 6.7421\n",
      "Epoch 842/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.5001 - val_loss: 5.7021\n",
      "Epoch 843/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.6533 - val_loss: 5.7858\n",
      "Epoch 844/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.7252 - val_loss: 6.4963\n",
      "Epoch 845/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.4679 - val_loss: 5.7949\n",
      "Epoch 846/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.6835 - val_loss: 6.6016\n",
      "Epoch 847/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.7408 - val_loss: 6.0583\n",
      "Epoch 848/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.0191 - val_loss: 7.1827\n",
      "Epoch 849/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6665 - val_loss: 6.3206\n",
      "Epoch 850/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.5127 - val_loss: 5.7472\n",
      "Epoch 851/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.7211 - val_loss: 7.3575\n",
      "Epoch 852/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.7975 - val_loss: 6.3904\n",
      "Epoch 853/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.6192 - val_loss: 5.7455\n",
      "Epoch 854/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.9547 - val_loss: 6.5118\n",
      "Epoch 855/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.5652 - val_loss: 6.2447\n",
      "Epoch 856/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.2162 - val_loss: 6.9390\n",
      "Epoch 857/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.5881 - val_loss: 6.9800\n",
      "Epoch 858/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.2781 - val_loss: 6.1120\n",
      "Epoch 859/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6759 - val_loss: 7.7314\n",
      "Epoch 860/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.8767 - val_loss: 6.5288\n",
      "Epoch 861/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.5983 - val_loss: 7.4041\n",
      "Epoch 862/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.5902 - val_loss: 5.6274\n",
      "Epoch 863/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.5660 - val_loss: 6.1527\n",
      "Epoch 864/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6415 - val_loss: 6.6746\n",
      "Epoch 865/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.6547 - val_loss: 5.6056\n",
      "Epoch 866/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.6935 - val_loss: 6.4051\n",
      "Epoch 867/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.4782 - val_loss: 6.2291\n",
      "Epoch 868/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.5198 - val_loss: 5.8019\n",
      "Epoch 869/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.7988 - val_loss: 6.5275\n",
      "Epoch 870/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.0109 - val_loss: 7.2177\n",
      "Epoch 871/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.4591 - val_loss: 7.0968\n",
      "Epoch 872/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.7321 - val_loss: 6.4125\n",
      "Epoch 873/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6406 - val_loss: 6.1527\n",
      "Epoch 874/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6012 - val_loss: 5.7959\n",
      "Epoch 875/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.0772 - val_loss: 6.6987\n",
      "Epoch 876/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.8842 - val_loss: 5.7582\n",
      "Epoch 877/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.2145 - val_loss: 6.9164\n",
      "Epoch 878/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.9346 - val_loss: 6.1021\n",
      "Epoch 879/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.9389 - val_loss: 6.3109\n",
      "Epoch 880/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.6214 - val_loss: 7.1599\n",
      "Epoch 881/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.7349 - val_loss: 5.9658\n",
      "Epoch 882/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.7581 - val_loss: 5.7818\n",
      "Epoch 883/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.5641 - val_loss: 5.9408\n",
      "Epoch 884/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.6302 - val_loss: 5.4061\n",
      "Epoch 885/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.4262 - val_loss: 5.7434\n",
      "Epoch 886/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.7094 - val_loss: 6.2181\n",
      "Epoch 887/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.7608 - val_loss: 6.6401\n",
      "Epoch 888/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.7077 - val_loss: 5.4813\n",
      "Epoch 889/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.8605 - val_loss: 5.9637\n",
      "Epoch 890/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.0678 - val_loss: 5.7515\n",
      "Epoch 891/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 5.7247 - val_loss: 5.6812\n",
      "Epoch 892/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 5.6228 - val_loss: 5.7960\n",
      "Epoch 893/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 5.5984 - val_loss: 5.9190\n",
      "Epoch 894/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 6.0658 - val_loss: 6.4383\n",
      "Epoch 895/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 5.8394 - val_loss: 5.9048\n",
      "Epoch 896/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 5.5626 - val_loss: 5.5673\n",
      "Epoch 897/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.4753 - val_loss: 5.6015\n",
      "Epoch 898/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.8990 - val_loss: 6.5926\n",
      "Epoch 899/1000\n",
      "1052/1052 [==============================] - 0s 113us/step - loss: 5.5866 - val_loss: 6.3342\n",
      "Epoch 900/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.1621 - val_loss: 6.5368\n",
      "Epoch 901/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.9353 - val_loss: 6.4715\n",
      "Epoch 902/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.5167 - val_loss: 5.7311\n",
      "Epoch 903/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.4975 - val_loss: 6.8955\n",
      "Epoch 904/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.9089 - val_loss: 6.2251\n",
      "Epoch 905/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.6876 - val_loss: 5.5375\n",
      "Epoch 906/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.9351 - val_loss: 5.7337\n",
      "Epoch 907/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.2473 - val_loss: 5.6560\n",
      "Epoch 908/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.4331 - val_loss: 6.2410\n",
      "Epoch 909/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.2580 - val_loss: 11.4335\n",
      "Epoch 910/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.8918 - val_loss: 5.8737\n",
      "Epoch 911/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.8135 - val_loss: 5.7105\n",
      "Epoch 912/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.4688 - val_loss: 6.4260\n",
      "Epoch 913/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.2154 - val_loss: 9.3411\n",
      "Epoch 914/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.7183 - val_loss: 6.4025\n",
      "Epoch 915/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.4093 - val_loss: 7.5800\n",
      "Epoch 916/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.7791 - val_loss: 7.7219\n",
      "Epoch 917/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.7607 - val_loss: 5.9858\n",
      "Epoch 918/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.7616 - val_loss: 6.5134\n",
      "Epoch 919/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6237 - val_loss: 6.6850\n",
      "Epoch 920/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.5583 - val_loss: 7.2420\n",
      "Epoch 921/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.4792 - val_loss: 6.2627\n",
      "Epoch 922/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.6946 - val_loss: 6.6188\n",
      "Epoch 923/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.5271 - val_loss: 6.5747\n",
      "Epoch 924/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6703 - val_loss: 5.9153\n",
      "Epoch 925/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.0330 - val_loss: 5.7792\n",
      "Epoch 926/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.9241 - val_loss: 6.9223\n",
      "Epoch 927/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.8907 - val_loss: 7.5234\n",
      "Epoch 928/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.0386 - val_loss: 7.3327\n",
      "Epoch 929/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.7052 - val_loss: 5.9487\n",
      "Epoch 930/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.5553 - val_loss: 6.2456\n",
      "Epoch 931/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.6563 - val_loss: 5.7572\n",
      "Epoch 932/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.7720 - val_loss: 5.9749\n",
      "Epoch 933/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.6886 - val_loss: 5.6885\n",
      "Epoch 934/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6788 - val_loss: 6.1720\n",
      "Epoch 935/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.0104 - val_loss: 6.3591\n",
      "Epoch 936/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.0484 - val_loss: 5.6969\n",
      "Epoch 937/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.4935 - val_loss: 5.6042\n",
      "Epoch 938/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.8455 - val_loss: 5.9317\n",
      "Epoch 939/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.4008 - val_loss: 5.8398\n",
      "Epoch 940/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.7338 - val_loss: 5.5979\n",
      "Epoch 941/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.7462 - val_loss: 8.2438\n",
      "Epoch 942/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.2563 - val_loss: 6.2527\n",
      "Epoch 943/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.0680 - val_loss: 5.9483\n",
      "Epoch 944/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.9469 - val_loss: 7.0994\n",
      "Epoch 945/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.7586 - val_loss: 6.5224\n",
      "Epoch 946/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 6.1778 - val_loss: 5.6220\n",
      "Epoch 947/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.4786 - val_loss: 6.2932\n",
      "Epoch 948/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.5388 - val_loss: 6.2686\n",
      "Epoch 949/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6628 - val_loss: 6.1437\n",
      "Epoch 950/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.5524 - val_loss: 5.3939\n",
      "Epoch 951/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6794 - val_loss: 5.9906\n",
      "Epoch 952/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6176 - val_loss: 5.7313\n",
      "Epoch 953/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.9934 - val_loss: 5.5669\n",
      "Epoch 954/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.5809 - val_loss: 5.7058\n",
      "Epoch 955/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6685 - val_loss: 6.1869\n",
      "Epoch 956/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.6728 - val_loss: 6.7471\n",
      "Epoch 957/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6567 - val_loss: 5.8888\n",
      "Epoch 958/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.7941 - val_loss: 5.4822\n",
      "Epoch 959/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.3302 - val_loss: 6.7999\n",
      "Epoch 960/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.8579 - val_loss: 5.5942\n",
      "Epoch 961/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.6498 - val_loss: 5.5487\n",
      "Epoch 962/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.7522 - val_loss: 6.5323\n",
      "Epoch 963/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.4594 - val_loss: 6.8950\n",
      "Epoch 964/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.3348 - val_loss: 7.3066\n",
      "Epoch 965/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6984 - val_loss: 6.0927\n",
      "Epoch 966/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.7544 - val_loss: 6.1128\n",
      "Epoch 967/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.8805 - val_loss: 5.7220\n",
      "Epoch 968/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.7038 - val_loss: 5.9730\n",
      "Epoch 969/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.5244 - val_loss: 5.7011\n",
      "Epoch 970/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.3961 - val_loss: 5.7668\n",
      "Epoch 971/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6023 - val_loss: 6.4694\n",
      "Epoch 972/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.4441 - val_loss: 5.8920\n",
      "Epoch 973/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.7407 - val_loss: 9.0118\n",
      "Epoch 974/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.1419 - val_loss: 5.8421\n",
      "Epoch 975/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.0646 - val_loss: 5.7930\n",
      "Epoch 976/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.5302 - val_loss: 6.0339\n",
      "Epoch 977/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.8144 - val_loss: 6.0302\n",
      "Epoch 978/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.9687 - val_loss: 7.9997\n",
      "Epoch 979/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.8932 - val_loss: 6.6664\n",
      "Epoch 980/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.2242 - val_loss: 8.2443\n",
      "Epoch 981/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.3670 - val_loss: 5.6643\n",
      "Epoch 982/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.7972 - val_loss: 5.8406\n",
      "Epoch 983/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.4023 - val_loss: 5.8882\n",
      "Epoch 984/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.7214 - val_loss: 6.7398\n",
      "Epoch 985/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 5.5048 - val_loss: 5.7326\n",
      "Epoch 986/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.4107 - val_loss: 5.6580\n",
      "Epoch 987/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.7159 - val_loss: 6.2548\n",
      "Epoch 988/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6532 - val_loss: 7.4440\n",
      "Epoch 989/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.5035 - val_loss: 5.4125\n",
      "Epoch 990/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.3413 - val_loss: 5.5784\n",
      "Epoch 991/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.9495 - val_loss: 6.2275\n",
      "Epoch 992/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.3774 - val_loss: 5.4012\n",
      "Epoch 993/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.3835 - val_loss: 6.5151\n",
      "Epoch 994/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.5443 - val_loss: 6.0960\n",
      "Epoch 995/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.2141 - val_loss: 6.3305\n",
      "Epoch 996/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.1979 - val_loss: 6.2115\n",
      "Epoch 997/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.2698 - val_loss: 5.9096\n",
      "Epoch 998/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.7389 - val_loss: 5.7353\n",
      "Epoch 999/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.8910 - val_loss: 8.8699\n",
      "Epoch 1000/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.0291 - val_loss: 7.1001\n",
      "5.801885959321418\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 0.39857805, -2.874988  , -4.1522555 ,  3.5720425 ,  0.07070028,\n",
       "         -0.48855358,  3.8396451 , -0.35278448, -1.1204606 , -0.24707508],\n",
       "        [ 0.28992748,  0.16765077, -0.44597188, -0.07781048,  0.15109262,\n",
       "         -1.036199  , -0.14750469,  0.08862649, -0.8946287 , -0.4639674 ],\n",
       "        [ 0.412285  , -0.08402127, -2.061377  ,  1.6398654 ,  0.29448637,\n",
       "         -1.8465567 , -0.08733255, -0.5006165 , -0.21092129, -1.5322034 ],\n",
       "        [-0.5294359 ,  0.0754496 ,  0.2348902 , -0.15903318,  0.5030779 ,\n",
       "         -0.7020627 , -0.05018321,  0.129734  ,  0.35723966,  0.11558765],\n",
       "        [ 0.3802432 , -0.24111709, -0.7402314 , -0.20249675, -0.72839683,\n",
       "         -0.6693197 ,  2.0102072 , -1.7434137 , -1.4586947 ,  0.02293078]],\n",
       "       dtype=float32),\n",
       " array([-2.1692998 , -1.6766753 , -4.190005  ,  5.6368356 , -4.445437  ,\n",
       "         5.6290693 ,  4.6944685 , -2.5627081 , -0.57562375, -1.1526766 ],\n",
       "       dtype=float32),\n",
       " array([[ 0.4723931 , -0.66036904,  1.0017245 ,  0.12725852, -0.69866145,\n",
       "          0.31095257,  0.45416644,  0.8261083 ,  0.86060375,  0.8921554 ,\n",
       "          0.89733076, -0.57963574,  0.00521195, -1.128948  ,  0.42588055],\n",
       "        [-0.9961509 , -0.93429077, -0.30547568,  1.2763057 ,  1.047465  ,\n",
       "         -0.95446575,  0.12670249, -0.2822636 , -0.3213104 , -0.6381813 ,\n",
       "         -1.0109606 ,  0.82450926, -1.1102529 ,  0.9463437 , -0.36183304],\n",
       "        [ 0.5134973 , -0.39750686,  0.956528  ,  0.07538625, -0.8956746 ,\n",
       "          0.59747446,  0.06315137,  0.98552525,  0.04724875,  0.7888612 ,\n",
       "          0.00651522, -0.16211975,  0.57700914, -0.3297499 ,  0.18318838],\n",
       "        [-1.2660015 , -1.3073566 , -2.1671371 ,  1.6097772 ,  2.0306745 ,\n",
       "         -2.0633526 ,  0.7979158 , -2.2720115 , -1.2516341 , -2.285742  ,\n",
       "         -1.3612969 ,  2.1905887 , -1.7785718 ,  1.9524872 , -1.7733611 ],\n",
       "        [ 0.18805572, -0.17501885,  1.259051  , -0.32663268, -0.8960431 ,\n",
       "          1.1735886 ,  0.23005761,  1.4330856 ,  1.0312871 ,  1.0495113 ,\n",
       "          1.2782872 , -1.2525336 ,  0.6578538 , -1.4151118 ,  0.55234116],\n",
       "        [-0.85916954, -0.39359236, -1.1395513 ,  0.44238988,  1.3472881 ,\n",
       "         -1.6310531 , -0.18605231, -1.0619144 , -0.92358404, -0.73563963,\n",
       "         -1.2728294 ,  0.7242596 , -1.0119116 ,  1.188036  , -1.1145227 ],\n",
       "        [-1.1424005 , -1.0205314 , -1.8727158 ,  0.9728931 ,  2.2138045 ,\n",
       "         -2.4240508 ,  0.11477542, -1.4850707 , -1.7422922 , -2.3288052 ,\n",
       "         -1.4365648 ,  1.3226163 , -1.849826  ,  2.366259  , -1.2209561 ],\n",
       "        [ 0.09067398,  0.03237216,  0.971563  , -0.09003527, -0.43683946,\n",
       "          0.75812346, -0.02972307,  0.81966007,  0.19435602,  1.1681448 ,\n",
       "          0.87351143, -0.561231  ,  0.7679511 , -0.6968844 ,  0.29496914],\n",
       "        [-0.4912284 , -0.33666822, -0.40766162,  0.14175582, -0.00957787,\n",
       "         -0.08187262,  0.1788887 , -0.17870311, -0.66490895, -0.7559038 ,\n",
       "         -0.24277604,  0.18817337, -0.43607783,  0.51643527,  0.00316665],\n",
       "        [-0.7646805 , -0.43231425, -0.6039128 ,  0.7552871 ,  0.4128068 ,\n",
       "         -0.41455573,  0.11355729, -0.7966647 , -0.45731097, -0.4516545 ,\n",
       "         -0.9308839 ,  0.57106227, -0.8537312 ,  0.8589437 , -0.3295609 ]],\n",
       "       dtype=float32),\n",
       " array([-1.2272182 , -0.87559843, -1.6165946 ,  0.9296432 ,  1.6609317 ,\n",
       "        -1.6945591 ,  0.11556695, -1.6414936 , -1.4795076 , -1.7079078 ,\n",
       "        -1.5078002 ,  1.4749908 , -1.4986086 ,  1.7164444 , -1.4558841 ],\n",
       "       dtype=float32),\n",
       " array([[-0.5552172 ],\n",
       "        [-0.22052446],\n",
       "        [-1.2798736 ],\n",
       "        [ 0.3906155 ],\n",
       "        [ 1.38902   ],\n",
       "        [-1.5580126 ],\n",
       "        [-0.01776969],\n",
       "        [-1.3738128 ],\n",
       "        [-0.9113229 ],\n",
       "        [-1.5875183 ],\n",
       "        [-0.9738821 ],\n",
       "        [ 0.9583304 ],\n",
       "        [-0.9751052 ],\n",
       "        [ 1.6138964 ],\n",
       "        [-0.87003666]], dtype=float32),\n",
       " array([2.0212786], dtype=float32)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_airfoil, history_airfoil=NN_model_structure_regression_6(X_train_airfoil, X_val_airfoil, Y_train_airfoil, Y_val_airfoil, adam2, 32, 1000)\n",
    "model_airfoil.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_airfoil.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_airfoil_structure6.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_19 (Dense)             (None, 5)                 40        \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 76\n",
      "Trainable params: 76\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 274 samples, validate on 59 samples\n",
      "Epoch 1/1000\n",
      "274/274 [==============================] - 0s 796us/step - loss: 509.9071 - val_loss: 331.6196\n",
      "Epoch 2/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 196.6833 - val_loss: 48.5453\n",
      "Epoch 3/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 67.9600 - val_loss: 33.3805\n",
      "Epoch 4/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 29.9293 - val_loss: 27.0716\n",
      "Epoch 5/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 23.1662 - val_loss: 21.4059\n",
      "Epoch 6/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 20.6323 - val_loss: 19.7333\n",
      "Epoch 7/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 20.5102 - val_loss: 19.4324\n",
      "Epoch 8/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 19.1207 - val_loss: 18.6264\n",
      "Epoch 9/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 18.1205 - val_loss: 18.5899\n",
      "Epoch 10/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 17.8147 - val_loss: 17.7103\n",
      "Epoch 11/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 17.2499 - val_loss: 17.3077\n",
      "Epoch 12/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 16.6011 - val_loss: 16.6333\n",
      "Epoch 13/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 15.9678 - val_loss: 15.7962\n",
      "Epoch 14/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 15.2883 - val_loss: 14.8521\n",
      "Epoch 15/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 14.5552 - val_loss: 14.0908\n",
      "Epoch 16/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 13.9265 - val_loss: 13.1508\n",
      "Epoch 17/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 13.1034 - val_loss: 12.6369\n",
      "Epoch 18/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 12.6363 - val_loss: 12.0765\n",
      "Epoch 19/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 11.5572 - val_loss: 11.5343\n",
      "Epoch 20/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 10.8715 - val_loss: 11.2867\n",
      "Epoch 21/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 10.3676 - val_loss: 10.7358\n",
      "Epoch 22/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 9.8251 - val_loss: 11.1162\n",
      "Epoch 23/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 9.2818 - val_loss: 10.9719\n",
      "Epoch 24/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 9.0660 - val_loss: 11.0803\n",
      "Epoch 25/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.7941 - val_loss: 11.1428\n",
      "Epoch 26/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 8.6966 - val_loss: 11.2712\n",
      "Epoch 27/1000\n",
      "274/274 [==============================] - 0s 122us/step - loss: 8.7504 - val_loss: 11.0872\n",
      "Epoch 28/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 8.8423 - val_loss: 11.2856\n",
      "Epoch 29/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.5976 - val_loss: 11.0866\n",
      "Epoch 30/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.4440 - val_loss: 11.0613\n",
      "Epoch 31/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 8.4195 - val_loss: 10.6988\n",
      "Epoch 32/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 8.4520 - val_loss: 10.7541\n",
      "Epoch 33/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.5834 - val_loss: 10.8230\n",
      "Epoch 34/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 8.4793 - val_loss: 10.8380\n",
      "Epoch 35/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 8.5562 - val_loss: 11.2099\n",
      "Epoch 36/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.2427 - val_loss: 11.2070\n",
      "Epoch 37/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.2319 - val_loss: 10.6948\n",
      "Epoch 38/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.2780 - val_loss: 10.4694\n",
      "Epoch 39/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.0228 - val_loss: 10.7880\n",
      "Epoch 40/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.4471 - val_loss: 10.9063\n",
      "Epoch 41/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.3355 - val_loss: 10.5746\n",
      "Epoch 42/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.9489 - val_loss: 10.8633\n",
      "Epoch 43/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 8.1373 - val_loss: 10.9292\n",
      "Epoch 44/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 7.8580 - val_loss: 11.0677\n",
      "Epoch 45/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.7995 - val_loss: 10.9202\n",
      "Epoch 46/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.6401 - val_loss: 10.3976\n",
      "Epoch 47/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.5541 - val_loss: 10.4777\n",
      "Epoch 48/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.5810 - val_loss: 10.5322\n",
      "Epoch 49/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.4263 - val_loss: 10.4103\n",
      "Epoch 50/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 7.4386 - val_loss: 10.6954\n",
      "Epoch 51/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3795 - val_loss: 10.1660\n",
      "Epoch 52/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3524 - val_loss: 10.1705\n",
      "Epoch 53/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.1965 - val_loss: 10.3250\n",
      "Epoch 54/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0321 - val_loss: 10.3284\n",
      "Epoch 55/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1498 - val_loss: 10.1617\n",
      "Epoch 56/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.4278 - val_loss: 10.1093\n",
      "Epoch 57/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.6700 - val_loss: 10.3815\n",
      "Epoch 58/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 7.0590 - val_loss: 9.9883\n",
      "Epoch 59/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 7.0325 - val_loss: 10.2846\n",
      "Epoch 60/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8605 - val_loss: 10.3000\n",
      "Epoch 61/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7660 - val_loss: 9.8910\n",
      "Epoch 62/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7477 - val_loss: 9.7864\n",
      "Epoch 63/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 6.7038 - val_loss: 10.0963\n",
      "Epoch 64/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6273 - val_loss: 9.8721\n",
      "Epoch 65/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6159 - val_loss: 10.0269\n",
      "Epoch 66/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7359 - val_loss: 9.6503\n",
      "Epoch 67/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.9353 - val_loss: 9.6595\n",
      "Epoch 68/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8335 - val_loss: 9.8536\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5958 - val_loss: 9.6995\n",
      "Epoch 70/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6149 - val_loss: 9.8118\n",
      "Epoch 71/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4987 - val_loss: 9.7161\n",
      "Epoch 72/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8881 - val_loss: 10.0628\n",
      "Epoch 73/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.7047 - val_loss: 9.6491\n",
      "Epoch 74/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.4696 - val_loss: 9.6570\n",
      "Epoch 75/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4290 - val_loss: 9.4753\n",
      "Epoch 76/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.4446 - val_loss: 9.5018\n",
      "Epoch 77/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.4836 - val_loss: 9.5490\n",
      "Epoch 78/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.4495 - val_loss: 9.4916\n",
      "Epoch 79/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.2403 - val_loss: 9.2529\n",
      "Epoch 80/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.5494 - val_loss: 9.7444\n",
      "Epoch 81/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.5670 - val_loss: 9.1659\n",
      "Epoch 82/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.6284 - val_loss: 9.2626\n",
      "Epoch 83/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2498 - val_loss: 9.2453\n",
      "Epoch 84/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.3973 - val_loss: 9.8335\n",
      "Epoch 85/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4886 - val_loss: 9.0814\n",
      "Epoch 86/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3307 - val_loss: 9.2093\n",
      "Epoch 87/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3396 - val_loss: 9.1976\n",
      "Epoch 88/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.5375 - val_loss: 8.9969\n",
      "Epoch 89/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3987 - val_loss: 9.1594\n",
      "Epoch 90/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5046 - val_loss: 9.1176\n",
      "Epoch 91/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6850 - val_loss: 9.4004\n",
      "Epoch 92/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.9820 - val_loss: 9.7790\n",
      "Epoch 93/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.9373 - val_loss: 9.5223\n",
      "Epoch 94/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6487 - val_loss: 9.4151\n",
      "Epoch 95/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.1435 - val_loss: 8.8944\n",
      "Epoch 96/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2597 - val_loss: 9.0853\n",
      "Epoch 97/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5376 - val_loss: 9.0804\n",
      "Epoch 98/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.2280 - val_loss: 9.1256\n",
      "Epoch 99/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2100 - val_loss: 9.0822\n",
      "Epoch 100/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2540 - val_loss: 8.7405\n",
      "Epoch 101/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1584 - val_loss: 8.8393\n",
      "Epoch 102/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1926 - val_loss: 9.2420\n",
      "Epoch 103/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1110 - val_loss: 8.9261\n",
      "Epoch 104/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0850 - val_loss: 8.9237\n",
      "Epoch 105/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.4254 - val_loss: 9.2034\n",
      "Epoch 106/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5484 - val_loss: 9.3288\n",
      "Epoch 107/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1171 - val_loss: 9.3398\n",
      "Epoch 108/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.1976 - val_loss: 9.0751\n",
      "Epoch 109/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4654 - val_loss: 8.7339\n",
      "Epoch 110/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1301 - val_loss: 8.8689\n",
      "Epoch 111/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1359 - val_loss: 9.0918\n",
      "Epoch 112/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.1200 - val_loss: 8.8368\n",
      "Epoch 113/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.0710 - val_loss: 9.0199\n",
      "Epoch 114/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1237 - val_loss: 8.5963\n",
      "Epoch 115/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3852 - val_loss: 9.4632\n",
      "Epoch 116/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4618 - val_loss: 8.9479\n",
      "Epoch 117/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7504 - val_loss: 9.6308\n",
      "Epoch 118/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1413 - val_loss: 8.7463\n",
      "Epoch 119/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 6.1356 - val_loss: 9.0046\n",
      "Epoch 120/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2350 - val_loss: 8.8162\n",
      "Epoch 121/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.9807 - val_loss: 9.0793\n",
      "Epoch 122/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.1942 - val_loss: 9.0820\n",
      "Epoch 123/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1062 - val_loss: 8.7389\n",
      "Epoch 124/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.0631 - val_loss: 9.0161\n",
      "Epoch 125/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2395 - val_loss: 8.7657\n",
      "Epoch 126/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.5900 - val_loss: 10.1507\n",
      "Epoch 127/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0717 - val_loss: 8.9220\n",
      "Epoch 128/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.1209 - val_loss: 9.4721\n",
      "Epoch 129/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.2366 - val_loss: 8.8218\n",
      "Epoch 130/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.9425 - val_loss: 8.7658\n",
      "Epoch 131/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.9241 - val_loss: 8.6260\n",
      "Epoch 132/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.9583 - val_loss: 8.9834\n",
      "Epoch 133/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0585 - val_loss: 9.2105\n",
      "Epoch 134/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.2779 - val_loss: 8.5156\n",
      "Epoch 135/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0607 - val_loss: 9.3321\n",
      "Epoch 136/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.4508 - val_loss: 8.8835\n",
      "Epoch 137/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.4105 - val_loss: 9.1034\n",
      "Epoch 138/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9954 - val_loss: 9.1434\n",
      "Epoch 139/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1075 - val_loss: 9.1030\n",
      "Epoch 140/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8850 - val_loss: 8.6492\n",
      "Epoch 141/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9100 - val_loss: 9.1603\n",
      "Epoch 142/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9170 - val_loss: 8.7604\n",
      "Epoch 143/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.9384 - val_loss: 8.8600\n",
      "Epoch 144/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.0477 - val_loss: 8.7545\n",
      "Epoch 145/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9077 - val_loss: 8.8143\n",
      "Epoch 146/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.8829 - val_loss: 8.8787\n",
      "Epoch 147/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1788 - val_loss: 8.5215\n",
      "Epoch 148/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3812 - val_loss: 9.2496\n",
      "Epoch 149/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1867 - val_loss: 8.7736\n",
      "Epoch 150/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.2955 - val_loss: 9.4346\n",
      "Epoch 151/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 6.1364 - val_loss: 8.8792\n",
      "Epoch 152/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8427 - val_loss: 8.5361\n",
      "Epoch 153/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.0894 - val_loss: 8.7299\n",
      "Epoch 154/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1368 - val_loss: 8.8119\n",
      "Epoch 155/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.2753 - val_loss: 8.4993\n",
      "Epoch 156/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2808 - val_loss: 9.5342\n",
      "Epoch 157/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0777 - val_loss: 8.6936\n",
      "Epoch 158/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.0263 - val_loss: 8.6451\n",
      "Epoch 159/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0166 - val_loss: 9.1025\n",
      "Epoch 160/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8153 - val_loss: 8.8128\n",
      "Epoch 161/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8941 - val_loss: 8.5093\n",
      "Epoch 162/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8005 - val_loss: 8.6826\n",
      "Epoch 163/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.7617 - val_loss: 9.1353\n",
      "Epoch 164/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8744 - val_loss: 8.8673\n",
      "Epoch 165/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7386 - val_loss: 8.6838\n",
      "Epoch 166/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7656 - val_loss: 8.6488\n",
      "Epoch 167/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8939 - val_loss: 8.8549\n",
      "Epoch 168/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.0401 - val_loss: 8.6279\n",
      "Epoch 169/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7791 - val_loss: 8.8077\n",
      "Epoch 170/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.7433 - val_loss: 8.7091\n",
      "Epoch 171/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.7424 - val_loss: 8.6388\n",
      "Epoch 172/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.8970 - val_loss: 8.5247\n",
      "Epoch 173/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.8580 - val_loss: 8.8133\n",
      "Epoch 174/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.8808 - val_loss: 8.6805\n",
      "Epoch 175/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8375 - val_loss: 8.9443\n",
      "Epoch 176/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7480 - val_loss: 9.0189\n",
      "Epoch 177/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7870 - val_loss: 8.6018\n",
      "Epoch 178/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8205 - val_loss: 8.8285\n",
      "Epoch 179/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8141 - val_loss: 8.6940\n",
      "Epoch 180/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.6810 - val_loss: 8.9848\n",
      "Epoch 181/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.7525 - val_loss: 8.9834\n",
      "Epoch 182/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.9729 - val_loss: 9.0681\n",
      "Epoch 183/1000\n",
      "274/274 [==============================] - 0s 117us/step - loss: 6.0137 - val_loss: 8.6796\n",
      "Epoch 184/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.4551 - val_loss: 9.4338\n",
      "Epoch 185/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1010 - val_loss: 8.8404\n",
      "Epoch 186/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.7359 - val_loss: 9.0227\n",
      "Epoch 187/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7414 - val_loss: 8.6710\n",
      "Epoch 188/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7919 - val_loss: 8.8631\n",
      "Epoch 189/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7885 - val_loss: 8.8016\n",
      "Epoch 190/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8396 - val_loss: 8.5705\n",
      "Epoch 191/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7128 - val_loss: 8.5624\n",
      "Epoch 192/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.8240 - val_loss: 8.6510\n",
      "Epoch 193/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6743 - val_loss: 8.8462\n",
      "Epoch 194/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.6698 - val_loss: 8.6023\n",
      "Epoch 195/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.6957 - val_loss: 8.6692\n",
      "Epoch 196/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6742 - val_loss: 8.8598\n",
      "Epoch 197/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.7410 - val_loss: 8.1981\n",
      "Epoch 198/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7223 - val_loss: 8.8605\n",
      "Epoch 199/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 5.8758 - val_loss: 8.8846\n",
      "Epoch 200/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 3.674 - 0s 102us/step - loss: 5.8137 - val_loss: 8.7367\n",
      "Epoch 201/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9719 - val_loss: 8.7501\n",
      "Epoch 202/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6887 - val_loss: 8.7933\n",
      "Epoch 203/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.7765 - val_loss: 8.8333\n",
      "Epoch 204/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.9901 - val_loss: 9.2048\n",
      "Epoch 205/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 5.9192 - val_loss: 8.3872\n",
      "Epoch 206/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7998 - val_loss: 8.9126\n",
      "Epoch 207/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.7642 - val_loss: 8.7421\n",
      "Epoch 208/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.6721 - val_loss: 8.6605\n",
      "Epoch 209/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.6336 - val_loss: 8.3879\n",
      "Epoch 210/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7462 - val_loss: 8.9197\n",
      "Epoch 211/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.9232 - val_loss: 8.8638\n",
      "Epoch 212/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8361 - val_loss: 9.0877\n",
      "Epoch 213/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.0514 - val_loss: 8.7823\n",
      "Epoch 214/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.0187 - val_loss: 9.7497\n",
      "Epoch 215/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8868 - val_loss: 8.4517\n",
      "Epoch 216/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 6.0580 - val_loss: 8.9513\n",
      "Epoch 217/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 6.0251 - val_loss: 9.1870\n",
      "Epoch 218/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7716 - val_loss: 8.5406\n",
      "Epoch 219/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6709 - val_loss: 9.0114\n",
      "Epoch 220/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.6438 - val_loss: 8.5119\n",
      "Epoch 221/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6783 - val_loss: 8.5154\n",
      "Epoch 222/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8179 - val_loss: 8.8086\n",
      "Epoch 223/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.7496 - val_loss: 9.0363\n",
      "Epoch 224/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 95us/step - loss: 5.7364 - val_loss: 8.6195\n",
      "Epoch 225/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7871 - val_loss: 8.9146\n",
      "Epoch 226/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7459 - val_loss: 8.7874\n",
      "Epoch 227/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6303 - val_loss: 8.4976\n",
      "Epoch 228/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6305 - val_loss: 8.4623\n",
      "Epoch 229/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6418 - val_loss: 8.6307\n",
      "Epoch 230/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6149 - val_loss: 9.0550\n",
      "Epoch 231/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6603 - val_loss: 8.8974\n",
      "Epoch 232/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7545 - val_loss: 8.4952\n",
      "Epoch 233/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6905 - val_loss: 8.6107\n",
      "Epoch 234/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6558 - val_loss: 8.6869\n",
      "Epoch 235/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6777 - val_loss: 8.8463\n",
      "Epoch 236/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6181 - val_loss: 8.5378\n",
      "Epoch 237/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 5.7600 - val_loss: 8.8362\n",
      "Epoch 238/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6668 - val_loss: 8.7040\n",
      "Epoch 239/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.5631 - val_loss: 8.7240\n",
      "Epoch 240/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6687 - val_loss: 8.5361\n",
      "Epoch 241/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6028 - val_loss: 8.7222\n",
      "Epoch 242/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6553 - val_loss: 8.9437\n",
      "Epoch 243/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.6637 - val_loss: 8.7962\n",
      "Epoch 244/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6198 - val_loss: 8.4050\n",
      "Epoch 245/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9774 - val_loss: 8.5026\n",
      "Epoch 246/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.6502 - val_loss: 8.9332\n",
      "Epoch 247/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5983 - val_loss: 8.8806\n",
      "Epoch 248/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7089 - val_loss: 8.6666\n",
      "Epoch 249/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6975 - val_loss: 8.2009\n",
      "Epoch 250/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5857 - val_loss: 8.6803\n",
      "Epoch 251/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6611 - val_loss: 8.6199\n",
      "Epoch 252/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.5905 - val_loss: 8.8553\n",
      "Epoch 253/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6631 - val_loss: 8.7248\n",
      "Epoch 254/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6268 - val_loss: 8.7765\n",
      "Epoch 255/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7114 - val_loss: 8.6949\n",
      "Epoch 256/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8777 - val_loss: 8.1676\n",
      "Epoch 257/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9848 - val_loss: 8.9355\n",
      "Epoch 258/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6191 - val_loss: 8.5135\n",
      "Epoch 259/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.7488 - val_loss: 8.8908\n",
      "Epoch 260/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7605 - val_loss: 9.2420\n",
      "Epoch 261/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.7510 - val_loss: 8.7472\n",
      "Epoch 262/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.6516 - val_loss: 8.7324\n",
      "Epoch 263/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5576 - val_loss: 8.5187\n",
      "Epoch 264/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6052 - val_loss: 8.7812\n",
      "Epoch 265/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6396 - val_loss: 8.8931\n",
      "Epoch 266/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6968 - val_loss: 8.5157\n",
      "Epoch 267/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6037 - val_loss: 8.7981\n",
      "Epoch 268/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 5.7239 - val_loss: 8.5512\n",
      "Epoch 269/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.7640 - val_loss: 8.8794\n",
      "Epoch 270/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4494 - val_loss: 8.4401\n",
      "Epoch 271/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.7445 - val_loss: 8.9658\n",
      "Epoch 272/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.5950 - val_loss: 8.4497\n",
      "Epoch 273/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.7840 - val_loss: 9.1483\n",
      "Epoch 274/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.0521 - val_loss: 8.5146\n",
      "Epoch 275/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7138 - val_loss: 9.0994\n",
      "Epoch 276/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7243 - val_loss: 8.2683\n",
      "Epoch 277/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6078 - val_loss: 9.0918\n",
      "Epoch 278/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6620 - val_loss: 8.9229\n",
      "Epoch 279/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 5.6277 - val_loss: 9.7329\n",
      "Epoch 280/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8497 - val_loss: 8.6475\n",
      "Epoch 281/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6728 - val_loss: 8.5455\n",
      "Epoch 282/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5673 - val_loss: 8.7229\n",
      "Epoch 283/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.5840 - val_loss: 8.9214\n",
      "Epoch 284/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5817 - val_loss: 8.6404\n",
      "Epoch 285/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6772 - val_loss: 8.4638\n",
      "Epoch 286/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7483 - val_loss: 8.4484\n",
      "Epoch 287/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.6943 - val_loss: 8.8372\n",
      "Epoch 288/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5420 - val_loss: 8.6191\n",
      "Epoch 289/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6869 - val_loss: 8.3377\n",
      "Epoch 290/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.8776 - val_loss: 8.9914\n",
      "Epoch 291/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.0447 - val_loss: 8.7741\n",
      "Epoch 292/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.6109 - val_loss: 9.2798\n",
      "Epoch 293/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5598 - val_loss: 8.5687\n",
      "Epoch 294/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.6423 - val_loss: 8.5222\n",
      "Epoch 295/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.5428 - val_loss: 8.3590\n",
      "Epoch 296/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5428 - val_loss: 8.8794\n",
      "Epoch 297/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6743 - val_loss: 8.5916\n",
      "Epoch 298/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8062 - val_loss: 8.8951\n",
      "Epoch 299/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.6503 - val_loss: 8.5441\n",
      "Epoch 300/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.7108 - val_loss: 8.7497\n",
      "Epoch 301/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.6405 - val_loss: 8.5863\n",
      "Epoch 302/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 95us/step - loss: 5.5555 - val_loss: 8.7638\n",
      "Epoch 303/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.6624 - val_loss: 8.8114\n",
      "Epoch 304/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.6017 - val_loss: 8.5380\n",
      "Epoch 305/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7479 - val_loss: 8.7185\n",
      "Epoch 306/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9090 - val_loss: 9.1011\n",
      "Epoch 307/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7145 - val_loss: 8.7071\n",
      "Epoch 308/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6476 - val_loss: 8.6085\n",
      "Epoch 309/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6927 - val_loss: 8.3453\n",
      "Epoch 310/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.8770 - val_loss: 9.0831\n",
      "Epoch 311/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.8787 - val_loss: 8.6481\n",
      "Epoch 312/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7158 - val_loss: 8.8031\n",
      "Epoch 313/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.5650 - val_loss: 8.5568\n",
      "Epoch 314/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.6846 - val_loss: 8.6689\n",
      "Epoch 315/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9569 - val_loss: 8.7508\n",
      "Epoch 316/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9225 - val_loss: 8.9966\n",
      "Epoch 317/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8275 - val_loss: 8.6669\n",
      "Epoch 318/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8332 - val_loss: 8.8414\n",
      "Epoch 319/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0637 - val_loss: 8.5137\n",
      "Epoch 320/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7845 - val_loss: 9.1180\n",
      "Epoch 321/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0085 - val_loss: 8.7271\n",
      "Epoch 322/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.6443 - val_loss: 8.7070\n",
      "Epoch 323/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7211 - val_loss: 8.6867\n",
      "Epoch 324/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.7966 - val_loss: 9.1902\n",
      "Epoch 325/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.9115 - val_loss: 8.6269\n",
      "Epoch 326/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.7905 - val_loss: 9.3357\n",
      "Epoch 327/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6633 - val_loss: 8.4201\n",
      "Epoch 328/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7272 - val_loss: 9.0342\n",
      "Epoch 329/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7722 - val_loss: 8.4818\n",
      "Epoch 330/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9487 - val_loss: 8.4435\n",
      "Epoch 331/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5739 - val_loss: 9.0261\n",
      "Epoch 332/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6782 - val_loss: 8.7623\n",
      "Epoch 333/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8943 - val_loss: 9.2665\n",
      "Epoch 334/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.8396 - val_loss: 8.7565\n",
      "Epoch 335/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.6343 - val_loss: 8.6939\n",
      "Epoch 336/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8828 - val_loss: 9.1240\n",
      "Epoch 337/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9132 - val_loss: 8.5079\n",
      "Epoch 338/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9952 - val_loss: 8.9254\n",
      "Epoch 339/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0915 - val_loss: 8.4612\n",
      "Epoch 340/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6423 - val_loss: 9.0314\n",
      "Epoch 341/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5681 - val_loss: 8.7904\n",
      "Epoch 342/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.5407 - val_loss: 8.6387\n",
      "Epoch 343/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7109 - val_loss: 8.5809\n",
      "Epoch 344/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5404 - val_loss: 8.6677\n",
      "Epoch 345/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.6317 - val_loss: 8.8037\n",
      "Epoch 346/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8235 - val_loss: 8.9037\n",
      "Epoch 347/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.5897 - val_loss: 8.6217\n",
      "Epoch 348/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6570 - val_loss: 8.5240\n",
      "Epoch 349/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7899 - val_loss: 8.8909\n",
      "Epoch 350/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6968 - val_loss: 8.5022\n",
      "Epoch 351/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.6222 - val_loss: 8.8621\n",
      "Epoch 352/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.5200 - val_loss: 8.5396\n",
      "Epoch 353/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.6108 - val_loss: 8.9390\n",
      "Epoch 354/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6945 - val_loss: 8.5213\n",
      "Epoch 355/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6277 - val_loss: 8.6124\n",
      "Epoch 356/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5990 - val_loss: 9.0218\n",
      "Epoch 357/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4756 - val_loss: 8.6164\n",
      "Epoch 358/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8013 - val_loss: 8.8583\n",
      "Epoch 359/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.7597 - val_loss: 8.4608\n",
      "Epoch 360/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8576 - val_loss: 8.8875\n",
      "Epoch 361/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.1127 - val_loss: 8.5844\n",
      "Epoch 362/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.8448 - val_loss: 9.4519\n",
      "Epoch 363/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8075 - val_loss: 8.4719\n",
      "Epoch 364/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.6614 - val_loss: 9.0453\n",
      "Epoch 365/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7531 - val_loss: 8.4963\n",
      "Epoch 366/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.6777 - val_loss: 8.3709\n",
      "Epoch 367/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.4831 - val_loss: 8.4645\n",
      "Epoch 368/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.5853 - val_loss: 9.0577\n",
      "Epoch 369/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.7572 - val_loss: 8.5750\n",
      "Epoch 370/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9332 - val_loss: 9.1786\n",
      "Epoch 371/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8635 - val_loss: 8.3471\n",
      "Epoch 372/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7021 - val_loss: 9.0862\n",
      "Epoch 373/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.7201 - val_loss: 8.5176\n",
      "Epoch 374/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.4778 - val_loss: 8.9450\n",
      "Epoch 375/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.6844 - val_loss: 8.5741\n",
      "Epoch 376/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8430 - val_loss: 9.1978\n",
      "Epoch 377/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 5.5648 - val_loss: 8.2142\n",
      "Epoch 378/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7212 - val_loss: 8.8532\n",
      "Epoch 379/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6749 - val_loss: 8.8570\n",
      "Epoch 380/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 95us/step - loss: 5.5023 - val_loss: 8.5733\n",
      "Epoch 381/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7217 - val_loss: 8.8234\n",
      "Epoch 382/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.6077 - val_loss: 8.4087\n",
      "Epoch 383/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6625 - val_loss: 8.8301\n",
      "Epoch 384/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4955 - val_loss: 8.5753\n",
      "Epoch 385/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.5994 - val_loss: 8.9910\n",
      "Epoch 386/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.5709 - val_loss: 8.3869\n",
      "Epoch 387/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6439 - val_loss: 8.4960\n",
      "Epoch 388/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4659 - val_loss: 8.9013\n",
      "Epoch 389/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.7351 - val_loss: 8.6051\n",
      "Epoch 390/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 5.6669 - val_loss: 8.7717\n",
      "Epoch 391/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7372 - val_loss: 8.1112\n",
      "Epoch 392/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5530 - val_loss: 9.0620\n",
      "Epoch 393/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6393 - val_loss: 8.5262\n",
      "Epoch 394/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.6020 - val_loss: 8.7894\n",
      "Epoch 395/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.7006 - val_loss: 8.5245\n",
      "Epoch 396/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.9346 - val_loss: 8.7387\n",
      "Epoch 397/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.5180 - val_loss: 8.5618\n",
      "Epoch 398/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6792 - val_loss: 9.0344\n",
      "Epoch 399/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.7262 - val_loss: 8.8140\n",
      "Epoch 400/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7882 - val_loss: 8.5298\n",
      "Epoch 401/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.6752 - val_loss: 8.5669\n",
      "Epoch 402/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.4769 - val_loss: 8.4855\n",
      "Epoch 403/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.6601 - val_loss: 8.7720\n",
      "Epoch 404/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.6363 - val_loss: 8.6615\n",
      "Epoch 405/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4977 - val_loss: 8.6131\n",
      "Epoch 406/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.5997 - val_loss: 8.5623\n",
      "Epoch 407/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5513 - val_loss: 8.3493\n",
      "Epoch 408/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5168 - val_loss: 8.7971\n",
      "Epoch 409/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.8257 - val_loss: 8.5815\n",
      "Epoch 410/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9263 - val_loss: 9.0092\n",
      "Epoch 411/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.7419 - val_loss: 8.4735\n",
      "Epoch 412/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.5719 - val_loss: 8.6897\n",
      "Epoch 413/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.5800 - val_loss: 8.5932\n",
      "Epoch 414/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7440 - val_loss: 9.0564\n",
      "Epoch 415/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4921 - val_loss: 8.1974\n",
      "Epoch 416/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6173 - val_loss: 9.0608\n",
      "Epoch 417/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8372 - val_loss: 8.8308\n",
      "Epoch 418/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5579 - val_loss: 9.1077\n",
      "Epoch 419/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.9007 - val_loss: 8.5593\n",
      "Epoch 420/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.6235 - val_loss: 8.8939\n",
      "Epoch 421/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5483 - val_loss: 8.2415\n",
      "Epoch 422/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6222 - val_loss: 8.9489\n",
      "Epoch 423/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.7890 - val_loss: 8.6325\n",
      "Epoch 424/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4703 - val_loss: 8.8102\n",
      "Epoch 425/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5903 - val_loss: 8.3969\n",
      "Epoch 426/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7331 - val_loss: 8.4648\n",
      "Epoch 427/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5865 - val_loss: 8.5669\n",
      "Epoch 428/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.5891 - val_loss: 8.3959\n",
      "Epoch 429/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5509 - val_loss: 9.2022\n",
      "Epoch 430/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5896 - val_loss: 8.5095\n",
      "Epoch 431/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6886 - val_loss: 9.0896\n",
      "Epoch 432/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6933 - val_loss: 8.2777\n",
      "Epoch 433/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6910 - val_loss: 8.6810\n",
      "Epoch 434/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.8007 - val_loss: 8.6592\n",
      "Epoch 435/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5649 - val_loss: 8.7071\n",
      "Epoch 436/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6956 - val_loss: 8.3203\n",
      "Epoch 437/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.6963 - val_loss: 8.5584\n",
      "Epoch 438/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.5496 - val_loss: 8.4725\n",
      "Epoch 439/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5370 - val_loss: 8.5907\n",
      "Epoch 440/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5419 - val_loss: 8.5739\n",
      "Epoch 441/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4980 - val_loss: 8.8527\n",
      "Epoch 442/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.5893 - val_loss: 8.4656\n",
      "Epoch 443/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.6107 - val_loss: 8.4396\n",
      "Epoch 444/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7231 - val_loss: 8.8878\n",
      "Epoch 445/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5736 - val_loss: 8.7771\n",
      "Epoch 446/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7963 - val_loss: 8.8697\n",
      "Epoch 447/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7225 - val_loss: 8.4960\n",
      "Epoch 448/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8046 - val_loss: 8.2425\n",
      "Epoch 449/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6203 - val_loss: 9.0752\n",
      "Epoch 450/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.8318 - val_loss: 8.6611\n",
      "Epoch 451/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6214 - val_loss: 8.6372\n",
      "Epoch 452/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.6999 - val_loss: 8.8686\n",
      "Epoch 453/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.6242 - val_loss: 8.6359\n",
      "Epoch 454/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.5221 - val_loss: 8.9300\n",
      "Epoch 455/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6136 - val_loss: 8.3099\n",
      "Epoch 456/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.5412 - val_loss: 8.6925\n",
      "Epoch 457/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.4628 - val_loss: 8.4470\n",
      "Epoch 458/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 95us/step - loss: 5.6360 - val_loss: 8.9481\n",
      "Epoch 459/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.7126 - val_loss: 8.4201\n",
      "Epoch 460/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8340 - val_loss: 8.6485\n",
      "Epoch 461/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5013 - val_loss: 8.3888\n",
      "Epoch 462/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.8040 - val_loss: 8.8932\n",
      "Epoch 463/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.5270 - val_loss: 8.3407\n",
      "Epoch 464/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.4886 - val_loss: 8.6863\n",
      "Epoch 465/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6011 - val_loss: 8.8876\n",
      "Epoch 466/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5669 - val_loss: 8.4295\n",
      "Epoch 467/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5421 - val_loss: 8.5838\n",
      "Epoch 468/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.0578 - val_loss: 8.9592\n",
      "Epoch 469/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5618 - val_loss: 8.6617\n",
      "Epoch 470/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5108 - val_loss: 8.6647\n",
      "Epoch 471/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5703 - val_loss: 8.3142\n",
      "Epoch 472/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6513 - val_loss: 8.8556\n",
      "Epoch 473/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6498 - val_loss: 8.5185\n",
      "Epoch 474/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6108 - val_loss: 8.7076\n",
      "Epoch 475/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.5196 - val_loss: 8.4451\n",
      "Epoch 476/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5959 - val_loss: 8.5671\n",
      "Epoch 477/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.9101 - val_loss: 8.5214\n",
      "Epoch 478/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.5799 - val_loss: 8.6841\n",
      "Epoch 479/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.6362 - val_loss: 8.6434\n",
      "Epoch 480/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4903 - val_loss: 8.6089\n",
      "Epoch 481/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4869 - val_loss: 8.5036\n",
      "Epoch 482/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.6369 - val_loss: 8.3944\n",
      "Epoch 483/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4406 - val_loss: 8.6790\n",
      "Epoch 484/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.5425 - val_loss: 8.7770\n",
      "Epoch 485/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.5306 - val_loss: 8.4203\n",
      "Epoch 486/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.4944 - val_loss: 8.7846\n",
      "Epoch 487/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5790 - val_loss: 8.9432\n",
      "Epoch 488/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.5000 - val_loss: 8.3827\n",
      "Epoch 489/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5529 - val_loss: 8.6418\n",
      "Epoch 490/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.4568 - val_loss: 8.5522\n",
      "Epoch 491/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5017 - val_loss: 8.5542\n",
      "Epoch 492/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6246 - val_loss: 8.6073\n",
      "Epoch 493/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7859 - val_loss: 8.6857\n",
      "Epoch 494/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7675 - val_loss: 8.9706\n",
      "Epoch 495/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6391 - val_loss: 8.4001\n",
      "Epoch 496/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6018 - val_loss: 8.7112\n",
      "Epoch 497/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.5268 - val_loss: 8.1852\n",
      "Epoch 498/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.5254 - val_loss: 8.8348\n",
      "Epoch 499/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6714 - val_loss: 8.5997\n",
      "Epoch 500/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 6.546 - 0s 97us/step - loss: 5.4912 - val_loss: 8.5180\n",
      "Epoch 501/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7070 - val_loss: 8.7118\n",
      "Epoch 502/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8195 - val_loss: 8.4420\n",
      "Epoch 503/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.4290 - val_loss: 8.5611\n",
      "Epoch 504/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.5634 - val_loss: 9.1455\n",
      "Epoch 505/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8265 - val_loss: 8.5001\n",
      "Epoch 506/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7307 - val_loss: 9.1193\n",
      "Epoch 507/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8732 - val_loss: 8.7357\n",
      "Epoch 508/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.7976 - val_loss: 8.6266\n",
      "Epoch 509/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.6399 - val_loss: 8.7537\n",
      "Epoch 510/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8404 - val_loss: 8.6027\n",
      "Epoch 511/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.7599 - val_loss: 8.9229\n",
      "Epoch 512/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 5.5833 - val_loss: 8.5415\n",
      "Epoch 513/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.4955 - val_loss: 8.2286\n",
      "Epoch 514/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5796 - val_loss: 8.5907\n",
      "Epoch 515/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.5866 - val_loss: 8.4484\n",
      "Epoch 516/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4244 - val_loss: 8.5620\n",
      "Epoch 517/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5109 - val_loss: 8.7085\n",
      "Epoch 518/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4664 - val_loss: 8.5312\n",
      "Epoch 519/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5458 - val_loss: 8.3058\n",
      "Epoch 520/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8593 - val_loss: 8.9572\n",
      "Epoch 521/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7992 - val_loss: 8.6936\n",
      "Epoch 522/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9353 - val_loss: 8.8291\n",
      "Epoch 523/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7174 - val_loss: 8.6471\n",
      "Epoch 524/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.5485 - val_loss: 8.4620\n",
      "Epoch 525/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.4796 - val_loss: 8.7308\n",
      "Epoch 526/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.4220 - val_loss: 8.5283\n",
      "Epoch 527/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4761 - val_loss: 8.5077\n",
      "Epoch 528/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5403 - val_loss: 8.5912\n",
      "Epoch 529/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4338 - val_loss: 8.5326\n",
      "Epoch 530/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7040 - val_loss: 8.9841\n",
      "Epoch 531/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6493 - val_loss: 8.4446\n",
      "Epoch 532/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5949 - val_loss: 8.3889\n",
      "Epoch 533/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.5719 - val_loss: 8.8610\n",
      "Epoch 534/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.4676 - val_loss: 8.5725\n",
      "Epoch 535/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4996 - val_loss: 8.6004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 536/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5514 - val_loss: 8.3512\n",
      "Epoch 537/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4515 - val_loss: 8.4367\n",
      "Epoch 538/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5273 - val_loss: 8.7352\n",
      "Epoch 539/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.4667 - val_loss: 8.3989\n",
      "Epoch 540/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5000 - val_loss: 8.4292\n",
      "Epoch 541/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6565 - val_loss: 8.5284\n",
      "Epoch 542/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4584 - val_loss: 8.5914\n",
      "Epoch 543/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4685 - val_loss: 8.5561\n",
      "Epoch 544/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4224 - val_loss: 8.3767\n",
      "Epoch 545/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5511 - val_loss: 8.5287\n",
      "Epoch 546/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.9950 - val_loss: 8.6287\n",
      "Epoch 547/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6545 - val_loss: 9.3989\n",
      "Epoch 548/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6878 - val_loss: 8.2388\n",
      "Epoch 549/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5664 - val_loss: 8.7989\n",
      "Epoch 550/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5286 - val_loss: 8.4106\n",
      "Epoch 551/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7381 - val_loss: 9.0548\n",
      "Epoch 552/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8872 - val_loss: 8.1928\n",
      "Epoch 553/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6918 - val_loss: 8.5209\n",
      "Epoch 554/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.2757 - val_loss: 8.7221\n",
      "Epoch 555/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1411 - val_loss: 9.3426\n",
      "Epoch 556/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6811 - val_loss: 8.7455\n",
      "Epoch 557/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6460 - val_loss: 9.0086\n",
      "Epoch 558/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4576 - val_loss: 8.4044\n",
      "Epoch 559/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.7129 - val_loss: 8.7309\n",
      "Epoch 560/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5529 - val_loss: 8.3505\n",
      "Epoch 561/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.5805 - val_loss: 8.5147\n",
      "Epoch 562/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.5855 - val_loss: 8.6794\n",
      "Epoch 563/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4819 - val_loss: 8.8049\n",
      "Epoch 564/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5383 - val_loss: 8.5382\n",
      "Epoch 565/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5048 - val_loss: 8.2987\n",
      "Epoch 566/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5425 - val_loss: 8.4235\n",
      "Epoch 567/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5884 - val_loss: 8.6163\n",
      "Epoch 568/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.5552 - val_loss: 8.6361\n",
      "Epoch 569/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9265 - val_loss: 8.4784\n",
      "Epoch 570/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5778 - val_loss: 8.8613\n",
      "Epoch 571/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6346 - val_loss: 8.5568\n",
      "Epoch 572/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.3936 - val_loss: 8.5803\n",
      "Epoch 573/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4429 - val_loss: 8.7936\n",
      "Epoch 574/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5231 - val_loss: 8.4783\n",
      "Epoch 575/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5128 - val_loss: 8.9018\n",
      "Epoch 576/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.6205 - val_loss: 8.2742\n",
      "Epoch 577/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.4435 - val_loss: 8.7979\n",
      "Epoch 578/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6357 - val_loss: 8.1472\n",
      "Epoch 579/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5411 - val_loss: 9.0588\n",
      "Epoch 580/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.5805 - val_loss: 8.3014\n",
      "Epoch 581/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.5334 - val_loss: 8.6409\n",
      "Epoch 582/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.5765 - val_loss: 8.8271\n",
      "Epoch 583/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.6680 - val_loss: 8.6069\n",
      "Epoch 584/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.7187 - val_loss: 8.4845\n",
      "Epoch 585/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8074 - val_loss: 8.4793\n",
      "Epoch 586/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8205 - val_loss: 8.4522\n",
      "Epoch 587/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.5382 - val_loss: 8.3359\n",
      "Epoch 588/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6050 - val_loss: 8.3879\n",
      "Epoch 589/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5432 - val_loss: 8.6813\n",
      "Epoch 590/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5379 - val_loss: 8.9056\n",
      "Epoch 591/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4335 - val_loss: 8.6054\n",
      "Epoch 592/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4770 - val_loss: 8.5314\n",
      "Epoch 593/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.5726 - val_loss: 8.3299\n",
      "Epoch 594/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.6659 - val_loss: 8.6274\n",
      "Epoch 595/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.7476 - val_loss: 9.1056\n",
      "Epoch 596/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5261 - val_loss: 8.4822\n",
      "Epoch 597/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5804 - val_loss: 8.2778\n",
      "Epoch 598/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.4392 - val_loss: 8.8358\n",
      "Epoch 599/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6975 - val_loss: 8.2832\n",
      "Epoch 600/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8737 - val_loss: 9.2317\n",
      "Epoch 601/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6489 - val_loss: 8.2633\n",
      "Epoch 602/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4316 - val_loss: 8.6258\n",
      "Epoch 603/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.5341 - val_loss: 8.3232\n",
      "Epoch 604/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.7143 - val_loss: 8.7910\n",
      "Epoch 605/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.5207 - val_loss: 8.6857\n",
      "Epoch 606/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.4934 - val_loss: 8.7405\n",
      "Epoch 607/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.4720 - val_loss: 8.4378\n",
      "Epoch 608/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.5895 - val_loss: 8.5666\n",
      "Epoch 609/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6837 - val_loss: 8.4845\n",
      "Epoch 610/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.6833 - val_loss: 8.9620\n",
      "Epoch 611/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7214 - val_loss: 8.3279\n",
      "Epoch 612/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.8347 - val_loss: 8.7572\n",
      "Epoch 613/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5224 - val_loss: 8.7554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 614/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.4166 - val_loss: 8.9390\n",
      "Epoch 615/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.4406 - val_loss: 8.4694\n",
      "Epoch 616/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8128 - val_loss: 8.4597\n",
      "Epoch 617/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5661 - val_loss: 8.6703\n",
      "Epoch 618/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8388 - val_loss: 8.7290\n",
      "Epoch 619/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6726 - val_loss: 8.6414\n",
      "Epoch 620/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7441 - val_loss: 8.3385\n",
      "Epoch 621/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.8636 - val_loss: 8.8257\n",
      "Epoch 622/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4520 - val_loss: 8.7298\n",
      "Epoch 623/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4170 - val_loss: 8.5650\n",
      "Epoch 624/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4669 - val_loss: 8.5760\n",
      "Epoch 625/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.5130 - val_loss: 8.5325\n",
      "Epoch 626/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7385 - val_loss: 8.4695\n",
      "Epoch 627/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.5338 - val_loss: 8.5741\n",
      "Epoch 628/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6867 - val_loss: 8.8320\n",
      "Epoch 629/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5133 - val_loss: 8.6661\n",
      "Epoch 630/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.4951 - val_loss: 8.4134\n",
      "Epoch 631/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4575 - val_loss: 8.3115\n",
      "Epoch 632/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.6386 - val_loss: 8.4991\n",
      "Epoch 633/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4728 - val_loss: 8.7226\n",
      "Epoch 634/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.4776 - val_loss: 8.3709\n",
      "Epoch 635/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4371 - val_loss: 8.8614\n",
      "Epoch 636/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.6021 - val_loss: 8.2737\n",
      "Epoch 637/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8750 - val_loss: 8.7989\n",
      "Epoch 638/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7355 - val_loss: 8.5037\n",
      "Epoch 639/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4923 - val_loss: 8.6039\n",
      "Epoch 640/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4225 - val_loss: 8.8942\n",
      "Epoch 641/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4446 - val_loss: 8.5768\n",
      "Epoch 642/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4803 - val_loss: 8.5922\n",
      "Epoch 643/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.4474 - val_loss: 8.5065\n",
      "Epoch 644/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7518 - val_loss: 8.4103\n",
      "Epoch 645/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.3848 - val_loss: 9.1095\n",
      "Epoch 646/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.1713 - val_loss: 8.4609\n",
      "Epoch 647/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.7131 - val_loss: 8.9936\n",
      "Epoch 648/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4783 - val_loss: 8.5718\n",
      "Epoch 649/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7558 - val_loss: 8.8001\n",
      "Epoch 650/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.8789 - val_loss: 8.5375\n",
      "Epoch 651/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 4.756 - 0s 90us/step - loss: 5.6216 - val_loss: 9.2184\n",
      "Epoch 652/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4875 - val_loss: 8.3863\n",
      "Epoch 653/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.4743 - val_loss: 8.5515\n",
      "Epoch 654/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5240 - val_loss: 8.5555\n",
      "Epoch 655/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6698 - val_loss: 8.7117\n",
      "Epoch 656/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.5549 - val_loss: 8.5861\n",
      "Epoch 657/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4467 - val_loss: 8.2780\n",
      "Epoch 658/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5674 - val_loss: 8.6178\n",
      "Epoch 659/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4368 - val_loss: 8.3730\n",
      "Epoch 660/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4050 - val_loss: 8.7217\n",
      "Epoch 661/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4735 - val_loss: 8.4229\n",
      "Epoch 662/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.7175 - val_loss: 9.1229\n",
      "Epoch 663/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6374 - val_loss: 8.3425\n",
      "Epoch 664/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8693 - val_loss: 8.7812\n",
      "Epoch 665/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5197 - val_loss: 8.2126\n",
      "Epoch 666/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.8970 - val_loss: 8.8825\n",
      "Epoch 667/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6042 - val_loss: 8.5236\n",
      "Epoch 668/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.7815 - val_loss: 8.4926\n",
      "Epoch 669/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8318 - val_loss: 8.9924\n",
      "Epoch 670/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6065 - val_loss: 8.3546\n",
      "Epoch 671/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5699 - val_loss: 8.5371\n",
      "Epoch 672/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4904 - val_loss: 8.4660\n",
      "Epoch 673/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.4789 - val_loss: 8.6052\n",
      "Epoch 674/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.4413 - val_loss: 8.8114\n",
      "Epoch 675/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4636 - val_loss: 8.5838\n",
      "Epoch 676/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4354 - val_loss: 8.3975\n",
      "Epoch 677/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5613 - val_loss: 8.5873\n",
      "Epoch 678/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4076 - val_loss: 8.7405\n",
      "Epoch 679/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4922 - val_loss: 8.5081\n",
      "Epoch 680/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5107 - val_loss: 8.6834\n",
      "Epoch 681/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5312 - val_loss: 8.2756\n",
      "Epoch 682/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5300 - val_loss: 8.4444\n",
      "Epoch 683/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5092 - val_loss: 8.4511\n",
      "Epoch 684/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.4657 - val_loss: 8.3332\n",
      "Epoch 685/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5043 - val_loss: 8.6183\n",
      "Epoch 686/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.4135 - val_loss: 8.5491\n",
      "Epoch 687/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4198 - val_loss: 8.3580\n",
      "Epoch 688/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4631 - val_loss: 8.3446\n",
      "Epoch 689/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4740 - val_loss: 8.7671\n",
      "Epoch 690/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5211 - val_loss: 8.7326\n",
      "Epoch 691/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7141 - val_loss: 8.8429\n",
      "Epoch 692/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.5951 - val_loss: 8.2461\n",
      "Epoch 693/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4619 - val_loss: 8.5367\n",
      "Epoch 694/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.4214 - val_loss: 8.6501\n",
      "Epoch 695/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.5354 - val_loss: 8.0752\n",
      "Epoch 696/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.4158 - val_loss: 8.7561\n",
      "Epoch 697/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4351 - val_loss: 8.5578\n",
      "Epoch 698/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.8457 - val_loss: 8.4356\n",
      "Epoch 699/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6897 - val_loss: 8.7154\n",
      "Epoch 700/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5653 - val_loss: 8.6669\n",
      "Epoch 701/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4806 - val_loss: 8.6147\n",
      "Epoch 702/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4989 - val_loss: 8.4118\n",
      "Epoch 703/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.4880 - val_loss: 8.7242\n",
      "Epoch 704/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6147 - val_loss: 8.6112\n",
      "Epoch 705/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5105 - val_loss: 8.4256\n",
      "Epoch 706/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4631 - val_loss: 8.3066\n",
      "Epoch 707/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4895 - val_loss: 8.1338\n",
      "Epoch 708/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4265 - val_loss: 8.8127\n",
      "Epoch 709/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5454 - val_loss: 8.6308\n",
      "Epoch 710/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5023 - val_loss: 8.5457\n",
      "Epoch 711/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0494 - val_loss: 8.6006\n",
      "Epoch 712/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5225 - val_loss: 8.1757\n",
      "Epoch 713/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4708 - val_loss: 8.3220\n",
      "Epoch 714/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.5519 - val_loss: 8.6825\n",
      "Epoch 715/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.5129 - val_loss: 8.3103\n",
      "Epoch 716/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4896 - val_loss: 8.4255\n",
      "Epoch 717/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4767 - val_loss: 8.3647\n",
      "Epoch 718/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.3792 - val_loss: 8.7315\n",
      "Epoch 719/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.4030 - val_loss: 8.4566\n",
      "Epoch 720/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.5002 - val_loss: 8.5724\n",
      "Epoch 721/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.6347 - val_loss: 8.3497\n",
      "Epoch 722/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.4386 - val_loss: 8.6425\n",
      "Epoch 723/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4360 - val_loss: 8.4183\n",
      "Epoch 724/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.4564 - val_loss: 8.5610\n",
      "Epoch 725/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.3844 - val_loss: 8.3940\n",
      "Epoch 726/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4681 - val_loss: 8.7933\n",
      "Epoch 727/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.5479 - val_loss: 8.3423\n",
      "Epoch 728/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4384 - val_loss: 8.8337\n",
      "Epoch 729/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3836 - val_loss: 8.3842\n",
      "Epoch 730/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.4180 - val_loss: 8.6647\n",
      "Epoch 731/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 5.8561 - val_loss: 8.5690\n",
      "Epoch 732/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5896 - val_loss: 9.0620\n",
      "Epoch 733/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7603 - val_loss: 8.5617\n",
      "Epoch 734/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 5.6062 - val_loss: 8.5918\n",
      "Epoch 735/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6556 - val_loss: 8.3045\n",
      "Epoch 736/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4184 - val_loss: 8.4295\n",
      "Epoch 737/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.5365 - val_loss: 8.3864\n",
      "Epoch 738/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 5.4358 - val_loss: 8.4483\n",
      "Epoch 739/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 5.4163 - val_loss: 8.7075\n",
      "Epoch 740/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.4540 - val_loss: 8.7784\n",
      "Epoch 741/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3874 - val_loss: 8.4991\n",
      "Epoch 742/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.4814 - val_loss: 8.2634\n",
      "Epoch 743/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.3987 - val_loss: 8.4589\n",
      "Epoch 744/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4779 - val_loss: 8.1493\n",
      "Epoch 745/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.5418 - val_loss: 8.3543\n",
      "Epoch 746/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6306 - val_loss: 8.9171\n",
      "Epoch 747/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7098 - val_loss: 8.4870\n",
      "Epoch 748/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9341 - val_loss: 8.1709\n",
      "Epoch 749/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.5623 - val_loss: 8.5992\n",
      "Epoch 750/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5113 - val_loss: 8.6225\n",
      "Epoch 751/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5492 - val_loss: 8.7930\n",
      "Epoch 752/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4012 - val_loss: 8.3928\n",
      "Epoch 753/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5210 - val_loss: 8.3685\n",
      "Epoch 754/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4008 - val_loss: 8.7739\n",
      "Epoch 755/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4327 - val_loss: 8.2300\n",
      "Epoch 756/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4624 - val_loss: 9.1321\n",
      "Epoch 757/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 5.4736 - val_loss: 8.4924\n",
      "Epoch 758/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 5.5223 - val_loss: 8.5731\n",
      "Epoch 759/1000\n",
      "274/274 [==============================] - 0s 118us/step - loss: 5.5038 - val_loss: 8.3277\n",
      "Epoch 760/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.7673 - val_loss: 9.0072\n",
      "Epoch 761/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5869 - val_loss: 8.3688\n",
      "Epoch 762/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.6404 - val_loss: 8.9012\n",
      "Epoch 763/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.9028 - val_loss: 8.1182\n",
      "Epoch 764/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.8248 - val_loss: 8.7761\n",
      "Epoch 765/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5113 - val_loss: 8.6029\n",
      "Epoch 766/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.5482 - val_loss: 8.6327\n",
      "Epoch 767/1000\n",
      "274/274 [==============================] - 0s 117us/step - loss: 5.3912 - val_loss: 8.9035\n",
      "Epoch 768/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.5005 - val_loss: 8.5564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 769/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4449 - val_loss: 8.9449\n",
      "Epoch 770/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4749 - val_loss: 8.4677\n",
      "Epoch 771/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6071 - val_loss: 8.8617\n",
      "Epoch 772/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6688 - val_loss: 8.2494\n",
      "Epoch 773/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4280 - val_loss: 8.6613\n",
      "Epoch 774/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6050 - val_loss: 8.5097\n",
      "Epoch 775/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4608 - val_loss: 8.4443\n",
      "Epoch 776/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4120 - val_loss: 8.4007\n",
      "Epoch 777/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.5085 - val_loss: 8.6314\n",
      "Epoch 778/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4332 - val_loss: 8.4039\n",
      "Epoch 779/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.4612 - val_loss: 8.3802\n",
      "Epoch 780/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.4200 - val_loss: 8.5151\n",
      "Epoch 781/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3732 - val_loss: 8.4934\n",
      "Epoch 782/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5854 - val_loss: 8.5827\n",
      "Epoch 783/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4578 - val_loss: 8.3762\n",
      "Epoch 784/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.4264 - val_loss: 8.3157\n",
      "Epoch 785/1000\n",
      "274/274 [==============================] - 0s 146us/step - loss: 5.4016 - val_loss: 8.4675\n",
      "Epoch 786/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5862 - val_loss: 8.5555\n",
      "Epoch 787/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.4235 - val_loss: 8.4287\n",
      "Epoch 788/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.5176 - val_loss: 8.6974\n",
      "Epoch 789/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5256 - val_loss: 8.1789\n",
      "Epoch 790/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.5043 - val_loss: 8.6496\n",
      "Epoch 791/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 5.3782 - val_loss: 8.3670\n",
      "Epoch 792/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4312 - val_loss: 8.4094\n",
      "Epoch 793/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3677 - val_loss: 8.5499\n",
      "Epoch 794/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4611 - val_loss: 8.3707\n",
      "Epoch 795/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 5.5688 - val_loss: 8.4056\n",
      "Epoch 796/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.4602 - val_loss: 8.4021\n",
      "Epoch 797/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5038 - val_loss: 8.5313\n",
      "Epoch 798/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.5286 - val_loss: 8.4127\n",
      "Epoch 799/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5255 - val_loss: 8.1809\n",
      "Epoch 800/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7211 - val_loss: 9.1285\n",
      "Epoch 801/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6099 - val_loss: 8.5737\n",
      "Epoch 802/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6140 - val_loss: 9.1598\n",
      "Epoch 803/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.5866 - val_loss: 8.4370\n",
      "Epoch 804/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3968 - val_loss: 8.3695\n",
      "Epoch 805/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.4272 - val_loss: 8.4076\n",
      "Epoch 806/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4539 - val_loss: 8.9635\n",
      "Epoch 807/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4888 - val_loss: 8.6763\n",
      "Epoch 808/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4304 - val_loss: 8.3011\n",
      "Epoch 809/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6030 - val_loss: 8.1454\n",
      "Epoch 810/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4299 - val_loss: 8.6395\n",
      "Epoch 811/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4053 - val_loss: 8.8412\n",
      "Epoch 812/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4396 - val_loss: 8.4416\n",
      "Epoch 813/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5565 - val_loss: 8.1663\n",
      "Epoch 814/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5930 - val_loss: 8.8032\n",
      "Epoch 815/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5390 - val_loss: 8.4027\n",
      "Epoch 816/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4588 - val_loss: 8.3942\n",
      "Epoch 817/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3945 - val_loss: 8.3919\n",
      "Epoch 818/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4457 - val_loss: 8.1557\n",
      "Epoch 819/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.3006 - val_loss: 8.6182\n",
      "Epoch 820/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4149 - val_loss: 8.7534\n",
      "Epoch 821/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5035 - val_loss: 8.2896\n",
      "Epoch 822/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 5.3496 - val_loss: 8.5789\n",
      "Epoch 823/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5459 - val_loss: 8.3268\n",
      "Epoch 824/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3721 - val_loss: 8.3665\n",
      "Epoch 825/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3904 - val_loss: 8.3440\n",
      "Epoch 826/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5345 - val_loss: 8.1800\n",
      "Epoch 827/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.5586 - val_loss: 8.6054\n",
      "Epoch 828/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5168 - val_loss: 8.0207\n",
      "Epoch 829/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4375 - val_loss: 8.6095\n",
      "Epoch 830/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5156 - val_loss: 8.6570\n",
      "Epoch 831/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.4617 - val_loss: 8.5754\n",
      "Epoch 832/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3476 - val_loss: 8.4544\n",
      "Epoch 833/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5248 - val_loss: 8.6070\n",
      "Epoch 834/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.3359 - val_loss: 8.2486\n",
      "Epoch 835/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6298 - val_loss: 8.0974\n",
      "Epoch 836/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7294 - val_loss: 8.4497\n",
      "Epoch 837/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7015 - val_loss: 8.3499\n",
      "Epoch 838/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6813 - val_loss: 8.4687\n",
      "Epoch 839/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5533 - val_loss: 8.4049\n",
      "Epoch 840/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5859 - val_loss: 8.1811\n",
      "Epoch 841/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6036 - val_loss: 8.7764\n",
      "Epoch 842/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.7271 - val_loss: 8.4894\n",
      "Epoch 843/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.5328 - val_loss: 8.7313\n",
      "Epoch 844/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3736 - val_loss: 8.3160\n",
      "Epoch 845/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.4919 - val_loss: 8.0916\n",
      "Epoch 846/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4562 - val_loss: 8.2708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 847/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3698 - val_loss: 8.5823\n",
      "Epoch 848/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5140 - val_loss: 8.4850\n",
      "Epoch 849/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6418 - val_loss: 9.0535\n",
      "Epoch 850/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5820 - val_loss: 8.4573\n",
      "Epoch 851/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3946 - val_loss: 8.3736\n",
      "Epoch 852/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3985 - val_loss: 8.4595\n",
      "Epoch 853/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.4027 - val_loss: 8.5185\n",
      "Epoch 854/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7183 - val_loss: 8.5634\n",
      "Epoch 855/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.3950 - val_loss: 8.4874\n",
      "Epoch 856/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4684 - val_loss: 8.2486\n",
      "Epoch 857/1000\n",
      "274/274 [==============================] - 0s 142us/step - loss: 5.9403 - val_loss: 8.8459\n",
      "Epoch 858/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4278 - val_loss: 8.3692\n",
      "Epoch 859/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4616 - val_loss: 8.5397\n",
      "Epoch 860/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.6842 - val_loss: 8.5144\n",
      "Epoch 861/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4997 - val_loss: 8.2263\n",
      "Epoch 862/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.4492 - val_loss: 8.1655\n",
      "Epoch 863/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4259 - val_loss: 8.5558\n",
      "Epoch 864/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5517 - val_loss: 8.6438\n",
      "Epoch 865/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4772 - val_loss: 8.6978\n",
      "Epoch 866/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5275 - val_loss: 8.9643\n",
      "Epoch 867/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4277 - val_loss: 8.4334\n",
      "Epoch 868/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5710 - val_loss: 8.9255\n",
      "Epoch 869/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3911 - val_loss: 8.2674\n",
      "Epoch 870/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5946 - val_loss: 9.0455\n",
      "Epoch 871/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8293 - val_loss: 8.4151\n",
      "Epoch 872/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4512 - val_loss: 8.6434\n",
      "Epoch 873/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4413 - val_loss: 8.4774\n",
      "Epoch 874/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3887 - val_loss: 8.7645\n",
      "Epoch 875/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3841 - val_loss: 8.4122\n",
      "Epoch 876/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4655 - val_loss: 8.5778\n",
      "Epoch 877/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.4816 - val_loss: 8.3625\n",
      "Epoch 878/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4329 - val_loss: 8.6812\n",
      "Epoch 879/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.3893 - val_loss: 8.3408\n",
      "Epoch 880/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5471 - val_loss: 8.3178\n",
      "Epoch 881/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6540 - val_loss: 8.6811\n",
      "Epoch 882/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4150 - val_loss: 8.3228\n",
      "Epoch 883/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3670 - val_loss: 8.6299\n",
      "Epoch 884/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3853 - val_loss: 8.5622\n",
      "Epoch 885/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4214 - val_loss: 8.4895\n",
      "Epoch 886/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5735 - val_loss: 8.5836\n",
      "Epoch 887/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4776 - val_loss: 8.1930\n",
      "Epoch 888/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5629 - val_loss: 8.5463\n",
      "Epoch 889/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 5.7356 - val_loss: 8.3825\n",
      "Epoch 890/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4276 - val_loss: 9.0202\n",
      "Epoch 891/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.4855 - val_loss: 8.3292\n",
      "Epoch 892/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3893 - val_loss: 8.6149\n",
      "Epoch 893/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6362 - val_loss: 8.2258\n",
      "Epoch 894/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.9070 - val_loss: 8.9587\n",
      "Epoch 895/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8235 - val_loss: 8.4066\n",
      "Epoch 896/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5914 - val_loss: 9.1545\n",
      "Epoch 897/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.5334 - val_loss: 8.2319\n",
      "Epoch 898/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3865 - val_loss: 8.7206\n",
      "Epoch 899/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4861 - val_loss: 8.4405\n",
      "Epoch 900/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4504 - val_loss: 8.7999\n",
      "Epoch 901/1000\n",
      "274/274 [==============================] - 0s 139us/step - loss: 5.4610 - val_loss: 8.6491\n",
      "Epoch 902/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6046 - val_loss: 8.1726\n",
      "Epoch 903/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 5.6960 - val_loss: 9.3619\n",
      "Epoch 904/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6738 - val_loss: 8.5408\n",
      "Epoch 905/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4835 - val_loss: 8.8986\n",
      "Epoch 906/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4372 - val_loss: 8.3678\n",
      "Epoch 907/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6162 - val_loss: 8.8112\n",
      "Epoch 908/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.3157 - val_loss: 8.3121\n",
      "Epoch 909/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.5617 - val_loss: 8.8520\n",
      "Epoch 910/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5287 - val_loss: 8.5891\n",
      "Epoch 911/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 5.5547 - val_loss: 8.3715\n",
      "Epoch 912/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4624 - val_loss: 8.9257\n",
      "Epoch 913/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7255 - val_loss: 8.2839\n",
      "Epoch 914/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5525 - val_loss: 9.1216\n",
      "Epoch 915/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 5.6413 - val_loss: 8.5445\n",
      "Epoch 916/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4849 - val_loss: 8.5194\n",
      "Epoch 917/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 5.4111 - val_loss: 8.3126\n",
      "Epoch 918/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5021 - val_loss: 8.4289\n",
      "Epoch 919/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3845 - val_loss: 8.2201\n",
      "Epoch 920/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.5258 - val_loss: 9.0608\n",
      "Epoch 921/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6475 - val_loss: 8.5316\n",
      "Epoch 922/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.5708 - val_loss: 8.1821\n",
      "Epoch 923/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5465 - val_loss: 8.5811\n",
      "Epoch 924/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4756 - val_loss: 8.3880\n",
      "Epoch 925/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4565 - val_loss: 8.7448\n",
      "Epoch 926/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.5552 - val_loss: 8.6037\n",
      "Epoch 927/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4399 - val_loss: 8.5321\n",
      "Epoch 928/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4504 - val_loss: 8.3492\n",
      "Epoch 929/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3823 - val_loss: 8.2344\n",
      "Epoch 930/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.5088 - val_loss: 9.0432\n",
      "Epoch 931/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3790 - val_loss: 8.4252\n",
      "Epoch 932/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3377 - val_loss: 8.6396\n",
      "Epoch 933/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4072 - val_loss: 8.5933\n",
      "Epoch 934/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3881 - val_loss: 8.6928\n",
      "Epoch 935/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.6503 - val_loss: 8.7425\n",
      "Epoch 936/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7810 - val_loss: 8.1905\n",
      "Epoch 937/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.9920 - val_loss: 8.9265\n",
      "Epoch 938/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4839 - val_loss: 8.1863\n",
      "Epoch 939/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4536 - val_loss: 8.8337\n",
      "Epoch 940/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5513 - val_loss: 8.6976\n",
      "Epoch 941/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.3220 - val_loss: 8.4269\n",
      "Epoch 942/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5792 - val_loss: 8.4771\n",
      "Epoch 943/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6351 - val_loss: 9.6785\n",
      "Epoch 944/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9418 - val_loss: 8.7456\n",
      "Epoch 945/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.0511 - val_loss: 9.3084\n",
      "Epoch 946/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.5193 - val_loss: 8.4487\n",
      "Epoch 947/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 5.6277 - val_loss: 9.0104\n",
      "Epoch 948/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7786 - val_loss: 8.3187\n",
      "Epoch 949/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.5089 - val_loss: 8.8224\n",
      "Epoch 950/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.4223 - val_loss: 8.4379\n",
      "Epoch 951/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4143 - val_loss: 9.0421\n",
      "Epoch 952/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5475 - val_loss: 8.4275\n",
      "Epoch 953/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3852 - val_loss: 8.6429\n",
      "Epoch 954/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3516 - val_loss: 8.6345\n",
      "Epoch 955/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4892 - val_loss: 8.3367\n",
      "Epoch 956/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3681 - val_loss: 8.4393\n",
      "Epoch 957/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.5998 - val_loss: 8.8657\n",
      "Epoch 958/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.6540 - val_loss: 8.3741\n",
      "Epoch 959/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5462 - val_loss: 8.3911\n",
      "Epoch 960/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8949 - val_loss: 8.6818\n",
      "Epoch 961/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4749 - val_loss: 8.2390\n",
      "Epoch 962/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5623 - val_loss: 8.6181\n",
      "Epoch 963/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3378 - val_loss: 8.8272\n",
      "Epoch 964/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3576 - val_loss: 8.7509\n",
      "Epoch 965/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3791 - val_loss: 8.4631\n",
      "Epoch 966/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3566 - val_loss: 8.4181\n",
      "Epoch 967/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5818 - val_loss: 8.7274\n",
      "Epoch 968/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5463 - val_loss: 8.5358\n",
      "Epoch 969/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3132 - val_loss: 8.8671\n",
      "Epoch 970/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.4591 - val_loss: 8.3735\n",
      "Epoch 971/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.3581 - val_loss: 8.9745\n",
      "Epoch 972/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5888 - val_loss: 8.4224\n",
      "Epoch 973/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5004 - val_loss: 8.4959\n",
      "Epoch 974/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4149 - val_loss: 8.6763\n",
      "Epoch 975/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4725 - val_loss: 8.3624\n",
      "Epoch 976/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.3484 - val_loss: 8.6842\n",
      "Epoch 977/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6348 - val_loss: 8.3932\n",
      "Epoch 978/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.5287 - val_loss: 8.2649\n",
      "Epoch 979/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6122 - val_loss: 8.9981\n",
      "Epoch 980/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6435 - val_loss: 8.5050\n",
      "Epoch 981/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.5669 - val_loss: 8.7336\n",
      "Epoch 982/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.5119 - val_loss: 8.5579\n",
      "Epoch 983/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3972 - val_loss: 8.7709\n",
      "Epoch 984/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3870 - val_loss: 8.4340\n",
      "Epoch 985/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.5830 - val_loss: 8.3439\n",
      "Epoch 986/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4811 - val_loss: 8.6265\n",
      "Epoch 987/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.4456 - val_loss: 8.4773\n",
      "Epoch 988/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3733 - val_loss: 8.6898\n",
      "Epoch 989/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.4040 - val_loss: 8.1429\n",
      "Epoch 990/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.7205 - val_loss: 8.7732\n",
      "Epoch 991/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4701 - val_loss: 8.4501\n",
      "Epoch 992/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5748 - val_loss: 8.8564\n",
      "Epoch 993/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4827 - val_loss: 8.8788\n",
      "Epoch 994/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4752 - val_loss: 8.6008\n",
      "Epoch 995/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.4346 - val_loss: 8.6898\n",
      "Epoch 996/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6902 - val_loss: 8.1489\n",
      "Epoch 997/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8317 - val_loss: 9.0866\n",
      "Epoch 998/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8471 - val_loss: 8.6520\n",
      "Epoch 999/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5414 - val_loss: 8.2892\n",
      "Epoch 1000/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.5115 - val_loss: 8.6884\n",
      "6.371952905493267\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-1.59509325e+00,  1.32915854e-01,  1.50374532e-01,\n",
       "         -1.60559261e+00,  1.66714025e+00],\n",
       "        [-5.40645599e-01,  3.34446102e-01, -1.20253181e+00,\n",
       "         -6.15950525e-01, -6.51584029e-01],\n",
       "        [ 1.04397321e+00,  3.03861797e-01, -1.10061996e-01,\n",
       "         -2.71698862e-01,  2.10035741e-01],\n",
       "        [ 5.79888105e-01, -9.61458147e-01,  9.46186602e-01,\n",
       "          6.88745439e-01, -1.10269701e+00],\n",
       "        [ 1.58493564e-01,  3.13258708e-01,  2.62436122e-01,\n",
       "          1.21346954e-03, -9.54081655e-01],\n",
       "        [ 4.81030136e-01,  1.13828683e+00,  1.19745433e+00,\n",
       "         -5.42439103e-01,  1.73349261e+00],\n",
       "        [ 2.56063193e-01,  1.59793541e-01, -1.75328875e+00,\n",
       "         -9.57204551e-02,  2.18215489e+00]], dtype=float32),\n",
       " array([-1.0935729 , -1.1934397 , -3.3114355 , -0.10305444,  3.3922274 ],\n",
       "       dtype=float32),\n",
       " array([[-1.005919  ,  0.68058753, -1.0886734 ,  0.48754424, -0.06260633],\n",
       "        [ 1.2751895 , -0.6617254 ,  0.7123754 , -1.6778141 ,  1.4914669 ],\n",
       "        [-1.0115366 , -0.02379875, -0.7073389 ,  0.7065652 , -0.23005417],\n",
       "        [ 0.6481255 , -1.0567919 ,  0.62399244, -0.82803214,  1.2366855 ],\n",
       "        [ 0.336929  , -0.13933118,  0.6869152 , -0.314     ,  0.6803865 ]],\n",
       "       dtype=float32),\n",
       " array([ 1.9255148, -1.8869112,  1.8889643, -1.9426527,  1.9358199],\n",
       "       dtype=float32),\n",
       " array([[ 1.8600318],\n",
       "        [-1.1547544],\n",
       "        [ 1.7167332],\n",
       "        [-1.7845393],\n",
       "        [ 1.8445282]], dtype=float32),\n",
       " array([1.9155898], dtype=float32)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_autompg, history_autompg=NN_model_structure_regression_1(X_train_autompg, X_val_autompg, Y_train_autompg, Y_val_autompg, adam2, 32, 1000)\n",
    "model_autompg.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_autompg.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_autompg_structure1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_22 (Dense)             (None, 5)                 40        \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 111\n",
      "Trainable params: 111\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 274 samples, validate on 59 samples\n",
      "Epoch 1/1000\n",
      "274/274 [==============================] - 0s 850us/step - loss: 496.6802 - val_loss: 276.6582\n",
      "Epoch 2/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 198.4963 - val_loss: 57.4538\n",
      "Epoch 3/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 55.5732 - val_loss: 31.1650\n",
      "Epoch 4/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 27.9984 - val_loss: 27.0868\n",
      "Epoch 5/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 25.0699 - val_loss: 22.6639\n",
      "Epoch 6/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 20.6271 - val_loss: 20.7605\n",
      "Epoch 7/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 19.1745 - val_loss: 19.1916\n",
      "Epoch 8/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 18.2717 - val_loss: 18.3778\n",
      "Epoch 9/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 17.0007 - val_loss: 17.4396\n",
      "Epoch 10/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 16.9986 - val_loss: 16.7800\n",
      "Epoch 11/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 15.7895 - val_loss: 16.0010\n",
      "Epoch 12/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 14.5291 - val_loss: 15.2589\n",
      "Epoch 13/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 13.4516 - val_loss: 14.4590\n",
      "Epoch 14/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 12.5349 - val_loss: 13.4967\n",
      "Epoch 15/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 11.3327 - val_loss: 12.8151\n",
      "Epoch 16/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 10.8775 - val_loss: 12.1875\n",
      "Epoch 17/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 10.0402 - val_loss: 11.7845\n",
      "Epoch 18/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 9.4970 - val_loss: 11.4274\n",
      "Epoch 19/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 9.2191 - val_loss: 11.0685\n",
      "Epoch 20/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.8384 - val_loss: 10.7454\n",
      "Epoch 21/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.7091 - val_loss: 10.4848\n",
      "Epoch 22/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.4401 - val_loss: 9.9858\n",
      "Epoch 23/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 8.2525 - val_loss: 9.9929\n",
      "Epoch 24/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.1563 - val_loss: 10.0632\n",
      "Epoch 25/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 7.9092 - val_loss: 9.4877\n",
      "Epoch 26/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 7.7334 - val_loss: 9.5171\n",
      "Epoch 27/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 7.4429 - val_loss: 9.3938\n",
      "Epoch 28/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.7452 - val_loss: 9.3819\n",
      "Epoch 29/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 7.5247 - val_loss: 9.2379\n",
      "Epoch 30/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 7.4268 - val_loss: 9.2069\n",
      "Epoch 31/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.7414 - val_loss: 9.5083\n",
      "Epoch 32/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.5771 - val_loss: 9.0539\n",
      "Epoch 33/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.3202 - val_loss: 9.4474\n",
      "Epoch 34/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 7.2306 - val_loss: 9.2282\n",
      "Epoch 35/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 7.1229 - val_loss: 9.3290\n",
      "Epoch 36/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0898 - val_loss: 9.1083\n",
      "Epoch 37/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.9551 - val_loss: 9.0644\n",
      "Epoch 38/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9062 - val_loss: 9.2808\n",
      "Epoch 39/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0264 - val_loss: 9.2668\n",
      "Epoch 40/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8803 - val_loss: 9.2866\n",
      "Epoch 41/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.8570 - val_loss: 9.1358\n",
      "Epoch 42/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.8762 - val_loss: 9.1660\n",
      "Epoch 43/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8961 - val_loss: 8.9506\n",
      "Epoch 44/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1849 - val_loss: 9.0076\n",
      "Epoch 45/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.8378 - val_loss: 9.1928\n",
      "Epoch 46/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.8934 - val_loss: 9.1555\n",
      "Epoch 47/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.8107 - val_loss: 8.8317\n",
      "Epoch 48/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.8338 - val_loss: 9.2734\n",
      "Epoch 49/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6193 - val_loss: 9.1633\n",
      "Epoch 50/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.7111 - val_loss: 8.7965\n",
      "Epoch 51/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.6464 - val_loss: 9.3966\n",
      "Epoch 52/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.6484 - val_loss: 8.7743\n",
      "Epoch 53/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.5612 - val_loss: 9.0069\n",
      "Epoch 54/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.8541 - val_loss: 9.0083\n",
      "Epoch 55/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7127 - val_loss: 9.0564\n",
      "Epoch 56/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.6127 - val_loss: 9.0392\n",
      "Epoch 57/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.6290 - val_loss: 9.0471\n",
      "Epoch 58/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.5656 - val_loss: 9.1578\n",
      "Epoch 59/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.5331 - val_loss: 9.0775\n",
      "Epoch 60/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.5701 - val_loss: 9.2165\n",
      "Epoch 61/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6685 - val_loss: 9.5289\n",
      "Epoch 62/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.6876 - val_loss: 9.0221\n",
      "Epoch 63/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.6032 - val_loss: 9.5386\n",
      "Epoch 64/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5685 - val_loss: 9.3585\n",
      "Epoch 65/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6044 - val_loss: 9.4148\n",
      "Epoch 66/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5463 - val_loss: 9.3424\n",
      "Epoch 67/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5331 - val_loss: 9.1569\n",
      "Epoch 68/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.5913 - val_loss: 9.5065\n",
      "Epoch 69/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6207 - val_loss: 9.2199\n",
      "Epoch 70/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4511 - val_loss: 9.2408\n",
      "Epoch 71/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.4028 - val_loss: 9.5162\n",
      "Epoch 72/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.3339 - val_loss: 9.3336\n",
      "Epoch 73/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.4878 - val_loss: 9.2590\n",
      "Epoch 74/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3363 - val_loss: 9.3569\n",
      "Epoch 75/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.3569 - val_loss: 9.1746\n",
      "Epoch 76/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.4947 - val_loss: 9.2789\n",
      "Epoch 77/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.4490 - val_loss: 9.4722\n",
      "Epoch 78/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6668 - val_loss: 9.1838\n",
      "Epoch 79/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.7100 - val_loss: 9.8383\n",
      "Epoch 80/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6056 - val_loss: 9.3463\n",
      "Epoch 81/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5375 - val_loss: 9.2118\n",
      "Epoch 82/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.3986 - val_loss: 9.5211\n",
      "Epoch 83/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5469 - val_loss: 9.2676\n",
      "Epoch 84/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3145 - val_loss: 9.5109\n",
      "Epoch 85/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3270 - val_loss: 9.4447\n",
      "Epoch 86/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.3381 - val_loss: 9.2143\n",
      "Epoch 87/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.3393 - val_loss: 9.3905\n",
      "Epoch 88/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2822 - val_loss: 9.5656\n",
      "Epoch 89/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3677 - val_loss: 9.4764\n",
      "Epoch 90/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3765 - val_loss: 9.5380\n",
      "Epoch 91/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1841 - val_loss: 9.6166\n",
      "Epoch 92/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.1804 - val_loss: 9.5375\n",
      "Epoch 93/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3315 - val_loss: 9.2678\n",
      "Epoch 94/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.3887 - val_loss: 9.2379\n",
      "Epoch 95/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.3583 - val_loss: 9.4282\n",
      "Epoch 96/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4960 - val_loss: 9.4126\n",
      "Epoch 97/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4924 - val_loss: 9.5717\n",
      "Epoch 98/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7050 - val_loss: 9.2605\n",
      "Epoch 99/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2755 - val_loss: 9.3338\n",
      "Epoch 100/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.1813 - val_loss: 9.6633\n",
      "Epoch 101/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1728 - val_loss: 9.4804\n",
      "Epoch 102/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.1666 - val_loss: 9.3241\n",
      "Epoch 103/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.3615 - val_loss: 9.6031\n",
      "Epoch 104/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5813 - val_loss: 9.0806\n",
      "Epoch 105/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.4870 - val_loss: 9.5400\n",
      "Epoch 106/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.3563 - val_loss: 9.3047\n",
      "Epoch 107/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4177 - val_loss: 9.3728\n",
      "Epoch 108/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2614 - val_loss: 9.3724\n",
      "Epoch 109/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.1168 - val_loss: 9.2650\n",
      "Epoch 110/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.0632 - val_loss: 9.4561\n",
      "Epoch 111/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.3328 - val_loss: 9.4698\n",
      "Epoch 112/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0715 - val_loss: 9.4483\n",
      "Epoch 113/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.1989 - val_loss: 9.4282\n",
      "Epoch 114/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1184 - val_loss: 9.5420\n",
      "Epoch 115/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 2.981 - 0s 97us/step - loss: 6.6923 - val_loss: 9.4496\n",
      "Epoch 116/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5092 - val_loss: 9.5520\n",
      "Epoch 117/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.1080 - val_loss: 9.3472\n",
      "Epoch 118/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 6.0407 - val_loss: 9.4312\n",
      "Epoch 119/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0800 - val_loss: 9.3447\n",
      "Epoch 120/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1174 - val_loss: 9.3587\n",
      "Epoch 121/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.0865 - val_loss: 9.4172\n",
      "Epoch 122/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.2679 - val_loss: 9.5924\n",
      "Epoch 123/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2046 - val_loss: 9.3302\n",
      "Epoch 124/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1043 - val_loss: 9.3150\n",
      "Epoch 125/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0532 - val_loss: 9.2908\n",
      "Epoch 126/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.2991 - val_loss: 9.1320\n",
      "Epoch 127/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.2173 - val_loss: 9.4303\n",
      "Epoch 128/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.4499 - val_loss: 9.4812\n",
      "Epoch 129/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.0916 - val_loss: 9.4645\n",
      "Epoch 130/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.0895 - val_loss: 9.4266\n",
      "Epoch 131/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.0459 - val_loss: 9.2814\n",
      "Epoch 132/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.1723 - val_loss: 9.1359\n",
      "Epoch 133/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2609 - val_loss: 9.2895\n",
      "Epoch 134/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0703 - val_loss: 9.1207\n",
      "Epoch 135/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0714 - val_loss: 9.2462\n",
      "Epoch 136/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.0782 - val_loss: 9.4242\n",
      "Epoch 137/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.0885 - val_loss: 9.4173\n",
      "Epoch 138/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0829 - val_loss: 9.4432\n",
      "Epoch 139/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.0103 - val_loss: 9.4025\n",
      "Epoch 140/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.1794 - val_loss: 9.2066\n",
      "Epoch 141/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0170 - val_loss: 9.1073\n",
      "Epoch 142/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1310 - val_loss: 9.2843\n",
      "Epoch 143/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.0138 - val_loss: 9.2904\n",
      "Epoch 144/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.0837 - val_loss: 9.5202\n",
      "Epoch 145/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3308 - val_loss: 9.4675\n",
      "Epoch 146/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1009 - val_loss: 9.2313\n",
      "Epoch 147/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 95us/step - loss: 6.8493 - val_loss: 9.5397\n",
      "Epoch 148/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3046 - val_loss: 9.1090\n",
      "Epoch 149/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0805 - val_loss: 9.4891\n",
      "Epoch 150/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.0689 - val_loss: 9.2142\n",
      "Epoch 151/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 6.0660 - val_loss: 9.2834\n",
      "Epoch 152/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.1743 - val_loss: 9.3061\n",
      "Epoch 153/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.0306 - val_loss: 9.5150\n",
      "Epoch 154/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.2312 - val_loss: 9.5048\n",
      "Epoch 155/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2374 - val_loss: 9.4134\n",
      "Epoch 156/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.1294 - val_loss: 9.6157\n",
      "Epoch 157/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9914 - val_loss: 9.2788\n",
      "Epoch 158/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4592 - val_loss: 9.5213\n",
      "Epoch 159/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0153 - val_loss: 9.4079\n",
      "Epoch 160/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9886 - val_loss: 9.2420\n",
      "Epoch 161/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9977 - val_loss: 9.2669\n",
      "Epoch 162/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.1152 - val_loss: 9.3567\n",
      "Epoch 163/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.0285 - val_loss: 9.4621\n",
      "Epoch 164/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9946 - val_loss: 9.2098\n",
      "Epoch 165/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0885 - val_loss: 9.4264\n",
      "Epoch 166/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0692 - val_loss: 9.3436\n",
      "Epoch 167/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.1879 - val_loss: 9.3946\n",
      "Epoch 168/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2823 - val_loss: 9.3274\n",
      "Epoch 169/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9290 - val_loss: 9.4068\n",
      "Epoch 170/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1897 - val_loss: 9.2311\n",
      "Epoch 171/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1091 - val_loss: 9.1068\n",
      "Epoch 172/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.9917 - val_loss: 9.2681\n",
      "Epoch 173/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.9944 - val_loss: 9.1939\n",
      "Epoch 174/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0614 - val_loss: 9.2357\n",
      "Epoch 175/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.9592 - val_loss: 9.0934\n",
      "Epoch 176/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0053 - val_loss: 9.1231\n",
      "Epoch 177/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.9983 - val_loss: 9.1639\n",
      "Epoch 178/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1318 - val_loss: 9.2803\n",
      "Epoch 179/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0137 - val_loss: 9.2501\n",
      "Epoch 180/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1451 - val_loss: 9.2512\n",
      "Epoch 181/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9332 - val_loss: 9.1848\n",
      "Epoch 182/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.9597 - val_loss: 9.2971\n",
      "Epoch 183/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.9011 - val_loss: 9.2019\n",
      "Epoch 184/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9907 - val_loss: 9.1906\n",
      "Epoch 185/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5323 - val_loss: 9.4456\n",
      "Epoch 186/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6039 - val_loss: 9.1933\n",
      "Epoch 187/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2481 - val_loss: 9.5422\n",
      "Epoch 188/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.2893 - val_loss: 9.1868\n",
      "Epoch 189/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.2334 - val_loss: 9.4142\n",
      "Epoch 190/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8822 - val_loss: 9.2497\n",
      "Epoch 191/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2335 - val_loss: 9.5843\n",
      "Epoch 192/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1528 - val_loss: 9.3608\n",
      "Epoch 193/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9289 - val_loss: 9.3043\n",
      "Epoch 194/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9775 - val_loss: 9.2629\n",
      "Epoch 195/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.2445 - val_loss: 9.2275\n",
      "Epoch 196/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.0556 - val_loss: 9.0867\n",
      "Epoch 197/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9594 - val_loss: 9.1303\n",
      "Epoch 198/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.1151 - val_loss: 9.2262\n",
      "Epoch 199/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9203 - val_loss: 9.1834\n",
      "Epoch 200/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.0438 - val_loss: 9.3173\n",
      "Epoch 201/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.8882 - val_loss: 9.2179\n",
      "Epoch 202/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9607 - val_loss: 9.1193\n",
      "Epoch 203/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9477 - val_loss: 9.1400\n",
      "Epoch 204/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9226 - val_loss: 9.1888\n",
      "Epoch 205/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.9993 - val_loss: 9.1154\n",
      "Epoch 206/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0772 - val_loss: 9.2529\n",
      "Epoch 207/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.2408 - val_loss: 9.1760\n",
      "Epoch 208/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3804 - val_loss: 9.3396\n",
      "Epoch 209/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.6843 - val_loss: 9.0147\n",
      "Epoch 210/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.2820 - val_loss: 9.3327\n",
      "Epoch 211/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9738 - val_loss: 9.1972\n",
      "Epoch 212/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.9450 - val_loss: 9.2989\n",
      "Epoch 213/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.0311 - val_loss: 9.3249\n",
      "Epoch 214/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.0909 - val_loss: 9.4262\n",
      "Epoch 215/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.9775 - val_loss: 9.2246\n",
      "Epoch 216/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9992 - val_loss: 9.3211\n",
      "Epoch 217/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9757 - val_loss: 9.3756\n",
      "Epoch 218/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 5.8635 - val_loss: 9.2081\n",
      "Epoch 219/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.0028 - val_loss: 9.2036\n",
      "Epoch 220/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9519 - val_loss: 9.2340\n",
      "Epoch 221/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.9610 - val_loss: 9.2289\n",
      "Epoch 222/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.9498 - val_loss: 9.2189\n",
      "Epoch 223/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.8222 - val_loss: 9.1732\n",
      "Epoch 224/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1133 - val_loss: 9.2088\n",
      "Epoch 225/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 99us/step - loss: 6.0172 - val_loss: 9.0738\n",
      "Epoch 226/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9596 - val_loss: 9.0944\n",
      "Epoch 227/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0292 - val_loss: 9.0308\n",
      "Epoch 228/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9615 - val_loss: 9.2492\n",
      "Epoch 229/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9926 - val_loss: 9.2684\n",
      "Epoch 230/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.0216 - val_loss: 9.2327\n",
      "Epoch 231/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.9455 - val_loss: 9.3054\n",
      "Epoch 232/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.8810 - val_loss: 9.2996\n",
      "Epoch 233/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0568 - val_loss: 9.2581\n",
      "Epoch 234/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.9185 - val_loss: 9.3559\n",
      "Epoch 235/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2727 - val_loss: 9.0237\n",
      "Epoch 236/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.2887 - val_loss: 8.9804\n",
      "Epoch 237/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.9475 - val_loss: 8.9968\n",
      "Epoch 238/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8858 - val_loss: 9.0590\n",
      "Epoch 239/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9638 - val_loss: 9.0297\n",
      "Epoch 240/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.9459 - val_loss: 8.9685\n",
      "Epoch 241/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0567 - val_loss: 9.1615\n",
      "Epoch 242/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.0019 - val_loss: 9.0034\n",
      "Epoch 243/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.1683 - val_loss: 8.9956\n",
      "Epoch 244/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.8498 - val_loss: 9.2182\n",
      "Epoch 245/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8582 - val_loss: 9.0446\n",
      "Epoch 246/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1284 - val_loss: 9.0676\n",
      "Epoch 247/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.8818 - val_loss: 8.9316\n",
      "Epoch 248/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.8758 - val_loss: 9.0181\n",
      "Epoch 249/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 6.053 - 0s 95us/step - loss: 5.8482 - val_loss: 9.0016\n",
      "Epoch 250/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.8616 - val_loss: 9.0969\n",
      "Epoch 251/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8565 - val_loss: 9.1386\n",
      "Epoch 252/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8849 - val_loss: 8.9569\n",
      "Epoch 253/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8053 - val_loss: 8.9379\n",
      "Epoch 254/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8506 - val_loss: 8.9212\n",
      "Epoch 255/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.9090 - val_loss: 9.0021\n",
      "Epoch 256/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.9161 - val_loss: 9.0711\n",
      "Epoch 257/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.8400 - val_loss: 9.1342\n",
      "Epoch 258/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0537 - val_loss: 9.0336\n",
      "Epoch 259/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9336 - val_loss: 9.1489\n",
      "Epoch 260/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9623 - val_loss: 9.0033\n",
      "Epoch 261/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8607 - val_loss: 9.2140\n",
      "Epoch 262/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9414 - val_loss: 8.7116\n",
      "Epoch 263/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8816 - val_loss: 8.9000\n",
      "Epoch 264/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8822 - val_loss: 8.9721\n",
      "Epoch 265/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9412 - val_loss: 8.9617\n",
      "Epoch 266/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.8004 - val_loss: 8.9598\n",
      "Epoch 267/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.7907 - val_loss: 8.9262\n",
      "Epoch 268/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8336 - val_loss: 8.8084\n",
      "Epoch 269/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8703 - val_loss: 9.0058\n",
      "Epoch 270/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0095 - val_loss: 9.0158\n",
      "Epoch 271/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0371 - val_loss: 8.7700\n",
      "Epoch 272/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.9942 - val_loss: 9.0986\n",
      "Epoch 273/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9491 - val_loss: 8.9275\n",
      "Epoch 274/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.9306 - val_loss: 9.2250\n",
      "Epoch 275/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 6.5855 - val_loss: 8.8523\n",
      "Epoch 276/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.6419 - val_loss: 9.2236\n",
      "Epoch 277/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3289 - val_loss: 8.8071\n",
      "Epoch 278/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.0175 - val_loss: 9.0375\n",
      "Epoch 279/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8684 - val_loss: 8.9319\n",
      "Epoch 280/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.8199 - val_loss: 8.7919\n",
      "Epoch 281/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.8442 - val_loss: 8.8636\n",
      "Epoch 282/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0521 - val_loss: 9.0383\n",
      "Epoch 283/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9184 - val_loss: 8.9370\n",
      "Epoch 284/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.8719 - val_loss: 8.9995\n",
      "Epoch 285/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.8041 - val_loss: 8.9557\n",
      "Epoch 286/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.8814 - val_loss: 8.8690\n",
      "Epoch 287/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7706 - val_loss: 8.8421\n",
      "Epoch 288/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.8218 - val_loss: 9.1325\n",
      "Epoch 289/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0287 - val_loss: 8.7841\n",
      "Epoch 290/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.8025 - val_loss: 9.0317\n",
      "Epoch 291/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.7484 - val_loss: 8.9162\n",
      "Epoch 292/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9359 - val_loss: 9.0877\n",
      "Epoch 293/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9062 - val_loss: 8.9840\n",
      "Epoch 294/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8288 - val_loss: 8.8865\n",
      "Epoch 295/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8983 - val_loss: 8.9101\n",
      "Epoch 296/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7628 - val_loss: 8.8237\n",
      "Epoch 297/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9539 - val_loss: 8.7482\n",
      "Epoch 298/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.8679 - val_loss: 8.6584\n",
      "Epoch 299/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0639 - val_loss: 8.9003\n",
      "Epoch 300/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.8431 - val_loss: 8.6956\n",
      "Epoch 301/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.8221 - val_loss: 8.9647\n",
      "Epoch 302/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 5.9055 - val_loss: 8.9498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 303/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7523 - val_loss: 8.8638\n",
      "Epoch 304/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.7908 - val_loss: 8.8065\n",
      "Epoch 305/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.8256 - val_loss: 8.5827\n",
      "Epoch 306/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.8570 - val_loss: 8.8753\n",
      "Epoch 307/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7759 - val_loss: 8.8519\n",
      "Epoch 308/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.9049 - val_loss: 8.7853\n",
      "Epoch 309/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8899 - val_loss: 8.7182\n",
      "Epoch 310/1000\n",
      "274/274 [==============================] - 0s 117us/step - loss: 5.7115 - val_loss: 8.6641\n",
      "Epoch 311/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.8424 - val_loss: 8.7593\n",
      "Epoch 312/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7408 - val_loss: 8.8220\n",
      "Epoch 313/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.8286 - val_loss: 8.8766\n",
      "Epoch 314/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.1053 - val_loss: 8.6958\n",
      "Epoch 315/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.9115 - val_loss: 8.9837\n",
      "Epoch 316/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.7743 - val_loss: 8.7237\n",
      "Epoch 317/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7237 - val_loss: 8.9283\n",
      "Epoch 318/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8391 - val_loss: 8.8035\n",
      "Epoch 319/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.7917 - val_loss: 8.6883\n",
      "Epoch 320/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7867 - val_loss: 8.6943\n",
      "Epoch 321/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8013 - val_loss: 8.7368\n",
      "Epoch 322/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7188 - val_loss: 8.7543\n",
      "Epoch 323/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7646 - val_loss: 8.6891\n",
      "Epoch 324/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9047 - val_loss: 8.7219\n",
      "Epoch 325/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7899 - val_loss: 8.8431\n",
      "Epoch 326/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7466 - val_loss: 8.8158\n",
      "Epoch 327/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9112 - val_loss: 8.8320\n",
      "Epoch 328/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8987 - val_loss: 8.7158\n",
      "Epoch 329/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.9014 - val_loss: 8.6776\n",
      "Epoch 330/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6764 - val_loss: 8.7706\n",
      "Epoch 331/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.8268 - val_loss: 8.7592\n",
      "Epoch 332/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7054 - val_loss: 8.7718\n",
      "Epoch 333/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.7416 - val_loss: 8.7889\n",
      "Epoch 334/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8082 - val_loss: 8.6904\n",
      "Epoch 335/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8289 - val_loss: 8.7617\n",
      "Epoch 336/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8450 - val_loss: 8.7097\n",
      "Epoch 337/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8051 - val_loss: 8.5227\n",
      "Epoch 338/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7483 - val_loss: 8.5587\n",
      "Epoch 339/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7851 - val_loss: 8.7166\n",
      "Epoch 340/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8018 - val_loss: 8.5424\n",
      "Epoch 341/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7310 - val_loss: 8.7143\n",
      "Epoch 342/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.6918 - val_loss: 8.5093\n",
      "Epoch 343/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6757 - val_loss: 8.6831\n",
      "Epoch 344/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.7895 - val_loss: 8.6288\n",
      "Epoch 345/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8167 - val_loss: 8.6978\n",
      "Epoch 346/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.7391 - val_loss: 8.5959\n",
      "Epoch 347/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.7295 - val_loss: 8.6797\n",
      "Epoch 348/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7222 - val_loss: 8.5940\n",
      "Epoch 349/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6727 - val_loss: 8.5947\n",
      "Epoch 350/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7251 - val_loss: 8.6434\n",
      "Epoch 351/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7425 - val_loss: 8.7601\n",
      "Epoch 352/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9402 - val_loss: 8.8969\n",
      "Epoch 353/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8173 - val_loss: 8.5878\n",
      "Epoch 354/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6831 - val_loss: 8.6909\n",
      "Epoch 355/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.7903 - val_loss: 8.5844\n",
      "Epoch 356/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6943 - val_loss: 8.7291\n",
      "Epoch 357/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.7797 - val_loss: 8.6799\n",
      "Epoch 358/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6395 - val_loss: 8.7803\n",
      "Epoch 359/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8704 - val_loss: 8.8449\n",
      "Epoch 360/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8406 - val_loss: 8.5488\n",
      "Epoch 361/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.0040 - val_loss: 9.1222\n",
      "Epoch 362/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9095 - val_loss: 8.6002\n",
      "Epoch 363/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 6.0499 - val_loss: 9.0433\n",
      "Epoch 364/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7115 - val_loss: 8.7853\n",
      "Epoch 365/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.8313 - val_loss: 8.8464\n",
      "Epoch 366/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.6387 - val_loss: 8.5552\n",
      "Epoch 367/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7448 - val_loss: 8.6231\n",
      "Epoch 368/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.8581 - val_loss: 8.6628\n",
      "Epoch 369/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7872 - val_loss: 8.6488\n",
      "Epoch 370/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7856 - val_loss: 8.6943\n",
      "Epoch 371/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6887 - val_loss: 8.7277\n",
      "Epoch 372/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6313 - val_loss: 8.6021\n",
      "Epoch 373/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6122 - val_loss: 8.5589\n",
      "Epoch 374/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6530 - val_loss: 8.6643\n",
      "Epoch 375/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7188 - val_loss: 8.6054\n",
      "Epoch 376/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.7538 - val_loss: 8.5752\n",
      "Epoch 377/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.6642 - val_loss: 8.5960\n",
      "Epoch 378/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6345 - val_loss: 8.6634\n",
      "Epoch 379/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.5963 - val_loss: 8.4608\n",
      "Epoch 380/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6315 - val_loss: 8.5848\n",
      "Epoch 381/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6213 - val_loss: 8.5761\n",
      "Epoch 382/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6589 - val_loss: 8.5431\n",
      "Epoch 383/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.7489 - val_loss: 8.7087\n",
      "Epoch 384/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8918 - val_loss: 8.4157\n",
      "Epoch 385/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6369 - val_loss: 8.5702\n",
      "Epoch 386/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.6691 - val_loss: 8.7955\n",
      "Epoch 387/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6329 - val_loss: 8.8256\n",
      "Epoch 388/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5766 - val_loss: 8.7434\n",
      "Epoch 389/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6111 - val_loss: 8.7842\n",
      "Epoch 390/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6821 - val_loss: 8.5908\n",
      "Epoch 391/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6184 - val_loss: 8.5518\n",
      "Epoch 392/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7379 - val_loss: 8.6884\n",
      "Epoch 393/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7911 - val_loss: 8.7117\n",
      "Epoch 394/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.9829 - val_loss: 8.4911\n",
      "Epoch 395/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7877 - val_loss: 8.7023\n",
      "Epoch 396/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5488 - val_loss: 8.4731\n",
      "Epoch 397/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.7855 - val_loss: 8.8704\n",
      "Epoch 398/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6421 - val_loss: 8.5228\n",
      "Epoch 399/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7237 - val_loss: 8.6615\n",
      "Epoch 400/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7700 - val_loss: 8.5848\n",
      "Epoch 401/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6982 - val_loss: 8.6331\n",
      "Epoch 402/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9877 - val_loss: 8.6740\n",
      "Epoch 403/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6639 - val_loss: 8.6580\n",
      "Epoch 404/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6550 - val_loss: 8.6933\n",
      "Epoch 405/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.6736 - val_loss: 8.6639\n",
      "Epoch 406/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7273 - val_loss: 8.6042\n",
      "Epoch 407/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.6797 - val_loss: 8.7899\n",
      "Epoch 408/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0239 - val_loss: 8.5741\n",
      "Epoch 409/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9707 - val_loss: 8.6611\n",
      "Epoch 410/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.6327 - val_loss: 8.6239\n",
      "Epoch 411/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5661 - val_loss: 8.4981\n",
      "Epoch 412/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6015 - val_loss: 8.6253\n",
      "Epoch 413/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.5693 - val_loss: 8.6639\n",
      "Epoch 414/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6146 - val_loss: 8.6837\n",
      "Epoch 415/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6762 - val_loss: 8.6865\n",
      "Epoch 416/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.2784 - val_loss: 8.5080\n",
      "Epoch 417/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1500 - val_loss: 8.7465\n",
      "Epoch 418/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7025 - val_loss: 8.7192\n",
      "Epoch 419/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6814 - val_loss: 8.7903\n",
      "Epoch 420/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6561 - val_loss: 8.6333\n",
      "Epoch 421/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.5893 - val_loss: 8.7181\n",
      "Epoch 422/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7763 - val_loss: 8.8602\n",
      "Epoch 423/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6570 - val_loss: 8.7604\n",
      "Epoch 424/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6824 - val_loss: 8.8860\n",
      "Epoch 425/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6052 - val_loss: 8.4912\n",
      "Epoch 426/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5491 - val_loss: 8.6523\n",
      "Epoch 427/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.6587 - val_loss: 8.5652\n",
      "Epoch 428/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5721 - val_loss: 8.6838\n",
      "Epoch 429/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6339 - val_loss: 8.5973\n",
      "Epoch 430/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8474 - val_loss: 8.7403\n",
      "Epoch 431/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9772 - val_loss: 8.4577\n",
      "Epoch 432/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.7830 - val_loss: 8.7671\n",
      "Epoch 433/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6179 - val_loss: 8.7326\n",
      "Epoch 434/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5686 - val_loss: 8.8733\n",
      "Epoch 435/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6209 - val_loss: 8.7703\n",
      "Epoch 436/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5996 - val_loss: 8.7110\n",
      "Epoch 437/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.6370 - val_loss: 8.6658\n",
      "Epoch 438/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7466 - val_loss: 8.6433\n",
      "Epoch 439/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7301 - val_loss: 8.7150\n",
      "Epoch 440/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8186 - val_loss: 8.6990\n",
      "Epoch 441/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6294 - val_loss: 8.6849\n",
      "Epoch 442/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6071 - val_loss: 8.6342\n",
      "Epoch 443/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.5075 - val_loss: 8.6602\n",
      "Epoch 444/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.5837 - val_loss: 8.6007\n",
      "Epoch 445/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.8406 - val_loss: 8.7512\n",
      "Epoch 446/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5609 - val_loss: 8.6377\n",
      "Epoch 447/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.6361 - val_loss: 8.5943\n",
      "Epoch 448/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.5856 - val_loss: 8.5842\n",
      "Epoch 449/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.6928 - val_loss: 8.5692\n",
      "Epoch 450/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.0272 - val_loss: 8.9038\n",
      "Epoch 451/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.7729 - val_loss: 8.8134\n",
      "Epoch 452/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6359 - val_loss: 8.8455\n",
      "Epoch 453/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5154 - val_loss: 9.0174\n",
      "Epoch 454/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7073 - val_loss: 8.6735\n",
      "Epoch 455/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.5542 - val_loss: 8.6958\n",
      "Epoch 456/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.6216 - val_loss: 8.7723\n",
      "Epoch 457/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5892 - val_loss: 8.6958\n",
      "Epoch 458/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 98us/step - loss: 5.6409 - val_loss: 8.7392\n",
      "Epoch 459/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.6203 - val_loss: 8.7447\n",
      "Epoch 460/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.6316 - val_loss: 8.7620\n",
      "Epoch 461/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6538 - val_loss: 8.7214\n",
      "Epoch 462/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5657 - val_loss: 8.8331\n",
      "Epoch 463/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5910 - val_loss: 8.8025\n",
      "Epoch 464/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7433 - val_loss: 8.4121\n",
      "Epoch 465/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.6952 - val_loss: 8.7810\n",
      "Epoch 466/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5658 - val_loss: 8.7120\n",
      "Epoch 467/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.6282 - val_loss: 8.6782\n",
      "Epoch 468/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.5252 - val_loss: 8.6984\n",
      "Epoch 469/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.5742 - val_loss: 8.7618\n",
      "Epoch 470/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.6499 - val_loss: 8.6189\n",
      "Epoch 471/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.7078 - val_loss: 8.7815\n",
      "Epoch 472/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6681 - val_loss: 8.6558\n",
      "Epoch 473/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.5452 - val_loss: 8.8080\n",
      "Epoch 474/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5294 - val_loss: 8.8707\n",
      "Epoch 475/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.5762 - val_loss: 8.6944\n",
      "Epoch 476/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.6118 - val_loss: 8.6272\n",
      "Epoch 477/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.6354 - val_loss: 8.8278\n",
      "Epoch 478/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.6483 - val_loss: 8.9115\n",
      "Epoch 479/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6184 - val_loss: 8.5957\n",
      "Epoch 480/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.6497 - val_loss: 8.8517\n",
      "Epoch 481/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6600 - val_loss: 8.7189\n",
      "Epoch 482/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.4698 - val_loss: 8.7709\n",
      "Epoch 483/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4934 - val_loss: 8.7364\n",
      "Epoch 484/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.5955 - val_loss: 8.6791\n",
      "Epoch 485/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5615 - val_loss: 8.7765\n",
      "Epoch 486/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.5002 - val_loss: 8.8344\n",
      "Epoch 487/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5560 - val_loss: 8.7057\n",
      "Epoch 488/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 5.6584 - val_loss: 8.7051\n",
      "Epoch 489/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4837 - val_loss: 8.7749\n",
      "Epoch 490/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.5087 - val_loss: 8.7026\n",
      "Epoch 491/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.5899 - val_loss: 8.8140\n",
      "Epoch 492/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5036 - val_loss: 8.8771\n",
      "Epoch 493/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.5681 - val_loss: 8.8830\n",
      "Epoch 494/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6038 - val_loss: 8.9842\n",
      "Epoch 495/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5170 - val_loss: 8.7273\n",
      "Epoch 496/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6613 - val_loss: 8.8778\n",
      "Epoch 497/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5151 - val_loss: 8.6405\n",
      "Epoch 498/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4948 - val_loss: 8.7185\n",
      "Epoch 499/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5570 - val_loss: 8.7962\n",
      "Epoch 500/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.5260 - val_loss: 8.8447\n",
      "Epoch 501/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.5025 - val_loss: 8.7626\n",
      "Epoch 502/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.5935 - val_loss: 8.9513\n",
      "Epoch 503/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7890 - val_loss: 8.7565\n",
      "Epoch 504/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.5364 - val_loss: 9.0688\n",
      "Epoch 505/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6038 - val_loss: 8.7898\n",
      "Epoch 506/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7231 - val_loss: 9.2205\n",
      "Epoch 507/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.7297 - val_loss: 8.7709\n",
      "Epoch 508/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.8535 - val_loss: 8.9941\n",
      "Epoch 509/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.6612 - val_loss: 8.8279\n",
      "Epoch 510/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6174 - val_loss: 8.9519\n",
      "Epoch 511/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5905 - val_loss: 8.7048\n",
      "Epoch 512/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6784 - val_loss: 8.9518\n",
      "Epoch 513/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.6410 - val_loss: 8.7849\n",
      "Epoch 514/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.6284 - val_loss: 8.9029\n",
      "Epoch 515/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6881 - val_loss: 8.8674\n",
      "Epoch 516/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6485 - val_loss: 8.9716\n",
      "Epoch 517/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5604 - val_loss: 8.9767\n",
      "Epoch 518/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5203 - val_loss: 8.7553\n",
      "Epoch 519/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.6108 - val_loss: 8.9231\n",
      "Epoch 520/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5247 - val_loss: 8.8914\n",
      "Epoch 521/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4606 - val_loss: 9.0910\n",
      "Epoch 522/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5042 - val_loss: 8.9762\n",
      "Epoch 523/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5667 - val_loss: 8.8836\n",
      "Epoch 524/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6248 - val_loss: 9.0033\n",
      "Epoch 525/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4316 - val_loss: 8.8270\n",
      "Epoch 526/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6565 - val_loss: 8.9366\n",
      "Epoch 527/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5089 - val_loss: 8.8157\n",
      "Epoch 528/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5117 - val_loss: 8.8723\n",
      "Epoch 529/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.5161 - val_loss: 8.8034\n",
      "Epoch 530/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5882 - val_loss: 9.1132\n",
      "Epoch 531/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5662 - val_loss: 8.8644\n",
      "Epoch 532/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.7700 - val_loss: 8.9354\n",
      "Epoch 533/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6863 - val_loss: 8.6378\n",
      "Epoch 534/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5013 - val_loss: 8.9160\n",
      "Epoch 535/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5789 - val_loss: 9.0065\n",
      "Epoch 536/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 95us/step - loss: 5.5638 - val_loss: 8.9769\n",
      "Epoch 537/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5820 - val_loss: 8.9405\n",
      "Epoch 538/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6917 - val_loss: 9.0594\n",
      "Epoch 539/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5223 - val_loss: 8.8248\n",
      "Epoch 540/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.5890 - val_loss: 8.8670\n",
      "Epoch 541/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.6798 - val_loss: 9.0760\n",
      "Epoch 542/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5623 - val_loss: 9.0072\n",
      "Epoch 543/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5893 - val_loss: 9.1566\n",
      "Epoch 544/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.6983 - val_loss: 8.9954\n",
      "Epoch 545/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.6340 - val_loss: 9.1652\n",
      "Epoch 546/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6192 - val_loss: 8.9936\n",
      "Epoch 547/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6035 - val_loss: 9.0864\n",
      "Epoch 548/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5067 - val_loss: 8.8888\n",
      "Epoch 549/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4873 - val_loss: 9.1093\n",
      "Epoch 550/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.6685 - val_loss: 8.9671\n",
      "Epoch 551/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.5800 - val_loss: 9.1014\n",
      "Epoch 552/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4967 - val_loss: 9.0905\n",
      "Epoch 553/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5413 - val_loss: 9.0842\n",
      "Epoch 554/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.5406 - val_loss: 9.0946\n",
      "Epoch 555/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9353 - val_loss: 9.0761\n",
      "Epoch 556/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6039 - val_loss: 9.0659\n",
      "Epoch 557/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5599 - val_loss: 8.8918\n",
      "Epoch 558/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5228 - val_loss: 8.9369\n",
      "Epoch 559/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4421 - val_loss: 9.0088\n",
      "Epoch 560/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5641 - val_loss: 9.0448\n",
      "Epoch 561/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8613 - val_loss: 9.0863\n",
      "Epoch 562/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4541 - val_loss: 9.1862\n",
      "Epoch 563/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5254 - val_loss: 9.1071\n",
      "Epoch 564/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.3942 - val_loss: 8.9320\n",
      "Epoch 565/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.5786 - val_loss: 8.9353\n",
      "Epoch 566/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5456 - val_loss: 9.2011\n",
      "Epoch 567/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5902 - val_loss: 9.1732\n",
      "Epoch 568/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.4586 - val_loss: 8.9460\n",
      "Epoch 569/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4850 - val_loss: 9.1687\n",
      "Epoch 570/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4673 - val_loss: 9.0573\n",
      "Epoch 571/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.4660 - val_loss: 9.2225\n",
      "Epoch 572/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.4756 - val_loss: 9.0282\n",
      "Epoch 573/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.4707 - val_loss: 9.1738\n",
      "Epoch 574/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4988 - val_loss: 8.9263\n",
      "Epoch 575/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.4888 - val_loss: 9.1082\n",
      "Epoch 576/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.3955 - val_loss: 9.0555\n",
      "Epoch 577/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5222 - val_loss: 9.1968\n",
      "Epoch 578/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4913 - val_loss: 9.0712\n",
      "Epoch 579/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4869 - val_loss: 9.1983\n",
      "Epoch 580/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4909 - val_loss: 9.1817\n",
      "Epoch 581/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5084 - val_loss: 9.0893\n",
      "Epoch 582/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.4255 - val_loss: 8.9753\n",
      "Epoch 583/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.4452 - val_loss: 8.8747\n",
      "Epoch 584/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.5841 - val_loss: 9.0041\n",
      "Epoch 585/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8467 - val_loss: 9.4749\n",
      "Epoch 586/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.5481 - val_loss: 9.1221\n",
      "Epoch 587/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.4623 - val_loss: 9.1773\n",
      "Epoch 588/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4626 - val_loss: 9.1670\n",
      "Epoch 589/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.4664 - val_loss: 9.1465\n",
      "Epoch 590/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4843 - val_loss: 9.2084\n",
      "Epoch 591/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.4011 - val_loss: 9.1517\n",
      "Epoch 592/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4848 - val_loss: 9.1195\n",
      "Epoch 593/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.5431 - val_loss: 9.2810\n",
      "Epoch 594/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.5321 - val_loss: 9.1967\n",
      "Epoch 595/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4808 - val_loss: 9.1715\n",
      "Epoch 596/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4852 - val_loss: 9.2268\n",
      "Epoch 597/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.5093 - val_loss: 9.0590\n",
      "Epoch 598/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4767 - val_loss: 9.2385\n",
      "Epoch 599/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5547 - val_loss: 9.3319\n",
      "Epoch 600/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4521 - val_loss: 9.2323\n",
      "Epoch 601/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4429 - val_loss: 9.1369\n",
      "Epoch 602/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3908 - val_loss: 9.1912\n",
      "Epoch 603/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.5711 - val_loss: 9.1564\n",
      "Epoch 604/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.4500 - val_loss: 9.3107\n",
      "Epoch 605/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5917 - val_loss: 9.2125\n",
      "Epoch 606/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5072 - val_loss: 9.2784\n",
      "Epoch 607/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5584 - val_loss: 9.1616\n",
      "Epoch 608/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5998 - val_loss: 9.0869\n",
      "Epoch 609/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5157 - val_loss: 9.2087\n",
      "Epoch 610/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4032 - val_loss: 9.1349\n",
      "Epoch 611/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4397 - val_loss: 9.2722\n",
      "Epoch 612/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6375 - val_loss: 9.2621\n",
      "Epoch 613/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5918 - val_loss: 9.2781\n",
      "Epoch 614/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 95us/step - loss: 5.6631 - val_loss: 9.2968\n",
      "Epoch 615/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.9053 - val_loss: 9.1283\n",
      "Epoch 616/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.8181 - val_loss: 9.2924\n",
      "Epoch 617/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6327 - val_loss: 9.1898\n",
      "Epoch 618/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6391 - val_loss: 9.1482\n",
      "Epoch 619/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.7913 - val_loss: 9.8639\n",
      "Epoch 620/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 5.6346 - val_loss: 9.3831\n",
      "Epoch 621/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7981 - val_loss: 9.2743\n",
      "Epoch 622/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.5542 - val_loss: 9.0564\n",
      "Epoch 623/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4329 - val_loss: 9.1250\n",
      "Epoch 624/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.5359 - val_loss: 9.2148\n",
      "Epoch 625/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3909 - val_loss: 9.1914\n",
      "Epoch 626/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.4476 - val_loss: 9.1574\n",
      "Epoch 627/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6810 - val_loss: 9.2970\n",
      "Epoch 628/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4830 - val_loss: 9.2732\n",
      "Epoch 629/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4297 - val_loss: 9.4044\n",
      "Epoch 630/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.5670 - val_loss: 9.1946\n",
      "Epoch 631/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4965 - val_loss: 9.2676\n",
      "Epoch 632/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.6080 - val_loss: 9.2689\n",
      "Epoch 633/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4695 - val_loss: 9.3200\n",
      "Epoch 634/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6736 - val_loss: 9.4523\n",
      "Epoch 635/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.6586 - val_loss: 9.3298\n",
      "Epoch 636/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.5789 - val_loss: 9.2810\n",
      "Epoch 637/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.5788 - val_loss: 9.2147\n",
      "Epoch 638/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4375 - val_loss: 9.2179\n",
      "Epoch 639/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.4489 - val_loss: 9.3066\n",
      "Epoch 640/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.4502 - val_loss: 9.3165\n",
      "Epoch 641/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4242 - val_loss: 9.2139\n",
      "Epoch 642/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 5.4821 - val_loss: 9.2019\n",
      "Epoch 643/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7145 - val_loss: 9.4404\n",
      "Epoch 644/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5414 - val_loss: 9.1617\n",
      "Epoch 645/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.4869 - val_loss: 9.3241\n",
      "Epoch 646/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.3736 - val_loss: 9.2444\n",
      "Epoch 647/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 5.4998 - val_loss: 9.4341\n",
      "Epoch 648/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.4388 - val_loss: 9.3659\n",
      "Epoch 649/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6704 - val_loss: 9.5160\n",
      "Epoch 650/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0787 - val_loss: 9.1729\n",
      "Epoch 651/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0089 - val_loss: 9.4578\n",
      "Epoch 652/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7013 - val_loss: 9.0976\n",
      "Epoch 653/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6265 - val_loss: 9.5012\n",
      "Epoch 654/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.5183 - val_loss: 9.4743\n",
      "Epoch 655/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3996 - val_loss: 9.3818\n",
      "Epoch 656/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.4065 - val_loss: 9.2516\n",
      "Epoch 657/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5300 - val_loss: 9.3025\n",
      "Epoch 658/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4201 - val_loss: 9.2682\n",
      "Epoch 659/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5707 - val_loss: 9.4579\n",
      "Epoch 660/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3969 - val_loss: 9.3298\n",
      "Epoch 661/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.4309 - val_loss: 9.4034\n",
      "Epoch 662/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.4718 - val_loss: 9.0689\n",
      "Epoch 663/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6390 - val_loss: 9.2943\n",
      "Epoch 664/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5337 - val_loss: 9.3178\n",
      "Epoch 665/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4772 - val_loss: 9.5683\n",
      "Epoch 666/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5104 - val_loss: 9.4847\n",
      "Epoch 667/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3920 - val_loss: 9.3844\n",
      "Epoch 668/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4477 - val_loss: 9.3706\n",
      "Epoch 669/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.5275 - val_loss: 9.3249\n",
      "Epoch 670/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4881 - val_loss: 9.5124\n",
      "Epoch 671/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4433 - val_loss: 9.2644\n",
      "Epoch 672/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4001 - val_loss: 9.2047\n",
      "Epoch 673/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.4627 - val_loss: 9.2799\n",
      "Epoch 674/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6331 - val_loss: 9.3093\n",
      "Epoch 675/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4904 - val_loss: 9.4385\n",
      "Epoch 676/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6374 - val_loss: 9.5197\n",
      "Epoch 677/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.4735 - val_loss: 9.5970\n",
      "Epoch 678/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.6906 - val_loss: 9.5909\n",
      "Epoch 679/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4440 - val_loss: 9.4612\n",
      "Epoch 680/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8030 - val_loss: 9.2695\n",
      "Epoch 681/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.0420 - val_loss: 9.5420\n",
      "Epoch 682/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2662 - val_loss: 9.4393\n",
      "Epoch 683/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6548 - val_loss: 9.8150\n",
      "Epoch 684/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 5.5444 - val_loss: 9.5281\n",
      "Epoch 685/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3885 - val_loss: 9.5984\n",
      "Epoch 686/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.4279 - val_loss: 9.4234\n",
      "Epoch 687/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.4236 - val_loss: 9.3829\n",
      "Epoch 688/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4141 - val_loss: 9.5465\n",
      "Epoch 689/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4431 - val_loss: 9.5357\n",
      "Epoch 690/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4582 - val_loss: 9.5569\n",
      "Epoch 691/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.5849 - val_loss: 9.6441\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 692/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4545 - val_loss: 9.4770\n",
      "Epoch 693/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4334 - val_loss: 9.5434\n",
      "Epoch 694/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4172 - val_loss: 9.5604\n",
      "Epoch 695/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3724 - val_loss: 9.5263\n",
      "Epoch 696/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4717 - val_loss: 9.4003\n",
      "Epoch 697/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3724 - val_loss: 9.4522\n",
      "Epoch 698/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.4315 - val_loss: 9.2963\n",
      "Epoch 699/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.4708 - val_loss: 9.5606\n",
      "Epoch 700/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.4129 - val_loss: 9.6840\n",
      "Epoch 701/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3829 - val_loss: 9.5142\n",
      "Epoch 702/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3749 - val_loss: 9.5679\n",
      "Epoch 703/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3428 - val_loss: 9.4988\n",
      "Epoch 704/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5166 - val_loss: 9.5305\n",
      "Epoch 705/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3766 - val_loss: 9.5556\n",
      "Epoch 706/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3627 - val_loss: 9.4762\n",
      "Epoch 707/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3694 - val_loss: 9.6171\n",
      "Epoch 708/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3747 - val_loss: 9.5339\n",
      "Epoch 709/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.3930 - val_loss: 9.5939\n",
      "Epoch 710/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3541 - val_loss: 9.7008\n",
      "Epoch 711/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.3915 - val_loss: 9.7126\n",
      "Epoch 712/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4396 - val_loss: 9.6573\n",
      "Epoch 713/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4119 - val_loss: 9.5725\n",
      "Epoch 714/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4232 - val_loss: 9.6696\n",
      "Epoch 715/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4335 - val_loss: 9.7679\n",
      "Epoch 716/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6212 - val_loss: 9.6352\n",
      "Epoch 717/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4633 - val_loss: 9.7580\n",
      "Epoch 718/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3523 - val_loss: 9.5517\n",
      "Epoch 719/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.3900 - val_loss: 9.5760\n",
      "Epoch 720/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.5844 - val_loss: 9.5961\n",
      "Epoch 721/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.5371 - val_loss: 9.7864\n",
      "Epoch 722/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3637 - val_loss: 9.6927\n",
      "Epoch 723/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.4648 - val_loss: 9.6276\n",
      "Epoch 724/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4691 - val_loss: 9.6313\n",
      "Epoch 725/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3414 - val_loss: 9.7213\n",
      "Epoch 726/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3444 - val_loss: 9.9470\n",
      "Epoch 727/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.3760 - val_loss: 9.9407\n",
      "Epoch 728/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.6005 - val_loss: 9.6875\n",
      "Epoch 729/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5285 - val_loss: 9.7447\n",
      "Epoch 730/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7568 - val_loss: 9.8239\n",
      "Epoch 731/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.6377 - val_loss: 9.7713\n",
      "Epoch 732/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5095 - val_loss: 9.6898\n",
      "Epoch 733/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.4776 - val_loss: 9.6183\n",
      "Epoch 734/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3441 - val_loss: 9.8223\n",
      "Epoch 735/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3685 - val_loss: 9.8687\n",
      "Epoch 736/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.3450 - val_loss: 9.9223\n",
      "Epoch 737/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.4567 - val_loss: 9.8731\n",
      "Epoch 738/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4683 - val_loss: 10.0765\n",
      "Epoch 739/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4947 - val_loss: 9.8968\n",
      "Epoch 740/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4151 - val_loss: 10.0376\n",
      "Epoch 741/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3607 - val_loss: 9.9718\n",
      "Epoch 742/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4080 - val_loss: 9.9739\n",
      "Epoch 743/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4807 - val_loss: 9.7504\n",
      "Epoch 744/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3764 - val_loss: 9.9711\n",
      "Epoch 745/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.3433 - val_loss: 10.1257\n",
      "Epoch 746/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.3585 - val_loss: 10.0307\n",
      "Epoch 747/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3716 - val_loss: 9.9072\n",
      "Epoch 748/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.3489 - val_loss: 10.0569\n",
      "Epoch 749/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.4981 - val_loss: 9.8644\n",
      "Epoch 750/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4709 - val_loss: 9.9101\n",
      "Epoch 751/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2985 - val_loss: 9.7858\n",
      "Epoch 752/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.3122 - val_loss: 10.1018\n",
      "Epoch 753/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3635 - val_loss: 10.1391\n",
      "Epoch 754/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3340 - val_loss: 10.0611\n",
      "Epoch 755/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4341 - val_loss: 9.9974\n",
      "Epoch 756/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3305 - val_loss: 9.9342\n",
      "Epoch 757/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7339 - val_loss: 10.1154\n",
      "Epoch 758/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.4349 - val_loss: 9.8767\n",
      "Epoch 759/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3995 - val_loss: 9.9416\n",
      "Epoch 760/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.3236 - val_loss: 10.0147\n",
      "Epoch 761/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3545 - val_loss: 10.3033\n",
      "Epoch 762/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3618 - val_loss: 10.2395\n",
      "Epoch 763/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.4453 - val_loss: 10.3601\n",
      "Epoch 764/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.4256 - val_loss: 10.2748\n",
      "Epoch 765/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.4272 - val_loss: 10.1673\n",
      "Epoch 766/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.3622 - val_loss: 10.1625\n",
      "Epoch 767/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.2619 - val_loss: 10.3529\n",
      "Epoch 768/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3632 - val_loss: 10.1657\n",
      "Epoch 769/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.3926 - val_loss: 10.1825\n",
      "Epoch 770/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2985 - val_loss: 10.1480\n",
      "Epoch 771/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.3231 - val_loss: 10.3405\n",
      "Epoch 772/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3500 - val_loss: 10.4051\n",
      "Epoch 773/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4806 - val_loss: 10.3455\n",
      "Epoch 774/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3717 - val_loss: 10.3812\n",
      "Epoch 775/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.2473 - val_loss: 10.5141\n",
      "Epoch 776/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.3276 - val_loss: 10.3599\n",
      "Epoch 777/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3586 - val_loss: 10.2670\n",
      "Epoch 778/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2829 - val_loss: 10.3305\n",
      "Epoch 779/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3253 - val_loss: 10.2716\n",
      "Epoch 780/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3009 - val_loss: 10.3026\n",
      "Epoch 781/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3888 - val_loss: 10.2489\n",
      "Epoch 782/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3930 - val_loss: 10.1808\n",
      "Epoch 783/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2393 - val_loss: 10.1851\n",
      "Epoch 784/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.5256 - val_loss: 10.5540\n",
      "Epoch 785/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6216 - val_loss: 10.2160\n",
      "Epoch 786/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3164 - val_loss: 10.5360\n",
      "Epoch 787/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3943 - val_loss: 10.2985\n",
      "Epoch 788/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.3065 - val_loss: 10.3769\n",
      "Epoch 789/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.2944 - val_loss: 10.2564\n",
      "Epoch 790/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2719 - val_loss: 10.3142\n",
      "Epoch 791/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2601 - val_loss: 10.3548\n",
      "Epoch 792/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.2658 - val_loss: 10.3717\n",
      "Epoch 793/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2573 - val_loss: 10.4857\n",
      "Epoch 794/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2460 - val_loss: 10.4970\n",
      "Epoch 795/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3938 - val_loss: 10.4438\n",
      "Epoch 796/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.2966 - val_loss: 10.5941\n",
      "Epoch 797/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3698 - val_loss: 10.3912\n",
      "Epoch 798/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3234 - val_loss: 10.6492\n",
      "Epoch 799/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.2720 - val_loss: 10.2583\n",
      "Epoch 800/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3111 - val_loss: 10.3701\n",
      "Epoch 801/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3088 - val_loss: 10.4114\n",
      "Epoch 802/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3038 - val_loss: 10.1898\n",
      "Epoch 803/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3378 - val_loss: 10.3250\n",
      "Epoch 804/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3772 - val_loss: 10.1800\n",
      "Epoch 805/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3224 - val_loss: 10.2339\n",
      "Epoch 806/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.3821 - val_loss: 10.7074\n",
      "Epoch 807/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4372 - val_loss: 10.2956\n",
      "Epoch 808/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4249 - val_loss: 10.4942\n",
      "Epoch 809/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.3899 - val_loss: 10.4610\n",
      "Epoch 810/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.6504 - val_loss: 10.4785\n",
      "Epoch 811/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.3578 - val_loss: 10.3885\n",
      "Epoch 812/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3900 - val_loss: 10.3731\n",
      "Epoch 813/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2099 - val_loss: 10.2927\n",
      "Epoch 814/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2470 - val_loss: 10.4020\n",
      "Epoch 815/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2797 - val_loss: 10.4725\n",
      "Epoch 816/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5071 - val_loss: 10.2851\n",
      "Epoch 817/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.2920 - val_loss: 10.4692\n",
      "Epoch 818/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2223 - val_loss: 10.3402\n",
      "Epoch 819/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1893 - val_loss: 10.3694\n",
      "Epoch 820/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2264 - val_loss: 10.5014\n",
      "Epoch 821/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2448 - val_loss: 10.3957\n",
      "Epoch 822/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1958 - val_loss: 10.5058\n",
      "Epoch 823/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.1519 - val_loss: 10.3629\n",
      "Epoch 824/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.1830 - val_loss: 10.3783\n",
      "Epoch 825/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2304 - val_loss: 10.2775\n",
      "Epoch 826/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.2434 - val_loss: 10.3585\n",
      "Epoch 827/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.3127 - val_loss: 10.2890\n",
      "Epoch 828/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.3423 - val_loss: 10.5717\n",
      "Epoch 829/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.3999 - val_loss: 10.2594\n",
      "Epoch 830/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2104 - val_loss: 10.6092\n",
      "Epoch 831/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.3075 - val_loss: 10.3943\n",
      "Epoch 832/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.2694 - val_loss: 10.3378\n",
      "Epoch 833/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.1667 - val_loss: 10.3459\n",
      "Epoch 834/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2931 - val_loss: 10.4618\n",
      "Epoch 835/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.3342 - val_loss: 10.2956\n",
      "Epoch 836/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1898 - val_loss: 10.5161\n",
      "Epoch 837/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.1846 - val_loss: 10.6244\n",
      "Epoch 838/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2762 - val_loss: 10.4112\n",
      "Epoch 839/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1393 - val_loss: 10.4511\n",
      "Epoch 840/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4489 - val_loss: 10.5566\n",
      "Epoch 841/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.1775 - val_loss: 10.6266\n",
      "Epoch 842/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4757 - val_loss: 10.6473\n",
      "Epoch 843/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6397 - val_loss: 10.4125\n",
      "Epoch 844/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4430 - val_loss: 10.8791\n",
      "Epoch 845/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.3287 - val_loss: 10.4999\n",
      "Epoch 846/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 91us/step - loss: 5.4278 - val_loss: 10.6188\n",
      "Epoch 847/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2362 - val_loss: 10.4001\n",
      "Epoch 848/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.1826 - val_loss: 10.2696\n",
      "Epoch 849/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.2283 - val_loss: 10.4458\n",
      "Epoch 850/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1903 - val_loss: 10.4778\n",
      "Epoch 851/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2311 - val_loss: 10.6569\n",
      "Epoch 852/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.3397 - val_loss: 10.6355\n",
      "Epoch 853/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1628 - val_loss: 10.5643\n",
      "Epoch 854/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.1851 - val_loss: 10.4916\n",
      "Epoch 855/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.2608 - val_loss: 10.2146\n",
      "Epoch 856/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1356 - val_loss: 10.5296\n",
      "Epoch 857/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1614 - val_loss: 10.4978\n",
      "Epoch 858/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4366 - val_loss: 10.4612\n",
      "Epoch 859/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8349 - val_loss: 10.8124\n",
      "Epoch 860/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7470 - val_loss: 10.3498\n",
      "Epoch 861/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.7195 - val_loss: 10.4494\n",
      "Epoch 862/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5479 - val_loss: 10.2867\n",
      "Epoch 863/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.2657 - val_loss: 10.7983\n",
      "Epoch 864/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.2036 - val_loss: 10.5398\n",
      "Epoch 865/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.2155 - val_loss: 10.6684\n",
      "Epoch 866/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.1858 - val_loss: 10.6800\n",
      "Epoch 867/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.2054 - val_loss: 10.6628\n",
      "Epoch 868/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2023 - val_loss: 10.6205\n",
      "Epoch 869/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2070 - val_loss: 10.4760\n",
      "Epoch 870/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2711 - val_loss: 10.6860\n",
      "Epoch 871/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3621 - val_loss: 10.4151\n",
      "Epoch 872/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1667 - val_loss: 10.8028\n",
      "Epoch 873/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2266 - val_loss: 10.7196\n",
      "Epoch 874/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.3406 - val_loss: 10.8443\n",
      "Epoch 875/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 5.6328 - val_loss: 10.6001\n",
      "Epoch 876/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2344 - val_loss: 10.3845\n",
      "Epoch 877/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1699 - val_loss: 10.5258\n",
      "Epoch 878/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1377 - val_loss: 10.5266\n",
      "Epoch 879/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3488 - val_loss: 10.5708\n",
      "Epoch 880/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.1929 - val_loss: 10.4804\n",
      "Epoch 881/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.2433 - val_loss: 10.5986\n",
      "Epoch 882/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3795 - val_loss: 10.3776\n",
      "Epoch 883/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 5.3184 - val_loss: 10.6618\n",
      "Epoch 884/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1551 - val_loss: 10.5160\n",
      "Epoch 885/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.1940 - val_loss: 10.5848\n",
      "Epoch 886/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.1841 - val_loss: 10.6046\n",
      "Epoch 887/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2275 - val_loss: 10.5648\n",
      "Epoch 888/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2744 - val_loss: 10.4675\n",
      "Epoch 889/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2453 - val_loss: 10.6749\n",
      "Epoch 890/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1884 - val_loss: 10.5586\n",
      "Epoch 891/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2142 - val_loss: 10.6691\n",
      "Epoch 892/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2404 - val_loss: 10.4976\n",
      "Epoch 893/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2905 - val_loss: 10.2652\n",
      "Epoch 894/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2496 - val_loss: 10.5507\n",
      "Epoch 895/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1613 - val_loss: 10.7158\n",
      "Epoch 896/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1654 - val_loss: 10.7692\n",
      "Epoch 897/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.1144 - val_loss: 10.3782\n",
      "Epoch 898/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1380 - val_loss: 10.6162\n",
      "Epoch 899/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1744 - val_loss: 10.7883\n",
      "Epoch 900/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2704 - val_loss: 10.4551\n",
      "Epoch 901/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1516 - val_loss: 10.4071\n",
      "Epoch 902/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2028 - val_loss: 10.3132\n",
      "Epoch 903/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 4.920 - 0s 106us/step - loss: 5.1647 - val_loss: 10.4949\n",
      "Epoch 904/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1084 - val_loss: 10.6214\n",
      "Epoch 905/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1600 - val_loss: 10.6352\n",
      "Epoch 906/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1895 - val_loss: 10.7169\n",
      "Epoch 907/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2208 - val_loss: 10.5484\n",
      "Epoch 908/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3067 - val_loss: 10.8437\n",
      "Epoch 909/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3626 - val_loss: 10.6556\n",
      "Epoch 910/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2625 - val_loss: 10.6624\n",
      "Epoch 911/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1098 - val_loss: 10.4564\n",
      "Epoch 912/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2337 - val_loss: 10.5468\n",
      "Epoch 913/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.1973 - val_loss: 10.6370\n",
      "Epoch 914/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 5.2270 - val_loss: 10.6780\n",
      "Epoch 915/1000\n",
      "274/274 [==============================] - 0s 83us/step - loss: 5.3256 - val_loss: 10.6307\n",
      "Epoch 916/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1087 - val_loss: 10.7190\n",
      "Epoch 917/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2549 - val_loss: 10.8421\n",
      "Epoch 918/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2451 - val_loss: 10.6916\n",
      "Epoch 919/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0764 - val_loss: 10.8298\n",
      "Epoch 920/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2310 - val_loss: 10.5861\n",
      "Epoch 921/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0479 - val_loss: 10.6625\n",
      "Epoch 922/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1773 - val_loss: 10.6425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 923/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2904 - val_loss: 10.4841\n",
      "Epoch 924/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2261 - val_loss: 10.5726\n",
      "Epoch 925/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.1530 - val_loss: 10.4436\n",
      "Epoch 926/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.1552 - val_loss: 10.6376\n",
      "Epoch 927/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1938 - val_loss: 10.8071\n",
      "Epoch 928/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.2430 - val_loss: 10.6157\n",
      "Epoch 929/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2027 - val_loss: 10.7877\n",
      "Epoch 930/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.1061 - val_loss: 10.5996\n",
      "Epoch 931/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1467 - val_loss: 10.7312\n",
      "Epoch 932/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1172 - val_loss: 10.6709\n",
      "Epoch 933/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.1645 - val_loss: 10.6093\n",
      "Epoch 934/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3003 - val_loss: 10.6316\n",
      "Epoch 935/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1933 - val_loss: 10.6350\n",
      "Epoch 936/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1205 - val_loss: 10.6505\n",
      "Epoch 937/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2005 - val_loss: 10.6155\n",
      "Epoch 938/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2250 - val_loss: 10.6866\n",
      "Epoch 939/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.1990 - val_loss: 10.8760\n",
      "Epoch 940/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.2024 - val_loss: 10.6352\n",
      "Epoch 941/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1622 - val_loss: 10.6278\n",
      "Epoch 942/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2825 - val_loss: 10.6522\n",
      "Epoch 943/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1165 - val_loss: 10.8923\n",
      "Epoch 944/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.1200 - val_loss: 10.7736\n",
      "Epoch 945/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1997 - val_loss: 10.8606\n",
      "Epoch 946/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.1070 - val_loss: 10.7408\n",
      "Epoch 947/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.1105 - val_loss: 10.5116\n",
      "Epoch 948/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1759 - val_loss: 10.7716\n",
      "Epoch 949/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1411 - val_loss: 10.6601\n",
      "Epoch 950/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0586 - val_loss: 10.7375\n",
      "Epoch 951/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 5.0931 - val_loss: 10.5029\n",
      "Epoch 952/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2151 - val_loss: 10.7865\n",
      "Epoch 953/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1650 - val_loss: 10.5897\n",
      "Epoch 954/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1228 - val_loss: 10.5483\n",
      "Epoch 955/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0907 - val_loss: 10.6631\n",
      "Epoch 956/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1302 - val_loss: 10.7082\n",
      "Epoch 957/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 5.1411 - val_loss: 10.6136\n",
      "Epoch 958/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.1799 - val_loss: 10.7103\n",
      "Epoch 959/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1675 - val_loss: 10.7458\n",
      "Epoch 960/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0987 - val_loss: 10.7597\n",
      "Epoch 961/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2666 - val_loss: 10.7040\n",
      "Epoch 962/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.1554 - val_loss: 10.6640\n",
      "Epoch 963/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.1165 - val_loss: 10.8202\n",
      "Epoch 964/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1380 - val_loss: 10.7987\n",
      "Epoch 965/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.6920 - val_loss: 10.7120\n",
      "Epoch 966/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4455 - val_loss: 10.8438\n",
      "Epoch 967/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.1760 - val_loss: 10.7196\n",
      "Epoch 968/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1213 - val_loss: 10.8007\n",
      "Epoch 969/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2012 - val_loss: 10.7244\n",
      "Epoch 970/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.1918 - val_loss: 10.7571\n",
      "Epoch 971/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0891 - val_loss: 10.5990\n",
      "Epoch 972/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.0903 - val_loss: 10.6196\n",
      "Epoch 973/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1121 - val_loss: 10.6676\n",
      "Epoch 974/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1631 - val_loss: 10.9408\n",
      "Epoch 975/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1669 - val_loss: 10.7003\n",
      "Epoch 976/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.3132 - val_loss: 10.5817\n",
      "Epoch 977/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1102 - val_loss: 10.7453\n",
      "Epoch 978/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1766 - val_loss: 10.7112\n",
      "Epoch 979/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.2381 - val_loss: 10.6496\n",
      "Epoch 980/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.1962 - val_loss: 10.6281\n",
      "Epoch 981/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0411 - val_loss: 10.8112\n",
      "Epoch 982/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.0941 - val_loss: 10.7088\n",
      "Epoch 983/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.1104 - val_loss: 10.5828\n",
      "Epoch 984/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.0270 - val_loss: 10.9824\n",
      "Epoch 985/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0885 - val_loss: 10.9175\n",
      "Epoch 986/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.0960 - val_loss: 10.6598\n",
      "Epoch 987/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.2806 - val_loss: 11.1014\n",
      "Epoch 988/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.3157 - val_loss: 10.9662\n",
      "Epoch 989/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.3279 - val_loss: 10.8584\n",
      "Epoch 990/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.2285 - val_loss: 10.5367\n",
      "Epoch 991/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.4958 - val_loss: 10.6203\n",
      "Epoch 992/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3076 - val_loss: 10.5575\n",
      "Epoch 993/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.3663 - val_loss: 10.8448\n",
      "Epoch 994/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1066 - val_loss: 10.8457\n",
      "Epoch 995/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.1286 - val_loss: 10.8801\n",
      "Epoch 996/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0595 - val_loss: 10.6099\n",
      "Epoch 997/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.0700 - val_loss: 10.7430\n",
      "Epoch 998/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1116 - val_loss: 10.8897\n",
      "Epoch 999/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1122 - val_loss: 10.8097\n",
      "Epoch 1000/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0905 - val_loss: 10.8068\n",
      "7.538889270717815\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 1.8621572 , -0.94891536,  1.2792019 ,  2.536485  ,  0.971716  ],\n",
       "        [-1.9282612 ,  0.44026133, -0.4402181 , -1.9349838 ,  0.5772517 ],\n",
       "        [ 0.1986694 ,  0.35925952,  0.39911836,  1.9117271 , -0.8598615 ],\n",
       "        [ 2.4493756 ,  0.36982045,  0.5048437 ,  2.0246198 , -1.7611738 ],\n",
       "        [-1.4726099 ,  0.6136756 ,  0.5517549 ,  0.02647304, -0.01828146],\n",
       "        [-1.0734944 , -0.33369312, -1.0108453 , -1.0291033 ,  1.3529366 ],\n",
       "        [ 0.5445342 , -1.2267237 , -1.2415302 , -0.7626701 ,  0.77862585]],\n",
       "       dtype=float32),\n",
       " array([-1.9989395, -1.5158943,  2.7006118,  2.1345346, -2.4006443],\n",
       "       dtype=float32),\n",
       " array([[-0.26419547, -0.77168554,  0.17058145,  0.1614366 ,  0.7320283 ,\n",
       "         -0.21614407,  0.21548632, -0.5747494 ,  0.69486046, -0.07920573],\n",
       "        [ 0.23817292, -0.4458577 , -0.5880809 ,  0.29146042,  0.80989975,\n",
       "         -0.30275044, -0.14817785, -0.71266186, -0.18011235, -0.08997463],\n",
       "        [-0.57301396,  0.6942921 ,  0.09045097, -0.05394081, -0.71651745,\n",
       "          0.23496541,  0.5995952 ,  0.29125503, -0.26538175,  1.015903  ],\n",
       "        [ 0.8185821 , -0.8278433 , -0.3205675 ,  0.3627096 , -0.15928692,\n",
       "         -0.01486695, -0.23448567, -0.13540988,  0.58078456, -0.7028795 ],\n",
       "        [-0.7860445 ,  0.30770445,  1.3005198 ,  0.4942107 , -0.9817281 ,\n",
       "         -0.46129617,  0.9410063 ,  1.0010492 , -0.4524574 ,  0.4122926 ]],\n",
       "       dtype=float32),\n",
       " array([-1.8684195 ,  1.8661655 ,  2.0490143 ,  0.83844405, -1.8965774 ,\n",
       "        -1.6221308 ,  2.0031898 ,  1.9502227 , -1.9035556 ,  1.8881308 ],\n",
       "       dtype=float32),\n",
       " array([[-1.2086074 ],\n",
       "        [ 1.2435788 ],\n",
       "        [ 1.255064  ],\n",
       "        [ 0.0373211 ],\n",
       "        [-1.5894521 ],\n",
       "        [-0.46205693],\n",
       "        [ 1.140826  ],\n",
       "        [ 1.2680986 ],\n",
       "        [-1.3447902 ],\n",
       "        [ 1.1439042 ]], dtype=float32),\n",
       " array([1.8028966], dtype=float32)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_autompg, history_autompg=NN_model_structure_regression_2(X_train_autompg, X_val_autompg, Y_train_autompg, Y_val_autompg, adam2, 32, 1000)\n",
    "model_autompg.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_autompg.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_autompg_structure2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_25 (Dense)             (None, 5)                 40        \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 15)                90        \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 146\n",
      "Trainable params: 146\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 274 samples, validate on 59 samples\n",
      "Epoch 1/1000\n",
      "274/274 [==============================] - 0s 909us/step - loss: 510.5779 - val_loss: 249.2299\n",
      "Epoch 2/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 132.0687 - val_loss: 57.8320\n",
      "Epoch 3/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 42.2037 - val_loss: 21.3618\n",
      "Epoch 4/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 18.2588 - val_loss: 14.5454\n",
      "Epoch 5/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 12.2903 - val_loss: 12.6890\n",
      "Epoch 6/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 10.5215 - val_loss: 12.9930\n",
      "Epoch 7/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 9.1304 - val_loss: 9.7960\n",
      "Epoch 8/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 8.5753 - val_loss: 9.4298\n",
      "Epoch 9/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.1062 - val_loss: 10.1037\n",
      "Epoch 10/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 8.0857 - val_loss: 9.4994\n",
      "Epoch 11/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 7.8601 - val_loss: 10.6554\n",
      "Epoch 12/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 7.9329 - val_loss: 9.5327\n",
      "Epoch 13/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.9275 - val_loss: 9.0895\n",
      "Epoch 14/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 7.8739 - val_loss: 10.3565\n",
      "Epoch 15/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 7.9549 - val_loss: 9.2899\n",
      "Epoch 16/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 7.4761 - val_loss: 9.4025\n",
      "Epoch 17/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.5941 - val_loss: 10.0820\n",
      "Epoch 18/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.5258 - val_loss: 9.3779\n",
      "Epoch 19/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.8312 - val_loss: 9.3808\n",
      "Epoch 20/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.8809 - val_loss: 9.3242\n",
      "Epoch 21/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.5906 - val_loss: 10.2077\n",
      "Epoch 22/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.6826 - val_loss: 9.7890\n",
      "Epoch 23/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.8701 - val_loss: 9.4948\n",
      "Epoch 24/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.3954 - val_loss: 10.0469\n",
      "Epoch 25/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.4559 - val_loss: 9.3550\n",
      "Epoch 26/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.2751 - val_loss: 9.5533\n",
      "Epoch 27/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.2076 - val_loss: 9.4453\n",
      "Epoch 28/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.4333 - val_loss: 9.9017\n",
      "Epoch 29/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 7.1761 - val_loss: 9.5265\n",
      "Epoch 30/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.5736 - val_loss: 10.0072\n",
      "Epoch 31/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.3815 - val_loss: 9.7748\n",
      "Epoch 32/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1526 - val_loss: 9.4564\n",
      "Epoch 33/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0333 - val_loss: 9.7011\n",
      "Epoch 34/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0628 - val_loss: 9.5655\n",
      "Epoch 35/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1723 - val_loss: 9.7143\n",
      "Epoch 36/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1003 - val_loss: 9.8210\n",
      "Epoch 37/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 7.3118 - val_loss: 9.2781\n",
      "Epoch 38/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.2622 - val_loss: 9.6415\n",
      "Epoch 39/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9525 - val_loss: 9.1837\n",
      "Epoch 40/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.9423 - val_loss: 9.5112\n",
      "Epoch 41/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9461 - val_loss: 9.6117\n",
      "Epoch 42/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.8643 - val_loss: 9.2014\n",
      "Epoch 43/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0562 - val_loss: 9.7689\n",
      "Epoch 44/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.8712 - val_loss: 9.5498\n",
      "Epoch 45/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.8638 - val_loss: 9.6133\n",
      "Epoch 46/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.8916 - val_loss: 9.4643\n",
      "Epoch 47/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0307 - val_loss: 9.8697\n",
      "Epoch 48/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1634 - val_loss: 9.2746\n",
      "Epoch 49/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9810 - val_loss: 10.1300\n",
      "Epoch 50/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.4142 - val_loss: 9.4932\n",
      "Epoch 51/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.9747 - val_loss: 10.0456\n",
      "Epoch 52/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0672 - val_loss: 9.3975\n",
      "Epoch 53/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1178 - val_loss: 10.3300\n",
      "Epoch 54/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.4263 - val_loss: 9.4044\n",
      "Epoch 55/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.2379 - val_loss: 10.0405\n",
      "Epoch 56/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8348 - val_loss: 9.3618\n",
      "Epoch 57/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.8508 - val_loss: 10.0767\n",
      "Epoch 58/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.7153 - val_loss: 9.4942\n",
      "Epoch 59/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6479 - val_loss: 10.1171\n",
      "Epoch 60/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7908 - val_loss: 9.6425\n",
      "Epoch 61/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7364 - val_loss: 9.7164\n",
      "Epoch 62/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.7639 - val_loss: 9.5699\n",
      "Epoch 63/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.6847 - val_loss: 9.7338\n",
      "Epoch 64/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.8925 - val_loss: 9.2003\n",
      "Epoch 65/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.6260 - val_loss: 9.5594\n",
      "Epoch 66/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6462 - val_loss: 9.7343\n",
      "Epoch 67/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.6510 - val_loss: 9.4939\n",
      "Epoch 68/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.6678 - val_loss: 9.6236\n",
      "Epoch 69/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.8138 - val_loss: 9.3244\n",
      "Epoch 70/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8362 - val_loss: 9.7179\n",
      "Epoch 71/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.6653 - val_loss: 9.7030\n",
      "Epoch 72/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5493 - val_loss: 9.4940\n",
      "Epoch 73/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6236 - val_loss: 9.5221\n",
      "Epoch 74/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.7554 - val_loss: 9.7570\n",
      "Epoch 75/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.7804 - val_loss: 9.6588\n",
      "Epoch 76/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7842 - val_loss: 9.8014\n",
      "Epoch 77/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0071 - val_loss: 9.7156\n",
      "Epoch 78/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6821 - val_loss: 9.4742\n",
      "Epoch 79/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5712 - val_loss: 9.4595\n",
      "Epoch 80/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.6089 - val_loss: 9.4868\n",
      "Epoch 81/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7050 - val_loss: 9.8706\n",
      "Epoch 82/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6074 - val_loss: 9.6339\n",
      "Epoch 83/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5447 - val_loss: 9.7345\n",
      "Epoch 84/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.5654 - val_loss: 9.6803\n",
      "Epoch 85/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5672 - val_loss: 9.4861\n",
      "Epoch 86/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.5748 - val_loss: 9.8005\n",
      "Epoch 87/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.5408 - val_loss: 9.6370\n",
      "Epoch 88/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5342 - val_loss: 9.8197\n",
      "Epoch 89/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5353 - val_loss: 9.5241\n",
      "Epoch 90/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5611 - val_loss: 9.6293\n",
      "Epoch 91/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5473 - val_loss: 9.5951\n",
      "Epoch 92/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4909 - val_loss: 9.6313\n",
      "Epoch 93/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5796 - val_loss: 9.4934\n",
      "Epoch 94/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.6631 - val_loss: 9.9395\n",
      "Epoch 95/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.5518 - val_loss: 9.6169\n",
      "Epoch 96/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.5812 - val_loss: 9.7075\n",
      "Epoch 97/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4905 - val_loss: 9.8162\n",
      "Epoch 98/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.4508 - val_loss: 9.8344\n",
      "Epoch 99/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5044 - val_loss: 9.7658\n",
      "Epoch 100/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4660 - val_loss: 9.6979\n",
      "Epoch 101/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.5676 - val_loss: 9.7006\n",
      "Epoch 102/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7186 - val_loss: 9.7900\n",
      "Epoch 103/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.6890 - val_loss: 9.5828\n",
      "Epoch 104/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.6992 - val_loss: 10.1683\n",
      "Epoch 105/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7074 - val_loss: 9.4342\n",
      "Epoch 106/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.4978 - val_loss: 9.5906\n",
      "Epoch 107/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5644 - val_loss: 9.5925\n",
      "Epoch 108/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4152 - val_loss: 9.8270\n",
      "Epoch 109/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4707 - val_loss: 9.5529\n",
      "Epoch 110/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.4905 - val_loss: 9.5140\n",
      "Epoch 111/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.4140 - val_loss: 9.6921\n",
      "Epoch 112/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.6125 - val_loss: 9.6393\n",
      "Epoch 113/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5650 - val_loss: 9.5812\n",
      "Epoch 114/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4499 - val_loss: 9.5348\n",
      "Epoch 115/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4808 - val_loss: 9.6776\n",
      "Epoch 116/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4611 - val_loss: 9.5495\n",
      "Epoch 117/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3800 - val_loss: 9.5960\n",
      "Epoch 118/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.3850 - val_loss: 9.6316\n",
      "Epoch 119/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.6565 - val_loss: 9.3522\n",
      "Epoch 120/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.3315 - val_loss: 9.8053\n",
      "Epoch 121/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2530 - val_loss: 9.4474\n",
      "Epoch 122/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4124 - val_loss: 10.1172\n",
      "Epoch 123/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.5038 - val_loss: 9.6714\n",
      "Epoch 124/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4159 - val_loss: 9.7973\n",
      "Epoch 125/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2146 - val_loss: 9.7650\n",
      "Epoch 126/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3711 - val_loss: 10.0726\n",
      "Epoch 127/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3985 - val_loss: 9.7389\n",
      "Epoch 128/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.2525 - val_loss: 9.8825\n",
      "Epoch 129/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1955 - val_loss: 9.8811\n",
      "Epoch 130/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.2379 - val_loss: 9.7703\n",
      "Epoch 131/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4803 - val_loss: 9.8861\n",
      "Epoch 132/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4343 - val_loss: 9.6558\n",
      "Epoch 133/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2536 - val_loss: 9.5570\n",
      "Epoch 134/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0679 - val_loss: 10.2079\n",
      "Epoch 135/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1191 - val_loss: 10.0155\n",
      "Epoch 136/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5174 - val_loss: 10.4118\n",
      "Epoch 137/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8546 - val_loss: 9.9040\n",
      "Epoch 138/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.8879 - val_loss: 10.4661\n",
      "Epoch 139/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.4423 - val_loss: 9.7373\n",
      "Epoch 140/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3321 - val_loss: 10.0147\n",
      "Epoch 141/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0814 - val_loss: 10.0728\n",
      "Epoch 142/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3791 - val_loss: 9.8005\n",
      "Epoch 143/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4193 - val_loss: 10.0210\n",
      "Epoch 144/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1916 - val_loss: 10.1514\n",
      "Epoch 145/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.0236 - val_loss: 9.9786\n",
      "Epoch 146/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1515 - val_loss: 10.0825\n",
      "Epoch 147/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 95us/step - loss: 6.0602 - val_loss: 9.9545\n",
      "Epoch 148/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4979 - val_loss: 9.8995\n",
      "Epoch 149/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1038 - val_loss: 10.0084\n",
      "Epoch 150/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0750 - val_loss: 9.9937\n",
      "Epoch 151/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.0216 - val_loss: 10.0494\n",
      "Epoch 152/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.0228 - val_loss: 10.0152\n",
      "Epoch 153/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.9480 - val_loss: 9.9850\n",
      "Epoch 154/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.1055 - val_loss: 9.9262\n",
      "Epoch 155/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1366 - val_loss: 9.8096\n",
      "Epoch 156/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1389 - val_loss: 10.2244\n",
      "Epoch 157/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1346 - val_loss: 9.9033\n",
      "Epoch 158/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0011 - val_loss: 10.2395\n",
      "Epoch 159/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3409 - val_loss: 9.9245\n",
      "Epoch 160/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0640 - val_loss: 10.0653\n",
      "Epoch 161/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0345 - val_loss: 9.8505\n",
      "Epoch 162/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.0343 - val_loss: 9.6834\n",
      "Epoch 163/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9756 - val_loss: 10.2032\n",
      "Epoch 164/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9685 - val_loss: 9.7798\n",
      "Epoch 165/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9178 - val_loss: 10.0984\n",
      "Epoch 166/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0179 - val_loss: 9.7973\n",
      "Epoch 167/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.0103 - val_loss: 9.9785\n",
      "Epoch 168/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2016 - val_loss: 9.9023\n",
      "Epoch 169/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8789 - val_loss: 10.0414\n",
      "Epoch 170/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.8764 - val_loss: 9.9231\n",
      "Epoch 171/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.9232 - val_loss: 9.8977\n",
      "Epoch 172/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.0592 - val_loss: 9.9185\n",
      "Epoch 173/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.1726 - val_loss: 9.9869\n",
      "Epoch 174/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.2947 - val_loss: 10.0852\n",
      "Epoch 175/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9777 - val_loss: 10.0206\n",
      "Epoch 176/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9806 - val_loss: 9.8954\n",
      "Epoch 177/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9001 - val_loss: 9.8525\n",
      "Epoch 178/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9429 - val_loss: 9.9360\n",
      "Epoch 179/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.0195 - val_loss: 10.0286\n",
      "Epoch 180/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1150 - val_loss: 9.6945\n",
      "Epoch 181/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.0413 - val_loss: 10.1034\n",
      "Epoch 182/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9563 - val_loss: 10.1255\n",
      "Epoch 183/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9007 - val_loss: 10.1073\n",
      "Epoch 184/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9150 - val_loss: 9.9946\n",
      "Epoch 185/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9168 - val_loss: 9.7277\n",
      "Epoch 186/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.9091 - val_loss: 9.7150\n",
      "Epoch 187/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8478 - val_loss: 9.8858\n",
      "Epoch 188/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.9172 - val_loss: 9.7741\n",
      "Epoch 189/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.9711 - val_loss: 10.0775\n",
      "Epoch 190/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9519 - val_loss: 9.7703\n",
      "Epoch 191/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0163 - val_loss: 10.2565\n",
      "Epoch 192/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.9699 - val_loss: 9.8492\n",
      "Epoch 193/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8920 - val_loss: 9.8222\n",
      "Epoch 194/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7802 - val_loss: 9.9664\n",
      "Epoch 195/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.8636 - val_loss: 9.8226\n",
      "Epoch 196/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.8756 - val_loss: 9.9556\n",
      "Epoch 197/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8704 - val_loss: 9.8343\n",
      "Epoch 198/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.1631 - val_loss: 10.1580\n",
      "Epoch 199/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.0431 - val_loss: 9.8572\n",
      "Epoch 200/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0600 - val_loss: 9.8088\n",
      "Epoch 201/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9000 - val_loss: 10.0138\n",
      "Epoch 202/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8081 - val_loss: 9.6380\n",
      "Epoch 203/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8132 - val_loss: 9.8830\n",
      "Epoch 204/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9161 - val_loss: 9.7883\n",
      "Epoch 205/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.9964 - val_loss: 9.8511\n",
      "Epoch 206/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.8236 - val_loss: 10.0531\n",
      "Epoch 207/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9008 - val_loss: 9.8417\n",
      "Epoch 208/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7788 - val_loss: 10.0763\n",
      "Epoch 209/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.9367 - val_loss: 9.7696\n",
      "Epoch 210/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.9196 - val_loss: 10.3276\n",
      "Epoch 211/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9299 - val_loss: 9.7810\n",
      "Epoch 212/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7308 - val_loss: 9.8907\n",
      "Epoch 213/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8649 - val_loss: 9.9842\n",
      "Epoch 214/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7480 - val_loss: 9.8255\n",
      "Epoch 215/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7705 - val_loss: 10.1321\n",
      "Epoch 216/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.8791 - val_loss: 9.7324\n",
      "Epoch 217/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0194 - val_loss: 10.4340\n",
      "Epoch 218/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9235 - val_loss: 9.9036\n",
      "Epoch 219/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.8193 - val_loss: 10.0481\n",
      "Epoch 220/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0244 - val_loss: 9.6532\n",
      "Epoch 221/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8703 - val_loss: 10.0117\n",
      "Epoch 222/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8133 - val_loss: 9.9375\n",
      "Epoch 223/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7788 - val_loss: 9.8453\n",
      "Epoch 224/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.9089 - val_loss: 10.4011\n",
      "Epoch 225/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8327 - val_loss: 9.6536\n",
      "Epoch 226/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9446 - val_loss: 9.7915\n",
      "Epoch 227/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8188 - val_loss: 9.7694\n",
      "Epoch 228/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1785 - val_loss: 10.2037\n",
      "Epoch 229/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.9506 - val_loss: 9.8297\n",
      "Epoch 230/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9867 - val_loss: 9.8535\n",
      "Epoch 231/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8278 - val_loss: 9.9099\n",
      "Epoch 232/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8087 - val_loss: 10.0006\n",
      "Epoch 233/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9547 - val_loss: 9.8136\n",
      "Epoch 234/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.7915 - val_loss: 9.8998\n",
      "Epoch 235/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8334 - val_loss: 9.6940\n",
      "Epoch 236/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9399 - val_loss: 9.7280\n",
      "Epoch 237/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0289 - val_loss: 10.0227\n",
      "Epoch 238/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0509 - val_loss: 9.8638\n",
      "Epoch 239/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.7986 - val_loss: 10.1252\n",
      "Epoch 240/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7157 - val_loss: 9.7201\n",
      "Epoch 241/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8492 - val_loss: 9.7888\n",
      "Epoch 242/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.0432 - val_loss: 9.7388\n",
      "Epoch 243/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9674 - val_loss: 9.6665\n",
      "Epoch 244/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8419 - val_loss: 9.8748\n",
      "Epoch 245/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8527 - val_loss: 9.5526\n",
      "Epoch 246/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.6292 - val_loss: 9.6813\n",
      "Epoch 247/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7245 - val_loss: 9.6353\n",
      "Epoch 248/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7032 - val_loss: 9.7623\n",
      "Epoch 249/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7346 - val_loss: 9.6840\n",
      "Epoch 250/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8795 - val_loss: 9.7305\n",
      "Epoch 251/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.8211 - val_loss: 9.6126\n",
      "Epoch 252/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7042 - val_loss: 9.6764\n",
      "Epoch 253/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6391 - val_loss: 9.6958\n",
      "Epoch 254/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.7815 - val_loss: 9.5689\n",
      "Epoch 255/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.8933 - val_loss: 9.7002\n",
      "Epoch 256/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.8181 - val_loss: 9.5990\n",
      "Epoch 257/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.7794 - val_loss: 9.6863\n",
      "Epoch 258/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7808 - val_loss: 9.4622\n",
      "Epoch 259/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8901 - val_loss: 9.9036\n",
      "Epoch 260/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8913 - val_loss: 9.5220\n",
      "Epoch 261/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6384 - val_loss: 10.0286\n",
      "Epoch 262/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6607 - val_loss: 9.7971\n",
      "Epoch 263/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7156 - val_loss: 9.7032\n",
      "Epoch 264/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.6294 - val_loss: 9.5282\n",
      "Epoch 265/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.6707 - val_loss: 9.5508\n",
      "Epoch 266/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7944 - val_loss: 9.5255\n",
      "Epoch 267/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6823 - val_loss: 9.5817\n",
      "Epoch 268/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.6025 - val_loss: 9.5222\n",
      "Epoch 269/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6648 - val_loss: 9.4809\n",
      "Epoch 270/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6406 - val_loss: 9.4562\n",
      "Epoch 271/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6809 - val_loss: 9.3950\n",
      "Epoch 272/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.6956 - val_loss: 9.5401\n",
      "Epoch 273/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6746 - val_loss: 9.7472\n",
      "Epoch 274/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.0019 - val_loss: 9.7289\n",
      "Epoch 275/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9841 - val_loss: 9.1576\n",
      "Epoch 276/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6984 - val_loss: 9.4355\n",
      "Epoch 277/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.8639 - val_loss: 9.5797\n",
      "Epoch 278/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0831 - val_loss: 9.7481\n",
      "Epoch 279/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7736 - val_loss: 9.1562\n",
      "Epoch 280/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.6290 - val_loss: 9.2908\n",
      "Epoch 281/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8710 - val_loss: 9.2853\n",
      "Epoch 282/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8447 - val_loss: 9.2066\n",
      "Epoch 283/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7081 - val_loss: 9.3631\n",
      "Epoch 284/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6287 - val_loss: 9.5096\n",
      "Epoch 285/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5327 - val_loss: 9.1733\n",
      "Epoch 286/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6653 - val_loss: 8.9685\n",
      "Epoch 287/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.6098 - val_loss: 9.2269\n",
      "Epoch 288/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9877 - val_loss: 9.7615\n",
      "Epoch 289/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8047 - val_loss: 9.1051\n",
      "Epoch 290/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8132 - val_loss: 9.3377\n",
      "Epoch 291/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7359 - val_loss: 8.9820\n",
      "Epoch 292/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.5515 - val_loss: 9.3338\n",
      "Epoch 293/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.8275 - val_loss: 9.0553\n",
      "Epoch 294/1000\n",
      "274/274 [==============================] - 0s 135us/step - loss: 5.9492 - val_loss: 9.6229\n",
      "Epoch 295/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 5.5868 - val_loss: 8.9407\n",
      "Epoch 296/1000\n",
      "274/274 [==============================] - 0s 118us/step - loss: 5.6432 - val_loss: 9.0536\n",
      "Epoch 297/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.5672 - val_loss: 8.8154\n",
      "Epoch 298/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5462 - val_loss: 8.9863\n",
      "Epoch 299/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 5.6339 - val_loss: 9.1554\n",
      "Epoch 300/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5882 - val_loss: 8.9738\n",
      "Epoch 301/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.5294 - val_loss: 8.8819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 302/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5369 - val_loss: 8.9405\n",
      "Epoch 303/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5177 - val_loss: 9.0040\n",
      "Epoch 304/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5439 - val_loss: 8.9542\n",
      "Epoch 305/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.4599 - val_loss: 9.0097\n",
      "Epoch 306/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.6905 - val_loss: 8.7818\n",
      "Epoch 307/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 5.8953 - val_loss: 9.1509\n",
      "Epoch 308/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.5058 - val_loss: 8.9672\n",
      "Epoch 309/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.4948 - val_loss: 9.1006\n",
      "Epoch 310/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.4853 - val_loss: 9.0322\n",
      "Epoch 311/1000\n",
      "274/274 [==============================] - 0s 146us/step - loss: 5.4793 - val_loss: 8.8103\n",
      "Epoch 312/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6249 - val_loss: 8.8347\n",
      "Epoch 313/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4714 - val_loss: 8.7145\n",
      "Epoch 314/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.5618 - val_loss: 8.6568\n",
      "Epoch 315/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.6926 - val_loss: 9.1087\n",
      "Epoch 316/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5249 - val_loss: 8.7157\n",
      "Epoch 317/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4458 - val_loss: 8.8292\n",
      "Epoch 318/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.5427 - val_loss: 8.8409\n",
      "Epoch 319/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6463 - val_loss: 8.6754\n",
      "Epoch 320/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5291 - val_loss: 8.6608\n",
      "Epoch 321/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4172 - val_loss: 9.1447\n",
      "Epoch 322/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.6494 - val_loss: 8.7100\n",
      "Epoch 323/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5601 - val_loss: 9.1760\n",
      "Epoch 324/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.5307 - val_loss: 8.7251\n",
      "Epoch 325/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5242 - val_loss: 8.6998\n",
      "Epoch 326/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4551 - val_loss: 8.6791\n",
      "Epoch 327/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.5751 - val_loss: 8.7585\n",
      "Epoch 328/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4703 - val_loss: 8.5684\n",
      "Epoch 329/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4342 - val_loss: 8.6257\n",
      "Epoch 330/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4527 - val_loss: 8.8349\n",
      "Epoch 331/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.4767 - val_loss: 8.7417\n",
      "Epoch 332/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5745 - val_loss: 8.7048\n",
      "Epoch 333/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4602 - val_loss: 8.6894\n",
      "Epoch 334/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4649 - val_loss: 8.6703\n",
      "Epoch 335/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7557 - val_loss: 9.0269\n",
      "Epoch 336/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5375 - val_loss: 8.7026\n",
      "Epoch 337/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5936 - val_loss: 9.5402\n",
      "Epoch 338/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4938 - val_loss: 8.6119\n",
      "Epoch 339/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6228 - val_loss: 8.8778\n",
      "Epoch 340/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4476 - val_loss: 8.6242\n",
      "Epoch 341/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.3934 - val_loss: 8.7511\n",
      "Epoch 342/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4147 - val_loss: 8.5355\n",
      "Epoch 343/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4461 - val_loss: 8.8067\n",
      "Epoch 344/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4878 - val_loss: 8.8030\n",
      "Epoch 345/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5375 - val_loss: 8.8102\n",
      "Epoch 346/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3916 - val_loss: 8.6893\n",
      "Epoch 347/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5732 - val_loss: 8.4881\n",
      "Epoch 348/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.4634 - val_loss: 9.6271\n",
      "Epoch 349/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.6485 - val_loss: 8.6823\n",
      "Epoch 350/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6300 - val_loss: 9.3068\n",
      "Epoch 351/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5198 - val_loss: 8.5794\n",
      "Epoch 352/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4217 - val_loss: 9.1739\n",
      "Epoch 353/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6630 - val_loss: 8.4164\n",
      "Epoch 354/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.5653 - val_loss: 9.0664\n",
      "Epoch 355/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.4474 - val_loss: 8.6360\n",
      "Epoch 356/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4224 - val_loss: 9.1163\n",
      "Epoch 357/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4701 - val_loss: 8.5346\n",
      "Epoch 358/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4487 - val_loss: 8.9922\n",
      "Epoch 359/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5389 - val_loss: 8.5902\n",
      "Epoch 360/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5641 - val_loss: 8.8414\n",
      "Epoch 361/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.6220 - val_loss: 8.6796\n",
      "Epoch 362/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.5805 - val_loss: 8.6737\n",
      "Epoch 363/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4578 - val_loss: 8.7727\n",
      "Epoch 364/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5085 - val_loss: 8.6629\n",
      "Epoch 365/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4226 - val_loss: 8.6938\n",
      "Epoch 366/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3414 - val_loss: 8.5318\n",
      "Epoch 367/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4594 - val_loss: 8.4472\n",
      "Epoch 368/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3813 - val_loss: 8.7629\n",
      "Epoch 369/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3785 - val_loss: 8.9178\n",
      "Epoch 370/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 5.3688 - val_loss: 8.6984\n",
      "Epoch 371/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.3513 - val_loss: 8.6618\n",
      "Epoch 372/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5043 - val_loss: 8.8918\n",
      "Epoch 373/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3936 - val_loss: 8.4574\n",
      "Epoch 374/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.4205 - val_loss: 8.9620\n",
      "Epoch 375/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4711 - val_loss: 8.6456\n",
      "Epoch 376/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4496 - val_loss: 9.1422\n",
      "Epoch 377/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.4110 - val_loss: 8.6419\n",
      "Epoch 378/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.4661 - val_loss: 8.8038\n",
      "Epoch 379/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5146 - val_loss: 8.5205\n",
      "Epoch 380/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.3860 - val_loss: 8.7792\n",
      "Epoch 381/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.4884 - val_loss: 8.8614\n",
      "Epoch 382/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3680 - val_loss: 8.7472\n",
      "Epoch 383/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.3699 - val_loss: 8.6898\n",
      "Epoch 384/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3600 - val_loss: 8.7111\n",
      "Epoch 385/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5949 - val_loss: 8.4811\n",
      "Epoch 386/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4563 - val_loss: 8.7926\n",
      "Epoch 387/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4569 - val_loss: 8.7658\n",
      "Epoch 388/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6208 - val_loss: 8.6345\n",
      "Epoch 389/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6474 - val_loss: 9.3318\n",
      "Epoch 390/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8912 - val_loss: 8.6235\n",
      "Epoch 391/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5170 - val_loss: 9.2298\n",
      "Epoch 392/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5208 - val_loss: 8.6838\n",
      "Epoch 393/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4047 - val_loss: 9.0973\n",
      "Epoch 394/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4460 - val_loss: 8.6605\n",
      "Epoch 395/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4117 - val_loss: 8.6719\n",
      "Epoch 396/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.4124 - val_loss: 8.9267\n",
      "Epoch 397/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4949 - val_loss: 8.4668\n",
      "Epoch 398/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.5795 - val_loss: 8.6671\n",
      "Epoch 399/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5743 - val_loss: 9.2023\n",
      "Epoch 400/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7613 - val_loss: 8.6494\n",
      "Epoch 401/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4620 - val_loss: 9.0826\n",
      "Epoch 402/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.3923 - val_loss: 8.7203\n",
      "Epoch 403/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4437 - val_loss: 8.4755\n",
      "Epoch 404/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4414 - val_loss: 8.6344\n",
      "Epoch 405/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6822 - val_loss: 9.5016\n",
      "Epoch 406/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6045 - val_loss: 8.6424\n",
      "Epoch 407/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6493 - val_loss: 8.3954\n",
      "Epoch 408/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7770 - val_loss: 9.1457\n",
      "Epoch 409/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4728 - val_loss: 8.6073\n",
      "Epoch 410/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6415 - val_loss: 8.9426\n",
      "Epoch 411/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.3052 - val_loss: 8.7097\n",
      "Epoch 412/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3275 - val_loss: 8.6955\n",
      "Epoch 413/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3341 - val_loss: 8.7214\n",
      "Epoch 414/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3469 - val_loss: 9.2246\n",
      "Epoch 415/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.4380 - val_loss: 8.5709\n",
      "Epoch 416/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3535 - val_loss: 9.1782\n",
      "Epoch 417/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3605 - val_loss: 8.7067\n",
      "Epoch 418/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5298 - val_loss: 8.6553\n",
      "Epoch 419/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3532 - val_loss: 8.8880\n",
      "Epoch 420/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5370 - val_loss: 8.6876\n",
      "Epoch 421/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 5.4107 - val_loss: 9.1172\n",
      "Epoch 422/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3842 - val_loss: 8.8105\n",
      "Epoch 423/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.3674 - val_loss: 8.7419\n",
      "Epoch 424/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.3276 - val_loss: 8.9460\n",
      "Epoch 425/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3637 - val_loss: 8.9232\n",
      "Epoch 426/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3813 - val_loss: 8.8144\n",
      "Epoch 427/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4264 - val_loss: 8.8898\n",
      "Epoch 428/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4775 - val_loss: 8.6575\n",
      "Epoch 429/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.9641 - val_loss: 9.3912\n",
      "Epoch 430/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8296 - val_loss: 8.6482\n",
      "Epoch 431/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6783 - val_loss: 9.5879\n",
      "Epoch 432/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4851 - val_loss: 8.6003\n",
      "Epoch 433/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3189 - val_loss: 9.0716\n",
      "Epoch 434/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.5593 - val_loss: 8.8898\n",
      "Epoch 435/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3478 - val_loss: 9.0833\n",
      "Epoch 436/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3263 - val_loss: 8.9207\n",
      "Epoch 437/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3361 - val_loss: 8.7298\n",
      "Epoch 438/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.6044 - val_loss: 9.2352\n",
      "Epoch 439/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5203 - val_loss: 8.8277\n",
      "Epoch 440/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7572 - val_loss: 10.2123\n",
      "Epoch 441/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7891 - val_loss: 8.5691\n",
      "Epoch 442/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7185 - val_loss: 8.8025\n",
      "Epoch 443/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3424 - val_loss: 8.9745\n",
      "Epoch 444/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4702 - val_loss: 8.7553\n",
      "Epoch 445/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3321 - val_loss: 9.0886\n",
      "Epoch 446/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6107 - val_loss: 8.8098\n",
      "Epoch 447/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.5576 - val_loss: 8.8462\n",
      "Epoch 448/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3918 - val_loss: 8.8447\n",
      "Epoch 449/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 5.3962 - val_loss: 8.8832\n",
      "Epoch 450/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3583 - val_loss: 9.0382\n",
      "Epoch 451/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4216 - val_loss: 8.7897\n",
      "Epoch 452/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3820 - val_loss: 8.9514\n",
      "Epoch 453/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3559 - val_loss: 8.8817\n",
      "Epoch 454/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3983 - val_loss: 8.6937\n",
      "Epoch 455/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4236 - val_loss: 8.5739\n",
      "Epoch 456/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5085 - val_loss: 9.1825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 457/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2745 - val_loss: 8.5973\n",
      "Epoch 458/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2855 - val_loss: 8.9812\n",
      "Epoch 459/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3487 - val_loss: 8.9717\n",
      "Epoch 460/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2779 - val_loss: 8.7128\n",
      "Epoch 461/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3719 - val_loss: 8.9644\n",
      "Epoch 462/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3723 - val_loss: 8.6785\n",
      "Epoch 463/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2961 - val_loss: 8.7527\n",
      "Epoch 464/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2391 - val_loss: 8.7150\n",
      "Epoch 465/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4546 - val_loss: 9.0428\n",
      "Epoch 466/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3182 - val_loss: 9.2246\n",
      "Epoch 467/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.4508 - val_loss: 9.3055\n",
      "Epoch 468/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3637 - val_loss: 8.6686\n",
      "Epoch 469/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3298 - val_loss: 9.0341\n",
      "Epoch 470/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4377 - val_loss: 8.9411\n",
      "Epoch 471/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3963 - val_loss: 9.2899\n",
      "Epoch 472/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4798 - val_loss: 9.1275\n",
      "Epoch 473/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4680 - val_loss: 8.6518\n",
      "Epoch 474/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4469 - val_loss: 9.0840\n",
      "Epoch 475/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5025 - val_loss: 8.9254\n",
      "Epoch 476/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4045 - val_loss: 9.0414\n",
      "Epoch 477/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.3832 - val_loss: 8.7974\n",
      "Epoch 478/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3192 - val_loss: 8.7062\n",
      "Epoch 479/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5511 - val_loss: 8.9832\n",
      "Epoch 480/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6006 - val_loss: 9.7621\n",
      "Epoch 481/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0600 - val_loss: 8.9575\n",
      "Epoch 482/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.2374 - val_loss: 10.4781\n",
      "Epoch 483/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6366 - val_loss: 8.7181\n",
      "Epoch 484/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3587 - val_loss: 8.8659\n",
      "Epoch 485/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2879 - val_loss: 9.0722\n",
      "Epoch 486/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.3203 - val_loss: 8.9757\n",
      "Epoch 487/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.5133 - val_loss: 9.4598\n",
      "Epoch 488/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.6008 - val_loss: 8.6579\n",
      "Epoch 489/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4932 - val_loss: 9.3771\n",
      "Epoch 490/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4082 - val_loss: 8.7145\n",
      "Epoch 491/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.3257 - val_loss: 9.1703\n",
      "Epoch 492/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.2232 - val_loss: 8.7256\n",
      "Epoch 493/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.4901 - val_loss: 8.7185\n",
      "Epoch 494/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4267 - val_loss: 8.9587\n",
      "Epoch 495/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2210 - val_loss: 8.9574\n",
      "Epoch 496/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2666 - val_loss: 9.2235\n",
      "Epoch 497/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3193 - val_loss: 8.8582\n",
      "Epoch 498/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.3246 - val_loss: 8.9151\n",
      "Epoch 499/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2462 - val_loss: 8.8842\n",
      "Epoch 500/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.2926 - val_loss: 9.1412\n",
      "Epoch 501/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2705 - val_loss: 8.5974\n",
      "Epoch 502/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3592 - val_loss: 8.9818\n",
      "Epoch 503/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.2904 - val_loss: 9.0637\n",
      "Epoch 504/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4356 - val_loss: 9.0898\n",
      "Epoch 505/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5901 - val_loss: 8.7326\n",
      "Epoch 506/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3799 - val_loss: 9.2060\n",
      "Epoch 507/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4070 - val_loss: 8.6352\n",
      "Epoch 508/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4708 - val_loss: 8.9744\n",
      "Epoch 509/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3591 - val_loss: 8.7439\n",
      "Epoch 510/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4046 - val_loss: 9.0167\n",
      "Epoch 511/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4397 - val_loss: 9.1571\n",
      "Epoch 512/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.2756 - val_loss: 8.8222\n",
      "Epoch 513/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3441 - val_loss: 9.4923\n",
      "Epoch 514/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3059 - val_loss: 8.5911\n",
      "Epoch 515/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3664 - val_loss: 8.7480\n",
      "Epoch 516/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2113 - val_loss: 8.9066\n",
      "Epoch 517/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3761 - val_loss: 9.2412\n",
      "Epoch 518/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4731 - val_loss: 8.7273\n",
      "Epoch 519/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 4.449 - 0s 95us/step - loss: 5.2426 - val_loss: 8.9392\n",
      "Epoch 520/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2706 - val_loss: 9.0072\n",
      "Epoch 521/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.3771 - val_loss: 9.0486\n",
      "Epoch 522/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5432 - val_loss: 8.7811\n",
      "Epoch 523/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2507 - val_loss: 9.0971\n",
      "Epoch 524/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4806 - val_loss: 8.5446\n",
      "Epoch 525/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8616 - val_loss: 9.6054\n",
      "Epoch 526/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.4404 - val_loss: 8.6914\n",
      "Epoch 527/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7457 - val_loss: 9.5520\n",
      "Epoch 528/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.4467 - val_loss: 9.0065\n",
      "Epoch 529/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 7.054 - 0s 97us/step - loss: 5.2816 - val_loss: 8.9106\n",
      "Epoch 530/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3779 - val_loss: 9.0881\n",
      "Epoch 531/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5413 - val_loss: 8.8324\n",
      "Epoch 532/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4379 - val_loss: 9.2679\n",
      "Epoch 533/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3367 - val_loss: 8.7668\n",
      "Epoch 534/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2440 - val_loss: 9.0415\n",
      "Epoch 535/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.4094 - val_loss: 8.6740\n",
      "Epoch 536/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3261 - val_loss: 9.4210\n",
      "Epoch 537/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.4134 - val_loss: 8.7329\n",
      "Epoch 538/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.2791 - val_loss: 9.2915\n",
      "Epoch 539/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4235 - val_loss: 8.9559\n",
      "Epoch 540/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3413 - val_loss: 9.1252\n",
      "Epoch 541/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4115 - val_loss: 9.1925\n",
      "Epoch 542/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3876 - val_loss: 8.8860\n",
      "Epoch 543/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2334 - val_loss: 8.9398\n",
      "Epoch 544/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.3211 - val_loss: 8.8042\n",
      "Epoch 545/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3515 - val_loss: 9.0631\n",
      "Epoch 546/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4443 - val_loss: 8.7725\n",
      "Epoch 547/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3601 - val_loss: 9.1786\n",
      "Epoch 548/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2770 - val_loss: 8.9608\n",
      "Epoch 549/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.2903 - val_loss: 8.9871\n",
      "Epoch 550/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.2932 - val_loss: 9.1036\n",
      "Epoch 551/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3213 - val_loss: 9.0800\n",
      "Epoch 552/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2337 - val_loss: 8.9470\n",
      "Epoch 553/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2985 - val_loss: 8.8640\n",
      "Epoch 554/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.2384 - val_loss: 9.0473\n",
      "Epoch 555/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2765 - val_loss: 9.1041\n",
      "Epoch 556/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3043 - val_loss: 8.7739\n",
      "Epoch 557/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5120 - val_loss: 9.9297\n",
      "Epoch 558/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5803 - val_loss: 8.8186\n",
      "Epoch 559/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 5.2677 - val_loss: 9.5368\n",
      "Epoch 560/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2086 - val_loss: 8.8932\n",
      "Epoch 561/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2876 - val_loss: 8.8595\n",
      "Epoch 562/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2185 - val_loss: 8.8169\n",
      "Epoch 563/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.2697 - val_loss: 9.4612\n",
      "Epoch 564/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2921 - val_loss: 8.9050\n",
      "Epoch 565/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5727 - val_loss: 9.6371\n",
      "Epoch 566/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.3868 - val_loss: 9.0730\n",
      "Epoch 567/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.3522 - val_loss: 9.1610\n",
      "Epoch 568/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3565 - val_loss: 9.2500\n",
      "Epoch 569/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.3485 - val_loss: 9.3655\n",
      "Epoch 570/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3125 - val_loss: 8.9800\n",
      "Epoch 571/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3268 - val_loss: 8.9245\n",
      "Epoch 572/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2708 - val_loss: 9.0812\n",
      "Epoch 573/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2807 - val_loss: 8.8701\n",
      "Epoch 574/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.3807 - val_loss: 9.8037\n",
      "Epoch 575/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.8704 - val_loss: 8.9004\n",
      "Epoch 576/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8865 - val_loss: 10.2579\n",
      "Epoch 577/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0522 - val_loss: 8.7610\n",
      "Epoch 578/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4219 - val_loss: 9.4861\n",
      "Epoch 579/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3124 - val_loss: 9.1162\n",
      "Epoch 580/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2499 - val_loss: 9.2764\n",
      "Epoch 581/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2087 - val_loss: 8.9691\n",
      "Epoch 582/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3274 - val_loss: 8.6533\n",
      "Epoch 583/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2499 - val_loss: 9.3042\n",
      "Epoch 584/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.2274 - val_loss: 8.8950\n",
      "Epoch 585/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.3249 - val_loss: 9.1155\n",
      "Epoch 586/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2319 - val_loss: 9.2398\n",
      "Epoch 587/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2132 - val_loss: 8.9517\n",
      "Epoch 588/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.1872 - val_loss: 9.1399\n",
      "Epoch 589/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4000 - val_loss: 9.0366\n",
      "Epoch 590/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4159 - val_loss: 8.7752\n",
      "Epoch 591/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.2066 - val_loss: 9.1762\n",
      "Epoch 592/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.3697 - val_loss: 8.8982\n",
      "Epoch 593/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3808 - val_loss: 9.1036\n",
      "Epoch 594/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.3112 - val_loss: 8.9456\n",
      "Epoch 595/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.4389 - val_loss: 9.2889\n",
      "Epoch 596/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.5495 - val_loss: 8.9206\n",
      "Epoch 597/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4156 - val_loss: 9.1886\n",
      "Epoch 598/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.3071 - val_loss: 9.0791\n",
      "Epoch 599/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2484 - val_loss: 9.1419\n",
      "Epoch 600/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.3366 - val_loss: 9.1419\n",
      "Epoch 601/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.3438 - val_loss: 9.0547\n",
      "Epoch 602/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.2983 - val_loss: 8.8516\n",
      "Epoch 603/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.2735 - val_loss: 8.9667\n",
      "Epoch 604/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2556 - val_loss: 8.9191\n",
      "Epoch 605/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2034 - val_loss: 9.0456\n",
      "Epoch 606/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.2028 - val_loss: 8.8934\n",
      "Epoch 607/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.2681 - val_loss: 9.4797\n",
      "Epoch 608/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2320 - val_loss: 8.8386\n",
      "Epoch 609/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4414 - val_loss: 9.5306\n",
      "Epoch 610/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5558 - val_loss: 8.7588\n",
      "Epoch 611/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3972 - val_loss: 9.7191\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 612/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4039 - val_loss: 8.7485\n",
      "Epoch 613/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.2465 - val_loss: 9.5812\n",
      "Epoch 614/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2483 - val_loss: 8.8515\n",
      "Epoch 615/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4136 - val_loss: 9.7163\n",
      "Epoch 616/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.2703 - val_loss: 8.7667\n",
      "Epoch 617/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3288 - val_loss: 9.4186\n",
      "Epoch 618/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6583 - val_loss: 9.0337\n",
      "Epoch 619/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8182 - val_loss: 10.6559\n",
      "Epoch 620/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6812 - val_loss: 8.9649\n",
      "Epoch 621/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6687 - val_loss: 9.7895\n",
      "Epoch 622/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6361 - val_loss: 8.8733\n",
      "Epoch 623/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3598 - val_loss: 9.6540\n",
      "Epoch 624/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.2393 - val_loss: 8.8865\n",
      "Epoch 625/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.5265 - val_loss: 9.7041\n",
      "Epoch 626/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.3490 - val_loss: 8.8804\n",
      "Epoch 627/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1533 - val_loss: 9.4479\n",
      "Epoch 628/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3147 - val_loss: 9.0169\n",
      "Epoch 629/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.3271 - val_loss: 9.4756\n",
      "Epoch 630/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1845 - val_loss: 8.8047\n",
      "Epoch 631/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.5238 - val_loss: 9.3027\n",
      "Epoch 632/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.4339 - val_loss: 8.9112\n",
      "Epoch 633/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5905 - val_loss: 9.0058\n",
      "Epoch 634/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4178 - val_loss: 9.3756\n",
      "Epoch 635/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2995 - val_loss: 9.0954\n",
      "Epoch 636/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2723 - val_loss: 8.8782\n",
      "Epoch 637/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4310 - val_loss: 9.0636\n",
      "Epoch 638/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4329 - val_loss: 8.6989\n",
      "Epoch 639/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3068 - val_loss: 9.4980\n",
      "Epoch 640/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.2824 - val_loss: 8.9365\n",
      "Epoch 641/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2882 - val_loss: 9.5729\n",
      "Epoch 642/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.2747 - val_loss: 9.0147\n",
      "Epoch 643/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.2701 - val_loss: 9.3758\n",
      "Epoch 644/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3400 - val_loss: 8.8075\n",
      "Epoch 645/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2480 - val_loss: 9.2316\n",
      "Epoch 646/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2131 - val_loss: 9.1598\n",
      "Epoch 647/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2644 - val_loss: 9.2632\n",
      "Epoch 648/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2296 - val_loss: 8.8680\n",
      "Epoch 649/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.2624 - val_loss: 9.2721\n",
      "Epoch 650/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.2507 - val_loss: 8.9666\n",
      "Epoch 651/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.3484 - val_loss: 8.9984\n",
      "Epoch 652/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2837 - val_loss: 9.1159\n",
      "Epoch 653/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3261 - val_loss: 8.9788\n",
      "Epoch 654/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2494 - val_loss: 9.4188\n",
      "Epoch 655/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4124 - val_loss: 9.0797\n",
      "Epoch 656/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.4196 - val_loss: 8.8432\n",
      "Epoch 657/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.3224 - val_loss: 9.2838\n",
      "Epoch 658/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.1923 - val_loss: 9.1101\n",
      "Epoch 659/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.3159 - val_loss: 8.9414\n",
      "Epoch 660/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4233 - val_loss: 8.9894\n",
      "Epoch 661/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.2317 - val_loss: 9.0649\n",
      "Epoch 662/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2214 - val_loss: 9.0196\n",
      "Epoch 663/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1535 - val_loss: 8.8009\n",
      "Epoch 664/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2799 - val_loss: 9.4084\n",
      "Epoch 665/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3102 - val_loss: 8.7832\n",
      "Epoch 666/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3109 - val_loss: 8.8909\n",
      "Epoch 667/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.2328 - val_loss: 9.1220\n",
      "Epoch 668/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.1930 - val_loss: 9.0109\n",
      "Epoch 669/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2271 - val_loss: 9.4383\n",
      "Epoch 670/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3070 - val_loss: 8.9516\n",
      "Epoch 671/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.2452 - val_loss: 9.1922\n",
      "Epoch 672/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1781 - val_loss: 8.9704\n",
      "Epoch 673/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1792 - val_loss: 9.0540\n",
      "Epoch 674/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.2804 - val_loss: 9.2105\n",
      "Epoch 675/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.2518 - val_loss: 8.7586\n",
      "Epoch 676/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.3307 - val_loss: 9.0922\n",
      "Epoch 677/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2611 - val_loss: 9.1145\n",
      "Epoch 678/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1739 - val_loss: 9.0674\n",
      "Epoch 679/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2453 - val_loss: 9.1617\n",
      "Epoch 680/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.1701 - val_loss: 8.8489\n",
      "Epoch 681/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2142 - val_loss: 9.2685\n",
      "Epoch 682/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1895 - val_loss: 8.9709\n",
      "Epoch 683/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2292 - val_loss: 8.9236\n",
      "Epoch 684/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2280 - val_loss: 9.2984\n",
      "Epoch 685/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4868 - val_loss: 9.2406\n",
      "Epoch 686/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6421 - val_loss: 8.9484\n",
      "Epoch 687/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6289 - val_loss: 9.3162\n",
      "Epoch 688/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.5054 - val_loss: 8.8378\n",
      "Epoch 689/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2223 - val_loss: 8.9215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 690/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2417 - val_loss: 9.0401\n",
      "Epoch 691/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1948 - val_loss: 9.1176\n",
      "Epoch 692/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2333 - val_loss: 9.2576\n",
      "Epoch 693/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2113 - val_loss: 9.1851\n",
      "Epoch 694/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2634 - val_loss: 9.0004\n",
      "Epoch 695/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3077 - val_loss: 9.0478\n",
      "Epoch 696/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3297 - val_loss: 9.2954\n",
      "Epoch 697/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2837 - val_loss: 9.1188\n",
      "Epoch 698/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2729 - val_loss: 9.0219\n",
      "Epoch 699/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1473 - val_loss: 8.9838\n",
      "Epoch 700/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2787 - val_loss: 8.9804\n",
      "Epoch 701/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2523 - val_loss: 9.1836\n",
      "Epoch 702/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3731 - val_loss: 8.9737\n",
      "Epoch 703/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.3386 - val_loss: 9.4829\n",
      "Epoch 704/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 5.2841 - val_loss: 9.1058\n",
      "Epoch 705/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2826 - val_loss: 9.5044\n",
      "Epoch 706/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.4887 - val_loss: 8.9162\n",
      "Epoch 707/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4087 - val_loss: 9.1142\n",
      "Epoch 708/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.3536 - val_loss: 9.0483\n",
      "Epoch 709/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3870 - val_loss: 9.0398\n",
      "Epoch 710/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4286 - val_loss: 9.3623\n",
      "Epoch 711/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2907 - val_loss: 9.2168\n",
      "Epoch 712/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.4255 - val_loss: 9.2029\n",
      "Epoch 713/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4386 - val_loss: 9.2738\n",
      "Epoch 714/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2707 - val_loss: 8.8447\n",
      "Epoch 715/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2827 - val_loss: 9.6100\n",
      "Epoch 716/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4591 - val_loss: 9.0657\n",
      "Epoch 717/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3844 - val_loss: 9.2236\n",
      "Epoch 718/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3276 - val_loss: 9.6834\n",
      "Epoch 719/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.6039 - val_loss: 8.8092\n",
      "Epoch 720/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.4992 - val_loss: 9.4674\n",
      "Epoch 721/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2959 - val_loss: 8.9725\n",
      "Epoch 722/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2488 - val_loss: 9.3138\n",
      "Epoch 723/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2156 - val_loss: 9.1059\n",
      "Epoch 724/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2435 - val_loss: 9.1265\n",
      "Epoch 725/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2523 - val_loss: 9.1040\n",
      "Epoch 726/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1847 - val_loss: 9.2323\n",
      "Epoch 727/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3018 - val_loss: 8.9092\n",
      "Epoch 728/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2225 - val_loss: 9.2193\n",
      "Epoch 729/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2098 - val_loss: 9.0077\n",
      "Epoch 730/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.2394 - val_loss: 8.9299\n",
      "Epoch 731/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2764 - val_loss: 9.5043\n",
      "Epoch 732/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3053 - val_loss: 9.1737\n",
      "Epoch 733/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2822 - val_loss: 8.9319\n",
      "Epoch 734/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2188 - val_loss: 9.4421\n",
      "Epoch 735/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3011 - val_loss: 9.1923\n",
      "Epoch 736/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2522 - val_loss: 9.2822\n",
      "Epoch 737/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4401 - val_loss: 8.8954\n",
      "Epoch 738/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6692 - val_loss: 9.6646\n",
      "Epoch 739/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4541 - val_loss: 8.9207\n",
      "Epoch 740/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3765 - val_loss: 9.3657\n",
      "Epoch 741/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.2995 - val_loss: 8.9295\n",
      "Epoch 742/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.3391 - val_loss: 9.2546\n",
      "Epoch 743/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2380 - val_loss: 8.9095\n",
      "Epoch 744/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2854 - val_loss: 9.1475\n",
      "Epoch 745/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2874 - val_loss: 9.1320\n",
      "Epoch 746/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2511 - val_loss: 8.9961\n",
      "Epoch 747/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2928 - val_loss: 9.2539\n",
      "Epoch 748/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2117 - val_loss: 9.1637\n",
      "Epoch 749/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.2867 - val_loss: 9.0506\n",
      "Epoch 750/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.2408 - val_loss: 9.0216\n",
      "Epoch 751/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5749 - val_loss: 9.4084\n",
      "Epoch 752/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4945 - val_loss: 9.0184\n",
      "Epoch 753/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4014 - val_loss: 9.5493\n",
      "Epoch 754/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.2294 - val_loss: 9.5737\n",
      "Epoch 755/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2405 - val_loss: 9.1770\n",
      "Epoch 756/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.4020 - val_loss: 9.0867\n",
      "Epoch 757/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1933 - val_loss: 9.1403\n",
      "Epoch 758/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1889 - val_loss: 9.1896\n",
      "Epoch 759/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2510 - val_loss: 8.9927\n",
      "Epoch 760/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2813 - val_loss: 9.0590\n",
      "Epoch 761/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3694 - val_loss: 9.1212\n",
      "Epoch 762/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4622 - val_loss: 9.7128\n",
      "Epoch 763/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4007 - val_loss: 9.1037\n",
      "Epoch 764/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6241 - val_loss: 9.8045\n",
      "Epoch 765/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.3338 - val_loss: 9.2185\n",
      "Epoch 766/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.1790 - val_loss: 9.2197\n",
      "Epoch 767/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2487 - val_loss: 9.1833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 768/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.8386 - val_loss: 8.8106\n",
      "Epoch 769/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4919 - val_loss: 9.6655\n",
      "Epoch 770/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2291 - val_loss: 9.0810\n",
      "Epoch 771/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1748 - val_loss: 9.4199\n",
      "Epoch 772/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.2102 - val_loss: 9.1575\n",
      "Epoch 773/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2575 - val_loss: 9.0017\n",
      "Epoch 774/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2741 - val_loss: 9.0950\n",
      "Epoch 775/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2275 - val_loss: 9.2051\n",
      "Epoch 776/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2298 - val_loss: 9.1894\n",
      "Epoch 777/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1524 - val_loss: 8.9838\n",
      "Epoch 778/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3250 - val_loss: 9.4986\n",
      "Epoch 779/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2932 - val_loss: 8.8735\n",
      "Epoch 780/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3059 - val_loss: 9.2621\n",
      "Epoch 781/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3356 - val_loss: 9.1871\n",
      "Epoch 782/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2143 - val_loss: 9.5786\n",
      "Epoch 783/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1670 - val_loss: 9.1263\n",
      "Epoch 784/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.2193 - val_loss: 9.3994\n",
      "Epoch 785/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.2677 - val_loss: 9.1423\n",
      "Epoch 786/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1460 - val_loss: 9.3035\n",
      "Epoch 787/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1755 - val_loss: 9.0583\n",
      "Epoch 788/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 4.794 - 0s 95us/step - loss: 5.2010 - val_loss: 9.4942\n",
      "Epoch 789/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2851 - val_loss: 9.0671\n",
      "Epoch 790/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5185 - val_loss: 9.8178\n",
      "Epoch 791/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3127 - val_loss: 8.8335\n",
      "Epoch 792/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.3140 - val_loss: 9.0766\n",
      "Epoch 793/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1667 - val_loss: 9.0941\n",
      "Epoch 794/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2060 - val_loss: 9.5354\n",
      "Epoch 795/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1866 - val_loss: 9.0290\n",
      "Epoch 796/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4732 - val_loss: 9.0141\n",
      "Epoch 797/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5442 - val_loss: 9.4062\n",
      "Epoch 798/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3931 - val_loss: 8.8752\n",
      "Epoch 799/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2248 - val_loss: 9.0423\n",
      "Epoch 800/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.1429 - val_loss: 9.1256\n",
      "Epoch 801/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3295 - val_loss: 9.0769\n",
      "Epoch 802/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6581 - val_loss: 9.3714\n",
      "Epoch 803/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.2568 - val_loss: 9.0895\n",
      "Epoch 804/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1471 - val_loss: 9.1653\n",
      "Epoch 805/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2539 - val_loss: 9.3425\n",
      "Epoch 806/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2887 - val_loss: 9.0610\n",
      "Epoch 807/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1872 - val_loss: 9.3063\n",
      "Epoch 808/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.1735 - val_loss: 9.4163\n",
      "Epoch 809/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2083 - val_loss: 9.2144\n",
      "Epoch 810/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1886 - val_loss: 9.0535\n",
      "Epoch 811/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.1781 - val_loss: 9.1063\n",
      "Epoch 812/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2318 - val_loss: 9.0726\n",
      "Epoch 813/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1589 - val_loss: 9.1820\n",
      "Epoch 814/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.1974 - val_loss: 9.0858\n",
      "Epoch 815/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2912 - val_loss: 9.2519\n",
      "Epoch 816/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2387 - val_loss: 9.1198\n",
      "Epoch 817/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.1548 - val_loss: 9.1156\n",
      "Epoch 818/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2069 - val_loss: 8.8351\n",
      "Epoch 819/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4747 - val_loss: 10.0239\n",
      "Epoch 820/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3933 - val_loss: 9.2784\n",
      "Epoch 821/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3587 - val_loss: 9.6268\n",
      "Epoch 822/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3536 - val_loss: 9.0679\n",
      "Epoch 823/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1960 - val_loss: 9.2202\n",
      "Epoch 824/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.2624 - val_loss: 8.9646\n",
      "Epoch 825/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1882 - val_loss: 9.3924\n",
      "Epoch 826/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2677 - val_loss: 8.9793\n",
      "Epoch 827/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.1506 - val_loss: 9.1677\n",
      "Epoch 828/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.2088 - val_loss: 9.1572\n",
      "Epoch 829/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2693 - val_loss: 9.3487\n",
      "Epoch 830/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2628 - val_loss: 9.7421\n",
      "Epoch 831/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3642 - val_loss: 9.0618\n",
      "Epoch 832/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.3452 - val_loss: 9.0507\n",
      "Epoch 833/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2507 - val_loss: 9.5546\n",
      "Epoch 834/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2172 - val_loss: 9.1074\n",
      "Epoch 835/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3158 - val_loss: 9.1853\n",
      "Epoch 836/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.2013 - val_loss: 9.3344\n",
      "Epoch 837/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.5907 - val_loss: 8.9845\n",
      "Epoch 838/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.3609 - val_loss: 9.6496\n",
      "Epoch 839/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4054 - val_loss: 8.8408\n",
      "Epoch 840/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2711 - val_loss: 9.3446\n",
      "Epoch 841/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2095 - val_loss: 9.1864\n",
      "Epoch 842/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.1079 - val_loss: 9.0984\n",
      "Epoch 843/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1944 - val_loss: 9.0178\n",
      "Epoch 844/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3007 - val_loss: 9.5995\n",
      "Epoch 845/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.2942 - val_loss: 8.9544\n",
      "Epoch 846/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2535 - val_loss: 9.0469\n",
      "Epoch 847/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2959 - val_loss: 9.1847\n",
      "Epoch 848/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3152 - val_loss: 9.1347\n",
      "Epoch 849/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3017 - val_loss: 9.2412\n",
      "Epoch 850/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2668 - val_loss: 9.0994\n",
      "Epoch 851/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2025 - val_loss: 9.1184\n",
      "Epoch 852/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2522 - val_loss: 9.5187\n",
      "Epoch 853/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.4741 - val_loss: 8.8765\n",
      "Epoch 854/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2233 - val_loss: 9.2985\n",
      "Epoch 855/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3320 - val_loss: 8.9823\n",
      "Epoch 856/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6665 - val_loss: 10.1348\n",
      "Epoch 857/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4427 - val_loss: 8.9399\n",
      "Epoch 858/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.2288 - val_loss: 9.2807\n",
      "Epoch 859/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3593 - val_loss: 9.0433\n",
      "Epoch 860/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2883 - val_loss: 9.2600\n",
      "Epoch 861/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2208 - val_loss: 9.2694\n",
      "Epoch 862/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.1542 - val_loss: 9.1633\n",
      "Epoch 863/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1799 - val_loss: 9.1992\n",
      "Epoch 864/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2736 - val_loss: 9.4265\n",
      "Epoch 865/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4226 - val_loss: 8.9602\n",
      "Epoch 866/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.3782 - val_loss: 9.3988\n",
      "Epoch 867/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5824 - val_loss: 9.0735\n",
      "Epoch 868/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.2835 - val_loss: 9.5422\n",
      "Epoch 869/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.1909 - val_loss: 9.3884\n",
      "Epoch 870/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2288 - val_loss: 9.0132\n",
      "Epoch 871/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.2382 - val_loss: 9.1841\n",
      "Epoch 872/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2060 - val_loss: 9.4360\n",
      "Epoch 873/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1428 - val_loss: 9.0223\n",
      "Epoch 874/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1545 - val_loss: 9.4219\n",
      "Epoch 875/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.1720 - val_loss: 8.9822\n",
      "Epoch 876/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3650 - val_loss: 9.6903\n",
      "Epoch 877/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2571 - val_loss: 9.1186\n",
      "Epoch 878/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.1847 - val_loss: 9.1905\n",
      "Epoch 879/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.1597 - val_loss: 8.9194\n",
      "Epoch 880/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1796 - val_loss: 9.5902\n",
      "Epoch 881/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.2641 - val_loss: 9.0520\n",
      "Epoch 882/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2391 - val_loss: 9.2148\n",
      "Epoch 883/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.2193 - val_loss: 9.0265\n",
      "Epoch 884/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 5.1800 - val_loss: 9.0707\n",
      "Epoch 885/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.1689 - val_loss: 9.0936\n",
      "Epoch 886/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.1394 - val_loss: 9.2519\n",
      "Epoch 887/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1931 - val_loss: 9.0834\n",
      "Epoch 888/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1771 - val_loss: 9.0516\n",
      "Epoch 889/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.1445 - val_loss: 9.2071\n",
      "Epoch 890/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.2225 - val_loss: 9.0543\n",
      "Epoch 891/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1856 - val_loss: 9.2314\n",
      "Epoch 892/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2658 - val_loss: 9.0405\n",
      "Epoch 893/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2835 - val_loss: 9.6537\n",
      "Epoch 894/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2643 - val_loss: 9.2152\n",
      "Epoch 895/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.2358 - val_loss: 9.9293\n",
      "Epoch 896/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3196 - val_loss: 9.0240\n",
      "Epoch 897/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.2140 - val_loss: 9.3988\n",
      "Epoch 898/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.1780 - val_loss: 9.1845\n",
      "Epoch 899/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2278 - val_loss: 9.6684\n",
      "Epoch 900/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4111 - val_loss: 8.8128\n",
      "Epoch 901/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.3973 - val_loss: 9.4941\n",
      "Epoch 902/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.2106 - val_loss: 9.1523\n",
      "Epoch 903/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.2626 - val_loss: 9.2402\n",
      "Epoch 904/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2305 - val_loss: 9.1222\n",
      "Epoch 905/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3375 - val_loss: 9.7630\n",
      "Epoch 906/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.2477 - val_loss: 9.3182\n",
      "Epoch 907/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.2798 - val_loss: 9.3306\n",
      "Epoch 908/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.2235 - val_loss: 9.0680\n",
      "Epoch 909/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1173 - val_loss: 9.2269\n",
      "Epoch 910/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1049 - val_loss: 9.1018\n",
      "Epoch 911/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1757 - val_loss: 9.6790\n",
      "Epoch 912/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3808 - val_loss: 8.9911\n",
      "Epoch 913/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2946 - val_loss: 9.7854\n",
      "Epoch 914/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3673 - val_loss: 8.8402\n",
      "Epoch 915/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.3549 - val_loss: 9.0735\n",
      "Epoch 916/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2431 - val_loss: 9.1320\n",
      "Epoch 917/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.3263 - val_loss: 9.3467\n",
      "Epoch 918/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2511 - val_loss: 9.1494\n",
      "Epoch 919/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3038 - val_loss: 10.3659\n",
      "Epoch 920/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3738 - val_loss: 8.8985\n",
      "Epoch 921/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2048 - val_loss: 9.3496\n",
      "Epoch 922/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2665 - val_loss: 9.2077\n",
      "Epoch 923/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 100us/step - loss: 5.1584 - val_loss: 9.4885\n",
      "Epoch 924/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1566 - val_loss: 9.1284\n",
      "Epoch 925/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2404 - val_loss: 9.1530\n",
      "Epoch 926/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 5.1914 - val_loss: 9.7069\n",
      "Epoch 927/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5140 - val_loss: 8.9464\n",
      "Epoch 928/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.3342 - val_loss: 9.4436\n",
      "Epoch 929/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5126 - val_loss: 9.1659\n",
      "Epoch 930/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3770 - val_loss: 9.5531\n",
      "Epoch 931/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3115 - val_loss: 9.0736\n",
      "Epoch 932/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2356 - val_loss: 8.9920\n",
      "Epoch 933/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3297 - val_loss: 9.5233\n",
      "Epoch 934/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2776 - val_loss: 9.0086\n",
      "Epoch 935/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1742 - val_loss: 9.2122\n",
      "Epoch 936/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3064 - val_loss: 9.0745\n",
      "Epoch 937/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1543 - val_loss: 9.2499\n",
      "Epoch 938/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.3637 - val_loss: 9.0270\n",
      "Epoch 939/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6364 - val_loss: 9.6309\n",
      "Epoch 940/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 5.5411 - val_loss: 8.8674\n",
      "Epoch 941/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3119 - val_loss: 9.7658\n",
      "Epoch 942/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3536 - val_loss: 8.9068\n",
      "Epoch 943/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4784 - val_loss: 9.5308\n",
      "Epoch 944/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1674 - val_loss: 9.2120\n",
      "Epoch 945/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1932 - val_loss: 9.2133\n",
      "Epoch 946/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3093 - val_loss: 9.4889\n",
      "Epoch 947/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.3304 - val_loss: 9.3149\n",
      "Epoch 948/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2909 - val_loss: 9.0039\n",
      "Epoch 949/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2076 - val_loss: 9.2194\n",
      "Epoch 950/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2073 - val_loss: 9.2418\n",
      "Epoch 951/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2336 - val_loss: 9.1507\n",
      "Epoch 952/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1316 - val_loss: 9.4606\n",
      "Epoch 953/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1747 - val_loss: 9.4411\n",
      "Epoch 954/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1945 - val_loss: 9.4261\n",
      "Epoch 955/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.2378 - val_loss: 9.3087\n",
      "Epoch 956/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2130 - val_loss: 9.2085\n",
      "Epoch 957/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.3146 - val_loss: 9.0191\n",
      "Epoch 958/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1955 - val_loss: 9.3056\n",
      "Epoch 959/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1683 - val_loss: 9.0381\n",
      "Epoch 960/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2467 - val_loss: 9.2625\n",
      "Epoch 961/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2423 - val_loss: 9.1901\n",
      "Epoch 962/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1459 - val_loss: 9.1200\n",
      "Epoch 963/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2855 - val_loss: 9.1357\n",
      "Epoch 964/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1514 - val_loss: 9.2457\n",
      "Epoch 965/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1884 - val_loss: 8.8015\n",
      "Epoch 966/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.2253 - val_loss: 9.1855\n",
      "Epoch 967/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1652 - val_loss: 9.0229\n",
      "Epoch 968/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.2987 - val_loss: 9.2135\n",
      "Epoch 969/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1937 - val_loss: 9.1229\n",
      "Epoch 970/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1738 - val_loss: 9.3811\n",
      "Epoch 971/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1779 - val_loss: 9.1419\n",
      "Epoch 972/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.1950 - val_loss: 9.1908\n",
      "Epoch 973/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1752 - val_loss: 9.1209\n",
      "Epoch 974/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2158 - val_loss: 9.0688\n",
      "Epoch 975/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.4926 - val_loss: 8.9824\n",
      "Epoch 976/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.6429 - val_loss: 9.9172\n",
      "Epoch 977/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.3030 - val_loss: 9.0523\n",
      "Epoch 978/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1474 - val_loss: 9.3657\n",
      "Epoch 979/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1721 - val_loss: 8.9487\n",
      "Epoch 980/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.1674 - val_loss: 9.0437\n",
      "Epoch 981/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2944 - val_loss: 9.1075\n",
      "Epoch 982/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.2358 - val_loss: 9.2069\n",
      "Epoch 983/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4213 - val_loss: 9.4917\n",
      "Epoch 984/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5536 - val_loss: 9.1655\n",
      "Epoch 985/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3795 - val_loss: 9.7421\n",
      "Epoch 986/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4275 - val_loss: 9.0807\n",
      "Epoch 987/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.3560 - val_loss: 9.6384\n",
      "Epoch 988/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3481 - val_loss: 9.1391\n",
      "Epoch 989/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.1888 - val_loss: 9.6152\n",
      "Epoch 990/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.2574 - val_loss: 9.1873\n",
      "Epoch 991/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2327 - val_loss: 9.4292\n",
      "Epoch 992/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2576 - val_loss: 8.9570\n",
      "Epoch 993/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.1318 - val_loss: 9.8953\n",
      "Epoch 994/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2464 - val_loss: 9.0253\n",
      "Epoch 995/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2120 - val_loss: 9.2466\n",
      "Epoch 996/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1402 - val_loss: 9.2819\n",
      "Epoch 997/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.2009 - val_loss: 9.1579\n",
      "Epoch 998/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.2327 - val_loss: 9.3107\n",
      "Epoch 999/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1796 - val_loss: 9.1797\n",
      "Epoch 1000/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 5.1572 - val_loss: 9.2811\n",
      "8.208699339527195\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 1.0505302 ,  0.3533768 , -0.13521643,  2.7658608 ,  0.97286737],\n",
       "        [-2.109175  ,  1.3434516 , -0.54942197,  1.9954491 , -0.46865967],\n",
       "        [ 0.18010966,  0.971631  ,  1.0157697 ,  1.9750657 , -0.07710479],\n",
       "        [ 3.138973  , -1.8404623 ,  1.14082   , -2.7908416 , -0.22023597],\n",
       "        [-1.5652248 ,  0.5182006 , -0.26527432,  0.8696655 , -0.58190536],\n",
       "        [-1.6834608 , -0.80253536, -1.4577963 ,  1.5871503 ,  0.6569788 ],\n",
       "        [-0.21412319, -1.043322  , -0.4362392 , -1.4875423 ,  1.2580156 ]],\n",
       "       dtype=float32),\n",
       " array([-1.4607203,  0.9350687,  2.5024896, -0.5237697,  1.5457788],\n",
       "       dtype=float32),\n",
       " array([[-0.09803031, -0.7969602 , -0.10738765,  0.11986196,  0.01278282,\n",
       "         -0.35776636, -0.6091727 ,  0.03267024, -0.1084067 , -0.13089083,\n",
       "         -0.76149297, -0.31194782, -0.20325273, -0.18411921,  0.61645716],\n",
       "        [ 0.27926522,  0.83242124,  0.7231125 , -0.32267728, -0.24925843,\n",
       "         -0.01952912,  0.7441183 ,  0.42166013,  0.06233505,  0.35210803,\n",
       "          0.09216362,  0.35754248,  0.04658926, -0.0582969 , -0.76141274],\n",
       "        [-0.6410667 , -0.11178276, -0.8262361 ,  0.6355761 ,  0.5385669 ,\n",
       "         -1.2541239 , -0.9143939 , -0.22639488, -0.444291  , -1.019486  ,\n",
       "          0.89240783, -0.211121  , -0.09574809, -0.9308148 ,  0.2995483 ],\n",
       "        [-0.10682283, -0.26219496, -0.7370482 ,  0.6952822 ,  0.20121558,\n",
       "          0.18691956,  0.14329231, -0.70648366, -0.10609795, -0.5157643 ,\n",
       "         -0.25889942, -0.05375632, -0.9358807 , -0.23551409,  0.26234406],\n",
       "        [-0.0518337 ,  0.649542  ,  0.7002282 , -0.20862219,  0.05113373,\n",
       "          0.8907897 ,  0.18591617,  0.3087218 ,  0.24669051,  0.2942293 ,\n",
       "         -0.00132455,  0.32180458,  0.95854723,  0.22482333, -0.6759467 ]],\n",
       "       dtype=float32),\n",
       " array([ 1.4411113,  1.5305308,  1.5651339, -1.5831167, -1.4683703,\n",
       "         1.6135907,  1.5604101,  1.4832495,  1.4428566,  1.5960623,\n",
       "        -1.1127845,  1.4294404,  1.5073472,  1.6051724, -1.5391656],\n",
       "       dtype=float32),\n",
       " array([[ 0.48752943],\n",
       "        [ 1.0668584 ],\n",
       "        [ 0.8539216 ],\n",
       "        [-0.98097914],\n",
       "        [-0.50517005],\n",
       "        [ 0.92421484],\n",
       "        [ 0.9190361 ],\n",
       "        [ 0.68031466],\n",
       "        [ 0.6295377 ],\n",
       "        [ 1.290063  ],\n",
       "        [-0.0592707 ],\n",
       "        [ 0.84803915],\n",
       "        [ 1.0917883 ],\n",
       "        [ 0.87228745],\n",
       "        [-1.1842711 ]], dtype=float32),\n",
       " array([1.5541393], dtype=float32)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_autompg, history_autompg=NN_model_structure_regression_3(X_train_autompg, X_val_autompg, Y_train_autompg, Y_val_autompg, adam2, 32, 1000)\n",
    "model_autompg.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_autompg.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_autompg_structure3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_28 (Dense)             (None, 10)                80        \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 141\n",
      "Trainable params: 141\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 274 samples, validate on 59 samples\n",
      "Epoch 1/1000\n",
      "274/274 [==============================] - 0s 995us/step - loss: 509.8328 - val_loss: 300.9741\n",
      "Epoch 2/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 212.3703 - val_loss: 64.1557\n",
      "Epoch 3/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 55.5463 - val_loss: 27.4922\n",
      "Epoch 4/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 28.0026 - val_loss: 23.8785\n",
      "Epoch 5/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 20.2959 - val_loss: 21.4635\n",
      "Epoch 6/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 18.1589 - val_loss: 19.3090\n",
      "Epoch 7/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 17.0335 - val_loss: 17.8803\n",
      "Epoch 8/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 15.3875 - val_loss: 17.2573\n",
      "Epoch 9/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 14.4977 - val_loss: 15.6907\n",
      "Epoch 10/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 13.5346 - val_loss: 14.9180\n",
      "Epoch 11/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 12.6280 - val_loss: 14.9106\n",
      "Epoch 12/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 12.0120 - val_loss: 13.9406\n",
      "Epoch 13/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 11.7012 - val_loss: 13.2342\n",
      "Epoch 14/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 11.3935 - val_loss: 12.3799\n",
      "Epoch 15/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 11.2204 - val_loss: 11.9217\n",
      "Epoch 16/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 10.3541 - val_loss: 11.7855\n",
      "Epoch 17/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 9.9280 - val_loss: 11.2791\n",
      "Epoch 18/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 9.6668 - val_loss: 10.5166\n",
      "Epoch 19/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 9.4340 - val_loss: 10.2107\n",
      "Epoch 20/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 9.1290 - val_loss: 10.2254\n",
      "Epoch 21/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 9.0522 - val_loss: 10.2147\n",
      "Epoch 22/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.9950 - val_loss: 9.9557\n",
      "Epoch 23/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 8.8480 - val_loss: 9.6806\n",
      "Epoch 24/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 8.7717 - val_loss: 9.8921\n",
      "Epoch 25/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.5448 - val_loss: 9.4755\n",
      "Epoch 26/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 8.3420 - val_loss: 9.3917\n",
      "Epoch 27/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.1638 - val_loss: 9.5227\n",
      "Epoch 28/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 8.1197 - val_loss: 9.3410\n",
      "Epoch 29/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.0540 - val_loss: 9.3779\n",
      "Epoch 30/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 8.0409 - val_loss: 9.2885\n",
      "Epoch 31/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 8.0384 - val_loss: 9.5784\n",
      "Epoch 32/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.2165 - val_loss: 9.2754\n",
      "Epoch 33/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.0126 - val_loss: 9.3045\n",
      "Epoch 34/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.1212 - val_loss: 9.3276\n",
      "Epoch 35/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 7.8918 - val_loss: 9.2080\n",
      "Epoch 36/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.8651 - val_loss: 9.1866\n",
      "Epoch 37/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.1890 - val_loss: 9.3743\n",
      "Epoch 38/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 7.6884 - val_loss: 9.4301\n",
      "Epoch 39/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.7937 - val_loss: 9.3711\n",
      "Epoch 40/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 7.8298 - val_loss: 9.1932\n",
      "Epoch 41/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 7.7667 - val_loss: 9.2533\n",
      "Epoch 42/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.8370 - val_loss: 9.3864\n",
      "Epoch 43/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 7.5434 - val_loss: 9.0178\n",
      "Epoch 44/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.5861 - val_loss: 9.3955\n",
      "Epoch 45/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.6237 - val_loss: 9.1649\n",
      "Epoch 46/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.4513 - val_loss: 9.2252\n",
      "Epoch 47/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.5015 - val_loss: 9.1589\n",
      "Epoch 48/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 7.5060 - val_loss: 9.0486\n",
      "Epoch 49/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.5471 - val_loss: 9.0104\n",
      "Epoch 50/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.4367 - val_loss: 9.0783\n",
      "Epoch 51/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.3936 - val_loss: 8.8150\n",
      "Epoch 52/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.3505 - val_loss: 9.0536\n",
      "Epoch 53/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.3629 - val_loss: 9.0748\n",
      "Epoch 54/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.2587 - val_loss: 9.3444\n",
      "Epoch 55/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1803 - val_loss: 8.8962\n",
      "Epoch 56/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 7.4144 - val_loss: 8.6929\n",
      "Epoch 57/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1495 - val_loss: 9.0756\n",
      "Epoch 58/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.1712 - val_loss: 8.7414\n",
      "Epoch 59/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3144 - val_loss: 8.9115\n",
      "Epoch 60/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.0204 - val_loss: 8.8652\n",
      "Epoch 61/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.1940 - val_loss: 8.8832\n",
      "Epoch 62/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1721 - val_loss: 8.7091\n",
      "Epoch 63/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1774 - val_loss: 8.6995\n",
      "Epoch 64/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1569 - val_loss: 8.6975\n",
      "Epoch 65/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 7.1032 - val_loss: 8.8827\n",
      "Epoch 66/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 7.0874 - val_loss: 8.7877\n",
      "Epoch 67/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0904 - val_loss: 8.7638\n",
      "Epoch 68/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0641 - val_loss: 8.5274\n",
      "Epoch 69/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 106us/step - loss: 7.0590 - val_loss: 8.8177\n",
      "Epoch 70/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9738 - val_loss: 8.7863\n",
      "Epoch 71/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.0380 - val_loss: 8.6611\n",
      "Epoch 72/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1006 - val_loss: 8.5166\n",
      "Epoch 73/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0124 - val_loss: 8.5545\n",
      "Epoch 74/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 6.9524 - val_loss: 8.6224\n",
      "Epoch 75/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 7.3334 - val_loss: 8.5522\n",
      "Epoch 76/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 7.0460 - val_loss: 8.6274\n",
      "Epoch 77/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1370 - val_loss: 8.5851\n",
      "Epoch 78/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.6291 - val_loss: 8.4503\n",
      "Epoch 79/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1187 - val_loss: 8.4790\n",
      "Epoch 80/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8954 - val_loss: 8.9029\n",
      "Epoch 81/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2429 - val_loss: 8.6715\n",
      "Epoch 82/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0355 - val_loss: 8.9856\n",
      "Epoch 83/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.9034 - val_loss: 8.6934\n",
      "Epoch 84/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1364 - val_loss: 8.7407\n",
      "Epoch 85/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.4074 - val_loss: 8.6639\n",
      "Epoch 86/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1780 - val_loss: 8.6507\n",
      "Epoch 87/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9533 - val_loss: 8.3875\n",
      "Epoch 88/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8673 - val_loss: 8.3173\n",
      "Epoch 89/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.8657 - val_loss: 8.2089\n",
      "Epoch 90/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7667 - val_loss: 8.6352\n",
      "Epoch 91/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8713 - val_loss: 8.5864\n",
      "Epoch 92/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9021 - val_loss: 8.5443\n",
      "Epoch 93/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.6592 - val_loss: 8.4681\n",
      "Epoch 94/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0109 - val_loss: 8.4886\n",
      "Epoch 95/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9623 - val_loss: 8.5450\n",
      "Epoch 96/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0183 - val_loss: 8.3467\n",
      "Epoch 97/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0354 - val_loss: 8.4212\n",
      "Epoch 98/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.9949 - val_loss: 8.6115\n",
      "Epoch 99/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7538 - val_loss: 8.2596\n",
      "Epoch 100/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7755 - val_loss: 8.4548\n",
      "Epoch 101/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0829 - val_loss: 8.2335\n",
      "Epoch 102/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0396 - val_loss: 8.5904\n",
      "Epoch 103/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8524 - val_loss: 8.3420\n",
      "Epoch 104/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.4583 - val_loss: 8.5262\n",
      "Epoch 105/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.6127 - val_loss: 8.5747\n",
      "Epoch 106/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.3028 - val_loss: 8.4796\n",
      "Epoch 107/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.7434 - val_loss: 8.6392\n",
      "Epoch 108/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5964 - val_loss: 8.3391\n",
      "Epoch 109/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5930 - val_loss: 8.2834\n",
      "Epoch 110/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6083 - val_loss: 8.2745\n",
      "Epoch 111/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6091 - val_loss: 8.3544\n",
      "Epoch 112/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0006 - val_loss: 8.4178\n",
      "Epoch 113/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8656 - val_loss: 8.1946\n",
      "Epoch 114/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6312 - val_loss: 8.1668\n",
      "Epoch 115/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5337 - val_loss: 8.4866\n",
      "Epoch 116/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.5337 - val_loss: 8.1320\n",
      "Epoch 117/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.5171 - val_loss: 8.5970\n",
      "Epoch 118/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6773 - val_loss: 8.0856\n",
      "Epoch 119/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3810 - val_loss: 8.1485\n",
      "Epoch 120/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5027 - val_loss: 8.1696\n",
      "Epoch 121/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4290 - val_loss: 8.2119\n",
      "Epoch 122/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.3992 - val_loss: 8.0769\n",
      "Epoch 123/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5324 - val_loss: 8.0467\n",
      "Epoch 124/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.5576 - val_loss: 8.0261\n",
      "Epoch 125/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3654 - val_loss: 8.1714\n",
      "Epoch 126/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4394 - val_loss: 7.9116\n",
      "Epoch 127/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4946 - val_loss: 8.0341\n",
      "Epoch 128/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4219 - val_loss: 7.9997\n",
      "Epoch 129/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5364 - val_loss: 8.2284\n",
      "Epoch 130/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2951 - val_loss: 8.0960\n",
      "Epoch 131/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3882 - val_loss: 8.0427\n",
      "Epoch 132/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.2633 - val_loss: 7.9002\n",
      "Epoch 133/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4723 - val_loss: 8.1353\n",
      "Epoch 134/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3952 - val_loss: 8.0211\n",
      "Epoch 135/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.2552 - val_loss: 8.0831\n",
      "Epoch 136/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.4424 - val_loss: 7.9339\n",
      "Epoch 137/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4958 - val_loss: 7.8878\n",
      "Epoch 138/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4853 - val_loss: 8.1090\n",
      "Epoch 139/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3976 - val_loss: 7.8040\n",
      "Epoch 140/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2581 - val_loss: 7.8450\n",
      "Epoch 141/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3402 - val_loss: 7.9167\n",
      "Epoch 142/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2798 - val_loss: 7.9070\n",
      "Epoch 143/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2865 - val_loss: 8.1446\n",
      "Epoch 144/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2362 - val_loss: 8.0549\n",
      "Epoch 145/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2387 - val_loss: 8.3815\n",
      "Epoch 146/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2091 - val_loss: 8.0203\n",
      "Epoch 147/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1933 - val_loss: 7.6810\n",
      "Epoch 148/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.2558 - val_loss: 8.0322\n",
      "Epoch 149/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2613 - val_loss: 7.6716\n",
      "Epoch 150/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.2156 - val_loss: 8.1765\n",
      "Epoch 151/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1999 - val_loss: 7.6893\n",
      "Epoch 152/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2341 - val_loss: 7.6390\n",
      "Epoch 153/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2444 - val_loss: 7.7691\n",
      "Epoch 154/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.1797 - val_loss: 7.5893\n",
      "Epoch 155/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3371 - val_loss: 7.7682\n",
      "Epoch 156/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2642 - val_loss: 7.8036\n",
      "Epoch 157/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0871 - val_loss: 7.9719\n",
      "Epoch 158/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.2649 - val_loss: 7.7263\n",
      "Epoch 159/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1779 - val_loss: 7.5892\n",
      "Epoch 160/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1369 - val_loss: 7.4436\n",
      "Epoch 161/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1123 - val_loss: 7.6875\n",
      "Epoch 162/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.1001 - val_loss: 7.6292\n",
      "Epoch 163/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1853 - val_loss: 7.8406\n",
      "Epoch 164/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2315 - val_loss: 7.6084\n",
      "Epoch 165/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3600 - val_loss: 7.8824\n",
      "Epoch 166/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1584 - val_loss: 7.8056\n",
      "Epoch 167/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.3291 - val_loss: 7.9184\n",
      "Epoch 168/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1334 - val_loss: 7.5552\n",
      "Epoch 169/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0400 - val_loss: 7.6665\n",
      "Epoch 170/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0876 - val_loss: 7.6376\n",
      "Epoch 171/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.1426 - val_loss: 7.7357\n",
      "Epoch 172/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9806 - val_loss: 7.6445\n",
      "Epoch 173/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.9954 - val_loss: 7.5007\n",
      "Epoch 174/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0051 - val_loss: 7.5423\n",
      "Epoch 175/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9607 - val_loss: 7.5378\n",
      "Epoch 176/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0160 - val_loss: 7.5368\n",
      "Epoch 177/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9795 - val_loss: 7.5032\n",
      "Epoch 178/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0111 - val_loss: 7.8234\n",
      "Epoch 179/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.1258 - val_loss: 7.5377\n",
      "Epoch 180/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0271 - val_loss: 7.3790\n",
      "Epoch 181/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.0720 - val_loss: 7.5969\n",
      "Epoch 182/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8989 - val_loss: 7.6147\n",
      "Epoch 183/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.9620 - val_loss: 7.3777\n",
      "Epoch 184/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9083 - val_loss: 7.4334\n",
      "Epoch 185/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9337 - val_loss: 7.5344\n",
      "Epoch 186/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.0417 - val_loss: 7.6579\n",
      "Epoch 187/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9472 - val_loss: 7.4941\n",
      "Epoch 188/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9647 - val_loss: 7.4170\n",
      "Epoch 189/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8832 - val_loss: 7.3225\n",
      "Epoch 190/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9859 - val_loss: 7.4735\n",
      "Epoch 191/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.8770 - val_loss: 7.6469\n",
      "Epoch 192/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8400 - val_loss: 7.6138\n",
      "Epoch 193/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7862 - val_loss: 7.2828\n",
      "Epoch 194/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9414 - val_loss: 7.7827\n",
      "Epoch 195/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8473 - val_loss: 7.3403\n",
      "Epoch 196/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8664 - val_loss: 7.5573\n",
      "Epoch 197/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0922 - val_loss: 7.4340\n",
      "Epoch 198/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8450 - val_loss: 7.5310\n",
      "Epoch 199/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.9611 - val_loss: 7.5302\n",
      "Epoch 200/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8572 - val_loss: 7.6330\n",
      "Epoch 201/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.9401 - val_loss: 7.3692\n",
      "Epoch 202/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8762 - val_loss: 7.4245\n",
      "Epoch 203/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7464 - val_loss: 7.3741\n",
      "Epoch 204/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.7755 - val_loss: 7.3358\n",
      "Epoch 205/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7400 - val_loss: 7.6390\n",
      "Epoch 206/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.8498 - val_loss: 7.6839\n",
      "Epoch 207/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.2813 - val_loss: 7.3932\n",
      "Epoch 208/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.9464 - val_loss: 7.4642\n",
      "Epoch 209/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6903 - val_loss: 7.3616\n",
      "Epoch 210/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.7649 - val_loss: 7.3885\n",
      "Epoch 211/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8151 - val_loss: 7.2131\n",
      "Epoch 212/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8074 - val_loss: 7.1894\n",
      "Epoch 213/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8959 - val_loss: 7.2418\n",
      "Epoch 214/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7789 - val_loss: 7.5183\n",
      "Epoch 215/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7829 - val_loss: 7.2989\n",
      "Epoch 216/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.5961 - val_loss: 7.5357\n",
      "Epoch 217/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6572 - val_loss: 7.1200\n",
      "Epoch 218/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.6828 - val_loss: 7.2747\n",
      "Epoch 219/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6423 - val_loss: 7.4001\n",
      "Epoch 220/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7418 - val_loss: 7.2333\n",
      "Epoch 221/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8227 - val_loss: 7.1946\n",
      "Epoch 222/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.7182 - val_loss: 7.3296\n",
      "Epoch 223/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7092 - val_loss: 7.4573\n",
      "Epoch 224/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5834 - val_loss: 7.4537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6028 - val_loss: 7.5012\n",
      "Epoch 226/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5942 - val_loss: 7.2672\n",
      "Epoch 227/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.6486 - val_loss: 7.4468\n",
      "Epoch 228/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.5175 - val_loss: 7.6055\n",
      "Epoch 229/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6610 - val_loss: 7.2470\n",
      "Epoch 230/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8357 - val_loss: 7.3344\n",
      "Epoch 231/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.6005 - val_loss: 7.1716\n",
      "Epoch 232/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7458 - val_loss: 7.4156\n",
      "Epoch 233/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4990 - val_loss: 7.0242\n",
      "Epoch 234/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.5332 - val_loss: 7.2627\n",
      "Epoch 235/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7255 - val_loss: 7.3622\n",
      "Epoch 236/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5520 - val_loss: 7.2774\n",
      "Epoch 237/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6019 - val_loss: 7.3502\n",
      "Epoch 238/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5323 - val_loss: 7.4245\n",
      "Epoch 239/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4973 - val_loss: 7.1559\n",
      "Epoch 240/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6934 - val_loss: 7.3394\n",
      "Epoch 241/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.5363 - val_loss: 7.5695\n",
      "Epoch 242/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6785 - val_loss: 7.2204\n",
      "Epoch 243/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5580 - val_loss: 7.5003\n",
      "Epoch 244/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5530 - val_loss: 7.2917\n",
      "Epoch 245/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.5571 - val_loss: 7.2718\n",
      "Epoch 246/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6448 - val_loss: 7.4853\n",
      "Epoch 247/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.8439 - val_loss: 6.8784\n",
      "Epoch 248/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6899 - val_loss: 7.1081\n",
      "Epoch 249/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.4322 - val_loss: 7.4039\n",
      "Epoch 250/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4251 - val_loss: 7.3939\n",
      "Epoch 251/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4810 - val_loss: 7.1557\n",
      "Epoch 252/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4826 - val_loss: 7.2937\n",
      "Epoch 253/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.4650 - val_loss: 7.3655\n",
      "Epoch 254/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4269 - val_loss: 7.3278\n",
      "Epoch 255/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.4859 - val_loss: 7.2218\n",
      "Epoch 256/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.5401 - val_loss: 7.2356\n",
      "Epoch 257/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.4893 - val_loss: 7.1318\n",
      "Epoch 258/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5815 - val_loss: 7.6569\n",
      "Epoch 259/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4431 - val_loss: 7.4320\n",
      "Epoch 260/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4544 - val_loss: 7.2786\n",
      "Epoch 261/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5222 - val_loss: 7.1636\n",
      "Epoch 262/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.5089 - val_loss: 7.3334\n",
      "Epoch 263/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4552 - val_loss: 7.3579\n",
      "Epoch 264/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9564 - val_loss: 8.5831\n",
      "Epoch 265/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8993 - val_loss: 7.1678\n",
      "Epoch 266/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7342 - val_loss: 8.0439\n",
      "Epoch 267/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7985 - val_loss: 7.3548\n",
      "Epoch 268/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6406 - val_loss: 7.5352\n",
      "Epoch 269/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5012 - val_loss: 7.3693\n",
      "Epoch 270/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.2917 - val_loss: 7.3972\n",
      "Epoch 271/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.4494 - val_loss: 7.4766\n",
      "Epoch 272/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.2696 - val_loss: 7.6380\n",
      "Epoch 273/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.3241 - val_loss: 7.2546\n",
      "Epoch 274/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4279 - val_loss: 7.6951\n",
      "Epoch 275/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3818 - val_loss: 7.6324\n",
      "Epoch 276/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2693 - val_loss: 7.2409\n",
      "Epoch 277/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3697 - val_loss: 7.3551\n",
      "Epoch 278/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3527 - val_loss: 7.2445\n",
      "Epoch 279/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3972 - val_loss: 7.3373\n",
      "Epoch 280/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3300 - val_loss: 7.4607\n",
      "Epoch 281/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3034 - val_loss: 7.2323\n",
      "Epoch 282/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.4489 - val_loss: 7.6019\n",
      "Epoch 283/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2517 - val_loss: 7.7464\n",
      "Epoch 284/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1564 - val_loss: 7.3926\n",
      "Epoch 285/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.1596 - val_loss: 7.3203\n",
      "Epoch 286/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2590 - val_loss: 7.2196\n",
      "Epoch 287/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3031 - val_loss: 7.1672\n",
      "Epoch 288/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2982 - val_loss: 7.3030\n",
      "Epoch 289/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.3571 - val_loss: 7.4675\n",
      "Epoch 290/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2504 - val_loss: 7.3331\n",
      "Epoch 291/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.1706 - val_loss: 7.5100\n",
      "Epoch 292/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1552 - val_loss: 7.3893\n",
      "Epoch 293/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2092 - val_loss: 7.3807\n",
      "Epoch 294/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2369 - val_loss: 7.7219\n",
      "Epoch 295/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1175 - val_loss: 7.4245\n",
      "Epoch 296/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.2050 - val_loss: 7.7855\n",
      "Epoch 297/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.2658 - val_loss: 7.5386\n",
      "Epoch 298/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.2948 - val_loss: 7.6618\n",
      "Epoch 299/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1760 - val_loss: 7.3431\n",
      "Epoch 300/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.2235 - val_loss: 7.7345\n",
      "Epoch 301/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.3144 - val_loss: 7.3730\n",
      "Epoch 302/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.0715 - val_loss: 7.5800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 303/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1170 - val_loss: 7.4737\n",
      "Epoch 304/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0417 - val_loss: 7.6562\n",
      "Epoch 305/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0552 - val_loss: 7.4647\n",
      "Epoch 306/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2225 - val_loss: 7.5155\n",
      "Epoch 307/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4088 - val_loss: 7.3332\n",
      "Epoch 308/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0350 - val_loss: 7.5245\n",
      "Epoch 309/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9943 - val_loss: 7.6190\n",
      "Epoch 310/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1414 - val_loss: 8.0457\n",
      "Epoch 311/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1932 - val_loss: 7.4715\n",
      "Epoch 312/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0336 - val_loss: 7.7627\n",
      "Epoch 313/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0690 - val_loss: 7.5483\n",
      "Epoch 314/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0020 - val_loss: 7.7888\n",
      "Epoch 315/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0353 - val_loss: 7.9634\n",
      "Epoch 316/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1422 - val_loss: 7.4455\n",
      "Epoch 317/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6377 - val_loss: 8.4941\n",
      "Epoch 318/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4362 - val_loss: 7.6219\n",
      "Epoch 319/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0477 - val_loss: 7.8336\n",
      "Epoch 320/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 4.9646 - val_loss: 7.7757\n",
      "Epoch 321/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9554 - val_loss: 7.8918\n",
      "Epoch 322/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.9449 - val_loss: 7.6741\n",
      "Epoch 323/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.0088 - val_loss: 7.6134\n",
      "Epoch 324/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9838 - val_loss: 7.7188\n",
      "Epoch 325/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9672 - val_loss: 7.6892\n",
      "Epoch 326/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.9289 - val_loss: 7.6636\n",
      "Epoch 327/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9840 - val_loss: 7.9722\n",
      "Epoch 328/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3992 - val_loss: 7.7644\n",
      "Epoch 329/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.3963 - val_loss: 8.7309\n",
      "Epoch 330/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5550 - val_loss: 7.7480\n",
      "Epoch 331/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2445 - val_loss: 7.9920\n",
      "Epoch 332/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.1036 - val_loss: 7.9093\n",
      "Epoch 333/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2993 - val_loss: 7.8613\n",
      "Epoch 334/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.0438 - val_loss: 8.4184\n",
      "Epoch 335/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.1499 - val_loss: 7.7143\n",
      "Epoch 336/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.3219 - val_loss: 8.3381\n",
      "Epoch 337/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9700 - val_loss: 8.0305\n",
      "Epoch 338/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8456 - val_loss: 7.8554\n",
      "Epoch 339/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.8948 - val_loss: 7.5261\n",
      "Epoch 340/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.1126 - val_loss: 7.6606\n",
      "Epoch 341/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.8514 - val_loss: 7.9152\n",
      "Epoch 342/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8810 - val_loss: 7.9074\n",
      "Epoch 343/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9381 - val_loss: 7.8504\n",
      "Epoch 344/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8495 - val_loss: 7.8950\n",
      "Epoch 345/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.9921 - val_loss: 8.0909\n",
      "Epoch 346/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.0362 - val_loss: 8.0815\n",
      "Epoch 347/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.0810 - val_loss: 8.3911\n",
      "Epoch 348/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.8542 - val_loss: 7.8790\n",
      "Epoch 349/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8716 - val_loss: 8.3149\n",
      "Epoch 350/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9402 - val_loss: 8.0536\n",
      "Epoch 351/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9195 - val_loss: 8.3730\n",
      "Epoch 352/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9187 - val_loss: 7.7259\n",
      "Epoch 353/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.8150 - val_loss: 8.0455\n",
      "Epoch 354/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.0204 - val_loss: 7.9162\n",
      "Epoch 355/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1517 - val_loss: 7.8069\n",
      "Epoch 356/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.9919 - val_loss: 8.1914\n",
      "Epoch 357/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8854 - val_loss: 7.7265\n",
      "Epoch 358/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.8987 - val_loss: 8.1084\n",
      "Epoch 359/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.6929 - val_loss: 7.7187\n",
      "Epoch 360/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.7441 - val_loss: 7.8318\n",
      "Epoch 361/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.7264 - val_loss: 7.8119\n",
      "Epoch 362/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.8049 - val_loss: 7.9821\n",
      "Epoch 363/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7649 - val_loss: 7.5844\n",
      "Epoch 364/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.6330 - val_loss: 7.8711\n",
      "Epoch 365/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.6079 - val_loss: 7.8789\n",
      "Epoch 366/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6854 - val_loss: 8.0035\n",
      "Epoch 367/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 4.6573 - val_loss: 8.0356\n",
      "Epoch 368/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.6920 - val_loss: 8.1220\n",
      "Epoch 369/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.6611 - val_loss: 7.9793\n",
      "Epoch 370/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.5999 - val_loss: 8.0773\n",
      "Epoch 371/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.7302 - val_loss: 7.8218\n",
      "Epoch 372/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7226 - val_loss: 7.8939\n",
      "Epoch 373/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6375 - val_loss: 8.2179\n",
      "Epoch 374/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6729 - val_loss: 7.7643\n",
      "Epoch 375/1000\n",
      "274/274 [==============================] - 0s 138us/step - loss: 4.6874 - val_loss: 7.7742\n",
      "Epoch 376/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 4.6297 - val_loss: 7.9160\n",
      "Epoch 377/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6137 - val_loss: 7.7042\n",
      "Epoch 378/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5550 - val_loss: 8.4351\n",
      "Epoch 379/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6508 - val_loss: 7.6225\n",
      "Epoch 380/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5575 - val_loss: 7.7841\n",
      "Epoch 381/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.6282 - val_loss: 8.3254\n",
      "Epoch 382/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7077 - val_loss: 7.8997\n",
      "Epoch 383/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.7788 - val_loss: 8.1078\n",
      "Epoch 384/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7560 - val_loss: 7.7451\n",
      "Epoch 385/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.5830 - val_loss: 7.9666\n",
      "Epoch 386/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6180 - val_loss: 7.8932\n",
      "Epoch 387/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5719 - val_loss: 8.0304\n",
      "Epoch 388/1000\n",
      "274/274 [==============================] - 0s 117us/step - loss: 4.8508 - val_loss: 7.8372\n",
      "Epoch 389/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.7633 - val_loss: 8.0231\n",
      "Epoch 390/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5730 - val_loss: 8.1049\n",
      "Epoch 391/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4475 - val_loss: 7.8675\n",
      "Epoch 392/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5527 - val_loss: 7.7685\n",
      "Epoch 393/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.5697 - val_loss: 8.3051\n",
      "Epoch 394/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5795 - val_loss: 7.6500\n",
      "Epoch 395/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4709 - val_loss: 8.1174\n",
      "Epoch 396/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.4708 - val_loss: 7.8589\n",
      "Epoch 397/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 4.4605 - val_loss: 8.4568\n",
      "Epoch 398/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.4400 - val_loss: 8.2388\n",
      "Epoch 399/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.4429 - val_loss: 8.2313\n",
      "Epoch 400/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.4747 - val_loss: 7.8036\n",
      "Epoch 401/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.4405 - val_loss: 7.7239\n",
      "Epoch 402/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5097 - val_loss: 7.6742\n",
      "Epoch 403/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.5341 - val_loss: 7.9780\n",
      "Epoch 404/1000\n",
      "274/274 [==============================] - 0s 118us/step - loss: 4.4962 - val_loss: 7.8987\n",
      "Epoch 405/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.4834 - val_loss: 7.7287\n",
      "Epoch 406/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.4829 - val_loss: 7.8364\n",
      "Epoch 407/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.5842 - val_loss: 7.6001\n",
      "Epoch 408/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.4227 - val_loss: 7.7993\n",
      "Epoch 409/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.6076 - val_loss: 8.2703\n",
      "Epoch 410/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6063 - val_loss: 7.9604\n",
      "Epoch 411/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.5570 - val_loss: 8.3619\n",
      "Epoch 412/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.4852 - val_loss: 7.6922\n",
      "Epoch 413/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.4640 - val_loss: 8.0056\n",
      "Epoch 414/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4312 - val_loss: 7.8762\n",
      "Epoch 415/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.4353 - val_loss: 7.7927\n",
      "Epoch 416/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6273 - val_loss: 8.6097\n",
      "Epoch 417/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.6289 - val_loss: 7.8305\n",
      "Epoch 418/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7882 - val_loss: 8.5248\n",
      "Epoch 419/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.7915 - val_loss: 7.7674\n",
      "Epoch 420/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7017 - val_loss: 8.7712\n",
      "Epoch 421/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.5594 - val_loss: 8.1563\n",
      "Epoch 422/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6819 - val_loss: 8.6055\n",
      "Epoch 423/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.3902 - val_loss: 7.9450\n",
      "Epoch 424/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4524 - val_loss: 7.6548\n",
      "Epoch 425/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 4.3380 - val_loss: 7.8621\n",
      "Epoch 426/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3362 - val_loss: 7.9897\n",
      "Epoch 427/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3494 - val_loss: 7.8502\n",
      "Epoch 428/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2685 - val_loss: 7.8525\n",
      "Epoch 429/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3789 - val_loss: 7.7901\n",
      "Epoch 430/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2531 - val_loss: 7.8388\n",
      "Epoch 431/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 4.4704 - val_loss: 7.9859\n",
      "Epoch 432/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4314 - val_loss: 8.0969\n",
      "Epoch 433/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4472 - val_loss: 7.9428\n",
      "Epoch 434/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.3410 - val_loss: 8.0796\n",
      "Epoch 435/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.4677 - val_loss: 8.0754\n",
      "Epoch 436/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2711 - val_loss: 7.7965\n",
      "Epoch 437/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3800 - val_loss: 7.6589\n",
      "Epoch 438/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2827 - val_loss: 7.9549\n",
      "Epoch 439/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2399 - val_loss: 8.0244\n",
      "Epoch 440/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 4.3134 - val_loss: 7.6790\n",
      "Epoch 441/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2905 - val_loss: 7.7907\n",
      "Epoch 442/1000\n",
      "274/274 [==============================] - 0s 117us/step - loss: 4.2669 - val_loss: 7.8157\n",
      "Epoch 443/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3966 - val_loss: 7.8537\n",
      "Epoch 444/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2468 - val_loss: 7.6621\n",
      "Epoch 445/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.2362 - val_loss: 7.6745\n",
      "Epoch 446/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 4.4456 - val_loss: 8.5695\n",
      "Epoch 447/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.4682 - val_loss: 7.6607\n",
      "Epoch 448/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3357 - val_loss: 8.0199\n",
      "Epoch 449/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.2075 - val_loss: 7.6914\n",
      "Epoch 450/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.1955 - val_loss: 7.7846\n",
      "Epoch 451/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2583 - val_loss: 7.9421\n",
      "Epoch 452/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5892 - val_loss: 7.7254\n",
      "Epoch 453/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.0530 - val_loss: 8.9321\n",
      "Epoch 454/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5285 - val_loss: 8.1798\n",
      "Epoch 455/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6084 - val_loss: 8.0867\n",
      "Epoch 456/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.4978 - val_loss: 7.7309\n",
      "Epoch 457/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 4.1938 - val_loss: 7.9575\n",
      "Epoch 458/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.2085 - val_loss: 7.6822\n",
      "Epoch 459/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.1684 - val_loss: 7.8183\n",
      "Epoch 460/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.2550 - val_loss: 8.0975\n",
      "Epoch 461/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3791 - val_loss: 7.7860\n",
      "Epoch 462/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2644 - val_loss: 8.0699\n",
      "Epoch 463/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.3239 - val_loss: 8.0446\n",
      "Epoch 464/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2281 - val_loss: 8.0947\n",
      "Epoch 465/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4994 - val_loss: 7.6966\n",
      "Epoch 466/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2688 - val_loss: 7.6580\n",
      "Epoch 467/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4487 - val_loss: 8.3021\n",
      "Epoch 468/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.3035 - val_loss: 7.6428\n",
      "Epoch 469/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.3345 - val_loss: 8.2227\n",
      "Epoch 470/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.4642 - val_loss: 8.0409\n",
      "Epoch 471/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.4097 - val_loss: 7.8243\n",
      "Epoch 472/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2836 - val_loss: 8.0852\n",
      "Epoch 473/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.1849 - val_loss: 7.8956\n",
      "Epoch 474/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.1749 - val_loss: 8.1717\n",
      "Epoch 475/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2683 - val_loss: 7.7720\n",
      "Epoch 476/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3577 - val_loss: 8.4600\n",
      "Epoch 477/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6408 - val_loss: 7.5979\n",
      "Epoch 478/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5192 - val_loss: 8.6556\n",
      "Epoch 479/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2654 - val_loss: 7.7521\n",
      "Epoch 480/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1522 - val_loss: 7.8815\n",
      "Epoch 481/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2084 - val_loss: 7.9435\n",
      "Epoch 482/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.1467 - val_loss: 7.9694\n",
      "Epoch 483/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.1543 - val_loss: 7.4814\n",
      "Epoch 484/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1927 - val_loss: 8.3118\n",
      "Epoch 485/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1792 - val_loss: 7.7355\n",
      "Epoch 486/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1661 - val_loss: 8.1525\n",
      "Epoch 487/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1893 - val_loss: 7.7509\n",
      "Epoch 488/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3096 - val_loss: 8.4498\n",
      "Epoch 489/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3004 - val_loss: 7.7305\n",
      "Epoch 490/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1653 - val_loss: 7.8458\n",
      "Epoch 491/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1430 - val_loss: 7.7471\n",
      "Epoch 492/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.3553 - val_loss: 8.6268\n",
      "Epoch 493/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 4.2641 - val_loss: 7.5943\n",
      "Epoch 494/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.1515 - val_loss: 7.7035\n",
      "Epoch 495/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 4.1093 - val_loss: 7.8390\n",
      "Epoch 496/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3022 - val_loss: 7.5527\n",
      "Epoch 497/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3827 - val_loss: 8.2354\n",
      "Epoch 498/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3003 - val_loss: 7.8088\n",
      "Epoch 499/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.1669 - val_loss: 8.0123\n",
      "Epoch 500/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2863 - val_loss: 7.9635\n",
      "Epoch 501/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.3605 - val_loss: 8.0823\n",
      "Epoch 502/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2571 - val_loss: 7.5869\n",
      "Epoch 503/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.0676 - val_loss: 8.2294\n",
      "Epoch 504/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2059 - val_loss: 7.7133\n",
      "Epoch 505/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.2869 - val_loss: 8.4541\n",
      "Epoch 506/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1103 - val_loss: 7.6049\n",
      "Epoch 507/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0828 - val_loss: 8.6292\n",
      "Epoch 508/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2651 - val_loss: 7.8038\n",
      "Epoch 509/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8971 - val_loss: 8.6742\n",
      "Epoch 510/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3837 - val_loss: 7.7660\n",
      "Epoch 511/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2108 - val_loss: 8.2012\n",
      "Epoch 512/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1366 - val_loss: 7.9531\n",
      "Epoch 513/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0972 - val_loss: 7.6697\n",
      "Epoch 514/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0894 - val_loss: 7.6003\n",
      "Epoch 515/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0947 - val_loss: 7.7962\n",
      "Epoch 516/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1057 - val_loss: 8.0512\n",
      "Epoch 517/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0423 - val_loss: 7.7505\n",
      "Epoch 518/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.1930 - val_loss: 7.9863\n",
      "Epoch 519/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2715 - val_loss: 7.8589\n",
      "Epoch 520/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.0004 - val_loss: 7.8299\n",
      "Epoch 521/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.2243 - val_loss: 7.7979\n",
      "Epoch 522/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0581 - val_loss: 7.7314\n",
      "Epoch 523/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0195 - val_loss: 7.9856\n",
      "Epoch 524/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0860 - val_loss: 7.9547\n",
      "Epoch 525/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.0240 - val_loss: 7.9033\n",
      "Epoch 526/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0665 - val_loss: 7.9110\n",
      "Epoch 527/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 4.0934 - val_loss: 7.4268\n",
      "Epoch 528/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.0420 - val_loss: 7.7769\n",
      "Epoch 529/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0155 - val_loss: 7.7150\n",
      "Epoch 530/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.0731 - val_loss: 7.6257\n",
      "Epoch 531/1000\n",
      "274/274 [==============================] - 0s 153us/step - loss: 3.9751 - val_loss: 7.9293\n",
      "Epoch 532/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 4.0945 - val_loss: 7.8247\n",
      "Epoch 533/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.1402 - val_loss: 8.2732\n",
      "Epoch 534/1000\n",
      "274/274 [==============================] - 0s 135us/step - loss: 4.0603 - val_loss: 7.7502\n",
      "Epoch 535/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.0869 - val_loss: 7.7484\n",
      "Epoch 536/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.0644 - val_loss: 8.0589\n",
      "Epoch 537/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.0590 - val_loss: 7.6188\n",
      "Epoch 538/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.1580 - val_loss: 8.0009\n",
      "Epoch 539/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.0078 - val_loss: 8.0300\n",
      "Epoch 540/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.9611 - val_loss: 7.5957\n",
      "Epoch 541/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 3.9965 - val_loss: 7.6450\n",
      "Epoch 542/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.1087 - val_loss: 8.1202\n",
      "Epoch 543/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.0382 - val_loss: 7.8998\n",
      "Epoch 544/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.0105 - val_loss: 7.7933\n",
      "Epoch 545/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1242 - val_loss: 7.9918\n",
      "Epoch 546/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 3.9530 - val_loss: 8.1393\n",
      "Epoch 547/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.1028 - val_loss: 7.7280\n",
      "Epoch 548/1000\n",
      "274/274 [==============================] - 0s 149us/step - loss: 3.9665 - val_loss: 7.9582\n",
      "Epoch 549/1000\n",
      "274/274 [==============================] - 0s 135us/step - loss: 4.0754 - val_loss: 8.0267\n",
      "Epoch 550/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9431 - val_loss: 7.6821\n",
      "Epoch 551/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.0606 - val_loss: 7.7343\n",
      "Epoch 552/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 3.9791 - val_loss: 8.0630\n",
      "Epoch 553/1000\n",
      "274/274 [==============================] - 0s 133us/step - loss: 4.0240 - val_loss: 7.8634\n",
      "Epoch 554/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.1517 - val_loss: 7.8362\n",
      "Epoch 555/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2061 - val_loss: 8.0143\n",
      "Epoch 556/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1329 - val_loss: 7.5339\n",
      "Epoch 557/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1409 - val_loss: 8.5759\n",
      "Epoch 558/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2173 - val_loss: 8.0968\n",
      "Epoch 559/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0543 - val_loss: 8.4423\n",
      "Epoch 560/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1144 - val_loss: 7.8044\n",
      "Epoch 561/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 4.1857 - val_loss: 8.1441\n",
      "Epoch 562/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.9221 - val_loss: 7.7523\n",
      "Epoch 563/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9756 - val_loss: 7.7330\n",
      "Epoch 564/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0447 - val_loss: 7.7062\n",
      "Epoch 565/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1048 - val_loss: 8.3559\n",
      "Epoch 566/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3025 - val_loss: 8.0958\n",
      "Epoch 567/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9769 - val_loss: 8.2123\n",
      "Epoch 568/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0536 - val_loss: 7.7091\n",
      "Epoch 569/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0255 - val_loss: 7.7000\n",
      "Epoch 570/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.9831 - val_loss: 7.6744\n",
      "Epoch 571/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0935 - val_loss: 7.8480\n",
      "Epoch 572/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0548 - val_loss: 7.9642\n",
      "Epoch 573/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0582 - val_loss: 8.0402\n",
      "Epoch 574/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1521 - val_loss: 8.1610\n",
      "Epoch 575/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.0028 - val_loss: 7.9739\n",
      "Epoch 576/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9059 - val_loss: 8.2297\n",
      "Epoch 577/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0271 - val_loss: 8.0649\n",
      "Epoch 578/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.9917 - val_loss: 7.8389\n",
      "Epoch 579/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0591 - val_loss: 8.1680\n",
      "Epoch 580/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1202 - val_loss: 7.8274\n",
      "Epoch 581/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0310 - val_loss: 7.8952\n",
      "Epoch 582/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.0114 - val_loss: 8.2437\n",
      "Epoch 583/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0155 - val_loss: 7.7735\n",
      "Epoch 584/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0107 - val_loss: 8.5610\n",
      "Epoch 585/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1299 - val_loss: 7.9488\n",
      "Epoch 586/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0974 - val_loss: 8.0358\n",
      "Epoch 587/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.4960 - val_loss: 8.1833\n",
      "Epoch 588/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.9255 - val_loss: 8.2648\n",
      "Epoch 589/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3888 - val_loss: 8.8238\n",
      "Epoch 590/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.4311 - val_loss: 8.0531\n",
      "Epoch 591/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.1877 - val_loss: 7.9661\n",
      "Epoch 592/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1353 - val_loss: 8.2747\n",
      "Epoch 593/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2488 - val_loss: 8.3750\n",
      "Epoch 594/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.3111 - val_loss: 7.8068\n",
      "Epoch 595/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9487 - val_loss: 8.3292\n",
      "Epoch 596/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0277 - val_loss: 7.8956\n",
      "Epoch 597/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2101 - val_loss: 7.8674\n",
      "Epoch 598/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 3.8829 - val_loss: 8.0804\n",
      "Epoch 599/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0471 - val_loss: 8.2289\n",
      "Epoch 600/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 3.9018 - val_loss: 7.8702\n",
      "Epoch 601/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1301 - val_loss: 8.7697\n",
      "Epoch 602/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1571 - val_loss: 7.9382\n",
      "Epoch 603/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0123 - val_loss: 8.3126\n",
      "Epoch 604/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.9865 - val_loss: 8.3710\n",
      "Epoch 605/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.1734 - val_loss: 7.9636\n",
      "Epoch 606/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.8916 - val_loss: 7.7418\n",
      "Epoch 607/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9122 - val_loss: 8.0844\n",
      "Epoch 608/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.0143 - val_loss: 8.3386\n",
      "Epoch 609/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8965 - val_loss: 7.9882\n",
      "Epoch 610/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9940 - val_loss: 8.0730\n",
      "Epoch 611/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 4.0036 - val_loss: 8.3826\n",
      "Epoch 612/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.0304 - val_loss: 7.7828\n",
      "Epoch 613/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0549 - val_loss: 8.8563\n",
      "Epoch 614/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3853 - val_loss: 8.1036\n",
      "Epoch 615/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.0193 - val_loss: 8.4506\n",
      "Epoch 616/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9286 - val_loss: 7.9952\n",
      "Epoch 617/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9123 - val_loss: 8.0809\n",
      "Epoch 618/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8426 - val_loss: 7.8714\n",
      "Epoch 619/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 3.8638 - val_loss: 8.0559\n",
      "Epoch 620/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8966 - val_loss: 8.0777\n",
      "Epoch 621/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1080 - val_loss: 7.8527\n",
      "Epoch 622/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9738 - val_loss: 8.3791\n",
      "Epoch 623/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8454 - val_loss: 7.8060\n",
      "Epoch 624/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9961 - val_loss: 8.3271\n",
      "Epoch 625/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9506 - val_loss: 8.2581\n",
      "Epoch 626/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9676 - val_loss: 8.1905\n",
      "Epoch 627/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 3.8844 - val_loss: 8.1276\n",
      "Epoch 628/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 3.9659 - val_loss: 8.0333\n",
      "Epoch 629/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 3.9652 - val_loss: 8.0275\n",
      "Epoch 630/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8034 - val_loss: 8.1433\n",
      "Epoch 631/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9095 - val_loss: 8.3260\n",
      "Epoch 632/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8587 - val_loss: 8.0497\n",
      "Epoch 633/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9525 - val_loss: 8.0599\n",
      "Epoch 634/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9261 - val_loss: 8.0558\n",
      "Epoch 635/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8424 - val_loss: 8.5340\n",
      "Epoch 636/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.0054 - val_loss: 8.1136\n",
      "Epoch 637/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9868 - val_loss: 8.2793\n",
      "Epoch 638/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0129 - val_loss: 8.4355\n",
      "Epoch 639/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0550 - val_loss: 8.3299\n",
      "Epoch 640/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0902 - val_loss: 8.4772\n",
      "Epoch 641/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.8472 - val_loss: 8.3187\n",
      "Epoch 642/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9770 - val_loss: 8.2665\n",
      "Epoch 643/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9260 - val_loss: 8.1529\n",
      "Epoch 644/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8232 - val_loss: 8.3271\n",
      "Epoch 645/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8940 - val_loss: 8.2327\n",
      "Epoch 646/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7895 - val_loss: 8.2527\n",
      "Epoch 647/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9471 - val_loss: 8.1732\n",
      "Epoch 648/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.8421 - val_loss: 8.1624\n",
      "Epoch 649/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8197 - val_loss: 8.1666\n",
      "Epoch 650/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8687 - val_loss: 8.0704\n",
      "Epoch 651/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.7877 - val_loss: 8.0885\n",
      "Epoch 652/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9790 - val_loss: 8.6367\n",
      "Epoch 653/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8246 - val_loss: 8.0919\n",
      "Epoch 654/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0789 - val_loss: 9.4091\n",
      "Epoch 655/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.2987 - val_loss: 8.6878\n",
      "Epoch 656/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 3.9811 - val_loss: 8.6084\n",
      "Epoch 657/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8010 - val_loss: 8.2917\n",
      "Epoch 658/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9679 - val_loss: 8.3524\n",
      "Epoch 659/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8728 - val_loss: 8.0983\n",
      "Epoch 660/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.7559 - val_loss: 8.2247\n",
      "Epoch 661/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8180 - val_loss: 8.2493\n",
      "Epoch 662/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8343 - val_loss: 8.1321\n",
      "Epoch 663/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.8393 - val_loss: 8.5892\n",
      "Epoch 664/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.8863 - val_loss: 8.2151\n",
      "Epoch 665/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0721 - val_loss: 8.1268\n",
      "Epoch 666/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8965 - val_loss: 8.3561\n",
      "Epoch 667/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 3.8412 - val_loss: 8.2155\n",
      "Epoch 668/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.8674 - val_loss: 8.4488\n",
      "Epoch 669/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.0866 - val_loss: 8.3098\n",
      "Epoch 670/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0747 - val_loss: 8.9293\n",
      "Epoch 671/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0677 - val_loss: 8.4010\n",
      "Epoch 672/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.9625 - val_loss: 9.0238\n",
      "Epoch 673/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1752 - val_loss: 8.4563\n",
      "Epoch 674/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.2276 - val_loss: 8.6525\n",
      "Epoch 675/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1518 - val_loss: 8.0712\n",
      "Epoch 676/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 3.8362 - val_loss: 8.6924\n",
      "Epoch 677/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 3.7693 - val_loss: 8.3785\n",
      "Epoch 678/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7751 - val_loss: 8.2462\n",
      "Epoch 679/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8702 - val_loss: 8.3488\n",
      "Epoch 680/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8674 - val_loss: 8.6344\n",
      "Epoch 681/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9182 - val_loss: 9.0353\n",
      "Epoch 682/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.9454 - val_loss: 8.3680\n",
      "Epoch 683/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8583 - val_loss: 8.5021\n",
      "Epoch 684/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.0800 - val_loss: 8.6357\n",
      "Epoch 685/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 3.9020 - val_loss: 8.5158\n",
      "Epoch 686/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7861 - val_loss: 8.3589\n",
      "Epoch 687/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8337 - val_loss: 8.5882\n",
      "Epoch 688/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9573 - val_loss: 8.7713\n",
      "Epoch 689/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0287 - val_loss: 9.1340\n",
      "Epoch 690/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.9095 - val_loss: 8.6742\n",
      "Epoch 691/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1895 - val_loss: 8.8609\n",
      "Epoch 692/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3095 - val_loss: 8.6682\n",
      "Epoch 693/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9284 - val_loss: 8.5011\n",
      "Epoch 694/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.8008 - val_loss: 8.6536\n",
      "Epoch 695/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8368 - val_loss: 8.2861\n",
      "Epoch 696/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.7692 - val_loss: 8.7446\n",
      "Epoch 697/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7203 - val_loss: 8.6919\n",
      "Epoch 698/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.0039 - val_loss: 8.7632\n",
      "Epoch 699/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.0342 - val_loss: 9.3085\n",
      "Epoch 700/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0561 - val_loss: 8.7511\n",
      "Epoch 701/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8476 - val_loss: 9.0439\n",
      "Epoch 702/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.0524 - val_loss: 8.3255\n",
      "Epoch 703/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.9616 - val_loss: 8.3777\n",
      "Epoch 704/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8156 - val_loss: 8.6145\n",
      "Epoch 705/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8321 - val_loss: 8.5251\n",
      "Epoch 706/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1181 - val_loss: 9.7869\n",
      "Epoch 707/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2438 - val_loss: 8.4959\n",
      "Epoch 708/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.6962 - val_loss: 8.6242\n",
      "Epoch 709/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9504 - val_loss: 8.5308\n",
      "Epoch 710/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.8657 - val_loss: 8.5159\n",
      "Epoch 711/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7700 - val_loss: 8.5950\n",
      "Epoch 712/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8540 - val_loss: 8.4355\n",
      "Epoch 713/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.6814 - val_loss: 8.6340\n",
      "Epoch 714/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8403 - val_loss: 8.3943\n",
      "Epoch 715/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 3.7679 - val_loss: 8.6550\n",
      "Epoch 716/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 3.9538 - val_loss: 8.5993\n",
      "Epoch 717/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 3.7518 - val_loss: 8.8200\n",
      "Epoch 718/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 3.7663 - val_loss: 8.6750\n",
      "Epoch 719/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7909 - val_loss: 8.7416\n",
      "Epoch 720/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8930 - val_loss: 8.6711\n",
      "Epoch 721/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.6543 - val_loss: 8.7891\n",
      "Epoch 722/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8979 - val_loss: 8.7623\n",
      "Epoch 723/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7890 - val_loss: 8.5375\n",
      "Epoch 724/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 3.8064 - val_loss: 8.5034\n",
      "Epoch 725/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.7176 - val_loss: 8.7175\n",
      "Epoch 726/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8424 - val_loss: 8.5192\n",
      "Epoch 727/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8023 - val_loss: 8.5776\n",
      "Epoch 728/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.7455 - val_loss: 8.6627\n",
      "Epoch 729/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8851 - val_loss: 9.6074\n",
      "Epoch 730/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0915 - val_loss: 8.6415\n",
      "Epoch 731/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.7691 - val_loss: 8.6932\n",
      "Epoch 732/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7778 - val_loss: 8.6198\n",
      "Epoch 733/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8389 - val_loss: 8.9970\n",
      "Epoch 734/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.7259 - val_loss: 8.8202\n",
      "Epoch 735/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 3.8887 - val_loss: 8.6290\n",
      "Epoch 736/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7907 - val_loss: 8.8319\n",
      "Epoch 737/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7615 - val_loss: 8.6298\n",
      "Epoch 738/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.7917 - val_loss: 8.7621\n",
      "Epoch 739/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 3.8114 - val_loss: 8.5963\n",
      "Epoch 740/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8923 - val_loss: 9.0858\n",
      "Epoch 741/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.7859 - val_loss: 8.8008\n",
      "Epoch 742/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7678 - val_loss: 8.7831\n",
      "Epoch 743/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9646 - val_loss: 8.9176\n",
      "Epoch 744/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 3.8679 - val_loss: 8.8208\n",
      "Epoch 745/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7928 - val_loss: 9.0744\n",
      "Epoch 746/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8171 - val_loss: 8.6216\n",
      "Epoch 747/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.7750 - val_loss: 8.5811\n",
      "Epoch 748/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 3.7651 - val_loss: 8.9738\n",
      "Epoch 749/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 3.7625 - val_loss: 8.7414\n",
      "Epoch 750/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 3.6588 - val_loss: 8.5968\n",
      "Epoch 751/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.7590 - val_loss: 8.5447\n",
      "Epoch 752/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.7247 - val_loss: 8.9413\n",
      "Epoch 753/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.7036 - val_loss: 8.8517\n",
      "Epoch 754/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1126 - val_loss: 9.8409\n",
      "Epoch 755/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0221 - val_loss: 8.7746\n",
      "Epoch 756/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.8454 - val_loss: 8.6443\n",
      "Epoch 757/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7555 - val_loss: 8.6848\n",
      "Epoch 758/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.7594 - val_loss: 8.8004\n",
      "Epoch 759/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8028 - val_loss: 8.8254\n",
      "Epoch 760/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8052 - val_loss: 9.1302\n",
      "Epoch 761/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 3.7412 - val_loss: 8.7677\n",
      "Epoch 762/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.7984 - val_loss: 8.9254\n",
      "Epoch 763/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7809 - val_loss: 9.1264\n",
      "Epoch 764/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7134 - val_loss: 9.1473\n",
      "Epoch 765/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 106us/step - loss: 3.7950 - val_loss: 9.3505\n",
      "Epoch 766/1000\n",
      "274/274 [==============================] - 0s 146us/step - loss: 3.7507 - val_loss: 9.0154\n",
      "Epoch 767/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.7444 - val_loss: 9.5358\n",
      "Epoch 768/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.0216 - val_loss: 8.9744\n",
      "Epoch 769/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9131 - val_loss: 8.9035\n",
      "Epoch 770/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7422 - val_loss: 8.7820\n",
      "Epoch 771/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7059 - val_loss: 8.7413\n",
      "Epoch 772/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7213 - val_loss: 8.8025\n",
      "Epoch 773/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7332 - val_loss: 8.8856\n",
      "Epoch 774/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7320 - val_loss: 8.9660\n",
      "Epoch 775/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.7325 - val_loss: 8.9743\n",
      "Epoch 776/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.6820 - val_loss: 8.7414\n",
      "Epoch 777/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7199 - val_loss: 8.8824\n",
      "Epoch 778/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7630 - val_loss: 8.9022\n",
      "Epoch 779/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8213 - val_loss: 8.9255\n",
      "Epoch 780/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.7612 - val_loss: 8.7545\n",
      "Epoch 781/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7598 - val_loss: 8.7864\n",
      "Epoch 782/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.6267 - val_loss: 8.7769\n",
      "Epoch 783/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.6869 - val_loss: 8.9029\n",
      "Epoch 784/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.6714 - val_loss: 8.9527\n",
      "Epoch 785/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.6537 - val_loss: 8.7714\n",
      "Epoch 786/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7674 - val_loss: 8.8864\n",
      "Epoch 787/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.7605 - val_loss: 8.9180\n",
      "Epoch 788/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.6745 - val_loss: 8.8584\n",
      "Epoch 789/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.6928 - val_loss: 9.0048\n",
      "Epoch 790/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.7012 - val_loss: 8.8021\n",
      "Epoch 791/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.6825 - val_loss: 8.8887\n",
      "Epoch 792/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.7321 - val_loss: 8.8779\n",
      "Epoch 793/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 3.7059 - val_loss: 8.9663\n",
      "Epoch 794/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.6382 - val_loss: 9.0429\n",
      "Epoch 795/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8041 - val_loss: 9.0730\n",
      "Epoch 796/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8155 - val_loss: 8.8936\n",
      "Epoch 797/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9548 - val_loss: 10.0505\n",
      "Epoch 798/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9608 - val_loss: 9.7842\n",
      "Epoch 799/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8383 - val_loss: 10.0028\n",
      "Epoch 800/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8726 - val_loss: 8.7917\n",
      "Epoch 801/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.6942 - val_loss: 8.8116\n",
      "Epoch 802/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.6519 - val_loss: 9.0233\n",
      "Epoch 803/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.6445 - val_loss: 8.9087\n",
      "Epoch 804/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.6850 - val_loss: 8.9706\n",
      "Epoch 805/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.8170 - val_loss: 9.0519\n",
      "Epoch 806/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.6269 - val_loss: 9.3128\n",
      "Epoch 807/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.8073 - val_loss: 8.9017\n",
      "Epoch 808/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.6394 - val_loss: 9.0038\n",
      "Epoch 809/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.7502 - val_loss: 9.1715\n",
      "Epoch 810/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.7075 - val_loss: 8.8763\n",
      "Epoch 811/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 3.7581 - val_loss: 8.8845\n",
      "Epoch 812/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8120 - val_loss: 9.2111\n",
      "Epoch 813/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.6807 - val_loss: 9.0791\n",
      "Epoch 814/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7064 - val_loss: 9.0471\n",
      "Epoch 815/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8607 - val_loss: 9.1644\n",
      "Epoch 816/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.6011 - val_loss: 9.1070\n",
      "Epoch 817/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.7238 - val_loss: 9.1543\n",
      "Epoch 818/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.6938 - val_loss: 8.8281\n",
      "Epoch 819/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.6788 - val_loss: 8.8633\n",
      "Epoch 820/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7121 - val_loss: 8.8328\n",
      "Epoch 821/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.6757 - val_loss: 9.1045\n",
      "Epoch 822/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8021 - val_loss: 9.2015\n",
      "Epoch 823/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.7099 - val_loss: 8.9755\n",
      "Epoch 824/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 3.7535 - val_loss: 9.1924\n",
      "Epoch 825/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7920 - val_loss: 9.3557\n",
      "Epoch 826/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.7400 - val_loss: 9.2240\n",
      "Epoch 827/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8934 - val_loss: 8.9151\n",
      "Epoch 828/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.7803 - val_loss: 9.2933\n",
      "Epoch 829/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7063 - val_loss: 9.8432\n",
      "Epoch 830/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.9076 - val_loss: 9.2585\n",
      "Epoch 831/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.7389 - val_loss: 9.2105\n",
      "Epoch 832/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7847 - val_loss: 9.0082\n",
      "Epoch 833/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8368 - val_loss: 8.8018\n",
      "Epoch 834/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9275 - val_loss: 9.3112\n",
      "Epoch 835/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.8731 - val_loss: 9.4199\n",
      "Epoch 836/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.6098 - val_loss: 9.1810\n",
      "Epoch 837/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9106 - val_loss: 8.9957\n",
      "Epoch 838/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9640 - val_loss: 9.1141\n",
      "Epoch 839/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.8349 - val_loss: 9.0934\n",
      "Epoch 840/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7736 - val_loss: 9.1171\n",
      "Epoch 841/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.6435 - val_loss: 8.9268\n",
      "Epoch 842/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.8026 - val_loss: 9.0582\n",
      "Epoch 843/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 3.6654 - val_loss: 9.3387\n",
      "Epoch 844/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8420 - val_loss: 8.9697\n",
      "Epoch 845/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8215 - val_loss: 9.1573\n",
      "Epoch 846/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.7315 - val_loss: 9.2725\n",
      "Epoch 847/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8203 - val_loss: 9.0379\n",
      "Epoch 848/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7360 - val_loss: 9.2747\n",
      "Epoch 849/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7651 - val_loss: 9.1575\n",
      "Epoch 850/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.6431 - val_loss: 8.9217\n",
      "Epoch 851/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.6570 - val_loss: 9.1022\n",
      "Epoch 852/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.6796 - val_loss: 8.9100\n",
      "Epoch 853/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.6739 - val_loss: 9.0518\n",
      "Epoch 854/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8158 - val_loss: 9.1880\n",
      "Epoch 855/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.6255 - val_loss: 9.1454\n",
      "Epoch 856/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.6372 - val_loss: 9.0858\n",
      "Epoch 857/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.6581 - val_loss: 9.2239\n",
      "Epoch 858/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.6555 - val_loss: 9.0064\n",
      "Epoch 859/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.6095 - val_loss: 9.1056\n",
      "Epoch 860/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8059 - val_loss: 9.1305\n",
      "Epoch 861/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.6351 - val_loss: 9.1410\n",
      "Epoch 862/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.6167 - val_loss: 9.1143\n",
      "Epoch 863/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.6778 - val_loss: 9.2502\n",
      "Epoch 864/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.6975 - val_loss: 8.9963\n",
      "Epoch 865/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.6232 - val_loss: 8.9488\n",
      "Epoch 866/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.6711 - val_loss: 9.2985\n",
      "Epoch 867/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.6554 - val_loss: 9.1799\n",
      "Epoch 868/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.5897 - val_loss: 9.1575\n",
      "Epoch 869/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.6631 - val_loss: 9.3072\n",
      "Epoch 870/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.6593 - val_loss: 9.2580\n",
      "Epoch 871/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.6057 - val_loss: 9.2141\n",
      "Epoch 872/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.8689 - val_loss: 9.3423\n",
      "Epoch 873/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 3.7029 - val_loss: 9.1948\n",
      "Epoch 874/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.6298 - val_loss: 9.1368\n",
      "Epoch 875/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.7792 - val_loss: 9.3065\n",
      "Epoch 876/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7469 - val_loss: 9.2113\n",
      "Epoch 877/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.6157 - val_loss: 9.0620\n",
      "Epoch 878/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7688 - val_loss: 9.5004\n",
      "Epoch 879/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.6412 - val_loss: 9.1016\n",
      "Epoch 880/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.6142 - val_loss: 9.2464\n",
      "Epoch 881/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7986 - val_loss: 9.4121\n",
      "Epoch 882/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9396 - val_loss: 9.5680\n",
      "Epoch 883/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7377 - val_loss: 9.4908\n",
      "Epoch 884/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.7225 - val_loss: 9.2285\n",
      "Epoch 885/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.7742 - val_loss: 9.3955\n",
      "Epoch 886/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.9789 - val_loss: 9.0440\n",
      "Epoch 887/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.9113 - val_loss: 9.0280\n",
      "Epoch 888/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9600 - val_loss: 9.7161\n",
      "Epoch 889/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9195 - val_loss: 9.5300\n",
      "Epoch 890/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7995 - val_loss: 9.5570\n",
      "Epoch 891/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.0117 - val_loss: 9.9168\n",
      "Epoch 892/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7843 - val_loss: 9.5721\n",
      "Epoch 893/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.6188 - val_loss: 9.1172\n",
      "Epoch 894/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.6658 - val_loss: 9.2289\n",
      "Epoch 895/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.6428 - val_loss: 9.2632\n",
      "Epoch 896/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.5761 - val_loss: 9.1100\n",
      "Epoch 897/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.6552 - val_loss: 9.0947\n",
      "Epoch 898/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.6554 - val_loss: 9.2762\n",
      "Epoch 899/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.5522 - val_loss: 9.4303\n",
      "Epoch 900/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.6397 - val_loss: 9.2881\n",
      "Epoch 901/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7523 - val_loss: 9.2822\n",
      "Epoch 902/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8237 - val_loss: 9.7287\n",
      "Epoch 903/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 3.8883 - val_loss: 9.4828\n",
      "Epoch 904/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.6390 - val_loss: 9.2215\n",
      "Epoch 905/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.6963 - val_loss: 9.1067\n",
      "Epoch 906/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.7090 - val_loss: 9.4698\n",
      "Epoch 907/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 3.7585 - val_loss: 9.2947\n",
      "Epoch 908/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.7494 - val_loss: 9.2114\n",
      "Epoch 909/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.6813 - val_loss: 9.3074\n",
      "Epoch 910/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 3.6586 - val_loss: 9.2822\n",
      "Epoch 911/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.7099 - val_loss: 9.3539\n",
      "Epoch 912/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.6643 - val_loss: 9.3389\n",
      "Epoch 913/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 3.8236 - val_loss: 9.3824\n",
      "Epoch 914/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.7363 - val_loss: 9.1811\n",
      "Epoch 915/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.6375 - val_loss: 9.2309\n",
      "Epoch 916/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.6038 - val_loss: 9.0491\n",
      "Epoch 917/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.6628 - val_loss: 9.2525\n",
      "Epoch 918/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.6305 - val_loss: 9.2684\n",
      "Epoch 919/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 113us/step - loss: 3.8652 - val_loss: 9.2371\n",
      "Epoch 920/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.6782 - val_loss: 9.5324\n",
      "Epoch 921/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.6824 - val_loss: 9.4482\n",
      "Epoch 922/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.7099 - val_loss: 9.7418\n",
      "Epoch 923/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8316 - val_loss: 9.3837\n",
      "Epoch 924/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.6565 - val_loss: 9.3757\n",
      "Epoch 925/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.5885 - val_loss: 9.4463\n",
      "Epoch 926/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 3.6480 - val_loss: 9.3341\n",
      "Epoch 927/1000\n",
      "274/274 [==============================] - 0s 135us/step - loss: 3.6823 - val_loss: 9.3021\n",
      "Epoch 928/1000\n",
      "274/274 [==============================] - 0s 164us/step - loss: 3.6332 - val_loss: 9.4466\n",
      "Epoch 929/1000\n",
      "274/274 [==============================] - 0s 138us/step - loss: 3.7154 - val_loss: 9.4157\n",
      "Epoch 930/1000\n",
      "274/274 [==============================] - 0s 138us/step - loss: 3.6784 - val_loss: 9.5897\n",
      "Epoch 931/1000\n",
      "274/274 [==============================] - 0s 171us/step - loss: 3.6548 - val_loss: 9.4423\n",
      "Epoch 932/1000\n",
      "274/274 [==============================] - 0s 138us/step - loss: 3.6833 - val_loss: 9.3460\n",
      "Epoch 933/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 3.6757 - val_loss: 9.3645\n",
      "Epoch 934/1000\n",
      "274/274 [==============================] - 0s 153us/step - loss: 3.5877 - val_loss: 9.5061\n",
      "Epoch 935/1000\n",
      "274/274 [==============================] - 0s 142us/step - loss: 3.8021 - val_loss: 9.5573\n",
      "Epoch 936/1000\n",
      "274/274 [==============================] - 0s 142us/step - loss: 3.9580 - val_loss: 9.4492\n",
      "Epoch 937/1000\n",
      "274/274 [==============================] - 0s 142us/step - loss: 3.6626 - val_loss: 9.4209\n",
      "Epoch 938/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 3.5916 - val_loss: 9.5385\n",
      "Epoch 939/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 3.5834 - val_loss: 9.2509\n",
      "Epoch 940/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 3.6034 - val_loss: 9.2750\n",
      "Epoch 941/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 3.7470 - val_loss: 9.7037\n",
      "Epoch 942/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 3.6218 - val_loss: 9.2574\n",
      "Epoch 943/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.7080 - val_loss: 9.8622\n",
      "Epoch 944/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.7676 - val_loss: 9.7568\n",
      "Epoch 945/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 3.6450 - val_loss: 9.4886\n",
      "Epoch 946/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 3.7352 - val_loss: 9.9548\n",
      "Epoch 947/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 3.8238 - val_loss: 9.3474\n",
      "Epoch 948/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 3.7024 - val_loss: 9.3113\n",
      "Epoch 949/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 3.6343 - val_loss: 9.5462\n",
      "Epoch 950/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 3.5553 - val_loss: 9.4860\n",
      "Epoch 951/1000\n",
      "274/274 [==============================] - 0s 121us/step - loss: 3.5582 - val_loss: 9.6546\n",
      "Epoch 952/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 3.6221 - val_loss: 9.4985\n",
      "Epoch 953/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 3.5791 - val_loss: 9.5241\n",
      "Epoch 954/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 3.5496 - val_loss: 9.3480\n",
      "Epoch 955/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.5785 - val_loss: 9.2542\n",
      "Epoch 956/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 3.6483 - val_loss: 9.6900\n",
      "Epoch 957/1000\n",
      "274/274 [==============================] - 0s 119us/step - loss: 3.6206 - val_loss: 9.4246\n",
      "Epoch 958/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 3.5990 - val_loss: 9.4431\n",
      "Epoch 959/1000\n",
      "274/274 [==============================] - 0s 142us/step - loss: 3.6205 - val_loss: 9.3417\n",
      "Epoch 960/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 3.7302 - val_loss: 9.7561\n",
      "Epoch 961/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 3.8780 - val_loss: 9.6217\n",
      "Epoch 962/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 3.7749 - val_loss: 9.3089\n",
      "Epoch 963/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 3.6239 - val_loss: 9.1759\n",
      "Epoch 964/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 3.6815 - val_loss: 10.0171\n",
      "Epoch 965/1000\n",
      "274/274 [==============================] - 0s 122us/step - loss: 3.5896 - val_loss: 9.7806\n",
      "Epoch 966/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 3.6279 - val_loss: 9.6040\n",
      "Epoch 967/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 1.931 - 0s 131us/step - loss: 3.6020 - val_loss: 9.4894\n",
      "Epoch 968/1000\n",
      "274/274 [==============================] - 0s 129us/step - loss: 3.5648 - val_loss: 9.4838\n",
      "Epoch 969/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 3.7028 - val_loss: 9.2963\n",
      "Epoch 970/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.7404 - val_loss: 9.7063\n",
      "Epoch 971/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 3.5649 - val_loss: 9.6334\n",
      "Epoch 972/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.6432 - val_loss: 9.7663\n",
      "Epoch 973/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 3.6699 - val_loss: 9.5976\n",
      "Epoch 974/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 3.6756 - val_loss: 9.6336\n",
      "Epoch 975/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 3.6126 - val_loss: 9.5507\n",
      "Epoch 976/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 4.1746 - val_loss: 10.6337\n",
      "Epoch 977/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 3.9826 - val_loss: 10.2922\n",
      "Epoch 978/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 3.7865 - val_loss: 9.7615\n",
      "Epoch 979/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 3.5748 - val_loss: 9.3128\n",
      "Epoch 980/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 3.7077 - val_loss: 9.2823\n",
      "Epoch 981/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 3.6622 - val_loss: 9.8469\n",
      "Epoch 982/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.7880 - val_loss: 9.4003\n",
      "Epoch 983/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.5401 - val_loss: 9.4702\n",
      "Epoch 984/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 3.6545 - val_loss: 9.2585\n",
      "Epoch 985/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.6388 - val_loss: 9.2438\n",
      "Epoch 986/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 3.7774 - val_loss: 9.9197\n",
      "Epoch 987/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 3.6772 - val_loss: 9.7105\n",
      "Epoch 988/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 3.9166 - val_loss: 9.4818\n",
      "Epoch 989/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 3.6355 - val_loss: 9.4962\n",
      "Epoch 990/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.6730 - val_loss: 9.6833\n",
      "Epoch 991/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 3.5746 - val_loss: 9.5278\n",
      "Epoch 992/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.7996 - val_loss: 9.8693\n",
      "Epoch 993/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 3.6090 - val_loss: 9.7037\n",
      "Epoch 994/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.6415 - val_loss: 9.8380\n",
      "Epoch 995/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.6019 - val_loss: 9.7429\n",
      "Epoch 996/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 3.6484 - val_loss: 9.5708\n",
      "Epoch 997/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.6257 - val_loss: 9.5713\n",
      "Epoch 998/1000\n",
      "274/274 [==============================] - 0s 142us/step - loss: 3.6440 - val_loss: 9.7599\n",
      "Epoch 999/1000\n",
      "274/274 [==============================] - 0s 149us/step - loss: 3.5650 - val_loss: 9.9947\n",
      "Epoch 1000/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.6182 - val_loss: 9.5779\n",
      "5.947025654679638\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-1.8734475 , -6.421421  ,  1.161752  ,  2.4628744 ,  2.7281158 ,\n",
       "         -1.9099524 , -2.5594108 ,  0.44500044,  1.217952  ,  1.2142584 ],\n",
       "        [ 1.56422   ,  4.8801527 ,  0.98925483, -0.5478158 ,  0.21167165,\n",
       "          0.02454631, -1.5325325 , -0.60694724,  1.3101336 , -1.7040946 ],\n",
       "        [-0.69268596, -1.6563165 , -1.6078761 , -0.7843384 , -0.19719788,\n",
       "          2.7005916 ,  1.891307  ,  0.92202884,  1.8089575 ,  0.578264  ],\n",
       "        [ 0.8683333 , -2.7352185 , -0.48507917,  1.5071272 , -1.4074535 ,\n",
       "         -1.2575696 , -0.4500129 , -0.21918994,  0.09280241,  1.5180876 ],\n",
       "        [ 0.26187485, -0.46950328,  0.88803357, -0.529626  ,  1.1293739 ,\n",
       "         -0.64260375,  0.22745948,  0.8429583 ,  0.74788487, -0.75852484],\n",
       "        [-0.32987183,  0.989335  , -1.0137888 , -1.623535  , -1.3660762 ,\n",
       "          3.1294386 , -1.2221633 , -0.29628396,  1.0580381 ,  0.59780824],\n",
       "        [ 0.63854307,  1.3310467 ,  0.962137  ,  0.80481625, -1.597244  ,\n",
       "          3.5222404 , -0.16001269, -1.4843432 , -2.1224802 ,  0.45218903]],\n",
       "       dtype=float32),\n",
       " array([-1.2221187 , -1.4298719 , -1.5203328 , -2.1332057 ,  1.0819054 ,\n",
       "        -0.50259495, -2.3435142 , -2.1270611 ,  0.7073634 ,  1.8632048 ],\n",
       "       dtype=float32),\n",
       " array([[-1.243785  , -1.076223  , -0.34040347, -0.12323434,  0.7450822 ],\n",
       "        [ 0.7358539 ,  1.5720297 ,  1.533442  ,  1.3249596 , -1.0324407 ],\n",
       "        [ 0.6864308 ,  1.1208704 ,  0.7173965 ,  0.27248788, -0.7410657 ],\n",
       "        [-0.8899116 , -0.12172782, -0.81272167, -0.29009503,  0.2348561 ],\n",
       "        [ 0.95163274,  1.4945639 ,  1.2081532 ,  1.3338706 , -0.9220197 ],\n",
       "        [ 0.38800737,  0.6383836 ,  0.77123636,  0.18084407, -0.51251256],\n",
       "        [-1.3183177 , -1.0645678 , -0.6654197 , -0.69803584,  0.7231811 ],\n",
       "        [ 0.12735675, -0.8580386 , -0.49997038, -0.34085658,  0.5728251 ],\n",
       "        [-0.52069795, -0.9377524 , -0.5795348 , -0.00435355,  1.0361149 ],\n",
       "        [ 1.4888616 ,  1.0474386 ,  0.72484463,  1.013659  , -0.6517496 ]],\n",
       "       dtype=float32),\n",
       " array([ 1.5084114,  1.5116574,  1.5067322,  1.4767294, -1.4724089],\n",
       "       dtype=float32),\n",
       " array([[ 1.3001468],\n",
       "        [ 1.5443107],\n",
       "        [ 1.558795 ],\n",
       "        [ 1.1260175],\n",
       "        [-0.8599972]], dtype=float32),\n",
       " array([1.5203738], dtype=float32)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_autompg, history_autompg=NN_model_structure_regression_4(X_train_autompg, X_val_autompg, Y_train_autompg, Y_val_autompg, adam2, 32, 1000)\n",
    "model_autompg.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_autompg.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_autompg_structure4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_31 (Dense)             (None, 10)                80        \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 201\n",
      "Trainable params: 201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 274 samples, validate on 59 samples\n",
      "Epoch 1/1000\n",
      "274/274 [==============================] - 0s 1ms/step - loss: 456.3991 - val_loss: 231.3984\n",
      "Epoch 2/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 148.2440 - val_loss: 92.6170\n",
      "Epoch 3/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 48.0473 - val_loss: 48.6340\n",
      "Epoch 4/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 30.0418 - val_loss: 22.9195\n",
      "Epoch 5/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 21.3264 - val_loss: 19.4630\n",
      "Epoch 6/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 15.8198 - val_loss: 14.5918\n",
      "Epoch 7/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 13.1266 - val_loss: 13.1449\n",
      "Epoch 8/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 11.5821 - val_loss: 12.2108\n",
      "Epoch 9/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 9.8953 - val_loss: 11.5714\n",
      "Epoch 10/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 9.4003 - val_loss: 11.3183\n",
      "Epoch 11/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 9.0934 - val_loss: 11.1221\n",
      "Epoch 12/1000\n",
      "274/274 [==============================] - 0s 142us/step - loss: 8.8525 - val_loss: 10.7498\n",
      "Epoch 13/1000\n",
      "274/274 [==============================] - 0s 135us/step - loss: 8.4007 - val_loss: 10.7033\n",
      "Epoch 14/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 8.2186 - val_loss: 10.6680\n",
      "Epoch 15/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 8.0153 - val_loss: 10.3339\n",
      "Epoch 16/1000\n",
      "274/274 [==============================] - 0s 123us/step - loss: 7.9366 - val_loss: 10.2567\n",
      "Epoch 17/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 7.6812 - val_loss: 10.3005\n",
      "Epoch 18/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 7.6155 - val_loss: 10.1135\n",
      "Epoch 19/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 7.5557 - val_loss: 10.1855\n",
      "Epoch 20/1000\n",
      "274/274 [==============================] - 0s 593us/step - loss: 7.6529 - val_loss: 10.4505\n",
      "Epoch 21/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 7.7809 - val_loss: 9.8075\n",
      "Epoch 22/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 7.5300 - val_loss: 10.0737\n",
      "Epoch 23/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 7.2704 - val_loss: 9.6882\n",
      "Epoch 24/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 7.0976 - val_loss: 9.9512\n",
      "Epoch 25/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 7.0256 - val_loss: 9.7368\n",
      "Epoch 26/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 7.3044 - val_loss: 9.9531\n",
      "Epoch 27/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 6.8892 - val_loss: 9.8449\n",
      "Epoch 28/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 7.1764 - val_loss: 9.6892\n",
      "Epoch 29/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 6.9322 - val_loss: 9.7467\n",
      "Epoch 30/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 6.9212 - val_loss: 9.8647\n",
      "Epoch 31/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.9192 - val_loss: 9.7128\n",
      "Epoch 32/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 6.7097 - val_loss: 9.4847\n",
      "Epoch 33/1000\n",
      "274/274 [==============================] - 0s 167us/step - loss: 6.7286 - val_loss: 9.4355\n",
      "Epoch 34/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.6347 - val_loss: 9.4284\n",
      "Epoch 35/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6329 - val_loss: 9.3868\n",
      "Epoch 36/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.7837 - val_loss: 9.4058\n",
      "Epoch 37/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5408 - val_loss: 9.3913\n",
      "Epoch 38/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7929 - val_loss: 9.5028\n",
      "Epoch 39/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.5620 - val_loss: 9.8021\n",
      "Epoch 40/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.6711 - val_loss: 9.6360\n",
      "Epoch 41/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.6198 - val_loss: 9.5918\n",
      "Epoch 42/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6157 - val_loss: 9.3701\n",
      "Epoch 43/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4774 - val_loss: 9.4615\n",
      "Epoch 44/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4280 - val_loss: 9.0296\n",
      "Epoch 45/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.5095 - val_loss: 9.2968\n",
      "Epoch 46/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 6.4000 - val_loss: 9.6296\n",
      "Epoch 47/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8784 - val_loss: 9.2588\n",
      "Epoch 48/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7559 - val_loss: 9.2502\n",
      "Epoch 49/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.6730 - val_loss: 9.1486\n",
      "Epoch 50/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5399 - val_loss: 9.0619\n",
      "Epoch 51/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.1871 - val_loss: 9.0011\n",
      "Epoch 52/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1928 - val_loss: 8.8772\n",
      "Epoch 53/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1730 - val_loss: 8.9025\n",
      "Epoch 54/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.1804 - val_loss: 8.9196\n",
      "Epoch 55/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.2454 - val_loss: 8.9730\n",
      "Epoch 56/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1600 - val_loss: 8.7369\n",
      "Epoch 57/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1627 - val_loss: 8.7600\n",
      "Epoch 58/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3038 - val_loss: 9.1086\n",
      "Epoch 59/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3489 - val_loss: 8.8177\n",
      "Epoch 60/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5544 - val_loss: 8.7179\n",
      "Epoch 61/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2028 - val_loss: 8.4381\n",
      "Epoch 62/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.0958 - val_loss: 8.8859\n",
      "Epoch 63/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.3875 - val_loss: 8.3741\n",
      "Epoch 64/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.2303 - val_loss: 8.7520\n",
      "Epoch 65/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.2287 - val_loss: 8.4334\n",
      "Epoch 66/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0496 - val_loss: 8.8603\n",
      "Epoch 67/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2341 - val_loss: 8.6692\n",
      "Epoch 68/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0451 - val_loss: 8.7115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.0744 - val_loss: 8.5025\n",
      "Epoch 70/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3839 - val_loss: 8.8189\n",
      "Epoch 71/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6111 - val_loss: 8.9096\n",
      "Epoch 72/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6948 - val_loss: 8.5152\n",
      "Epoch 73/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0562 - val_loss: 8.4321\n",
      "Epoch 74/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.0234 - val_loss: 8.2808\n",
      "Epoch 75/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9929 - val_loss: 8.4918\n",
      "Epoch 76/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2376 - val_loss: 8.8814\n",
      "Epoch 77/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3296 - val_loss: 8.5071\n",
      "Epoch 78/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4519 - val_loss: 8.1580\n",
      "Epoch 79/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8903 - val_loss: 8.2115\n",
      "Epoch 80/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9019 - val_loss: 8.1566\n",
      "Epoch 81/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0061 - val_loss: 8.1647\n",
      "Epoch 82/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.9505 - val_loss: 8.1772\n",
      "Epoch 83/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9254 - val_loss: 8.4707\n",
      "Epoch 84/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1797 - val_loss: 8.4980\n",
      "Epoch 85/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9517 - val_loss: 8.0240\n",
      "Epoch 86/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.0778 - val_loss: 8.0097\n",
      "Epoch 87/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.9606 - val_loss: 8.5867\n",
      "Epoch 88/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.0755 - val_loss: 8.5228\n",
      "Epoch 89/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.0436 - val_loss: 8.1531\n",
      "Epoch 90/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7727 - val_loss: 8.0540\n",
      "Epoch 91/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9714 - val_loss: 8.2115\n",
      "Epoch 92/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.0838 - val_loss: 8.1202\n",
      "Epoch 93/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0992 - val_loss: 8.2601\n",
      "Epoch 94/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8487 - val_loss: 8.3174\n",
      "Epoch 95/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1230 - val_loss: 8.4225\n",
      "Epoch 96/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1497 - val_loss: 8.3394\n",
      "Epoch 97/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8770 - val_loss: 8.2139\n",
      "Epoch 98/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8397 - val_loss: 8.0002\n",
      "Epoch 99/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7826 - val_loss: 7.9972\n",
      "Epoch 100/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9011 - val_loss: 8.0789\n",
      "Epoch 101/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.9430 - val_loss: 8.0925\n",
      "Epoch 102/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7625 - val_loss: 8.2674\n",
      "Epoch 103/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7074 - val_loss: 7.9027\n",
      "Epoch 104/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9492 - val_loss: 7.9809\n",
      "Epoch 105/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7466 - val_loss: 8.0223\n",
      "Epoch 106/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.9955 - val_loss: 7.9758\n",
      "Epoch 107/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.7144 - val_loss: 7.9711\n",
      "Epoch 108/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8802 - val_loss: 8.3378\n",
      "Epoch 109/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8991 - val_loss: 8.6329\n",
      "Epoch 110/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8238 - val_loss: 8.1672\n",
      "Epoch 111/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6421 - val_loss: 8.0902\n",
      "Epoch 112/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7285 - val_loss: 7.9518\n",
      "Epoch 113/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6804 - val_loss: 7.9286\n",
      "Epoch 114/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.6636 - val_loss: 7.8983\n",
      "Epoch 115/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7666 - val_loss: 7.7883\n",
      "Epoch 116/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.6332 - val_loss: 8.0620\n",
      "Epoch 117/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.6712 - val_loss: 7.9576\n",
      "Epoch 118/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6899 - val_loss: 7.8558\n",
      "Epoch 119/1000\n",
      "274/274 [==============================] - 0s 211us/step - loss: 5.6219 - val_loss: 7.9269\n",
      "Epoch 120/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.7265 - val_loss: 8.1235\n",
      "Epoch 121/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8045 - val_loss: 7.9760\n",
      "Epoch 122/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 5.9984 - val_loss: 7.7593\n",
      "Epoch 123/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 5.6269 - val_loss: 7.7804\n",
      "Epoch 124/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6634 - val_loss: 7.9481\n",
      "Epoch 125/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6681 - val_loss: 7.8817\n",
      "Epoch 126/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7202 - val_loss: 8.1604\n",
      "Epoch 127/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6234 - val_loss: 7.9643\n",
      "Epoch 128/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6669 - val_loss: 8.0914\n",
      "Epoch 129/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.6839 - val_loss: 8.0238\n",
      "Epoch 130/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7391 - val_loss: 7.8172\n",
      "Epoch 131/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.7641 - val_loss: 7.8728\n",
      "Epoch 132/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.4717 - val_loss: 8.0779\n",
      "Epoch 133/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.6032 - val_loss: 8.5262\n",
      "Epoch 134/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.5469 - val_loss: 8.4248\n",
      "Epoch 135/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.9300 - val_loss: 8.5151\n",
      "Epoch 136/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0068 - val_loss: 8.0344\n",
      "Epoch 137/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6707 - val_loss: 8.6809\n",
      "Epoch 138/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8116 - val_loss: 8.5415\n",
      "Epoch 139/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7153 - val_loss: 8.1823\n",
      "Epoch 140/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6631 - val_loss: 8.1628\n",
      "Epoch 141/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6422 - val_loss: 7.8975\n",
      "Epoch 142/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8039 - val_loss: 8.1723\n",
      "Epoch 143/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5047 - val_loss: 7.9821\n",
      "Epoch 144/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6539 - val_loss: 7.9445\n",
      "Epoch 145/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.5821 - val_loss: 7.9052\n",
      "Epoch 146/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5945 - val_loss: 8.1801\n",
      "Epoch 147/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5071 - val_loss: 7.8542\n",
      "Epoch 148/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.5463 - val_loss: 7.8883\n",
      "Epoch 149/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5394 - val_loss: 7.9728\n",
      "Epoch 150/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5337 - val_loss: 7.9722\n",
      "Epoch 151/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5296 - val_loss: 8.1453\n",
      "Epoch 152/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5069 - val_loss: 8.1354\n",
      "Epoch 153/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7565 - val_loss: 8.3209\n",
      "Epoch 154/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8433 - val_loss: 8.6605\n",
      "Epoch 155/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.5205 - val_loss: 8.3997\n",
      "Epoch 156/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8082 - val_loss: 7.9662\n",
      "Epoch 157/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9291 - val_loss: 8.2199\n",
      "Epoch 158/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.6593 - val_loss: 8.2949\n",
      "Epoch 159/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6064 - val_loss: 8.2067\n",
      "Epoch 160/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.5625 - val_loss: 7.7589\n",
      "Epoch 161/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6464 - val_loss: 7.8126\n",
      "Epoch 162/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5366 - val_loss: 8.0654\n",
      "Epoch 163/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5176 - val_loss: 8.1331\n",
      "Epoch 164/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5589 - val_loss: 7.9103\n",
      "Epoch 165/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4948 - val_loss: 7.9378\n",
      "Epoch 166/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3209 - val_loss: 7.9747\n",
      "Epoch 167/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3931 - val_loss: 7.7562\n",
      "Epoch 168/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4110 - val_loss: 7.8065\n",
      "Epoch 169/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4473 - val_loss: 7.7109\n",
      "Epoch 170/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3652 - val_loss: 8.2411\n",
      "Epoch 171/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4553 - val_loss: 8.0553\n",
      "Epoch 172/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4592 - val_loss: 8.1048\n",
      "Epoch 173/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.4038 - val_loss: 7.9333\n",
      "Epoch 174/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.3627 - val_loss: 7.9381\n",
      "Epoch 175/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 5.3771 - val_loss: 8.0915\n",
      "Epoch 176/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4398 - val_loss: 8.0203\n",
      "Epoch 177/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5387 - val_loss: 7.9497\n",
      "Epoch 178/1000\n",
      "274/274 [==============================] - 0s 149us/step - loss: 5.4791 - val_loss: 7.8559\n",
      "Epoch 179/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 5.4060 - val_loss: 7.9524\n",
      "Epoch 180/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3357 - val_loss: 7.9108\n",
      "Epoch 181/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4004 - val_loss: 8.0718\n",
      "Epoch 182/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.6874 - val_loss: 8.0053\n",
      "Epoch 183/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7388 - val_loss: 8.1741\n",
      "Epoch 184/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8249 - val_loss: 8.4855\n",
      "Epoch 185/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6894 - val_loss: 8.1790\n",
      "Epoch 186/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.6880 - val_loss: 7.8566\n",
      "Epoch 187/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6422 - val_loss: 8.4604\n",
      "Epoch 188/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.5812 - val_loss: 8.7033\n",
      "Epoch 189/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5975 - val_loss: 8.0976\n",
      "Epoch 190/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.2766 - val_loss: 8.3819\n",
      "Epoch 191/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4666 - val_loss: 8.2909\n",
      "Epoch 192/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6604 - val_loss: 8.4683\n",
      "Epoch 193/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.3254 - val_loss: 8.3817\n",
      "Epoch 194/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6068 - val_loss: 8.5314\n",
      "Epoch 195/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 5.4732 - val_loss: 8.3219\n",
      "Epoch 196/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.5916 - val_loss: 8.3071\n",
      "Epoch 197/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.5138 - val_loss: 8.1394\n",
      "Epoch 198/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.3976 - val_loss: 8.2870\n",
      "Epoch 199/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.3430 - val_loss: 8.0255\n",
      "Epoch 200/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.3904 - val_loss: 7.9586\n",
      "Epoch 201/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5309 - val_loss: 8.2392\n",
      "Epoch 202/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4466 - val_loss: 8.2781\n",
      "Epoch 203/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2701 - val_loss: 8.3433\n",
      "Epoch 204/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.4467 - val_loss: 8.2201\n",
      "Epoch 205/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5538 - val_loss: 8.0604\n",
      "Epoch 206/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6592 - val_loss: 8.0818\n",
      "Epoch 207/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4797 - val_loss: 7.9877\n",
      "Epoch 208/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.4456 - val_loss: 8.1858\n",
      "Epoch 209/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3356 - val_loss: 8.1483\n",
      "Epoch 210/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3949 - val_loss: 8.3333\n",
      "Epoch 211/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2831 - val_loss: 8.1267\n",
      "Epoch 212/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3514 - val_loss: 7.9052\n",
      "Epoch 213/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2967 - val_loss: 8.1256\n",
      "Epoch 214/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5777 - val_loss: 8.2652\n",
      "Epoch 215/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2736 - val_loss: 8.4438\n",
      "Epoch 216/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.4054 - val_loss: 7.9563\n",
      "Epoch 217/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3608 - val_loss: 8.1027\n",
      "Epoch 218/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3497 - val_loss: 8.1883\n",
      "Epoch 219/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4419 - val_loss: 8.1528\n",
      "Epoch 220/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2716 - val_loss: 8.1108\n",
      "Epoch 221/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2953 - val_loss: 7.9834\n",
      "Epoch 222/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2565 - val_loss: 7.8780\n",
      "Epoch 223/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 95us/step - loss: 5.2858 - val_loss: 8.2997\n",
      "Epoch 224/1000\n",
      "274/274 [==============================] - 0s 115us/step - loss: 5.2582 - val_loss: 8.1034\n",
      "Epoch 225/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3997 - val_loss: 8.1096\n",
      "Epoch 226/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2980 - val_loss: 8.2123\n",
      "Epoch 227/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4284 - val_loss: 8.1367\n",
      "Epoch 228/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2567 - val_loss: 8.1453\n",
      "Epoch 229/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3472 - val_loss: 8.0794\n",
      "Epoch 230/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.2085 - val_loss: 8.1586\n",
      "Epoch 231/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.2700 - val_loss: 7.9606\n",
      "Epoch 232/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3354 - val_loss: 8.0870\n",
      "Epoch 233/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2680 - val_loss: 8.0325\n",
      "Epoch 234/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2609 - val_loss: 8.1094\n",
      "Epoch 235/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3468 - val_loss: 8.1318\n",
      "Epoch 236/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2889 - val_loss: 8.1547\n",
      "Epoch 237/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3491 - val_loss: 8.0315\n",
      "Epoch 238/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3867 - val_loss: 8.0113\n",
      "Epoch 239/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6982 - val_loss: 7.8608\n",
      "Epoch 240/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6383 - val_loss: 8.2382\n",
      "Epoch 241/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2228 - val_loss: 8.2356\n",
      "Epoch 242/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 5.2653 - val_loss: 8.3697\n",
      "Epoch 243/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1926 - val_loss: 8.3638\n",
      "Epoch 244/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3425 - val_loss: 8.1935\n",
      "Epoch 245/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3799 - val_loss: 8.2183\n",
      "Epoch 246/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3967 - val_loss: 8.0843\n",
      "Epoch 247/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3324 - val_loss: 8.4039\n",
      "Epoch 248/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3118 - val_loss: 8.3008\n",
      "Epoch 249/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1837 - val_loss: 8.1689\n",
      "Epoch 250/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.2166 - val_loss: 8.0887\n",
      "Epoch 251/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1911 - val_loss: 8.0738\n",
      "Epoch 252/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1901 - val_loss: 8.1501\n",
      "Epoch 253/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2850 - val_loss: 8.3253\n",
      "Epoch 254/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1566 - val_loss: 8.0630\n",
      "Epoch 255/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1765 - val_loss: 8.1227\n",
      "Epoch 256/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2533 - val_loss: 7.9775\n",
      "Epoch 257/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3283 - val_loss: 8.2414\n",
      "Epoch 258/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4764 - val_loss: 8.4619\n",
      "Epoch 259/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3462 - val_loss: 8.3040\n",
      "Epoch 260/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2172 - val_loss: 8.2366\n",
      "Epoch 261/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3782 - val_loss: 8.1756\n",
      "Epoch 262/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3549 - val_loss: 8.0255\n",
      "Epoch 263/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2555 - val_loss: 8.3480\n",
      "Epoch 264/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.1353 - val_loss: 8.3418\n",
      "Epoch 265/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.1442 - val_loss: 8.3696\n",
      "Epoch 266/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1828 - val_loss: 8.3377\n",
      "Epoch 267/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1184 - val_loss: 8.1447\n",
      "Epoch 268/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.2153 - val_loss: 8.2251\n",
      "Epoch 269/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4098 - val_loss: 8.2674\n",
      "Epoch 270/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2856 - val_loss: 8.2460\n",
      "Epoch 271/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3402 - val_loss: 8.2054\n",
      "Epoch 272/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 5.2719 - val_loss: 8.1537\n",
      "Epoch 273/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.0953 - val_loss: 8.4704\n",
      "Epoch 274/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1782 - val_loss: 8.5178\n",
      "Epoch 275/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3204 - val_loss: 8.4481\n",
      "Epoch 276/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2475 - val_loss: 8.1846\n",
      "Epoch 277/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.1944 - val_loss: 8.3066\n",
      "Epoch 278/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2051 - val_loss: 8.4720\n",
      "Epoch 279/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1910 - val_loss: 8.4079\n",
      "Epoch 280/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2121 - val_loss: 8.4300\n",
      "Epoch 281/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2271 - val_loss: 8.4853\n",
      "Epoch 282/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5137 - val_loss: 8.5902\n",
      "Epoch 283/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2254 - val_loss: 8.2690\n",
      "Epoch 284/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.1747 - val_loss: 8.4390\n",
      "Epoch 285/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2600 - val_loss: 8.9314\n",
      "Epoch 286/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.4944 - val_loss: 8.3022\n",
      "Epoch 287/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2001 - val_loss: 8.2658\n",
      "Epoch 288/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.0340 - val_loss: 8.1006\n",
      "Epoch 289/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1438 - val_loss: 8.1695\n",
      "Epoch 290/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1245 - val_loss: 8.3186\n",
      "Epoch 291/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.1408 - val_loss: 8.3257\n",
      "Epoch 292/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3357 - val_loss: 8.7361\n",
      "Epoch 293/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3099 - val_loss: 8.6871\n",
      "Epoch 294/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2323 - val_loss: 8.3423\n",
      "Epoch 295/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2476 - val_loss: 8.0647\n",
      "Epoch 296/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2533 - val_loss: 8.1393\n",
      "Epoch 297/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0758 - val_loss: 8.3402\n",
      "Epoch 298/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.1044 - val_loss: 8.4976\n",
      "Epoch 299/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.0585 - val_loss: 8.5232\n",
      "Epoch 300/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1485 - val_loss: 8.4505\n",
      "Epoch 301/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.0729 - val_loss: 8.3398\n",
      "Epoch 302/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.1291 - val_loss: 8.1490\n",
      "Epoch 303/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4650 - val_loss: 8.4962\n",
      "Epoch 304/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5434 - val_loss: 8.4385\n",
      "Epoch 305/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.2512 - val_loss: 8.4397\n",
      "Epoch 306/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 5.0569 - val_loss: 8.3854\n",
      "Epoch 307/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.9932 - val_loss: 8.3849\n",
      "Epoch 308/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1926 - val_loss: 8.7492\n",
      "Epoch 309/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 5.2582 - val_loss: 8.3829\n",
      "Epoch 310/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1213 - val_loss: 8.2097\n",
      "Epoch 311/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.0544 - val_loss: 8.6839\n",
      "Epoch 312/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0987 - val_loss: 8.5029\n",
      "Epoch 313/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2455 - val_loss: 8.4026\n",
      "Epoch 314/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.1196 - val_loss: 8.5725\n",
      "Epoch 315/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4577 - val_loss: 8.5546\n",
      "Epoch 316/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1291 - val_loss: 8.3772\n",
      "Epoch 317/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.0946 - val_loss: 8.3195\n",
      "Epoch 318/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0684 - val_loss: 8.4611\n",
      "Epoch 319/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.2330 - val_loss: 8.2921\n",
      "Epoch 320/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1833 - val_loss: 8.2363\n",
      "Epoch 321/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1792 - val_loss: 8.1827\n",
      "Epoch 322/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0333 - val_loss: 8.3765\n",
      "Epoch 323/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0732 - val_loss: 8.1883\n",
      "Epoch 324/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0483 - val_loss: 8.3640\n",
      "Epoch 325/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.0672 - val_loss: 8.3166\n",
      "Epoch 326/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.9961 - val_loss: 8.2650\n",
      "Epoch 327/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.9894 - val_loss: 8.2886\n",
      "Epoch 328/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.9791 - val_loss: 8.4432\n",
      "Epoch 329/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.9810 - val_loss: 8.4661\n",
      "Epoch 330/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.0145 - val_loss: 8.2974\n",
      "Epoch 331/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 5.0341 - val_loss: 8.3233\n",
      "Epoch 332/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3061 - val_loss: 8.7034\n",
      "Epoch 333/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.0678 - val_loss: 8.6790\n",
      "Epoch 334/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9410 - val_loss: 8.3256\n",
      "Epoch 335/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0120 - val_loss: 8.2142\n",
      "Epoch 336/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.0192 - val_loss: 8.4113\n",
      "Epoch 337/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1114 - val_loss: 8.6185\n",
      "Epoch 338/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0299 - val_loss: 8.3416\n",
      "Epoch 339/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.0528 - val_loss: 8.2019\n",
      "Epoch 340/1000\n",
      "274/274 [==============================] - 0s 115us/step - loss: 4.9878 - val_loss: 8.4013\n",
      "Epoch 341/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.1717 - val_loss: 8.4031\n",
      "Epoch 342/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.9538 - val_loss: 9.0828\n",
      "Epoch 343/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1714 - val_loss: 8.6570\n",
      "Epoch 344/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.1334 - val_loss: 8.3169\n",
      "Epoch 345/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.0028 - val_loss: 8.4953\n",
      "Epoch 346/1000\n",
      "274/274 [==============================] - 0s 115us/step - loss: 5.0632 - val_loss: 8.4358\n",
      "Epoch 347/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1645 - val_loss: 8.7103\n",
      "Epoch 348/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1591 - val_loss: 8.9286\n",
      "Epoch 349/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3403 - val_loss: 9.7098\n",
      "Epoch 350/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6900 - val_loss: 9.4185\n",
      "Epoch 351/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4065 - val_loss: 9.0393\n",
      "Epoch 352/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.1762 - val_loss: 9.1140\n",
      "Epoch 353/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1847 - val_loss: 8.9343\n",
      "Epoch 354/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1946 - val_loss: 9.0002\n",
      "Epoch 355/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1640 - val_loss: 8.6312\n",
      "Epoch 356/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.9138 - val_loss: 8.6220\n",
      "Epoch 357/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9726 - val_loss: 8.4774\n",
      "Epoch 358/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9072 - val_loss: 8.6098\n",
      "Epoch 359/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.9194 - val_loss: 8.5997\n",
      "Epoch 360/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8452 - val_loss: 8.6104\n",
      "Epoch 361/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0144 - val_loss: 8.5694\n",
      "Epoch 362/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0916 - val_loss: 8.8089\n",
      "Epoch 363/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1568 - val_loss: 8.7667\n",
      "Epoch 364/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.2965 - val_loss: 8.9817\n",
      "Epoch 365/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.4564 - val_loss: 9.0354\n",
      "Epoch 366/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4166 - val_loss: 8.5469\n",
      "Epoch 367/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9060 - val_loss: 8.7662\n",
      "Epoch 368/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8713 - val_loss: 8.4938\n",
      "Epoch 369/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0159 - val_loss: 8.3738\n",
      "Epoch 370/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.3618 - val_loss: 8.6422\n",
      "Epoch 371/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.1119 - val_loss: 8.6760\n",
      "Epoch 372/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.2249 - val_loss: 8.4399\n",
      "Epoch 373/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9189 - val_loss: 8.3363\n",
      "Epoch 374/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9203 - val_loss: 8.5178\n",
      "Epoch 375/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0236 - val_loss: 8.6821\n",
      "Epoch 376/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.9358 - val_loss: 8.8211\n",
      "Epoch 377/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 109us/step - loss: 4.9208 - val_loss: 8.5961\n",
      "Epoch 378/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7999 - val_loss: 8.5287\n",
      "Epoch 379/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9856 - val_loss: 8.6835\n",
      "Epoch 380/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9718 - val_loss: 8.5471\n",
      "Epoch 381/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.7970 - val_loss: 8.4566\n",
      "Epoch 382/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8562 - val_loss: 8.1388\n",
      "Epoch 383/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8530 - val_loss: 8.5416\n",
      "Epoch 384/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1592 - val_loss: 8.9409\n",
      "Epoch 385/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.9279 - val_loss: 8.6379\n",
      "Epoch 386/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8738 - val_loss: 8.5829\n",
      "Epoch 387/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8658 - val_loss: 8.5962\n",
      "Epoch 388/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7913 - val_loss: 8.8915\n",
      "Epoch 389/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7752 - val_loss: 8.7973\n",
      "Epoch 390/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8649 - val_loss: 8.8002\n",
      "Epoch 391/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.8294 - val_loss: 8.5828\n",
      "Epoch 392/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.8224 - val_loss: 8.6712\n",
      "Epoch 393/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.8966 - val_loss: 8.6292\n",
      "Epoch 394/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7954 - val_loss: 8.6728\n",
      "Epoch 395/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0458 - val_loss: 8.9757\n",
      "Epoch 396/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.2227 - val_loss: 8.8043\n",
      "Epoch 397/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8430 - val_loss: 8.8019\n",
      "Epoch 398/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.7979 - val_loss: 8.5990\n",
      "Epoch 399/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7811 - val_loss: 8.5662\n",
      "Epoch 400/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7730 - val_loss: 8.6905\n",
      "Epoch 401/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8226 - val_loss: 8.6770\n",
      "Epoch 402/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7735 - val_loss: 8.9408\n",
      "Epoch 403/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 4.8173 - val_loss: 8.8228\n",
      "Epoch 404/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8924 - val_loss: 8.5090\n",
      "Epoch 405/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.8067 - val_loss: 8.6395\n",
      "Epoch 406/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.7932 - val_loss: 8.7448\n",
      "Epoch 407/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7609 - val_loss: 8.8775\n",
      "Epoch 408/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9023 - val_loss: 8.7868\n",
      "Epoch 409/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7545 - val_loss: 8.8641\n",
      "Epoch 410/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8526 - val_loss: 8.5819\n",
      "Epoch 411/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.8901 - val_loss: 8.7589\n",
      "Epoch 412/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8034 - val_loss: 9.0160\n",
      "Epoch 413/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9307 - val_loss: 8.5608\n",
      "Epoch 414/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.8926 - val_loss: 8.6127\n",
      "Epoch 415/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9728 - val_loss: 8.8665\n",
      "Epoch 416/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.7753 - val_loss: 8.7616\n",
      "Epoch 417/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.7835 - val_loss: 8.9083\n",
      "Epoch 418/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.9379 - val_loss: 8.7295\n",
      "Epoch 419/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7697 - val_loss: 8.5705\n",
      "Epoch 420/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.7832 - val_loss: 8.6630\n",
      "Epoch 421/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7330 - val_loss: 8.8094\n",
      "Epoch 422/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8112 - val_loss: 8.7213\n",
      "Epoch 423/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.9815 - val_loss: 9.4062\n",
      "Epoch 424/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.1984 - val_loss: 9.1283\n",
      "Epoch 425/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8832 - val_loss: 8.7926\n",
      "Epoch 426/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0649 - val_loss: 9.0382\n",
      "Epoch 427/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.9527 - val_loss: 9.0348\n",
      "Epoch 428/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9689 - val_loss: 8.8877\n",
      "Epoch 429/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7458 - val_loss: 8.8834\n",
      "Epoch 430/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6790 - val_loss: 8.8011\n",
      "Epoch 431/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9085 - val_loss: 8.8203\n",
      "Epoch 432/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7184 - val_loss: 8.7261\n",
      "Epoch 433/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7786 - val_loss: 8.6562\n",
      "Epoch 434/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8348 - val_loss: 8.6251\n",
      "Epoch 435/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8308 - val_loss: 8.7739\n",
      "Epoch 436/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7432 - val_loss: 9.0690\n",
      "Epoch 437/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.0772 - val_loss: 9.3669\n",
      "Epoch 438/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.1204 - val_loss: 9.6367\n",
      "Epoch 439/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4321 - val_loss: 9.4376\n",
      "Epoch 440/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1324 - val_loss: 9.7495\n",
      "Epoch 441/1000\n",
      "274/274 [==============================] - 0s 117us/step - loss: 5.0259 - val_loss: 9.0891\n",
      "Epoch 442/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.0844 - val_loss: 8.6034\n",
      "Epoch 443/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 4.8181 - val_loss: 8.6350\n",
      "Epoch 444/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8268 - val_loss: 8.6874\n",
      "Epoch 445/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6920 - val_loss: 8.6966\n",
      "Epoch 446/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7230 - val_loss: 8.8935\n",
      "Epoch 447/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6913 - val_loss: 8.6566\n",
      "Epoch 448/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7617 - val_loss: 8.8083\n",
      "Epoch 449/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.7089 - val_loss: 8.9559\n",
      "Epoch 450/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.7850 - val_loss: 8.8480\n",
      "Epoch 451/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9061 - val_loss: 8.6469\n",
      "Epoch 452/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.8070 - val_loss: 8.8616\n",
      "Epoch 453/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.7066 - val_loss: 8.7771\n",
      "Epoch 454/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8526 - val_loss: 8.9594\n",
      "Epoch 455/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8642 - val_loss: 8.7621\n",
      "Epoch 456/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0166 - val_loss: 9.0635\n",
      "Epoch 457/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.1530 - val_loss: 9.0055\n",
      "Epoch 458/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.1582 - val_loss: 9.0186\n",
      "Epoch 459/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8617 - val_loss: 8.6003\n",
      "Epoch 460/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7637 - val_loss: 8.7790\n",
      "Epoch 461/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7128 - val_loss: 8.9410\n",
      "Epoch 462/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.8851 - val_loss: 9.1360\n",
      "Epoch 463/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7917 - val_loss: 9.0003\n",
      "Epoch 464/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.7393 - val_loss: 8.8751\n",
      "Epoch 465/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7248 - val_loss: 8.8202\n",
      "Epoch 466/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.7293 - val_loss: 8.8303\n",
      "Epoch 467/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6189 - val_loss: 8.8361\n",
      "Epoch 468/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7046 - val_loss: 8.7538\n",
      "Epoch 469/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.6521 - val_loss: 9.0629\n",
      "Epoch 470/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7871 - val_loss: 8.7275\n",
      "Epoch 471/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9467 - val_loss: 8.7276\n",
      "Epoch 472/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8664 - val_loss: 8.8678\n",
      "Epoch 473/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.6009 - val_loss: 8.6116\n",
      "Epoch 474/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.7448 - val_loss: 8.5929\n",
      "Epoch 475/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6577 - val_loss: 9.1167\n",
      "Epoch 476/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.7409 - val_loss: 8.8247\n",
      "Epoch 477/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.7021 - val_loss: 8.6217\n",
      "Epoch 478/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.7428 - val_loss: 9.0535\n",
      "Epoch 479/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6812 - val_loss: 9.0879\n",
      "Epoch 480/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7361 - val_loss: 8.8834\n",
      "Epoch 481/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6612 - val_loss: 8.9662\n",
      "Epoch 482/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6007 - val_loss: 8.9132\n",
      "Epoch 483/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5611 - val_loss: 8.9391\n",
      "Epoch 484/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.6998 - val_loss: 9.1017\n",
      "Epoch 485/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.9766 - val_loss: 9.5426\n",
      "Epoch 486/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.9880 - val_loss: 9.1959\n",
      "Epoch 487/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.6979 - val_loss: 8.9856\n",
      "Epoch 488/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.6020 - val_loss: 9.0785\n",
      "Epoch 489/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7119 - val_loss: 8.7370\n",
      "Epoch 490/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.7467 - val_loss: 8.9497\n",
      "Epoch 491/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5883 - val_loss: 9.2374\n",
      "Epoch 492/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7160 - val_loss: 9.3035\n",
      "Epoch 493/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0113 - val_loss: 9.1919\n",
      "Epoch 494/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.5663 - val_loss: 9.0605\n",
      "Epoch 495/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6406 - val_loss: 8.9174\n",
      "Epoch 496/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.6790 - val_loss: 9.0138\n",
      "Epoch 497/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.7076 - val_loss: 8.9131\n",
      "Epoch 498/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.5951 - val_loss: 8.9741\n",
      "Epoch 499/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 4.5528 - val_loss: 8.9706\n",
      "Epoch 500/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6080 - val_loss: 9.2101\n",
      "Epoch 501/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6804 - val_loss: 8.8075\n",
      "Epoch 502/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9344 - val_loss: 8.8078\n",
      "Epoch 503/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7471 - val_loss: 9.3504\n",
      "Epoch 504/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8302 - val_loss: 9.1448\n",
      "Epoch 505/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6447 - val_loss: 8.7050\n",
      "Epoch 506/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6712 - val_loss: 9.0666\n",
      "Epoch 507/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.6508 - val_loss: 9.0748\n",
      "Epoch 508/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.8135 - val_loss: 9.3850\n",
      "Epoch 509/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.6663 - val_loss: 8.8170\n",
      "Epoch 510/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.6508 - val_loss: 9.1873\n",
      "Epoch 511/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6123 - val_loss: 9.0503\n",
      "Epoch 512/1000\n",
      "274/274 [==============================] - 0s 117us/step - loss: 4.5996 - val_loss: 9.2579\n",
      "Epoch 513/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.6806 - val_loss: 9.2095\n",
      "Epoch 514/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.7355 - val_loss: 9.1666\n",
      "Epoch 515/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.9227 - val_loss: 8.9851\n",
      "Epoch 516/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5813 - val_loss: 9.2344\n",
      "Epoch 517/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.5319 - val_loss: 8.9613\n",
      "Epoch 518/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.7164 - val_loss: 8.7521\n",
      "Epoch 519/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5931 - val_loss: 8.8018\n",
      "Epoch 520/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5836 - val_loss: 9.2015\n",
      "Epoch 521/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7794 - val_loss: 9.2899\n",
      "Epoch 522/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.7203 - val_loss: 9.5199\n",
      "Epoch 523/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6072 - val_loss: 9.0654\n",
      "Epoch 524/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6259 - val_loss: 9.2069\n",
      "Epoch 525/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6136 - val_loss: 9.4998\n",
      "Epoch 526/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7115 - val_loss: 9.0025\n",
      "Epoch 527/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6270 - val_loss: 8.8955\n",
      "Epoch 528/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5258 - val_loss: 8.7509\n",
      "Epoch 529/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7409 - val_loss: 9.0299\n",
      "Epoch 530/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5269 - val_loss: 9.1873\n",
      "Epoch 531/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 106us/step - loss: 4.5727 - val_loss: 8.8775\n",
      "Epoch 532/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6018 - val_loss: 9.1001\n",
      "Epoch 533/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.5837 - val_loss: 9.1844\n",
      "Epoch 534/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5463 - val_loss: 9.0217\n",
      "Epoch 535/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.7627 - val_loss: 9.0490\n",
      "Epoch 536/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6522 - val_loss: 9.1114\n",
      "Epoch 537/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5244 - val_loss: 9.3211\n",
      "Epoch 538/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6063 - val_loss: 9.2372\n",
      "Epoch 539/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7855 - val_loss: 9.1567\n",
      "Epoch 540/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.6017 - val_loss: 8.8265\n",
      "Epoch 541/1000\n",
      "274/274 [==============================] - 0s 117us/step - loss: 4.5430 - val_loss: 9.1281\n",
      "Epoch 542/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 4.5819 - val_loss: 9.0315\n",
      "Epoch 543/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.5913 - val_loss: 8.9073\n",
      "Epoch 544/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.9359 - val_loss: 9.7062\n",
      "Epoch 545/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.9547 - val_loss: 9.3332\n",
      "Epoch 546/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 4.6740 - val_loss: 8.9811\n",
      "Epoch 547/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.5576 - val_loss: 9.2874\n",
      "Epoch 548/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.5796 - val_loss: 9.0175\n",
      "Epoch 549/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.6795 - val_loss: 9.1634\n",
      "Epoch 550/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.4982 - val_loss: 9.0809\n",
      "Epoch 551/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.6883 - val_loss: 8.9332\n",
      "Epoch 552/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.4525 - val_loss: 8.9902\n",
      "Epoch 553/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.5691 - val_loss: 9.2853\n",
      "Epoch 554/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 4.6380 - val_loss: 9.2459\n",
      "Epoch 555/1000\n",
      "274/274 [==============================] - 0s 142us/step - loss: 4.5686 - val_loss: 8.8621\n",
      "Epoch 556/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.5506 - val_loss: 8.9261\n",
      "Epoch 557/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.7054 - val_loss: 9.0124\n",
      "Epoch 558/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.6246 - val_loss: 9.4465\n",
      "Epoch 559/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.4681 - val_loss: 8.9296\n",
      "Epoch 560/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.5548 - val_loss: 8.9891\n",
      "Epoch 561/1000\n",
      "274/274 [==============================] - 0s 115us/step - loss: 4.5276 - val_loss: 9.0784\n",
      "Epoch 562/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.5425 - val_loss: 8.9800\n",
      "Epoch 563/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.5050 - val_loss: 8.7979\n",
      "Epoch 564/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 4.6083 - val_loss: 9.2687\n",
      "Epoch 565/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7006 - val_loss: 9.1708\n",
      "Epoch 566/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.6633 - val_loss: 9.0373\n",
      "Epoch 567/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 4.7192 - val_loss: 8.9199\n",
      "Epoch 568/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.4493 - val_loss: 8.9457\n",
      "Epoch 569/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5573 - val_loss: 8.6905\n",
      "Epoch 570/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5544 - val_loss: 9.1464\n",
      "Epoch 571/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6717 - val_loss: 9.0397\n",
      "Epoch 572/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8528 - val_loss: 9.7062\n",
      "Epoch 573/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.7210 - val_loss: 9.8202\n",
      "Epoch 574/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.8260 - val_loss: 9.7079\n",
      "Epoch 575/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0348 - val_loss: 9.0184\n",
      "Epoch 576/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.6399 - val_loss: 9.0880\n",
      "Epoch 577/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.5463 - val_loss: 9.1756\n",
      "Epoch 578/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5262 - val_loss: 9.0612\n",
      "Epoch 579/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5465 - val_loss: 9.0597\n",
      "Epoch 580/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6033 - val_loss: 9.0823\n",
      "Epoch 581/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.6713 - val_loss: 9.2623\n",
      "Epoch 582/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5128 - val_loss: 9.0257\n",
      "Epoch 583/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6197 - val_loss: 8.8721\n",
      "Epoch 584/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.5573 - val_loss: 9.2743\n",
      "Epoch 585/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.6756 - val_loss: 9.0501\n",
      "Epoch 586/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4441 - val_loss: 9.2810\n",
      "Epoch 587/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4759 - val_loss: 9.0973\n",
      "Epoch 588/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.4534 - val_loss: 8.9674\n",
      "Epoch 589/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4591 - val_loss: 8.9709\n",
      "Epoch 590/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4765 - val_loss: 9.1829\n",
      "Epoch 591/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.4912 - val_loss: 9.3731\n",
      "Epoch 592/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.4641 - val_loss: 9.0899\n",
      "Epoch 593/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.4504 - val_loss: 9.3853\n",
      "Epoch 594/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6217 - val_loss: 9.2483\n",
      "Epoch 595/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7818 - val_loss: 9.0860\n",
      "Epoch 596/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7447 - val_loss: 9.4798\n",
      "Epoch 597/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.6096 - val_loss: 9.5647\n",
      "Epoch 598/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6568 - val_loss: 9.1773\n",
      "Epoch 599/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.4969 - val_loss: 8.8635\n",
      "Epoch 600/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4699 - val_loss: 9.0731\n",
      "Epoch 601/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.5639 - val_loss: 9.2489\n",
      "Epoch 602/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7129 - val_loss: 9.5082\n",
      "Epoch 603/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9310 - val_loss: 9.3778\n",
      "Epoch 604/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.0724 - val_loss: 9.1492\n",
      "Epoch 605/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.7519 - val_loss: 9.0037\n",
      "Epoch 606/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4842 - val_loss: 8.8915\n",
      "Epoch 607/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4598 - val_loss: 9.0829\n",
      "Epoch 608/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.4453 - val_loss: 9.2984\n",
      "Epoch 609/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5254 - val_loss: 9.2376\n",
      "Epoch 610/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.4845 - val_loss: 8.8094\n",
      "Epoch 611/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.4539 - val_loss: 9.0589\n",
      "Epoch 612/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.6465 - val_loss: 8.9729\n",
      "Epoch 613/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4617 - val_loss: 8.7547\n",
      "Epoch 614/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.5245 - val_loss: 9.1929\n",
      "Epoch 615/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.7264 - val_loss: 9.2390\n",
      "Epoch 616/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7429 - val_loss: 8.8807\n",
      "Epoch 617/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6145 - val_loss: 9.3379\n",
      "Epoch 618/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7573 - val_loss: 9.2078\n",
      "Epoch 619/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 4.5295 - val_loss: 9.1496\n",
      "Epoch 620/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4898 - val_loss: 8.9943\n",
      "Epoch 621/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4470 - val_loss: 8.9020\n",
      "Epoch 622/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5351 - val_loss: 9.0117\n",
      "Epoch 623/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 4.5246 - val_loss: 9.2055\n",
      "Epoch 624/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8038 - val_loss: 9.5943\n",
      "Epoch 625/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.6545 - val_loss: 9.1097\n",
      "Epoch 626/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5062 - val_loss: 9.0122\n",
      "Epoch 627/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.4884 - val_loss: 9.2835\n",
      "Epoch 628/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.4568 - val_loss: 9.0764\n",
      "Epoch 629/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.3794 - val_loss: 8.9013\n",
      "Epoch 630/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.4354 - val_loss: 9.1319\n",
      "Epoch 631/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4437 - val_loss: 9.0066\n",
      "Epoch 632/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.5390 - val_loss: 9.1305\n",
      "Epoch 633/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4499 - val_loss: 8.9444\n",
      "Epoch 634/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.5214 - val_loss: 9.1973\n",
      "Epoch 635/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 4.5061 - val_loss: 9.1304\n",
      "Epoch 636/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6700 - val_loss: 9.2921\n",
      "Epoch 637/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.6064 - val_loss: 9.4473\n",
      "Epoch 638/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4982 - val_loss: 9.2863\n",
      "Epoch 639/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4726 - val_loss: 9.1944\n",
      "Epoch 640/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.4089 - val_loss: 9.1952\n",
      "Epoch 641/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.5021 - val_loss: 9.0467\n",
      "Epoch 642/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.6493 - val_loss: 9.0194\n",
      "Epoch 643/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5141 - val_loss: 9.1497\n",
      "Epoch 644/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4313 - val_loss: 9.1079\n",
      "Epoch 645/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.4692 - val_loss: 9.1927\n",
      "Epoch 646/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3976 - val_loss: 9.1332\n",
      "Epoch 647/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4121 - val_loss: 9.1062\n",
      "Epoch 648/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5072 - val_loss: 9.2323\n",
      "Epoch 649/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4636 - val_loss: 8.9866\n",
      "Epoch 650/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4491 - val_loss: 8.9354\n",
      "Epoch 651/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3410 - val_loss: 9.0739\n",
      "Epoch 652/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4110 - val_loss: 9.1143\n",
      "Epoch 653/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3754 - val_loss: 9.3631\n",
      "Epoch 654/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3500 - val_loss: 9.3730\n",
      "Epoch 655/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3725 - val_loss: 9.1849\n",
      "Epoch 656/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4563 - val_loss: 9.4794\n",
      "Epoch 657/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6024 - val_loss: 9.1595\n",
      "Epoch 658/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4443 - val_loss: 9.1737\n",
      "Epoch 659/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4125 - val_loss: 9.3436\n",
      "Epoch 660/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4056 - val_loss: 9.3494\n",
      "Epoch 661/1000\n",
      "274/274 [==============================] - 0s 138us/step - loss: 4.4624 - val_loss: 9.1021\n",
      "Epoch 662/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.4633 - val_loss: 9.0371\n",
      "Epoch 663/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.4908 - val_loss: 9.1005\n",
      "Epoch 664/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.5344 - val_loss: 8.9697\n",
      "Epoch 665/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.7100 - val_loss: 9.3474\n",
      "Epoch 666/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.4896 - val_loss: 9.2839\n",
      "Epoch 667/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6321 - val_loss: 9.1777\n",
      "Epoch 668/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.5147 - val_loss: 9.1696\n",
      "Epoch 669/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5167 - val_loss: 9.4009\n",
      "Epoch 670/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1410 - val_loss: 9.9228\n",
      "Epoch 671/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9989 - val_loss: 9.7460\n",
      "Epoch 672/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8168 - val_loss: 9.1516\n",
      "Epoch 673/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3751 - val_loss: 9.0612\n",
      "Epoch 674/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7312 - val_loss: 9.3224\n",
      "Epoch 675/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7047 - val_loss: 9.5603\n",
      "Epoch 676/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9114 - val_loss: 9.2688\n",
      "Epoch 677/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4483 - val_loss: 9.3525\n",
      "Epoch 678/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.6487 - val_loss: 8.9858\n",
      "Epoch 679/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.4183 - val_loss: 8.9246\n",
      "Epoch 680/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.5466 - val_loss: 9.3846\n",
      "Epoch 681/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2915 - val_loss: 9.3493\n",
      "Epoch 682/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5037 - val_loss: 9.3771\n",
      "Epoch 683/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.3695 - val_loss: 9.0304\n",
      "Epoch 684/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4435 - val_loss: 9.0575\n",
      "Epoch 685/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 4.3488 - val_loss: 9.2215\n",
      "Epoch 686/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3486 - val_loss: 8.9846\n",
      "Epoch 687/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4385 - val_loss: 9.0553\n",
      "Epoch 688/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4061 - val_loss: 9.0579\n",
      "Epoch 689/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5062 - val_loss: 9.6327\n",
      "Epoch 690/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6085 - val_loss: 9.4062\n",
      "Epoch 691/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5312 - val_loss: 9.1395\n",
      "Epoch 692/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4196 - val_loss: 9.0061\n",
      "Epoch 693/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.3132 - val_loss: 9.1523\n",
      "Epoch 694/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2972 - val_loss: 8.9396\n",
      "Epoch 695/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3039 - val_loss: 9.0946\n",
      "Epoch 696/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4272 - val_loss: 9.1243\n",
      "Epoch 697/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3440 - val_loss: 9.1491\n",
      "Epoch 698/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.4059 - val_loss: 9.2185\n",
      "Epoch 699/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2781 - val_loss: 9.1008\n",
      "Epoch 700/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2902 - val_loss: 9.6216\n",
      "Epoch 701/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6204 - val_loss: 9.7336\n",
      "Epoch 702/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.5913 - val_loss: 8.9844\n",
      "Epoch 703/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.3697 - val_loss: 8.9195\n",
      "Epoch 704/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.3386 - val_loss: 9.2684\n",
      "Epoch 705/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 4.4419 - val_loss: 9.2259\n",
      "Epoch 706/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4211 - val_loss: 9.2895\n",
      "Epoch 707/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3252 - val_loss: 9.2204\n",
      "Epoch 708/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.4087 - val_loss: 9.1971\n",
      "Epoch 709/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5455 - val_loss: 9.2227\n",
      "Epoch 710/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3297 - val_loss: 9.1971\n",
      "Epoch 711/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3379 - val_loss: 9.4195\n",
      "Epoch 712/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.4138 - val_loss: 9.4543\n",
      "Epoch 713/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6226 - val_loss: 9.0527\n",
      "Epoch 714/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6217 - val_loss: 9.0480\n",
      "Epoch 715/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6303 - val_loss: 9.2565\n",
      "Epoch 716/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5177 - val_loss: 9.2455\n",
      "Epoch 717/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4736 - val_loss: 8.8753\n",
      "Epoch 718/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3617 - val_loss: 9.4145\n",
      "Epoch 719/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3911 - val_loss: 9.1603\n",
      "Epoch 720/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2663 - val_loss: 9.1639\n",
      "Epoch 721/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4876 - val_loss: 9.3064\n",
      "Epoch 722/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3480 - val_loss: 9.3305\n",
      "Epoch 723/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.5551 - val_loss: 9.2451\n",
      "Epoch 724/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3448 - val_loss: 8.9682\n",
      "Epoch 725/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2870 - val_loss: 9.1867\n",
      "Epoch 726/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.2820 - val_loss: 9.4784\n",
      "Epoch 727/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3057 - val_loss: 9.2308\n",
      "Epoch 728/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2276 - val_loss: 9.2135\n",
      "Epoch 729/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5075 - val_loss: 9.1201\n",
      "Epoch 730/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3031 - val_loss: 9.1365\n",
      "Epoch 731/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4655 - val_loss: 9.1264\n",
      "Epoch 732/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.4227 - val_loss: 9.0074\n",
      "Epoch 733/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.4006 - val_loss: 9.5137\n",
      "Epoch 734/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7364 - val_loss: 10.1140\n",
      "Epoch 735/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 4.6946 - val_loss: 9.0571\n",
      "Epoch 736/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.2719 - val_loss: 9.0005\n",
      "Epoch 737/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2763 - val_loss: 9.1118\n",
      "Epoch 738/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.2984 - val_loss: 9.1987\n",
      "Epoch 739/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.3991 - val_loss: 9.1773\n",
      "Epoch 740/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3380 - val_loss: 9.0090\n",
      "Epoch 741/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2609 - val_loss: 9.0016\n",
      "Epoch 742/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.4447 - val_loss: 9.0233\n",
      "Epoch 743/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4368 - val_loss: 9.6293\n",
      "Epoch 744/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4671 - val_loss: 9.2433\n",
      "Epoch 745/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2877 - val_loss: 8.8284\n",
      "Epoch 746/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3434 - val_loss: 8.9293\n",
      "Epoch 747/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2887 - val_loss: 9.2830\n",
      "Epoch 748/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.2777 - val_loss: 9.3243\n",
      "Epoch 749/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4482 - val_loss: 9.5987\n",
      "Epoch 750/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5432 - val_loss: 9.3191\n",
      "Epoch 751/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.5608 - val_loss: 9.0322\n",
      "Epoch 752/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2435 - val_loss: 9.1674\n",
      "Epoch 753/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3149 - val_loss: 9.1521\n",
      "Epoch 754/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3111 - val_loss: 9.2206\n",
      "Epoch 755/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.2735 - val_loss: 9.1665\n",
      "Epoch 756/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.5878 - val_loss: 9.8335\n",
      "Epoch 757/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8402 - val_loss: 8.9751\n",
      "Epoch 758/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3374 - val_loss: 9.1840\n",
      "Epoch 759/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3539 - val_loss: 9.1206\n",
      "Epoch 760/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.2494 - val_loss: 8.9989\n",
      "Epoch 761/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.2193 - val_loss: 8.9879\n",
      "Epoch 762/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2849 - val_loss: 9.0445\n",
      "Epoch 763/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2364 - val_loss: 9.0334\n",
      "Epoch 764/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2996 - val_loss: 9.3086\n",
      "Epoch 765/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2633 - val_loss: 9.0061\n",
      "Epoch 766/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2791 - val_loss: 9.2377\n",
      "Epoch 767/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2324 - val_loss: 9.2167\n",
      "Epoch 768/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4057 - val_loss: 9.4581\n",
      "Epoch 769/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4622 - val_loss: 9.1963\n",
      "Epoch 770/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2559 - val_loss: 9.1779\n",
      "Epoch 771/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4095 - val_loss: 9.3371\n",
      "Epoch 772/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4215 - val_loss: 9.2238\n",
      "Epoch 773/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5241 - val_loss: 9.6397\n",
      "Epoch 774/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4303 - val_loss: 9.1873\n",
      "Epoch 775/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3156 - val_loss: 9.5575\n",
      "Epoch 776/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.3969 - val_loss: 9.6057\n",
      "Epoch 777/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4115 - val_loss: 9.2498\n",
      "Epoch 778/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2137 - val_loss: 9.1631\n",
      "Epoch 779/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.2949 - val_loss: 8.8976\n",
      "Epoch 780/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.2875 - val_loss: 9.4499\n",
      "Epoch 781/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.4002 - val_loss: 9.2930\n",
      "Epoch 782/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.2195 - val_loss: 9.0253\n",
      "Epoch 783/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.3129 - val_loss: 9.2884\n",
      "Epoch 784/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3639 - val_loss: 9.2436\n",
      "Epoch 785/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.4195 - val_loss: 9.2668\n",
      "Epoch 786/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2200 - val_loss: 9.0084\n",
      "Epoch 787/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.4156 - val_loss: 9.0555\n",
      "Epoch 788/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.6263 - val_loss: 9.7737\n",
      "Epoch 789/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3032 - val_loss: 9.0476\n",
      "Epoch 790/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3966 - val_loss: 8.8835\n",
      "Epoch 791/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3342 - val_loss: 8.9844\n",
      "Epoch 792/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2551 - val_loss: 9.1394\n",
      "Epoch 793/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3691 - val_loss: 9.3554\n",
      "Epoch 794/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5269 - val_loss: 9.3439\n",
      "Epoch 795/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.4112 - val_loss: 9.9090\n",
      "Epoch 796/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4951 - val_loss: 9.0665\n",
      "Epoch 797/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.3517 - val_loss: 9.2491\n",
      "Epoch 798/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3610 - val_loss: 9.1949\n",
      "Epoch 799/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2600 - val_loss: 9.4553\n",
      "Epoch 800/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2363 - val_loss: 9.2604\n",
      "Epoch 801/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2446 - val_loss: 9.1755\n",
      "Epoch 802/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1579 - val_loss: 9.4039\n",
      "Epoch 803/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.1688 - val_loss: 9.3176\n",
      "Epoch 804/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.1613 - val_loss: 8.9680\n",
      "Epoch 805/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.1673 - val_loss: 9.1334\n",
      "Epoch 806/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1911 - val_loss: 9.0943\n",
      "Epoch 807/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2886 - val_loss: 9.1559\n",
      "Epoch 808/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3582 - val_loss: 9.4760\n",
      "Epoch 809/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1995 - val_loss: 9.0966\n",
      "Epoch 810/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2597 - val_loss: 9.4009\n",
      "Epoch 811/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3494 - val_loss: 9.3848\n",
      "Epoch 812/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1857 - val_loss: 9.2104\n",
      "Epoch 813/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3248 - val_loss: 9.3681\n",
      "Epoch 814/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4388 - val_loss: 9.2342\n",
      "Epoch 815/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.4403 - val_loss: 9.5703\n",
      "Epoch 816/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7160 - val_loss: 10.3823\n",
      "Epoch 817/1000\n",
      "274/274 [==============================] - 0s 115us/step - loss: 4.7305 - val_loss: 9.3597\n",
      "Epoch 818/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4388 - val_loss: 9.3166\n",
      "Epoch 819/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.2365 - val_loss: 9.3910\n",
      "Epoch 820/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5937 - val_loss: 9.5997\n",
      "Epoch 821/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.2016 - val_loss: 9.4381\n",
      "Epoch 822/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2443 - val_loss: 9.2336\n",
      "Epoch 823/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3689 - val_loss: 9.2536\n",
      "Epoch 824/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.4039 - val_loss: 9.7124\n",
      "Epoch 825/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.1800 - val_loss: 9.0028\n",
      "Epoch 826/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 4.2185 - val_loss: 9.4445\n",
      "Epoch 827/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2123 - val_loss: 9.2136\n",
      "Epoch 828/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.3940 - val_loss: 9.1327\n",
      "Epoch 829/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.4081 - val_loss: 9.7307\n",
      "Epoch 830/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.6244 - val_loss: 9.6278\n",
      "Epoch 831/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.1796 - val_loss: 9.4296\n",
      "Epoch 832/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3219 - val_loss: 8.9378\n",
      "Epoch 833/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.3152 - val_loss: 9.3306\n",
      "Epoch 834/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.6255 - val_loss: 10.0061\n",
      "Epoch 835/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 4.5731 - val_loss: 9.6657\n",
      "Epoch 836/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7396 - val_loss: 10.1779\n",
      "Epoch 837/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.4733 - val_loss: 9.5438\n",
      "Epoch 838/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6747 - val_loss: 9.2816\n",
      "Epoch 839/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 116us/step - loss: 4.2153 - val_loss: 9.0466\n",
      "Epoch 840/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2366 - val_loss: 8.9588\n",
      "Epoch 841/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6293 - val_loss: 9.9120\n",
      "Epoch 842/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.9465 - val_loss: 9.3457\n",
      "Epoch 843/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3303 - val_loss: 9.8750\n",
      "Epoch 844/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1508 - val_loss: 9.2852\n",
      "Epoch 845/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4677 - val_loss: 9.3099\n",
      "Epoch 846/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 4.2034 - val_loss: 9.1575\n",
      "Epoch 847/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2736 - val_loss: 9.1798\n",
      "Epoch 848/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.2011 - val_loss: 9.7429\n",
      "Epoch 849/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.2951 - val_loss: 9.3353\n",
      "Epoch 850/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7893 - val_loss: 10.1856\n",
      "Epoch 851/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4210 - val_loss: 9.3866\n",
      "Epoch 852/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.2710 - val_loss: 9.5377\n",
      "Epoch 853/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.1962 - val_loss: 9.1451\n",
      "Epoch 854/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1745 - val_loss: 9.3723\n",
      "Epoch 855/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1826 - val_loss: 9.3472\n",
      "Epoch 856/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2076 - val_loss: 9.3396\n",
      "Epoch 857/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2451 - val_loss: 9.8516\n",
      "Epoch 858/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.2912 - val_loss: 9.1851\n",
      "Epoch 859/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.3242 - val_loss: 9.2778\n",
      "Epoch 860/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2532 - val_loss: 9.4077\n",
      "Epoch 861/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.1867 - val_loss: 8.9902\n",
      "Epoch 862/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0924 - val_loss: 9.8216\n",
      "Epoch 863/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1303 - val_loss: 9.4698\n",
      "Epoch 864/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.3387 - val_loss: 9.4269\n",
      "Epoch 865/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.1867 - val_loss: 9.2197\n",
      "Epoch 866/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2113 - val_loss: 9.5113\n",
      "Epoch 867/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1765 - val_loss: 9.5223\n",
      "Epoch 868/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2086 - val_loss: 9.1125\n",
      "Epoch 869/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.0852 - val_loss: 9.5731\n",
      "Epoch 870/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.1240 - val_loss: 9.4085\n",
      "Epoch 871/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.3177 - val_loss: 9.4927\n",
      "Epoch 872/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2613 - val_loss: 9.4163\n",
      "Epoch 873/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1196 - val_loss: 9.3295\n",
      "Epoch 874/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.3608 - val_loss: 9.4429\n",
      "Epoch 875/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.1672 - val_loss: 9.2112\n",
      "Epoch 876/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.2368 - val_loss: 9.7521\n",
      "Epoch 877/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 4.1925 - val_loss: 9.4083\n",
      "Epoch 878/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.1187 - val_loss: 9.6458\n",
      "Epoch 879/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1863 - val_loss: 9.1490\n",
      "Epoch 880/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1314 - val_loss: 9.6692\n",
      "Epoch 881/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0330 - val_loss: 9.4220\n",
      "Epoch 882/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1492 - val_loss: 9.3679\n",
      "Epoch 883/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.3276 - val_loss: 9.2210\n",
      "Epoch 884/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.1736 - val_loss: 9.3618\n",
      "Epoch 885/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1082 - val_loss: 9.1759\n",
      "Epoch 886/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0114 - val_loss: 10.2152\n",
      "Epoch 887/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.4238 - val_loss: 9.8515\n",
      "Epoch 888/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2493 - val_loss: 10.1780\n",
      "Epoch 889/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3952 - val_loss: 9.3814\n",
      "Epoch 890/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1235 - val_loss: 9.9253\n",
      "Epoch 891/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.1020 - val_loss: 9.1657\n",
      "Epoch 892/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.0801 - val_loss: 9.5731\n",
      "Epoch 893/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2492 - val_loss: 9.5337\n",
      "Epoch 894/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2203 - val_loss: 10.3005\n",
      "Epoch 895/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.2054 - val_loss: 9.5425\n",
      "Epoch 896/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1071 - val_loss: 9.4963\n",
      "Epoch 897/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1888 - val_loss: 9.5321\n",
      "Epoch 898/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.1760 - val_loss: 9.3088\n",
      "Epoch 899/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1183 - val_loss: 9.4946\n",
      "Epoch 900/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0905 - val_loss: 9.4765\n",
      "Epoch 901/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.1345 - val_loss: 9.2780\n",
      "Epoch 902/1000\n",
      "274/274 [==============================] - 0s 115us/step - loss: 4.2806 - val_loss: 9.2903\n",
      "Epoch 903/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0633 - val_loss: 9.3578\n",
      "Epoch 904/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.9962 - val_loss: 9.6229\n",
      "Epoch 905/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1587 - val_loss: 9.5480\n",
      "Epoch 906/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0777 - val_loss: 9.4150\n",
      "Epoch 907/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3307 - val_loss: 9.9733\n",
      "Epoch 908/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3212 - val_loss: 9.1139\n",
      "Epoch 909/1000\n",
      "274/274 [==============================] - 0s 117us/step - loss: 4.2481 - val_loss: 9.7363\n",
      "Epoch 910/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1041 - val_loss: 9.6645\n",
      "Epoch 911/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0225 - val_loss: 9.3869\n",
      "Epoch 912/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0003 - val_loss: 9.4331\n",
      "Epoch 913/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0689 - val_loss: 9.4117\n",
      "Epoch 914/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1030 - val_loss: 9.4305\n",
      "Epoch 915/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0917 - val_loss: 9.6855\n",
      "Epoch 916/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3358 - val_loss: 9.5743\n",
      "Epoch 917/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3687 - val_loss: 9.5871\n",
      "Epoch 918/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.2621 - val_loss: 9.8092\n",
      "Epoch 919/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3963 - val_loss: 9.8416\n",
      "Epoch 920/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2348 - val_loss: 10.1013\n",
      "Epoch 921/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2160 - val_loss: 9.5289\n",
      "Epoch 922/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0627 - val_loss: 9.5806\n",
      "Epoch 923/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0881 - val_loss: 9.2644\n",
      "Epoch 924/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1229 - val_loss: 9.7962\n",
      "Epoch 925/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.2584 - val_loss: 9.5265\n",
      "Epoch 926/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0302 - val_loss: 9.9773\n",
      "Epoch 927/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3956 - val_loss: 9.5219\n",
      "Epoch 928/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1680 - val_loss: 9.9104\n",
      "Epoch 929/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1076 - val_loss: 9.3678\n",
      "Epoch 930/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1705 - val_loss: 9.4190\n",
      "Epoch 931/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4288 - val_loss: 10.1462\n",
      "Epoch 932/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2589 - val_loss: 9.6809\n",
      "Epoch 933/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4387 - val_loss: 9.4764\n",
      "Epoch 934/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2306 - val_loss: 9.8270\n",
      "Epoch 935/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.0975 - val_loss: 9.3666\n",
      "Epoch 936/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0650 - val_loss: 9.5598\n",
      "Epoch 937/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0271 - val_loss: 9.5582\n",
      "Epoch 938/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0914 - val_loss: 9.8448\n",
      "Epoch 939/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0781 - val_loss: 9.5041\n",
      "Epoch 940/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0299 - val_loss: 9.7232\n",
      "Epoch 941/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.9737 - val_loss: 9.5842\n",
      "Epoch 942/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.9899 - val_loss: 9.9945\n",
      "Epoch 943/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.2310 - val_loss: 9.8483\n",
      "Epoch 944/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.3582 - val_loss: 9.6016\n",
      "Epoch 945/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.1248 - val_loss: 9.7608\n",
      "Epoch 946/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.0569 - val_loss: 9.3937\n",
      "Epoch 947/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0793 - val_loss: 9.5614\n",
      "Epoch 948/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.0060 - val_loss: 9.5440\n",
      "Epoch 949/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.9949 - val_loss: 9.9607\n",
      "Epoch 950/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0940 - val_loss: 9.4184\n",
      "Epoch 951/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0161 - val_loss: 9.8850\n",
      "Epoch 952/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.1171 - val_loss: 9.5306\n",
      "Epoch 953/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.4542 - val_loss: 9.7519\n",
      "Epoch 954/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0856 - val_loss: 9.7768\n",
      "Epoch 955/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1051 - val_loss: 9.8121\n",
      "Epoch 956/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1653 - val_loss: 9.6690\n",
      "Epoch 957/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.2940 - val_loss: 9.6287\n",
      "Epoch 958/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0871 - val_loss: 9.6699\n",
      "Epoch 959/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.0866 - val_loss: 9.7489\n",
      "Epoch 960/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0772 - val_loss: 9.6105\n",
      "Epoch 961/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1903 - val_loss: 9.7504\n",
      "Epoch 962/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1247 - val_loss: 9.7389\n",
      "Epoch 963/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0762 - val_loss: 9.7618\n",
      "Epoch 964/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1624 - val_loss: 10.0185\n",
      "Epoch 965/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2268 - val_loss: 9.9292\n",
      "Epoch 966/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0808 - val_loss: 10.0379\n",
      "Epoch 967/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1390 - val_loss: 9.5129\n",
      "Epoch 968/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2132 - val_loss: 9.4944\n",
      "Epoch 969/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.0829 - val_loss: 9.7938\n",
      "Epoch 970/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.3075 - val_loss: 9.8480\n",
      "Epoch 971/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.5380 - val_loss: 11.1884\n",
      "Epoch 972/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3952 - val_loss: 9.6062\n",
      "Epoch 973/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0245 - val_loss: 9.6559\n",
      "Epoch 974/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.1202 - val_loss: 9.6748\n",
      "Epoch 975/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0411 - val_loss: 9.7256\n",
      "Epoch 976/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0711 - val_loss: 9.8633\n",
      "Epoch 977/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0634 - val_loss: 9.9016\n",
      "Epoch 978/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0849 - val_loss: 9.7028\n",
      "Epoch 979/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0980 - val_loss: 9.4355\n",
      "Epoch 980/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.1943 - val_loss: 9.7586\n",
      "Epoch 981/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0326 - val_loss: 9.5268\n",
      "Epoch 982/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0232 - val_loss: 9.8844\n",
      "Epoch 983/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0192 - val_loss: 9.5155\n",
      "Epoch 984/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.0356 - val_loss: 9.5750\n",
      "Epoch 985/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.0492 - val_loss: 9.7245\n",
      "Epoch 986/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.0500 - val_loss: 9.4670\n",
      "Epoch 987/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0670 - val_loss: 9.9211\n",
      "Epoch 988/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1207 - val_loss: 9.5402\n",
      "Epoch 989/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.2854 - val_loss: 10.3525\n",
      "Epoch 990/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 3.539 - 0s 109us/step - loss: 4.4448 - val_loss: 9.7057\n",
      "Epoch 991/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0472 - val_loss: 9.3386\n",
      "Epoch 992/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.0958 - val_loss: 9.9695\n",
      "Epoch 993/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 4.0652 - val_loss: 9.5598\n",
      "Epoch 994/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1602 - val_loss: 10.3415\n",
      "Epoch 995/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.0335 - val_loss: 9.4829\n",
      "Epoch 996/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2142 - val_loss: 9.9590\n",
      "Epoch 997/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1586 - val_loss: 9.4444\n",
      "Epoch 998/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.0958 - val_loss: 9.7333\n",
      "Epoch 999/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0566 - val_loss: 9.8629\n",
      "Epoch 1000/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.0079 - val_loss: 9.5620\n",
      "7.129009448875816\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 4.3556862e+00, -9.8558676e-01,  3.4957063e+00, -2.5149055e+00,\n",
       "          4.1072149e+00, -1.4654508e+00, -3.6878756e-01,  7.3338300e-01,\n",
       "         -2.8168871e+00,  9.4766253e-01],\n",
       "        [-4.0873653e-01,  9.5570225e-01, -2.5147905e+00,  2.1838560e+00,\n",
       "         -2.3769341e+00,  5.5652970e-01, -1.1814021e+00,  1.1163929e+00,\n",
       "          1.0337913e+00, -1.4861494e+00],\n",
       "        [-1.5664078e+00,  5.7811904e-01,  1.5507472e+00,  1.4246424e+00,\n",
       "          4.7220376e-01, -1.0173656e+00, -5.6427622e-01, -1.7438691e+00,\n",
       "          2.3114300e+00,  1.0944103e+00],\n",
       "        [ 4.3667011e-02, -7.3571140e-01,  1.1948775e+00, -2.3046863e+00,\n",
       "          2.0765352e+00,  7.9192877e-01,  1.1755912e+00, -9.5961010e-01,\n",
       "         -8.2030541e-01, -2.5274384e-01],\n",
       "        [-4.4600233e-01,  5.8837116e-01,  3.5861680e-01,  1.2449651e+00,\n",
       "         -2.8521671e+00, -6.6574830e-01,  1.7491629e+00,  1.9707493e-01,\n",
       "          7.3478633e-01,  3.1479467e-03],\n",
       "        [ 1.5449178e+00, -1.2813964e-01, -5.2312595e-01, -1.5187745e-01,\n",
       "         -1.6402634e+00,  4.7628179e-01, -9.5132768e-01,  2.1086881e+00,\n",
       "         -5.1696551e-01,  7.0083298e-02],\n",
       "        [-7.0780194e-01, -1.1687921e+00, -1.0887047e+00,  6.6953510e-01,\n",
       "          1.0213640e+00,  6.7930794e-01,  1.9393276e+00,  1.4835213e+00,\n",
       "         -8.6670250e-01, -3.3413616e-01]], dtype=float32),\n",
       " array([ 2.4858277 , -1.4087507 ,  1.2209295 ,  2.0855694 , -3.3898141 ,\n",
       "        -1.1250293 ,  1.9661242 , -3.5136752 , -0.38569045,  1.6060059 ],\n",
       "       dtype=float32),\n",
       " array([[-0.40574476,  0.35448542,  0.28712833, -0.08323281, -0.6080407 ,\n",
       "          0.25767982,  0.31464797, -0.15969138,  0.46079877,  0.30476567],\n",
       "        [-0.0137855 , -0.63079566, -0.60406613,  0.24721213,  0.6057884 ,\n",
       "         -0.13381405,  0.10981375,  0.3605449 , -0.11585703,  0.2187064 ],\n",
       "        [ 1.0672847 , -1.3053501 , -1.1932263 ,  0.89376616,  0.8508688 ,\n",
       "          0.09272368,  1.1238865 ,  0.1625024 , -1.1746854 , -1.6206652 ],\n",
       "        [-0.45105714,  0.21016227,  0.8116429 , -0.6189503 , -0.767293  ,\n",
       "         -0.10073704, -0.43714717, -0.32757908, -0.05466244,  0.01501342],\n",
       "        [ 0.41520855,  0.05786223, -0.67453945,  0.10008436,  0.44502681,\n",
       "         -0.03938285, -0.5310034 , -0.17738111, -0.25822464, -0.649466  ],\n",
       "        [ 0.9543554 , -1.0368472 , -0.861204  ,  0.34046426,  0.86349773,\n",
       "          0.4503633 ,  0.93639576,  0.08046088, -0.74880165, -0.95374143],\n",
       "        [ 0.6843778 ,  0.25469536, -0.41048518,  0.5842026 ,  0.02394156,\n",
       "          0.3906832 , -0.03751302, -0.03523055, -0.9156473 , -0.34446812],\n",
       "        [-0.99909765,  0.05608631,  0.8313875 , -0.6095833 , -0.67839354,\n",
       "         -0.63932157, -0.33337438,  0.27941242,  0.80189943,  0.5706285 ],\n",
       "        [-0.12262114, -0.81203634, -0.6681359 ,  0.6082435 ,  0.16672002,\n",
       "         -0.17243098,  0.11594299,  0.06003547,  0.01706321, -0.4612252 ],\n",
       "        [-0.6240974 ,  1.098587  ,  1.311839  , -0.9554408 , -1.3637533 ,\n",
       "          0.21246043, -0.8001056 , -0.2700337 ,  0.3906503 ,  0.60132086]],\n",
       "       dtype=float32),\n",
       " array([-1.4192685 ,  1.4290367 ,  1.4819058 , -1.41579   , -1.4549025 ,\n",
       "        -0.8473206 , -1.2779348 ,  0.82224435,  1.3837534 ,  1.4455979 ],\n",
       "       dtype=float32),\n",
       " array([[-0.67782456],\n",
       "        [ 1.114807  ],\n",
       "        [ 1.4596893 ],\n",
       "        [-0.85089743],\n",
       "        [-1.2717499 ],\n",
       "        [-0.00567641],\n",
       "        [-0.49747708],\n",
       "        [ 0.00204203],\n",
       "        [ 0.47281197],\n",
       "        [ 0.96201503]], dtype=float32),\n",
       " array([1.514063], dtype=float32)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_autompg, history_autompg=NN_model_structure_regression_5(X_train_autompg, X_val_autompg, Y_train_autompg, Y_val_autompg, adam2, 32, 1000)\n",
    "model_autompg.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_autompg.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_autompg_structure5.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_34 (Dense)             (None, 10)                80        \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 15)                165       \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 261\n",
      "Trainable params: 261\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 274 samples, validate on 59 samples\n",
      "Epoch 1/1000\n",
      "274/274 [==============================] - 0s 1ms/step - loss: 445.9236 - val_loss: 165.6939\n",
      "Epoch 2/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 91.9301 - val_loss: 48.0806\n",
      "Epoch 3/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 31.1703 - val_loss: 33.8686\n",
      "Epoch 4/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 20.2013 - val_loss: 26.2461\n",
      "Epoch 5/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 18.5432 - val_loss: 21.0293\n",
      "Epoch 6/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 14.3498 - val_loss: 18.8951\n",
      "Epoch 7/1000\n",
      "274/274 [==============================] - 0s 115us/step - loss: 13.4612 - val_loss: 18.7357\n",
      "Epoch 8/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 10.01 - 0s 113us/step - loss: 10.4277 - val_loss: 16.0028\n",
      "Epoch 9/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 9.4508 - val_loss: 15.9782\n",
      "Epoch 10/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 8.9385 - val_loss: 13.8893\n",
      "Epoch 11/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.9829 - val_loss: 13.4021\n",
      "Epoch 12/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.6853 - val_loss: 12.8186\n",
      "Epoch 13/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.3472 - val_loss: 12.5245\n",
      "Epoch 14/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 7.4501 - val_loss: 11.5754\n",
      "Epoch 15/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.3490 - val_loss: 11.8451\n",
      "Epoch 16/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.2956 - val_loss: 10.9220\n",
      "Epoch 17/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 7.1246 - val_loss: 10.8408\n",
      "Epoch 18/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.1130 - val_loss: 10.3250\n",
      "Epoch 19/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.0646 - val_loss: 10.5651\n",
      "Epoch 20/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.9707 - val_loss: 10.1832\n",
      "Epoch 21/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 7.0025 - val_loss: 10.2632\n",
      "Epoch 22/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.9570 - val_loss: 10.1621\n",
      "Epoch 23/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 7.2765 - val_loss: 9.9714\n",
      "Epoch 24/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7968 - val_loss: 10.1177\n",
      "Epoch 25/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.0368 - val_loss: 9.6431\n",
      "Epoch 26/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.2376 - val_loss: 10.3034\n",
      "Epoch 27/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.9693 - val_loss: 10.7703\n",
      "Epoch 28/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 7.0563 - val_loss: 10.0516\n",
      "Epoch 29/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.2152 - val_loss: 11.4472\n",
      "Epoch 30/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8514 - val_loss: 9.9645\n",
      "Epoch 31/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7757 - val_loss: 10.1130\n",
      "Epoch 32/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.7892 - val_loss: 9.8880\n",
      "Epoch 33/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.2726 - val_loss: 9.5698\n",
      "Epoch 34/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 7.0163 - val_loss: 11.1757\n",
      "Epoch 35/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 6.7435 - val_loss: 9.8836\n",
      "Epoch 36/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 6.8536 - val_loss: 9.8206\n",
      "Epoch 37/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 6.4577 - val_loss: 9.5609\n",
      "Epoch 38/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 6.5901 - val_loss: 9.8301\n",
      "Epoch 39/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 6.4784 - val_loss: 9.6404\n",
      "Epoch 40/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.4303 - val_loss: 9.3962\n",
      "Epoch 41/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.5445 - val_loss: 9.3127\n",
      "Epoch 42/1000\n",
      "274/274 [==============================] - 0s 126us/step - loss: 6.6899 - val_loss: 9.4234\n",
      "Epoch 43/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 6.4392 - val_loss: 9.5808\n",
      "Epoch 44/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 6.4191 - val_loss: 9.8178\n",
      "Epoch 45/1000\n",
      "274/274 [==============================] - 0s 118us/step - loss: 6.5721 - val_loss: 9.8211\n",
      "Epoch 46/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.7210 - val_loss: 9.5819\n",
      "Epoch 47/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 6.5750 - val_loss: 9.9148\n",
      "Epoch 48/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.5468 - val_loss: 9.7137\n",
      "Epoch 49/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 6.4473 - val_loss: 9.1982\n",
      "Epoch 50/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.2940 - val_loss: 10.2208\n",
      "Epoch 51/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.4403 - val_loss: 9.2332\n",
      "Epoch 52/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.6648 - val_loss: 9.2218\n",
      "Epoch 53/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.5457 - val_loss: 9.8736\n",
      "Epoch 54/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.3872 - val_loss: 9.4014\n",
      "Epoch 55/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.6508 - val_loss: 9.5125\n",
      "Epoch 56/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.3173 - val_loss: 9.3894\n",
      "Epoch 57/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 6.3481 - val_loss: 9.4063\n",
      "Epoch 58/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.2269 - val_loss: 9.4501\n",
      "Epoch 59/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 6.4344 - val_loss: 10.2045\n",
      "Epoch 60/1000\n",
      "274/274 [==============================] - 0s 130us/step - loss: 6.8930 - val_loss: 9.2920\n",
      "Epoch 61/1000\n",
      "274/274 [==============================] - 0s 160us/step - loss: 6.7559 - val_loss: 9.3096\n",
      "Epoch 62/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 6.7114 - val_loss: 9.4613\n",
      "Epoch 63/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4459 - val_loss: 9.1527\n",
      "Epoch 64/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1961 - val_loss: 10.1176\n",
      "Epoch 65/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.3029 - val_loss: 9.3187\n",
      "Epoch 66/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.5710 - val_loss: 9.2040\n",
      "Epoch 67/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.2560 - val_loss: 9.7583\n",
      "Epoch 68/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4757 - val_loss: 9.3815\n",
      "Epoch 69/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1475 - val_loss: 9.5481\n",
      "Epoch 70/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2375 - val_loss: 9.2985\n",
      "Epoch 71/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4157 - val_loss: 9.2776\n",
      "Epoch 72/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0654 - val_loss: 10.7359\n",
      "Epoch 73/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3706 - val_loss: 9.2295\n",
      "Epoch 74/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4972 - val_loss: 9.4312\n",
      "Epoch 75/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4365 - val_loss: 9.6728\n",
      "Epoch 76/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1747 - val_loss: 9.2651\n",
      "Epoch 77/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1223 - val_loss: 9.3638\n",
      "Epoch 78/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0614 - val_loss: 9.5672\n",
      "Epoch 79/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1800 - val_loss: 9.1338\n",
      "Epoch 80/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0692 - val_loss: 9.7101\n",
      "Epoch 81/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2880 - val_loss: 9.1880\n",
      "Epoch 82/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4217 - val_loss: 9.1332\n",
      "Epoch 83/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6104 - val_loss: 10.7535\n",
      "Epoch 84/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.3556 - val_loss: 9.3785\n",
      "Epoch 85/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0675 - val_loss: 9.9090\n",
      "Epoch 86/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0338 - val_loss: 9.1438\n",
      "Epoch 87/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.0193 - val_loss: 9.2329\n",
      "Epoch 88/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1291 - val_loss: 9.7684\n",
      "Epoch 89/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.1568 - val_loss: 8.9609\n",
      "Epoch 90/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.2899 - val_loss: 8.9574\n",
      "Epoch 91/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3495 - val_loss: 9.5388\n",
      "Epoch 92/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1243 - val_loss: 9.7162\n",
      "Epoch 93/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1437 - val_loss: 9.2903\n",
      "Epoch 94/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0281 - val_loss: 10.0682\n",
      "Epoch 95/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0720 - val_loss: 9.1690\n",
      "Epoch 96/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9793 - val_loss: 9.0312\n",
      "Epoch 97/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3283 - val_loss: 11.0876\n",
      "Epoch 98/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6479 - val_loss: 9.2640\n",
      "Epoch 99/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.1755 - val_loss: 9.7349\n",
      "Epoch 100/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4694 - val_loss: 10.3602\n",
      "Epoch 101/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4494 - val_loss: 9.1997\n",
      "Epoch 102/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5434 - val_loss: 9.7362\n",
      "Epoch 103/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.4877 - val_loss: 10.4007\n",
      "Epoch 104/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3775 - val_loss: 9.3419\n",
      "Epoch 105/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9975 - val_loss: 9.2444\n",
      "Epoch 106/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1316 - val_loss: 10.1933\n",
      "Epoch 107/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.1190 - val_loss: 8.8154\n",
      "Epoch 108/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0539 - val_loss: 9.3784\n",
      "Epoch 109/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1642 - val_loss: 10.2356\n",
      "Epoch 110/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9907 - val_loss: 9.0947\n",
      "Epoch 111/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.2836 - val_loss: 9.7441\n",
      "Epoch 112/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9382 - val_loss: 9.1739\n",
      "Epoch 113/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1125 - val_loss: 8.9536\n",
      "Epoch 114/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.7022 - val_loss: 10.9906\n",
      "Epoch 115/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 6.0905 - val_loss: 9.2163\n",
      "Epoch 116/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.3640 - val_loss: 10.1936\n",
      "Epoch 117/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7869 - val_loss: 8.7679\n",
      "Epoch 118/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7133 - val_loss: 9.2705\n",
      "Epoch 119/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8623 - val_loss: 9.5516\n",
      "Epoch 120/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.7318 - val_loss: 8.8200\n",
      "Epoch 121/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.1434 - val_loss: 9.8081\n",
      "Epoch 122/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7881 - val_loss: 8.8377\n",
      "Epoch 123/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.7914 - val_loss: 9.1461\n",
      "Epoch 124/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 5.9304 - val_loss: 8.9410\n",
      "Epoch 125/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.8107 - val_loss: 13.3685\n",
      "Epoch 126/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 6.7651 - val_loss: 9.8485\n",
      "Epoch 127/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.5344 - val_loss: 10.0509\n",
      "Epoch 128/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.3552 - val_loss: 9.1629\n",
      "Epoch 129/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9799 - val_loss: 8.9101\n",
      "Epoch 130/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8870 - val_loss: 10.1674\n",
      "Epoch 131/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.0902 - val_loss: 8.8325\n",
      "Epoch 132/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.1562 - val_loss: 8.6892\n",
      "Epoch 133/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 6.3422 - val_loss: 9.6251\n",
      "Epoch 134/1000\n",
      "274/274 [==============================] - 0s 118us/step - loss: 5.7960 - val_loss: 9.0284\n",
      "Epoch 135/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7621 - val_loss: 9.2738\n",
      "Epoch 136/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6851 - val_loss: 8.9899\n",
      "Epoch 137/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5874 - val_loss: 8.7996\n",
      "Epoch 138/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.7263 - val_loss: 9.8691\n",
      "Epoch 139/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8215 - val_loss: 8.7747\n",
      "Epoch 140/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7236 - val_loss: 8.9674\n",
      "Epoch 141/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 5.7873 - val_loss: 9.2562\n",
      "Epoch 142/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7573 - val_loss: 9.2855\n",
      "Epoch 143/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5873 - val_loss: 9.3699\n",
      "Epoch 144/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6510 - val_loss: 9.2610\n",
      "Epoch 145/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 106us/step - loss: 5.5644 - val_loss: 8.9928\n",
      "Epoch 146/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4713 - val_loss: 8.7769\n",
      "Epoch 147/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.6286 - val_loss: 10.3621\n",
      "Epoch 148/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.6572 - val_loss: 9.1683\n",
      "Epoch 149/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5449 - val_loss: 8.9705\n",
      "Epoch 150/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.4875 - val_loss: 9.6443\n",
      "Epoch 151/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6101 - val_loss: 8.8866\n",
      "Epoch 152/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8253 - val_loss: 10.2936\n",
      "Epoch 153/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.5676 - val_loss: 8.6869\n",
      "Epoch 154/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5447 - val_loss: 10.3058\n",
      "Epoch 155/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5676 - val_loss: 8.8802\n",
      "Epoch 156/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5469 - val_loss: 9.0988\n",
      "Epoch 157/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5138 - val_loss: 9.9780\n",
      "Epoch 158/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4658 - val_loss: 8.9120\n",
      "Epoch 159/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.6576 - val_loss: 8.8020\n",
      "Epoch 160/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7839 - val_loss: 10.4170\n",
      "Epoch 161/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6175 - val_loss: 8.7854\n",
      "Epoch 162/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3382 - val_loss: 9.3487\n",
      "Epoch 163/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9265 - val_loss: 8.9188\n",
      "Epoch 164/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5778 - val_loss: 8.8436\n",
      "Epoch 165/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4651 - val_loss: 9.3640\n",
      "Epoch 166/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9237 - val_loss: 9.1315\n",
      "Epoch 167/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1714 - val_loss: 10.5488\n",
      "Epoch 168/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4834 - val_loss: 8.9515\n",
      "Epoch 169/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.3949 - val_loss: 8.7694\n",
      "Epoch 170/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.9356 - val_loss: 10.5823\n",
      "Epoch 171/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7748 - val_loss: 8.8528\n",
      "Epoch 172/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7724 - val_loss: 8.5556\n",
      "Epoch 173/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7694 - val_loss: 8.8830\n",
      "Epoch 174/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.9599 - val_loss: 11.2526\n",
      "Epoch 175/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.0969 - val_loss: 8.9902\n",
      "Epoch 176/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3123 - val_loss: 9.0066\n",
      "Epoch 177/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3157 - val_loss: 8.8031\n",
      "Epoch 178/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2373 - val_loss: 9.2806\n",
      "Epoch 179/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3347 - val_loss: 8.8585\n",
      "Epoch 180/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3255 - val_loss: 9.1541\n",
      "Epoch 181/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5339 - val_loss: 8.8416\n",
      "Epoch 182/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2866 - val_loss: 8.8757\n",
      "Epoch 183/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2571 - val_loss: 8.8534\n",
      "Epoch 184/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2541 - val_loss: 9.1746\n",
      "Epoch 185/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3042 - val_loss: 8.9604\n",
      "Epoch 186/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5457 - val_loss: 10.6568\n",
      "Epoch 187/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4543 - val_loss: 8.8592\n",
      "Epoch 188/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.5825 - val_loss: 9.7665\n",
      "Epoch 189/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.2753 - val_loss: 9.1982\n",
      "Epoch 190/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2391 - val_loss: 9.3517\n",
      "Epoch 191/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.1834 - val_loss: 8.7248\n",
      "Epoch 192/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.6787 - val_loss: 9.9347\n",
      "Epoch 193/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.3217 - val_loss: 8.7637\n",
      "Epoch 194/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4835 - val_loss: 9.1990\n",
      "Epoch 195/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6938 - val_loss: 9.7801\n",
      "Epoch 196/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 5.1504 - val_loss: 8.7758\n",
      "Epoch 197/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0203 - val_loss: 10.0803\n",
      "Epoch 198/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.4566 - val_loss: 9.3977\n",
      "Epoch 199/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6801 - val_loss: 10.0785\n",
      "Epoch 200/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.6041 - val_loss: 9.8499\n",
      "Epoch 201/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.7692 - val_loss: 9.5620\n",
      "Epoch 202/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.3068 - val_loss: 10.3930\n",
      "Epoch 203/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.4001 - val_loss: 8.7005\n",
      "Epoch 204/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3841 - val_loss: 8.6766\n",
      "Epoch 205/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.2038 - val_loss: 9.8833\n",
      "Epoch 206/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1494 - val_loss: 8.6483\n",
      "Epoch 207/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.3927 - val_loss: 9.1032\n",
      "Epoch 208/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.1853 - val_loss: 9.4957\n",
      "Epoch 209/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.0622 - val_loss: 8.9734\n",
      "Epoch 210/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1946 - val_loss: 9.9369\n",
      "Epoch 211/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3916 - val_loss: 9.0210\n",
      "Epoch 212/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.1060 - val_loss: 8.9513\n",
      "Epoch 213/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 5.1724 - val_loss: 9.3593\n",
      "Epoch 214/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.2856 - val_loss: 9.2806\n",
      "Epoch 215/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3228 - val_loss: 8.9273\n",
      "Epoch 216/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4751 - val_loss: 9.3278\n",
      "Epoch 217/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1528 - val_loss: 9.3527\n",
      "Epoch 218/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0166 - val_loss: 9.3564\n",
      "Epoch 219/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.0631 - val_loss: 9.2092\n",
      "Epoch 220/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.0938 - val_loss: 9.2279\n",
      "Epoch 221/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0017 - val_loss: 9.5841\n",
      "Epoch 222/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0839 - val_loss: 8.8730\n",
      "Epoch 223/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1620 - val_loss: 9.2773\n",
      "Epoch 224/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2620 - val_loss: 9.2284\n",
      "Epoch 225/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0368 - val_loss: 9.2999\n",
      "Epoch 226/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1311 - val_loss: 8.8071\n",
      "Epoch 227/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1270 - val_loss: 8.9384\n",
      "Epoch 228/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.0552 - val_loss: 9.4433\n",
      "Epoch 229/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0033 - val_loss: 9.1543\n",
      "Epoch 230/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.9093 - val_loss: 8.9507\n",
      "Epoch 231/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0790 - val_loss: 10.1726\n",
      "Epoch 232/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1115 - val_loss: 8.7298\n",
      "Epoch 233/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.2784 - val_loss: 9.1790\n",
      "Epoch 234/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6181 - val_loss: 10.1152\n",
      "Epoch 235/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1966 - val_loss: 9.3883\n",
      "Epoch 236/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9288 - val_loss: 8.8849\n",
      "Epoch 237/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.9426 - val_loss: 10.2406\n",
      "Epoch 238/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1900 - val_loss: 9.2238\n",
      "Epoch 239/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1431 - val_loss: 8.9813\n",
      "Epoch 240/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.0998 - val_loss: 9.6003\n",
      "Epoch 241/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.9668 - val_loss: 9.0427\n",
      "Epoch 242/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0083 - val_loss: 8.9919\n",
      "Epoch 243/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1833 - val_loss: 9.9639\n",
      "Epoch 244/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0570 - val_loss: 9.0517\n",
      "Epoch 245/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.0835 - val_loss: 9.0768\n",
      "Epoch 246/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0025 - val_loss: 10.6412\n",
      "Epoch 247/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1840 - val_loss: 9.0838\n",
      "Epoch 248/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2663 - val_loss: 9.0954\n",
      "Epoch 249/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4571 - val_loss: 9.2452\n",
      "Epoch 250/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.0439 - val_loss: 9.1168\n",
      "Epoch 251/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9501 - val_loss: 9.7729\n",
      "Epoch 252/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.1882 - val_loss: 9.4616\n",
      "Epoch 253/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.9785 - val_loss: 9.2782\n",
      "Epoch 254/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.9269 - val_loss: 9.0422\n",
      "Epoch 255/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.8804 - val_loss: 9.3377\n",
      "Epoch 256/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.9611 - val_loss: 9.5962\n",
      "Epoch 257/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9558 - val_loss: 9.6185\n",
      "Epoch 258/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0143 - val_loss: 8.8947\n",
      "Epoch 259/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1025 - val_loss: 10.3443\n",
      "Epoch 260/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0952 - val_loss: 8.9913\n",
      "Epoch 261/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8270 - val_loss: 9.6016\n",
      "Epoch 262/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9574 - val_loss: 9.1218\n",
      "Epoch 263/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.1047 - val_loss: 9.2830\n",
      "Epoch 264/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5434 - val_loss: 12.4865\n",
      "Epoch 265/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7949 - val_loss: 9.2560\n",
      "Epoch 266/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8200 - val_loss: 9.1882\n",
      "Epoch 267/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.0703 - val_loss: 10.0429\n",
      "Epoch 268/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9202 - val_loss: 9.4018\n",
      "Epoch 269/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3232 - val_loss: 10.6186\n",
      "Epoch 270/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.2869 - val_loss: 9.7271\n",
      "Epoch 271/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.0857 - val_loss: 9.1259\n",
      "Epoch 272/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.8081 - val_loss: 9.7069\n",
      "Epoch 273/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7681 - val_loss: 9.1112\n",
      "Epoch 274/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.9579 - val_loss: 10.1059\n",
      "Epoch 275/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.8113 - val_loss: 9.0307\n",
      "Epoch 276/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9979 - val_loss: 9.8968\n",
      "Epoch 277/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2730 - val_loss: 9.7511\n",
      "Epoch 278/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.9876 - val_loss: 9.3521\n",
      "Epoch 279/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0516 - val_loss: 10.3434\n",
      "Epoch 280/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2040 - val_loss: 9.2939\n",
      "Epoch 281/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.1731 - val_loss: 9.1160\n",
      "Epoch 282/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.9505 - val_loss: 9.2761\n",
      "Epoch 283/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3025 - val_loss: 10.2604\n",
      "Epoch 284/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.1247 - val_loss: 8.9072\n",
      "Epoch 285/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8482 - val_loss: 9.6687\n",
      "Epoch 286/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0705 - val_loss: 9.2648\n",
      "Epoch 287/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.1029 - val_loss: 10.4946\n",
      "Epoch 288/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.2448 - val_loss: 9.4547\n",
      "Epoch 289/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.8619 - val_loss: 9.2073\n",
      "Epoch 290/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8459 - val_loss: 9.5606\n",
      "Epoch 291/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.0016 - val_loss: 9.6038\n",
      "Epoch 292/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1586 - val_loss: 9.0693\n",
      "Epoch 293/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.7712 - val_loss: 9.8003\n",
      "Epoch 294/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9014 - val_loss: 9.3496\n",
      "Epoch 295/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.9564 - val_loss: 8.8454\n",
      "Epoch 296/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7970 - val_loss: 9.9977\n",
      "Epoch 297/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7826 - val_loss: 8.9355\n",
      "Epoch 298/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7870 - val_loss: 9.3668\n",
      "Epoch 299/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 105us/step - loss: 4.6818 - val_loss: 9.3267\n",
      "Epoch 300/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7148 - val_loss: 9.5371\n",
      "Epoch 301/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.7661 - val_loss: 9.2620\n",
      "Epoch 302/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6816 - val_loss: 9.3831\n",
      "Epoch 303/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6446 - val_loss: 8.9768\n",
      "Epoch 304/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6922 - val_loss: 9.5400\n",
      "Epoch 305/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9837 - val_loss: 9.9628\n",
      "Epoch 306/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9312 - val_loss: 9.2931\n",
      "Epoch 307/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8056 - val_loss: 9.8737\n",
      "Epoch 308/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.0417 - val_loss: 8.7027\n",
      "Epoch 309/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8796 - val_loss: 10.3205\n",
      "Epoch 310/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.8368 - val_loss: 9.2783\n",
      "Epoch 311/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.9322 - val_loss: 9.4892\n",
      "Epoch 312/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.7440 - val_loss: 9.1014\n",
      "Epoch 313/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8841 - val_loss: 9.6188\n",
      "Epoch 314/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0718 - val_loss: 9.4612\n",
      "Epoch 315/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3430 - val_loss: 9.4183\n",
      "Epoch 316/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7814 - val_loss: 9.5582\n",
      "Epoch 317/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.8273 - val_loss: 9.4793\n",
      "Epoch 318/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9214 - val_loss: 10.2950\n",
      "Epoch 319/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8230 - val_loss: 9.2091\n",
      "Epoch 320/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9894 - val_loss: 8.9140\n",
      "Epoch 321/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3985 - val_loss: 12.5601\n",
      "Epoch 322/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.7617 - val_loss: 9.2654\n",
      "Epoch 323/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8987 - val_loss: 9.7660\n",
      "Epoch 324/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.8293 - val_loss: 9.7510\n",
      "Epoch 325/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8331 - val_loss: 9.2232\n",
      "Epoch 326/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7680 - val_loss: 9.5248\n",
      "Epoch 327/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.7366 - val_loss: 9.1633\n",
      "Epoch 328/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0227 - val_loss: 9.7548\n",
      "Epoch 329/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0169 - val_loss: 10.3164\n",
      "Epoch 330/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.8126 - val_loss: 9.3150\n",
      "Epoch 331/1000\n",
      "274/274 [==============================] - 0s 115us/step - loss: 4.7824 - val_loss: 9.6902\n",
      "Epoch 332/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.6715 - val_loss: 9.1960\n",
      "Epoch 333/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.6999 - val_loss: 9.4633\n",
      "Epoch 334/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.7254 - val_loss: 9.4967\n",
      "Epoch 335/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.8017 - val_loss: 9.7378\n",
      "Epoch 336/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.1993 - val_loss: 11.4842\n",
      "Epoch 337/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1860 - val_loss: 9.1244\n",
      "Epoch 338/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9218 - val_loss: 9.7501\n",
      "Epoch 339/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.5866 - val_loss: 9.2767\n",
      "Epoch 340/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0660 - val_loss: 9.5187\n",
      "Epoch 341/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 4.8806 - val_loss: 9.5124\n",
      "Epoch 342/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.7250 - val_loss: 9.6677\n",
      "Epoch 343/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8908 - val_loss: 9.5880\n",
      "Epoch 344/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8010 - val_loss: 9.3887\n",
      "Epoch 345/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.3630 - val_loss: 11.5070\n",
      "Epoch 346/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4971 - val_loss: 9.4159\n",
      "Epoch 347/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.0026 - val_loss: 9.2533\n",
      "Epoch 348/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8010 - val_loss: 9.8259\n",
      "Epoch 349/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9929 - val_loss: 10.0247\n",
      "Epoch 350/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.9770 - val_loss: 9.4410\n",
      "Epoch 351/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.0139 - val_loss: 9.5578\n",
      "Epoch 352/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.7585 - val_loss: 10.3007\n",
      "Epoch 353/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.0557 - val_loss: 9.8158\n",
      "Epoch 354/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.8488 - val_loss: 9.0302\n",
      "Epoch 355/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7430 - val_loss: 10.2243\n",
      "Epoch 356/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9611 - val_loss: 9.1723\n",
      "Epoch 357/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.7498 - val_loss: 8.8370\n",
      "Epoch 358/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6829 - val_loss: 9.8872\n",
      "Epoch 359/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7233 - val_loss: 9.9048\n",
      "Epoch 360/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.6221 - val_loss: 9.6636\n",
      "Epoch 361/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.7891 - val_loss: 9.1937\n",
      "Epoch 362/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6940 - val_loss: 10.1659\n",
      "Epoch 363/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.5942 - val_loss: 9.0266\n",
      "Epoch 364/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.6403 - val_loss: 9.6028\n",
      "Epoch 365/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5827 - val_loss: 9.4026\n",
      "Epoch 366/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.9536 - val_loss: 9.3324\n",
      "Epoch 367/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.6381 - val_loss: 9.7939\n",
      "Epoch 368/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5853 - val_loss: 9.5582\n",
      "Epoch 369/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6031 - val_loss: 9.4240\n",
      "Epoch 370/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.6828 - val_loss: 10.4960\n",
      "Epoch 371/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.2419 - val_loss: 9.4357\n",
      "Epoch 372/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.8073 - val_loss: 11.5697\n",
      "Epoch 373/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4639 - val_loss: 10.2389\n",
      "Epoch 374/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6195 - val_loss: 9.4116\n",
      "Epoch 375/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.8205 - val_loss: 9.7731\n",
      "Epoch 376/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.6458 - val_loss: 9.5744\n",
      "Epoch 377/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.5128 - val_loss: 9.2836\n",
      "Epoch 378/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5974 - val_loss: 9.7086\n",
      "Epoch 379/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6673 - val_loss: 9.4124\n",
      "Epoch 380/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6725 - val_loss: 10.3399\n",
      "Epoch 381/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0171 - val_loss: 9.3051\n",
      "Epoch 382/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.7806 - val_loss: 9.5148\n",
      "Epoch 383/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.8989 - val_loss: 9.8429\n",
      "Epoch 384/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.9087 - val_loss: 9.3376\n",
      "Epoch 385/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7063 - val_loss: 9.3981\n",
      "Epoch 386/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6346 - val_loss: 9.6751\n",
      "Epoch 387/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6748 - val_loss: 9.8199\n",
      "Epoch 388/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6793 - val_loss: 9.9106\n",
      "Epoch 389/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5040 - val_loss: 9.5771\n",
      "Epoch 390/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.7123 - val_loss: 10.3682\n",
      "Epoch 391/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.6247 - val_loss: 9.4135\n",
      "Epoch 392/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.8394 - val_loss: 9.4230\n",
      "Epoch 393/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6570 - val_loss: 9.7491\n",
      "Epoch 394/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.7165 - val_loss: 9.9393\n",
      "Epoch 395/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.8276 - val_loss: 9.5332\n",
      "Epoch 396/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.6023 - val_loss: 9.2064\n",
      "Epoch 397/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6234 - val_loss: 9.3868\n",
      "Epoch 398/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.5279 - val_loss: 10.3248\n",
      "Epoch 399/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6066 - val_loss: 9.5005\n",
      "Epoch 400/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4802 - val_loss: 9.3875\n",
      "Epoch 401/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4488 - val_loss: 9.3473\n",
      "Epoch 402/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5877 - val_loss: 8.8705\n",
      "Epoch 403/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.8725 - val_loss: 11.7851\n",
      "Epoch 404/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7634 - val_loss: 9.2942\n",
      "Epoch 405/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6757 - val_loss: 9.5732\n",
      "Epoch 406/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6352 - val_loss: 10.2438\n",
      "Epoch 407/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.8247 - val_loss: 9.5406\n",
      "Epoch 408/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.4416 - val_loss: 9.2996\n",
      "Epoch 409/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.6201 - val_loss: 10.0291\n",
      "Epoch 410/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4551 - val_loss: 9.3911\n",
      "Epoch 411/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.6087 - val_loss: 9.2935\n",
      "Epoch 412/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.3755 - val_loss: 9.2063\n",
      "Epoch 413/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.4032 - val_loss: 9.0812\n",
      "Epoch 414/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7717 - val_loss: 9.4667\n",
      "Epoch 415/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6098 - val_loss: 9.5893\n",
      "Epoch 416/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.5580 - val_loss: 9.3881\n",
      "Epoch 417/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4561 - val_loss: 9.6153\n",
      "Epoch 418/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.4343 - val_loss: 9.6723\n",
      "Epoch 419/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.3999 - val_loss: 9.1555\n",
      "Epoch 420/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3298 - val_loss: 10.0947\n",
      "Epoch 421/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5348 - val_loss: 9.0826\n",
      "Epoch 422/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.1222 - val_loss: 10.1934\n",
      "Epoch 423/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5026 - val_loss: 9.2427\n",
      "Epoch 424/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5324 - val_loss: 9.3651\n",
      "Epoch 425/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3357 - val_loss: 9.7297\n",
      "Epoch 426/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4935 - val_loss: 9.3845\n",
      "Epoch 427/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4385 - val_loss: 11.2705\n",
      "Epoch 428/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.9123 - val_loss: 9.4718\n",
      "Epoch 429/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.9392 - val_loss: 9.4966\n",
      "Epoch 430/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4285 - val_loss: 9.9237\n",
      "Epoch 431/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3226 - val_loss: 9.1126\n",
      "Epoch 432/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0436 - val_loss: 11.5795\n",
      "Epoch 433/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.0287 - val_loss: 9.6901\n",
      "Epoch 434/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.8438 - val_loss: 9.1327\n",
      "Epoch 435/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.4777 - val_loss: 10.4808\n",
      "Epoch 436/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5833 - val_loss: 9.4887\n",
      "Epoch 437/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.4134 - val_loss: 8.8973\n",
      "Epoch 438/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5393 - val_loss: 10.0090\n",
      "Epoch 439/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4185 - val_loss: 9.3706\n",
      "Epoch 440/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6529 - val_loss: 9.1301\n",
      "Epoch 441/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2619 - val_loss: 9.7078\n",
      "Epoch 442/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.3178 - val_loss: 9.0546\n",
      "Epoch 443/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.5777 - val_loss: 10.3186\n",
      "Epoch 444/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4571 - val_loss: 9.5010\n",
      "Epoch 445/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1929 - val_loss: 9.8565\n",
      "Epoch 446/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3194 - val_loss: 9.4819\n",
      "Epoch 447/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.2462 - val_loss: 9.5039\n",
      "Epoch 448/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.5516 - val_loss: 10.0820\n",
      "Epoch 449/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4799 - val_loss: 9.1787\n",
      "Epoch 450/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 4.3136 - val_loss: 9.6696\n",
      "Epoch 451/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.3496 - val_loss: 9.9834\n",
      "Epoch 452/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3532 - val_loss: 9.5865\n",
      "Epoch 453/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 104us/step - loss: 4.3343 - val_loss: 10.0348\n",
      "Epoch 454/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 4.5227 - val_loss: 9.2831\n",
      "Epoch 455/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2939 - val_loss: 9.5876\n",
      "Epoch 456/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.3295 - val_loss: 9.8713\n",
      "Epoch 457/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1992 - val_loss: 9.6501\n",
      "Epoch 458/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1859 - val_loss: 9.3151\n",
      "Epoch 459/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2080 - val_loss: 9.6513\n",
      "Epoch 460/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2012 - val_loss: 9.3797\n",
      "Epoch 461/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.5742 - val_loss: 11.4702\n",
      "Epoch 462/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.7221 - val_loss: 9.6695\n",
      "Epoch 463/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2402 - val_loss: 9.3472\n",
      "Epoch 464/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2294 - val_loss: 10.1944\n",
      "Epoch 465/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3370 - val_loss: 9.2538\n",
      "Epoch 466/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4400 - val_loss: 10.5934\n",
      "Epoch 467/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5718 - val_loss: 10.8085\n",
      "Epoch 468/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.4572 - val_loss: 9.5305\n",
      "Epoch 469/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6427 - val_loss: 10.7926\n",
      "Epoch 470/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.3710 - val_loss: 9.7592\n",
      "Epoch 471/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3065 - val_loss: 9.5684\n",
      "Epoch 472/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.2056 - val_loss: 10.0254\n",
      "Epoch 473/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2727 - val_loss: 9.8526\n",
      "Epoch 474/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2667 - val_loss: 9.4920\n",
      "Epoch 475/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4423 - val_loss: 9.8743\n",
      "Epoch 476/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1926 - val_loss: 10.6960\n",
      "Epoch 477/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4700 - val_loss: 9.6059\n",
      "Epoch 478/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4164 - val_loss: 10.3039\n",
      "Epoch 479/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.5078 - val_loss: 10.7803\n",
      "Epoch 480/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9303 - val_loss: 9.9019\n",
      "Epoch 481/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5666 - val_loss: 10.6682\n",
      "Epoch 482/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5771 - val_loss: 10.1373\n",
      "Epoch 483/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.7381 - val_loss: 9.6727\n",
      "Epoch 484/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6453 - val_loss: 9.8736\n",
      "Epoch 485/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3107 - val_loss: 10.2535\n",
      "Epoch 486/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2794 - val_loss: 9.3673\n",
      "Epoch 487/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4155 - val_loss: 9.3303\n",
      "Epoch 488/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3366 - val_loss: 10.6762\n",
      "Epoch 489/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3517 - val_loss: 10.1595\n",
      "Epoch 490/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1877 - val_loss: 10.0922\n",
      "Epoch 491/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2617 - val_loss: 10.1262\n",
      "Epoch 492/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2166 - val_loss: 10.2931\n",
      "Epoch 493/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2603 - val_loss: 9.4764\n",
      "Epoch 494/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5672 - val_loss: 9.6229\n",
      "Epoch 495/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3783 - val_loss: 10.9533\n",
      "Epoch 496/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2406 - val_loss: 9.7395\n",
      "Epoch 497/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3088 - val_loss: 10.8579\n",
      "Epoch 498/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4895 - val_loss: 9.5244\n",
      "Epoch 499/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3661 - val_loss: 10.9219\n",
      "Epoch 500/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.3250 - val_loss: 9.8941\n",
      "Epoch 501/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.4165 - val_loss: 9.3940\n",
      "Epoch 502/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3575 - val_loss: 11.2757\n",
      "Epoch 503/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7174 - val_loss: 9.8163\n",
      "Epoch 504/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.4777 - val_loss: 9.6349\n",
      "Epoch 505/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4102 - val_loss: 11.2665\n",
      "Epoch 506/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.1890 - val_loss: 9.7351\n",
      "Epoch 507/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2687 - val_loss: 10.7902\n",
      "Epoch 508/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1847 - val_loss: 10.2033\n",
      "Epoch 509/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1712 - val_loss: 10.2760\n",
      "Epoch 510/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.1730 - val_loss: 10.1020\n",
      "Epoch 511/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1827 - val_loss: 9.7721\n",
      "Epoch 512/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.1204 - val_loss: 9.9321\n",
      "Epoch 513/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2014 - val_loss: 10.8976\n",
      "Epoch 514/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.2636 - val_loss: 9.9590\n",
      "Epoch 515/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4663 - val_loss: 9.9523\n",
      "Epoch 516/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9001 - val_loss: 13.3421\n",
      "Epoch 517/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.9994 - val_loss: 10.1121\n",
      "Epoch 518/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4071 - val_loss: 10.7649\n",
      "Epoch 519/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.4529 - val_loss: 9.7180\n",
      "Epoch 520/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.2364 - val_loss: 9.8046\n",
      "Epoch 521/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2105 - val_loss: 11.6373\n",
      "Epoch 522/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.4113 - val_loss: 9.7947\n",
      "Epoch 523/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.1360 - val_loss: 10.0796\n",
      "Epoch 524/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.0846 - val_loss: 10.1376\n",
      "Epoch 525/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.1612 - val_loss: 10.7966\n",
      "Epoch 526/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3933 - val_loss: 10.1565\n",
      "Epoch 527/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2643 - val_loss: 9.9572\n",
      "Epoch 528/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1321 - val_loss: 10.3099\n",
      "Epoch 529/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2110 - val_loss: 10.2664\n",
      "Epoch 530/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 108us/step - loss: 4.5252 - val_loss: 11.7044\n",
      "Epoch 531/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3284 - val_loss: 10.0544\n",
      "Epoch 532/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5346 - val_loss: 9.7475\n",
      "Epoch 533/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0208 - val_loss: 11.2219\n",
      "Epoch 534/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2655 - val_loss: 9.8997\n",
      "Epoch 535/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.4190 - val_loss: 10.8918\n",
      "Epoch 536/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2155 - val_loss: 10.6048\n",
      "Epoch 537/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.2274 - val_loss: 10.2864\n",
      "Epoch 538/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.1338 - val_loss: 10.4832\n",
      "Epoch 539/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0559 - val_loss: 10.3772\n",
      "Epoch 540/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0529 - val_loss: 11.0560\n",
      "Epoch 541/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.5908 - val_loss: 9.9119\n",
      "Epoch 542/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3897 - val_loss: 11.0406\n",
      "Epoch 543/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1542 - val_loss: 10.6941\n",
      "Epoch 544/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1190 - val_loss: 10.2315\n",
      "Epoch 545/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2349 - val_loss: 10.4197\n",
      "Epoch 546/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1762 - val_loss: 10.1978\n",
      "Epoch 547/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0299 - val_loss: 10.8338\n",
      "Epoch 548/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3005 - val_loss: 10.2436\n",
      "Epoch 549/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1026 - val_loss: 10.4330\n",
      "Epoch 550/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1424 - val_loss: 10.2633\n",
      "Epoch 551/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1879 - val_loss: 11.0339\n",
      "Epoch 552/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1881 - val_loss: 10.1543\n",
      "Epoch 553/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2467 - val_loss: 10.2900\n",
      "Epoch 554/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1917 - val_loss: 10.1598\n",
      "Epoch 555/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1741 - val_loss: 10.3960\n",
      "Epoch 556/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0792 - val_loss: 10.5874\n",
      "Epoch 557/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0758 - val_loss: 10.4335\n",
      "Epoch 558/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0585 - val_loss: 10.5697\n",
      "Epoch 559/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0496 - val_loss: 10.6542\n",
      "Epoch 560/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1922 - val_loss: 10.5182\n",
      "Epoch 561/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2471 - val_loss: 11.0183\n",
      "Epoch 562/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0124 - val_loss: 10.1417\n",
      "Epoch 563/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0946 - val_loss: 10.6755\n",
      "Epoch 564/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.1059 - val_loss: 11.0476\n",
      "Epoch 565/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.0346 - val_loss: 10.7612\n",
      "Epoch 566/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.1512 - val_loss: 10.7866\n",
      "Epoch 567/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.0970 - val_loss: 11.0356\n",
      "Epoch 568/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.9838 - val_loss: 10.2717\n",
      "Epoch 569/1000\n",
      "274/274 [==============================] - 0s 139us/step - loss: 4.0216 - val_loss: 11.1395\n",
      "Epoch 570/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 4.3704 - val_loss: 10.7105\n",
      "Epoch 571/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.7743 - val_loss: 10.2307\n",
      "Epoch 572/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.5861 - val_loss: 11.4231\n",
      "Epoch 573/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.3384 - val_loss: 10.3499\n",
      "Epoch 574/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 4.2167 - val_loss: 10.2983\n",
      "Epoch 575/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.5527 - val_loss: 12.5504\n",
      "Epoch 576/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.3873 - val_loss: 10.4515\n",
      "Epoch 577/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 4.3699 - val_loss: 10.6398\n",
      "Epoch 578/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.1851 - val_loss: 10.7226\n",
      "Epoch 579/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.2425 - val_loss: 11.4876\n",
      "Epoch 580/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 4.1591 - val_loss: 10.2589\n",
      "Epoch 581/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 4.4309 - val_loss: 11.2021\n",
      "Epoch 582/1000\n",
      "274/274 [==============================] - 0s 142us/step - loss: 4.4149 - val_loss: 10.6655\n",
      "Epoch 583/1000\n",
      "274/274 [==============================] - 0s 135us/step - loss: 4.0066 - val_loss: 10.5965\n",
      "Epoch 584/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.0927 - val_loss: 10.5160\n",
      "Epoch 585/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.0429 - val_loss: 10.4759\n",
      "Epoch 586/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.2550 - val_loss: 10.4451\n",
      "Epoch 587/1000\n",
      "274/274 [==============================] - 0s 135us/step - loss: 4.3215 - val_loss: 11.3399\n",
      "Epoch 588/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.2210 - val_loss: 10.7835\n",
      "Epoch 589/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1123 - val_loss: 10.8340\n",
      "Epoch 590/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0604 - val_loss: 10.7115\n",
      "Epoch 591/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.1360 - val_loss: 11.0435\n",
      "Epoch 592/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.0472 - val_loss: 10.5453\n",
      "Epoch 593/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.2453 - val_loss: 12.5030\n",
      "Epoch 594/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.3532 - val_loss: 10.7108\n",
      "Epoch 595/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 4.0440 - val_loss: 11.0583\n",
      "Epoch 596/1000\n",
      "274/274 [==============================] - 0s 138us/step - loss: 4.0356 - val_loss: 10.7565\n",
      "Epoch 597/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.0881 - val_loss: 10.9470\n",
      "Epoch 598/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4165 - val_loss: 13.3199\n",
      "Epoch 599/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.8683 - val_loss: 10.9264\n",
      "Epoch 600/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1025 - val_loss: 11.8473\n",
      "Epoch 601/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1076 - val_loss: 10.8244\n",
      "Epoch 602/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.3591 - val_loss: 10.5865\n",
      "Epoch 603/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4161 - val_loss: 12.3983\n",
      "Epoch 604/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7201 - val_loss: 11.0503\n",
      "Epoch 605/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0818 - val_loss: 10.8926\n",
      "Epoch 606/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0034 - val_loss: 11.0212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 607/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9293 - val_loss: 10.8746\n",
      "Epoch 608/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0530 - val_loss: 11.5257\n",
      "Epoch 609/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3897 - val_loss: 11.9081\n",
      "Epoch 610/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2310 - val_loss: 11.4008\n",
      "Epoch 611/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0820 - val_loss: 10.9405\n",
      "Epoch 612/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2615 - val_loss: 10.8357\n",
      "Epoch 613/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1737 - val_loss: 11.6387\n",
      "Epoch 614/1000\n",
      "274/274 [==============================] - 0s 135us/step - loss: 4.0288 - val_loss: 11.0453\n",
      "Epoch 615/1000\n",
      "274/274 [==============================] - 0s 118us/step - loss: 4.1331 - val_loss: 10.8045\n",
      "Epoch 616/1000\n",
      "274/274 [==============================] - 0s 118us/step - loss: 4.0971 - val_loss: 11.2860\n",
      "Epoch 617/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1193 - val_loss: 10.7765\n",
      "Epoch 618/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3260 - val_loss: 12.4816\n",
      "Epoch 619/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4043 - val_loss: 11.7271\n",
      "Epoch 620/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3744 - val_loss: 10.8826\n",
      "Epoch 621/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.5172 - val_loss: 13.4069\n",
      "Epoch 622/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3841 - val_loss: 11.0056\n",
      "Epoch 623/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1024 - val_loss: 12.2297\n",
      "Epoch 624/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1109 - val_loss: 11.1659\n",
      "Epoch 625/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3061 - val_loss: 11.5195\n",
      "Epoch 626/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2252 - val_loss: 12.1034\n",
      "Epoch 627/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1938 - val_loss: 11.0872\n",
      "Epoch 628/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9505 - val_loss: 11.8115\n",
      "Epoch 629/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3384 - val_loss: 11.0250\n",
      "Epoch 630/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9629 - val_loss: 11.9188\n",
      "Epoch 631/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0094 - val_loss: 11.1523\n",
      "Epoch 632/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9864 - val_loss: 11.2185\n",
      "Epoch 633/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0375 - val_loss: 11.4069\n",
      "Epoch 634/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0098 - val_loss: 11.4697\n",
      "Epoch 635/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0423 - val_loss: 11.4044\n",
      "Epoch 636/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9361 - val_loss: 11.1437\n",
      "Epoch 637/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9140 - val_loss: 11.3176\n",
      "Epoch 638/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9316 - val_loss: 11.7239\n",
      "Epoch 639/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.9188 - val_loss: 11.7147\n",
      "Epoch 640/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9477 - val_loss: 11.6225\n",
      "Epoch 641/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0475 - val_loss: 11.1958\n",
      "Epoch 642/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2983 - val_loss: 13.7156\n",
      "Epoch 643/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3623 - val_loss: 11.3264\n",
      "Epoch 644/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2412 - val_loss: 12.3117\n",
      "Epoch 645/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3121 - val_loss: 12.3941\n",
      "Epoch 646/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0696 - val_loss: 11.2698\n",
      "Epoch 647/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9440 - val_loss: 11.5754\n",
      "Epoch 648/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.0006 - val_loss: 11.9113\n",
      "Epoch 649/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0298 - val_loss: 11.7120\n",
      "Epoch 650/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0230 - val_loss: 11.6845\n",
      "Epoch 651/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.1839 - val_loss: 11.8191\n",
      "Epoch 652/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9050 - val_loss: 12.1420\n",
      "Epoch 653/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0596 - val_loss: 11.9013\n",
      "Epoch 654/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9408 - val_loss: 12.3145\n",
      "Epoch 655/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0345 - val_loss: 11.7147\n",
      "Epoch 656/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9686 - val_loss: 11.8364\n",
      "Epoch 657/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9952 - val_loss: 11.6328\n",
      "Epoch 658/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9905 - val_loss: 11.9722\n",
      "Epoch 659/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9014 - val_loss: 11.8460\n",
      "Epoch 660/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0372 - val_loss: 12.2465\n",
      "Epoch 661/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0364 - val_loss: 11.7240\n",
      "Epoch 662/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.1509 - val_loss: 11.5212\n",
      "Epoch 663/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2729 - val_loss: 12.3418\n",
      "Epoch 664/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.1239 - val_loss: 12.3101\n",
      "Epoch 665/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3424 - val_loss: 11.8628\n",
      "Epoch 666/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3446 - val_loss: 15.3322\n",
      "Epoch 667/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 5.0852 - val_loss: 11.5979\n",
      "Epoch 668/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4780 - val_loss: 11.7831\n",
      "Epoch 669/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1082 - val_loss: 12.3417\n",
      "Epoch 670/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0680 - val_loss: 11.3580\n",
      "Epoch 671/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0612 - val_loss: 12.9663\n",
      "Epoch 672/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1352 - val_loss: 11.4790\n",
      "Epoch 673/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9634 - val_loss: 12.1501\n",
      "Epoch 674/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 3.9457 - val_loss: 11.8886\n",
      "Epoch 675/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.0025 - val_loss: 11.5337\n",
      "Epoch 676/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9498 - val_loss: 12.6519\n",
      "Epoch 677/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 3.9775 - val_loss: 12.0703\n",
      "Epoch 678/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9398 - val_loss: 12.2372\n",
      "Epoch 679/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.9905 - val_loss: 11.6942\n",
      "Epoch 680/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9508 - val_loss: 12.1618\n",
      "Epoch 681/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0341 - val_loss: 11.7625\n",
      "Epoch 682/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7882 - val_loss: 12.3274\n",
      "Epoch 683/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.0390 - val_loss: 12.4067\n",
      "Epoch 684/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0827 - val_loss: 11.8016\n",
      "Epoch 685/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.1444 - val_loss: 12.0030\n",
      "Epoch 686/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0269 - val_loss: 11.9580\n",
      "Epoch 687/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9130 - val_loss: 11.3887\n",
      "Epoch 688/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 3.9167 - val_loss: 12.9071\n",
      "Epoch 689/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0519 - val_loss: 11.7069\n",
      "Epoch 690/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.0084 - val_loss: 11.7397\n",
      "Epoch 691/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5042 - val_loss: 14.2523\n",
      "Epoch 692/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2988 - val_loss: 11.8331\n",
      "Epoch 693/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1427 - val_loss: 12.5421\n",
      "Epoch 694/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0721 - val_loss: 11.4650\n",
      "Epoch 695/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.0691 - val_loss: 12.6647\n",
      "Epoch 696/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1013 - val_loss: 12.3860\n",
      "Epoch 697/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9886 - val_loss: 12.1381\n",
      "Epoch 698/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.0709 - val_loss: 12.5911\n",
      "Epoch 699/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8848 - val_loss: 11.9780\n",
      "Epoch 700/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9040 - val_loss: 12.2858\n",
      "Epoch 701/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0782 - val_loss: 11.6656\n",
      "Epoch 702/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1082 - val_loss: 12.2937\n",
      "Epoch 703/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1259 - val_loss: 11.4764\n",
      "Epoch 704/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6290 - val_loss: 14.0166\n",
      "Epoch 705/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.7159 - val_loss: 11.9857\n",
      "Epoch 706/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.6134 - val_loss: 11.8548\n",
      "Epoch 707/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.1528 - val_loss: 14.0723\n",
      "Epoch 708/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.3244 - val_loss: 11.8713\n",
      "Epoch 709/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.9826 - val_loss: 11.9955\n",
      "Epoch 710/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.8398 - val_loss: 12.1512\n",
      "Epoch 711/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0516 - val_loss: 12.5119\n",
      "Epoch 712/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.9394 - val_loss: 11.7682\n",
      "Epoch 713/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.8656 - val_loss: 11.8353\n",
      "Epoch 714/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.8507 - val_loss: 11.7860\n",
      "Epoch 715/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0266 - val_loss: 12.0505\n",
      "Epoch 716/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.8624 - val_loss: 12.4436\n",
      "Epoch 717/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 3.8805 - val_loss: 11.9010\n",
      "Epoch 718/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0640 - val_loss: 11.6867\n",
      "Epoch 719/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9044 - val_loss: 13.0017\n",
      "Epoch 720/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4652 - val_loss: 11.8480\n",
      "Epoch 721/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2663 - val_loss: 11.8987\n",
      "Epoch 722/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.0108 - val_loss: 12.1042\n",
      "Epoch 723/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.9100 - val_loss: 12.2359\n",
      "Epoch 724/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1578 - val_loss: 13.5081\n",
      "Epoch 725/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1978 - val_loss: 11.8335\n",
      "Epoch 726/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8760 - val_loss: 11.9266\n",
      "Epoch 727/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 3.9602 - val_loss: 11.9893\n",
      "Epoch 728/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.0458 - val_loss: 12.7837\n",
      "Epoch 729/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.1270 - val_loss: 11.9444\n",
      "Epoch 730/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.9856 - val_loss: 12.9642\n",
      "Epoch 731/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.8675 - val_loss: 11.7410\n",
      "Epoch 732/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9826 - val_loss: 12.1634\n",
      "Epoch 733/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 3.9457 - val_loss: 12.0045\n",
      "Epoch 734/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 3.9941 - val_loss: 11.8723\n",
      "Epoch 735/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0776 - val_loss: 13.5692\n",
      "Epoch 736/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2362 - val_loss: 11.5529\n",
      "Epoch 737/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 3.8784 - val_loss: 13.2329\n",
      "Epoch 738/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9575 - val_loss: 11.9937\n",
      "Epoch 739/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9343 - val_loss: 12.3233\n",
      "Epoch 740/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.1201 - val_loss: 11.8323\n",
      "Epoch 741/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.0728 - val_loss: 12.4601\n",
      "Epoch 742/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0301 - val_loss: 12.4808\n",
      "Epoch 743/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3219 - val_loss: 11.7474\n",
      "Epoch 744/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0968 - val_loss: 12.4934\n",
      "Epoch 745/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 3.9561 - val_loss: 12.2528\n",
      "Epoch 746/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1186 - val_loss: 12.1674\n",
      "Epoch 747/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 4.4250 - val_loss: 11.7347\n",
      "Epoch 748/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0321 - val_loss: 12.8197\n",
      "Epoch 749/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9707 - val_loss: 12.1098\n",
      "Epoch 750/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1790 - val_loss: 12.8249\n",
      "Epoch 751/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0427 - val_loss: 11.9225\n",
      "Epoch 752/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.9660 - val_loss: 11.9339\n",
      "Epoch 753/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.9350 - val_loss: 12.9708\n",
      "Epoch 754/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0280 - val_loss: 11.9526\n",
      "Epoch 755/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9571 - val_loss: 12.7067\n",
      "Epoch 756/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2228 - val_loss: 11.9905\n",
      "Epoch 757/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2781 - val_loss: 11.8082\n",
      "Epoch 758/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8845 - val_loss: 12.1719\n",
      "Epoch 759/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 101us/step - loss: 3.8415 - val_loss: 12.1648\n",
      "Epoch 760/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.8953 - val_loss: 12.1328\n",
      "Epoch 761/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9024 - val_loss: 12.1086\n",
      "Epoch 762/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8724 - val_loss: 12.2294\n",
      "Epoch 763/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.7927 - val_loss: 11.9306\n",
      "Epoch 764/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8271 - val_loss: 12.1692\n",
      "Epoch 765/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8829 - val_loss: 11.9100\n",
      "Epoch 766/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 3.9149 - val_loss: 12.0983\n",
      "Epoch 767/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2165 - val_loss: 11.6238\n",
      "Epoch 768/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0224 - val_loss: 12.6869\n",
      "Epoch 769/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0480 - val_loss: 12.0575\n",
      "Epoch 770/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.8186 - val_loss: 12.2252\n",
      "Epoch 771/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0395 - val_loss: 13.0748\n",
      "Epoch 772/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9893 - val_loss: 12.2984\n",
      "Epoch 773/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8892 - val_loss: 11.8410\n",
      "Epoch 774/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8175 - val_loss: 12.0090\n",
      "Epoch 775/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9123 - val_loss: 12.2872\n",
      "Epoch 776/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7570 - val_loss: 12.2014\n",
      "Epoch 777/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.9329 - val_loss: 11.9089\n",
      "Epoch 778/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8532 - val_loss: 11.8040\n",
      "Epoch 779/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9700 - val_loss: 11.8583\n",
      "Epoch 780/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9902 - val_loss: 12.1661\n",
      "Epoch 781/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8936 - val_loss: 12.2929\n",
      "Epoch 782/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 3.7976 - val_loss: 11.8488\n",
      "Epoch 783/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8603 - val_loss: 12.0382\n",
      "Epoch 784/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8147 - val_loss: 11.9465\n",
      "Epoch 785/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1059 - val_loss: 11.5501\n",
      "Epoch 786/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9988 - val_loss: 13.7159\n",
      "Epoch 787/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1286 - val_loss: 12.2832\n",
      "Epoch 788/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8924 - val_loss: 12.4981\n",
      "Epoch 789/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8938 - val_loss: 11.7035\n",
      "Epoch 790/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8622 - val_loss: 11.7859\n",
      "Epoch 791/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8076 - val_loss: 12.1806\n",
      "Epoch 792/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9262 - val_loss: 12.0069\n",
      "Epoch 793/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9127 - val_loss: 12.5432\n",
      "Epoch 794/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.0131 - val_loss: 11.6732\n",
      "Epoch 795/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0914 - val_loss: 13.0458\n",
      "Epoch 796/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0926 - val_loss: 11.6836\n",
      "Epoch 797/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.9802 - val_loss: 11.5108\n",
      "Epoch 798/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1576 - val_loss: 12.2020\n",
      "Epoch 799/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.1638 - val_loss: 12.6095\n",
      "Epoch 800/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8639 - val_loss: 11.9427\n",
      "Epoch 801/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.0092 - val_loss: 11.8061\n",
      "Epoch 802/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 3.8823 - val_loss: 12.1000\n",
      "Epoch 803/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 3.8369 - val_loss: 12.1825\n",
      "Epoch 804/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9333 - val_loss: 12.6973\n",
      "Epoch 805/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1129 - val_loss: 11.5814\n",
      "Epoch 806/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.4480 - val_loss: 12.3817\n",
      "Epoch 807/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8210 - val_loss: 11.6758\n",
      "Epoch 808/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9512 - val_loss: 12.1683\n",
      "Epoch 809/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9167 - val_loss: 12.7078\n",
      "Epoch 810/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.7859 - val_loss: 11.8151\n",
      "Epoch 811/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9102 - val_loss: 12.5207\n",
      "Epoch 812/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8827 - val_loss: 11.8171\n",
      "Epoch 813/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3119 - val_loss: 12.9770\n",
      "Epoch 814/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.0279 - val_loss: 12.4497\n",
      "Epoch 815/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.7588 - val_loss: 12.3259\n",
      "Epoch 816/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 3.7545 - val_loss: 11.8342\n",
      "Epoch 817/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 3.9201 - val_loss: 11.7614\n",
      "Epoch 818/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 3.7904 - val_loss: 12.0257\n",
      "Epoch 819/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 3.8409 - val_loss: 11.8356\n",
      "Epoch 820/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8850 - val_loss: 11.9665\n",
      "Epoch 821/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7642 - val_loss: 11.8057\n",
      "Epoch 822/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.7817 - val_loss: 11.7571\n",
      "Epoch 823/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.3458 - val_loss: 13.7829\n",
      "Epoch 824/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.0992 - val_loss: 12.0431\n",
      "Epoch 825/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.8209 - val_loss: 12.6718\n",
      "Epoch 826/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8714 - val_loss: 11.9157\n",
      "Epoch 827/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0184 - val_loss: 11.9218\n",
      "Epoch 828/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9828 - val_loss: 12.6508\n",
      "Epoch 829/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.8687 - val_loss: 11.9619\n",
      "Epoch 830/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.7713 - val_loss: 11.8415\n",
      "Epoch 831/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.8241 - val_loss: 13.1030\n",
      "Epoch 832/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.8604 - val_loss: 11.6224\n",
      "Epoch 833/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9998 - val_loss: 12.2807\n",
      "Epoch 834/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.9381 - val_loss: 12.0677\n",
      "Epoch 835/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.0198 - val_loss: 11.6071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 836/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.1553 - val_loss: 13.2124\n",
      "Epoch 837/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9833 - val_loss: 11.7902\n",
      "Epoch 838/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.7298 - val_loss: 12.2273\n",
      "Epoch 839/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9555 - val_loss: 11.7172\n",
      "Epoch 840/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.9850 - val_loss: 11.7956\n",
      "Epoch 841/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9410 - val_loss: 12.1545\n",
      "Epoch 842/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9980 - val_loss: 12.6266\n",
      "Epoch 843/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0537 - val_loss: 12.0363\n",
      "Epoch 844/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.9417 - val_loss: 12.2144\n",
      "Epoch 845/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.8741 - val_loss: 12.0340\n",
      "Epoch 846/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.8783 - val_loss: 12.6394\n",
      "Epoch 847/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.9651 - val_loss: 12.2543\n",
      "Epoch 848/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 3.9375 - val_loss: 12.3146\n",
      "Epoch 849/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.7650 - val_loss: 11.9001\n",
      "Epoch 850/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7982 - val_loss: 12.3386\n",
      "Epoch 851/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9382 - val_loss: 11.5259\n",
      "Epoch 852/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9669 - val_loss: 13.4843\n",
      "Epoch 853/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1212 - val_loss: 11.7175\n",
      "Epoch 854/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.8197 - val_loss: 11.7463\n",
      "Epoch 855/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.7323 - val_loss: 12.5064\n",
      "Epoch 856/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8608 - val_loss: 11.7112\n",
      "Epoch 857/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.9242 - val_loss: 12.0011\n",
      "Epoch 858/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.8130 - val_loss: 11.9660\n",
      "Epoch 859/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.8794 - val_loss: 12.1025\n",
      "Epoch 860/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9146 - val_loss: 12.4631\n",
      "Epoch 861/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 3.7760 - val_loss: 12.2112\n",
      "Epoch 862/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 3.7958 - val_loss: 12.1789\n",
      "Epoch 863/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 3.7723 - val_loss: 12.0092\n",
      "Epoch 864/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8528 - val_loss: 11.9797\n",
      "Epoch 865/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9024 - val_loss: 12.1449\n",
      "Epoch 866/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.9338 - val_loss: 11.8437\n",
      "Epoch 867/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3147 - val_loss: 12.7060\n",
      "Epoch 868/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.1297 - val_loss: 12.8316\n",
      "Epoch 869/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.8775 - val_loss: 11.6393\n",
      "Epoch 870/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1097 - val_loss: 12.1766\n",
      "Epoch 871/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 3.8919 - val_loss: 12.0616\n",
      "Epoch 872/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9546 - val_loss: 12.3886\n",
      "Epoch 873/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8572 - val_loss: 12.2976\n",
      "Epoch 874/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.8400 - val_loss: 11.9874\n",
      "Epoch 875/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.7972 - val_loss: 12.4648\n",
      "Epoch 876/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.9367 - val_loss: 11.8133\n",
      "Epoch 877/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.7805 - val_loss: 12.1546\n",
      "Epoch 878/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 3.7614 - val_loss: 12.0661\n",
      "Epoch 879/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 3.7289 - val_loss: 11.8932\n",
      "Epoch 880/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 3.8037 - val_loss: 11.8657\n",
      "Epoch 881/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.7466 - val_loss: 11.9773\n",
      "Epoch 882/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 3.7666 - val_loss: 11.7073\n",
      "Epoch 883/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8345 - val_loss: 12.5703\n",
      "Epoch 884/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1330 - val_loss: 12.2281\n",
      "Epoch 885/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.1973 - val_loss: 11.7842\n",
      "Epoch 886/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.9852 - val_loss: 11.8502\n",
      "Epoch 887/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7227 - val_loss: 12.0136\n",
      "Epoch 888/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8162 - val_loss: 12.0664\n",
      "Epoch 889/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.7613 - val_loss: 11.9436\n",
      "Epoch 890/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.7530 - val_loss: 12.0725\n",
      "Epoch 891/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.6919 - val_loss: 11.6627\n",
      "Epoch 892/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7624 - val_loss: 12.5025\n",
      "Epoch 893/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.8827 - val_loss: 12.0227\n",
      "Epoch 894/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 3.9650 - val_loss: 12.1900\n",
      "Epoch 895/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 3.8751 - val_loss: 11.7686\n",
      "Epoch 896/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.9469 - val_loss: 11.3882\n",
      "Epoch 897/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 3.7063 - val_loss: 12.3254\n",
      "Epoch 898/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.7846 - val_loss: 11.8576\n",
      "Epoch 899/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7983 - val_loss: 11.7709\n",
      "Epoch 900/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.7792 - val_loss: 12.1228\n",
      "Epoch 901/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.8192 - val_loss: 11.8527\n",
      "Epoch 902/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.7102 - val_loss: 11.7985\n",
      "Epoch 903/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.7687 - val_loss: 11.9627\n",
      "Epoch 904/1000\n",
      "274/274 [==============================] - 0s 175us/step - loss: 3.9132 - val_loss: 11.5113\n",
      "Epoch 905/1000\n",
      "274/274 [==============================] - 0s 142us/step - loss: 3.9870 - val_loss: 13.1411\n",
      "Epoch 906/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1780 - val_loss: 12.1166\n",
      "Epoch 907/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8081 - val_loss: 12.6496\n",
      "Epoch 908/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.9858 - val_loss: 12.0300\n",
      "Epoch 909/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.9163 - val_loss: 11.8266\n",
      "Epoch 910/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.9897 - val_loss: 12.0956\n",
      "Epoch 911/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 3.6933 - val_loss: 11.7612\n",
      "Epoch 912/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 3.7755 - val_loss: 12.4585\n",
      "Epoch 913/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.8978 - val_loss: 11.6763\n",
      "Epoch 914/1000\n",
      "274/274 [==============================] - 0s 135us/step - loss: 3.7568 - val_loss: 11.9979\n",
      "Epoch 915/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 3.8865 - val_loss: 12.1845\n",
      "Epoch 916/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.6561 - val_loss: 12.0941\n",
      "Epoch 917/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.0934 - val_loss: 12.4790\n",
      "Epoch 918/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 3.9939 - val_loss: 12.1707\n",
      "Epoch 919/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 3.7563 - val_loss: 11.6960\n",
      "Epoch 920/1000\n",
      "274/274 [==============================] - 0s 117us/step - loss: 4.1504 - val_loss: 12.9286\n",
      "Epoch 921/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3058 - val_loss: 12.0274\n",
      "Epoch 922/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1058 - val_loss: 11.9574\n",
      "Epoch 923/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 3.8985 - val_loss: 11.6845\n",
      "Epoch 924/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.6762 - val_loss: 11.8891\n",
      "Epoch 925/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7235 - val_loss: 11.9312\n",
      "Epoch 926/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0338 - val_loss: 11.4324\n",
      "Epoch 927/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.8600 - val_loss: 12.3579\n",
      "Epoch 928/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.8704 - val_loss: 11.7243\n",
      "Epoch 929/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9327 - val_loss: 11.5663\n",
      "Epoch 930/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7626 - val_loss: 12.0942\n",
      "Epoch 931/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.7244 - val_loss: 11.8294\n",
      "Epoch 932/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.9025 - val_loss: 11.6391\n",
      "Epoch 933/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.7522 - val_loss: 11.6972\n",
      "Epoch 934/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8335 - val_loss: 11.5749\n",
      "Epoch 935/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 3.7477 - val_loss: 11.6065\n",
      "Epoch 936/1000\n",
      "274/274 [==============================] - 0s 117us/step - loss: 3.8421 - val_loss: 12.5817\n",
      "Epoch 937/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0116 - val_loss: 11.4082\n",
      "Epoch 938/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7952 - val_loss: 11.8431\n",
      "Epoch 939/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.7489 - val_loss: 11.5504\n",
      "Epoch 940/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 3.7903 - val_loss: 11.3776\n",
      "Epoch 941/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 3.9405 - val_loss: 11.5021\n",
      "Epoch 942/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8179 - val_loss: 11.8725\n",
      "Epoch 943/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 3.7103 - val_loss: 11.9842\n",
      "Epoch 944/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.7401 - val_loss: 11.7110\n",
      "Epoch 945/1000\n",
      "274/274 [==============================] - 0s 122us/step - loss: 3.7191 - val_loss: 11.6738\n",
      "Epoch 946/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.6982 - val_loss: 11.6161\n",
      "Epoch 947/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7967 - val_loss: 12.2160\n",
      "Epoch 948/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7508 - val_loss: 11.4008\n",
      "Epoch 949/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.6841 - val_loss: 11.5689\n",
      "Epoch 950/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 3.7275 - val_loss: 12.1869\n",
      "Epoch 951/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 3.9935 - val_loss: 11.6296\n",
      "Epoch 952/1000\n",
      "274/274 [==============================] - 0s 119us/step - loss: 4.1742 - val_loss: 12.4876\n",
      "Epoch 953/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.8611 - val_loss: 11.2474\n",
      "Epoch 954/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.7435 - val_loss: 11.9781\n",
      "Epoch 955/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 3.8208 - val_loss: 11.4087\n",
      "Epoch 956/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.7974 - val_loss: 11.4125\n",
      "Epoch 957/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.8627 - val_loss: 12.5261\n",
      "Epoch 958/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.1400 - val_loss: 11.4809\n",
      "Epoch 959/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.8024 - val_loss: 11.6147\n",
      "Epoch 960/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0946 - val_loss: 12.2483\n",
      "Epoch 961/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.7697 - val_loss: 11.8676\n",
      "Epoch 962/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7578 - val_loss: 11.4187\n",
      "Epoch 963/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9472 - val_loss: 11.5250\n",
      "Epoch 964/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.2292 - val_loss: 12.6276\n",
      "Epoch 965/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.9963 - val_loss: 11.5932\n",
      "Epoch 966/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.6932 - val_loss: 11.7441\n",
      "Epoch 967/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8383 - val_loss: 11.6164\n",
      "Epoch 968/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0824 - val_loss: 12.5193\n",
      "Epoch 969/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0031 - val_loss: 11.8283\n",
      "Epoch 970/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 3.7215 - val_loss: 11.2089\n",
      "Epoch 971/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 3.7281 - val_loss: 11.3000\n",
      "Epoch 972/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 3.7782 - val_loss: 11.7303\n",
      "Epoch 973/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 3.6610 - val_loss: 11.6287\n",
      "Epoch 974/1000\n",
      "274/274 [==============================] - 0s 115us/step - loss: 3.6560 - val_loss: 11.8929\n",
      "Epoch 975/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.7023 - val_loss: 11.2690\n",
      "Epoch 976/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.7997 - val_loss: 11.7030\n",
      "Epoch 977/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 3.8043 - val_loss: 12.1505\n",
      "Epoch 978/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.9489 - val_loss: 11.9305\n",
      "Epoch 979/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7987 - val_loss: 11.4090\n",
      "Epoch 980/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1913 - val_loss: 12.8513\n",
      "Epoch 981/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0448 - val_loss: 11.3706\n",
      "Epoch 982/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9274 - val_loss: 11.2680\n",
      "Epoch 983/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8973 - val_loss: 11.7324\n",
      "Epoch 984/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 3.7328 - val_loss: 11.4052\n",
      "Epoch 985/1000\n",
      "274/274 [==============================] - 0s 115us/step - loss: 3.8890 - val_loss: 11.8106\n",
      "Epoch 986/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.3221 - val_loss: 11.5398\n",
      "Epoch 987/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1938 - val_loss: 11.8853\n",
      "Epoch 988/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.0085 - val_loss: 11.8525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 989/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 3.7390 - val_loss: 11.4907\n",
      "Epoch 990/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 3.9799 - val_loss: 11.8065\n",
      "Epoch 991/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 3.8006 - val_loss: 11.7417\n",
      "Epoch 992/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1923 - val_loss: 11.5913\n",
      "Epoch 993/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0162 - val_loss: 11.5335\n",
      "Epoch 994/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8471 - val_loss: 11.5371\n",
      "Epoch 995/1000\n",
      "274/274 [==============================] - 0s 115us/step - loss: 3.8924 - val_loss: 11.5389\n",
      "Epoch 996/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.7849 - val_loss: 12.2400\n",
      "Epoch 997/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.8439 - val_loss: 11.1868\n",
      "Epoch 998/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0184 - val_loss: 11.6166\n",
      "Epoch 999/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7567 - val_loss: 11.7762\n",
      "Epoch 1000/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7348 - val_loss: 11.5535\n",
      "8.827140985909155\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 0.05218785, -4.439589  ,  1.184245  , -0.32698205, -1.9974234 ,\n",
       "         -1.882257  , -0.8196187 , -0.21171416, -1.1699376 ,  0.5623695 ],\n",
       "        [-0.8764483 ,  3.2636888 , -1.4104617 ,  0.20296542, -1.9889956 ,\n",
       "         -0.8744576 ,  1.8381467 , -0.40577483,  0.8736507 , -2.3100579 ],\n",
       "        [-0.27670828, -0.42422557, -0.55878794, -0.52224237, -2.5005019 ,\n",
       "          1.1224926 ,  0.8319177 ,  0.20461716,  0.07792918,  1.2341498 ],\n",
       "        [ 1.5049043 , -2.7252157 ,  1.696431  , -1.0925831 ,  0.7352186 ,\n",
       "          1.5018852 , -0.48673   ,  0.16460963, -0.936903  ,  3.003468  ],\n",
       "        [-1.3972381 ,  0.52844405, -0.32371458, -1.2367066 , -0.03497618,\n",
       "          0.19337356, -0.6444655 ,  0.19330864,  1.0046711 , -0.80353117],\n",
       "        [ 0.8101482 ,  1.0985392 , -2.1631794 ,  1.1020138 ,  1.3484505 ,\n",
       "          1.2724284 ,  0.46078345, -0.02956701, -0.3547916 , -1.2015022 ],\n",
       "        [ 1.640306  ,  1.1607018 ,  0.03521889, -0.84423286, -0.720385  ,\n",
       "         -0.68723327, -0.09126253,  0.40228236,  0.3040376 ,  0.90780663]],\n",
       "       dtype=float32),\n",
       " array([ 3.3452408 , -1.3508025 ,  2.1693919 ,  2.593994  , -1.8498158 ,\n",
       "        -2.3370326 ,  1.6928627 ,  2.039521  , -1.3810889 , -0.22684453],\n",
       "       dtype=float32),\n",
       " array([[-0.11905567,  0.17031342, -0.17230722, -0.3622739 ,  0.6201032 ,\n",
       "          0.8522605 , -0.88094735, -0.08297026,  0.16717078,  0.29086316,\n",
       "         -0.08419093,  0.6167069 ,  0.72046244,  0.6419352 , -0.14539923],\n",
       "        [ 0.6227468 ,  0.91616994,  0.23793946,  0.21468915,  1.2675059 ,\n",
       "          0.58172816, -0.64113635, -0.23842998,  0.4537062 ,  0.1575628 ,\n",
       "         -0.9279709 ,  1.1034201 ,  0.4976866 ,  0.6095368 , -0.04162461],\n",
       "        [-0.4227509 , -0.9311723 , -0.26261944, -0.54093957, -0.10723604,\n",
       "         -0.8897598 ,  0.54405296,  0.01600639, -1.1332226 , -0.42569968,\n",
       "          0.8730632 , -0.7609323 , -0.83871454, -0.22108869, -0.00996081],\n",
       "        [ 0.6011236 , -0.17323911, -0.4199094 ,  0.3892695 ,  0.31689432,\n",
       "          0.4354588 , -0.77949196, -0.31424144,  0.4611906 , -0.4310094 ,\n",
       "          0.03074859,  0.01663151,  0.5184909 ,  0.6262726 , -0.13875283],\n",
       "        [-0.25132382, -0.5048929 , -0.5073935 , -0.48569214, -0.7002839 ,\n",
       "         -0.0758285 ,  0.04555811,  0.33214727, -0.42967913, -0.37351608,\n",
       "          0.61954063, -0.6480976 , -0.28970706, -0.7266997 ,  0.16016832],\n",
       "        [ 0.07683669, -0.8514909 ,  0.20426062, -0.56529874, -0.82431996,\n",
       "         -0.619225  ,  0.8501001 ,  0.10070304,  0.14537163, -0.08821295,\n",
       "          0.25395134, -0.56231   , -0.549881  , -0.6353222 ,  0.06425147],\n",
       "        [-0.9187346 , -0.8235141 , -1.018234  , -0.95494866, -0.8865123 ,\n",
       "         -0.6526    ,  1.065823  ,  0.0672754 , -1.178206  , -0.98365134,\n",
       "          1.3993115 , -1.1445355 , -1.1835938 , -1.1701462 ,  0.08799249],\n",
       "        [ 0.3888259 ,  0.20782284, -0.06034059,  0.5585033 ,  0.7887944 ,\n",
       "          0.66017   , -0.7405067 , -0.44860446,  0.28593364,  0.18148345,\n",
       "         -0.6773066 ,  0.72269183,  0.35031846,  0.49626622, -0.5727521 ],\n",
       "        [-0.06069385, -0.8281089 , -0.6823838 , -0.26091823, -0.6320657 ,\n",
       "         -0.9113052 ,  0.54186654,  0.04252985, -0.6899441 ,  0.01820265,\n",
       "          0.5641689 , -0.91924244, -0.45582813, -0.9039207 ,  0.10915282],\n",
       "        [-0.12513353, -0.46016374, -0.1727592 , -0.5175148 , -0.23006397,\n",
       "         -0.5669245 ,  0.5349784 ,  0.17658953,  0.21095765, -0.40834257,\n",
       "         -0.19185713, -0.04804634, -0.5724751 , -0.68641096,  0.07997985]],\n",
       "       dtype=float32),\n",
       " array([ 1.3760272 ,  1.5345865 ,  1.184792  ,  1.32401   ,  1.5048667 ,\n",
       "         1.5330626 , -1.519628  ,  0.82837856,  1.4196593 ,  1.253086  ,\n",
       "        -1.4622939 ,  1.5113616 ,  1.5513659 ,  1.508606  ,  0.8241068 ],\n",
       "       dtype=float32),\n",
       " array([[ 0.44113538],\n",
       "        [ 0.728448  ],\n",
       "        [ 0.0120625 ],\n",
       "        [ 0.3724175 ],\n",
       "        [ 1.0042342 ],\n",
       "        [ 0.95749396],\n",
       "        [-0.98005295],\n",
       "        [ 0.00432972],\n",
       "        [ 0.37178728],\n",
       "        [ 0.16168721],\n",
       "        [-0.55937713],\n",
       "        [ 0.76652503],\n",
       "        [ 0.90242535],\n",
       "        [ 1.0173599 ],\n",
       "        [ 0.00364132]], dtype=float32),\n",
       " array([1.6182108], dtype=float32)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_autompg, history_autompg=NN_model_structure_regression_6(X_train_autompg, X_val_autompg, Y_train_autompg, Y_val_autompg, adam2, 32, 1000)\n",
    "model_autompg.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_autompg.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_autompg_structure6.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_37 (Dense)             (None, 5)                 115       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 151\n",
      "Trainable params: 151\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 143 samples, validate on 31 samples\n",
      "Epoch 1/1000\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2884 - val_loss: 0.0409\n",
      "Epoch 2/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0730 - val_loss: 0.0586\n",
      "Epoch 3/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0611 - val_loss: 0.0321\n",
      "Epoch 4/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0590 - val_loss: 0.0282\n",
      "Epoch 5/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0399 - val_loss: 0.0193\n",
      "Epoch 6/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0337 - val_loss: 0.0141\n",
      "Epoch 7/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0284 - val_loss: 0.0171\n",
      "Epoch 8/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0205 - val_loss: 0.0133\n",
      "Epoch 9/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0211 - val_loss: 0.0107\n",
      "Epoch 10/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0230 - val_loss: 0.0069\n",
      "Epoch 11/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0197 - val_loss: 0.0080\n",
      "Epoch 12/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0170 - val_loss: 0.0089\n",
      "Epoch 13/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0160 - val_loss: 0.0100\n",
      "Epoch 14/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0117 - val_loss: 0.0083\n",
      "Epoch 15/1000\n",
      "143/143 [==============================] - 0s 149us/step - loss: 0.0120 - val_loss: 0.0077\n",
      "Epoch 16/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0103 - val_loss: 0.0068\n",
      "Epoch 17/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0098 - val_loss: 0.0067\n",
      "Epoch 18/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0096 - val_loss: 0.0067\n",
      "Epoch 19/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0096 - val_loss: 0.0066\n",
      "Epoch 20/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0093 - val_loss: 0.0068\n",
      "Epoch 21/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0090 - val_loss: 0.0064\n",
      "Epoch 22/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0087 - val_loss: 0.0063\n",
      "Epoch 23/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0084 - val_loss: 0.0061\n",
      "Epoch 24/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0099 - val_loss: 0.0059\n",
      "Epoch 25/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0100 - val_loss: 0.0064\n",
      "Epoch 26/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0087 - val_loss: 0.0069\n",
      "Epoch 27/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0104 - val_loss: 0.0061\n",
      "Epoch 28/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0085 - val_loss: 0.0060\n",
      "Epoch 29/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0081 - val_loss: 0.0070\n",
      "Epoch 30/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0082 - val_loss: 0.0058\n",
      "Epoch 31/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0080 - val_loss: 0.0060\n",
      "Epoch 32/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0080 - val_loss: 0.0057\n",
      "Epoch 33/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0078 - val_loss: 0.0057\n",
      "Epoch 34/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0074 - val_loss: 0.0063\n",
      "Epoch 35/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0078 - val_loss: 0.0055\n",
      "Epoch 36/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0074 - val_loss: 0.0055\n",
      "Epoch 37/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0072 - val_loss: 0.0054\n",
      "Epoch 38/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0074 - val_loss: 0.0054\n",
      "Epoch 39/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0072 - val_loss: 0.0054\n",
      "Epoch 40/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0078 - val_loss: 0.0055\n",
      "Epoch 41/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0079 - val_loss: 0.0054\n",
      "Epoch 42/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0078 - val_loss: 0.0060\n",
      "Epoch 43/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0074 - val_loss: 0.0052\n",
      "Epoch 44/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0071 - val_loss: 0.0055\n",
      "Epoch 45/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0070 - val_loss: 0.0053\n",
      "Epoch 46/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0070 - val_loss: 0.0052\n",
      "Epoch 47/1000\n",
      "143/143 [==============================] - 0s 130us/step - loss: 0.0071 - val_loss: 0.0052\n",
      "Epoch 48/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0069 - val_loss: 0.0053\n",
      "Epoch 49/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0068 - val_loss: 0.0052\n",
      "Epoch 50/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0068 - val_loss: 0.0051\n",
      "Epoch 51/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0067 - val_loss: 0.0051\n",
      "Epoch 52/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0067 - val_loss: 0.0054\n",
      "Epoch 53/1000\n",
      "143/143 [==============================] - 0s 138us/step - loss: 0.0068 - val_loss: 0.0052\n",
      "Epoch 54/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0067 - val_loss: 0.0054\n",
      "Epoch 55/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0066 - val_loss: 0.0052\n",
      "Epoch 56/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0066 - val_loss: 0.0052\n",
      "Epoch 57/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0069 - val_loss: 0.0049\n",
      "Epoch 58/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0071 - val_loss: 0.0048\n",
      "Epoch 59/1000\n",
      "143/143 [==============================] - 0s 154us/step - loss: 0.0068 - val_loss: 0.0054\n",
      "Epoch 60/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0066 - val_loss: 0.0050\n",
      "Epoch 61/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0065 - val_loss: 0.0055\n",
      "Epoch 62/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0064 - val_loss: 0.0049\n",
      "Epoch 63/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0066 - val_loss: 0.0049\n",
      "Epoch 64/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0063 - val_loss: 0.0054\n",
      "Epoch 65/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0065 - val_loss: 0.0049\n",
      "Epoch 66/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0066 - val_loss: 0.0052\n",
      "Epoch 67/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0065 - val_loss: 0.0051\n",
      "Epoch 68/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0065 - val_loss: 0.0052\n",
      "Epoch 69/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 105us/step - loss: 0.0063 - val_loss: 0.0049\n",
      "Epoch 70/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0061 - val_loss: 0.0052\n",
      "Epoch 71/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0062 - val_loss: 0.0046\n",
      "Epoch 72/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0066 - val_loss: 0.0047\n",
      "Epoch 73/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0061 - val_loss: 0.0049\n",
      "Epoch 74/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0061 - val_loss: 0.0049\n",
      "Epoch 75/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0061 - val_loss: 0.0047\n",
      "Epoch 76/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0061 - val_loss: 0.0049\n",
      "Epoch 77/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0063 - val_loss: 0.0046\n",
      "Epoch 78/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0060 - val_loss: 0.0049\n",
      "Epoch 79/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0061 - val_loss: 0.0048\n",
      "Epoch 80/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0061 - val_loss: 0.0049\n",
      "Epoch 81/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0070 - val_loss: 0.0046\n",
      "Epoch 82/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0069 - val_loss: 0.0054\n",
      "Epoch 83/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0060 - val_loss: 0.0052\n",
      "Epoch 84/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0062 - val_loss: 0.0053\n",
      "Epoch 85/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0064 - val_loss: 0.0047\n",
      "Epoch 86/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0068 - val_loss: 0.0048\n",
      "Epoch 87/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0074 - val_loss: 0.0048\n",
      "Epoch 88/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0069 - val_loss: 0.0047\n",
      "Epoch 89/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0058 - val_loss: 0.0054\n",
      "Epoch 90/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0062 - val_loss: 0.0045\n",
      "Epoch 91/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0058 - val_loss: 0.0045\n",
      "Epoch 92/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0057 - val_loss: 0.0046\n",
      "Epoch 93/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0060 - val_loss: 0.0045\n",
      "Epoch 94/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0057 - val_loss: 0.0047\n",
      "Epoch 95/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0057 - val_loss: 0.0046\n",
      "Epoch 96/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0057 - val_loss: 0.0048\n",
      "Epoch 97/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0057 - val_loss: 0.0045\n",
      "Epoch 98/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 99/1000\n",
      "143/143 [==============================] - 0s 136us/step - loss: 0.0057 - val_loss: 0.0044\n",
      "Epoch 100/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0057 - val_loss: 0.0045\n",
      "Epoch 101/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 102/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0060 - val_loss: 0.0046\n",
      "Epoch 103/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0060 - val_loss: 0.0044\n",
      "Epoch 104/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0055 - val_loss: 0.0054\n",
      "Epoch 105/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0058 - val_loss: 0.0044\n",
      "Epoch 106/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0057 - val_loss: 0.0048\n",
      "Epoch 107/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0056 - val_loss: 0.0045\n",
      "Epoch 108/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0057 - val_loss: 0.0043\n",
      "Epoch 109/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0057 - val_loss: 0.0046\n",
      "Epoch 110/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0056 - val_loss: 0.0042\n",
      "Epoch 111/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 112/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0055 - val_loss: 0.0046\n",
      "Epoch 113/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 114/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0056 - val_loss: 0.0042\n",
      "Epoch 115/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0055 - val_loss: 0.0046\n",
      "Epoch 116/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0053 - val_loss: 0.0043\n",
      "Epoch 117/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0059 - val_loss: 0.0047\n",
      "Epoch 118/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0060 - val_loss: 0.0046\n",
      "Epoch 119/1000\n",
      "143/143 [==============================] - 0s 129us/step - loss: 0.0058 - val_loss: 0.0043\n",
      "Epoch 120/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0059 - val_loss: 0.0052\n",
      "Epoch 121/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0054 - val_loss: 0.0043\n",
      "Epoch 122/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 123/1000\n",
      "143/143 [==============================] - 0s 140us/step - loss: 0.0055 - val_loss: 0.0043\n",
      "Epoch 124/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0054 - val_loss: 0.0045\n",
      "Epoch 125/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 126/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0053 - val_loss: 0.0044\n",
      "Epoch 127/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0055 - val_loss: 0.0046\n",
      "Epoch 128/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0054 - val_loss: 0.0045\n",
      "Epoch 129/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0057 - val_loss: 0.0044\n",
      "Epoch 130/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 131/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0054 - val_loss: 0.0044\n",
      "Epoch 132/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 133/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0051 - val_loss: 0.0041\n",
      "Epoch 134/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0053 - val_loss: 0.0047\n",
      "Epoch 135/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0053 - val_loss: 0.0041\n",
      "Epoch 136/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0052 - val_loss: 0.0045\n",
      "Epoch 137/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0052 - val_loss: 0.0046\n",
      "Epoch 138/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0053 - val_loss: 0.0043\n",
      "Epoch 139/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0053 - val_loss: 0.0044\n",
      "Epoch 140/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0053 - val_loss: 0.0043\n",
      "Epoch 141/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0059 - val_loss: 0.0044\n",
      "Epoch 142/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0052 - val_loss: 0.0042\n",
      "Epoch 143/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0044\n",
      "Epoch 144/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0050 - val_loss: 0.0040\n",
      "Epoch 145/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0042\n",
      "Epoch 146/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0040\n",
      "Epoch 147/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0054 - val_loss: 0.0041\n",
      "Epoch 148/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0059 - val_loss: 0.0044\n",
      "Epoch 149/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0054 - val_loss: 0.0041\n",
      "Epoch 150/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0042\n",
      "Epoch 151/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0039\n",
      "Epoch 152/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0045\n",
      "Epoch 153/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0051 - val_loss: 0.0042\n",
      "Epoch 154/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0050 - val_loss: 0.0048\n",
      "Epoch 155/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0051 - val_loss: 0.0042\n",
      "Epoch 156/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0050 - val_loss: 0.0043\n",
      "Epoch 157/1000\n",
      "143/143 [==============================] - 0s 99us/step - loss: 0.0054 - val_loss: 0.0043\n",
      "Epoch 158/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0052 - val_loss: 0.0043\n",
      "Epoch 159/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0050 - val_loss: 0.0040\n",
      "Epoch 160/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 161/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0050 - val_loss: 0.0041\n",
      "Epoch 162/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0049 - val_loss: 0.0045\n",
      "Epoch 163/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0049 - val_loss: 0.0041\n",
      "Epoch 164/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0049 - val_loss: 0.0041\n",
      "Epoch 165/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0049 - val_loss: 0.0044\n",
      "Epoch 166/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0043\n",
      "Epoch 167/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0051 - val_loss: 0.0045\n",
      "Epoch 168/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0042\n",
      "Epoch 169/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0042\n",
      "Epoch 170/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0041\n",
      "Epoch 171/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0048 - val_loss: 0.0040\n",
      "Epoch 172/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0042\n",
      "Epoch 173/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0043\n",
      "Epoch 174/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0045\n",
      "Epoch 175/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0052 - val_loss: 0.0042\n",
      "Epoch 176/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 177/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0046\n",
      "Epoch 178/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0051 - val_loss: 0.0043\n",
      "Epoch 179/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 180/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0042\n",
      "Epoch 181/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 182/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0039\n",
      "Epoch 183/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 184/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0042\n",
      "Epoch 185/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0041\n",
      "Epoch 186/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0042\n",
      "Epoch 187/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0039\n",
      "Epoch 188/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0048 - val_loss: 0.0045\n",
      "Epoch 189/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0047 - val_loss: 0.0042\n",
      "Epoch 190/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0047 - val_loss: 0.0044\n",
      "Epoch 191/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0047 - val_loss: 0.0043\n",
      "Epoch 192/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0048 - val_loss: 0.0042\n",
      "Epoch 193/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0042\n",
      "Epoch 194/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0039\n",
      "Epoch 195/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0042\n",
      "Epoch 196/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0038\n",
      "Epoch 197/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 198/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 199/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0042\n",
      "Epoch 200/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0040\n",
      "Epoch 201/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0042\n",
      "Epoch 202/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0047 - val_loss: 0.0042\n",
      "Epoch 203/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0048 - val_loss: 0.0041\n",
      "Epoch 204/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0042\n",
      "Epoch 205/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0046 - val_loss: 0.0040\n",
      "Epoch 206/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0051 - val_loss: 0.0046\n",
      "Epoch 207/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0055 - val_loss: 0.0043\n",
      "Epoch 208/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0046 - val_loss: 0.0051\n",
      "Epoch 209/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0046 - val_loss: 0.0041\n",
      "Epoch 210/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 211/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0037\n",
      "Epoch 212/1000\n",
      "143/143 [==============================] - 0s 128us/step - loss: 0.0049 - val_loss: 0.0043\n",
      "Epoch 213/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0038\n",
      "Epoch 214/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0046 - val_loss: 0.0041\n",
      "Epoch 215/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0046 - val_loss: 0.0040\n",
      "Epoch 216/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0051 - val_loss: 0.0044\n",
      "Epoch 217/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 218/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0047 - val_loss: 0.0041\n",
      "Epoch 219/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0048\n",
      "Epoch 220/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0051 - val_loss: 0.0039\n",
      "Epoch 221/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0051 - val_loss: 0.0042\n",
      "Epoch 222/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 223/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 116us/step - loss: 0.0049 - val_loss: 0.0040\n",
      "Epoch 224/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0047 - val_loss: 0.0044\n",
      "Epoch 225/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 226/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0044 - val_loss: 0.0042\n",
      "Epoch 227/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0041\n",
      "Epoch 228/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0039\n",
      "Epoch 229/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0045 - val_loss: 0.0041\n",
      "Epoch 230/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0044 - val_loss: 0.0038\n",
      "Epoch 231/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0044 - val_loss: 0.0040\n",
      "Epoch 232/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0044 - val_loss: 0.0038\n",
      "Epoch 233/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0043\n",
      "Epoch 234/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0042\n",
      "Epoch 235/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0044 - val_loss: 0.0040\n",
      "Epoch 236/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0046\n",
      "Epoch 237/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0039\n",
      "Epoch 238/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0046 - val_loss: 0.0044\n",
      "Epoch 239/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0039\n",
      "Epoch 240/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0042 - val_loss: 0.0041\n",
      "Epoch 241/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0043 - val_loss: 0.0038\n",
      "Epoch 242/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0040\n",
      "Epoch 243/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0041\n",
      "Epoch 244/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0040\n",
      "Epoch 245/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 246/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0039\n",
      "Epoch 247/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0048 - val_loss: 0.0045\n",
      "Epoch 248/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0040\n",
      "Epoch 249/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0054 - val_loss: 0.0041\n",
      "Epoch 250/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0035\n",
      "Epoch 251/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0038\n",
      "Epoch 252/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0043 - val_loss: 0.0038\n",
      "Epoch 253/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 254/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0046 - val_loss: 0.0041\n",
      "Epoch 255/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 256/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0045 - val_loss: 0.0041\n",
      "Epoch 257/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0048 - val_loss: 0.0041\n",
      "Epoch 258/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0036\n",
      "Epoch 259/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0040\n",
      "Epoch 260/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 261/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0039\n",
      "Epoch 262/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 263/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0044 - val_loss: 0.0038\n",
      "Epoch 264/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0041 - val_loss: 0.0042\n",
      "Epoch 265/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0042 - val_loss: 0.0039\n",
      "Epoch 266/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 267/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0043 - val_loss: 0.0038\n",
      "Epoch 268/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0042 - val_loss: 0.0041\n",
      "Epoch 269/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0042 - val_loss: 0.0038\n",
      "Epoch 270/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0042\n",
      "Epoch 271/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0042 - val_loss: 0.0038\n",
      "Epoch 272/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 273/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 274/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 275/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0041 - val_loss: 0.0039\n",
      "Epoch 276/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0038\n",
      "Epoch 277/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0045\n",
      "Epoch 278/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0043 - val_loss: 0.0038\n",
      "Epoch 279/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0040 - val_loss: 0.0042\n",
      "Epoch 280/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0038\n",
      "Epoch 281/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 282/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0043 - val_loss: 0.0040\n",
      "Epoch 283/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0040 - val_loss: 0.0042\n",
      "Epoch 284/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0041 - val_loss: 0.0038\n",
      "Epoch 285/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0041 - val_loss: 0.0043\n",
      "Epoch 286/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0039\n",
      "Epoch 287/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 288/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0045 - val_loss: 0.0036\n",
      "Epoch 289/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0039\n",
      "Epoch 290/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 291/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 292/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0042 - val_loss: 0.0040\n",
      "Epoch 293/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0036\n",
      "Epoch 294/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 295/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0046\n",
      "Epoch 296/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0038\n",
      "Epoch 297/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 298/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0038\n",
      "Epoch 299/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0044\n",
      "Epoch 300/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0048 - val_loss: 0.0036\n",
      "Epoch 301/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0049\n",
      "Epoch 302/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0033\n",
      "Epoch 303/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 304/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 305/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0047 - val_loss: 0.0038\n",
      "Epoch 306/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0039\n",
      "Epoch 307/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 308/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0039 - val_loss: 0.0037\n",
      "Epoch 309/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 310/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 311/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0036\n",
      "Epoch 312/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0038\n",
      "Epoch 313/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0040 - val_loss: 0.0036\n",
      "Epoch 314/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0041\n",
      "Epoch 315/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 316/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 317/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0038 - val_loss: 0.0041\n",
      "Epoch 318/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0039 - val_loss: 0.0035\n",
      "Epoch 319/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0051\n",
      "Epoch 320/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0035\n",
      "Epoch 321/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 322/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 323/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0037\n",
      "Epoch 324/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0039 - val_loss: 0.0038\n",
      "Epoch 325/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 326/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0042\n",
      "Epoch 327/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0034\n",
      "Epoch 328/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 329/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0036\n",
      "Epoch 330/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0039 - val_loss: 0.0055\n",
      "Epoch 331/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0043 - val_loss: 0.0038\n",
      "Epoch 332/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0038 - val_loss: 0.0054\n",
      "Epoch 333/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0044 - val_loss: 0.0036\n",
      "Epoch 334/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0044 - val_loss: 0.0038\n",
      "Epoch 335/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 336/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0035\n",
      "Epoch 337/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0043\n",
      "Epoch 338/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0040 - val_loss: 0.0034\n",
      "Epoch 339/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Epoch 340/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0040 - val_loss: 0.0036\n",
      "Epoch 341/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0042 - val_loss: 0.0035\n",
      "Epoch 342/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0055\n",
      "Epoch 343/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0036\n",
      "Epoch 344/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 345/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 346/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0035\n",
      "Epoch 347/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 348/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0033\n",
      "Epoch 349/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 350/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.003 - 0s 111us/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 351/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0055\n",
      "Epoch 352/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 353/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0058 - val_loss: 0.0080\n",
      "Epoch 354/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0059 - val_loss: 0.0043\n",
      "Epoch 355/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0067\n",
      "Epoch 356/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0037\n",
      "Epoch 357/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0041 - val_loss: 0.0052\n",
      "Epoch 358/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0046 - val_loss: 0.0034\n",
      "Epoch 359/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 360/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0043\n",
      "Epoch 361/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0034\n",
      "Epoch 362/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 363/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0033\n",
      "Epoch 364/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0051\n",
      "Epoch 365/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0041 - val_loss: 0.0035\n",
      "Epoch 366/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0044 - val_loss: 0.0041\n",
      "Epoch 367/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0041 - val_loss: 0.0034\n",
      "Epoch 368/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 369/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0037 - val_loss: 0.0039\n",
      "Epoch 370/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 371/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Epoch 372/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 373/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0039 - val_loss: 0.0044\n",
      "Epoch 374/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0037 - val_loss: 0.0036\n",
      "Epoch 375/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 376/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0036 - val_loss: 0.0035\n",
      "Epoch 377/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0040\n",
      "Epoch 378/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 379/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0036 - val_loss: 0.0035\n",
      "Epoch 380/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0043\n",
      "Epoch 381/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 382/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0036 - val_loss: 0.0042\n",
      "Epoch 383/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0036 - val_loss: 0.0033\n",
      "Epoch 384/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 385/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 386/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0035\n",
      "Epoch 387/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 388/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 389/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 390/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0038 - val_loss: 0.0053\n",
      "Epoch 391/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0038\n",
      "Epoch 392/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0051\n",
      "Epoch 393/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0033\n",
      "Epoch 394/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0054\n",
      "Epoch 395/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0037\n",
      "Epoch 396/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 397/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0040 - val_loss: 0.0034\n",
      "Epoch 398/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0041 - val_loss: 0.0035\n",
      "Epoch 399/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0041\n",
      "Epoch 400/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0035\n",
      "Epoch 401/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 402/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 403/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0038\n",
      "Epoch 404/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0053\n",
      "Epoch 405/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0042 - val_loss: 0.0035\n",
      "Epoch 406/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0058\n",
      "Epoch 407/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0046 - val_loss: 0.0036\n",
      "Epoch 408/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 409/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0036 - val_loss: 0.0035\n",
      "Epoch 410/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 411/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 412/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 413/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 414/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0034\n",
      "Epoch 415/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 416/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0033\n",
      "Epoch 417/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0036 - val_loss: 0.0039\n",
      "Epoch 418/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 419/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 420/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 421/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 422/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 423/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 424/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 425/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0047\n",
      "Epoch 426/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 427/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0041\n",
      "Epoch 428/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0036 - val_loss: 0.0032\n",
      "Epoch 429/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0046\n",
      "Epoch 430/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0033\n",
      "Epoch 431/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 432/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0032\n",
      "Epoch 433/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 434/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0035 - val_loss: 0.0033\n",
      "Epoch 435/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0040 - val_loss: 0.0044\n",
      "Epoch 436/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0037 - val_loss: 0.0034\n",
      "Epoch 437/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0053\n",
      "Epoch 438/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0036\n",
      "Epoch 439/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 440/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 441/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0036\n",
      "Epoch 442/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 443/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 444/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 445/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 446/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 447/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 448/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 449/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0039 - val_loss: 0.0036\n",
      "Epoch 450/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0036 - val_loss: 0.0041\n",
      "Epoch 451/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 452/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0034 - val_loss: 0.0040\n",
      "Epoch 453/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 454/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 455/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0041\n",
      "Epoch 456/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 457/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 458/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0035\n",
      "Epoch 459/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0044 - val_loss: 0.0051\n",
      "Epoch 460/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 461/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0046\n",
      "Epoch 462/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0036 - val_loss: 0.0032\n",
      "Epoch 463/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0040\n",
      "Epoch 464/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 465/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 466/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0041\n",
      "Epoch 467/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 468/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 469/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 470/1000\n",
      "143/143 [==============================] - 0s 127us/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 471/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0044\n",
      "Epoch 472/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 473/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0050\n",
      "Epoch 474/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 475/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0055\n",
      "Epoch 476/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 477/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0040 - val_loss: 0.0046\n",
      "Epoch 478/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 479/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0039\n",
      "Epoch 480/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0033 - val_loss: 0.0039\n",
      "Epoch 481/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 482/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0041\n",
      "Epoch 483/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0035 - val_loss: 0.0033\n",
      "Epoch 484/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 485/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0041\n",
      "Epoch 486/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 487/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0032 - val_loss: 0.0041\n",
      "Epoch 488/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 489/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 490/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 491/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0049\n",
      "Epoch 492/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 493/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0040\n",
      "Epoch 494/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 495/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 496/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 497/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0032 - val_loss: 0.0051\n",
      "Epoch 498/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 499/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0033 - val_loss: 0.0044\n",
      "Epoch 500/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0036 - val_loss: 0.0031\n",
      "Epoch 501/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0035\n",
      "Epoch 502/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0048 - val_loss: 0.0058\n",
      "Epoch 503/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0034\n",
      "Epoch 504/1000\n",
      "143/143 [==============================] - 0s 129us/step - loss: 0.0032 - val_loss: 0.0048\n",
      "Epoch 505/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0037 - val_loss: 0.0033\n",
      "Epoch 506/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 507/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0042\n",
      "Epoch 508/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 509/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0040 - val_loss: 0.0049\n",
      "Epoch 510/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0037 - val_loss: 0.0036\n",
      "Epoch 511/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0032 - val_loss: 0.0049\n",
      "Epoch 512/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0037 - val_loss: 0.0033\n",
      "Epoch 513/1000\n",
      "143/143 [==============================] - 0s 128us/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 514/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 515/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0035 - val_loss: 0.0031\n",
      "Epoch 516/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0034 - val_loss: 0.0041\n",
      "Epoch 517/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 518/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0052\n",
      "Epoch 519/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0035 - val_loss: 0.0034\n",
      "Epoch 520/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0034 - val_loss: 0.0046\n",
      "Epoch 521/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0035\n",
      "Epoch 522/1000\n",
      "143/143 [==============================] - 0s 129us/step - loss: 0.0034 - val_loss: 0.0047\n",
      "Epoch 523/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 524/1000\n",
      "143/143 [==============================] - 0s 136us/step - loss: 0.0034 - val_loss: 0.0041\n",
      "Epoch 525/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 526/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0035 - val_loss: 0.0051\n",
      "Epoch 527/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0039 - val_loss: 0.0033\n",
      "Epoch 528/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 529/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0032 - val_loss: 0.0035\n",
      "Epoch 530/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0043\n",
      "Epoch 531/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 532/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0032 - val_loss: 0.0038\n",
      "Epoch 533/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0039\n",
      "Epoch 534/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0038\n",
      "Epoch 535/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0035\n",
      "Epoch 536/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0036\n",
      "Epoch 537/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0031 - val_loss: 0.0037\n",
      "Epoch 538/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0031 - val_loss: 0.0036\n",
      "Epoch 539/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 540/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0041\n",
      "Epoch 541/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 542/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 543/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0032 - val_loss: 0.0035\n",
      "Epoch 544/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0035 - val_loss: 0.0042\n",
      "Epoch 545/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0040\n",
      "Epoch 546/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0034\n",
      "Epoch 547/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 548/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0031 - val_loss: 0.0034\n",
      "Epoch 549/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 550/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 551/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0036\n",
      "Epoch 552/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 553/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0039\n",
      "Epoch 554/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0032 - val_loss: 0.0040\n",
      "Epoch 555/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 556/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0053\n",
      "Epoch 557/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0035 - val_loss: 0.0032\n",
      "Epoch 558/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 559/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0031 - val_loss: 0.0033\n",
      "Epoch 560/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 561/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0047\n",
      "Epoch 562/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 563/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0043\n",
      "Epoch 564/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0035\n",
      "Epoch 565/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0032 - val_loss: 0.0049\n",
      "Epoch 566/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0037\n",
      "Epoch 567/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0051\n",
      "Epoch 568/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0031 - val_loss: 0.0038\n",
      "Epoch 569/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0039 - val_loss: 0.0068\n",
      "Epoch 570/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 571/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 572/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 573/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0037 - val_loss: 0.0031\n",
      "Epoch 574/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0047\n",
      "Epoch 575/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 576/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 577/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0030 - val_loss: 0.0036\n",
      "Epoch 578/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 579/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0030 - val_loss: 0.0047\n",
      "Epoch 580/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 581/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 582/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0040 - val_loss: 0.0055\n",
      "Epoch 583/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0039\n",
      "Epoch 584/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0064\n",
      "Epoch 585/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0038 - val_loss: 0.0037\n",
      "Epoch 586/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0040 - val_loss: 0.0046\n",
      "Epoch 587/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 588/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 589/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0035\n",
      "Epoch 590/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0031 - val_loss: 0.0035\n",
      "Epoch 591/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0031 - val_loss: 0.0035\n",
      "Epoch 592/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0030 - val_loss: 0.0035\n",
      "Epoch 593/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0030 - val_loss: 0.0035\n",
      "Epoch 594/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0030 - val_loss: 0.0041\n",
      "Epoch 595/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0036\n",
      "Epoch 596/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0030 - val_loss: 0.0036\n",
      "Epoch 597/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 598/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0036\n",
      "Epoch 599/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0035\n",
      "Epoch 600/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0029 - val_loss: 0.0034\n",
      "Epoch 601/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0030 - val_loss: 0.0041\n",
      "Epoch 602/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 603/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0050\n",
      "Epoch 604/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 605/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0031 - val_loss: 0.0041\n",
      "Epoch 606/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0038\n",
      "Epoch 607/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0030 - val_loss: 0.0036\n",
      "Epoch 608/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0030 - val_loss: 0.0039\n",
      "Epoch 609/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0034\n",
      "Epoch 610/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0029 - val_loss: 0.0039\n",
      "Epoch 611/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0030 - val_loss: 0.0035\n",
      "Epoch 612/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0039\n",
      "Epoch 613/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0030 - val_loss: 0.0034\n",
      "Epoch 614/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 615/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0033\n",
      "Epoch 616/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0031 - val_loss: 0.0035\n",
      "Epoch 617/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0031 - val_loss: 0.0045\n",
      "Epoch 618/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 619/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0032 - val_loss: 0.0041\n",
      "Epoch 620/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0030 - val_loss: 0.0035\n",
      "Epoch 621/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0030 - val_loss: 0.0034\n",
      "Epoch 622/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0031 - val_loss: 0.0043\n",
      "Epoch 623/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0043\n",
      "Epoch 624/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 625/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0034 - val_loss: 0.0058\n",
      "Epoch 626/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 627/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0037 - val_loss: 0.0036\n",
      "Epoch 628/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0054\n",
      "Epoch 629/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 630/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0068\n",
      "Epoch 631/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0036\n",
      "Epoch 632/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0040 - val_loss: 0.0037\n",
      "Epoch 633/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0040 - val_loss: 0.0048\n",
      "Epoch 634/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0047 - val_loss: 0.0041\n",
      "Epoch 635/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0060\n",
      "Epoch 636/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 637/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0058\n",
      "Epoch 638/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0038 - val_loss: 0.0033\n",
      "Epoch 639/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0035 - val_loss: 0.0057\n",
      "Epoch 640/1000\n",
      "143/143 [==============================] - 0s 129us/step - loss: 0.0033 - val_loss: 0.0040\n",
      "Epoch 641/1000\n",
      "143/143 [==============================] - 0s 216us/step - loss: 0.0032 - val_loss: 0.0051\n",
      "Epoch 642/1000\n",
      "143/143 [==============================] - 0s 167us/step - loss: 0.0031 - val_loss: 0.0034\n",
      "Epoch 643/1000\n",
      "143/143 [==============================] - 0s 140us/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 644/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 645/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0030 - val_loss: 0.0038\n",
      "Epoch 646/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0033 - val_loss: 0.0044\n",
      "Epoch 647/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 648/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 649/1000\n",
      "143/143 [==============================] - 0s 170us/step - loss: 0.0029 - val_loss: 0.0033\n",
      "Epoch 650/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0031 - val_loss: 0.0048\n",
      "Epoch 651/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 652/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0049\n",
      "Epoch 653/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 654/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0051\n",
      "Epoch 655/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0035\n",
      "Epoch 656/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0041\n",
      "Epoch 657/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0030 - val_loss: 0.0035\n",
      "Epoch 658/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 659/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0028 - val_loss: 0.0033\n",
      "Epoch 660/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0037\n",
      "Epoch 661/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0029 - val_loss: 0.0037\n",
      "Epoch 662/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0029 - val_loss: 0.0035\n",
      "Epoch 663/1000\n",
      "143/143 [==============================] - 0s 131us/step - loss: 0.0028 - val_loss: 0.0041\n",
      "Epoch 664/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0035\n",
      "Epoch 665/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0048\n",
      "Epoch 666/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 667/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0043\n",
      "Epoch 668/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0034\n",
      "Epoch 669/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0038\n",
      "Epoch 670/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0031 - val_loss: 0.0037\n",
      "Epoch 671/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 672/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0042\n",
      "Epoch 673/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0039\n",
      "Epoch 674/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 675/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0037\n",
      "Epoch 676/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 677/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0040\n",
      "Epoch 678/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 679/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0056\n",
      "Epoch 680/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 681/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0041\n",
      "Epoch 682/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0038\n",
      "Epoch 683/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0033\n",
      "Epoch 684/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0046\n",
      "Epoch 685/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 686/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0043\n",
      "Epoch 687/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0034\n",
      "Epoch 688/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0043\n",
      "Epoch 689/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0035\n",
      "Epoch 690/1000\n",
      "143/143 [==============================] - 0s 181us/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 691/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 692/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0037\n",
      "Epoch 693/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 694/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 695/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0038\n",
      "Epoch 696/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0039\n",
      "Epoch 697/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 698/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 699/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0028 - val_loss: 0.0044\n",
      "Epoch 700/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 701/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0046\n",
      "Epoch 702/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0028 - val_loss: 0.0034\n",
      "Epoch 703/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0040\n",
      "Epoch 704/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 705/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0049\n",
      "Epoch 706/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0034\n",
      "Epoch 707/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0030 - val_loss: 0.0052\n",
      "Epoch 708/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0037\n",
      "Epoch 709/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0030 - val_loss: 0.0038\n",
      "Epoch 710/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0043\n",
      "Epoch 711/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 712/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0032 - val_loss: 0.0041\n",
      "Epoch 713/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0039\n",
      "Epoch 714/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0028 - val_loss: 0.0037\n",
      "Epoch 715/1000\n",
      "143/143 [==============================] - 0s 136us/step - loss: 0.0027 - val_loss: 0.0039\n",
      "Epoch 716/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0028 - val_loss: 0.0040\n",
      "Epoch 717/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0028 - val_loss: 0.0037\n",
      "Epoch 718/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0038\n",
      "Epoch 719/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 720/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 721/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0027 - val_loss: 0.0038\n",
      "Epoch 722/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 723/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0031 - val_loss: 0.0046\n",
      "Epoch 724/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0031 - val_loss: 0.0041\n",
      "Epoch 725/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 726/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0038\n",
      "Epoch 727/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0047\n",
      "Epoch 728/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0031 - val_loss: 0.0036\n",
      "Epoch 729/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0033 - val_loss: 0.0049\n",
      "Epoch 730/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0030 - val_loss: 0.0039\n",
      "Epoch 731/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0038\n",
      "Epoch 732/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0041\n",
      "Epoch 733/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0034\n",
      "Epoch 734/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0049\n",
      "Epoch 735/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0028 - val_loss: 0.0038\n",
      "Epoch 736/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0056\n",
      "Epoch 737/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 738/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0037\n",
      "Epoch 739/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0027 - val_loss: 0.0039\n",
      "Epoch 740/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0037\n",
      "Epoch 741/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0026 - val_loss: 0.0039\n",
      "Epoch 742/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 743/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0034 - val_loss: 0.0056\n",
      "Epoch 744/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0029 - val_loss: 0.0038\n",
      "Epoch 745/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0039\n",
      "Epoch 746/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0028 - val_loss: 0.0044\n",
      "Epoch 747/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0038\n",
      "Epoch 748/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0032 - val_loss: 0.0038\n",
      "Epoch 749/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0029 - val_loss: 0.0046\n",
      "Epoch 750/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0029 - val_loss: 0.0044\n",
      "Epoch 751/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0043\n",
      "Epoch 752/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0042 - val_loss: 0.0054\n",
      "Epoch 753/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0026 - val_loss: 0.0037\n",
      "Epoch 754/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0032 - val_loss: 0.0043\n",
      "Epoch 755/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0025 - val_loss: 0.0034\n",
      "Epoch 756/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0045\n",
      "Epoch 757/1000\n",
      "143/143 [==============================] - 0s 130us/step - loss: 0.0028 - val_loss: 0.0037\n",
      "Epoch 758/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0026 - val_loss: 0.0042\n",
      "Epoch 759/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0040\n",
      "Epoch 760/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0037\n",
      "Epoch 761/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0038\n",
      "Epoch 762/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0040\n",
      "Epoch 763/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0026 - val_loss: 0.0039\n",
      "Epoch 764/1000\n",
      "143/143 [==============================] - 0s 174us/step - loss: 0.0026 - val_loss: 0.0038\n",
      "Epoch 765/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0028 - val_loss: 0.0034\n",
      "Epoch 766/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0043\n",
      "Epoch 767/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 768/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 769/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0048\n",
      "Epoch 770/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0032 - val_loss: 0.0035\n",
      "Epoch 771/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0039\n",
      "Epoch 772/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0040\n",
      "Epoch 773/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 774/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0045\n",
      "Epoch 775/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0026 - val_loss: 0.0037\n",
      "Epoch 776/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0026 - val_loss: 0.0043\n",
      "Epoch 777/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0026 - val_loss: 0.0037\n",
      "Epoch 778/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0031 - val_loss: 0.0052\n",
      "Epoch 779/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0027 - val_loss: 0.0038\n",
      "Epoch 780/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0051\n",
      "Epoch 781/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0039\n",
      "Epoch 782/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0037\n",
      "Epoch 783/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0058\n",
      "Epoch 784/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0041 - val_loss: 0.0036\n",
      "Epoch 785/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0031 - val_loss: 0.0038\n",
      "Epoch 786/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0040\n",
      "Epoch 787/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 788/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0043\n",
      "Epoch 789/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0030 - val_loss: 0.0043\n",
      "Epoch 790/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0031 - val_loss: 0.0034\n",
      "Epoch 791/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0046\n",
      "Epoch 792/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0039\n",
      "Epoch 793/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0031 - val_loss: 0.0059\n",
      "Epoch 794/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0038\n",
      "Epoch 795/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0057\n",
      "Epoch 796/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0032 - val_loss: 0.0040\n",
      "Epoch 797/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0045\n",
      "Epoch 798/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0038\n",
      "Epoch 799/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0037\n",
      "Epoch 800/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0051\n",
      "Epoch 801/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0035\n",
      "Epoch 802/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0042\n",
      "Epoch 803/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0039\n",
      "Epoch 804/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0037\n",
      "Epoch 805/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0048\n",
      "Epoch 806/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 807/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0039\n",
      "Epoch 808/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0038\n",
      "Epoch 809/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0041\n",
      "Epoch 810/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 811/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0041\n",
      "Epoch 812/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0025 - val_loss: 0.0037\n",
      "Epoch 813/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0046\n",
      "Epoch 814/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0037\n",
      "Epoch 815/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0025 - val_loss: 0.0040\n",
      "Epoch 816/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0040\n",
      "Epoch 817/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 818/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0044\n",
      "Epoch 819/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0039\n",
      "Epoch 820/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0034 - val_loss: 0.0061\n",
      "Epoch 821/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0032 - val_loss: 0.0037\n",
      "Epoch 822/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0040\n",
      "Epoch 823/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0044\n",
      "Epoch 824/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0047\n",
      "Epoch 825/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0061\n",
      "Epoch 826/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 827/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0045\n",
      "Epoch 828/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0040\n",
      "Epoch 829/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0027 - val_loss: 0.0039\n",
      "Epoch 830/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0047\n",
      "Epoch 831/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0027 - val_loss: 0.0039\n",
      "Epoch 832/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0025 - val_loss: 0.0040\n",
      "Epoch 833/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 834/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0027 - val_loss: 0.0046\n",
      "Epoch 835/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0038\n",
      "Epoch 836/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0028 - val_loss: 0.0040\n",
      "Epoch 837/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0063\n",
      "Epoch 838/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 839/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 126us/step - loss: 0.0025 - val_loss: 0.0046\n",
      "Epoch 840/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0027 - val_loss: 0.0037\n",
      "Epoch 841/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0030 - val_loss: 0.0035\n",
      "Epoch 842/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0039\n",
      "Epoch 843/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0045\n",
      "Epoch 844/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0037\n",
      "Epoch 845/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0057\n",
      "Epoch 846/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 847/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0027 - val_loss: 0.0040\n",
      "Epoch 848/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0036\n",
      "Epoch 849/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0025 - val_loss: 0.0036\n",
      "Epoch 850/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0026 - val_loss: 0.0047\n",
      "Epoch 851/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 852/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0027 - val_loss: 0.0046\n",
      "Epoch 853/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0035\n",
      "Epoch 854/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0025 - val_loss: 0.0045\n",
      "Epoch 855/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0037\n",
      "Epoch 856/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0039\n",
      "Epoch 857/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0024 - val_loss: 0.0045\n",
      "Epoch 858/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0037\n",
      "Epoch 859/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0047\n",
      "Epoch 860/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 861/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0038\n",
      "Epoch 862/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0057\n",
      "Epoch 863/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0041\n",
      "Epoch 864/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0031 - val_loss: 0.0052\n",
      "Epoch 865/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0026 - val_loss: 0.0034\n",
      "Epoch 866/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0039\n",
      "Epoch 867/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0023 - val_loss: 0.0038\n",
      "Epoch 868/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0046\n",
      "Epoch 869/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 870/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0048\n",
      "Epoch 871/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0036\n",
      "Epoch 872/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0052\n",
      "Epoch 873/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0026 - val_loss: 0.0037\n",
      "Epoch 874/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0023 - val_loss: 0.0044\n",
      "Epoch 875/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0036\n",
      "Epoch 876/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0039\n",
      "Epoch 877/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0024 - val_loss: 0.0046\n",
      "Epoch 878/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0037\n",
      "Epoch 879/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0040\n",
      "Epoch 880/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0022 - val_loss: 0.0040\n",
      "Epoch 881/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0042\n",
      "Epoch 882/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0039\n",
      "Epoch 883/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0041\n",
      "Epoch 884/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0040\n",
      "Epoch 885/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0043\n",
      "Epoch 886/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0039\n",
      "Epoch 887/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0046\n",
      "Epoch 888/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0039\n",
      "Epoch 889/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0038\n",
      "Epoch 890/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0041\n",
      "Epoch 891/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0044\n",
      "Epoch 892/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0023 - val_loss: 0.0039\n",
      "Epoch 893/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0043\n",
      "Epoch 894/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0039\n",
      "Epoch 895/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0038\n",
      "Epoch 896/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0026 - val_loss: 0.0056\n",
      "Epoch 897/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0026 - val_loss: 0.0038\n",
      "Epoch 898/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0041\n",
      "Epoch 899/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0046\n",
      "Epoch 900/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0040\n",
      "Epoch 901/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0040\n",
      "Epoch 902/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0051\n",
      "Epoch 903/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0028 - val_loss: 0.0049\n",
      "Epoch 904/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0038\n",
      "Epoch 905/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0025 - val_loss: 0.0050\n",
      "Epoch 906/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0039\n",
      "Epoch 907/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0050\n",
      "Epoch 908/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0038\n",
      "Epoch 909/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0026 - val_loss: 0.0040\n",
      "Epoch 910/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0042\n",
      "Epoch 911/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0039\n",
      "Epoch 912/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0045\n",
      "Epoch 913/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0042\n",
      "Epoch 914/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0043\n",
      "Epoch 915/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0022 - val_loss: 0.0050\n",
      "Epoch 916/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0039\n",
      "Epoch 917/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0038\n",
      "Epoch 918/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0043\n",
      "Epoch 919/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0041\n",
      "Epoch 920/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0022 - val_loss: 0.0048\n",
      "Epoch 921/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0022 - val_loss: 0.0039\n",
      "Epoch 922/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0040\n",
      "Epoch 923/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0024 - val_loss: 0.0048\n",
      "Epoch 924/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0022 - val_loss: 0.0038\n",
      "Epoch 925/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0058\n",
      "Epoch 926/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0027 - val_loss: 0.0039\n",
      "Epoch 927/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0047\n",
      "Epoch 928/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0042\n",
      "Epoch 929/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Epoch 930/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0045\n",
      "Epoch 931/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0039\n",
      "Epoch 932/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0042\n",
      "Epoch 933/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0056\n",
      "Epoch 934/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0022 - val_loss: 0.0038\n",
      "Epoch 935/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0053\n",
      "Epoch 936/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0040\n",
      "Epoch 937/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0023 - val_loss: 0.0041\n",
      "Epoch 938/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0042\n",
      "Epoch 939/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0022 - val_loss: 0.0038\n",
      "Epoch 940/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0041\n",
      "Epoch 941/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0041\n",
      "Epoch 942/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0047\n",
      "Epoch 943/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.001 - 0s 112us/step - loss: 0.0022 - val_loss: 0.0039\n",
      "Epoch 944/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0042\n",
      "Epoch 945/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0041\n",
      "Epoch 946/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0043\n",
      "Epoch 947/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0043\n",
      "Epoch 948/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Epoch 949/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0058\n",
      "Epoch 950/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0024 - val_loss: 0.0043\n",
      "Epoch 951/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0056\n",
      "Epoch 952/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0039\n",
      "Epoch 953/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0023 - val_loss: 0.0043\n",
      "Epoch 954/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0047\n",
      "Epoch 955/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0040\n",
      "Epoch 956/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0041\n",
      "Epoch 957/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0045\n",
      "Epoch 958/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0040\n",
      "Epoch 959/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0053\n",
      "Epoch 960/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0025 - val_loss: 0.0052\n",
      "Epoch 961/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0044\n",
      "Epoch 962/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0059\n",
      "Epoch 963/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0041\n",
      "Epoch 964/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0026 - val_loss: 0.0058\n",
      "Epoch 965/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0042\n",
      "Epoch 966/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0043\n",
      "Epoch 967/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 0.0043\n",
      "Epoch 968/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0044\n",
      "Epoch 969/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0039\n",
      "Epoch 970/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0048\n",
      "Epoch 971/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0045\n",
      "Epoch 972/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 973/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0045\n",
      "Epoch 974/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0050\n",
      "Epoch 975/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0041\n",
      "Epoch 976/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0020 - val_loss: 0.0048\n",
      "Epoch 977/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0041\n",
      "Epoch 978/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0041\n",
      "Epoch 979/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Epoch 980/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0053\n",
      "Epoch 981/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0044\n",
      "Epoch 982/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0041\n",
      "Epoch 983/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0045\n",
      "Epoch 984/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0048\n",
      "Epoch 985/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 986/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 987/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 988/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0068\n",
      "Epoch 989/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0026 - val_loss: 0.0039\n",
      "Epoch 990/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0041\n",
      "Epoch 991/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0047\n",
      "Epoch 992/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0022 - val_loss: 0.0041\n",
      "Epoch 993/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0039\n",
      "Epoch 994/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0066\n",
      "Epoch 995/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0025 - val_loss: 0.0041\n",
      "Epoch 996/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0039\n",
      "Epoch 997/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0051\n",
      "Epoch 998/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0041\n",
      "Epoch 999/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0043\n",
      "Epoch 1000/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0057\n",
      "0.006008231546729803\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 1.0967789 , -0.85125566, -0.3005834 , -0.14808619, -0.260356  ],\n",
       "        [ 0.58913124, -0.8320359 ,  0.04420534, -0.35048822,  0.6666084 ],\n",
       "        [ 0.69449055, -0.38064197,  0.5204143 , -0.9067357 ,  0.08135187],\n",
       "        [ 0.34750026, -0.9946707 ,  0.13325608, -0.48520643,  0.00784478],\n",
       "        [ 0.04665023, -0.11869799,  0.06540714,  0.03166735, -0.03685782],\n",
       "        [-0.7637425 , -0.18330225, -0.1342704 , -0.22876924, -0.6698236 ],\n",
       "        [-0.06361876,  0.22113003,  0.5706431 , -0.59720993, -0.263737  ],\n",
       "        [-0.02164517, -0.12007421, -0.40791076, -0.8447536 , -0.47136036],\n",
       "        [-1.3762275 , -0.02534995,  0.23357524, -0.14083318,  0.0298421 ],\n",
       "        [ 0.7895214 , -0.3284756 , -0.8241457 , -0.5841204 ,  0.18694809],\n",
       "        [-0.46001127,  0.04347777,  0.94150555, -0.04406102,  0.845491  ],\n",
       "        [-0.5934397 ,  0.891223  , -0.07054701, -0.15037079,  0.6251079 ],\n",
       "        [-0.07849779,  0.06309937, -0.23583801, -0.26852795,  0.2579096 ],\n",
       "        [-0.7977668 ,  0.362444  , -2.3188639 ,  0.08026398,  0.6890272 ],\n",
       "        [ 0.41067338, -0.14044343, -0.28253204, -0.06339233,  0.12554052],\n",
       "        [ 0.587585  ,  0.17339039, -0.53384703, -0.04512816,  0.24489367],\n",
       "        [-0.2820084 , -0.36963913,  0.6621134 , -0.17277335,  0.09179785],\n",
       "        [ 0.64877975,  0.00917367,  0.25447488, -0.73862594,  0.19942144],\n",
       "        [ 0.51300156,  1.0694044 ,  0.44320312,  0.0844185 ,  1.3892095 ],\n",
       "        [ 0.3844272 ,  0.03773833, -0.4362461 , -0.09960639,  0.41440862],\n",
       "        [ 0.43080273, -1.2523787 ,  2.520551  , -0.63301986,  0.4985161 ],\n",
       "        [-0.5519962 , -0.69362366,  0.52914727, -0.6694307 ,  0.24082811]],\n",
       "       dtype=float32),\n",
       " array([ 0.4176346 ,  0.00748613,  0.55571014, -0.4644793 ,  0.18202114],\n",
       "       dtype=float32),\n",
       " array([[-0.32411155,  0.0040422 ,  0.32431066,  1.1917902 ,  0.3108253 ],\n",
       "        [ 0.5650991 ,  0.28178585,  0.60582566,  0.82186925,  0.08318577],\n",
       "        [ 0.5443336 , -0.13511592,  0.7680778 ,  0.5720011 , -0.25334084],\n",
       "        [-0.45634264,  0.20046245, -0.02096238,  0.0263694 ,  0.30268723],\n",
       "        [-0.14769141,  0.3149446 , -0.6704867 , -0.38344404,  0.2693835 ]],\n",
       "       dtype=float32),\n",
       " array([ 0.03823338,  0.22698197,  0.0450831 , -0.26207602,  0.05051637],\n",
       "       dtype=float32),\n",
       " array([[ 0.00097602],\n",
       "        [ 0.0033526 ],\n",
       "        [-0.62502044],\n",
       "        [-0.19616182],\n",
       "        [-0.01996933]], dtype=float32),\n",
       " array([0.02945896], dtype=float32)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_automobile, history_automobile=NN_model_structure_regression_1(X_train_automobile, X_val_automobile, Y_train_automobile, Y_val_automobile, adam2, 32, 1000)\n",
    "model_automobile.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_automobile.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_automobile_structure1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_40 (Dense)             (None, 5)                 115       \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 186\n",
      "Trainable params: 186\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 143 samples, validate on 31 samples\n",
      "Epoch 1/1000\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.4836 - val_loss: 0.0647\n",
      "Epoch 2/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.1215 - val_loss: 0.1724\n",
      "Epoch 3/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0972 - val_loss: 0.0473\n",
      "Epoch 4/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0486 - val_loss: 0.0437\n",
      "Epoch 5/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0485 - val_loss: 0.0111\n",
      "Epoch 6/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0315 - val_loss: 0.0098\n",
      "Epoch 7/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0233 - val_loss: 0.0153\n",
      "Epoch 8/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0207 - val_loss: 0.0099\n",
      "Epoch 9/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0182 - val_loss: 0.0095\n",
      "Epoch 10/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0158 - val_loss: 0.0067\n",
      "Epoch 11/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0138 - val_loss: 0.0061\n",
      "Epoch 12/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0121 - val_loss: 0.0054\n",
      "Epoch 13/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0113 - val_loss: 0.0052\n",
      "Epoch 14/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0104 - val_loss: 0.0051\n",
      "Epoch 15/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0102 - val_loss: 0.0051\n",
      "Epoch 16/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0092 - val_loss: 0.0052\n",
      "Epoch 17/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0091 - val_loss: 0.0050\n",
      "Epoch 18/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0091 - val_loss: 0.0051\n",
      "Epoch 19/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0089 - val_loss: 0.0050\n",
      "Epoch 20/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0089 - val_loss: 0.0051\n",
      "Epoch 21/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0084 - val_loss: 0.0054\n",
      "Epoch 22/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0077 - val_loss: 0.0056\n",
      "Epoch 23/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0081 - val_loss: 0.0055\n",
      "Epoch 24/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0079 - val_loss: 0.0051\n",
      "Epoch 25/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0081 - val_loss: 0.0057\n",
      "Epoch 26/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0089 - val_loss: 0.0055\n",
      "Epoch 27/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0107 - val_loss: 0.0054\n",
      "Epoch 28/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0095 - val_loss: 0.0052\n",
      "Epoch 29/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0090 - val_loss: 0.0051\n",
      "Epoch 30/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0074 - val_loss: 0.0067\n",
      "Epoch 31/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0077 - val_loss: 0.0055\n",
      "Epoch 32/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0080 - val_loss: 0.0055\n",
      "Epoch 33/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0075 - val_loss: 0.0052\n",
      "Epoch 34/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0078 - val_loss: 0.0053\n",
      "Epoch 35/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0079 - val_loss: 0.0051\n",
      "Epoch 36/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0074 - val_loss: 0.0058\n",
      "Epoch 37/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0073 - val_loss: 0.0055\n",
      "Epoch 38/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0072 - val_loss: 0.0058\n",
      "Epoch 39/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0075 - val_loss: 0.0052\n",
      "Epoch 40/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0072 - val_loss: 0.0054\n",
      "Epoch 41/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0076 - val_loss: 0.0054\n",
      "Epoch 42/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0078 - val_loss: 0.0053\n",
      "Epoch 43/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0073 - val_loss: 0.0052\n",
      "Epoch 44/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0073 - val_loss: 0.0058\n",
      "Epoch 45/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0073 - val_loss: 0.0053\n",
      "Epoch 46/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0072 - val_loss: 0.0058\n",
      "Epoch 47/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0072 - val_loss: 0.0056\n",
      "Epoch 48/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0072 - val_loss: 0.0056\n",
      "Epoch 49/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0073 - val_loss: 0.0050\n",
      "Epoch 50/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0072 - val_loss: 0.0053\n",
      "Epoch 51/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0070 - val_loss: 0.0052\n",
      "Epoch 52/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0069 - val_loss: 0.0055\n",
      "Epoch 53/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0074 - val_loss: 0.0057\n",
      "Epoch 54/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0076 - val_loss: 0.0053\n",
      "Epoch 55/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0074 - val_loss: 0.0052\n",
      "Epoch 56/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0069 - val_loss: 0.0060\n",
      "Epoch 57/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0070 - val_loss: 0.0052\n",
      "Epoch 58/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0068 - val_loss: 0.0059\n",
      "Epoch 59/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0068 - val_loss: 0.0052\n",
      "Epoch 60/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0069 - val_loss: 0.0056\n",
      "Epoch 61/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0068 - val_loss: 0.0051\n",
      "Epoch 62/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0067 - val_loss: 0.0054\n",
      "Epoch 63/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0068 - val_loss: 0.0053\n",
      "Epoch 64/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0068 - val_loss: 0.0053\n",
      "Epoch 65/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0071 - val_loss: 0.0058\n",
      "Epoch 66/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0071 - val_loss: 0.0054\n",
      "Epoch 67/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0067 - val_loss: 0.0054\n",
      "Epoch 68/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0069 - val_loss: 0.0054\n",
      "Epoch 69/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0071 - val_loss: 0.0052\n",
      "Epoch 70/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0066 - val_loss: 0.0053\n",
      "Epoch 71/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0067 - val_loss: 0.0054\n",
      "Epoch 72/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0067 - val_loss: 0.0056\n",
      "Epoch 73/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0069 - val_loss: 0.0051\n",
      "Epoch 74/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0069 - val_loss: 0.0049\n",
      "Epoch 75/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0067 - val_loss: 0.0048\n",
      "Epoch 76/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0066 - val_loss: 0.0054\n",
      "Epoch 77/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0066 - val_loss: 0.0050\n",
      "Epoch 78/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0067 - val_loss: 0.0053\n",
      "Epoch 79/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0069 - val_loss: 0.0052\n",
      "Epoch 80/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0067 - val_loss: 0.0051\n",
      "Epoch 81/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0066 - val_loss: 0.0050\n",
      "Epoch 82/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0067 - val_loss: 0.0051\n",
      "Epoch 83/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0066 - val_loss: 0.0051\n",
      "Epoch 84/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0069 - val_loss: 0.0051\n",
      "Epoch 85/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0066 - val_loss: 0.0051\n",
      "Epoch 86/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0063 - val_loss: 0.0053\n",
      "Epoch 87/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0064 - val_loss: 0.0048\n",
      "Epoch 88/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.007 - 0s 133us/step - loss: 0.0063 - val_loss: 0.0053\n",
      "Epoch 89/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0063 - val_loss: 0.0051\n",
      "Epoch 90/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0064 - val_loss: 0.0057\n",
      "Epoch 91/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0071 - val_loss: 0.0051\n",
      "Epoch 92/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0064 - val_loss: 0.0052\n",
      "Epoch 93/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0062 - val_loss: 0.0052\n",
      "Epoch 94/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0060 - val_loss: 0.0047\n",
      "Epoch 95/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0062 - val_loss: 0.0056\n",
      "Epoch 96/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0068 - val_loss: 0.0049\n",
      "Epoch 97/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0063 - val_loss: 0.0053\n",
      "Epoch 98/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0065 - val_loss: 0.0051\n",
      "Epoch 99/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0067 - val_loss: 0.0052\n",
      "Epoch 100/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0063 - val_loss: 0.0045\n",
      "Epoch 101/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0064 - val_loss: 0.0049\n",
      "Epoch 102/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0060 - val_loss: 0.0049\n",
      "Epoch 103/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0064 - val_loss: 0.0056\n",
      "Epoch 104/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0065 - val_loss: 0.0050\n",
      "Epoch 105/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0066 - val_loss: 0.0052\n",
      "Epoch 106/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0061 - val_loss: 0.0049\n",
      "Epoch 107/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0061 - val_loss: 0.0049\n",
      "Epoch 108/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0063 - val_loss: 0.0051\n",
      "Epoch 109/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0059 - val_loss: 0.0050\n",
      "Epoch 110/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0057 - val_loss: 0.0060\n",
      "Epoch 111/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0059 - val_loss: 0.0053\n",
      "Epoch 112/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0064 - val_loss: 0.0055\n",
      "Epoch 113/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0064 - val_loss: 0.0051\n",
      "Epoch 114/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0070 - val_loss: 0.0050\n",
      "Epoch 115/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0069 - val_loss: 0.0053\n",
      "Epoch 116/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0062 - val_loss: 0.0048\n",
      "Epoch 117/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0057 - val_loss: 0.0048\n",
      "Epoch 118/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0059 - val_loss: 0.0046\n",
      "Epoch 119/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0057 - val_loss: 0.0049\n",
      "Epoch 120/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0057 - val_loss: 0.0051\n",
      "Epoch 121/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0057 - val_loss: 0.0050\n",
      "Epoch 122/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0056 - val_loss: 0.0056\n",
      "Epoch 123/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0061 - val_loss: 0.0048\n",
      "Epoch 124/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0059 - val_loss: 0.0049\n",
      "Epoch 125/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 126/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0057 - val_loss: 0.0046\n",
      "Epoch 127/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0057 - val_loss: 0.0049\n",
      "Epoch 128/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0054 - val_loss: 0.0048\n",
      "Epoch 129/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 130/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 131/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0055 - val_loss: 0.0043\n",
      "Epoch 132/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0059 - val_loss: 0.0050\n",
      "Epoch 133/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 134/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0054 - val_loss: 0.0049\n",
      "Epoch 135/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 136/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 137/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0057 - val_loss: 0.0048\n",
      "Epoch 138/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0059 - val_loss: 0.0045\n",
      "Epoch 139/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0061 - val_loss: 0.0048\n",
      "Epoch 140/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0063 - val_loss: 0.0046\n",
      "Epoch 141/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0052 - val_loss: 0.0045\n",
      "Epoch 142/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0052 - val_loss: 0.0052\n",
      "Epoch 143/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 144/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0052 - val_loss: 0.0049\n",
      "Epoch 145/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0052 - val_loss: 0.0047\n",
      "Epoch 146/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 147/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0045\n",
      "Epoch 148/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0051 - val_loss: 0.0049\n",
      "Epoch 149/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0055 - val_loss: 0.0044\n",
      "Epoch 150/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0050\n",
      "Epoch 151/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0052 - val_loss: 0.0047\n",
      "Epoch 152/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0053 - val_loss: 0.0049\n",
      "Epoch 153/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 154/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0056 - val_loss: 0.0059\n",
      "Epoch 155/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0059 - val_loss: 0.0044\n",
      "Epoch 156/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0060 - val_loss: 0.0056\n",
      "Epoch 157/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0060 - val_loss: 0.0045\n",
      "Epoch 158/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 159/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0048\n",
      "Epoch 160/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0052 - val_loss: 0.0053\n",
      "Epoch 161/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0056 - val_loss: 0.0046\n",
      "Epoch 162/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 163/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0050\n",
      "Epoch 164/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0051 - val_loss: 0.0049\n",
      "Epoch 165/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0052\n",
      "Epoch 166/1000\n",
      "143/143 [==============================] - 0s 127us/step - loss: 0.0052 - val_loss: 0.0050\n",
      "Epoch 167/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0057 - val_loss: 0.0045\n",
      "Epoch 168/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0063 - val_loss: 0.0065\n",
      "Epoch 169/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0065 - val_loss: 0.0042\n",
      "Epoch 170/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0058 - val_loss: 0.0047\n",
      "Epoch 171/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0049 - val_loss: 0.0044\n",
      "Epoch 172/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0050 - val_loss: 0.0043\n",
      "Epoch 173/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0051 - val_loss: 0.0050\n",
      "Epoch 174/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0057 - val_loss: 0.0046\n",
      "Epoch 175/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0054 - val_loss: 0.0051\n",
      "Epoch 176/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0059 - val_loss: 0.0044\n",
      "Epoch 177/1000\n",
      "143/143 [==============================] - 0s 127us/step - loss: 0.0058 - val_loss: 0.0052\n",
      "Epoch 178/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0052 - val_loss: 0.0042\n",
      "Epoch 179/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0053 - val_loss: 0.0047\n",
      "Epoch 180/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0050 - val_loss: 0.0044\n",
      "Epoch 181/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0044\n",
      "Epoch 182/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0049 - val_loss: 0.0045\n",
      "Epoch 183/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0049 - val_loss: 0.0043\n",
      "Epoch 184/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0058 - val_loss: 0.0049\n",
      "Epoch 185/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0050 - val_loss: 0.0043\n",
      "Epoch 186/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0051 - val_loss: 0.0053\n",
      "Epoch 187/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0059 - val_loss: 0.0047\n",
      "Epoch 188/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 189/1000\n",
      "143/143 [==============================] - 0s 174us/step - loss: 0.0054 - val_loss: 0.0043\n",
      "Epoch 190/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0059 - val_loss: 0.0058\n",
      "Epoch 191/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0059 - val_loss: 0.0044\n",
      "Epoch 192/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0065 - val_loss: 0.0056\n",
      "Epoch 193/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0070 - val_loss: 0.0046\n",
      "Epoch 194/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0081 - val_loss: 0.0049\n",
      "Epoch 195/1000\n",
      "143/143 [==============================] - 0s 94us/step - loss: 0.0058 - val_loss: 0.0040\n",
      "Epoch 196/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0050 - val_loss: 0.0042\n",
      "Epoch 197/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 198/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0043\n",
      "Epoch 199/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0045\n",
      "Epoch 200/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0050 - val_loss: 0.0044\n",
      "Epoch 201/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0047\n",
      "Epoch 202/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0047\n",
      "Epoch 203/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0047\n",
      "Epoch 204/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0048 - val_loss: 0.0044\n",
      "Epoch 205/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0050 - val_loss: 0.0048\n",
      "Epoch 206/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0051 - val_loss: 0.0041\n",
      "Epoch 207/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0050 - val_loss: 0.0042\n",
      "Epoch 208/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0049 - val_loss: 0.0045\n",
      "Epoch 209/1000\n",
      "143/143 [==============================] - 0s 128us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 210/1000\n",
      "143/143 [==============================] - 0s 136us/step - loss: 0.0051 - val_loss: 0.0042\n",
      "Epoch 211/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0052 - val_loss: 0.0045\n",
      "Epoch 212/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0043\n",
      "Epoch 213/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0050 - val_loss: 0.0045\n",
      "Epoch 214/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0049 - val_loss: 0.0047\n",
      "Epoch 215/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0043\n",
      "Epoch 216/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0051\n",
      "Epoch 217/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0049 - val_loss: 0.0044\n",
      "Epoch 218/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 219/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 220/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0052\n",
      "Epoch 221/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0042\n",
      "Epoch 222/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 223/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 105us/step - loss: 0.0047 - val_loss: 0.0043\n",
      "Epoch 224/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0044\n",
      "Epoch 225/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0046 - val_loss: 0.0042\n",
      "Epoch 226/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 227/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 228/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0047 - val_loss: 0.0042\n",
      "Epoch 229/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 230/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0048 - val_loss: 0.0055\n",
      "Epoch 231/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0055 - val_loss: 0.0040\n",
      "Epoch 232/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0050\n",
      "Epoch 233/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0042\n",
      "Epoch 234/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0042\n",
      "Epoch 235/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0047 - val_loss: 0.0042\n",
      "Epoch 236/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 237/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0044\n",
      "Epoch 238/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0042\n",
      "Epoch 239/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0043\n",
      "Epoch 240/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0041\n",
      "Epoch 241/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0041\n",
      "Epoch 242/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0056 - val_loss: 0.0055\n",
      "Epoch 243/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0054 - val_loss: 0.0040\n",
      "Epoch 244/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0052 - val_loss: 0.0049\n",
      "Epoch 245/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0054 - val_loss: 0.0046\n",
      "Epoch 246/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0049 - val_loss: 0.0047\n",
      "Epoch 247/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 248/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 249/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0044\n",
      "Epoch 250/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 251/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0049 - val_loss: 0.0043\n",
      "Epoch 252/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0048 - val_loss: 0.0044\n",
      "Epoch 253/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0044 - val_loss: 0.0042\n",
      "Epoch 254/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 255/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0047 - val_loss: 0.0041\n",
      "Epoch 256/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0047\n",
      "Epoch 257/1000\n",
      "143/143 [==============================] - 0s 127us/step - loss: 0.0045 - val_loss: 0.0042\n",
      "Epoch 258/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 259/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 260/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 261/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0045 - val_loss: 0.0047\n",
      "Epoch 262/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0043\n",
      "Epoch 263/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 264/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0047 - val_loss: 0.0041\n",
      "Epoch 265/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 266/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0042\n",
      "Epoch 267/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 268/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0045 - val_loss: 0.0041\n",
      "Epoch 269/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 270/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0044 - val_loss: 0.0042\n",
      "Epoch 271/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 272/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0044\n",
      "Epoch 273/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 274/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 275/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 276/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0046 - val_loss: 0.0038\n",
      "Epoch 277/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 278/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 279/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0048 - val_loss: 0.0043\n",
      "Epoch 280/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0048 - val_loss: 0.0044\n",
      "Epoch 281/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0049 - val_loss: 0.0038\n",
      "Epoch 282/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0047 - val_loss: 0.0044\n",
      "Epoch 283/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0044 - val_loss: 0.0041\n",
      "Epoch 284/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 285/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0050 - val_loss: 0.0043\n",
      "Epoch 286/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0042\n",
      "Epoch 287/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0043\n",
      "Epoch 288/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 289/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0045 - val_loss: 0.0038\n",
      "Epoch 290/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 291/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0041\n",
      "Epoch 292/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 293/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0045 - val_loss: 0.0037\n",
      "Epoch 294/1000\n",
      "143/143 [==============================] - 0s 143us/step - loss: 0.0046 - val_loss: 0.0051\n",
      "Epoch 295/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0047 - val_loss: 0.0038\n",
      "Epoch 296/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 297/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0042\n",
      "Epoch 298/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 299/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0043 - val_loss: 0.0038\n",
      "Epoch 300/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0044 - val_loss: 0.0041\n",
      "Epoch 301/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0043 - val_loss: 0.0050\n",
      "Epoch 302/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0047 - val_loss: 0.0039\n",
      "Epoch 303/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 304/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0040\n",
      "Epoch 305/1000\n",
      "143/143 [==============================] - 0s 136us/step - loss: 0.0045 - val_loss: 0.0040\n",
      "Epoch 306/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 307/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0044 - val_loss: 0.0037\n",
      "Epoch 308/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0051 - val_loss: 0.0064\n",
      "Epoch 309/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0060 - val_loss: 0.0039\n",
      "Epoch 310/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0051 - val_loss: 0.0057\n",
      "Epoch 311/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0037\n",
      "Epoch 312/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 313/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0048 - val_loss: 0.0040\n",
      "Epoch 314/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 315/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0043 - val_loss: 0.0040\n",
      "Epoch 316/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0043 - val_loss: 0.0037\n",
      "Epoch 317/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0043\n",
      "Epoch 318/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0043 - val_loss: 0.0039\n",
      "Epoch 319/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0043 - val_loss: 0.0050\n",
      "Epoch 320/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0038\n",
      "Epoch 321/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0045 - val_loss: 0.0050\n",
      "Epoch 322/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0052 - val_loss: 0.0039\n",
      "Epoch 323/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0041 - val_loss: 0.0050\n",
      "Epoch 324/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 325/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0043 - val_loss: 0.0041\n",
      "Epoch 326/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0054\n",
      "Epoch 327/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0048 - val_loss: 0.0037\n",
      "Epoch 328/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0050 - val_loss: 0.0058\n",
      "Epoch 329/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0056 - val_loss: 0.0040\n",
      "Epoch 330/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0048 - val_loss: 0.0045\n",
      "Epoch 331/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0044 - val_loss: 0.0040\n",
      "Epoch 332/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0044 - val_loss: 0.0039\n",
      "Epoch 333/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0038\n",
      "Epoch 334/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0040\n",
      "Epoch 335/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 336/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0038\n",
      "Epoch 337/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 338/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0038\n",
      "Epoch 339/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 340/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0034\n",
      "Epoch 341/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 342/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0038\n",
      "Epoch 343/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0041 - val_loss: 0.0045\n",
      "Epoch 344/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0041 - val_loss: 0.0036\n",
      "Epoch 345/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0049 - val_loss: 0.0043\n",
      "Epoch 346/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0042 - val_loss: 0.0038\n",
      "Epoch 347/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0041 - val_loss: 0.0045\n",
      "Epoch 348/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0042 - val_loss: 0.0039\n",
      "Epoch 349/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0045\n",
      "Epoch 350/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0043 - val_loss: 0.0037\n",
      "Epoch 351/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0045\n",
      "Epoch 352/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0042 - val_loss: 0.0038\n",
      "Epoch 353/1000\n",
      "143/143 [==============================] - 0s 174us/step - loss: 0.0042 - val_loss: 0.0044\n",
      "Epoch 354/1000\n",
      "143/143 [==============================] - 0s 181us/step - loss: 0.0042 - val_loss: 0.0035\n",
      "Epoch 355/1000\n",
      "143/143 [==============================] - 0s 195us/step - loss: 0.0043 - val_loss: 0.0054\n",
      "Epoch 356/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0045 - val_loss: 0.0035\n",
      "Epoch 357/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0041 - val_loss: 0.0042\n",
      "Epoch 358/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 359/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 360/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0043 - val_loss: 0.0037\n",
      "Epoch 361/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0049 - val_loss: 0.0044\n",
      "Epoch 362/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0036\n",
      "Epoch 363/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 364/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0034\n",
      "Epoch 365/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0057 - val_loss: 0.0051\n",
      "Epoch 366/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0037\n",
      "Epoch 367/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0061\n",
      "Epoch 368/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0055 - val_loss: 0.0037\n",
      "Epoch 369/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 370/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0055 - val_loss: 0.0037\n",
      "Epoch 371/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0039\n",
      "Epoch 372/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0038\n",
      "Epoch 373/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0046 - val_loss: 0.0043\n",
      "Epoch 374/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0044 - val_loss: 0.0040\n",
      "Epoch 375/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0042 - val_loss: 0.0039\n",
      "Epoch 376/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0040 - val_loss: 0.0042\n",
      "Epoch 377/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 114us/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 378/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0038\n",
      "Epoch 379/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0039 - val_loss: 0.0037\n",
      "Epoch 380/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0038\n",
      "Epoch 381/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 382/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0041 - val_loss: 0.0036\n",
      "Epoch 383/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0044\n",
      "Epoch 384/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0041 - val_loss: 0.0038\n",
      "Epoch 385/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 386/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 387/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0039 - val_loss: 0.0042\n",
      "Epoch 388/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0039 - val_loss: 0.0035\n",
      "Epoch 389/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0041 - val_loss: 0.0045\n",
      "Epoch 390/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 391/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0049\n",
      "Epoch 392/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0043 - val_loss: 0.0036\n",
      "Epoch 393/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0040 - val_loss: 0.0051\n",
      "Epoch 394/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0037\n",
      "Epoch 395/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0054\n",
      "Epoch 396/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0037\n",
      "Epoch 397/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 398/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0042 - val_loss: 0.0038\n",
      "Epoch 399/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 400/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 401/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 402/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 403/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 404/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 405/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0042\n",
      "Epoch 406/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0037\n",
      "Epoch 407/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 408/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 409/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 410/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 411/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 412/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 413/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 414/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0048\n",
      "Epoch 415/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 416/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0039 - val_loss: 0.0038\n",
      "Epoch 417/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 418/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0040 - val_loss: 0.0035\n",
      "Epoch 419/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0041 - val_loss: 0.0062\n",
      "Epoch 420/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0046 - val_loss: 0.0040\n",
      "Epoch 421/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0045 - val_loss: 0.0064\n",
      "Epoch 422/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0044 - val_loss: 0.0036\n",
      "Epoch 423/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0037 - val_loss: 0.0057\n",
      "Epoch 424/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0041 - val_loss: 0.0039\n",
      "Epoch 425/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0042 - val_loss: 0.0044\n",
      "Epoch 426/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 427/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0038 - val_loss: 0.0040\n",
      "Epoch 428/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0042\n",
      "Epoch 429/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0037 - val_loss: 0.0036\n",
      "Epoch 430/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 431/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0044\n",
      "Epoch 432/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0036\n",
      "Epoch 433/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0037 - val_loss: 0.0054\n",
      "Epoch 434/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0044 - val_loss: 0.0038\n",
      "Epoch 435/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0043 - val_loss: 0.0057\n",
      "Epoch 436/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0042 - val_loss: 0.0038\n",
      "Epoch 437/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 438/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0036 - val_loss: 0.0035\n",
      "Epoch 439/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0036 - val_loss: 0.0042\n",
      "Epoch 440/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0036 - val_loss: 0.0039\n",
      "Epoch 441/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0048\n",
      "Epoch 442/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0039 - val_loss: 0.0036\n",
      "Epoch 443/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0042\n",
      "Epoch 444/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 445/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0052\n",
      "Epoch 446/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 447/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0037 - val_loss: 0.0050\n",
      "Epoch 448/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 449/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0036 - val_loss: 0.0049\n",
      "Epoch 450/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0033\n",
      "Epoch 451/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0037 - val_loss: 0.0036\n",
      "Epoch 452/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 453/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0040\n",
      "Epoch 454/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0047 - val_loss: 0.0059\n",
      "Epoch 455/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0032\n",
      "Epoch 456/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 457/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0039 - val_loss: 0.0036\n",
      "Epoch 458/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0034 - val_loss: 0.0044\n",
      "Epoch 459/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 460/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 461/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 462/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 463/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0033 - val_loss: 0.0039\n",
      "Epoch 464/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0039\n",
      "Epoch 465/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 466/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 467/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Epoch 468/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 469/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0034 - val_loss: 0.0043\n",
      "Epoch 470/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 471/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0033 - val_loss: 0.0045\n",
      "Epoch 472/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 473/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 474/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 475/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 476/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0035 - val_loss: 0.0058\n",
      "Epoch 477/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0044\n",
      "Epoch 478/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0045 - val_loss: 0.0051\n",
      "Epoch 479/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0035 - val_loss: 0.0034\n",
      "Epoch 480/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0040\n",
      "Epoch 481/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0036 - val_loss: 0.0047\n",
      "Epoch 482/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0042\n",
      "Epoch 483/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 484/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0035\n",
      "Epoch 485/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 486/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0035 - val_loss: 0.0042\n",
      "Epoch 487/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 488/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 489/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0039 - val_loss: 0.0071\n",
      "Epoch 490/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0050 - val_loss: 0.0038\n",
      "Epoch 491/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0053\n",
      "Epoch 492/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0033\n",
      "Epoch 493/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 494/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 495/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 496/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0032 - val_loss: 0.0039\n",
      "Epoch 497/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 498/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 499/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 500/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 501/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0035 - val_loss: 0.0041\n",
      "Epoch 502/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0031 - val_loss: 0.0030\n",
      "Epoch 503/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 504/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0031 - val_loss: 0.0035\n",
      "Epoch 505/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0032 - val_loss: 0.0037\n",
      "Epoch 506/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0034\n",
      "Epoch 507/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0030\n",
      "Epoch 508/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0043\n",
      "Epoch 509/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0032 - val_loss: 0.0036\n",
      "Epoch 510/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0032 - val_loss: 0.0041\n",
      "Epoch 511/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0031 - val_loss: 0.0033\n",
      "Epoch 512/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0031 - val_loss: 0.0033\n",
      "Epoch 513/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0031 - val_loss: 0.0055\n",
      "Epoch 514/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 515/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 516/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0040 - val_loss: 0.0083\n",
      "Epoch 517/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 518/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0039 - val_loss: 0.0071\n",
      "Epoch 519/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0038 - val_loss: 0.0032\n",
      "Epoch 520/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0032\n",
      "Epoch 521/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 522/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 523/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0047\n",
      "Epoch 524/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 525/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 526/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 527/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0038\n",
      "Epoch 528/1000\n",
      "143/143 [==============================] - 0s 127us/step - loss: 0.0029 - val_loss: 0.0033\n",
      "Epoch 529/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0032 - val_loss: 0.0044\n",
      "Epoch 530/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0030 - val_loss: 0.0033\n",
      "Epoch 531/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0040\n",
      "Epoch 532/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 533/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0035\n",
      "Epoch 534/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0029 - val_loss: 0.0035\n",
      "Epoch 535/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 536/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0030 - val_loss: 0.0039\n",
      "Epoch 537/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0029 - val_loss: 0.0032\n",
      "Epoch 538/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0029 - val_loss: 0.0044\n",
      "Epoch 539/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0031 - val_loss: 0.0033\n",
      "Epoch 540/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 541/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0055\n",
      "Epoch 542/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0034\n",
      "Epoch 543/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 544/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0029 - val_loss: 0.0040\n",
      "Epoch 545/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0028 - val_loss: 0.0034\n",
      "Epoch 546/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0028 - val_loss: 0.0034\n",
      "Epoch 547/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 548/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0028 - val_loss: 0.0034\n",
      "Epoch 549/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 550/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0032\n",
      "Epoch 551/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 552/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 553/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0029 - val_loss: 0.0032\n",
      "Epoch 554/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0041\n",
      "Epoch 555/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0027 - val_loss: 0.0031\n",
      "Epoch 556/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0065\n",
      "Epoch 557/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0039 - val_loss: 0.0035\n",
      "Epoch 558/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0038 - val_loss: 0.0033\n",
      "Epoch 559/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0034 - val_loss: 0.0069\n",
      "Epoch 560/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0042 - val_loss: 0.0032\n",
      "Epoch 561/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0034\n",
      "Epoch 562/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0029 - val_loss: 0.0043\n",
      "Epoch 563/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0035\n",
      "Epoch 564/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 565/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 566/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 567/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0029 - val_loss: 0.0049\n",
      "Epoch 568/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 569/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0038 - val_loss: 0.0033\n",
      "Epoch 570/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0029 - val_loss: 0.0039\n",
      "Epoch 571/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0029 - val_loss: 0.0045\n",
      "Epoch 572/1000\n",
      "143/143 [==============================] - 0s 130us/step - loss: 0.0029 - val_loss: 0.0032\n",
      "Epoch 573/1000\n",
      "143/143 [==============================] - 0s 127us/step - loss: 0.0030 - val_loss: 0.0063\n",
      "Epoch 574/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 575/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0034\n",
      "Epoch 576/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 577/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 578/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0051\n",
      "Epoch 579/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0036\n",
      "Epoch 580/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0029 - val_loss: 0.0046\n",
      "Epoch 581/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0030 - val_loss: 0.0034\n",
      "Epoch 582/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0035\n",
      "Epoch 583/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0027 - val_loss: 0.0038\n",
      "Epoch 584/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0027 - val_loss: 0.0031\n",
      "Epoch 585/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0030 - val_loss: 0.0076\n",
      "Epoch 586/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0046 - val_loss: 0.0051\n",
      "Epoch 587/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0051 - val_loss: 0.0061\n",
      "Epoch 588/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0036 - val_loss: 0.0032\n",
      "Epoch 589/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 590/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 591/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0031 - val_loss: 0.0033\n",
      "Epoch 592/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 593/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Epoch 594/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0026 - val_loss: 0.0037\n",
      "Epoch 595/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 596/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 597/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Epoch 598/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0058\n",
      "Epoch 599/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0033\n",
      "Epoch 600/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0032 - val_loss: 0.0035\n",
      "Epoch 601/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0031 - val_loss: 0.0046\n",
      "Epoch 602/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0031 - val_loss: 0.0034\n",
      "Epoch 603/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 604/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 605/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 606/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0025 - val_loss: 0.0042\n",
      "Epoch 607/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Epoch 608/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0040\n",
      "Epoch 609/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0024 - val_loss: 0.0032\n",
      "Epoch 610/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0043\n",
      "Epoch 611/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0033\n",
      "Epoch 612/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0038\n",
      "Epoch 613/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0046\n",
      "Epoch 614/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0032\n",
      "Epoch 615/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0036\n",
      "Epoch 616/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0045\n",
      "Epoch 617/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0028 - val_loss: 0.0033\n",
      "Epoch 618/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 619/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0047\n",
      "Epoch 620/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0029 - val_loss: 0.0032\n",
      "Epoch 621/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 622/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0031 - val_loss: 0.0053\n",
      "Epoch 623/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 624/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0026 - val_loss: 0.0038\n",
      "Epoch 625/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0025 - val_loss: 0.0034\n",
      "Epoch 626/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0032\n",
      "Epoch 627/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0026 - val_loss: 0.0041\n",
      "Epoch 628/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0025 - val_loss: 0.0035\n",
      "Epoch 629/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0041\n",
      "Epoch 630/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0032\n",
      "Epoch 631/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0028 - val_loss: 0.0032\n",
      "Epoch 632/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0032 - val_loss: 0.0048\n",
      "Epoch 633/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0037\n",
      "Epoch 634/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 635/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0025 - val_loss: 0.0037\n",
      "Epoch 636/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 637/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0031\n",
      "Epoch 638/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 639/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0052\n",
      "Epoch 640/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0029 - val_loss: 0.0035\n",
      "Epoch 641/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0024 - val_loss: 0.0034\n",
      "Epoch 642/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0035\n",
      "Epoch 643/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0033\n",
      "Epoch 644/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0027 - val_loss: 0.0050\n",
      "Epoch 645/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 646/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0034\n",
      "Epoch 647/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0037\n",
      "Epoch 648/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0055\n",
      "Epoch 649/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0030 - val_loss: 0.0033\n",
      "Epoch 650/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0028 - val_loss: 0.0041\n",
      "Epoch 651/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0025 - val_loss: 0.0038\n",
      "Epoch 652/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0035\n",
      "Epoch 653/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0024 - val_loss: 0.0033\n",
      "Epoch 654/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0023 - val_loss: 0.0043\n",
      "Epoch 655/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0023 - val_loss: 0.0033\n",
      "Epoch 656/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0038\n",
      "Epoch 657/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0033\n",
      "Epoch 658/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0043\n",
      "Epoch 659/1000\n",
      "143/143 [==============================] - 0s 129us/step - loss: 0.0024 - val_loss: 0.0036\n",
      "Epoch 660/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0024 - val_loss: 0.0033\n",
      "Epoch 661/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0025 - val_loss: 0.0050\n",
      "Epoch 662/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0038\n",
      "Epoch 663/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 664/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0036\n",
      "Epoch 665/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0048\n",
      "Epoch 666/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0034\n",
      "Epoch 667/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0032\n",
      "Epoch 668/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0023 - val_loss: 0.0046\n",
      "Epoch 669/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 670/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0024 - val_loss: 0.0034\n",
      "Epoch 671/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0042\n",
      "Epoch 672/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0022 - val_loss: 0.0034\n",
      "Epoch 673/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0023 - val_loss: 0.0042\n",
      "Epoch 674/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0040\n",
      "Epoch 675/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0034\n",
      "Epoch 676/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0023 - val_loss: 0.0039\n",
      "Epoch 677/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0035\n",
      "Epoch 678/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0036\n",
      "Epoch 679/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0035\n",
      "Epoch 680/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0042\n",
      "Epoch 681/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0024 - val_loss: 0.0033\n",
      "Epoch 682/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0037\n",
      "Epoch 683/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0023 - val_loss: 0.0039\n",
      "Epoch 684/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0042\n",
      "Epoch 685/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 118us/step - loss: 0.0024 - val_loss: 0.0033\n",
      "Epoch 686/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 687/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0028 - val_loss: 0.0045\n",
      "Epoch 688/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0046\n",
      "Epoch 689/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 690/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0034\n",
      "Epoch 691/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0027 - val_loss: 0.0039\n",
      "Epoch 692/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0034\n",
      "Epoch 693/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0038\n",
      "Epoch 694/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0036\n",
      "Epoch 695/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0024 - val_loss: 0.0034\n",
      "Epoch 696/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0034\n",
      "Epoch 697/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0024 - val_loss: 0.0058\n",
      "Epoch 698/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 699/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0036\n",
      "Epoch 700/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0024 - val_loss: 0.0046\n",
      "Epoch 701/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0044\n",
      "Epoch 702/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0025 - val_loss: 0.0037\n",
      "Epoch 703/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0039\n",
      "Epoch 704/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0042\n",
      "Epoch 705/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0037\n",
      "Epoch 706/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0040\n",
      "Epoch 707/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0034\n",
      "Epoch 708/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0042\n",
      "Epoch 709/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0022 - val_loss: 0.0043\n",
      "Epoch 710/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0024 - val_loss: 0.0036\n",
      "Epoch 711/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0028 - val_loss: 0.0042\n",
      "Epoch 712/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0038\n",
      "Epoch 713/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0034\n",
      "Epoch 714/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0046\n",
      "Epoch 715/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0022 - val_loss: 0.0038\n",
      "Epoch 716/1000\n",
      "143/143 [==============================] - 0s 128us/step - loss: 0.0022 - val_loss: 0.0035\n",
      "Epoch 717/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0021 - val_loss: 0.0036\n",
      "Epoch 718/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0022 - val_loss: 0.0041\n",
      "Epoch 719/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0046\n",
      "Epoch 720/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0036\n",
      "Epoch 721/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0022 - val_loss: 0.0036\n",
      "Epoch 722/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0023 - val_loss: 0.0042\n",
      "Epoch 723/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0051\n",
      "Epoch 724/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0037\n",
      "Epoch 725/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0024 - val_loss: 0.0034\n",
      "Epoch 726/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0041\n",
      "Epoch 727/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0040\n",
      "Epoch 728/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0022 - val_loss: 0.0036\n",
      "Epoch 729/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0039\n",
      "Epoch 730/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0040\n",
      "Epoch 731/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0021 - val_loss: 0.0036\n",
      "Epoch 732/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0043\n",
      "Epoch 733/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0022 - val_loss: 0.0036\n",
      "Epoch 734/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0022 - val_loss: 0.0034\n",
      "Epoch 735/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0024 - val_loss: 0.0036\n",
      "Epoch 736/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0025 - val_loss: 0.0073\n",
      "Epoch 737/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0030 - val_loss: 0.0038\n",
      "Epoch 738/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0038\n",
      "Epoch 739/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0033 - val_loss: 0.0072\n",
      "Epoch 740/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 741/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0029 - val_loss: 0.0040\n",
      "Epoch 742/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0064\n",
      "Epoch 743/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 744/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 745/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0023 - val_loss: 0.0043\n",
      "Epoch 746/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0034\n",
      "Epoch 747/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0036\n",
      "Epoch 748/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0021 - val_loss: 0.0046\n",
      "Epoch 749/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0023 - val_loss: 0.0034\n",
      "Epoch 750/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0023 - val_loss: 0.0040\n",
      "Epoch 751/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0022 - val_loss: 0.0039\n",
      "Epoch 752/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0022 - val_loss: 0.0034\n",
      "Epoch 753/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0023 - val_loss: 0.0044\n",
      "Epoch 754/1000\n",
      "143/143 [==============================] - 0s 128us/step - loss: 0.0023 - val_loss: 0.0044\n",
      "Epoch 755/1000\n",
      "143/143 [==============================] - 0s 127us/step - loss: 0.0024 - val_loss: 0.0036\n",
      "Epoch 756/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0027 - val_loss: 0.0054\n",
      "Epoch 757/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0034\n",
      "Epoch 758/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0044\n",
      "Epoch 759/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0024 - val_loss: 0.0038\n",
      "Epoch 760/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 761/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0025 - val_loss: 0.0043\n",
      "Epoch 762/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0022 - val_loss: 0.0042\n",
      "Epoch 763/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0022 - val_loss: 0.0033\n",
      "Epoch 764/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0051\n",
      "Epoch 765/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0023 - val_loss: 0.0037\n",
      "Epoch 766/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0039\n",
      "Epoch 767/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0038\n",
      "Epoch 768/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0021 - val_loss: 0.0047\n",
      "Epoch 769/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0022 - val_loss: 0.0038\n",
      "Epoch 770/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0021 - val_loss: 0.0036\n",
      "Epoch 771/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 0.0036\n",
      "Epoch 772/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0023 - val_loss: 0.0039\n",
      "Epoch 773/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0041\n",
      "Epoch 774/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0019 - val_loss: 0.0036\n",
      "Epoch 775/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0020 - val_loss: 0.0051\n",
      "Epoch 776/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0022 - val_loss: 0.0038\n",
      "Epoch 777/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0039\n",
      "Epoch 778/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0020 - val_loss: 0.0040\n",
      "Epoch 779/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0020 - val_loss: 0.0044\n",
      "Epoch 780/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Epoch 781/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0037\n",
      "Epoch 782/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0035\n",
      "Epoch 783/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0020 - val_loss: 0.0041\n",
      "Epoch 784/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0038\n",
      "Epoch 785/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0020 - val_loss: 0.0050\n",
      "Epoch 786/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0021 - val_loss: 0.0039\n",
      "Epoch 787/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0021 - val_loss: 0.0037\n",
      "Epoch 788/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0034\n",
      "Epoch 789/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0024 - val_loss: 0.0035\n",
      "Epoch 790/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0027 - val_loss: 0.0056\n",
      "Epoch 791/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0034\n",
      "Epoch 792/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0034\n",
      "Epoch 793/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 794/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0035\n",
      "Epoch 795/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 796/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0020 - val_loss: 0.0035\n",
      "Epoch 797/1000\n",
      "143/143 [==============================] - 0s 128us/step - loss: 0.0021 - val_loss: 0.0042\n",
      "Epoch 798/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0036\n",
      "Epoch 799/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0035\n",
      "Epoch 800/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0050\n",
      "Epoch 801/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0023 - val_loss: 0.0043\n",
      "Epoch 802/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0040\n",
      "Epoch 803/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0052\n",
      "Epoch 804/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0026 - val_loss: 0.0044\n",
      "Epoch 805/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0033\n",
      "Epoch 806/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0040\n",
      "Epoch 807/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 808/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0021 - val_loss: 0.0036\n",
      "Epoch 809/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0048\n",
      "Epoch 810/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0023 - val_loss: 0.0043\n",
      "Epoch 811/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0021 - val_loss: 0.0038\n",
      "Epoch 812/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0047\n",
      "Epoch 813/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0020 - val_loss: 0.0036\n",
      "Epoch 814/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0037\n",
      "Epoch 815/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0043\n",
      "Epoch 816/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0020 - val_loss: 0.0037\n",
      "Epoch 817/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0035\n",
      "Epoch 818/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0036\n",
      "Epoch 819/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0038\n",
      "Epoch 820/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 821/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 822/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0020 - val_loss: 0.0035\n",
      "Epoch 823/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0022 - val_loss: 0.0041\n",
      "Epoch 824/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0038\n",
      "Epoch 825/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0020 - val_loss: 0.0068\n",
      "Epoch 826/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0025 - val_loss: 0.0041\n",
      "Epoch 827/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0025 - val_loss: 0.0042\n",
      "Epoch 828/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0061\n",
      "Epoch 829/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0026 - val_loss: 0.0038\n",
      "Epoch 830/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0023 - val_loss: 0.0035\n",
      "Epoch 831/1000\n",
      "143/143 [==============================] - 0s 140us/step - loss: 0.0020 - val_loss: 0.0035\n",
      "Epoch 832/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0020 - val_loss: 0.0038\n",
      "Epoch 833/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0037\n",
      "Epoch 834/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 835/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0021 - val_loss: 0.0039\n",
      "Epoch 836/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0020 - val_loss: 0.0040\n",
      "Epoch 837/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0020 - val_loss: 0.0037\n",
      "Epoch 838/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0019 - val_loss: 0.0051\n",
      "Epoch 839/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 133us/step - loss: 0.0021 - val_loss: 0.0037\n",
      "Epoch 840/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0038\n",
      "Epoch 841/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0019 - val_loss: 0.0042\n",
      "Epoch 842/1000\n",
      "143/143 [==============================] - 0s 130us/step - loss: 0.0019 - val_loss: 0.0042\n",
      "Epoch 843/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 844/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Epoch 845/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0020 - val_loss: 0.0037\n",
      "Epoch 846/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0035\n",
      "Epoch 847/1000\n",
      "143/143 [==============================] - 0s 127us/step - loss: 0.0025 - val_loss: 0.0048\n",
      "Epoch 848/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0049\n",
      "Epoch 849/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0026 - val_loss: 0.0044\n",
      "Epoch 850/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0025 - val_loss: 0.0055\n",
      "Epoch 851/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 0.0035\n",
      "Epoch 852/1000\n",
      "143/143 [==============================] - 0s 135us/step - loss: 0.0020 - val_loss: 0.0041\n",
      "Epoch 853/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0020 - val_loss: 0.0039\n",
      "Epoch 854/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0034\n",
      "Epoch 855/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0044\n",
      "Epoch 856/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0020 - val_loss: 0.0044\n",
      "Epoch 857/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0021 - val_loss: 0.0038\n",
      "Epoch 858/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0055\n",
      "Epoch 859/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0025 - val_loss: 0.0035\n",
      "Epoch 860/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0037\n",
      "Epoch 861/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0052\n",
      "Epoch 862/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0036\n",
      "Epoch 863/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0020 - val_loss: 0.0055\n",
      "Epoch 864/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0036\n",
      "Epoch 865/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0042\n",
      "Epoch 866/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 867/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0034\n",
      "Epoch 868/1000\n",
      "143/143 [==============================] - 0s 167us/step - loss: 0.0022 - val_loss: 0.0043\n",
      "Epoch 869/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0021 - val_loss: 0.0038\n",
      "Epoch 870/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0019 - val_loss: 0.0036\n",
      "Epoch 871/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0020 - val_loss: 0.0049\n",
      "Epoch 872/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0020 - val_loss: 0.0035\n",
      "Epoch 873/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 0.0048\n",
      "Epoch 874/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0039\n",
      "Epoch 875/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0018 - val_loss: 0.0046\n",
      "Epoch 876/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0037\n",
      "Epoch 877/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0038\n",
      "Epoch 878/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0020 - val_loss: 0.0054\n",
      "Epoch 879/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0037\n",
      "Epoch 880/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0036\n",
      "Epoch 881/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0022 - val_loss: 0.0051\n",
      "Epoch 882/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0037\n",
      "Epoch 883/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0042\n",
      "Epoch 884/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0020 - val_loss: 0.0048\n",
      "Epoch 885/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0037\n",
      "Epoch 886/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0022 - val_loss: 0.0036\n",
      "Epoch 887/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 888/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0037\n",
      "Epoch 889/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0036\n",
      "Epoch 890/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0020 - val_loss: 0.0035\n",
      "Epoch 891/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 892/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 893/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0036\n",
      "Epoch 894/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 895/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0019 - val_loss: 0.0038\n",
      "Epoch 896/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0020 - val_loss: 0.0035\n",
      "Epoch 897/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0020 - val_loss: 0.0045\n",
      "Epoch 898/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 899/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0019 - val_loss: 0.0037\n",
      "Epoch 900/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0018 - val_loss: 0.0046\n",
      "Epoch 901/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Epoch 902/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 903/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0020 - val_loss: 0.0046\n",
      "Epoch 904/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0037\n",
      "Epoch 905/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0041\n",
      "Epoch 906/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0047\n",
      "Epoch 907/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0020 - val_loss: 0.0051\n",
      "Epoch 908/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0037\n",
      "Epoch 909/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 910/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0018 - val_loss: 0.0035\n",
      "Epoch 911/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0018 - val_loss: 0.0048\n",
      "Epoch 912/1000\n",
      "143/143 [==============================] - 0s 129us/step - loss: 0.0019 - val_loss: 0.0039\n",
      "Epoch 913/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 914/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0045\n",
      "Epoch 915/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 916/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0045\n",
      "Epoch 917/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0040\n",
      "Epoch 918/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0038\n",
      "Epoch 919/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0019 - val_loss: 0.0039\n",
      "Epoch 920/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0035\n",
      "Epoch 921/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0040\n",
      "Epoch 922/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0039\n",
      "Epoch 923/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0039\n",
      "Epoch 924/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0023 - val_loss: 0.0053\n",
      "Epoch 925/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0021 - val_loss: 0.0041\n",
      "Epoch 926/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0019 - val_loss: 0.0039\n",
      "Epoch 927/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0037\n",
      "Epoch 928/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0021 - val_loss: 0.0039\n",
      "Epoch 929/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 930/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0037\n",
      "Epoch 931/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0037\n",
      "Epoch 932/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0021 - val_loss: 0.0043\n",
      "Epoch 933/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0039\n",
      "Epoch 934/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 935/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0042\n",
      "Epoch 936/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0018 - val_loss: 0.0040\n",
      "Epoch 937/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0035\n",
      "Epoch 938/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0044\n",
      "Epoch 939/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0019 - val_loss: 0.0052\n",
      "Epoch 940/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0042\n",
      "Epoch 941/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0025 - val_loss: 0.0052\n",
      "Epoch 942/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0042\n",
      "Epoch 943/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0034\n",
      "Epoch 944/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0022 - val_loss: 0.0038\n",
      "Epoch 945/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0020 - val_loss: 0.0043\n",
      "Epoch 946/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0018 - val_loss: 0.0039\n",
      "Epoch 947/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0042\n",
      "Epoch 948/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0035\n",
      "Epoch 949/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0018 - val_loss: 0.0039\n",
      "Epoch 950/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0042\n",
      "Epoch 951/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0049\n",
      "Epoch 952/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0038\n",
      "Epoch 953/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0038\n",
      "Epoch 954/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0061\n",
      "Epoch 955/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0025 - val_loss: 0.0043\n",
      "Epoch 956/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0019 - val_loss: 0.0038\n",
      "Epoch 957/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Epoch 958/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0019 - val_loss: 0.0059\n",
      "Epoch 959/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0020 - val_loss: 0.0040\n",
      "Epoch 960/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0049\n",
      "Epoch 961/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0023 - val_loss: 0.0048\n",
      "Epoch 962/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0043\n",
      "Epoch 963/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0027 - val_loss: 0.0059\n",
      "Epoch 964/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0024 - val_loss: 0.0040\n",
      "Epoch 965/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0037\n",
      "Epoch 966/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0053\n",
      "Epoch 967/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0038\n",
      "Epoch 968/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0036\n",
      "Epoch 969/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0066\n",
      "Epoch 970/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 971/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0024 - val_loss: 0.0039\n",
      "Epoch 972/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0047\n",
      "Epoch 973/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0034\n",
      "Epoch 974/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0048\n",
      "Epoch 975/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 976/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0018 - val_loss: 0.0036\n",
      "Epoch 977/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0017 - val_loss: 0.0051\n",
      "Epoch 978/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0019 - val_loss: 0.0036\n",
      "Epoch 979/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0018 - val_loss: 0.0045\n",
      "Epoch 980/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0040\n",
      "Epoch 981/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0018 - val_loss: 0.0038\n",
      "Epoch 982/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 983/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 984/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0035\n",
      "Epoch 985/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0020 - val_loss: 0.0045\n",
      "Epoch 986/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0018 - val_loss: 0.0042\n",
      "Epoch 987/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 988/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0017 - val_loss: 0.0037\n",
      "Epoch 989/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0037\n",
      "Epoch 990/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 991/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0041\n",
      "Epoch 992/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 993/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0040\n",
      "Epoch 994/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0049\n",
      "Epoch 995/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0037\n",
      "Epoch 996/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0055\n",
      "Epoch 997/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0042\n",
      "Epoch 998/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0018 - val_loss: 0.0037\n",
      "Epoch 999/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0019 - val_loss: 0.0048\n",
      "Epoch 1000/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0019 - val_loss: 0.0042\n",
      "0.009654373861849308\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 2.96538621e-01,  3.02006215e-01, -2.16691002e-01,\n",
       "          8.51159155e-01,  2.78918654e-01],\n",
       "        [-3.67945395e-02,  1.12654485e-01,  3.83709610e-01,\n",
       "         -4.79814082e-01, -2.69231826e-01],\n",
       "        [-1.06634343e+00,  3.07257921e-01, -4.36545968e-01,\n",
       "         -9.36583281e-01, -5.88371575e-01],\n",
       "        [-3.27710956e-01,  5.15551984e-01,  2.30621502e-01,\n",
       "         -3.17301452e-01,  6.68447495e-01],\n",
       "        [-1.63873002e-01, -1.00535996e-01,  6.91782981e-02,\n",
       "         -4.50444221e-01,  3.58819246e-01],\n",
       "        [-3.87287706e-01, -1.64963275e-01, -8.99864852e-01,\n",
       "          9.65856850e-01, -1.93739146e-01],\n",
       "        [ 6.40089344e-03,  6.50404513e-01,  3.40497606e-02,\n",
       "         -2.30683327e-01, -3.60969901e-01],\n",
       "        [ 3.90403122e-01,  4.14002448e-01, -6.75896928e-02,\n",
       "          1.62398770e-01, -4.61649567e-01],\n",
       "        [-6.35486245e-01,  4.36819196e-02, -6.68296516e-01,\n",
       "          1.58710063e-01, -2.89600104e-01],\n",
       "        [ 9.85796809e-01,  4.20030832e-01,  8.32027733e-01,\n",
       "          1.92658484e-01, -2.12646164e-02],\n",
       "        [-1.05066836e-01,  7.17070162e-01,  1.09598684e+00,\n",
       "         -7.95825899e-01, -3.33071381e-01],\n",
       "        [ 1.05662847e+00,  3.94488335e-01,  8.78466606e-01,\n",
       "         -4.45486307e-02,  1.13360696e-01],\n",
       "        [ 7.59092927e-01, -1.64303496e-01,  1.25912189e+00,\n",
       "         -4.70223129e-01,  2.76495099e-01],\n",
       "        [ 2.04996780e-01,  3.77190590e-01,  8.66539776e-01,\n",
       "          1.96260428e+00, -1.62629396e-01],\n",
       "        [-9.80353728e-02,  6.67397976e-02, -5.02002947e-02,\n",
       "          1.99802786e-01, -1.88284054e-01],\n",
       "        [ 8.36935520e-01,  6.32882774e-01,  6.81159019e-01,\n",
       "         -6.86478019e-02, -3.74395579e-01],\n",
       "        [-5.19342840e-01,  7.81829059e-02, -9.68992054e-01,\n",
       "          1.48507327e-01, -5.45378566e-01],\n",
       "        [ 2.07564095e-03,  5.45909777e-02,  1.50521445e+00,\n",
       "          2.24130258e-01, -2.93417275e-01],\n",
       "        [-1.11175823e+00,  3.42876732e-01, -2.84614772e-01,\n",
       "         -9.89177465e-01, -4.97647613e-01],\n",
       "        [ 1.01242259e-01,  6.13950908e-01,  1.06233731e-01,\n",
       "          7.83979356e-01, -4.10004467e-01],\n",
       "        [ 2.62757931e-02,  4.91233647e-01,  1.15898445e-01,\n",
       "         -2.53728175e+00,  2.60578282e-02],\n",
       "        [-6.07242227e-01, -1.16258793e-01, -6.98639527e-02,\n",
       "         -1.96892247e-01,  2.59474218e-01]], dtype=float32),\n",
       " array([-0.35972178,  0.2806087 , -0.2524552 , -0.80941194, -0.11703994],\n",
       "       dtype=float32),\n",
       " array([[-0.33660647, -0.05347661,  0.2852184 , -0.24981287,  0.7525614 ,\n",
       "         -0.22780418, -0.23313636, -0.75966126, -0.02507438,  0.2145256 ],\n",
       "        [ 0.10154111,  0.6533189 , -0.15454654, -0.35752237,  0.17560397,\n",
       "         -0.29258052, -0.16801496,  0.2164503 ,  0.38820758, -0.09684373],\n",
       "        [ 0.28841192, -0.020213  ,  0.07436119,  0.57404715,  0.12836446,\n",
       "          0.36792728, -0.3236357 ,  0.32526544,  0.17948367, -0.42648518],\n",
       "        [-0.5218637 ,  0.16212685, -0.31398422,  0.21156202, -0.39035046,\n",
       "          0.14968579, -0.15259607,  0.29358304, -0.0326516 , -0.93591315],\n",
       "        [ 0.5213751 ,  0.2931455 ,  0.09393463, -0.09853753,  0.23006935,\n",
       "          0.0857059 , -0.3147327 ,  0.44725367,  0.08012787,  0.31573334]],\n",
       "       dtype=float32),\n",
       " array([-0.32666796, -0.2647808 ,  0.10441039,  0.11126431,  0.07231437,\n",
       "         0.25106433, -0.2657286 , -0.06330638, -0.33422756, -0.15017506],\n",
       "       dtype=float32),\n",
       " array([[-5.0172657e-03],\n",
       "        [ 2.5624591e-03],\n",
       "        [-2.9181764e-02],\n",
       "        [ 7.7108398e-02],\n",
       "        [-1.4280997e-01],\n",
       "        [ 3.4255356e-02],\n",
       "        [-1.1495710e-04],\n",
       "        [ 7.7592641e-02],\n",
       "        [-4.0298458e-03],\n",
       "        [-6.1970890e-01]], dtype=float32),\n",
       " array([0.21426801], dtype=float32)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_automobile, history_automobile=NN_model_structure_regression_2(X_train_automobile, X_val_automobile, Y_train_automobile, Y_val_automobile, adam2, 32, 1000)\n",
    "model_automobile.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_automobile.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_automobile_structure2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_43 (Dense)             (None, 5)                 115       \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 15)                90        \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 221\n",
      "Trainable params: 221\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 143 samples, validate on 31 samples\n",
      "Epoch 1/1000\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2974 - val_loss: 0.0567\n",
      "Epoch 2/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0796 - val_loss: 0.0362\n",
      "Epoch 3/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0366 - val_loss: 0.0201\n",
      "Epoch 4/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0353 - val_loss: 0.0144\n",
      "Epoch 5/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0265 - val_loss: 0.0115\n",
      "Epoch 6/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0248 - val_loss: 0.0165\n",
      "Epoch 7/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0258 - val_loss: 0.0063\n",
      "Epoch 8/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0176 - val_loss: 0.0045\n",
      "Epoch 9/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0160 - val_loss: 0.0059\n",
      "Epoch 10/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0160 - val_loss: 0.0037\n",
      "Epoch 11/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0142 - val_loss: 0.0050\n",
      "Epoch 12/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0125 - val_loss: 0.0029\n",
      "Epoch 13/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0109 - val_loss: 0.0029\n",
      "Epoch 14/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0103 - val_loss: 0.0033\n",
      "Epoch 15/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0095 - val_loss: 0.0031\n",
      "Epoch 16/1000\n",
      "143/143 [==============================] - 0s 174us/step - loss: 0.0089 - val_loss: 0.0029\n",
      "Epoch 17/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0087 - val_loss: 0.0035\n",
      "Epoch 18/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0084 - val_loss: 0.0037\n",
      "Epoch 19/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0080 - val_loss: 0.0035\n",
      "Epoch 20/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0086 - val_loss: 0.0043\n",
      "Epoch 21/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0093 - val_loss: 0.0044\n",
      "Epoch 22/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0119 - val_loss: 0.0035\n",
      "Epoch 23/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0094 - val_loss: 0.0123\n",
      "Epoch 24/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0100 - val_loss: 0.0078\n",
      "Epoch 25/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0097 - val_loss: 0.0035\n",
      "Epoch 26/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0074 - val_loss: 0.0034\n",
      "Epoch 27/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0072 - val_loss: 0.0039\n",
      "Epoch 28/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0071 - val_loss: 0.0045\n",
      "Epoch 29/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0074 - val_loss: 0.0040\n",
      "Epoch 30/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0070 - val_loss: 0.0066\n",
      "Epoch 31/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0077 - val_loss: 0.0045\n",
      "Epoch 32/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0078 - val_loss: 0.0038\n",
      "Epoch 33/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0075 - val_loss: 0.0064\n",
      "Epoch 34/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0077 - val_loss: 0.0036\n",
      "Epoch 35/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0068 - val_loss: 0.0039\n",
      "Epoch 36/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0067 - val_loss: 0.0041\n",
      "Epoch 37/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0072 - val_loss: 0.0074\n",
      "Epoch 38/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0092 - val_loss: 0.0069\n",
      "Epoch 39/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0068 - val_loss: 0.0049\n",
      "Epoch 40/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0070 - val_loss: 0.0042\n",
      "Epoch 41/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0068 - val_loss: 0.0065\n",
      "Epoch 42/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0068 - val_loss: 0.0048\n",
      "Epoch 43/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0063 - val_loss: 0.0085\n",
      "Epoch 44/1000\n",
      "143/143 [==============================] - 0s 174us/step - loss: 0.0077 - val_loss: 0.0058\n",
      "Epoch 45/1000\n",
      "143/143 [==============================] - 0s 202us/step - loss: 0.0068 - val_loss: 0.0060\n",
      "Epoch 46/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0075 - val_loss: 0.0052\n",
      "Epoch 47/1000\n",
      "143/143 [==============================] - 0s 181us/step - loss: 0.0068 - val_loss: 0.0049\n",
      "Epoch 48/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0068 - val_loss: 0.0051\n",
      "Epoch 49/1000\n",
      "143/143 [==============================] - 0s 167us/step - loss: 0.0058 - val_loss: 0.0041\n",
      "Epoch 50/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0065 - val_loss: 0.0067\n",
      "Epoch 51/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0065 - val_loss: 0.0052\n",
      "Epoch 52/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0091 - val_loss: 0.0039\n",
      "Epoch 53/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0071 - val_loss: 0.0052\n",
      "Epoch 54/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0061 - val_loss: 0.0038\n",
      "Epoch 55/1000\n",
      "143/143 [==============================] - 0s 151us/step - loss: 0.0055 - val_loss: 0.0076\n",
      "Epoch 56/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0078 - val_loss: 0.0049\n",
      "Epoch 57/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0077 - val_loss: 0.0035\n",
      "Epoch 58/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0068 - val_loss: 0.0059\n",
      "Epoch 59/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0070 - val_loss: 0.0032\n",
      "Epoch 60/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0065 - val_loss: 0.0043\n",
      "Epoch 61/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0062 - val_loss: 0.0044\n",
      "Epoch 62/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0057 - val_loss: 0.0037\n",
      "Epoch 63/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0058 - val_loss: 0.0037\n",
      "Epoch 64/1000\n",
      "143/143 [==============================] - 0s 136us/step - loss: 0.0062 - val_loss: 0.0063\n",
      "Epoch 65/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0066 - val_loss: 0.0043\n",
      "Epoch 66/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0062 - val_loss: 0.0059\n",
      "Epoch 67/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0071 - val_loss: 0.0041\n",
      "Epoch 68/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0082 - val_loss: 0.0051\n",
      "Epoch 69/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 139us/step - loss: 0.0067 - val_loss: 0.0058\n",
      "Epoch 70/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0056 - val_loss: 0.0038\n",
      "Epoch 71/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0057 - val_loss: 0.0055\n",
      "Epoch 72/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0052 - val_loss: 0.0036\n",
      "Epoch 73/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0062 - val_loss: 0.0050\n",
      "Epoch 74/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0037\n",
      "Epoch 75/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0051 - val_loss: 0.0049\n",
      "Epoch 76/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0052 - val_loss: 0.0035\n",
      "Epoch 77/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0052 - val_loss: 0.0041\n",
      "Epoch 78/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0051 - val_loss: 0.0040\n",
      "Epoch 79/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0053 - val_loss: 0.0044\n",
      "Epoch 80/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0052 - val_loss: 0.0041\n",
      "Epoch 81/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0060 - val_loss: 0.0040\n",
      "Epoch 82/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0061 - val_loss: 0.0058\n",
      "Epoch 83/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0056 - val_loss: 0.0034\n",
      "Epoch 84/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0052 - val_loss: 0.0055\n",
      "Epoch 85/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0052 - val_loss: 0.0044\n",
      "Epoch 86/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0053 - val_loss: 0.0068\n",
      "Epoch 87/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0057 - val_loss: 0.0043\n",
      "Epoch 88/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0062 - val_loss: 0.0070\n",
      "Epoch 89/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0053 - val_loss: 0.0041\n",
      "Epoch 90/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0062 - val_loss: 0.0050\n",
      "Epoch 91/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0035\n",
      "Epoch 92/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0056\n",
      "Epoch 93/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0040\n",
      "Epoch 94/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0052 - val_loss: 0.0066\n",
      "Epoch 95/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0053 - val_loss: 0.0041\n",
      "Epoch 96/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 97/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0057 - val_loss: 0.0044\n",
      "Epoch 98/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0059 - val_loss: 0.0036\n",
      "Epoch 99/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0061 - val_loss: 0.0048\n",
      "Epoch 100/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0054 - val_loss: 0.0035\n",
      "Epoch 101/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0047 - val_loss: 0.0045\n",
      "Epoch 102/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0051 - val_loss: 0.0037\n",
      "Epoch 103/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0053 - val_loss: 0.0037\n",
      "Epoch 104/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0049 - val_loss: 0.0044\n",
      "Epoch 105/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0050 - val_loss: 0.0037\n",
      "Epoch 106/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0050 - val_loss: 0.0045\n",
      "Epoch 107/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 108/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0046 - val_loss: 0.0042\n",
      "Epoch 109/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0037\n",
      "Epoch 110/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0039\n",
      "Epoch 111/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0046 - val_loss: 0.0044\n",
      "Epoch 112/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0036\n",
      "Epoch 113/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0049 - val_loss: 0.0065\n",
      "Epoch 114/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0050 - val_loss: 0.0042\n",
      "Epoch 115/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0055 - val_loss: 0.0080\n",
      "Epoch 116/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0059 - val_loss: 0.0044\n",
      "Epoch 117/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0063 - val_loss: 0.0068\n",
      "Epoch 118/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0037\n",
      "Epoch 119/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0044 - val_loss: 0.0058\n",
      "Epoch 120/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0039\n",
      "Epoch 121/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0049 - val_loss: 0.0045\n",
      "Epoch 122/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0044 - val_loss: 0.0041\n",
      "Epoch 123/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0046 - val_loss: 0.0042\n",
      "Epoch 124/1000\n",
      "143/143 [==============================] - 0s 128us/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 125/1000\n",
      "143/143 [==============================] - 0s 138us/step - loss: 0.0046 - val_loss: 0.0038\n",
      "Epoch 126/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0047 - val_loss: 0.0046\n",
      "Epoch 127/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0045 - val_loss: 0.0050\n",
      "Epoch 128/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0045 - val_loss: 0.0042\n",
      "Epoch 129/1000\n",
      "143/143 [==============================] - 0s 151us/step - loss: 0.0043 - val_loss: 0.0045\n",
      "Epoch 130/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0044 - val_loss: 0.0042\n",
      "Epoch 131/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 132/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0041\n",
      "Epoch 133/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0042\n",
      "Epoch 134/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0048 - val_loss: 0.0063\n",
      "Epoch 135/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0043\n",
      "Epoch 136/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0060\n",
      "Epoch 137/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0037\n",
      "Epoch 138/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0044 - val_loss: 0.0059\n",
      "Epoch 139/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0039\n",
      "Epoch 140/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0045\n",
      "Epoch 141/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0049\n",
      "Epoch 142/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0042 - val_loss: 0.0044\n",
      "Epoch 143/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0041 - val_loss: 0.0044\n",
      "Epoch 144/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0040 - val_loss: 0.0044\n",
      "Epoch 145/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 146/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0044\n",
      "Epoch 147/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0041 - val_loss: 0.0061\n",
      "Epoch 148/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0042 - val_loss: 0.0044\n",
      "Epoch 149/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 150/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 151/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0040 - val_loss: 0.0051\n",
      "Epoch 152/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 153/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0057\n",
      "Epoch 154/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0044\n",
      "Epoch 155/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0049\n",
      "Epoch 156/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0050\n",
      "Epoch 157/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0058\n",
      "Epoch 158/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 159/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0053\n",
      "Epoch 160/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0045 - val_loss: 0.0068\n",
      "Epoch 161/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 162/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0063\n",
      "Epoch 163/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0041 - val_loss: 0.0048\n",
      "Epoch 164/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0041 - val_loss: 0.0051\n",
      "Epoch 165/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0051\n",
      "Epoch 166/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0045\n",
      "Epoch 167/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0075\n",
      "Epoch 168/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 169/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0038 - val_loss: 0.0070\n",
      "Epoch 170/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 171/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0038 - val_loss: 0.0067\n",
      "Epoch 172/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0037 - val_loss: 0.0043\n",
      "Epoch 173/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0067\n",
      "Epoch 174/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0038 - val_loss: 0.0047\n",
      "Epoch 175/1000\n",
      "143/143 [==============================] - 0s 293us/step - loss: 0.0040 - val_loss: 0.0059\n",
      "Epoch 176/1000\n",
      "143/143 [==============================] - 0s 174us/step - loss: 0.0036 - val_loss: 0.0051\n",
      "Epoch 177/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0036 - val_loss: 0.0057\n",
      "Epoch 178/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0040 - val_loss: 0.0048\n",
      "Epoch 179/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0036 - val_loss: 0.0055\n",
      "Epoch 180/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0036 - val_loss: 0.0070\n",
      "Epoch 181/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0038 - val_loss: 0.0048\n",
      "Epoch 182/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0040 - val_loss: 0.0048\n",
      "Epoch 183/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0039 - val_loss: 0.0066\n",
      "Epoch 184/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0036 - val_loss: 0.0056\n",
      "Epoch 185/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0035 - val_loss: 0.0053\n",
      "Epoch 186/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0034 - val_loss: 0.0046\n",
      "Epoch 187/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0036 - val_loss: 0.0067\n",
      "Epoch 188/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0038 - val_loss: 0.0052\n",
      "Epoch 189/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0049 - val_loss: 0.0057\n",
      "Epoch 190/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.002 - 0s 126us/step - loss: 0.0040 - val_loss: 0.0063\n",
      "Epoch 191/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0039 - val_loss: 0.0048\n",
      "Epoch 192/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0075\n",
      "Epoch 193/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0039 - val_loss: 0.0061\n",
      "Epoch 194/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 195/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0064\n",
      "Epoch 196/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0034 - val_loss: 0.0047\n",
      "Epoch 197/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0059\n",
      "Epoch 198/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0065\n",
      "Epoch 199/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 200/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0063\n",
      "Epoch 201/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0051\n",
      "Epoch 202/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0034 - val_loss: 0.0095\n",
      "Epoch 203/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0042 - val_loss: 0.0040\n",
      "Epoch 204/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0062\n",
      "Epoch 205/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0055\n",
      "Epoch 206/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0082\n",
      "Epoch 207/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 208/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0042 - val_loss: 0.0057\n",
      "Epoch 209/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0038 - val_loss: 0.0066\n",
      "Epoch 210/1000\n",
      "143/143 [==============================] - 0s 167us/step - loss: 0.0035 - val_loss: 0.0049\n",
      "Epoch 211/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0062\n",
      "Epoch 212/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0052\n",
      "Epoch 213/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0056\n",
      "Epoch 214/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0033 - val_loss: 0.0072\n",
      "Epoch 215/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0033 - val_loss: 0.0048\n",
      "Epoch 216/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0054\n",
      "Epoch 217/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0083\n",
      "Epoch 218/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0039 - val_loss: 0.0058\n",
      "Epoch 219/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0055 - val_loss: 0.0108\n",
      "Epoch 220/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 221/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0064\n",
      "Epoch 222/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0031 - val_loss: 0.0049\n",
      "Epoch 223/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0050\n",
      "Epoch 224/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0031 - val_loss: 0.0054\n",
      "Epoch 225/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0031 - val_loss: 0.0045\n",
      "Epoch 226/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0032 - val_loss: 0.0063\n",
      "Epoch 227/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0033 - val_loss: 0.0047\n",
      "Epoch 228/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0031 - val_loss: 0.0046\n",
      "Epoch 229/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0032 - val_loss: 0.0061\n",
      "Epoch 230/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0055\n",
      "Epoch 231/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0029 - val_loss: 0.0050\n",
      "Epoch 232/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0029 - val_loss: 0.0057\n",
      "Epoch 233/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0029 - val_loss: 0.0050\n",
      "Epoch 234/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0054\n",
      "Epoch 235/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0064\n",
      "Epoch 236/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0049\n",
      "Epoch 237/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0077\n",
      "Epoch 238/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0061\n",
      "Epoch 239/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0031 - val_loss: 0.0052\n",
      "Epoch 240/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0031 - val_loss: 0.0059\n",
      "Epoch 241/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 242/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0053\n",
      "Epoch 243/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0031 - val_loss: 0.0074\n",
      "Epoch 244/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0049\n",
      "Epoch 245/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0045\n",
      "Epoch 246/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0030 - val_loss: 0.0056\n",
      "Epoch 247/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0029 - val_loss: 0.0076\n",
      "Epoch 248/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 249/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0054\n",
      "Epoch 250/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0073\n",
      "Epoch 251/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0058\n",
      "Epoch 252/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0051\n",
      "Epoch 253/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0061\n",
      "Epoch 254/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0049\n",
      "Epoch 255/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0074\n",
      "Epoch 256/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0031 - val_loss: 0.0068\n",
      "Epoch 257/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0028 - val_loss: 0.0055\n",
      "Epoch 258/1000\n",
      "143/143 [==============================] - 0s 131us/step - loss: 0.0027 - val_loss: 0.0050\n",
      "Epoch 259/1000\n",
      "143/143 [==============================] - 0s 134us/step - loss: 0.0029 - val_loss: 0.0076\n",
      "Epoch 260/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0058\n",
      "Epoch 261/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0046\n",
      "Epoch 262/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0030 - val_loss: 0.0075\n",
      "Epoch 263/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0028 - val_loss: 0.0050\n",
      "Epoch 264/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0028 - val_loss: 0.0057\n",
      "Epoch 265/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0056\n",
      "Epoch 266/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0048\n",
      "Epoch 267/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0073\n",
      "Epoch 268/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0051\n",
      "Epoch 269/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0059\n",
      "Epoch 270/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0066\n",
      "Epoch 271/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0052\n",
      "Epoch 272/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0067\n",
      "Epoch 273/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0054\n",
      "Epoch 274/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0056\n",
      "Epoch 275/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0056\n",
      "Epoch 276/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0062\n",
      "Epoch 277/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0060\n",
      "Epoch 278/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0068\n",
      "Epoch 279/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0060\n",
      "Epoch 280/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0050\n",
      "Epoch 281/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0075\n",
      "Epoch 282/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0059\n",
      "Epoch 283/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0053\n",
      "Epoch 284/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0026 - val_loss: 0.0064\n",
      "Epoch 285/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0057\n",
      "Epoch 286/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0065\n",
      "Epoch 287/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0053\n",
      "Epoch 288/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0029 - val_loss: 0.0072\n",
      "Epoch 289/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0027 - val_loss: 0.0059\n",
      "Epoch 290/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0061\n",
      "Epoch 291/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0075\n",
      "Epoch 292/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0029 - val_loss: 0.0054\n",
      "Epoch 293/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0052\n",
      "Epoch 294/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0078\n",
      "Epoch 295/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0025 - val_loss: 0.0050\n",
      "Epoch 296/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0031 - val_loss: 0.0057\n",
      "Epoch 297/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0065\n",
      "Epoch 298/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0028 - val_loss: 0.0052\n",
      "Epoch 299/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0026 - val_loss: 0.0070\n",
      "Epoch 300/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0024 - val_loss: 0.0054\n",
      "Epoch 301/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0056\n",
      "Epoch 302/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0066\n",
      "Epoch 303/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0068\n",
      "Epoch 304/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0052\n",
      "Epoch 305/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0059\n",
      "Epoch 306/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0026 - val_loss: 0.0064\n",
      "Epoch 307/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0025 - val_loss: 0.0058\n",
      "Epoch 308/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0057\n",
      "Epoch 309/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0057\n",
      "Epoch 310/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0072\n",
      "Epoch 311/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0052\n",
      "Epoch 312/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0053\n",
      "Epoch 313/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0081\n",
      "Epoch 314/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0026 - val_loss: 0.0056\n",
      "Epoch 315/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0033 - val_loss: 0.0060\n",
      "Epoch 316/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0027 - val_loss: 0.0065\n",
      "Epoch 317/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0028 - val_loss: 0.0058\n",
      "Epoch 318/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0028 - val_loss: 0.0082\n",
      "Epoch 319/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0050\n",
      "Epoch 320/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0044\n",
      "Epoch 321/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0071\n",
      "Epoch 322/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0026 - val_loss: 0.0046\n",
      "Epoch 323/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0048\n",
      "Epoch 324/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0025 - val_loss: 0.0060\n",
      "Epoch 325/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0023 - val_loss: 0.0049\n",
      "Epoch 326/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0055\n",
      "Epoch 327/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0025 - val_loss: 0.0063\n",
      "Epoch 328/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0051\n",
      "Epoch 329/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0053\n",
      "Epoch 330/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0024 - val_loss: 0.0062\n",
      "Epoch 331/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0066\n",
      "Epoch 332/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0048\n",
      "Epoch 333/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0088\n",
      "Epoch 334/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0058\n",
      "Epoch 335/1000\n",
      "143/143 [==============================] - 0s 129us/step - loss: 0.0027 - val_loss: 0.0098\n",
      "Epoch 336/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0053\n",
      "Epoch 337/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0047\n",
      "Epoch 338/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0073\n",
      "Epoch 339/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0053\n",
      "Epoch 340/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0058\n",
      "Epoch 341/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0050\n",
      "Epoch 342/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0024 - val_loss: 0.0052\n",
      "Epoch 343/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0023 - val_loss: 0.0063\n",
      "Epoch 344/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0029 - val_loss: 0.0041\n",
      "Epoch 345/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0028 - val_loss: 0.0051\n",
      "Epoch 346/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0024 - val_loss: 0.0064\n",
      "Epoch 347/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0049\n",
      "Epoch 348/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0065\n",
      "Epoch 349/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0023 - val_loss: 0.0058\n",
      "Epoch 350/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0022 - val_loss: 0.0062\n",
      "Epoch 351/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0024 - val_loss: 0.0060\n",
      "Epoch 352/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0022 - val_loss: 0.0055\n",
      "Epoch 353/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0069\n",
      "Epoch 354/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0024 - val_loss: 0.0052\n",
      "Epoch 355/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0055\n",
      "Epoch 356/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0026 - val_loss: 0.0080\n",
      "Epoch 357/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0025 - val_loss: 0.0049\n",
      "Epoch 358/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0026 - val_loss: 0.0062\n",
      "Epoch 359/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0024 - val_loss: 0.0071\n",
      "Epoch 360/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0050\n",
      "Epoch 361/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0066\n",
      "Epoch 362/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0052\n",
      "Epoch 363/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0049\n",
      "Epoch 364/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0069\n",
      "Epoch 365/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0053\n",
      "Epoch 366/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0052\n",
      "Epoch 367/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0024 - val_loss: 0.0065\n",
      "Epoch 368/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0056\n",
      "Epoch 369/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0052\n",
      "Epoch 370/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0022 - val_loss: 0.0065\n",
      "Epoch 371/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0026 - val_loss: 0.0053\n",
      "Epoch 372/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0053\n",
      "Epoch 373/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0024 - val_loss: 0.0067\n",
      "Epoch 374/1000\n",
      "143/143 [==============================] - 0s 167us/step - loss: 0.0023 - val_loss: 0.0057\n",
      "Epoch 375/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0058\n",
      "Epoch 376/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0024 - val_loss: 0.0066\n",
      "Epoch 377/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 125us/step - loss: 0.0022 - val_loss: 0.0061\n",
      "Epoch 378/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0021 - val_loss: 0.0058\n",
      "Epoch 379/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0060\n",
      "Epoch 380/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0055\n",
      "Epoch 381/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0021 - val_loss: 0.0057\n",
      "Epoch 382/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0077\n",
      "Epoch 383/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0054\n",
      "Epoch 384/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0023 - val_loss: 0.0053\n",
      "Epoch 385/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0021 - val_loss: 0.0056\n",
      "Epoch 386/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0022 - val_loss: 0.0069\n",
      "Epoch 387/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0066\n",
      "Epoch 388/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0053\n",
      "Epoch 389/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0026 - val_loss: 0.0077\n",
      "Epoch 390/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0069\n",
      "Epoch 391/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0060\n",
      "Epoch 392/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0087\n",
      "Epoch 393/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0049\n",
      "Epoch 394/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0057\n",
      "Epoch 395/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0032 - val_loss: 0.0062\n",
      "Epoch 396/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0045\n",
      "Epoch 397/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0066\n",
      "Epoch 398/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0029 - val_loss: 0.0048\n",
      "Epoch 399/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0044\n",
      "Epoch 400/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0063\n",
      "Epoch 401/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0051\n",
      "Epoch 402/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0052\n",
      "Epoch 403/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0058\n",
      "Epoch 404/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0050\n",
      "Epoch 405/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0024 - val_loss: 0.0078\n",
      "Epoch 406/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0032 - val_loss: 0.0056\n",
      "Epoch 407/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0025 - val_loss: 0.0058\n",
      "Epoch 408/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0056\n",
      "Epoch 409/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0052\n",
      "Epoch 410/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0072\n",
      "Epoch 411/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0055\n",
      "Epoch 412/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0023 - val_loss: 0.0049\n",
      "Epoch 413/1000\n",
      "143/143 [==============================] - 0s 158us/step - loss: 0.0026 - val_loss: 0.0082\n",
      "Epoch 414/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0052\n",
      "Epoch 415/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0062\n",
      "Epoch 416/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0054\n",
      "Epoch 417/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0059\n",
      "Epoch 418/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0059\n",
      "Epoch 419/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0022 - val_loss: 0.0047\n",
      "Epoch 420/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0074\n",
      "Epoch 421/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0056\n",
      "Epoch 422/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0056\n",
      "Epoch 423/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0055\n",
      "Epoch 424/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0061\n",
      "Epoch 425/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0061\n",
      "Epoch 426/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0020 - val_loss: 0.0055\n",
      "Epoch 427/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0022 - val_loss: 0.0067\n",
      "Epoch 428/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0055\n",
      "Epoch 429/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0057\n",
      "Epoch 430/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 0.0061\n",
      "Epoch 431/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0054\n",
      "Epoch 432/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0067\n",
      "Epoch 433/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0051\n",
      "Epoch 434/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0061\n",
      "Epoch 435/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0057\n",
      "Epoch 436/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0052\n",
      "Epoch 437/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0056\n",
      "Epoch 438/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0070\n",
      "Epoch 439/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0059\n",
      "Epoch 440/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0055\n",
      "Epoch 441/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0069\n",
      "Epoch 442/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0055\n",
      "Epoch 443/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0058\n",
      "Epoch 444/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0061\n",
      "Epoch 445/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0056\n",
      "Epoch 446/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0055\n",
      "Epoch 447/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0058\n",
      "Epoch 448/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0060\n",
      "Epoch 449/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0054\n",
      "Epoch 450/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0054\n",
      "Epoch 451/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0068\n",
      "Epoch 452/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0058\n",
      "Epoch 453/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0063\n",
      "Epoch 454/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0062\n",
      "Epoch 455/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0050\n",
      "Epoch 456/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0064\n",
      "Epoch 457/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0060\n",
      "Epoch 458/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0054\n",
      "Epoch 459/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0022 - val_loss: 0.0053\n",
      "Epoch 460/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 0.0060\n",
      "Epoch 461/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0058\n",
      "Epoch 462/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 0.0055\n",
      "Epoch 463/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0057\n",
      "Epoch 464/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0062\n",
      "Epoch 465/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0021 - val_loss: 0.0057\n",
      "Epoch 466/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0052\n",
      "Epoch 467/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0022 - val_loss: 0.0056\n",
      "Epoch 468/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0060\n",
      "Epoch 469/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.002 - 0s 111us/step - loss: 0.0020 - val_loss: 0.0059\n",
      "Epoch 470/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0058\n",
      "Epoch 471/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0022 - val_loss: 0.0057\n",
      "Epoch 472/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0055\n",
      "Epoch 473/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0020 - val_loss: 0.0071\n",
      "Epoch 474/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0052\n",
      "Epoch 475/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0022 - val_loss: 0.0067\n",
      "Epoch 476/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0023 - val_loss: 0.0057\n",
      "Epoch 477/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0020 - val_loss: 0.0069\n",
      "Epoch 478/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0027 - val_loss: 0.0054\n",
      "Epoch 479/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0025 - val_loss: 0.0057\n",
      "Epoch 480/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0070\n",
      "Epoch 481/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0044\n",
      "Epoch 482/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0053\n",
      "Epoch 483/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0020 - val_loss: 0.0055\n",
      "Epoch 484/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 0.0057\n",
      "Epoch 485/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0019 - val_loss: 0.0053\n",
      "Epoch 486/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0056\n",
      "Epoch 487/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0055\n",
      "Epoch 488/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0057\n",
      "Epoch 489/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0053\n",
      "Epoch 490/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0073\n",
      "Epoch 491/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0061\n",
      "Epoch 492/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0047\n",
      "Epoch 493/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0020 - val_loss: 0.0049\n",
      "Epoch 494/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0050\n",
      "Epoch 495/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0054\n",
      "Epoch 496/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0020 - val_loss: 0.0057\n",
      "Epoch 497/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0048\n",
      "Epoch 498/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0020 - val_loss: 0.0055\n",
      "Epoch 499/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0053\n",
      "Epoch 500/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0019 - val_loss: 0.0051\n",
      "Epoch 501/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0054\n",
      "Epoch 502/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0055\n",
      "Epoch 503/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0055\n",
      "Epoch 504/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0022 - val_loss: 0.0048\n",
      "Epoch 505/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0082\n",
      "Epoch 506/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0026 - val_loss: 0.0058\n",
      "Epoch 507/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0047\n",
      "Epoch 508/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0072\n",
      "Epoch 509/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0050\n",
      "Epoch 510/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0056\n",
      "Epoch 511/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0079\n",
      "Epoch 512/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0051\n",
      "Epoch 513/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0060\n",
      "Epoch 514/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0061\n",
      "Epoch 515/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0053\n",
      "Epoch 516/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0019 - val_loss: 0.0055\n",
      "Epoch 517/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0063\n",
      "Epoch 518/1000\n",
      "143/143 [==============================] - 0s 314us/step - loss: 0.0019 - val_loss: 0.0055\n",
      "Epoch 519/1000\n",
      "143/143 [==============================] - 0s 174us/step - loss: 0.0020 - val_loss: 0.0054\n",
      "Epoch 520/1000\n",
      "143/143 [==============================] - 0s 167us/step - loss: 0.0019 - val_loss: 0.0068\n",
      "Epoch 521/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0050\n",
      "Epoch 522/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0026 - val_loss: 0.0054\n",
      "Epoch 523/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0057\n",
      "Epoch 524/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0062\n",
      "Epoch 525/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0056\n",
      "Epoch 526/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0020 - val_loss: 0.0052\n",
      "Epoch 527/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0075\n",
      "Epoch 528/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0047\n",
      "Epoch 529/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0025 - val_loss: 0.0051\n",
      "Epoch 530/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.001 - 0s 126us/step - loss: 0.0019 - val_loss: 0.0062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 531/1000\n",
      "143/143 [==============================] - 0s 136us/step - loss: 0.0018 - val_loss: 0.0054\n",
      "Epoch 532/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0023 - val_loss: 0.0065\n",
      "Epoch 533/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0021 - val_loss: 0.0060\n",
      "Epoch 534/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0055\n",
      "Epoch 535/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0020 - val_loss: 0.0059\n",
      "Epoch 536/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0059\n",
      "Epoch 537/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0021 - val_loss: 0.0057\n",
      "Epoch 538/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0064\n",
      "Epoch 539/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0050\n",
      "Epoch 540/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0051\n",
      "Epoch 541/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0067\n",
      "Epoch 542/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0026 - val_loss: 0.0044\n",
      "Epoch 543/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0056\n",
      "Epoch 544/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0057\n",
      "Epoch 545/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0018 - val_loss: 0.0056\n",
      "Epoch 546/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0055\n",
      "Epoch 547/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0052\n",
      "Epoch 548/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0058\n",
      "Epoch 549/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0019 - val_loss: 0.0055\n",
      "Epoch 550/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0057\n",
      "Epoch 551/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0055\n",
      "Epoch 552/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0025 - val_loss: 0.0064\n",
      "Epoch 553/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0059\n",
      "Epoch 554/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0025 - val_loss: 0.0041\n",
      "Epoch 555/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0056\n",
      "Epoch 556/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0050\n",
      "Epoch 557/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 558/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0056\n",
      "Epoch 559/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0056\n",
      "Epoch 560/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0059\n",
      "Epoch 561/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0018 - val_loss: 0.0053\n",
      "Epoch 562/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0055\n",
      "Epoch 563/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0018 - val_loss: 0.0055\n",
      "Epoch 564/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0053\n",
      "Epoch 565/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0058\n",
      "Epoch 566/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0056\n",
      "Epoch 567/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0019 - val_loss: 0.0063\n",
      "Epoch 568/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 0.0048\n",
      "Epoch 569/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0054\n",
      "Epoch 570/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0057\n",
      "Epoch 571/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0058\n",
      "Epoch 572/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0044\n",
      "Epoch 573/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0052\n",
      "Epoch 574/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0020 - val_loss: 0.0068\n",
      "Epoch 575/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0048\n",
      "Epoch 576/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0051\n",
      "Epoch 577/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0052\n",
      "Epoch 578/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0020 - val_loss: 0.0054\n",
      "Epoch 579/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0060\n",
      "Epoch 580/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0054\n",
      "Epoch 581/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0018 - val_loss: 0.0059\n",
      "Epoch 582/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0017 - val_loss: 0.0049\n",
      "Epoch 583/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0019 - val_loss: 0.0048\n",
      "Epoch 584/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0020 - val_loss: 0.0052\n",
      "Epoch 585/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0020 - val_loss: 0.0056\n",
      "Epoch 586/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0050\n",
      "Epoch 587/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0018 - val_loss: 0.0051\n",
      "Epoch 588/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0018 - val_loss: 0.0064\n",
      "Epoch 589/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0018 - val_loss: 0.0052\n",
      "Epoch 590/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0056\n",
      "Epoch 591/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0017 - val_loss: 0.0056\n",
      "Epoch 592/1000\n",
      "143/143 [==============================] - 0s 129us/step - loss: 0.0019 - val_loss: 0.0052\n",
      "Epoch 593/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0047\n",
      "Epoch 594/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0021 - val_loss: 0.0091\n",
      "Epoch 595/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0030 - val_loss: 0.0053\n",
      "Epoch 596/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0022 - val_loss: 0.0041\n",
      "Epoch 597/1000\n",
      "143/143 [==============================] - 0s 140us/step - loss: 0.0022 - val_loss: 0.0066\n",
      "Epoch 598/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0024 - val_loss: 0.0054\n",
      "Epoch 599/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0019 - val_loss: 0.0050\n",
      "Epoch 600/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0047\n",
      "Epoch 601/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0018 - val_loss: 0.0058\n",
      "Epoch 602/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0020 - val_loss: 0.0054\n",
      "Epoch 603/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0022 - val_loss: 0.0050\n",
      "Epoch 604/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0025 - val_loss: 0.0063\n",
      "Epoch 605/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0051\n",
      "Epoch 606/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0053\n",
      "Epoch 607/1000\n",
      "143/143 [==============================] - 0s 131us/step - loss: 0.0026 - val_loss: 0.0053\n",
      "Epoch 608/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0021 - val_loss: 0.0056\n",
      "Epoch 609/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0028 - val_loss: 0.0069\n",
      "Epoch 610/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 611/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0052\n",
      "Epoch 612/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0018 - val_loss: 0.0048\n",
      "Epoch 613/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0018 - val_loss: 0.0048\n",
      "Epoch 614/1000\n",
      "143/143 [==============================] - 0s 100us/step - loss: 0.0018 - val_loss: 0.0067\n",
      "Epoch 615/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0052\n",
      "Epoch 616/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0061\n",
      "Epoch 617/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0051\n",
      "Epoch 618/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0021 - val_loss: 0.0046\n",
      "Epoch 619/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0062\n",
      "Epoch 620/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0049\n",
      "Epoch 621/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0017 - val_loss: 0.0059\n",
      "Epoch 622/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0018 - val_loss: 0.0050\n",
      "Epoch 623/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0017 - val_loss: 0.0056\n",
      "Epoch 624/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0019 - val_loss: 0.0060\n",
      "Epoch 625/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0024 - val_loss: 0.0044\n",
      "Epoch 626/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0018 - val_loss: 0.0055\n",
      "Epoch 627/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 0.0054\n",
      "Epoch 628/1000\n",
      "143/143 [==============================] - 0s 136us/step - loss: 0.0018 - val_loss: 0.0051\n",
      "Epoch 629/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0018 - val_loss: 0.0055\n",
      "Epoch 630/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0016 - val_loss: 0.0053\n",
      "Epoch 631/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0018 - val_loss: 0.0057\n",
      "Epoch 632/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0056\n",
      "Epoch 633/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0055\n",
      "Epoch 634/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0060\n",
      "Epoch 635/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0019 - val_loss: 0.0049\n",
      "Epoch 636/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0017 - val_loss: 0.0058\n",
      "Epoch 637/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0017 - val_loss: 0.0055\n",
      "Epoch 638/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0061\n",
      "Epoch 639/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0020 - val_loss: 0.0057\n",
      "Epoch 640/1000\n",
      "143/143 [==============================] - 0s 148us/step - loss: 0.0018 - val_loss: 0.0056\n",
      "Epoch 641/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0058\n",
      "Epoch 642/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0052\n",
      "Epoch 643/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0020 - val_loss: 0.0058\n",
      "Epoch 644/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0023 - val_loss: 0.0067\n",
      "Epoch 645/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0020 - val_loss: 0.0048\n",
      "Epoch 646/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0020 - val_loss: 0.0054\n",
      "Epoch 647/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0057\n",
      "Epoch 648/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0054\n",
      "Epoch 649/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0054\n",
      "Epoch 650/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0059\n",
      "Epoch 651/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0018 - val_loss: 0.0052\n",
      "Epoch 652/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0050\n",
      "Epoch 653/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0017 - val_loss: 0.0050\n",
      "Epoch 654/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0060\n",
      "Epoch 655/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0017 - val_loss: 0.0053\n",
      "Epoch 656/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0050\n",
      "Epoch 657/1000\n",
      "143/143 [==============================] - 0s 140us/step - loss: 0.0019 - val_loss: 0.0076\n",
      "Epoch 658/1000\n",
      "143/143 [==============================] - 0s 188us/step - loss: 0.0025 - val_loss: 0.0054\n",
      "Epoch 659/1000\n",
      "143/143 [==============================] - 0s 181us/step - loss: 0.0022 - val_loss: 0.0040\n",
      "Epoch 660/1000\n",
      "143/143 [==============================] - 0s 174us/step - loss: 0.0024 - val_loss: 0.0066\n",
      "Epoch 661/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0024 - val_loss: 0.0053\n",
      "Epoch 662/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0020 - val_loss: 0.0043\n",
      "Epoch 663/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0018 - val_loss: 0.0060\n",
      "Epoch 664/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0018 - val_loss: 0.0057\n",
      "Epoch 665/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0049\n",
      "Epoch 666/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0016 - val_loss: 0.0051\n",
      "Epoch 667/1000\n",
      "143/143 [==============================] - 0s 202us/step - loss: 0.0017 - val_loss: 0.0054\n",
      "Epoch 668/1000\n",
      "143/143 [==============================] - 0s 188us/step - loss: 0.0017 - val_loss: 0.0055\n",
      "Epoch 669/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0016 - val_loss: 0.0055\n",
      "Epoch 670/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0016 - val_loss: 0.0052\n",
      "Epoch 671/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0016 - val_loss: 0.0054\n",
      "Epoch 672/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0016 - val_loss: 0.0051\n",
      "Epoch 673/1000\n",
      "143/143 [==============================] - 0s 145us/step - loss: 0.0018 - val_loss: 0.0049\n",
      "Epoch 674/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0023 - val_loss: 0.0067\n",
      "Epoch 675/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0027 - val_loss: 0.0049\n",
      "Epoch 676/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0030 - val_loss: 0.0053\n",
      "Epoch 677/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0032 - val_loss: 0.0074\n",
      "Epoch 678/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0045\n",
      "Epoch 679/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0053\n",
      "Epoch 680/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0057\n",
      "Epoch 681/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0022 - val_loss: 0.0052\n",
      "Epoch 682/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0058\n",
      "Epoch 683/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0045\n",
      "Epoch 684/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0053\n",
      "Epoch 685/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0067\n",
      "Epoch 686/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 687/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0023 - val_loss: 0.0070\n",
      "Epoch 688/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0058\n",
      "Epoch 689/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0052\n",
      "Epoch 690/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0046\n",
      "Epoch 691/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0052\n",
      "Epoch 692/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0020 - val_loss: 0.0067\n",
      "Epoch 693/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 694/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.002 - 0s 119us/step - loss: 0.0023 - val_loss: 0.0048\n",
      "Epoch 695/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0060\n",
      "Epoch 696/1000\n",
      "143/143 [==============================] - 0s 174us/step - loss: 0.0023 - val_loss: 0.0047\n",
      "Epoch 697/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0020 - val_loss: 0.0049\n",
      "Epoch 698/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0020 - val_loss: 0.0053\n",
      "Epoch 699/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0049\n",
      "Epoch 700/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0057\n",
      "Epoch 701/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0050\n",
      "Epoch 702/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0054\n",
      "Epoch 703/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0046\n",
      "Epoch 704/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0017 - val_loss: 0.0051\n",
      "Epoch 705/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0016 - val_loss: 0.0054\n",
      "Epoch 706/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0053\n",
      "Epoch 707/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0022 - val_loss: 0.0059\n",
      "Epoch 708/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0053\n",
      "Epoch 709/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0017 - val_loss: 0.0048\n",
      "Epoch 710/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0062\n",
      "Epoch 711/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0051\n",
      "Epoch 712/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0051\n",
      "Epoch 713/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0050\n",
      "Epoch 714/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0016 - val_loss: 0.0054\n",
      "Epoch 715/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0051\n",
      "Epoch 716/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0055\n",
      "Epoch 717/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0051\n",
      "Epoch 718/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0053\n",
      "Epoch 719/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0054\n",
      "Epoch 720/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0053\n",
      "Epoch 721/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0056\n",
      "Epoch 722/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0050\n",
      "Epoch 723/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0056\n",
      "Epoch 724/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0058\n",
      "Epoch 725/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0018 - val_loss: 0.0052\n",
      "Epoch 726/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0059\n",
      "Epoch 727/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0015 - val_loss: 0.0053\n",
      "Epoch 728/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0055\n",
      "Epoch 729/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0060\n",
      "Epoch 730/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0017 - val_loss: 0.0049\n",
      "Epoch 731/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0016 - val_loss: 0.0058\n",
      "Epoch 732/1000\n",
      "143/143 [==============================] - 0s 141us/step - loss: 0.0017 - val_loss: 0.0057\n",
      "Epoch 733/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0019 - val_loss: 0.0049\n",
      "Epoch 734/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0017 - val_loss: 0.0052\n",
      "Epoch 735/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0055\n",
      "Epoch 736/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0048\n",
      "Epoch 737/1000\n",
      "143/143 [==============================] - 0s 135us/step - loss: 0.0019 - val_loss: 0.0049\n",
      "Epoch 738/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0018 - val_loss: 0.0054\n",
      "Epoch 739/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0053\n",
      "Epoch 740/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0051\n",
      "Epoch 741/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0056\n",
      "Epoch 742/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0046\n",
      "Epoch 743/1000\n",
      "143/143 [==============================] - 0s 128us/step - loss: 0.0017 - val_loss: 0.0051\n",
      "Epoch 744/1000\n",
      "143/143 [==============================] - 0s 140us/step - loss: 0.0016 - val_loss: 0.0058\n",
      "Epoch 745/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0052\n",
      "Epoch 746/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0015 - val_loss: 0.0049\n",
      "Epoch 747/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0015 - val_loss: 0.0054\n",
      "Epoch 748/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0016 - val_loss: 0.0052\n",
      "Epoch 749/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0057\n",
      "Epoch 750/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0054\n",
      "Epoch 751/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0015 - val_loss: 0.0061\n",
      "Epoch 752/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0049\n",
      "Epoch 753/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0016 - val_loss: 0.0053\n",
      "Epoch 754/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0059\n",
      "Epoch 755/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 0.0052\n",
      "Epoch 756/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0051\n",
      "Epoch 757/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0056\n",
      "Epoch 758/1000\n",
      "143/143 [==============================] - 0s 135us/step - loss: 0.0016 - val_loss: 0.0049\n",
      "Epoch 759/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0015 - val_loss: 0.0054\n",
      "Epoch 760/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0016 - val_loss: 0.0056\n",
      "Epoch 761/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0047\n",
      "Epoch 762/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0062\n",
      "Epoch 763/1000\n",
      "143/143 [==============================] - 0s 136us/step - loss: 0.0016 - val_loss: 0.0054\n",
      "Epoch 764/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0054\n",
      "Epoch 765/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0049\n",
      "Epoch 766/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0052\n",
      "Epoch 767/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0057\n",
      "Epoch 768/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0057\n",
      "Epoch 769/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.002 - 0s 102us/step - loss: 0.0017 - val_loss: 0.0052\n",
      "Epoch 770/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0051\n",
      "Epoch 771/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0060\n",
      "Epoch 772/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0016 - val_loss: 0.0048\n",
      "Epoch 773/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 0.0066\n",
      "Epoch 774/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0053\n",
      "Epoch 775/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0047\n",
      "Epoch 776/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0059\n",
      "Epoch 777/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0053\n",
      "Epoch 778/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0051\n",
      "Epoch 779/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0015 - val_loss: 0.0051\n",
      "Epoch 780/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0053\n",
      "Epoch 781/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0055\n",
      "Epoch 782/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0050\n",
      "Epoch 783/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0057\n",
      "Epoch 784/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0054\n",
      "Epoch 785/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0050\n",
      "Epoch 786/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0016 - val_loss: 0.0060\n",
      "Epoch 787/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0051\n",
      "Epoch 788/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0018 - val_loss: 0.0049\n",
      "Epoch 789/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0052\n",
      "Epoch 790/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0019 - val_loss: 0.0060\n",
      "Epoch 791/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0059\n",
      "Epoch 792/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0020 - val_loss: 0.0059\n",
      "Epoch 793/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0046\n",
      "Epoch 794/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0016 - val_loss: 0.0051\n",
      "Epoch 795/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0015 - val_loss: 0.0057\n",
      "Epoch 796/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0015 - val_loss: 0.0048\n",
      "Epoch 797/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0047\n",
      "Epoch 798/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0063\n",
      "Epoch 799/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 0.0053\n",
      "Epoch 800/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0018 - val_loss: 0.0052\n",
      "Epoch 801/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0061\n",
      "Epoch 802/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0054\n",
      "Epoch 803/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0051\n",
      "Epoch 804/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0061\n",
      "Epoch 805/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0019 - val_loss: 0.0056\n",
      "Epoch 806/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 807/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0016 - val_loss: 0.0059\n",
      "Epoch 808/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0051\n",
      "Epoch 809/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0051\n",
      "Epoch 810/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0051\n",
      "Epoch 811/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0058\n",
      "Epoch 812/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0015 - val_loss: 0.0049\n",
      "Epoch 813/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0054\n",
      "Epoch 814/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0015 - val_loss: 0.0053\n",
      "Epoch 815/1000\n",
      "143/143 [==============================] - 0s 136us/step - loss: 0.0015 - val_loss: 0.0048\n",
      "Epoch 816/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0017 - val_loss: 0.0061\n",
      "Epoch 817/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0019 - val_loss: 0.0056\n",
      "Epoch 818/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0018 - val_loss: 0.0057\n",
      "Epoch 819/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0053\n",
      "Epoch 820/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0016 - val_loss: 0.0050\n",
      "Epoch 821/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0015 - val_loss: 0.0053\n",
      "Epoch 822/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0016 - val_loss: 0.0055\n",
      "Epoch 823/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0053\n",
      "Epoch 824/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0058\n",
      "Epoch 825/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0053\n",
      "Epoch 826/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0052\n",
      "Epoch 827/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0018 - val_loss: 0.0053\n",
      "Epoch 828/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0053\n",
      "Epoch 829/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0057\n",
      "Epoch 830/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0053\n",
      "Epoch 831/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0055\n",
      "Epoch 832/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0055\n",
      "Epoch 833/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0052\n",
      "Epoch 834/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0051\n",
      "Epoch 835/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0054\n",
      "Epoch 836/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0053\n",
      "Epoch 837/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0051\n",
      "Epoch 838/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 839/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0062\n",
      "Epoch 840/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0065\n",
      "Epoch 841/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0060\n",
      "Epoch 842/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0014 - val_loss: 0.0055\n",
      "Epoch 843/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0053\n",
      "Epoch 844/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0019 - val_loss: 0.0060\n",
      "Epoch 845/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0051\n",
      "Epoch 846/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0015 - val_loss: 0.0066\n",
      "Epoch 847/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0051\n",
      "Epoch 848/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0052\n",
      "Epoch 849/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0048\n",
      "Epoch 850/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0059\n",
      "Epoch 851/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0048\n",
      "Epoch 852/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 853/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0067\n",
      "Epoch 854/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0019 - val_loss: 0.0053\n",
      "Epoch 855/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0023 - val_loss: 0.0048\n",
      "Epoch 856/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0022 - val_loss: 0.0063\n",
      "Epoch 857/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0051\n",
      "Epoch 858/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0052\n",
      "Epoch 859/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0019 - val_loss: 0.0069\n",
      "Epoch 860/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0022 - val_loss: 0.0054\n",
      "Epoch 861/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0057\n",
      "Epoch 862/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0052\n",
      "Epoch 863/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0047\n",
      "Epoch 864/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0019 - val_loss: 0.0047\n",
      "Epoch 865/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0053\n",
      "Epoch 866/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0017 - val_loss: 0.0061\n",
      "Epoch 867/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 868/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0048\n",
      "Epoch 869/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0020 - val_loss: 0.0059\n",
      "Epoch 870/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 871/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0016 - val_loss: 0.0063\n",
      "Epoch 872/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0018 - val_loss: 0.0051\n",
      "Epoch 873/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0047\n",
      "Epoch 874/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0019 - val_loss: 0.0057\n",
      "Epoch 875/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0020 - val_loss: 0.0055\n",
      "Epoch 876/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0051\n",
      "Epoch 877/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0018 - val_loss: 0.0054\n",
      "Epoch 878/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0052\n",
      "Epoch 879/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0060\n",
      "Epoch 880/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0048\n",
      "Epoch 881/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0016 - val_loss: 0.0047\n",
      "Epoch 882/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 0.0053\n",
      "Epoch 883/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0015 - val_loss: 0.0048\n",
      "Epoch 884/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0015 - val_loss: 0.0055\n",
      "Epoch 885/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0014 - val_loss: 0.0049\n",
      "Epoch 886/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0053\n",
      "Epoch 887/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0064\n",
      "Epoch 888/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0019 - val_loss: 0.0042\n",
      "Epoch 889/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0049\n",
      "Epoch 890/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0016 - val_loss: 0.0052\n",
      "Epoch 891/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0049\n",
      "Epoch 892/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0076\n",
      "Epoch 893/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0049\n",
      "Epoch 894/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0020 - val_loss: 0.0054\n",
      "Epoch 895/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0045\n",
      "Epoch 896/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0047\n",
      "Epoch 897/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0054\n",
      "Epoch 898/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0051\n",
      "Epoch 899/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0049\n",
      "Epoch 900/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0018 - val_loss: 0.0056\n",
      "Epoch 901/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0016 - val_loss: 0.0052\n",
      "Epoch 902/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0063\n",
      "Epoch 903/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 904/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0051\n",
      "Epoch 905/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0053\n",
      "Epoch 906/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0050\n",
      "Epoch 907/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0052\n",
      "Epoch 908/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0014 - val_loss: 0.0053\n",
      "Epoch 909/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0051\n",
      "Epoch 910/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0015 - val_loss: 0.0052\n",
      "Epoch 911/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0015 - val_loss: 0.0055\n",
      "Epoch 912/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0057\n",
      "Epoch 913/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0047\n",
      "Epoch 914/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0055\n",
      "Epoch 915/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0014 - val_loss: 0.0055\n",
      "Epoch 916/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0015 - val_loss: 0.0059\n",
      "Epoch 917/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0017 - val_loss: 0.0050\n",
      "Epoch 918/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0055\n",
      "Epoch 919/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0016 - val_loss: 0.0053\n",
      "Epoch 920/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0016 - val_loss: 0.0048\n",
      "Epoch 921/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0016 - val_loss: 0.0049\n",
      "Epoch 922/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0054\n",
      "Epoch 923/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0015 - val_loss: 0.0060\n",
      "Epoch 924/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0017 - val_loss: 0.0049\n",
      "Epoch 925/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0052\n",
      "Epoch 926/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0052\n",
      "Epoch 927/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0050\n",
      "Epoch 928/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0014 - val_loss: 0.0063\n",
      "Epoch 929/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0054\n",
      "Epoch 930/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0050\n",
      "Epoch 931/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0054\n",
      "Epoch 932/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0014 - val_loss: 0.0057\n",
      "Epoch 933/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0050\n",
      "Epoch 934/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0060\n",
      "Epoch 935/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0020 - val_loss: 0.0058\n",
      "Epoch 936/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0019 - val_loss: 0.0050\n",
      "Epoch 937/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0067\n",
      "Epoch 938/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0017 - val_loss: 0.0050\n",
      "Epoch 939/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0047\n",
      "Epoch 940/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0018 - val_loss: 0.0051\n",
      "Epoch 941/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0014 - val_loss: 0.0050\n",
      "Epoch 942/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 0.0053\n",
      "Epoch 943/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0016 - val_loss: 0.0058\n",
      "Epoch 944/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0048\n",
      "Epoch 945/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0014 - val_loss: 0.0056\n",
      "Epoch 946/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0014 - val_loss: 0.0051\n",
      "Epoch 947/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0049\n",
      "Epoch 948/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0016 - val_loss: 0.0048\n",
      "Epoch 949/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0060\n",
      "Epoch 950/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0019 - val_loss: 0.0059\n",
      "Epoch 951/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 0.0049\n",
      "Epoch 952/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0014 - val_loss: 0.0047\n",
      "Epoch 953/1000\n",
      "143/143 [==============================] - 0s 130us/step - loss: 0.0014 - val_loss: 0.0055\n",
      "Epoch 954/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0014 - val_loss: 0.0054\n",
      "Epoch 955/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0048\n",
      "Epoch 956/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0017 - val_loss: 0.0051\n",
      "Epoch 957/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0057\n",
      "Epoch 958/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0051\n",
      "Epoch 959/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0017 - val_loss: 0.0056\n",
      "Epoch 960/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0052\n",
      "Epoch 961/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0055\n",
      "Epoch 962/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0015 - val_loss: 0.0050\n",
      "Epoch 963/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0046\n",
      "Epoch 964/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0056\n",
      "Epoch 965/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0052\n",
      "Epoch 966/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0015 - val_loss: 0.0051\n",
      "Epoch 967/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0014 - val_loss: 0.0058\n",
      "Epoch 968/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0013 - val_loss: 0.0051\n",
      "Epoch 969/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0049\n",
      "Epoch 970/1000\n",
      "143/143 [==============================] - 0s 128us/step - loss: 0.0013 - val_loss: 0.0056\n",
      "Epoch 971/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0052\n",
      "Epoch 972/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0055\n",
      "Epoch 973/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0053\n",
      "Epoch 974/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0048\n",
      "Epoch 975/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0051\n",
      "Epoch 976/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0056\n",
      "Epoch 977/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0016 - val_loss: 0.0051\n",
      "Epoch 978/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 979/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0014 - val_loss: 0.0053\n",
      "Epoch 980/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0059\n",
      "Epoch 981/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0017 - val_loss: 0.0048\n",
      "Epoch 982/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0018 - val_loss: 0.0049\n",
      "Epoch 983/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0019 - val_loss: 0.0065\n",
      "Epoch 984/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0050\n",
      "Epoch 985/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0019 - val_loss: 0.0062\n",
      "Epoch 986/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0058\n",
      "Epoch 987/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0020 - val_loss: 0.0053\n",
      "Epoch 988/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 989/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0047\n",
      "Epoch 990/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0052\n",
      "Epoch 991/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0015 - val_loss: 0.0050\n",
      "Epoch 992/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0053\n",
      "Epoch 993/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 120us/step - loss: 0.0015 - val_loss: 0.0054\n",
      "Epoch 994/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0054\n",
      "Epoch 995/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0013 - val_loss: 0.0049\n",
      "Epoch 996/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0014 - val_loss: 0.0048\n",
      "Epoch 997/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0016 - val_loss: 0.0065\n",
      "Epoch 998/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0015 - val_loss: 0.0048\n",
      "Epoch 999/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0047\n",
      "Epoch 1000/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0014 - val_loss: 0.0057\n",
      "0.015034993179142475\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.792388  ,  0.8352976 ,  0.56654626, -0.05322287, -0.30493784],\n",
       "        [-0.5113226 ,  0.305184  ,  0.15142906,  0.8989809 ,  0.8401689 ],\n",
       "        [ 1.4343079 , -0.41060036,  0.1935165 ,  0.02391584,  0.60686857],\n",
       "        [ 0.6301367 ,  0.3707191 ,  0.05371154,  0.00745301, -0.61123866],\n",
       "        [ 0.42221132, -0.41640517, -0.0160974 , -0.38436106, -0.07389599],\n",
       "        [-1.5815036 ,  0.79170394,  0.6203946 ,  0.8198848 ,  0.5863235 ],\n",
       "        [ 0.7325629 ,  0.81557465, -0.12781943,  0.1914464 , -0.64791185],\n",
       "        [ 0.41655102, -0.11018033,  0.41411   , -0.15567775, -0.5590992 ],\n",
       "        [ 0.41913128, -0.53998387,  0.12068506, -0.5051021 , -0.873651  ],\n",
       "        [-0.8225282 ,  0.78305614,  0.41209444,  0.9779791 , -0.13946828],\n",
       "        [ 0.20452589, -0.58384603,  0.39220715,  0.16406694, -0.05798318],\n",
       "        [-0.37285885, -0.5241034 , -0.30242723,  0.2247544 ,  0.68075496],\n",
       "        [-0.37110952, -0.20133552,  0.16587389, -0.8218622 , -0.01654555],\n",
       "        [-1.8740476 , -2.0501342 , -0.04733768, -0.2702692 , -0.47388995],\n",
       "        [ 0.06875318, -0.71144044, -0.15221187, -0.0475959 ,  0.42085353],\n",
       "        [-0.3721215 ,  0.36007303, -0.15314668, -0.20547648, -0.08167477],\n",
       "        [ 0.5317856 , -0.0424041 ,  0.11967509, -0.6246803 , -0.31254467],\n",
       "        [ 0.3020962 , -0.51640916,  0.19419816, -0.50069195,  0.35920006],\n",
       "        [-0.01490968, -1.5165807 ,  0.70759594, -0.6062335 ,  0.7384047 ],\n",
       "        [ 0.2649414 , -0.84476143,  0.12899962, -0.42698428, -0.53171617],\n",
       "        [ 1.9487219 , -0.33721036,  0.02493025,  0.18544348,  1.1108373 ],\n",
       "        [ 0.42129153, -1.2589345 ,  0.00860768, -0.05532162,  0.6990087 ]],\n",
       "       dtype=float32),\n",
       " array([ 1.0085335 ,  0.1290918 ,  0.14212692, -0.13519908,  0.34336382],\n",
       "       dtype=float32),\n",
       " array([[ 0.61133593,  0.7751432 ,  0.6674652 , -0.36733353,  0.04097411,\n",
       "         -0.26106083, -0.14673598,  0.34044105, -0.11627088, -0.30221346,\n",
       "         -0.6517095 , -0.18377943, -0.49382383,  0.03444254,  0.04642536],\n",
       "        [ 0.22505566,  0.37143725,  0.56417763, -0.63366264,  0.13307466,\n",
       "          0.17389846,  0.21024865, -0.44332835,  0.3922924 ,  0.13061461,\n",
       "         -0.5132349 , -0.20397782, -0.72022223,  0.42956024,  0.04650739],\n",
       "        [ 0.03299477,  0.04030999, -0.35151967,  0.14918815, -0.02285962,\n",
       "          0.1252668 , -0.09077685, -0.42470977,  0.20000698,  0.16252473,\n",
       "         -0.13964733, -0.03296288, -0.04982067,  0.13523132,  0.33058387],\n",
       "        [ 0.20733982,  0.01136896, -0.16495906,  0.42086312, -0.1604731 ,\n",
       "         -0.08760311,  0.12737688,  0.14440624, -0.32765087,  0.01965656,\n",
       "          0.5635397 ,  0.3064663 ,  0.04213242, -0.21463522,  0.4057886 ],\n",
       "        [-0.06256634, -0.19374923,  0.6812516 , -0.5409211 ,  0.18118736,\n",
       "         -0.03511996,  0.13039413, -0.57636243,  0.31711653, -0.02908663,\n",
       "          0.22427444, -0.24503438, -0.461335  ,  0.19677341,  0.05671415]],\n",
       "       dtype=float32),\n",
       " array([-0.2506573 , -0.21354432, -0.23968472,  0.09786514, -0.07395133,\n",
       "         0.24583495,  0.31080145,  0.18053977, -0.05916091,  0.22615096,\n",
       "         0.18043059,  0.23823538,  0.17576513,  0.0269571 , -0.2642469 ],\n",
       "       dtype=float32),\n",
       " array([[-0.05879738],\n",
       "        [-0.08528255],\n",
       "        [-0.31463075],\n",
       "        [ 0.04165491],\n",
       "        [-0.02142343],\n",
       "        [ 0.00420104],\n",
       "        [-0.0004831 ],\n",
       "        [-0.00162266],\n",
       "        [-0.02087622],\n",
       "        [ 0.01721011],\n",
       "        [ 0.14303696],\n",
       "        [ 0.0073256 ],\n",
       "        [ 0.25174972],\n",
       "        [-0.00202777],\n",
       "        [-0.00458908]], dtype=float32),\n",
       " array([0.22342655], dtype=float32)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_automobile, history_automobile=NN_model_structure_regression_3(X_train_automobile, X_val_automobile, Y_train_automobile, Y_val_automobile, adam2, 32, 1000)\n",
    "model_automobile.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_automobile.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_automobile_structure3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_46 (Dense)             (None, 10)                230       \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 291\n",
      "Trainable params: 291\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 143 samples, validate on 31 samples\n",
      "Epoch 1/1000\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.3025 - val_loss: 0.0582\n",
      "Epoch 2/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0591 - val_loss: 0.0515\n",
      "Epoch 3/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0566 - val_loss: 0.0207\n",
      "Epoch 4/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0251 - val_loss: 0.0081\n",
      "Epoch 5/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0206 - val_loss: 0.0098\n",
      "Epoch 6/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0153 - val_loss: 0.0095\n",
      "Epoch 7/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0127 - val_loss: 0.0091\n",
      "Epoch 8/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0113 - val_loss: 0.0084\n",
      "Epoch 9/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0101 - val_loss: 0.0076\n",
      "Epoch 10/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0099 - val_loss: 0.0080\n",
      "Epoch 11/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0099 - val_loss: 0.0074\n",
      "Epoch 12/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0102 - val_loss: 0.0076\n",
      "Epoch 13/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0094 - val_loss: 0.0076\n",
      "Epoch 14/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0089 - val_loss: 0.0072\n",
      "Epoch 15/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0096 - val_loss: 0.0068\n",
      "Epoch 16/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0090 - val_loss: 0.0069\n",
      "Epoch 17/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0081 - val_loss: 0.0066\n",
      "Epoch 18/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0081 - val_loss: 0.0067\n",
      "Epoch 19/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0079 - val_loss: 0.0064\n",
      "Epoch 20/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0077 - val_loss: 0.0061\n",
      "Epoch 21/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0078 - val_loss: 0.0060\n",
      "Epoch 22/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0078 - val_loss: 0.0065\n",
      "Epoch 23/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0077 - val_loss: 0.0057\n",
      "Epoch 24/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0074 - val_loss: 0.0061\n",
      "Epoch 25/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0073 - val_loss: 0.0062\n",
      "Epoch 26/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0087 - val_loss: 0.0067\n",
      "Epoch 27/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0076 - val_loss: 0.0054\n",
      "Epoch 28/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0071 - val_loss: 0.0061\n",
      "Epoch 29/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0074 - val_loss: 0.0055\n",
      "Epoch 30/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0073 - val_loss: 0.0053\n",
      "Epoch 31/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0075 - val_loss: 0.0052\n",
      "Epoch 32/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0068 - val_loss: 0.0049\n",
      "Epoch 33/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0070 - val_loss: 0.0053\n",
      "Epoch 34/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0072 - val_loss: 0.0059\n",
      "Epoch 35/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0074 - val_loss: 0.0046\n",
      "Epoch 36/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0066 - val_loss: 0.0053\n",
      "Epoch 37/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0067 - val_loss: 0.0045\n",
      "Epoch 38/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0068 - val_loss: 0.0045\n",
      "Epoch 39/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0070 - val_loss: 0.0055\n",
      "Epoch 40/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0066 - val_loss: 0.0045\n",
      "Epoch 41/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0065 - val_loss: 0.0046\n",
      "Epoch 42/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0062 - val_loss: 0.0041\n",
      "Epoch 43/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0065 - val_loss: 0.0041\n",
      "Epoch 44/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0063 - val_loss: 0.0046\n",
      "Epoch 45/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0060 - val_loss: 0.0042\n",
      "Epoch 46/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0064 - val_loss: 0.0041\n",
      "Epoch 47/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0065 - val_loss: 0.0072\n",
      "Epoch 48/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0077 - val_loss: 0.0046\n",
      "Epoch 49/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0070 - val_loss: 0.0041\n",
      "Epoch 50/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0065 - val_loss: 0.0063\n",
      "Epoch 51/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0072 - val_loss: 0.0046\n",
      "Epoch 52/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0077 - val_loss: 0.0045\n",
      "Epoch 53/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0066 - val_loss: 0.0054\n",
      "Epoch 54/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0063 - val_loss: 0.0061\n",
      "Epoch 55/1000\n",
      "143/143 [==============================] - 0s 135us/step - loss: 0.0101 - val_loss: 0.0135\n",
      "Epoch 56/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0112 - val_loss: 0.0067\n",
      "Epoch 57/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0074 - val_loss: 0.0057\n",
      "Epoch 58/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0072 - val_loss: 0.0037\n",
      "Epoch 59/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0060 - val_loss: 0.0036\n",
      "Epoch 60/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0060 - val_loss: 0.0042\n",
      "Epoch 61/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0057 - val_loss: 0.0041\n",
      "Epoch 62/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0055 - val_loss: 0.0040\n",
      "Epoch 63/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0055 - val_loss: 0.0042\n",
      "Epoch 64/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0055 - val_loss: 0.0038\n",
      "Epoch 65/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0060 - val_loss: 0.0083\n",
      "Epoch 66/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0073 - val_loss: 0.0073\n",
      "Epoch 67/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0071 - val_loss: 0.0088\n",
      "Epoch 68/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0083 - val_loss: 0.0041\n",
      "Epoch 69/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0055 - val_loss: 0.0042\n",
      "Epoch 70/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0052 - val_loss: 0.0037\n",
      "Epoch 71/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0051 - val_loss: 0.0044\n",
      "Epoch 72/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0053 - val_loss: 0.0037\n",
      "Epoch 73/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0041\n",
      "Epoch 74/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0040\n",
      "Epoch 75/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0036\n",
      "Epoch 76/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0038\n",
      "Epoch 77/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0057 - val_loss: 0.0072\n",
      "Epoch 78/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0059 - val_loss: 0.0059\n",
      "Epoch 79/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0060 - val_loss: 0.0094\n",
      "Epoch 80/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0069 - val_loss: 0.0057\n",
      "Epoch 81/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0076 - val_loss: 0.0047\n",
      "Epoch 82/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0055 - val_loss: 0.0042\n",
      "Epoch 83/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0039\n",
      "Epoch 84/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0037\n",
      "Epoch 85/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 86/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0039\n",
      "Epoch 87/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0041\n",
      "Epoch 88/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0035\n",
      "Epoch 89/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0045 - val_loss: 0.0057\n",
      "Epoch 90/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0054 - val_loss: 0.0041\n",
      "Epoch 91/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 92/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0044 - val_loss: 0.0036\n",
      "Epoch 93/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 94/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0046 - val_loss: 0.0035\n",
      "Epoch 95/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0052 - val_loss: 0.0035\n",
      "Epoch 96/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0066\n",
      "Epoch 97/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0049 - val_loss: 0.0065\n",
      "Epoch 98/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0060 - val_loss: 0.0062\n",
      "Epoch 99/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0061 - val_loss: 0.0036\n",
      "Epoch 100/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0045 - val_loss: 0.0037\n",
      "Epoch 101/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0042 - val_loss: 0.0039\n",
      "Epoch 102/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0040 - val_loss: 0.0036\n",
      "Epoch 103/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0039 - val_loss: 0.0033\n",
      "Epoch 104/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0039 - val_loss: 0.0037\n",
      "Epoch 105/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 106/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0039 - val_loss: 0.0037\n",
      "Epoch 107/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0035\n",
      "Epoch 108/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0042 - val_loss: 0.0048\n",
      "Epoch 109/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 110/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0035\n",
      "Epoch 111/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0044 - val_loss: 0.0041\n",
      "Epoch 112/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0053\n",
      "Epoch 113/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0058 - val_loss: 0.0058\n",
      "Epoch 114/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0059 - val_loss: 0.0040\n",
      "Epoch 115/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0048 - val_loss: 0.0052\n",
      "Epoch 116/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0043 - val_loss: 0.0040\n",
      "Epoch 117/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0037 - val_loss: 0.0061\n",
      "Epoch 118/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0042 - val_loss: 0.0035\n",
      "Epoch 119/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0042\n",
      "Epoch 120/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 121/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0039 - val_loss: 0.0035\n",
      "Epoch 122/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0054 - val_loss: 0.0071\n",
      "Epoch 123/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0043 - val_loss: 0.0042\n",
      "Epoch 124/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 125/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 126/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 127/1000\n",
      "143/143 [==============================] - 0s 127us/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 128/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0057\n",
      "Epoch 129/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0034\n",
      "Epoch 130/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0033\n",
      "Epoch 131/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0035 - val_loss: 0.0050\n",
      "Epoch 132/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0037\n",
      "Epoch 133/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0036\n",
      "Epoch 134/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0048 - val_loss: 0.0048\n",
      "Epoch 135/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 136/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 137/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 138/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 139/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 140/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0032 - val_loss: 0.0038\n",
      "Epoch 141/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0036 - val_loss: 0.0049\n",
      "Epoch 142/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0042\n",
      "Epoch 143/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0037 - val_loss: 0.0057\n",
      "Epoch 144/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 145/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 146/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0039 - val_loss: 0.0044\n",
      "Epoch 147/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 148/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 149/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0035\n",
      "Epoch 150/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 151/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0031 - val_loss: 0.0036\n",
      "Epoch 152/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0032 - val_loss: 0.0039\n",
      "Epoch 153/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0031 - val_loss: 0.0044\n",
      "Epoch 154/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 155/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 156/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0035 - val_loss: 0.0052\n",
      "Epoch 157/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0030\n",
      "Epoch 158/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 159/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0047\n",
      "Epoch 160/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 161/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 162/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 163/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0050\n",
      "Epoch 164/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 165/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 166/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0049\n",
      "Epoch 167/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0036\n",
      "Epoch 168/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0035\n",
      "Epoch 169/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0028 - val_loss: 0.0042\n",
      "Epoch 170/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0029 - val_loss: 0.0039\n",
      "Epoch 171/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 172/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0027 - val_loss: 0.0039\n",
      "Epoch 173/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 174/1000\n",
      "143/143 [==============================] - 0s 140us/step - loss: 0.0027 - val_loss: 0.0046\n",
      "Epoch 175/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 176/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 177/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 178/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0029 - val_loss: 0.0051\n",
      "Epoch 179/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0030 - val_loss: 0.0040\n",
      "Epoch 180/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0031 - val_loss: 0.0041\n",
      "Epoch 181/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 182/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0030 - val_loss: 0.0036\n",
      "Epoch 183/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0032 - val_loss: 0.0038\n",
      "Epoch 184/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0032 - val_loss: 0.0044\n",
      "Epoch 185/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0028 - val_loss: 0.0045\n",
      "Epoch 186/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0028 - val_loss: 0.0031\n",
      "Epoch 187/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0046\n",
      "Epoch 188/1000\n",
      "143/143 [==============================] - 0s 136us/step - loss: 0.0029 - val_loss: 0.0043\n",
      "Epoch 189/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0042\n",
      "Epoch 190/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0029 - val_loss: 0.0044\n",
      "Epoch 191/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0027 - val_loss: 0.0046\n",
      "Epoch 192/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0072\n",
      "Epoch 193/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 194/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 195/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0038\n",
      "Epoch 196/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0050\n",
      "Epoch 197/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0038\n",
      "Epoch 198/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 199/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0042\n",
      "Epoch 200/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0026 - val_loss: 0.0038\n",
      "Epoch 201/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0049\n",
      "Epoch 202/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0040\n",
      "Epoch 203/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 204/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 205/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0051\n",
      "Epoch 206/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0031 - val_loss: 0.0057\n",
      "Epoch 207/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 208/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0039\n",
      "Epoch 209/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0028 - val_loss: 0.0037\n",
      "Epoch 210/1000\n",
      "143/143 [==============================] - 0s 167us/step - loss: 0.0027 - val_loss: 0.0046\n",
      "Epoch 211/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0025 - val_loss: 0.0037\n",
      "Epoch 212/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0026 - val_loss: 0.0039\n",
      "Epoch 213/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0037\n",
      "Epoch 214/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0026 - val_loss: 0.0043\n",
      "Epoch 215/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0043\n",
      "Epoch 216/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0049\n",
      "Epoch 217/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0049\n",
      "Epoch 218/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0028 - val_loss: 0.0032\n",
      "Epoch 219/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0037\n",
      "Epoch 220/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0085\n",
      "Epoch 221/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0039 - val_loss: 0.0041\n",
      "Epoch 222/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0040 - val_loss: 0.0034\n",
      "Epoch 223/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 126us/step - loss: 0.0032 - val_loss: 0.0041\n",
      "Epoch 224/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0030 - val_loss: 0.0048\n",
      "Epoch 225/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 226/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 227/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0029 - val_loss: 0.0060\n",
      "Epoch 228/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0031 - val_loss: 0.0038\n",
      "Epoch 229/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0031 - val_loss: 0.0036\n",
      "Epoch 230/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0061\n",
      "Epoch 231/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0035 - val_loss: 0.0043\n",
      "Epoch 232/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0035\n",
      "Epoch 233/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0028 - val_loss: 0.0059\n",
      "Epoch 234/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 235/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 236/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0050\n",
      "Epoch 237/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0026 - val_loss: 0.0038\n",
      "Epoch 238/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0023 - val_loss: 0.0043\n",
      "Epoch 239/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0024 - val_loss: 0.0040\n",
      "Epoch 240/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 241/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0028 - val_loss: 0.0068\n",
      "Epoch 242/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0044\n",
      "Epoch 243/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0042\n",
      "Epoch 244/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 245/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0037\n",
      "Epoch 246/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0023 - val_loss: 0.0040\n",
      "Epoch 247/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0049\n",
      "Epoch 248/1000\n",
      "143/143 [==============================] - 0s 127us/step - loss: 0.0028 - val_loss: 0.0051\n",
      "Epoch 249/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0026 - val_loss: 0.0038\n",
      "Epoch 250/1000\n",
      "143/143 [==============================] - 0s 135us/step - loss: 0.0026 - val_loss: 0.0039\n",
      "Epoch 251/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0065\n",
      "Epoch 252/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0046\n",
      "Epoch 253/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0037\n",
      "Epoch 254/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0026 - val_loss: 0.0060\n",
      "Epoch 255/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0027 - val_loss: 0.0043\n",
      "Epoch 256/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0028 - val_loss: 0.0041\n",
      "Epoch 257/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0063\n",
      "Epoch 258/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 259/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0041\n",
      "Epoch 260/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0039\n",
      "Epoch 261/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0088\n",
      "Epoch 262/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 263/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0029 - val_loss: 0.0039\n",
      "Epoch 264/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0025 - val_loss: 0.0048\n",
      "Epoch 265/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0038\n",
      "Epoch 266/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0024 - val_loss: 0.0043\n",
      "Epoch 267/1000\n",
      "143/143 [==============================] - 0s 141us/step - loss: 0.0026 - val_loss: 0.0049\n",
      "Epoch 268/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0024 - val_loss: 0.0042\n",
      "Epoch 269/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0044\n",
      "Epoch 270/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0051\n",
      "Epoch 271/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 272/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0046\n",
      "Epoch 273/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0022 - val_loss: 0.0041\n",
      "Epoch 274/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0041\n",
      "Epoch 275/1000\n",
      "143/143 [==============================] - 0s 134us/step - loss: 0.0022 - val_loss: 0.0057\n",
      "Epoch 276/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0040\n",
      "Epoch 277/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0024 - val_loss: 0.0040\n",
      "Epoch 278/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0047\n",
      "Epoch 279/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0056\n",
      "Epoch 280/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0045\n",
      "Epoch 281/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0052\n",
      "Epoch 282/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0028 - val_loss: 0.0054\n",
      "Epoch 283/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0041\n",
      "Epoch 284/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0044\n",
      "Epoch 285/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0043\n",
      "Epoch 286/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0021 - val_loss: 0.0045\n",
      "Epoch 287/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0042\n",
      "Epoch 288/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0047\n",
      "Epoch 289/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0068\n",
      "Epoch 290/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 291/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0030 - val_loss: 0.0039\n",
      "Epoch 292/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0025 - val_loss: 0.0071\n",
      "Epoch 293/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0031 - val_loss: 0.0043\n",
      "Epoch 294/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0048\n",
      "Epoch 295/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0022 - val_loss: 0.0043\n",
      "Epoch 296/1000\n",
      "143/143 [==============================] - 0s 131us/step - loss: 0.0024 - val_loss: 0.0060\n",
      "Epoch 297/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0052\n",
      "Epoch 298/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0025 - val_loss: 0.0049\n",
      "Epoch 299/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0030 - val_loss: 0.0061\n",
      "Epoch 300/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0049\n",
      "Epoch 301/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0025 - val_loss: 0.0045\n",
      "Epoch 302/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0032 - val_loss: 0.0058\n",
      "Epoch 303/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0026 - val_loss: 0.0042\n",
      "Epoch 304/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0042\n",
      "Epoch 305/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0027 - val_loss: 0.0059\n",
      "Epoch 306/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0042\n",
      "Epoch 307/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0024 - val_loss: 0.0040\n",
      "Epoch 308/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0021 - val_loss: 0.0047\n",
      "Epoch 309/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0047\n",
      "Epoch 310/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0042\n",
      "Epoch 311/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0047\n",
      "Epoch 312/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0020 - val_loss: 0.0044\n",
      "Epoch 313/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0043\n",
      "Epoch 314/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 0.0050\n",
      "Epoch 315/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0045\n",
      "Epoch 316/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0025 - val_loss: 0.0043\n",
      "Epoch 317/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0025 - val_loss: 0.0042\n",
      "Epoch 318/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0025 - val_loss: 0.0054\n",
      "Epoch 319/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0048\n",
      "Epoch 320/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0043\n",
      "Epoch 321/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0044\n",
      "Epoch 322/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0083\n",
      "Epoch 323/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0030 - val_loss: 0.0046\n",
      "Epoch 324/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0041\n",
      "Epoch 325/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0033 - val_loss: 0.0076\n",
      "Epoch 326/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0043\n",
      "Epoch 327/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0025 - val_loss: 0.0041\n",
      "Epoch 328/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0056\n",
      "Epoch 329/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0044\n",
      "Epoch 330/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Epoch 331/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0064\n",
      "Epoch 332/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0021 - val_loss: 0.0045\n",
      "Epoch 333/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0026 - val_loss: 0.0044\n",
      "Epoch 334/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0025 - val_loss: 0.0049\n",
      "Epoch 335/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0050\n",
      "Epoch 336/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0047\n",
      "Epoch 337/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0045\n",
      "Epoch 338/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0050\n",
      "Epoch 339/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 340/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0020 - val_loss: 0.0054\n",
      "Epoch 341/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0048\n",
      "Epoch 342/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0020 - val_loss: 0.0045\n",
      "Epoch 343/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0061\n",
      "Epoch 344/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0052\n",
      "Epoch 345/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0048\n",
      "Epoch 346/1000\n",
      "143/143 [==============================] - 0s 129us/step - loss: 0.0026 - val_loss: 0.0053\n",
      "Epoch 347/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0081\n",
      "Epoch 348/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0047\n",
      "Epoch 349/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0052\n",
      "Epoch 350/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0056\n",
      "Epoch 351/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0042\n",
      "Epoch 352/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0055\n",
      "Epoch 353/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0071\n",
      "Epoch 354/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0025 - val_loss: 0.0041\n",
      "Epoch 355/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0030 - val_loss: 0.0047\n",
      "Epoch 356/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0062\n",
      "Epoch 357/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0023 - val_loss: 0.0044\n",
      "Epoch 358/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0049\n",
      "Epoch 359/1000\n",
      "143/143 [==============================] - 0s 129us/step - loss: 0.0020 - val_loss: 0.0052\n",
      "Epoch 360/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0058\n",
      "Epoch 361/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0047\n",
      "Epoch 362/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 0.0054\n",
      "Epoch 363/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0058\n",
      "Epoch 364/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0057\n",
      "Epoch 365/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0022 - val_loss: 0.0051\n",
      "Epoch 366/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0050\n",
      "Epoch 367/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0061\n",
      "Epoch 368/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0055\n",
      "Epoch 369/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0052\n",
      "Epoch 370/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0046\n",
      "Epoch 371/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0052\n",
      "Epoch 372/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0060\n",
      "Epoch 373/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0021 - val_loss: 0.0047\n",
      "Epoch 374/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0062\n",
      "Epoch 375/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0053\n",
      "Epoch 376/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0048\n",
      "Epoch 377/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 0.0065\n",
      "Epoch 378/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0021 - val_loss: 0.0049\n",
      "Epoch 379/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0021 - val_loss: 0.0047\n",
      "Epoch 380/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0050\n",
      "Epoch 381/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0065\n",
      "Epoch 382/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0052\n",
      "Epoch 383/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0051\n",
      "Epoch 384/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0057\n",
      "Epoch 385/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0056\n",
      "Epoch 386/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0048\n",
      "Epoch 387/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0061\n",
      "Epoch 388/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0059\n",
      "Epoch 389/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0047\n",
      "Epoch 390/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0055\n",
      "Epoch 391/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0028 - val_loss: 0.0079\n",
      "Epoch 392/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0027 - val_loss: 0.0047\n",
      "Epoch 393/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0043\n",
      "Epoch 394/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0055\n",
      "Epoch 395/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0060\n",
      "Epoch 396/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0047\n",
      "Epoch 397/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0051\n",
      "Epoch 398/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0054\n",
      "Epoch 399/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0049\n",
      "Epoch 400/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0054\n",
      "Epoch 401/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0052\n",
      "Epoch 402/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0053\n",
      "Epoch 403/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0065\n",
      "Epoch 404/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0052\n",
      "Epoch 405/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0051\n",
      "Epoch 406/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0077\n",
      "Epoch 407/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0055\n",
      "Epoch 408/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0049\n",
      "Epoch 409/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0050\n",
      "Epoch 410/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0056\n",
      "Epoch 411/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0020 - val_loss: 0.0057\n",
      "Epoch 412/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0054\n",
      "Epoch 413/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0055\n",
      "Epoch 414/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0049\n",
      "Epoch 415/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0055\n",
      "Epoch 416/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0054\n",
      "Epoch 417/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0050\n",
      "Epoch 418/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0052\n",
      "Epoch 419/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0021 - val_loss: 0.0085\n",
      "Epoch 420/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0051\n",
      "Epoch 421/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0047\n",
      "Epoch 422/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0050\n",
      "Epoch 423/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0065\n",
      "Epoch 424/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0023 - val_loss: 0.0051\n",
      "Epoch 425/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0051\n",
      "Epoch 426/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0054\n",
      "Epoch 427/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0064\n",
      "Epoch 428/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0045\n",
      "Epoch 429/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0057\n",
      "Epoch 430/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0021 - val_loss: 0.0050\n",
      "Epoch 431/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0020 - val_loss: 0.0048\n",
      "Epoch 432/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0024 - val_loss: 0.0066\n",
      "Epoch 433/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0026 - val_loss: 0.0062\n",
      "Epoch 434/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0028 - val_loss: 0.0045\n",
      "Epoch 435/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0020 - val_loss: 0.0053\n",
      "Epoch 436/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0019 - val_loss: 0.0055\n",
      "Epoch 437/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0018 - val_loss: 0.0049\n",
      "Epoch 438/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0018 - val_loss: 0.0066\n",
      "Epoch 439/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0022 - val_loss: 0.0053\n",
      "Epoch 440/1000\n",
      "143/143 [==============================] - 0s 131us/step - loss: 0.0018 - val_loss: 0.0049\n",
      "Epoch 441/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0019 - val_loss: 0.0051\n",
      "Epoch 442/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0019 - val_loss: 0.0059\n",
      "Epoch 443/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0018 - val_loss: 0.0053\n",
      "Epoch 444/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0018 - val_loss: 0.0051\n",
      "Epoch 445/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0055\n",
      "Epoch 446/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0018 - val_loss: 0.0065\n",
      "Epoch 447/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0051\n",
      "Epoch 448/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0019 - val_loss: 0.0055\n",
      "Epoch 449/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0068\n",
      "Epoch 450/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0024 - val_loss: 0.0054\n",
      "Epoch 451/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0053\n",
      "Epoch 452/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0028 - val_loss: 0.0084\n",
      "Epoch 453/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0029 - val_loss: 0.0052\n",
      "Epoch 454/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0024 - val_loss: 0.0052\n",
      "Epoch 455/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0024 - val_loss: 0.0058\n",
      "Epoch 456/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0022 - val_loss: 0.0059\n",
      "Epoch 457/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0022 - val_loss: 0.0049\n",
      "Epoch 458/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0054\n",
      "Epoch 459/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0018 - val_loss: 0.0050\n",
      "Epoch 460/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0051\n",
      "Epoch 461/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0054\n",
      "Epoch 462/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0020 - val_loss: 0.0053\n",
      "Epoch 463/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0064\n",
      "Epoch 464/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0019 - val_loss: 0.0053\n",
      "Epoch 465/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0050\n",
      "Epoch 466/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0056\n",
      "Epoch 467/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0017 - val_loss: 0.0058\n",
      "Epoch 468/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0018 - val_loss: 0.0050\n",
      "Epoch 469/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0020 - val_loss: 0.0065\n",
      "Epoch 470/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0021 - val_loss: 0.0056\n",
      "Epoch 471/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0019 - val_loss: 0.0053\n",
      "Epoch 472/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0017 - val_loss: 0.0057\n",
      "Epoch 473/1000\n",
      "143/143 [==============================] - 0s 151us/step - loss: 0.0018 - val_loss: 0.0061\n",
      "Epoch 474/1000\n",
      "143/143 [==============================] - 0s 130us/step - loss: 0.0018 - val_loss: 0.0050\n",
      "Epoch 475/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0027 - val_loss: 0.0079\n",
      "Epoch 476/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0028 - val_loss: 0.0061\n",
      "Epoch 477/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0048\n",
      "Epoch 478/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0062\n",
      "Epoch 479/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0054\n",
      "Epoch 480/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0057\n",
      "Epoch 481/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0051\n",
      "Epoch 482/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 0.0058\n",
      "Epoch 483/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0056\n",
      "Epoch 484/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 0.0051\n",
      "Epoch 485/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0017 - val_loss: 0.0058\n",
      "Epoch 486/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0054\n",
      "Epoch 487/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0057\n",
      "Epoch 488/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0019 - val_loss: 0.0062\n",
      "Epoch 489/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0056\n",
      "Epoch 490/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0053\n",
      "Epoch 491/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0048\n",
      "Epoch 492/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0065\n",
      "Epoch 493/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0058\n",
      "Epoch 494/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 495/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0059\n",
      "Epoch 496/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0057\n",
      "Epoch 497/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0054\n",
      "Epoch 498/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0053\n",
      "Epoch 499/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0060\n",
      "Epoch 500/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0068\n",
      "Epoch 501/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0054\n",
      "Epoch 502/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0049\n",
      "Epoch 503/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0068\n",
      "Epoch 504/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0073\n",
      "Epoch 505/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0051\n",
      "Epoch 506/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0057\n",
      "Epoch 507/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0072\n",
      "Epoch 508/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0048\n",
      "Epoch 509/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0049\n",
      "Epoch 510/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0071\n",
      "Epoch 511/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0049\n",
      "Epoch 512/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0050\n",
      "Epoch 513/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0017 - val_loss: 0.0052\n",
      "Epoch 514/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0065\n",
      "Epoch 515/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0060\n",
      "Epoch 516/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0051\n",
      "Epoch 517/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0054\n",
      "Epoch 518/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0053\n",
      "Epoch 519/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0068\n",
      "Epoch 520/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0055\n",
      "Epoch 521/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0019 - val_loss: 0.0054\n",
      "Epoch 522/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0059\n",
      "Epoch 523/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0061\n",
      "Epoch 524/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0019 - val_loss: 0.0062\n",
      "Epoch 525/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0052\n",
      "Epoch 526/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0059\n",
      "Epoch 527/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0059\n",
      "Epoch 528/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0057\n",
      "Epoch 529/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0056\n",
      "Epoch 530/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0054\n",
      "Epoch 531/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 107us/step - loss: 0.0018 - val_loss: 0.0058\n",
      "Epoch 532/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0018 - val_loss: 0.0079\n",
      "Epoch 533/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0061\n",
      "Epoch 534/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 0.0052\n",
      "Epoch 535/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0065\n",
      "Epoch 536/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0020 - val_loss: 0.0067\n",
      "Epoch 537/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0055\n",
      "Epoch 538/1000\n",
      "143/143 [==============================] - 0s 130us/step - loss: 0.0017 - val_loss: 0.0054\n",
      "Epoch 539/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0058\n",
      "Epoch 540/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0016 - val_loss: 0.0053\n",
      "Epoch 541/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0017 - val_loss: 0.0052\n",
      "Epoch 542/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0018 - val_loss: 0.0059\n",
      "Epoch 543/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0071\n",
      "Epoch 544/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0020 - val_loss: 0.0057\n",
      "Epoch 545/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0019 - val_loss: 0.0056\n",
      "Epoch 546/1000\n",
      "143/143 [==============================] - 0s 134us/step - loss: 0.0016 - val_loss: 0.0055\n",
      "Epoch 547/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0057\n",
      "Epoch 548/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0053\n",
      "Epoch 549/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0061\n",
      "Epoch 550/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0020 - val_loss: 0.0074\n",
      "Epoch 551/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0019 - val_loss: 0.0060\n",
      "Epoch 552/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0055\n",
      "Epoch 553/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0065\n",
      "Epoch 554/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0016 - val_loss: 0.0056\n",
      "Epoch 555/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0017 - val_loss: 0.0054\n",
      "Epoch 556/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0057\n",
      "Epoch 557/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0073\n",
      "Epoch 558/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0054\n",
      "Epoch 559/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0059\n",
      "Epoch 560/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0060\n",
      "Epoch 561/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0057\n",
      "Epoch 562/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0055\n",
      "Epoch 563/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0057\n",
      "Epoch 564/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0016 - val_loss: 0.0065\n",
      "Epoch 565/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0018 - val_loss: 0.0056\n",
      "Epoch 566/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0016 - val_loss: 0.0067\n",
      "Epoch 567/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0019 - val_loss: 0.0065\n",
      "Epoch 568/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0053\n",
      "Epoch 569/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0056\n",
      "Epoch 570/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0063\n",
      "Epoch 571/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0016 - val_loss: 0.0073\n",
      "Epoch 572/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0019 - val_loss: 0.0055\n",
      "Epoch 573/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0058\n",
      "Epoch 574/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0015 - val_loss: 0.0052\n",
      "Epoch 575/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0020 - val_loss: 0.0054\n",
      "Epoch 576/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0027 - val_loss: 0.0063\n",
      "Epoch 577/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0097\n",
      "Epoch 578/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0050\n",
      "Epoch 579/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0052\n",
      "Epoch 580/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0022 - val_loss: 0.0056\n",
      "Epoch 581/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0076\n",
      "Epoch 582/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0026 - val_loss: 0.0049\n",
      "Epoch 583/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0022 - val_loss: 0.0057\n",
      "Epoch 584/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0051\n",
      "Epoch 585/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0018 - val_loss: 0.0052\n",
      "Epoch 586/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0019 - val_loss: 0.0047\n",
      "Epoch 587/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0015 - val_loss: 0.0060\n",
      "Epoch 588/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0052\n",
      "Epoch 589/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0057\n",
      "Epoch 590/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0026 - val_loss: 0.0058\n",
      "Epoch 591/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0066\n",
      "Epoch 592/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 0.0053\n",
      "Epoch 593/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0051\n",
      "Epoch 594/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0054\n",
      "Epoch 595/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0053\n",
      "Epoch 596/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0058\n",
      "Epoch 597/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0016 - val_loss: 0.0055\n",
      "Epoch 598/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0019 - val_loss: 0.0053\n",
      "Epoch 599/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0018 - val_loss: 0.0061\n",
      "Epoch 600/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0018 - val_loss: 0.0065\n",
      "Epoch 601/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0018 - val_loss: 0.0056\n",
      "Epoch 602/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0016 - val_loss: 0.0055\n",
      "Epoch 603/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0016 - val_loss: 0.0053\n",
      "Epoch 604/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0017 - val_loss: 0.0062\n",
      "Epoch 605/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0018 - val_loss: 0.0062\n",
      "Epoch 606/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0056\n",
      "Epoch 607/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0054\n",
      "Epoch 608/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0063\n",
      "Epoch 609/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0062\n",
      "Epoch 610/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0054\n",
      "Epoch 611/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0018 - val_loss: 0.0055\n",
      "Epoch 612/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0057\n",
      "Epoch 613/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0061\n",
      "Epoch 614/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0055\n",
      "Epoch 615/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0059\n",
      "Epoch 616/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0058\n",
      "Epoch 617/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0054\n",
      "Epoch 618/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0060\n",
      "Epoch 619/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0063\n",
      "Epoch 620/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0057\n",
      "Epoch 621/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0055\n",
      "Epoch 622/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0062\n",
      "Epoch 623/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0061\n",
      "Epoch 624/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0056\n",
      "Epoch 625/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0016 - val_loss: 0.0061\n",
      "Epoch 626/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0059\n",
      "Epoch 627/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0016 - val_loss: 0.0056\n",
      "Epoch 628/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 0.0061\n",
      "Epoch 629/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0068\n",
      "Epoch 630/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0018 - val_loss: 0.0055\n",
      "Epoch 631/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0058\n",
      "Epoch 632/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0055\n",
      "Epoch 633/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0055\n",
      "Epoch 634/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0065\n",
      "Epoch 635/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0080\n",
      "Epoch 636/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0054\n",
      "Epoch 637/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0058\n",
      "Epoch 638/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0058\n",
      "Epoch 639/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0025 - val_loss: 0.0083\n",
      "Epoch 640/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0030 - val_loss: 0.0057\n",
      "Epoch 641/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0057\n",
      "Epoch 642/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0056\n",
      "Epoch 643/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0054\n",
      "Epoch 644/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0018 - val_loss: 0.0054\n",
      "Epoch 645/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0017 - val_loss: 0.0070\n",
      "Epoch 646/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0052\n",
      "Epoch 647/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0056\n",
      "Epoch 648/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0015 - val_loss: 0.0059\n",
      "Epoch 649/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0054\n",
      "Epoch 650/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0057\n",
      "Epoch 651/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0055\n",
      "Epoch 652/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0056\n",
      "Epoch 653/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0065\n",
      "Epoch 654/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0053\n",
      "Epoch 655/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0057\n",
      "Epoch 656/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0016 - val_loss: 0.0054\n",
      "Epoch 657/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0056\n",
      "Epoch 658/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0058\n",
      "Epoch 659/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0066\n",
      "Epoch 660/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0019 - val_loss: 0.0059\n",
      "Epoch 661/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0054\n",
      "Epoch 662/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0066\n",
      "Epoch 663/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0018 - val_loss: 0.0060\n",
      "Epoch 664/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0051\n",
      "Epoch 665/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0051\n",
      "Epoch 666/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0074\n",
      "Epoch 667/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0065\n",
      "Epoch 668/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0016 - val_loss: 0.0057\n",
      "Epoch 669/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0017 - val_loss: 0.0059\n",
      "Epoch 670/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0016 - val_loss: 0.0054\n",
      "Epoch 671/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0056\n",
      "Epoch 672/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0053\n",
      "Epoch 673/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0016 - val_loss: 0.0064\n",
      "Epoch 674/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0017 - val_loss: 0.0062\n",
      "Epoch 675/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0057\n",
      "Epoch 676/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0015 - val_loss: 0.0060\n",
      "Epoch 677/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0059\n",
      "Epoch 678/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0054\n",
      "Epoch 679/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0016 - val_loss: 0.0059\n",
      "Epoch 680/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0015 - val_loss: 0.0058\n",
      "Epoch 681/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0054\n",
      "Epoch 682/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0059\n",
      "Epoch 683/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0015 - val_loss: 0.0066\n",
      "Epoch 684/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0054\n",
      "Epoch 685/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0052\n",
      "Epoch 686/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0015 - val_loss: 0.0059\n",
      "Epoch 687/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0076\n",
      "Epoch 688/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0055\n",
      "Epoch 689/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0018 - val_loss: 0.0057\n",
      "Epoch 690/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0017 - val_loss: 0.0070\n",
      "Epoch 691/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0017 - val_loss: 0.0054\n",
      "Epoch 692/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0056\n",
      "Epoch 693/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0058\n",
      "Epoch 694/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0014 - val_loss: 0.0059\n",
      "Epoch 695/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0063\n",
      "Epoch 696/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0073\n",
      "Epoch 697/1000\n",
      "143/143 [==============================] - 0s 127us/step - loss: 0.0015 - val_loss: 0.0054\n",
      "Epoch 698/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0016 - val_loss: 0.0055\n",
      "Epoch 699/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0054\n",
      "Epoch 700/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0015 - val_loss: 0.0058\n",
      "Epoch 701/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0062\n",
      "Epoch 702/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0014 - val_loss: 0.0060\n",
      "Epoch 703/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0056\n",
      "Epoch 704/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0014 - val_loss: 0.0070\n",
      "Epoch 705/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0015 - val_loss: 0.0055\n",
      "Epoch 706/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0071\n",
      "Epoch 707/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0021 - val_loss: 0.0088\n",
      "Epoch 708/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0061\n",
      "Epoch 709/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0018 - val_loss: 0.0052\n",
      "Epoch 710/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0019 - val_loss: 0.0053\n",
      "Epoch 711/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0015 - val_loss: 0.0054\n",
      "Epoch 712/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0014 - val_loss: 0.0053\n",
      "Epoch 713/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 0.0059\n",
      "Epoch 714/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0016 - val_loss: 0.0074\n",
      "Epoch 715/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0065\n",
      "Epoch 716/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0057\n",
      "Epoch 717/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0057\n",
      "Epoch 718/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0059\n",
      "Epoch 719/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0105\n",
      "Epoch 720/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0031 - val_loss: 0.0056\n",
      "Epoch 721/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0027 - val_loss: 0.0051\n",
      "Epoch 722/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0021 - val_loss: 0.0051\n",
      "Epoch 723/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0019 - val_loss: 0.0063\n",
      "Epoch 724/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0052\n",
      "Epoch 725/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0051\n",
      "Epoch 726/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0054\n",
      "Epoch 727/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0055\n",
      "Epoch 728/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0016 - val_loss: 0.0053\n",
      "Epoch 729/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0054\n",
      "Epoch 730/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0014 - val_loss: 0.0063\n",
      "Epoch 731/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0054\n",
      "Epoch 732/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0063\n",
      "Epoch 733/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0052\n",
      "Epoch 734/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0016 - val_loss: 0.0053\n",
      "Epoch 735/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0056\n",
      "Epoch 736/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0022 - val_loss: 0.0065\n",
      "Epoch 737/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0049\n",
      "Epoch 738/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0015 - val_loss: 0.0053\n",
      "Epoch 739/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0073\n",
      "Epoch 740/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0022 - val_loss: 0.0061\n",
      "Epoch 741/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0022 - val_loss: 0.0051\n",
      "Epoch 742/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0018 - val_loss: 0.0058\n",
      "Epoch 743/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0062\n",
      "Epoch 744/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0053\n",
      "Epoch 745/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0019 - val_loss: 0.0058\n",
      "Epoch 746/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0022 - val_loss: 0.0057\n",
      "Epoch 747/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0018 - val_loss: 0.0057\n",
      "Epoch 748/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0017 - val_loss: 0.0053\n",
      "Epoch 749/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0022 - val_loss: 0.0049\n",
      "Epoch 750/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0054\n",
      "Epoch 751/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0016 - val_loss: 0.0055\n",
      "Epoch 752/1000\n",
      "143/143 [==============================] - 0s 128us/step - loss: 0.0015 - val_loss: 0.0047\n",
      "Epoch 753/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0053\n",
      "Epoch 754/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0016 - val_loss: 0.0073\n",
      "Epoch 755/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0016 - val_loss: 0.0056\n",
      "Epoch 756/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0022 - val_loss: 0.0057\n",
      "Epoch 757/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0062\n",
      "Epoch 758/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0018 - val_loss: 0.0052\n",
      "Epoch 759/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0015 - val_loss: 0.0050\n",
      "Epoch 760/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0050\n",
      "Epoch 761/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0016 - val_loss: 0.0068\n",
      "Epoch 762/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0014 - val_loss: 0.0053\n",
      "Epoch 763/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0016 - val_loss: 0.0050\n",
      "Epoch 764/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0064\n",
      "Epoch 765/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0017 - val_loss: 0.0055\n",
      "Epoch 766/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0057\n",
      "Epoch 767/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0055\n",
      "Epoch 768/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0017 - val_loss: 0.0050\n",
      "Epoch 769/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0017 - val_loss: 0.0073\n",
      "Epoch 770/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0024 - val_loss: 0.0057\n",
      "Epoch 771/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0019 - val_loss: 0.0057\n",
      "Epoch 772/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0016 - val_loss: 0.0056\n",
      "Epoch 773/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 0.0058\n",
      "Epoch 774/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0053\n",
      "Epoch 775/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0064\n",
      "Epoch 776/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0053\n",
      "Epoch 777/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0054\n",
      "Epoch 778/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0062\n",
      "Epoch 779/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0016 - val_loss: 0.0056\n",
      "Epoch 780/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0014 - val_loss: 0.0054\n",
      "Epoch 781/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0014 - val_loss: 0.0060\n",
      "Epoch 782/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0015 - val_loss: 0.0058\n",
      "Epoch 783/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0015 - val_loss: 0.0052\n",
      "Epoch 784/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0052\n",
      "Epoch 785/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0015 - val_loss: 0.0055\n",
      "Epoch 786/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0068\n",
      "Epoch 787/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0018 - val_loss: 0.0055\n",
      "Epoch 788/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0016 - val_loss: 0.0051\n",
      "Epoch 789/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0058\n",
      "Epoch 790/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0016 - val_loss: 0.0063\n",
      "Epoch 791/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0052\n",
      "Epoch 792/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0057\n",
      "Epoch 793/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0064\n",
      "Epoch 794/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0056\n",
      "Epoch 795/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0013 - val_loss: 0.0057\n",
      "Epoch 796/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0014 - val_loss: 0.0060\n",
      "Epoch 797/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0056\n",
      "Epoch 798/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0057\n",
      "Epoch 799/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0065\n",
      "Epoch 800/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0016 - val_loss: 0.0059\n",
      "Epoch 801/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0015 - val_loss: 0.0060\n",
      "Epoch 802/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0014 - val_loss: 0.0056\n",
      "Epoch 803/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0058\n",
      "Epoch 804/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0052\n",
      "Epoch 805/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0013 - val_loss: 0.0063\n",
      "Epoch 806/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0052\n",
      "Epoch 807/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0013 - val_loss: 0.0061\n",
      "Epoch 808/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0056\n",
      "Epoch 809/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0055\n",
      "Epoch 810/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0019 - val_loss: 0.0059\n",
      "Epoch 811/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0021 - val_loss: 0.0097\n",
      "Epoch 812/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0031 - val_loss: 0.0054\n",
      "Epoch 813/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0026 - val_loss: 0.0053\n",
      "Epoch 814/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0023 - val_loss: 0.0050\n",
      "Epoch 815/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0020 - val_loss: 0.0064\n",
      "Epoch 816/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0018 - val_loss: 0.0049\n",
      "Epoch 817/1000\n",
      "143/143 [==============================] - 0s 129us/step - loss: 0.0021 - val_loss: 0.0044\n",
      "Epoch 818/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0016 - val_loss: 0.0060\n",
      "Epoch 819/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0017 - val_loss: 0.0066\n",
      "Epoch 820/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0018 - val_loss: 0.0049\n",
      "Epoch 821/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0053\n",
      "Epoch 822/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0015 - val_loss: 0.0066\n",
      "Epoch 823/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0052\n",
      "Epoch 824/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0049\n",
      "Epoch 825/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0068\n",
      "Epoch 826/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0055\n",
      "Epoch 827/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0051\n",
      "Epoch 828/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0017 - val_loss: 0.0055\n",
      "Epoch 829/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0069\n",
      "Epoch 830/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0052\n",
      "Epoch 831/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0049\n",
      "Epoch 832/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0073\n",
      "Epoch 833/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0024 - val_loss: 0.0049\n",
      "Epoch 834/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0021 - val_loss: 0.0046\n",
      "Epoch 835/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0052\n",
      "Epoch 836/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0014 - val_loss: 0.0055\n",
      "Epoch 837/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0014 - val_loss: 0.0051\n",
      "Epoch 838/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0048\n",
      "Epoch 839/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0054\n",
      "Epoch 840/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0013 - val_loss: 0.0061\n",
      "Epoch 841/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0052\n",
      "Epoch 842/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0016 - val_loss: 0.0054\n",
      "Epoch 843/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0015 - val_loss: 0.0053\n",
      "Epoch 844/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0063\n",
      "Epoch 845/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0055\n",
      "Epoch 846/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0054\n",
      "Epoch 847/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0057\n",
      "Epoch 848/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0064\n",
      "Epoch 849/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0052\n",
      "Epoch 850/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0014 - val_loss: 0.0053\n",
      "Epoch 851/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0015 - val_loss: 0.0072\n",
      "Epoch 852/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0018 - val_loss: 0.0055\n",
      "Epoch 853/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0015 - val_loss: 0.0053\n",
      "Epoch 854/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0057\n",
      "Epoch 855/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0051\n",
      "Epoch 856/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0049\n",
      "Epoch 857/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0017 - val_loss: 0.0058\n",
      "Epoch 858/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0054\n",
      "Epoch 859/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0057\n",
      "Epoch 860/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0057\n",
      "Epoch 861/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0050\n",
      "Epoch 862/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0016 - val_loss: 0.0055\n",
      "Epoch 863/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0054\n",
      "Epoch 864/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0014 - val_loss: 0.0055\n",
      "Epoch 865/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0014 - val_loss: 0.0058\n",
      "Epoch 866/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0054\n",
      "Epoch 867/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0013 - val_loss: 0.0054\n",
      "Epoch 868/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0053\n",
      "Epoch 869/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 0.0070\n",
      "Epoch 870/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0055\n",
      "Epoch 871/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0013 - val_loss: 0.0052\n",
      "Epoch 872/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0013 - val_loss: 0.0053\n",
      "Epoch 873/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0058\n",
      "Epoch 874/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0013 - val_loss: 0.0051\n",
      "Epoch 875/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0051\n",
      "Epoch 876/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0014 - val_loss: 0.0069\n",
      "Epoch 877/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0015 - val_loss: 0.0060\n",
      "Epoch 878/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0052\n",
      "Epoch 879/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0013 - val_loss: 0.0056\n",
      "Epoch 880/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0013 - val_loss: 0.0053\n",
      "Epoch 881/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0051\n",
      "Epoch 882/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0064\n",
      "Epoch 883/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0053\n",
      "Epoch 884/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0013 - val_loss: 0.0048\n",
      "Epoch 885/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0063\n",
      "Epoch 886/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0016 - val_loss: 0.0058\n",
      "Epoch 887/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0013 - val_loss: 0.0055\n",
      "Epoch 888/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0013 - val_loss: 0.0051\n",
      "Epoch 889/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0051\n",
      "Epoch 890/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0063\n",
      "Epoch 891/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0058\n",
      "Epoch 892/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0015 - val_loss: 0.0052\n",
      "Epoch 893/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0054\n",
      "Epoch 894/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0020 - val_loss: 0.0060\n",
      "Epoch 895/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0017 - val_loss: 0.0062\n",
      "Epoch 896/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0057\n",
      "Epoch 897/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0015 - val_loss: 0.0048\n",
      "Epoch 898/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0016 - val_loss: 0.0049\n",
      "Epoch 899/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0072\n",
      "Epoch 900/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0052\n",
      "Epoch 901/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0055\n",
      "Epoch 902/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0015 - val_loss: 0.0058\n",
      "Epoch 903/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0015 - val_loss: 0.0057\n",
      "Epoch 904/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0014 - val_loss: 0.0049\n",
      "Epoch 905/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0056\n",
      "Epoch 906/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0060\n",
      "Epoch 907/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0048\n",
      "Epoch 908/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0051\n",
      "Epoch 909/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0013 - val_loss: 0.0058\n",
      "Epoch 910/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0013 - val_loss: 0.0055\n",
      "Epoch 911/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0013 - val_loss: 0.0056\n",
      "Epoch 912/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0054\n",
      "Epoch 913/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0012 - val_loss: 0.0051\n",
      "Epoch 914/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0012 - val_loss: 0.0051\n",
      "Epoch 915/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0056\n",
      "Epoch 916/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0064\n",
      "Epoch 917/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0051\n",
      "Epoch 918/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0053\n",
      "Epoch 919/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0013 - val_loss: 0.0051\n",
      "Epoch 920/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0054\n",
      "Epoch 921/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0053\n",
      "Epoch 922/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0065\n",
      "Epoch 923/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0053\n",
      "Epoch 924/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0053\n",
      "Epoch 925/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0054\n",
      "Epoch 926/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0061\n",
      "Epoch 927/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0014 - val_loss: 0.0057\n",
      "Epoch 928/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0013 - val_loss: 0.0051\n",
      "Epoch 929/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0051\n",
      "Epoch 930/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0055\n",
      "Epoch 931/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0012 - val_loss: 0.0055\n",
      "Epoch 932/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0013 - val_loss: 0.0071\n",
      "Epoch 933/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0022 - val_loss: 0.0055\n",
      "Epoch 934/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0056\n",
      "Epoch 935/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0050\n",
      "Epoch 936/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0018 - val_loss: 0.0063\n",
      "Epoch 937/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0013 - val_loss: 0.0049\n",
      "Epoch 938/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0013 - val_loss: 0.0048\n",
      "Epoch 939/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0012 - val_loss: 0.0051\n",
      "Epoch 940/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0059\n",
      "Epoch 941/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0051\n",
      "Epoch 942/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0053\n",
      "Epoch 943/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0019 - val_loss: 0.0054\n",
      "Epoch 944/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0070\n",
      "Epoch 945/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0051\n",
      "Epoch 946/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0051\n",
      "Epoch 947/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0020 - val_loss: 0.0049\n",
      "Epoch 948/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 0.0078\n",
      "Epoch 949/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0025 - val_loss: 0.0054\n",
      "Epoch 950/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0047\n",
      "Epoch 951/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0054\n",
      "Epoch 952/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0050\n",
      "Epoch 953/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0013 - val_loss: 0.0058\n",
      "Epoch 954/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0014 - val_loss: 0.0053\n",
      "Epoch 955/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0014 - val_loss: 0.0050\n",
      "Epoch 956/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0012 - val_loss: 0.0048\n",
      "Epoch 957/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 0.0052\n",
      "Epoch 958/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 0.0052\n",
      "Epoch 959/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0056\n",
      "Epoch 960/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0013 - val_loss: 0.0061\n",
      "Epoch 961/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0053\n",
      "Epoch 962/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0013 - val_loss: 0.0052\n",
      "Epoch 963/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0057\n",
      "Epoch 964/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0014 - val_loss: 0.0052\n",
      "Epoch 965/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0013 - val_loss: 0.0055\n",
      "Epoch 966/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0050\n",
      "Epoch 967/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0055\n",
      "Epoch 968/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0012 - val_loss: 0.0052\n",
      "Epoch 969/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0014 - val_loss: 0.0052\n",
      "Epoch 970/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0012 - val_loss: 0.0064\n",
      "Epoch 971/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0053\n",
      "Epoch 972/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0012 - val_loss: 0.0052\n",
      "Epoch 973/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0012 - val_loss: 0.0054\n",
      "Epoch 974/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0012 - val_loss: 0.0053\n",
      "Epoch 975/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0050\n",
      "Epoch 976/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0012 - val_loss: 0.0050\n",
      "Epoch 977/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0011 - val_loss: 0.0056\n",
      "Epoch 978/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0014 - val_loss: 0.0060\n",
      "Epoch 979/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0013 - val_loss: 0.0049\n",
      "Epoch 980/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0012 - val_loss: 0.0048\n",
      "Epoch 981/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0054\n",
      "Epoch 982/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0011 - val_loss: 0.0054\n",
      "Epoch 983/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0011 - val_loss: 0.0055\n",
      "Epoch 984/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0011 - val_loss: 0.0048\n",
      "Epoch 985/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0013 - val_loss: 0.0055\n",
      "Epoch 986/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0054\n",
      "Epoch 987/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0056\n",
      "Epoch 988/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0052\n",
      "Epoch 989/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0011 - val_loss: 0.0053\n",
      "Epoch 990/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0012 - val_loss: 0.0051\n",
      "Epoch 991/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0015 - val_loss: 0.0051\n",
      "Epoch 992/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0016 - val_loss: 0.0068\n",
      "Epoch 993/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 115us/step - loss: 0.0014 - val_loss: 0.0058\n",
      "Epoch 994/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0045\n",
      "Epoch 995/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0049\n",
      "Epoch 996/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0013 - val_loss: 0.0050\n",
      "Epoch 997/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0047\n",
      "Epoch 998/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0052\n",
      "Epoch 999/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0057\n",
      "Epoch 1000/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0054\n",
      "0.0064208111725747585\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 7.20673800e-01, -5.06255329e-01, -1.71767280e-01,\n",
       "         -2.53437340e-01,  9.21964124e-02,  6.05357766e-01,\n",
       "          8.68049264e-02,  2.23658830e-01, -6.06232822e-01,\n",
       "         -3.03710610e-01],\n",
       "        [-4.26197141e-01,  2.68055677e-01,  1.62956104e-01,\n",
       "         -1.52625307e-01,  4.64951724e-01, -6.59884810e-01,\n",
       "         -7.22933412e-02, -4.42152709e-01, -1.58244327e-01,\n",
       "         -1.90732926e-01],\n",
       "        [-2.88230330e-01, -1.68657407e-01, -9.25236568e-02,\n",
       "         -5.78952581e-02, -3.74478161e-01, -7.91995108e-01,\n",
       "         -1.71004802e-01, -3.30248624e-01,  4.02846813e-01,\n",
       "         -1.82194095e-02],\n",
       "        [ 1.10337257e+00,  9.98816043e-02,  1.64170414e-01,\n",
       "         -4.17907566e-01,  2.02510357e-01, -6.19491696e-01,\n",
       "         -2.71853536e-01,  8.97835553e-01, -4.48642552e-01,\n",
       "         -4.38523561e-01],\n",
       "        [ 7.23150969e-02,  2.54875813e-02, -1.35496045e-02,\n",
       "         -1.85862899e-01,  2.07694024e-01, -1.33636579e-01,\n",
       "         -8.52980912e-02, -8.30966160e-02, -1.43872216e-01,\n",
       "          3.47552001e-02],\n",
       "        [-6.30771041e-01,  4.42880601e-01, -7.22625315e-01,\n",
       "          4.44896132e-01,  1.35322481e-01,  1.11275601e+00,\n",
       "          1.60660245e-03, -4.60421741e-01, -2.77803123e-01,\n",
       "          4.43336368e-01],\n",
       "        [ 5.11120856e-01,  6.63246447e-03, -4.10175860e-01,\n",
       "         -8.71348456e-02, -6.08732700e-02, -7.60141075e-01,\n",
       "          4.26961929e-01,  5.31374872e-01,  9.23617333e-02,\n",
       "          3.86294246e-01],\n",
       "        [ 4.93483484e-01, -2.93336838e-01,  3.16618443e-01,\n",
       "         -3.06968719e-01,  2.86000758e-01, -2.19590720e-02,\n",
       "         -7.03451633e-02,  5.61730623e-01, -1.64084844e-02,\n",
       "         -3.71759981e-01],\n",
       "        [ 9.26024318e-01, -9.55818519e-02, -2.27693886e-01,\n",
       "         -3.35676283e-01,  4.05302733e-01,  6.21766388e-01,\n",
       "          1.23094535e-02,  1.02308464e+00,  4.26222444e-01,\n",
       "         -3.56775194e-01],\n",
       "        [-1.42362043e-02, -2.59531498e-01,  1.87522089e+00,\n",
       "          4.86223549e-02, -2.20707715e-01, -5.99913061e-01,\n",
       "         -1.33762881e-01, -1.25373438e-01, -3.70015204e-01,\n",
       "         -1.05713516e-01],\n",
       "        [-2.94413185e-03, -3.60846311e-01,  2.27340639e-01,\n",
       "          3.75899941e-01,  6.63855523e-02,  2.47981459e-01,\n",
       "         -1.20519906e-01, -1.71909362e-01,  9.24686253e-01,\n",
       "         -5.04110977e-02],\n",
       "        [-5.77482879e-01, -1.70284808e-01,  1.06799841e+00,\n",
       "         -2.59345263e-01, -2.33091429e-01, -6.06097162e-01,\n",
       "          1.16216190e-01, -2.63270140e-02,  1.95664123e-01,\n",
       "          1.29951462e-01],\n",
       "        [-6.00385785e-01, -3.64351898e-01,  1.17820203e+00,\n",
       "         -4.45468724e-01, -5.51556408e-01,  3.09538037e-01,\n",
       "         -2.34065086e-01,  2.58863896e-01,  3.84695798e-01,\n",
       "          3.39743286e-01],\n",
       "        [ 1.18312132e+00,  6.41431138e-02, -3.06508213e-01,\n",
       "         -9.88733694e-02,  7.61419833e-01,  2.06158948e+00,\n",
       "          2.73955703e-01,  5.38411066e-02,  5.65003693e-01,\n",
       "         -7.12418258e-02],\n",
       "        [-6.59844756e-01,  1.43795758e-01,  2.73290649e-02,\n",
       "         -2.85286874e-01, -2.22390175e-01, -1.80008952e-02,\n",
       "          2.13256385e-02, -5.40351458e-02,  7.65000880e-01,\n",
       "          3.18256319e-01],\n",
       "        [-5.06099284e-01,  7.38715380e-02,  2.53592134e-01,\n",
       "         -3.62863392e-01,  4.47680831e-01,  4.40704972e-01,\n",
       "         -2.17192471e-01,  2.02500954e-01, -2.97364533e-01,\n",
       "          1.81581795e-01],\n",
       "        [ 1.04284990e+00, -1.01173721e-01, -1.84258088e-01,\n",
       "          2.66031642e-02, -5.38519144e-01, -4.35130656e-01,\n",
       "         -2.82852024e-01,  5.31826258e-01,  3.69274206e-02,\n",
       "          2.40113139e-01],\n",
       "        [ 7.26642549e-01, -1.51157081e-01,  6.55967474e-01,\n",
       "         -2.56916046e-01,  4.14237827e-01,  4.91525158e-02,\n",
       "          3.55340153e-01, -3.42243046e-01, -6.69906676e-01,\n",
       "         -3.58370543e-01],\n",
       "        [-1.63709268e-01,  4.81603816e-02, -1.54297900e+00,\n",
       "         -3.32469970e-01,  4.55173463e-01, -4.04925868e-02,\n",
       "          3.25563550e-01,  4.16191109e-02,  9.77126718e-01,\n",
       "         -2.38224432e-01],\n",
       "        [-9.26704347e-01,  8.77752006e-01,  3.15221161e-01,\n",
       "          1.13632545e-01,  7.15621412e-02, -1.47701442e-01,\n",
       "          4.00174350e-01,  4.17786151e-01,  5.68618834e-01,\n",
       "          6.10462837e-02],\n",
       "        [-7.40334272e-01,  2.24033743e-01, -1.95223689e-01,\n",
       "          9.52272862e-02, -2.39454150e-01, -1.70993996e+00,\n",
       "          2.54411668e-01, -3.54994610e-02, -2.64153361e-01,\n",
       "         -7.95127526e-02],\n",
       "        [-6.01631165e-01,  1.62462890e-01, -5.36986999e-02,\n",
       "         -2.45053917e-02,  2.60954708e-01, -5.54092407e-01,\n",
       "         -2.19673719e-02, -5.13276339e-01,  7.20670760e-01,\n",
       "         -3.54651451e-01]], dtype=float32),\n",
       " array([-0.11261798, -0.0699627 ,  0.19884118, -0.09850311, -0.11342767,\n",
       "        -0.53975815,  0.00955691,  0.02567359, -0.11434545, -0.06098253],\n",
       "       dtype=float32),\n",
       " array([[-0.42311078, -0.10003869, -0.46690875,  0.51503915,  0.20375568],\n",
       "        [-0.8132625 , -0.02652228, -0.2138645 , -0.16524646,  0.12498578],\n",
       "        [-0.70742244, -0.48924315, -0.36580172,  0.5524678 ,  0.64326984],\n",
       "        [ 0.2908688 ,  0.03101462,  0.1411483 ,  0.44546747, -0.31928644],\n",
       "        [-0.5122257 , -0.32949814,  0.22813787, -0.24328849,  0.02524429],\n",
       "        [-0.5807038 , -0.11208142,  0.11065597,  0.3180688 ,  0.5962863 ],\n",
       "        [ 0.22545631,  0.6847026 ,  0.3766861 ,  0.26431233,  0.04474764],\n",
       "        [ 0.4577236 ,  0.2686753 ,  0.12844999,  0.38555178, -0.6190986 ],\n",
       "        [-0.3720083 ,  0.29190686,  0.47438842,  0.619755  ,  0.31762815],\n",
       "        [ 0.07868998, -0.32601187, -0.12515596,  0.18483931, -0.0442414 ]],\n",
       "       dtype=float32),\n",
       " array([ 0.08954167, -0.02561089, -0.00051682,  0.00398035,  0.02421178],\n",
       "       dtype=float32),\n",
       " array([[-0.17940645],\n",
       "        [-0.05423642],\n",
       "        [ 0.07470557],\n",
       "        [ 0.2409981 ],\n",
       "        [ 0.41761422]], dtype=float32),\n",
       " array([0.07996563], dtype=float32)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_automobile, history_automobile=NN_model_structure_regression_4(X_train_automobile, X_val_automobile, Y_train_automobile, Y_val_automobile, adam2, 32, 1000)\n",
    "model_automobile.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_automobile.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_automobile_structure4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_49 (Dense)             (None, 10)                230       \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 351\n",
      "Trainable params: 351\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 143 samples, validate on 31 samples\n",
      "Epoch 1/1000\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.3298 - val_loss: 0.0415\n",
      "Epoch 2/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.1066 - val_loss: 0.0238\n",
      "Epoch 3/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0551 - val_loss: 0.0627\n",
      "Epoch 4/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0509 - val_loss: 0.0168\n",
      "Epoch 5/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0313 - val_loss: 0.0179\n",
      "Epoch 6/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0219 - val_loss: 0.0122\n",
      "Epoch 7/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0189 - val_loss: 0.0132\n",
      "Epoch 8/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0173 - val_loss: 0.0084\n",
      "Epoch 9/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0133 - val_loss: 0.0069\n",
      "Epoch 10/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0128 - val_loss: 0.0063\n",
      "Epoch 11/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0125 - val_loss: 0.0067\n",
      "Epoch 12/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0117 - val_loss: 0.0069\n",
      "Epoch 13/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0110 - val_loss: 0.0060\n",
      "Epoch 14/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0105 - val_loss: 0.0059\n",
      "Epoch 15/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0102 - val_loss: 0.0061\n",
      "Epoch 16/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0098 - val_loss: 0.0061\n",
      "Epoch 17/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0098 - val_loss: 0.0062\n",
      "Epoch 18/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0092 - val_loss: 0.0060\n",
      "Epoch 19/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0094 - val_loss: 0.0056\n",
      "Epoch 20/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0094 - val_loss: 0.0061\n",
      "Epoch 21/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0097 - val_loss: 0.0058\n",
      "Epoch 22/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0084 - val_loss: 0.0058\n",
      "Epoch 23/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0086 - val_loss: 0.0058\n",
      "Epoch 24/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0090 - val_loss: 0.0053\n",
      "Epoch 25/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0084 - val_loss: 0.0066\n",
      "Epoch 26/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0086 - val_loss: 0.0058\n",
      "Epoch 27/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0080 - val_loss: 0.0056\n",
      "Epoch 28/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0085 - val_loss: 0.0049\n",
      "Epoch 29/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0081 - val_loss: 0.0054\n",
      "Epoch 30/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0075 - val_loss: 0.0057\n",
      "Epoch 31/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0075 - val_loss: 0.0050\n",
      "Epoch 32/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0079 - val_loss: 0.0049\n",
      "Epoch 33/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0073 - val_loss: 0.0054\n",
      "Epoch 34/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0074 - val_loss: 0.0057\n",
      "Epoch 35/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0074 - val_loss: 0.0052\n",
      "Epoch 36/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0072 - val_loss: 0.0051\n",
      "Epoch 37/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0074 - val_loss: 0.0049\n",
      "Epoch 38/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0070 - val_loss: 0.0048\n",
      "Epoch 39/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0076 - val_loss: 0.0049\n",
      "Epoch 40/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0076 - val_loss: 0.0053\n",
      "Epoch 41/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0069 - val_loss: 0.0052\n",
      "Epoch 42/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0072 - val_loss: 0.0050\n",
      "Epoch 43/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0071 - val_loss: 0.0050\n",
      "Epoch 44/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0069 - val_loss: 0.0049\n",
      "Epoch 45/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0072 - val_loss: 0.0065\n",
      "Epoch 46/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0082 - val_loss: 0.0053\n",
      "Epoch 47/1000\n",
      "143/143 [==============================] - 0s 151us/step - loss: 0.0069 - val_loss: 0.0053\n",
      "Epoch 48/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0069 - val_loss: 0.0049\n",
      "Epoch 49/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0070 - val_loss: 0.0057\n",
      "Epoch 50/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0073 - val_loss: 0.0057\n",
      "Epoch 51/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0072 - val_loss: 0.0059\n",
      "Epoch 52/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0071 - val_loss: 0.0048\n",
      "Epoch 53/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0066 - val_loss: 0.0049\n",
      "Epoch 54/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0077 - val_loss: 0.0061\n",
      "Epoch 55/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0078 - val_loss: 0.0046\n",
      "Epoch 56/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0070 - val_loss: 0.0048\n",
      "Epoch 57/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0063 - val_loss: 0.0051\n",
      "Epoch 58/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0073 - val_loss: 0.0052\n",
      "Epoch 59/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0075 - val_loss: 0.0071\n",
      "Epoch 60/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0081 - val_loss: 0.0046\n",
      "Epoch 61/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0072 - val_loss: 0.0060\n",
      "Epoch 62/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0070 - val_loss: 0.0056\n",
      "Epoch 63/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0064 - val_loss: 0.0051\n",
      "Epoch 64/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0062 - val_loss: 0.0040\n",
      "Epoch 65/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0067 - val_loss: 0.0053\n",
      "Epoch 66/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0069 - val_loss: 0.0047\n",
      "Epoch 67/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0064 - val_loss: 0.0054\n",
      "Epoch 68/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0063 - val_loss: 0.0053\n",
      "Epoch 69/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 126us/step - loss: 0.0061 - val_loss: 0.0044\n",
      "Epoch 70/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0064 - val_loss: 0.0047\n",
      "Epoch 71/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0066 - val_loss: 0.0048\n",
      "Epoch 72/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0062 - val_loss: 0.0053\n",
      "Epoch 73/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0060 - val_loss: 0.0046\n",
      "Epoch 74/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0066 - val_loss: 0.0057\n",
      "Epoch 75/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0063 - val_loss: 0.0053\n",
      "Epoch 76/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0066 - val_loss: 0.0050\n",
      "Epoch 77/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0060 - val_loss: 0.0048\n",
      "Epoch 78/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0059 - val_loss: 0.0047\n",
      "Epoch 79/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0059 - val_loss: 0.0049\n",
      "Epoch 80/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0058 - val_loss: 0.0058\n",
      "Epoch 81/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0061 - val_loss: 0.0045\n",
      "Epoch 82/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0059 - val_loss: 0.0044\n",
      "Epoch 83/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0059 - val_loss: 0.0047\n",
      "Epoch 84/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0058 - val_loss: 0.0047\n",
      "Epoch 85/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0061 - val_loss: 0.0048\n",
      "Epoch 86/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0058 - val_loss: 0.0048\n",
      "Epoch 87/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0065 - val_loss: 0.0047\n",
      "Epoch 88/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0055 - val_loss: 0.0053\n",
      "Epoch 89/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0062 - val_loss: 0.0049\n",
      "Epoch 90/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0059 - val_loss: 0.0051\n",
      "Epoch 91/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0059 - val_loss: 0.0049\n",
      "Epoch 92/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0062 - val_loss: 0.0058\n",
      "Epoch 93/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0060 - val_loss: 0.0044\n",
      "Epoch 94/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0059 - val_loss: 0.0044\n",
      "Epoch 95/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0057 - val_loss: 0.0057\n",
      "Epoch 96/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0058 - val_loss: 0.0053\n",
      "Epoch 97/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0062 - val_loss: 0.0043\n",
      "Epoch 98/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0055 - val_loss: 0.0041\n",
      "Epoch 99/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0057 - val_loss: 0.0043\n",
      "Epoch 100/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0056 - val_loss: 0.0053\n",
      "Epoch 101/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0056 - val_loss: 0.0042\n",
      "Epoch 102/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0054 - val_loss: 0.0043\n",
      "Epoch 103/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0054 - val_loss: 0.0045\n",
      "Epoch 104/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0054 - val_loss: 0.0052\n",
      "Epoch 105/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0057 - val_loss: 0.0041\n",
      "Epoch 106/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 107/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0058 - val_loss: 0.0062\n",
      "Epoch 108/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0058 - val_loss: 0.0050\n",
      "Epoch 109/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0054 - val_loss: 0.0051\n",
      "Epoch 110/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0053 - val_loss: 0.0043\n",
      "Epoch 111/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 112/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0061 - val_loss: 0.0055\n",
      "Epoch 113/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0057 - val_loss: 0.0051\n",
      "Epoch 114/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0058 - val_loss: 0.0049\n",
      "Epoch 115/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0041\n",
      "Epoch 116/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0051 - val_loss: 0.0042\n",
      "Epoch 117/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0052 - val_loss: 0.0058\n",
      "Epoch 118/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0057 - val_loss: 0.0048\n",
      "Epoch 119/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0056 - val_loss: 0.0042\n",
      "Epoch 120/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0052 - val_loss: 0.0052\n",
      "Epoch 121/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0050\n",
      "Epoch 122/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0050 - val_loss: 0.0045\n",
      "Epoch 123/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0047\n",
      "Epoch 124/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0047\n",
      "Epoch 125/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0047\n",
      "Epoch 126/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0054 - val_loss: 0.0056\n",
      "Epoch 127/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0050\n",
      "Epoch 128/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0062 - val_loss: 0.0046\n",
      "Epoch 129/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0045\n",
      "Epoch 130/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0047 - val_loss: 0.0046\n",
      "Epoch 131/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 132/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0047 - val_loss: 0.0043\n",
      "Epoch 133/1000\n",
      "143/143 [==============================] - 0s 127us/step - loss: 0.0047 - val_loss: 0.0038\n",
      "Epoch 134/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0049\n",
      "Epoch 135/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0050 - val_loss: 0.0049\n",
      "Epoch 136/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0051 - val_loss: 0.0039\n",
      "Epoch 137/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0051 - val_loss: 0.0042\n",
      "Epoch 138/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 139/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0051 - val_loss: 0.0063\n",
      "Epoch 140/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0057 - val_loss: 0.0046\n",
      "Epoch 141/1000\n",
      "143/143 [==============================] - 0s 127us/step - loss: 0.0048 - val_loss: 0.0045\n",
      "Epoch 142/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 143/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0047 - val_loss: 0.0041\n",
      "Epoch 144/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0049 - val_loss: 0.0039\n",
      "Epoch 145/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0048 - val_loss: 0.0054\n",
      "Epoch 146/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0052 - val_loss: 0.0058\n",
      "Epoch 147/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0045 - val_loss: 0.0071\n",
      "Epoch 148/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0050 - val_loss: 0.0043\n",
      "Epoch 149/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0055 - val_loss: 0.0040\n",
      "Epoch 150/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0042\n",
      "Epoch 151/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 152/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0043 - val_loss: 0.0041\n",
      "Epoch 153/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0045\n",
      "Epoch 154/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0045 - val_loss: 0.0057\n",
      "Epoch 155/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 156/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0048 - val_loss: 0.0060\n",
      "Epoch 157/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0062 - val_loss: 0.0069\n",
      "Epoch 158/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0055 - val_loss: 0.0045\n",
      "Epoch 159/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0046 - val_loss: 0.0043\n",
      "Epoch 160/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0042 - val_loss: 0.0045\n",
      "Epoch 161/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 162/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0049 - val_loss: 0.0042\n",
      "Epoch 163/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0045 - val_loss: 0.0047\n",
      "Epoch 164/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0044\n",
      "Epoch 165/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0043 - val_loss: 0.0038\n",
      "Epoch 166/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 167/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0039 - val_loss: 0.0045\n",
      "Epoch 168/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0040 - val_loss: 0.0044\n",
      "Epoch 169/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 170/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0048\n",
      "Epoch 171/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0042 - val_loss: 0.0045\n",
      "Epoch 172/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 173/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 174/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 175/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 176/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 177/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0042 - val_loss: 0.0049\n",
      "Epoch 178/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 179/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 180/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 181/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0038 - val_loss: 0.0041\n",
      "Epoch 182/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0042\n",
      "Epoch 183/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0037 - val_loss: 0.0043\n",
      "Epoch 184/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0043 - val_loss: 0.0035\n",
      "Epoch 185/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0047\n",
      "Epoch 186/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0044 - val_loss: 0.0087\n",
      "Epoch 187/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0044 - val_loss: 0.0041\n",
      "Epoch 188/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0042 - val_loss: 0.0038\n",
      "Epoch 189/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0044\n",
      "Epoch 190/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0036 - val_loss: 0.0039\n",
      "Epoch 191/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 192/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 193/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0040\n",
      "Epoch 194/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0034 - val_loss: 0.0040\n",
      "Epoch 195/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 196/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 197/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0040\n",
      "Epoch 198/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 199/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0040 - val_loss: 0.0054\n",
      "Epoch 200/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 201/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 202/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 203/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 204/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0041\n",
      "Epoch 205/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0034 - val_loss: 0.0048\n",
      "Epoch 206/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 207/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0036 - val_loss: 0.0060\n",
      "Epoch 208/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0043\n",
      "Epoch 209/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0066\n",
      "Epoch 210/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0051 - val_loss: 0.0050\n",
      "Epoch 211/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0040 - val_loss: 0.0056\n",
      "Epoch 212/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0048 - val_loss: 0.0038\n",
      "Epoch 213/1000\n",
      "143/143 [==============================] - 0s 129us/step - loss: 0.0047 - val_loss: 0.0068\n",
      "Epoch 214/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0056 - val_loss: 0.0053\n",
      "Epoch 215/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0040 - val_loss: 0.0037\n",
      "Epoch 216/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 217/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0041 - val_loss: 0.0060\n",
      "Epoch 218/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0035 - val_loss: 0.0053\n",
      "Epoch 219/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0048 - val_loss: 0.0036\n",
      "Epoch 220/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0040 - val_loss: 0.0053\n",
      "Epoch 221/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0045 - val_loss: 0.0052\n",
      "Epoch 222/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0046 - val_loss: 0.0044\n",
      "Epoch 223/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 118us/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 224/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 225/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0040\n",
      "Epoch 226/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0039\n",
      "Epoch 227/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0032 - val_loss: 0.0041\n",
      "Epoch 228/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0031 - val_loss: 0.0039\n",
      "Epoch 229/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 230/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0032 - val_loss: 0.0056\n",
      "Epoch 231/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 232/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 233/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0032 - val_loss: 0.0039\n",
      "Epoch 234/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0033 - val_loss: 0.0050\n",
      "Epoch 235/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0033 - val_loss: 0.0044\n",
      "Epoch 236/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0060\n",
      "Epoch 237/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0043 - val_loss: 0.0065\n",
      "Epoch 238/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0040 - val_loss: 0.0034\n",
      "Epoch 239/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0038\n",
      "Epoch 240/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0032 - val_loss: 0.0045\n",
      "Epoch 241/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0033 - val_loss: 0.0057\n",
      "Epoch 242/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 243/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0036 - val_loss: 0.0039\n",
      "Epoch 244/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0033 - val_loss: 0.0060\n",
      "Epoch 245/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 246/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 247/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0035 - val_loss: 0.0057\n",
      "Epoch 248/1000\n",
      "143/143 [==============================] - 0s 140us/step - loss: 0.0034 - val_loss: 0.0044\n",
      "Epoch 249/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0037 - val_loss: 0.0034\n",
      "Epoch 250/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0033 - val_loss: 0.0050\n",
      "Epoch 251/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0033 - val_loss: 0.0041\n",
      "Epoch 252/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0032 - val_loss: 0.0036\n",
      "Epoch 253/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.004 - 0s 154us/step - loss: 0.0031 - val_loss: 0.0058\n",
      "Epoch 254/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0039 - val_loss: 0.0037\n",
      "Epoch 255/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0033 - val_loss: 0.0045\n",
      "Epoch 256/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0034 - val_loss: 0.0049\n",
      "Epoch 257/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0028 - val_loss: 0.0037\n",
      "Epoch 258/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0030 - val_loss: 0.0044\n",
      "Epoch 259/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 260/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0029 - val_loss: 0.0037\n",
      "Epoch 261/1000\n",
      "143/143 [==============================] - 0s 147us/step - loss: 0.0028 - val_loss: 0.0051\n",
      "Epoch 262/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0031 - val_loss: 0.0039\n",
      "Epoch 263/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0030 - val_loss: 0.0039\n",
      "Epoch 264/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0030 - val_loss: 0.0038\n",
      "Epoch 265/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0028 - val_loss: 0.0038\n",
      "Epoch 266/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0040\n",
      "Epoch 267/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0029 - val_loss: 0.0048\n",
      "Epoch 268/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0035 - val_loss: 0.0043\n",
      "Epoch 269/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 270/1000\n",
      "143/143 [==============================] - 0s 202us/step - loss: 0.0030 - val_loss: 0.0038\n",
      "Epoch 271/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0030 - val_loss: 0.0050\n",
      "Epoch 272/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0039 - val_loss: 0.0038\n",
      "Epoch 273/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0037 - val_loss: 0.0049\n",
      "Epoch 274/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 275/1000\n",
      "143/143 [==============================] - 0s 167us/step - loss: 0.0033 - val_loss: 0.0040\n",
      "Epoch 276/1000\n",
      "143/143 [==============================] - 0s 174us/step - loss: 0.0031 - val_loss: 0.0034\n",
      "Epoch 277/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0031 - val_loss: 0.0039\n",
      "Epoch 278/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0030 - val_loss: 0.0062\n",
      "Epoch 279/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 280/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0031 - val_loss: 0.0036\n",
      "Epoch 281/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0030 - val_loss: 0.0043\n",
      "Epoch 282/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0033 - val_loss: 0.0057\n",
      "Epoch 283/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0032 - val_loss: 0.0040\n",
      "Epoch 284/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0028 - val_loss: 0.0040\n",
      "Epoch 285/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0030 - val_loss: 0.0047\n",
      "Epoch 286/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0029 - val_loss: 0.0035\n",
      "Epoch 287/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 288/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0027 - val_loss: 0.0033\n",
      "Epoch 289/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0027 - val_loss: 0.0054\n",
      "Epoch 290/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0029 - val_loss: 0.0038\n",
      "Epoch 291/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0031 - val_loss: 0.0037\n",
      "Epoch 292/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0029 - val_loss: 0.0044\n",
      "Epoch 293/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0029 - val_loss: 0.0046\n",
      "Epoch 294/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0039\n",
      "Epoch 295/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 296/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0042\n",
      "Epoch 297/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0025 - val_loss: 0.0041\n",
      "Epoch 298/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 299/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0025 - val_loss: 0.0037\n",
      "Epoch 300/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 301/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0023 - val_loss: 0.0038\n",
      "Epoch 302/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0024 - val_loss: 0.0033\n",
      "Epoch 303/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 304/1000\n",
      "143/143 [==============================] - 0s 130us/step - loss: 0.0028 - val_loss: 0.0073\n",
      "Epoch 305/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0038 - val_loss: 0.0037\n",
      "Epoch 306/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0031 - val_loss: 0.0039\n",
      "Epoch 307/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0045\n",
      "Epoch 308/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 309/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0025 - val_loss: 0.0039\n",
      "Epoch 310/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0043\n",
      "Epoch 311/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0036\n",
      "Epoch 312/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0042\n",
      "Epoch 313/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0039\n",
      "Epoch 314/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0037\n",
      "Epoch 315/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0043\n",
      "Epoch 316/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0037\n",
      "Epoch 317/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0039\n",
      "Epoch 318/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0024 - val_loss: 0.0038\n",
      "Epoch 319/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 320/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0024 - val_loss: 0.0034\n",
      "Epoch 321/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0037\n",
      "Epoch 322/1000\n",
      "143/143 [==============================] - 0s 342us/step - loss: 0.0022 - val_loss: 0.0033\n",
      "Epoch 323/1000\n",
      "143/143 [==============================] - 0s 195us/step - loss: 0.0024 - val_loss: 0.0036\n",
      "Epoch 324/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 325/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0024 - val_loss: 0.0046\n",
      "Epoch 326/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0028 - val_loss: 0.0060\n",
      "Epoch 327/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0028 - val_loss: 0.0037\n",
      "Epoch 328/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0036\n",
      "Epoch 329/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0038\n",
      "Epoch 330/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0022 - val_loss: 0.0039\n",
      "Epoch 331/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0035\n",
      "Epoch 332/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0041\n",
      "Epoch 333/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0039\n",
      "Epoch 334/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0032 - val_loss: 0.0063\n",
      "Epoch 335/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0050\n",
      "Epoch 336/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 337/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0026 - val_loss: 0.0034\n",
      "Epoch 338/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0042\n",
      "Epoch 339/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0030 - val_loss: 0.0051\n",
      "Epoch 340/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0039\n",
      "Epoch 341/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0036\n",
      "Epoch 342/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0022 - val_loss: 0.0037\n",
      "Epoch 343/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0054\n",
      "Epoch 344/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0027 - val_loss: 0.0040\n",
      "Epoch 345/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0038\n",
      "Epoch 346/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0035\n",
      "Epoch 347/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0042\n",
      "Epoch 348/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0046\n",
      "Epoch 349/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 350/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0024 - val_loss: 0.0036\n",
      "Epoch 351/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0033 - val_loss: 0.0047\n",
      "Epoch 352/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0032 - val_loss: 0.0051\n",
      "Epoch 353/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0037\n",
      "Epoch 354/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0027 - val_loss: 0.0043\n",
      "Epoch 355/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0068\n",
      "Epoch 356/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 357/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0024 - val_loss: 0.0039\n",
      "Epoch 358/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 359/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0069\n",
      "Epoch 360/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 361/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 362/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0023 - val_loss: 0.0040\n",
      "Epoch 363/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0022 - val_loss: 0.0037\n",
      "Epoch 364/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0035\n",
      "Epoch 365/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0023 - val_loss: 0.0043\n",
      "Epoch 366/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0036\n",
      "Epoch 367/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0031\n",
      "Epoch 368/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0020 - val_loss: 0.0046\n",
      "Epoch 369/1000\n",
      "143/143 [==============================] - 0s 130us/step - loss: 0.0022 - val_loss: 0.0035\n",
      "Epoch 370/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 371/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0034\n",
      "Epoch 372/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0033\n",
      "Epoch 373/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0042\n",
      "Epoch 374/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0044\n",
      "Epoch 375/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0040\n",
      "Epoch 376/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0024 - val_loss: 0.0034\n",
      "Epoch 377/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0032\n",
      "Epoch 378/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0040\n",
      "Epoch 379/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0043\n",
      "Epoch 380/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0036\n",
      "Epoch 381/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0025 - val_loss: 0.0038\n",
      "Epoch 382/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0039\n",
      "Epoch 383/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 384/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0043\n",
      "Epoch 385/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0065\n",
      "Epoch 386/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0033 - val_loss: 0.0050\n",
      "Epoch 387/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 388/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 389/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0026 - val_loss: 0.0044\n",
      "Epoch 390/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0025 - val_loss: 0.0044\n",
      "Epoch 391/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0020 - val_loss: 0.0039\n",
      "Epoch 392/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0028 - val_loss: 0.0042\n",
      "Epoch 393/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0040\n",
      "Epoch 394/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0021 - val_loss: 0.0033\n",
      "Epoch 395/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0046\n",
      "Epoch 396/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0033\n",
      "Epoch 397/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0022 - val_loss: 0.0033\n",
      "Epoch 398/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0020 - val_loss: 0.0047\n",
      "Epoch 399/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0033\n",
      "Epoch 400/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 401/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0023 - val_loss: 0.0039\n",
      "Epoch 402/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0035\n",
      "Epoch 403/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0032\n",
      "Epoch 404/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0039\n",
      "Epoch 405/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 0.0036\n",
      "Epoch 406/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0035\n",
      "Epoch 407/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 408/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0034\n",
      "Epoch 409/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0036\n",
      "Epoch 410/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 411/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0022 - val_loss: 0.0040\n",
      "Epoch 412/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0019 - val_loss: 0.0034\n",
      "Epoch 413/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0039\n",
      "Epoch 414/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0046\n",
      "Epoch 415/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Epoch 416/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0035\n",
      "Epoch 417/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0036\n",
      "Epoch 418/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0038\n",
      "Epoch 419/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0033\n",
      "Epoch 420/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0026 - val_loss: 0.0051\n",
      "Epoch 421/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0023 - val_loss: 0.0037\n",
      "Epoch 422/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0030\n",
      "Epoch 423/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0031\n",
      "Epoch 424/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0021 - val_loss: 0.0045\n",
      "Epoch 425/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0021 - val_loss: 0.0033\n",
      "Epoch 426/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0019 - val_loss: 0.0036\n",
      "Epoch 427/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0039\n",
      "Epoch 428/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0019 - val_loss: 0.0034\n",
      "Epoch 429/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0020 - val_loss: 0.0033\n",
      "Epoch 430/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0019 - val_loss: 0.0038\n",
      "Epoch 431/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0036\n",
      "Epoch 432/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0017 - val_loss: 0.0034\n",
      "Epoch 433/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0044\n",
      "Epoch 434/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 435/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0035\n",
      "Epoch 436/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0023 - val_loss: 0.0033\n",
      "Epoch 437/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0042\n",
      "Epoch 438/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0073\n",
      "Epoch 439/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0032\n",
      "Epoch 440/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0039\n",
      "Epoch 441/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0048\n",
      "Epoch 442/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0033\n",
      "Epoch 443/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0034\n",
      "Epoch 444/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 445/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 446/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0032\n",
      "Epoch 447/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0030\n",
      "Epoch 448/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0037\n",
      "Epoch 449/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0033\n",
      "Epoch 450/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0033\n",
      "Epoch 451/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0021 - val_loss: 0.0038\n",
      "Epoch 452/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0018 - val_loss: 0.0047\n",
      "Epoch 453/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0034\n",
      "Epoch 454/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0037\n",
      "Epoch 455/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0032\n",
      "Epoch 456/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.002 - 0s 133us/step - loss: 0.0017 - val_loss: 0.0030\n",
      "Epoch 457/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0034\n",
      "Epoch 458/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 459/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0020 - val_loss: 0.0041\n",
      "Epoch 460/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0030\n",
      "Epoch 461/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0035\n",
      "Epoch 462/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0033\n",
      "Epoch 463/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0032\n",
      "Epoch 464/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0020 - val_loss: 0.0060\n",
      "Epoch 465/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0034\n",
      "Epoch 466/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 467/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0032\n",
      "Epoch 468/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0034\n",
      "Epoch 469/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 470/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 471/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0036\n",
      "Epoch 472/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0018 - val_loss: 0.0031\n",
      "Epoch 473/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0033\n",
      "Epoch 474/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0021 - val_loss: 0.0051\n",
      "Epoch 475/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0021 - val_loss: 0.0034\n",
      "Epoch 476/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0018 - val_loss: 0.0034\n",
      "Epoch 477/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0019 - val_loss: 0.0031\n",
      "Epoch 478/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0019 - val_loss: 0.0036\n",
      "Epoch 479/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0021 - val_loss: 0.0054\n",
      "Epoch 480/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0023 - val_loss: 0.0040\n",
      "Epoch 481/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0018 - val_loss: 0.0040\n",
      "Epoch 482/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0032\n",
      "Epoch 483/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0036\n",
      "Epoch 484/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0042\n",
      "Epoch 485/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0035\n",
      "Epoch 486/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0045\n",
      "Epoch 487/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 488/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0062\n",
      "Epoch 489/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0033\n",
      "Epoch 490/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0018 - val_loss: 0.0033\n",
      "Epoch 491/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 492/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0032\n",
      "Epoch 493/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0034\n",
      "Epoch 494/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 495/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0037\n",
      "Epoch 496/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0038\n",
      "Epoch 497/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0034\n",
      "Epoch 498/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0037\n",
      "Epoch 499/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0015 - val_loss: 0.0035\n",
      "Epoch 500/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0036\n",
      "Epoch 501/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 502/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0035\n",
      "Epoch 503/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0034\n",
      "Epoch 504/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0032\n",
      "Epoch 505/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0020 - val_loss: 0.0039\n",
      "Epoch 506/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0062\n",
      "Epoch 507/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0035\n",
      "Epoch 508/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0021 - val_loss: 0.0034\n",
      "Epoch 509/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0048\n",
      "Epoch 510/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0024 - val_loss: 0.0042\n",
      "Epoch 511/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0031\n",
      "Epoch 512/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0032\n",
      "Epoch 513/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0016 - val_loss: 0.0035\n",
      "Epoch 514/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0036\n",
      "Epoch 515/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0036\n",
      "Epoch 516/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0033\n",
      "Epoch 517/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0036\n",
      "Epoch 518/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0036\n",
      "Epoch 519/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0015 - val_loss: 0.0032\n",
      "Epoch 520/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0039\n",
      "Epoch 521/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0037\n",
      "Epoch 522/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0032\n",
      "Epoch 523/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0015 - val_loss: 0.0032\n",
      "Epoch 524/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0036\n",
      "Epoch 525/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0016 - val_loss: 0.0067\n",
      "Epoch 526/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0037\n",
      "Epoch 527/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0031\n",
      "Epoch 528/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 529/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0024 - val_loss: 0.0036\n",
      "Epoch 530/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0042\n",
      "Epoch 531/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 139us/step - loss: 0.0018 - val_loss: 0.0031\n",
      "Epoch 532/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0036\n",
      "Epoch 533/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0026 - val_loss: 0.0039\n",
      "Epoch 534/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0060\n",
      "Epoch 535/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0028 - val_loss: 0.0038\n",
      "Epoch 536/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0019 - val_loss: 0.0035\n",
      "Epoch 537/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0038\n",
      "Epoch 538/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0031\n",
      "Epoch 539/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 540/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 541/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0037\n",
      "Epoch 542/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0031\n",
      "Epoch 543/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0017 - val_loss: 0.0048\n",
      "Epoch 544/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0037\n",
      "Epoch 545/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0032\n",
      "Epoch 546/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0034\n",
      "Epoch 547/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0034\n",
      "Epoch 548/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0047\n",
      "Epoch 549/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0036\n",
      "Epoch 550/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0034\n",
      "Epoch 551/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0031\n",
      "Epoch 552/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0061\n",
      "Epoch 553/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0025 - val_loss: 0.0039\n",
      "Epoch 554/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0033\n",
      "Epoch 555/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0033\n",
      "Epoch 556/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0048\n",
      "Epoch 557/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0035\n",
      "Epoch 558/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0033\n",
      "Epoch 559/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0051\n",
      "Epoch 560/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0035\n",
      "Epoch 561/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0034\n",
      "Epoch 562/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0038\n",
      "Epoch 563/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0060\n",
      "Epoch 564/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0028 - val_loss: 0.0038\n",
      "Epoch 565/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0031\n",
      "Epoch 566/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0036\n",
      "Epoch 567/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0039\n",
      "Epoch 568/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0016 - val_loss: 0.0052\n",
      "Epoch 569/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0032\n",
      "Epoch 570/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 571/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0036\n",
      "Epoch 572/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0042\n",
      "Epoch 573/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0033\n",
      "Epoch 574/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0036\n",
      "Epoch 575/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0045\n",
      "Epoch 576/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0035\n",
      "Epoch 577/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0033\n",
      "Epoch 578/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 579/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0032\n",
      "Epoch 580/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 581/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0050\n",
      "Epoch 582/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0032\n",
      "Epoch 583/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0019 - val_loss: 0.0034\n",
      "Epoch 584/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 585/1000\n",
      "143/143 [==============================] - 0s 140us/step - loss: 0.0014 - val_loss: 0.0037\n",
      "Epoch 586/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0013 - val_loss: 0.0035\n",
      "Epoch 587/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0013 - val_loss: 0.0035\n",
      "Epoch 588/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0033\n",
      "Epoch 589/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0036\n",
      "Epoch 590/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0035\n",
      "Epoch 591/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 592/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0048\n",
      "Epoch 593/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0037\n",
      "Epoch 594/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0039\n",
      "Epoch 595/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0034\n",
      "Epoch 596/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0040\n",
      "Epoch 597/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0040\n",
      "Epoch 598/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0036\n",
      "Epoch 599/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0035\n",
      "Epoch 600/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0034\n",
      "Epoch 601/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0048\n",
      "Epoch 602/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0045\n",
      "Epoch 603/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 604/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0036\n",
      "Epoch 605/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0035\n",
      "Epoch 606/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0047\n",
      "Epoch 607/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0021 - val_loss: 0.0037\n",
      "Epoch 608/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0037\n",
      "Epoch 609/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0033\n",
      "Epoch 610/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 0.0035\n",
      "Epoch 611/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0048\n",
      "Epoch 612/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0057\n",
      "Epoch 613/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0023 - val_loss: 0.0037\n",
      "Epoch 614/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0044\n",
      "Epoch 615/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0051\n",
      "Epoch 616/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0018 - val_loss: 0.0032\n",
      "Epoch 617/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0016 - val_loss: 0.0035\n",
      "Epoch 618/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0035\n",
      "Epoch 619/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0018 - val_loss: 0.0042\n",
      "Epoch 620/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 621/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0039\n",
      "Epoch 622/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0036\n",
      "Epoch 623/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 624/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 625/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 0.0035\n",
      "Epoch 626/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0038\n",
      "Epoch 627/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0035\n",
      "Epoch 628/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 629/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0036\n",
      "Epoch 630/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0013 - val_loss: 0.0037\n",
      "Epoch 631/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0035\n",
      "Epoch 632/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 633/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0015 - val_loss: 0.0039\n",
      "Epoch 634/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0037\n",
      "Epoch 635/1000\n",
      "143/143 [==============================] - 0s 127us/step - loss: 0.0014 - val_loss: 0.0036\n",
      "Epoch 636/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0015 - val_loss: 0.0034\n",
      "Epoch 637/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0033\n",
      "Epoch 638/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0039\n",
      "Epoch 639/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0013 - val_loss: 0.0037\n",
      "Epoch 640/1000\n",
      "143/143 [==============================] - 0s 129us/step - loss: 0.0015 - val_loss: 0.0037\n",
      "Epoch 641/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 642/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0038\n",
      "Epoch 643/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 644/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 645/1000\n",
      "143/143 [==============================] - 0s 188us/step - loss: 0.0015 - val_loss: 0.0037\n",
      "Epoch 646/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0016 - val_loss: 0.0034\n",
      "Epoch 647/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0036\n",
      "Epoch 648/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0036\n",
      "Epoch 649/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0035\n",
      "Epoch 650/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0036\n",
      "Epoch 651/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0038\n",
      "Epoch 652/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0036\n",
      "Epoch 653/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0035\n",
      "Epoch 654/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0038\n",
      "Epoch 655/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0012 - val_loss: 0.0040\n",
      "Epoch 656/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0018 - val_loss: 0.0038\n",
      "Epoch 657/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 658/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 659/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0038\n",
      "Epoch 660/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0035\n",
      "Epoch 661/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0045\n",
      "Epoch 662/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0052\n",
      "Epoch 663/1000\n",
      "143/143 [==============================] - 0s 147us/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 664/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0020 - val_loss: 0.0045\n",
      "Epoch 665/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0022 - val_loss: 0.0031\n",
      "Epoch 666/1000\n",
      "143/143 [==============================] - 0s 128us/step - loss: 0.0021 - val_loss: 0.0038\n",
      "Epoch 667/1000\n",
      "143/143 [==============================] - 0s 129us/step - loss: 0.0014 - val_loss: 0.0045\n",
      "Epoch 668/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0013 - val_loss: 0.0034\n",
      "Epoch 669/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 670/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0045\n",
      "Epoch 671/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0063\n",
      "Epoch 672/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0024 - val_loss: 0.0047\n",
      "Epoch 673/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0048\n",
      "Epoch 674/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0023 - val_loss: 0.0034\n",
      "Epoch 675/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0022 - val_loss: 0.0052\n",
      "Epoch 676/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0024 - val_loss: 0.0040\n",
      "Epoch 677/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0038\n",
      "Epoch 678/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0038\n",
      "Epoch 679/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0024 - val_loss: 0.0066\n",
      "Epoch 680/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0035\n",
      "Epoch 681/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0035\n",
      "Epoch 682/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 683/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0020 - val_loss: 0.0050\n",
      "Epoch 684/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0037\n",
      "Epoch 685/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0037\n",
      "Epoch 686/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0035\n",
      "Epoch 687/1000\n",
      "143/143 [==============================] - 0s 128us/step - loss: 0.0013 - val_loss: 0.0037\n",
      "Epoch 688/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0050\n",
      "Epoch 689/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0045\n",
      "Epoch 690/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0034\n",
      "Epoch 691/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0014 - val_loss: 0.0035\n",
      "Epoch 692/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0013 - val_loss: 0.0037\n",
      "Epoch 693/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0037\n",
      "Epoch 694/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0036\n",
      "Epoch 695/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0038\n",
      "Epoch 696/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0012 - val_loss: 0.0042\n",
      "Epoch 697/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0037\n",
      "Epoch 698/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0012 - val_loss: 0.0035\n",
      "Epoch 699/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0012 - val_loss: 0.0041\n",
      "Epoch 700/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0014 - val_loss: 0.0037\n",
      "Epoch 701/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0034\n",
      "Epoch 702/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0035\n",
      "Epoch 703/1000\n",
      "143/143 [==============================] - 0s 129us/step - loss: 0.0015 - val_loss: 0.0040\n",
      "Epoch 704/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 705/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0013 - val_loss: 0.0037\n",
      "Epoch 706/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 707/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0038\n",
      "Epoch 708/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0049\n",
      "Epoch 709/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0012 - val_loss: 0.0038\n",
      "Epoch 710/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0037\n",
      "Epoch 711/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 712/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0045\n",
      "Epoch 713/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0035\n",
      "Epoch 714/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0040\n",
      "Epoch 715/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 716/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 717/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0053\n",
      "Epoch 718/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0039\n",
      "Epoch 719/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0036\n",
      "Epoch 720/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0037\n",
      "Epoch 721/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 722/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 723/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0013 - val_loss: 0.0045\n",
      "Epoch 724/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0038\n",
      "Epoch 725/1000\n",
      "143/143 [==============================] - 0s 140us/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 726/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0018 - val_loss: 0.0036\n",
      "Epoch 727/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0015 - val_loss: 0.0057\n",
      "Epoch 728/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0038\n",
      "Epoch 729/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0034\n",
      "Epoch 730/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0038\n",
      "Epoch 731/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0014 - val_loss: 0.0052\n",
      "Epoch 732/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 733/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0039\n",
      "Epoch 734/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0012 - val_loss: 0.0036\n",
      "Epoch 735/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 736/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 737/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0038\n",
      "Epoch 738/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0038\n",
      "Epoch 739/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0047\n",
      "Epoch 740/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0036\n",
      "Epoch 741/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0012 - val_loss: 0.0040\n",
      "Epoch 742/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0039\n",
      "Epoch 743/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0012 - val_loss: 0.0036\n",
      "Epoch 744/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0040\n",
      "Epoch 745/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0046\n",
      "Epoch 746/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0064\n",
      "Epoch 747/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0035\n",
      "Epoch 748/1000\n",
      "143/143 [==============================] - 0s 140us/step - loss: 0.0018 - val_loss: 0.0042\n",
      "Epoch 749/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0022 - val_loss: 0.0035\n",
      "Epoch 750/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0042\n",
      "Epoch 751/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 752/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0012 - val_loss: 0.0033\n",
      "Epoch 753/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 754/1000\n",
      "143/143 [==============================] - 0s 181us/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 755/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 756/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 757/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0039\n",
      "Epoch 758/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0012 - val_loss: 0.0040\n",
      "Epoch 759/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0042\n",
      "Epoch 760/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0041\n",
      "Epoch 761/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0039\n",
      "Epoch 762/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0013 - val_loss: 0.0039\n",
      "Epoch 763/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0012 - val_loss: 0.0044\n",
      "Epoch 764/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0044\n",
      "Epoch 765/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0038\n",
      "Epoch 766/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0038\n",
      "Epoch 767/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0039\n",
      "Epoch 768/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0070\n",
      "Epoch 769/1000\n",
      "143/143 [==============================] - 0s 129us/step - loss: 0.0022 - val_loss: 0.0043\n",
      "Epoch 770/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0032\n",
      "Epoch 771/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0013 - val_loss: 0.0037\n",
      "Epoch 772/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0036\n",
      "Epoch 773/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0045\n",
      "Epoch 774/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 775/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0053\n",
      "Epoch 776/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0015 - val_loss: 0.0039\n",
      "Epoch 777/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 778/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0027 - val_loss: 0.0041\n",
      "Epoch 779/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0018 - val_loss: 0.0052\n",
      "Epoch 780/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0035\n",
      "Epoch 781/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 782/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0037\n",
      "Epoch 783/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0047\n",
      "Epoch 784/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 785/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0037\n",
      "Epoch 786/1000\n",
      "143/143 [==============================] - 0s 128us/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 787/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0050\n",
      "Epoch 788/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0036\n",
      "Epoch 789/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0038\n",
      "Epoch 790/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0040\n",
      "Epoch 791/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0040\n",
      "Epoch 792/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0039\n",
      "Epoch 793/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0012 - val_loss: 0.0041\n",
      "Epoch 794/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0011 - val_loss: 0.0039\n",
      "Epoch 795/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0042\n",
      "Epoch 796/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0012 - val_loss: 0.0047\n",
      "Epoch 797/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0048\n",
      "Epoch 798/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 799/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 800/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0035\n",
      "Epoch 801/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0039\n",
      "Epoch 802/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0047\n",
      "Epoch 803/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0013 - val_loss: 0.0044\n",
      "Epoch 804/1000\n",
      "143/143 [==============================] - 0s 172us/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 805/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0012 - val_loss: 0.0050\n",
      "Epoch 806/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 807/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 808/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 809/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0016 - val_loss: 0.0040\n",
      "Epoch 810/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 811/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0020 - val_loss: 0.0045\n",
      "Epoch 812/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0023 - val_loss: 0.0045\n",
      "Epoch 813/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0054\n",
      "Epoch 814/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0017 - val_loss: 0.0035\n",
      "Epoch 815/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0012 - val_loss: 0.0042\n",
      "Epoch 816/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0041\n",
      "Epoch 817/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0011 - val_loss: 0.0038\n",
      "Epoch 818/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0043\n",
      "Epoch 819/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0050\n",
      "Epoch 820/1000\n",
      "143/143 [==============================] - 0s 137us/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 821/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0013 - val_loss: 0.0045\n",
      "Epoch 822/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0014 - val_loss: 0.0069\n",
      "Epoch 823/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0044\n",
      "Epoch 824/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0040\n",
      "Epoch 825/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0038\n",
      "Epoch 826/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 827/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0012 - val_loss: 0.0049\n",
      "Epoch 828/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0012 - val_loss: 0.0043\n",
      "Epoch 829/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0011 - val_loss: 0.0043\n",
      "Epoch 830/1000\n",
      "143/143 [==============================] - 0s 129us/step - loss: 0.0012 - val_loss: 0.0038\n",
      "Epoch 831/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0050\n",
      "Epoch 832/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0015 - val_loss: 0.0050\n",
      "Epoch 833/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 834/1000\n",
      "143/143 [==============================] - 0s 167us/step - loss: 0.0012 - val_loss: 0.0041\n",
      "Epoch 835/1000\n",
      "143/143 [==============================] - 0s 171us/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 836/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0041\n",
      "Epoch 837/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0050\n",
      "Epoch 838/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 839/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 133us/step - loss: 0.0012 - val_loss: 0.0039\n",
      "Epoch 840/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0041\n",
      "Epoch 841/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0011 - val_loss: 0.0042\n",
      "Epoch 842/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0043\n",
      "Epoch 843/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0012 - val_loss: 0.0042\n",
      "Epoch 844/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0040\n",
      "Epoch 845/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0012 - val_loss: 0.0049\n",
      "Epoch 846/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 847/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0014 - val_loss: 0.0045\n",
      "Epoch 848/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0036\n",
      "Epoch 849/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0038\n",
      "Epoch 850/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 851/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0046\n",
      "Epoch 852/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0013 - val_loss: 0.0044\n",
      "Epoch 853/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 0.0041\n",
      "Epoch 854/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0011 - val_loss: 0.0041\n",
      "Epoch 855/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0010 - val_loss: 0.0048\n",
      "Epoch 856/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0044\n",
      "Epoch 857/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0012 - val_loss: 0.0043\n",
      "Epoch 858/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0013 - val_loss: 0.0039\n",
      "Epoch 859/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0043\n",
      "Epoch 860/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 861/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0041\n",
      "Epoch 862/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0043\n",
      "Epoch 863/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0010 - val_loss: 0.0044\n",
      "Epoch 864/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0050\n",
      "Epoch 865/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0013 - val_loss: 0.0046\n",
      "Epoch 866/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 867/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0011 - val_loss: 0.0038\n",
      "Epoch 868/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0013 - val_loss: 0.0039\n",
      "Epoch 869/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0011 - val_loss: 0.0041\n",
      "Epoch 870/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0012 - val_loss: 0.0044\n",
      "Epoch 871/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0010 - val_loss: 0.0045\n",
      "Epoch 872/1000\n",
      "143/143 [==============================] - 0s 140us/step - loss: 0.0010 - val_loss: 0.0042\n",
      "Epoch 873/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0011 - val_loss: 0.0043\n",
      "Epoch 874/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0014 - val_loss: 0.0046\n",
      "Epoch 875/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0048\n",
      "Epoch 876/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0012 - val_loss: 0.0045\n",
      "Epoch 877/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0041\n",
      "Epoch 878/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0012 - val_loss: 0.0044\n",
      "Epoch 879/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 880/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0049\n",
      "Epoch 881/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0057\n",
      "Epoch 882/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 883/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0036\n",
      "Epoch 884/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 885/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0057\n",
      "Epoch 886/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 887/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0014 - val_loss: 0.0046\n",
      "Epoch 888/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 0.0051\n",
      "Epoch 889/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 890/1000\n",
      "143/143 [==============================] - 0s 174us/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 891/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0015 - val_loss: 0.0065\n",
      "Epoch 892/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0019 - val_loss: 0.0034\n",
      "Epoch 893/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 894/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0054\n",
      "Epoch 895/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0045\n",
      "Epoch 896/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 897/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 898/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0039\n",
      "Epoch 899/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0047\n",
      "Epoch 900/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0012 - val_loss: 0.0060\n",
      "Epoch 901/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0037\n",
      "Epoch 902/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 903/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0042\n",
      "Epoch 904/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0011 - val_loss: 0.0042\n",
      "Epoch 905/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0010 - val_loss: 0.0051\n",
      "Epoch 906/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0043\n",
      "Epoch 907/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 9.9763e-04 - val_loss: 0.0042\n",
      "Epoch 908/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0040\n",
      "Epoch 909/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0012 - val_loss: 0.0044\n",
      "Epoch 910/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0052\n",
      "Epoch 911/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0014 - val_loss: 0.0049\n",
      "Epoch 912/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0011 - val_loss: 0.0042\n",
      "Epoch 913/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0040\n",
      "Epoch 914/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0014 - val_loss: 0.0047\n",
      "Epoch 915/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0039\n",
      "Epoch 916/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 917/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0058\n",
      "Epoch 918/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0048\n",
      "Epoch 919/1000\n",
      "143/143 [==============================] - 0s 140us/step - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 920/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 921/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0012 - val_loss: 0.0044\n",
      "Epoch 922/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0055\n",
      "Epoch 923/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0017 - val_loss: 0.0042\n",
      "Epoch 924/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0012 - val_loss: 0.0038\n",
      "Epoch 925/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0040\n",
      "Epoch 926/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 927/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0010 - val_loss: 0.0041\n",
      "Epoch 928/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 9.6870e-04 - val_loss: 0.0044\n",
      "Epoch 929/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0011 - val_loss: 0.0043\n",
      "Epoch 930/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0041\n",
      "Epoch 931/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0047\n",
      "Epoch 932/1000\n",
      "143/143 [==============================] - 0s 129us/step - loss: 9.9025e-04 - val_loss: 0.0043\n",
      "Epoch 933/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0012 - val_loss: 0.0044\n",
      "Epoch 934/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0011 - val_loss: 0.0042\n",
      "Epoch 935/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0010 - val_loss: 0.0043\n",
      "Epoch 936/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 9.8996e-04 - val_loss: 0.0052\n",
      "Epoch 937/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0046\n",
      "Epoch 938/1000\n",
      "143/143 [==============================] - 0s 140us/step - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 939/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0012 - val_loss: 0.0046\n",
      "Epoch 940/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0018 - val_loss: 0.0038\n",
      "Epoch 941/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0053\n",
      "Epoch 942/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0039\n",
      "Epoch 943/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0055\n",
      "Epoch 944/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0043\n",
      "Epoch 945/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0023 - val_loss: 0.0063\n",
      "Epoch 946/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0037\n",
      "Epoch 947/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Epoch 948/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 949/1000\n",
      "143/143 [==============================] - 0s 328us/step - loss: 0.0016 - val_loss: 0.0053\n",
      "Epoch 950/1000\n",
      "143/143 [==============================] - 0s 174us/step - loss: 0.0017 - val_loss: 0.0039\n",
      "Epoch 951/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0044\n",
      "Epoch 952/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0041\n",
      "Epoch 953/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0011 - val_loss: 0.0041\n",
      "Epoch 954/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0042\n",
      "Epoch 955/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0010 - val_loss: 0.0041\n",
      "Epoch 956/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 9.9029e-04 - val_loss: 0.0045\n",
      "Epoch 957/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0010 - val_loss: 0.0046\n",
      "Epoch 958/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0054\n",
      "Epoch 959/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0050\n",
      "Epoch 960/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 961/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0016 - val_loss: 0.0056\n",
      "Epoch 962/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0021 - val_loss: 0.0038\n",
      "Epoch 963/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0013 - val_loss: 0.0051\n",
      "Epoch 964/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0013 - val_loss: 0.0044\n",
      "Epoch 965/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0012 - val_loss: 0.0041\n",
      "Epoch 966/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0014 - val_loss: 0.0039\n",
      "Epoch 967/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0045\n",
      "Epoch 968/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0013 - val_loss: 0.0046\n",
      "Epoch 969/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0050\n",
      "Epoch 970/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0040\n",
      "Epoch 971/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0011 - val_loss: 0.0040\n",
      "Epoch 972/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0014 - val_loss: 0.0050\n",
      "Epoch 973/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0054\n",
      "Epoch 974/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 975/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0041\n",
      "Epoch 976/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0046\n",
      "Epoch 977/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0011 - val_loss: 0.0044\n",
      "Epoch 978/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0011 - val_loss: 0.0042\n",
      "Epoch 979/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0013 - val_loss: 0.0039\n",
      "Epoch 980/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0046\n",
      "Epoch 981/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0010 - val_loss: 0.0045\n",
      "Epoch 982/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 9.9575e-04 - val_loss: 0.0045\n",
      "Epoch 983/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0043\n",
      "Epoch 984/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0041\n",
      "Epoch 985/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0010 - val_loss: 0.0054\n",
      "Epoch 986/1000\n",
      "143/143 [==============================] - 0s 129us/step - loss: 0.0013 - val_loss: 0.0040\n",
      "Epoch 987/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0042\n",
      "Epoch 988/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0041\n",
      "Epoch 989/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0011 - val_loss: 0.0058\n",
      "Epoch 990/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0054\n",
      "Epoch 991/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0044\n",
      "Epoch 992/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0044\n",
      "Epoch 993/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0010 - val_loss: 0.0042\n",
      "Epoch 994/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0012 - val_loss: 0.0049\n",
      "Epoch 995/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 9.8161e-04 - val_loss: 0.0041\n",
      "Epoch 996/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 9.8963e-04 - val_loss: 0.0049\n",
      "Epoch 997/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0010 - val_loss: 0.0051\n",
      "Epoch 998/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0045\n",
      "Epoch 999/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 1000/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0012 - val_loss: 0.0039\n",
      "0.009712672792375088\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 3.0819517e-01,  1.9252868e-01,  2.4932690e-01, -1.3983034e-02,\n",
       "         -8.9831609e-01,  1.7871407e-01, -4.3583980e-01,  1.7268035e-01,\n",
       "          1.9031966e-01,  3.5769415e-01],\n",
       "        [-2.3768518e-02, -5.0292236e-01,  4.5423552e-01,  6.1553615e-01,\n",
       "         -2.8360093e-01, -3.5647106e-01, -5.1185107e-01, -8.3151735e-02,\n",
       "         -3.8281971e-01,  1.9003157e-02],\n",
       "        [-2.0098183e-01,  1.9330713e-01, -5.2858835e-01,  2.6283902e-01,\n",
       "          9.6761936e-01, -5.5107337e-01,  4.2783856e-01, -1.5716547e-01,\n",
       "          8.7647066e-02, -3.3642927e-01],\n",
       "        [ 6.7926002e-01, -2.9228437e-01,  8.2343715e-01,  7.4097723e-01,\n",
       "          7.9637098e-01,  6.8369053e-02,  1.4360452e-02,  6.3393301e-01,\n",
       "         -8.3496355e-02,  5.3214240e-01],\n",
       "        [-1.7533982e-01,  2.4053140e-01, -8.7647319e-01,  3.8572270e-01,\n",
       "          1.6414054e-01,  8.7323773e-01,  2.2078288e-01, -4.7912183e-01,\n",
       "          7.2972678e-02, -6.5828055e-01],\n",
       "        [ 3.1930082e-02,  5.0202620e-01, -4.3037954e-01,  5.5683339e-01,\n",
       "         -1.0893533e+00,  5.6064856e-01, -5.5082804e-01, -2.5844473e-01,\n",
       "          2.8264022e-01, -5.4413486e-01],\n",
       "        [ 1.4392653e-01, -1.2841694e-01, -2.6499504e-01, -2.1470423e-01,\n",
       "          6.6190079e-02, -2.3219797e-01, -7.2322404e-01, -2.2444594e-01,\n",
       "         -8.7460458e-01, -4.7283316e-01],\n",
       "        [-2.2313800e-01,  4.0619290e-01, -1.0702244e-01,  1.8944679e-01,\n",
       "          2.9667962e-01,  5.2856618e-01,  1.1085889e-02,  1.7371978e-01,\n",
       "         -8.2332897e-01,  3.1527635e-01],\n",
       "        [-3.6591291e-01,  6.3835144e-01, -1.0430030e+00,  5.4093379e-01,\n",
       "          4.0556571e-01,  1.3626662e+00, -2.4613830e-01,  3.4704234e-02,\n",
       "         -1.3875133e-02,  1.2391789e-01],\n",
       "        [ 3.3150244e-01, -2.4422117e-01,  6.1017257e-01, -6.7757052e-01,\n",
       "         -3.8250563e-01, -1.6561678e-01, -5.1475191e-01, -5.9654374e-02,\n",
       "         -8.9400452e-01, -6.1593212e-02],\n",
       "        [ 1.8605720e-01, -1.8951023e-01, -6.3407183e-01, -1.9691983e-01,\n",
       "         -9.5566750e-02,  1.2433262e+00,  1.4032738e-01, -1.7646858e-01,\n",
       "         -2.9547453e-01,  5.0650924e-02],\n",
       "        [-1.2222558e-01,  1.5399420e-01,  1.2941372e+00, -5.0284982e-01,\n",
       "         -1.7475814e-01,  3.4737647e-01,  2.0899994e+00, -1.5105547e-01,\n",
       "          7.0580381e-01, -3.9052910e-01],\n",
       "        [-3.1070060e-01, -2.0711400e-01,  7.2899777e-01, -1.6440022e-01,\n",
       "         -6.0201710e-01,  4.0791887e-01, -2.8353276e-02, -3.6958358e-01,\n",
       "         -7.1952365e-02, -4.9065694e-01],\n",
       "        [ 5.1754588e-01,  9.4586164e-02, -2.0144789e-01,  9.1688752e-02,\n",
       "         -1.6628710e+00,  7.9796320e-01,  9.6079952e-01,  5.0608599e-01,\n",
       "         -1.0863813e-01,  4.2827448e-01],\n",
       "        [ 1.9845724e-02, -1.0252101e-01, -3.7053892e-01,  1.5341060e-01,\n",
       "          2.2200665e-01, -2.8200743e-01,  4.5054698e-01, -1.4221103e-01,\n",
       "          7.0524669e-01, -1.1478291e-01],\n",
       "        [ 1.6134600e-01, -5.2272320e-01,  2.7093452e-01, -5.8991283e-01,\n",
       "          3.0566332e-01, -1.0030714e-01,  1.6407587e-01,  6.1961794e-01,\n",
       "          1.2129036e-03,  5.6075805e-01],\n",
       "        [ 2.4158928e-01, -1.5221655e-01,  8.0180681e-01,  4.5330173e-01,\n",
       "          5.7566321e-01,  3.8960028e-01,  1.0395121e-01, -5.3156430e-01,\n",
       "         -4.6878532e-01,  7.7213585e-02],\n",
       "        [-3.8172430e-01, -3.8234541e-01, -7.1975607e-01,  8.2794592e-02,\n",
       "         -2.2835290e-01, -1.7880369e-02,  3.8697416e-01, -3.6961725e-01,\n",
       "          4.3377832e-01, -2.9615380e-02],\n",
       "        [-6.9833487e-01,  2.1584533e-01, -1.0198135e+00,  2.9816511e-01,\n",
       "         -7.8668937e-02,  6.0571991e-02,  5.2324057e-01, -2.3133257e-01,\n",
       "          7.0995754e-01, -2.9303932e-01],\n",
       "        [ 4.5651940e-01, -4.0844339e-01, -9.1343015e-02,  4.3172464e-01,\n",
       "          5.2772693e-02, -2.4117264e-01,  4.8496929e-01,  9.9107510e-01,\n",
       "          1.3696306e+00,  8.5392946e-01],\n",
       "        [-3.0560952e-01,  7.1881503e-02, -6.6777962e-01,  1.5837498e-02,\n",
       "          1.5749531e+00, -3.9668220e-01,  3.3683339e-01,  9.8125525e-03,\n",
       "          3.9739436e-01,  2.8717479e-01],\n",
       "        [ 3.9008665e-01, -2.5722444e-01, -1.5500930e-01,  4.4810188e-01,\n",
       "          9.4648099e-01, -2.3178853e-01,  4.8001143e-01, -4.5849171e-01,\n",
       "          4.5891505e-01, -4.7437325e-01]], dtype=float32),\n",
       " array([-0.03015263, -0.01141332, -0.07991527, -0.0202053 ,  0.53174496,\n",
       "         0.02220086,  0.10816418, -0.0690069 , -0.0889568 ,  0.01708959],\n",
       "       dtype=float32),\n",
       " array([[ 0.01486291,  0.48590446,  0.3896901 , -0.42309675,  0.07202965,\n",
       "          0.39373332, -0.12474725,  0.23379289,  0.12199931, -0.06125888],\n",
       "        [-0.46066043, -0.4610353 , -0.14701611, -0.19826193,  0.3791987 ,\n",
       "          0.07179028,  0.11153631, -0.67424953,  0.3674837 ,  0.09324849],\n",
       "        [-0.17059883, -0.45767418, -0.0488625 ,  0.22720098,  0.20073311,\n",
       "         -0.56330705,  0.50740236, -0.51146454, -0.40464187, -0.07720939],\n",
       "        [ 0.6377994 , -0.08144475,  0.02868135,  0.15857245, -0.2899558 ,\n",
       "          0.03541575,  0.0440759 , -0.05904232,  0.25606757, -0.2245152 ],\n",
       "        [-0.4542706 , -0.38032857,  0.48276415,  0.17728433,  0.09043615,\n",
       "         -0.8644419 ,  0.20209834, -0.14747493,  0.63374555,  0.24319912],\n",
       "        [-0.25268048, -0.48682225, -0.23433352,  0.24947858,  0.38850108,\n",
       "         -0.32558382,  0.27350307, -0.20504409,  0.17907037, -0.14304851],\n",
       "        [ 0.42685843,  0.32042968, -0.4381728 ,  0.12107551, -0.16169488,\n",
       "          0.82461727, -0.6246807 ,  0.00637564, -1.0409724 , -0.05578215],\n",
       "        [ 0.35814002,  0.2975777 , -0.06642753,  0.33018264, -0.00782132,\n",
       "          0.09581827, -0.40938887, -0.18211502,  0.24146098,  0.13239342],\n",
       "        [-0.6530086 , -0.06534427,  0.36061448, -0.12055984,  0.13916819,\n",
       "         -0.10932617,  0.4438156 , -0.2110417 ,  0.15015368, -0.08182639],\n",
       "        [ 0.09755725, -0.3331458 , -0.07839596,  0.29576558,  0.05956594,\n",
       "          0.07445442, -0.22956009, -0.05566177,  0.04205931, -0.22556454]],\n",
       "       dtype=float32),\n",
       " array([ 0.08626868,  0.16238032, -0.06762484, -0.01953566,  0.00044705,\n",
       "         0.04710867, -0.07146158, -0.01183326, -0.09143352,  0.00507729],\n",
       "       dtype=float32),\n",
       " array([[ 9.9502489e-02],\n",
       "        [ 4.0763189e-07],\n",
       "        [-4.4685815e-02],\n",
       "        [ 1.5902346e-02],\n",
       "        [-4.3049321e-02],\n",
       "        [ 3.5180184e-01],\n",
       "        [-1.8907550e-01],\n",
       "        [ 8.6982892e-04],\n",
       "        [-3.2423515e-02],\n",
       "        [-8.7849617e-02]], dtype=float32),\n",
       " array([0.11607556], dtype=float32)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_automobile, history_automobile=NN_model_structure_regression_5(X_train_automobile, X_val_automobile, Y_train_automobile, Y_val_automobile, adam2, 32, 1000)\n",
    "model_automobile.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_automobile.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_automobile_structure5.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_52 (Dense)             (None, 10)                230       \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 15)                165       \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 411\n",
      "Trainable params: 411\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 143 samples, validate on 31 samples\n",
      "Epoch 1/1000\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.4275 - val_loss: 0.1039\n",
      "Epoch 2/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.1174 - val_loss: 0.0215\n",
      "Epoch 3/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0708 - val_loss: 0.0197\n",
      "Epoch 4/1000\n",
      "143/143 [==============================] - 0s 135us/step - loss: 0.0459 - val_loss: 0.0499\n",
      "Epoch 5/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0518 - val_loss: 0.0210\n",
      "Epoch 6/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0333 - val_loss: 0.0169\n",
      "Epoch 7/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0201 - val_loss: 0.0116\n",
      "Epoch 8/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0167 - val_loss: 0.0064\n",
      "Epoch 9/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0166 - val_loss: 0.0054\n",
      "Epoch 10/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0123 - val_loss: 0.0068\n",
      "Epoch 11/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0124 - val_loss: 0.0064\n",
      "Epoch 12/1000\n",
      "143/143 [==============================] - 0s 142us/step - loss: 0.0112 - val_loss: 0.0070\n",
      "Epoch 13/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0109 - val_loss: 0.0056\n",
      "Epoch 14/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0106 - val_loss: 0.0054\n",
      "Epoch 15/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0102 - val_loss: 0.0060\n",
      "Epoch 16/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0099 - val_loss: 0.0056\n",
      "Epoch 17/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0098 - val_loss: 0.0055\n",
      "Epoch 18/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0101 - val_loss: 0.0051\n",
      "Epoch 19/1000\n",
      "143/143 [==============================] - 0s 140us/step - loss: 0.0106 - val_loss: 0.0046\n",
      "Epoch 20/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0094 - val_loss: 0.0064\n",
      "Epoch 21/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0101 - val_loss: 0.0055\n",
      "Epoch 22/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0093 - val_loss: 0.0067\n",
      "Epoch 23/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0090 - val_loss: 0.0048\n",
      "Epoch 24/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0088 - val_loss: 0.0059\n",
      "Epoch 25/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0087 - val_loss: 0.0049\n",
      "Epoch 26/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0086 - val_loss: 0.0055\n",
      "Epoch 27/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0085 - val_loss: 0.0049\n",
      "Epoch 28/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0084 - val_loss: 0.0055\n",
      "Epoch 29/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0082 - val_loss: 0.0056\n",
      "Epoch 30/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0083 - val_loss: 0.0053\n",
      "Epoch 31/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0081 - val_loss: 0.0050\n",
      "Epoch 32/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0081 - val_loss: 0.0050\n",
      "Epoch 33/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0081 - val_loss: 0.0052\n",
      "Epoch 34/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0083 - val_loss: 0.0059\n",
      "Epoch 35/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0080 - val_loss: 0.0052\n",
      "Epoch 36/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0079 - val_loss: 0.0052\n",
      "Epoch 37/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0082 - val_loss: 0.0047\n",
      "Epoch 38/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0087 - val_loss: 0.0053\n",
      "Epoch 39/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0080 - val_loss: 0.0054\n",
      "Epoch 40/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0078 - val_loss: 0.0053\n",
      "Epoch 41/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0080 - val_loss: 0.0051\n",
      "Epoch 42/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0083 - val_loss: 0.0052\n",
      "Epoch 43/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0091 - val_loss: 0.0054\n",
      "Epoch 44/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0086 - val_loss: 0.0047\n",
      "Epoch 45/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0096 - val_loss: 0.0048\n",
      "Epoch 46/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0093 - val_loss: 0.0055\n",
      "Epoch 47/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0078 - val_loss: 0.0049\n",
      "Epoch 48/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0078 - val_loss: 0.0065\n",
      "Epoch 49/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0081 - val_loss: 0.0048\n",
      "Epoch 50/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0070 - val_loss: 0.0068\n",
      "Epoch 51/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0085 - val_loss: 0.0060\n",
      "Epoch 52/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0090 - val_loss: 0.0058\n",
      "Epoch 53/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0087 - val_loss: 0.0047\n",
      "Epoch 54/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0076 - val_loss: 0.0057\n",
      "Epoch 55/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0078 - val_loss: 0.0052\n",
      "Epoch 56/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0074 - val_loss: 0.0047\n",
      "Epoch 57/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0072 - val_loss: 0.0055\n",
      "Epoch 58/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0073 - val_loss: 0.0049\n",
      "Epoch 59/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0073 - val_loss: 0.0053\n",
      "Epoch 60/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0074 - val_loss: 0.0054\n",
      "Epoch 61/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0073 - val_loss: 0.0051\n",
      "Epoch 62/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0071 - val_loss: 0.0053\n",
      "Epoch 63/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0072 - val_loss: 0.0051\n",
      "Epoch 64/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0070 - val_loss: 0.0064\n",
      "Epoch 65/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0078 - val_loss: 0.0058\n",
      "Epoch 66/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0081 - val_loss: 0.0059\n",
      "Epoch 67/1000\n",
      "143/143 [==============================] - 0s 135us/step - loss: 0.0081 - val_loss: 0.0052\n",
      "Epoch 68/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0079 - val_loss: 0.0053\n",
      "Epoch 69/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0078 - val_loss: 0.0049\n",
      "Epoch 70/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0073 - val_loss: 0.0051\n",
      "Epoch 71/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0069 - val_loss: 0.0050\n",
      "Epoch 72/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0069 - val_loss: 0.0047\n",
      "Epoch 73/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0069 - val_loss: 0.0048\n",
      "Epoch 74/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0069 - val_loss: 0.0056\n",
      "Epoch 75/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0071 - val_loss: 0.0049\n",
      "Epoch 76/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0067 - val_loss: 0.0061\n",
      "Epoch 77/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0071 - val_loss: 0.0049\n",
      "Epoch 78/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0075 - val_loss: 0.0054\n",
      "Epoch 79/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0069 - val_loss: 0.0043\n",
      "Epoch 80/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0068 - val_loss: 0.0053\n",
      "Epoch 81/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0067 - val_loss: 0.0048\n",
      "Epoch 82/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0066 - val_loss: 0.0058\n",
      "Epoch 83/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0070 - val_loss: 0.0055\n",
      "Epoch 84/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0067 - val_loss: 0.0050\n",
      "Epoch 85/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0065 - val_loss: 0.0047\n",
      "Epoch 86/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0065 - val_loss: 0.0047\n",
      "Epoch 87/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0064 - val_loss: 0.0054\n",
      "Epoch 88/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0067 - val_loss: 0.0050\n",
      "Epoch 89/1000\n",
      "143/143 [==============================] - 0s 140us/step - loss: 0.0067 - val_loss: 0.0055\n",
      "Epoch 90/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0064 - val_loss: 0.0048\n",
      "Epoch 91/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0067 - val_loss: 0.0066\n",
      "Epoch 92/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0074 - val_loss: 0.0050\n",
      "Epoch 93/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0064 - val_loss: 0.0053\n",
      "Epoch 94/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0063 - val_loss: 0.0046\n",
      "Epoch 95/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0066 - val_loss: 0.0042\n",
      "Epoch 96/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0065 - val_loss: 0.0045\n",
      "Epoch 97/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0065 - val_loss: 0.0048\n",
      "Epoch 98/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0064 - val_loss: 0.0045\n",
      "Epoch 99/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0063 - val_loss: 0.0045\n",
      "Epoch 100/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0061 - val_loss: 0.0054\n",
      "Epoch 101/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0064 - val_loss: 0.0052\n",
      "Epoch 102/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0064 - val_loss: 0.0060\n",
      "Epoch 103/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0064 - val_loss: 0.0044\n",
      "Epoch 104/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0062 - val_loss: 0.0050\n",
      "Epoch 105/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0062 - val_loss: 0.0052\n",
      "Epoch 106/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0061 - val_loss: 0.0048\n",
      "Epoch 107/1000\n",
      "143/143 [==============================] - 0s 140us/step - loss: 0.0060 - val_loss: 0.0051\n",
      "Epoch 108/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0060 - val_loss: 0.0054\n",
      "Epoch 109/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0064 - val_loss: 0.0053\n",
      "Epoch 110/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0073 - val_loss: 0.0046\n",
      "Epoch 111/1000\n",
      "143/143 [==============================] - 0s 137us/step - loss: 0.0062 - val_loss: 0.0054\n",
      "Epoch 112/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0065 - val_loss: 0.0047\n",
      "Epoch 113/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0061 - val_loss: 0.0043\n",
      "Epoch 114/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0059 - val_loss: 0.0046\n",
      "Epoch 115/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0057 - val_loss: 0.0049\n",
      "Epoch 116/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0060 - val_loss: 0.0061\n",
      "Epoch 117/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0065 - val_loss: 0.0044\n",
      "Epoch 118/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0062 - val_loss: 0.0044\n",
      "Epoch 119/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0062 - val_loss: 0.0051\n",
      "Epoch 120/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0060 - val_loss: 0.0043\n",
      "Epoch 121/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 122/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0059 - val_loss: 0.0044\n",
      "Epoch 123/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0058 - val_loss: 0.0044\n",
      "Epoch 124/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 125/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0058 - val_loss: 0.0043\n",
      "Epoch 126/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0056 - val_loss: 0.0053\n",
      "Epoch 127/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0067 - val_loss: 0.0048\n",
      "Epoch 128/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0060 - val_loss: 0.0053\n",
      "Epoch 129/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0054 - val_loss: 0.0046\n",
      "Epoch 130/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0058 - val_loss: 0.0042\n",
      "Epoch 131/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 132/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0054 - val_loss: 0.0043\n",
      "Epoch 133/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0054 - val_loss: 0.0046\n",
      "Epoch 134/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0054 - val_loss: 0.0051\n",
      "Epoch 135/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0056 - val_loss: 0.0045\n",
      "Epoch 136/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0040\n",
      "Epoch 137/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0060 - val_loss: 0.0043\n",
      "Epoch 138/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0055 - val_loss: 0.0054\n",
      "Epoch 139/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0058 - val_loss: 0.0053\n",
      "Epoch 140/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0057 - val_loss: 0.0041\n",
      "Epoch 141/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0057 - val_loss: 0.0047\n",
      "Epoch 142/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0056 - val_loss: 0.0053\n",
      "Epoch 143/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 144/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0060 - val_loss: 0.0050\n",
      "Epoch 145/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0060 - val_loss: 0.0058\n",
      "Epoch 146/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0063 - val_loss: 0.0046\n",
      "Epoch 147/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 148/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0054 - val_loss: 0.0042\n",
      "Epoch 149/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0051 - val_loss: 0.0038\n",
      "Epoch 150/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0051 - val_loss: 0.0049\n",
      "Epoch 151/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 152/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0061 - val_loss: 0.0042\n",
      "Epoch 153/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0057 - val_loss: 0.0051\n",
      "Epoch 154/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0054 - val_loss: 0.0048\n",
      "Epoch 155/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0053\n",
      "Epoch 156/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0059 - val_loss: 0.0041\n",
      "Epoch 157/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0056 - val_loss: 0.0064\n",
      "Epoch 158/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0054 - val_loss: 0.0044\n",
      "Epoch 159/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0050\n",
      "Epoch 160/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0051 - val_loss: 0.0048\n",
      "Epoch 161/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 162/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0060 - val_loss: 0.0054\n",
      "Epoch 163/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0055 - val_loss: 0.0068\n",
      "Epoch 164/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0059 - val_loss: 0.0042\n",
      "Epoch 165/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0057 - val_loss: 0.0045\n",
      "Epoch 166/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0051 - val_loss: 0.0065\n",
      "Epoch 167/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0057 - val_loss: 0.0038\n",
      "Epoch 168/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 169/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0058 - val_loss: 0.0057\n",
      "Epoch 170/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0055 - val_loss: 0.0044\n",
      "Epoch 171/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0053 - val_loss: 0.0040\n",
      "Epoch 172/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0040\n",
      "Epoch 173/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0038\n",
      "Epoch 174/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 175/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0049 - val_loss: 0.0057\n",
      "Epoch 176/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0053 - val_loss: 0.0042\n",
      "Epoch 177/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 178/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 179/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0042\n",
      "Epoch 180/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0042\n",
      "Epoch 181/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 182/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0047\n",
      "Epoch 183/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0047 - val_loss: 0.0046\n",
      "Epoch 184/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0046 - val_loss: 0.0041\n",
      "Epoch 185/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0045\n",
      "Epoch 186/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0047 - val_loss: 0.0044\n",
      "Epoch 187/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0044 - val_loss: 0.0039\n",
      "Epoch 188/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 189/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0054\n",
      "Epoch 190/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 191/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0058 - val_loss: 0.0046\n",
      "Epoch 192/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0044 - val_loss: 0.0063\n",
      "Epoch 193/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0053 - val_loss: 0.0044\n",
      "Epoch 194/1000\n",
      "143/143 [==============================] - 0s 130us/step - loss: 0.0048 - val_loss: 0.0048\n",
      "Epoch 195/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0049 - val_loss: 0.0054\n",
      "Epoch 196/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0056 - val_loss: 0.0059\n",
      "Epoch 197/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 198/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 199/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0046 - val_loss: 0.0043\n",
      "Epoch 200/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0044 - val_loss: 0.0040\n",
      "Epoch 201/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0045 - val_loss: 0.0050\n",
      "Epoch 202/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 203/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 204/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 205/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0044 - val_loss: 0.0042\n",
      "Epoch 206/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0043 - val_loss: 0.0042\n",
      "Epoch 207/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0041 - val_loss: 0.0045\n",
      "Epoch 208/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0053 - val_loss: 0.0053\n",
      "Epoch 209/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0043 - val_loss: 0.0041\n",
      "Epoch 210/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 211/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 212/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0044\n",
      "Epoch 213/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0043 - val_loss: 0.0045\n",
      "Epoch 214/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0043 - val_loss: 0.0042\n",
      "Epoch 215/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0040 - val_loss: 0.0052\n",
      "Epoch 216/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 217/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0042 - val_loss: 0.0041\n",
      "Epoch 218/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0048 - val_loss: 0.0057\n",
      "Epoch 219/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0059 - val_loss: 0.0046\n",
      "Epoch 220/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0073\n",
      "Epoch 221/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0055 - val_loss: 0.0064\n",
      "Epoch 222/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0047 - val_loss: 0.0043\n",
      "Epoch 223/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0041\n",
      "Epoch 224/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0042 - val_loss: 0.0040\n",
      "Epoch 225/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0046 - val_loss: 0.0041\n",
      "Epoch 226/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0050\n",
      "Epoch 227/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 228/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0040 - val_loss: 0.0049\n",
      "Epoch 229/1000\n",
      "143/143 [==============================] - 0s 130us/step - loss: 0.0040 - val_loss: 0.0046\n",
      "Epoch 230/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0050 - val_loss: 0.0042\n",
      "Epoch 231/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0039 - val_loss: 0.0041\n",
      "Epoch 232/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 233/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0038\n",
      "Epoch 234/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0039 - val_loss: 0.0036\n",
      "Epoch 235/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 236/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0045 - val_loss: 0.0055\n",
      "Epoch 237/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0052 - val_loss: 0.0086\n",
      "Epoch 238/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0056 - val_loss: 0.0038\n",
      "Epoch 239/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0045\n",
      "Epoch 240/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 241/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0041 - val_loss: 0.0054\n",
      "Epoch 242/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0041 - val_loss: 0.0045\n",
      "Epoch 243/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0042 - val_loss: 0.0038\n",
      "Epoch 244/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0038 - val_loss: 0.0052\n",
      "Epoch 245/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0039 - val_loss: 0.0037\n",
      "Epoch 246/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 247/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 248/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 249/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0037 - val_loss: 0.0054\n",
      "Epoch 250/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 251/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0040 - val_loss: 0.0049\n",
      "Epoch 252/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0040 - val_loss: 0.0037\n",
      "Epoch 253/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0039 - val_loss: 0.0033\n",
      "Epoch 254/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0037 - val_loss: 0.0058\n",
      "Epoch 255/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0036\n",
      "Epoch 256/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 257/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 258/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0035 - val_loss: 0.0042\n",
      "Epoch 259/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0035 - val_loss: 0.0055\n",
      "Epoch 260/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 261/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0036 - val_loss: 0.0042\n",
      "Epoch 262/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 263/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 264/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0036 - val_loss: 0.0078\n",
      "Epoch 265/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0052 - val_loss: 0.0042\n",
      "Epoch 266/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0045 - val_loss: 0.0039\n",
      "Epoch 267/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 268/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0038 - val_loss: 0.0048\n",
      "Epoch 269/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0043 - val_loss: 0.0074\n",
      "Epoch 270/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0061 - val_loss: 0.0045\n",
      "Epoch 271/1000\n",
      "143/143 [==============================] - 0s 129us/step - loss: 0.0031 - val_loss: 0.0047\n",
      "Epoch 272/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 273/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 274/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0038 - val_loss: 0.0040\n",
      "Epoch 275/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0036 - val_loss: 0.0039\n",
      "Epoch 276/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0032 - val_loss: 0.0036\n",
      "Epoch 277/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 278/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 279/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0110\n",
      "Epoch 280/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0065 - val_loss: 0.0036\n",
      "Epoch 281/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0039 - val_loss: 0.0032\n",
      "Epoch 282/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0048\n",
      "Epoch 283/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 284/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0032 - val_loss: 0.0036\n",
      "Epoch 285/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 286/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 287/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Epoch 288/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 289/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0034 - val_loss: 0.0066\n",
      "Epoch 290/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 291/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0040 - val_loss: 0.0037\n",
      "Epoch 292/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0040\n",
      "Epoch 293/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0038\n",
      "Epoch 294/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0030 - val_loss: 0.0044\n",
      "Epoch 295/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0069\n",
      "Epoch 296/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0051 - val_loss: 0.0045\n",
      "Epoch 297/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0055 - val_loss: 0.0046\n",
      "Epoch 298/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0057 - val_loss: 0.0113\n",
      "Epoch 299/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0053 - val_loss: 0.0037\n",
      "Epoch 300/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0046 - val_loss: 0.0035\n",
      "Epoch 301/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0069\n",
      "Epoch 302/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0036\n",
      "Epoch 303/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0035\n",
      "Epoch 304/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0040\n",
      "Epoch 305/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0043\n",
      "Epoch 306/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0062\n",
      "Epoch 307/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0046\n",
      "Epoch 308/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0032 - val_loss: 0.0046\n",
      "Epoch 309/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0041 - val_loss: 0.0056\n",
      "Epoch 310/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 311/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 312/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0042 - val_loss: 0.0074\n",
      "Epoch 313/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0034\n",
      "Epoch 314/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0038\n",
      "Epoch 315/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0037 - val_loss: 0.0049\n",
      "Epoch 316/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0036\n",
      "Epoch 317/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 318/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0033\n",
      "Epoch 319/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0047\n",
      "Epoch 320/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0029 - val_loss: 0.0037\n",
      "Epoch 321/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0027 - val_loss: 0.0038\n",
      "Epoch 322/1000\n",
      "143/143 [==============================] - 0s 131us/step - loss: 0.0027 - val_loss: 0.0037\n",
      "Epoch 323/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0038\n",
      "Epoch 324/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0072\n",
      "Epoch 325/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0042\n",
      "Epoch 326/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0027 - val_loss: 0.0039\n",
      "Epoch 327/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0042\n",
      "Epoch 328/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0026 - val_loss: 0.0041\n",
      "Epoch 329/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0026 - val_loss: 0.0050\n",
      "Epoch 330/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0033 - val_loss: 0.0049\n",
      "Epoch 331/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 332/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0056\n",
      "Epoch 333/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0039 - val_loss: 0.0047\n",
      "Epoch 334/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0031 - val_loss: 0.0036\n",
      "Epoch 335/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0028 - val_loss: 0.0040\n",
      "Epoch 336/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0026 - val_loss: 0.0045\n",
      "Epoch 337/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0029 - val_loss: 0.0051\n",
      "Epoch 338/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0041\n",
      "Epoch 339/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 340/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0026 - val_loss: 0.0044\n",
      "Epoch 341/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0040\n",
      "Epoch 342/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0041\n",
      "Epoch 343/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0028 - val_loss: 0.0041\n",
      "Epoch 344/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 345/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 346/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0026 - val_loss: 0.0039\n",
      "Epoch 347/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0028 - val_loss: 0.0037\n",
      "Epoch 348/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0041\n",
      "Epoch 349/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0025 - val_loss: 0.0041\n",
      "Epoch 350/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0028 - val_loss: 0.0039\n",
      "Epoch 351/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0026 - val_loss: 0.0037\n",
      "Epoch 352/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0023 - val_loss: 0.0048\n",
      "Epoch 353/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 354/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0037\n",
      "Epoch 355/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0046\n",
      "Epoch 356/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0054\n",
      "Epoch 357/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0027 - val_loss: 0.0043\n",
      "Epoch 358/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0029 - val_loss: 0.0038\n",
      "Epoch 359/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0048\n",
      "Epoch 360/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0036 - val_loss: 0.0048\n",
      "Epoch 361/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0030 - val_loss: 0.0050\n",
      "Epoch 362/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0027 - val_loss: 0.0053\n",
      "Epoch 363/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0036 - val_loss: 0.0043\n",
      "Epoch 364/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 365/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0070\n",
      "Epoch 366/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0040 - val_loss: 0.0044\n",
      "Epoch 367/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0036\n",
      "Epoch 368/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0049\n",
      "Epoch 369/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0026 - val_loss: 0.0040\n",
      "Epoch 370/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0027 - val_loss: 0.0048\n",
      "Epoch 371/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0034 - val_loss: 0.0053\n",
      "Epoch 372/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0066\n",
      "Epoch 373/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 374/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0035 - val_loss: 0.0034\n",
      "Epoch 375/1000\n",
      "143/143 [==============================] - 0s 128us/step - loss: 0.0026 - val_loss: 0.0037\n",
      "Epoch 376/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0046\n",
      "Epoch 377/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 116us/step - loss: 0.0026 - val_loss: 0.0043\n",
      "Epoch 378/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0042\n",
      "Epoch 379/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0025 - val_loss: 0.0038\n",
      "Epoch 380/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0024 - val_loss: 0.0045\n",
      "Epoch 381/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0042\n",
      "Epoch 382/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0022 - val_loss: 0.0039\n",
      "Epoch 383/1000\n",
      "143/143 [==============================] - 0s 129us/step - loss: 0.0023 - val_loss: 0.0037\n",
      "Epoch 384/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0024 - val_loss: 0.0043\n",
      "Epoch 385/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 0.0045\n",
      "Epoch 386/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0026 - val_loss: 0.0040\n",
      "Epoch 387/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0025 - val_loss: 0.0037\n",
      "Epoch 388/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0023 - val_loss: 0.0040\n",
      "Epoch 389/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0042\n",
      "Epoch 390/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0022 - val_loss: 0.0042\n",
      "Epoch 391/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0048\n",
      "Epoch 392/1000\n",
      "143/143 [==============================] - 0s 140us/step - loss: 0.0023 - val_loss: 0.0037\n",
      "Epoch 393/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0022 - val_loss: 0.0040\n",
      "Epoch 394/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0057\n",
      "Epoch 395/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0022 - val_loss: 0.0040\n",
      "Epoch 396/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 397/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0022 - val_loss: 0.0040\n",
      "Epoch 398/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0022 - val_loss: 0.0040\n",
      "Epoch 399/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Epoch 400/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0021 - val_loss: 0.0047\n",
      "Epoch 401/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0043\n",
      "Epoch 402/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0038 - val_loss: 0.0048\n",
      "Epoch 403/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0031 - val_loss: 0.0043\n",
      "Epoch 404/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0026 - val_loss: 0.0038\n",
      "Epoch 405/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0053\n",
      "Epoch 406/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0057\n",
      "Epoch 407/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0039 - val_loss: 0.0065\n",
      "Epoch 408/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0047\n",
      "Epoch 409/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0055\n",
      "Epoch 410/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0029 - val_loss: 0.0043\n",
      "Epoch 411/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0024 - val_loss: 0.0038\n",
      "Epoch 412/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0026 - val_loss: 0.0056\n",
      "Epoch 413/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0027 - val_loss: 0.0042\n",
      "Epoch 414/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0042\n",
      "Epoch 415/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0034 - val_loss: 0.0040\n",
      "Epoch 416/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0065\n",
      "Epoch 417/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0034 - val_loss: 0.0041\n",
      "Epoch 418/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0026 - val_loss: 0.0039\n",
      "Epoch 419/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0024 - val_loss: 0.0043\n",
      "Epoch 420/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0021 - val_loss: 0.0043\n",
      "Epoch 421/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0041\n",
      "Epoch 422/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0030 - val_loss: 0.0070\n",
      "Epoch 423/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0038\n",
      "Epoch 424/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 425/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 426/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0023 - val_loss: 0.0041\n",
      "Epoch 427/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0024 - val_loss: 0.0042\n",
      "Epoch 428/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0054\n",
      "Epoch 429/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0024 - val_loss: 0.0036\n",
      "Epoch 430/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0024 - val_loss: 0.0040\n",
      "Epoch 431/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0047\n",
      "Epoch 432/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0053\n",
      "Epoch 433/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0021 - val_loss: 0.0042\n",
      "Epoch 434/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0022 - val_loss: 0.0037\n",
      "Epoch 435/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 436/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0044\n",
      "Epoch 437/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0020 - val_loss: 0.0043\n",
      "Epoch 438/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0047\n",
      "Epoch 439/1000\n",
      "143/143 [==============================] - 0s 128us/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Epoch 440/1000\n",
      "143/143 [==============================] - 0s 127us/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 441/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 442/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0019 - val_loss: 0.0042\n",
      "Epoch 443/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0054\n",
      "Epoch 444/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0042\n",
      "Epoch 445/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0070\n",
      "Epoch 446/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0044 - val_loss: 0.0037\n",
      "Epoch 447/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0031 - val_loss: 0.0070\n",
      "Epoch 448/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0030 - val_loss: 0.0043\n",
      "Epoch 449/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0047\n",
      "Epoch 450/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0033 - val_loss: 0.0052\n",
      "Epoch 451/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0024 - val_loss: 0.0045\n",
      "Epoch 452/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0023 - val_loss: 0.0039\n",
      "Epoch 453/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0045\n",
      "Epoch 454/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0044\n",
      "Epoch 455/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0020 - val_loss: 0.0045\n",
      "Epoch 456/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0050\n",
      "Epoch 457/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0024 - val_loss: 0.0042\n",
      "Epoch 458/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 459/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 0.0044\n",
      "Epoch 460/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0037\n",
      "Epoch 461/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0052\n",
      "Epoch 462/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0021 - val_loss: 0.0047\n",
      "Epoch 463/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0039\n",
      "Epoch 464/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0042\n",
      "Epoch 465/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0040\n",
      "Epoch 466/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 467/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0038\n",
      "Epoch 468/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0018 - val_loss: 0.0042\n",
      "Epoch 469/1000\n",
      "143/143 [==============================] - 0s 128us/step - loss: 0.0018 - val_loss: 0.0040\n",
      "Epoch 470/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0040\n",
      "Epoch 471/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Epoch 472/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0054\n",
      "Epoch 473/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0023 - val_loss: 0.0050\n",
      "Epoch 474/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0022 - val_loss: 0.0044\n",
      "Epoch 475/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0041\n",
      "Epoch 476/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0023 - val_loss: 0.0043\n",
      "Epoch 477/1000\n",
      "143/143 [==============================] - 0s 129us/step - loss: 0.0021 - val_loss: 0.0044\n",
      "Epoch 478/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 479/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0047\n",
      "Epoch 480/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0037\n",
      "Epoch 481/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 0.0042\n",
      "Epoch 482/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0049\n",
      "Epoch 483/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0048\n",
      "Epoch 484/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 485/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0042\n",
      "Epoch 486/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 487/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0042\n",
      "Epoch 488/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0017 - val_loss: 0.0040\n",
      "Epoch 489/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0042\n",
      "Epoch 490/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0040\n",
      "Epoch 491/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 492/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0051\n",
      "Epoch 493/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0044\n",
      "Epoch 494/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 495/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0020 - val_loss: 0.0045\n",
      "Epoch 496/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0024 - val_loss: 0.0046\n",
      "Epoch 497/1000\n",
      "143/143 [==============================] - 0s 127us/step - loss: 0.0026 - val_loss: 0.0038\n",
      "Epoch 498/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0037 - val_loss: 0.0085\n",
      "Epoch 499/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 500/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0032 - val_loss: 0.0089\n",
      "Epoch 501/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0046 - val_loss: 0.0042\n",
      "Epoch 502/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0032 - val_loss: 0.0047\n",
      "Epoch 503/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 504/1000\n",
      "143/143 [==============================] - 0s 147us/step - loss: 0.0019 - val_loss: 0.0041\n",
      "Epoch 505/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 506/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 507/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 508/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0021 - val_loss: 0.0046\n",
      "Epoch 509/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0050\n",
      "Epoch 510/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0019 - val_loss: 0.0039\n",
      "Epoch 511/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0038\n",
      "Epoch 512/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0047\n",
      "Epoch 513/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 514/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0019 - val_loss: 0.0039\n",
      "Epoch 515/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 516/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 517/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0020 - val_loss: 0.0045\n",
      "Epoch 518/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0019 - val_loss: 0.0050\n",
      "Epoch 519/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0019 - val_loss: 0.0039\n",
      "Epoch 520/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 521/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0020 - val_loss: 0.0047\n",
      "Epoch 522/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 523/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0038\n",
      "Epoch 524/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 525/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 526/1000\n",
      "143/143 [==============================] - 0s 167us/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 527/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0021 - val_loss: 0.0036\n",
      "Epoch 528/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0025 - val_loss: 0.0045\n",
      "Epoch 529/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0032 - val_loss: 0.0053\n",
      "Epoch 530/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0027 - val_loss: 0.0055\n",
      "Epoch 531/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 110us/step - loss: 0.0029 - val_loss: 0.0043\n",
      "Epoch 532/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 533/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 534/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0038\n",
      "Epoch 535/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0040\n",
      "Epoch 536/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0016 - val_loss: 0.0040\n",
      "Epoch 537/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 538/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0047\n",
      "Epoch 539/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0055\n",
      "Epoch 540/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0023 - val_loss: 0.0044\n",
      "Epoch 541/1000\n",
      "143/143 [==============================] - 0s 140us/step - loss: 0.0024 - val_loss: 0.0042\n",
      "Epoch 542/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0061\n",
      "Epoch 543/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0021 - val_loss: 0.0041\n",
      "Epoch 544/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0044\n",
      "Epoch 545/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 0.0036\n",
      "Epoch 546/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0048\n",
      "Epoch 547/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 548/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 549/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 550/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0048\n",
      "Epoch 551/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 552/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0019 - val_loss: 0.0050\n",
      "Epoch 553/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 554/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0017 - val_loss: 0.0059\n",
      "Epoch 555/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 556/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0042\n",
      "Epoch 557/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 558/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0021 - val_loss: 0.0045\n",
      "Epoch 559/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0047\n",
      "Epoch 560/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0018 - val_loss: 0.0055\n",
      "Epoch 561/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0038\n",
      "Epoch 562/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0019 - val_loss: 0.0041\n",
      "Epoch 563/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0038\n",
      "Epoch 564/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0020 - val_loss: 0.0055\n",
      "Epoch 565/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 0.0042\n",
      "Epoch 566/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0039\n",
      "Epoch 567/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0051\n",
      "Epoch 568/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0051\n",
      "Epoch 569/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0022 - val_loss: 0.0049\n",
      "Epoch 570/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0042\n",
      "Epoch 571/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0060\n",
      "Epoch 572/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0026 - val_loss: 0.0048\n",
      "Epoch 573/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0044\n",
      "Epoch 574/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0038\n",
      "Epoch 575/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0022 - val_loss: 0.0047\n",
      "Epoch 576/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0050\n",
      "Epoch 577/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0020 - val_loss: 0.0037\n",
      "Epoch 578/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0022 - val_loss: 0.0044\n",
      "Epoch 579/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0022 - val_loss: 0.0050\n",
      "Epoch 580/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0039\n",
      "Epoch 581/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 582/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 583/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 584/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 585/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0046\n",
      "Epoch 586/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 587/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0039\n",
      "Epoch 588/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 589/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 590/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0052\n",
      "Epoch 591/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 592/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 593/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0039\n",
      "Epoch 594/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0041\n",
      "Epoch 595/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0020 - val_loss: 0.0063\n",
      "Epoch 596/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0022 - val_loss: 0.0042\n",
      "Epoch 597/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0037\n",
      "Epoch 598/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 599/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 600/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 601/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0019 - val_loss: 0.0055\n",
      "Epoch 602/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0018 - val_loss: 0.0038\n",
      "Epoch 603/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 604/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 605/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0016 - val_loss: 0.0040\n",
      "Epoch 606/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0015 - val_loss: 0.0040\n",
      "Epoch 607/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 608/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0038\n",
      "Epoch 609/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 610/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0048\n",
      "Epoch 611/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0016 - val_loss: 0.0058\n",
      "Epoch 612/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0025 - val_loss: 0.0040\n",
      "Epoch 613/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 614/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0018 - val_loss: 0.0045\n",
      "Epoch 615/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0020 - val_loss: 0.0041\n",
      "Epoch 616/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 0.0038\n",
      "Epoch 617/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0047\n",
      "Epoch 618/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 619/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 620/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0014 - val_loss: 0.0050\n",
      "Epoch 621/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 622/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 623/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 624/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 625/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0040\n",
      "Epoch 626/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0038\n",
      "Epoch 627/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0050\n",
      "Epoch 628/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0049\n",
      "Epoch 629/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 630/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 631/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0047\n",
      "Epoch 632/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 633/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 634/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0054\n",
      "Epoch 635/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 636/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0042\n",
      "Epoch 637/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 638/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0038\n",
      "Epoch 639/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0025 - val_loss: 0.0040\n",
      "Epoch 640/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0069\n",
      "Epoch 641/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0024 - val_loss: 0.0044\n",
      "Epoch 642/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0044\n",
      "Epoch 643/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0039\n",
      "Epoch 644/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0049\n",
      "Epoch 645/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 646/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 647/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0020 - val_loss: 0.0035\n",
      "Epoch 648/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0066\n",
      "Epoch 649/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0037\n",
      "Epoch 650/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 651/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0019 - val_loss: 0.0042\n",
      "Epoch 652/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 653/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 654/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 655/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 656/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0047\n",
      "Epoch 657/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 658/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0037\n",
      "Epoch 659/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0049\n",
      "Epoch 660/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0047\n",
      "Epoch 661/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0049\n",
      "Epoch 662/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0040\n",
      "Epoch 663/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0054\n",
      "Epoch 664/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0018 - val_loss: 0.0042\n",
      "Epoch 665/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 666/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 667/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0051\n",
      "Epoch 668/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0018 - val_loss: 0.0060\n",
      "Epoch 669/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0020 - val_loss: 0.0040\n",
      "Epoch 670/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0038\n",
      "Epoch 671/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 672/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 673/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0056\n",
      "Epoch 674/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0022 - val_loss: 0.0041\n",
      "Epoch 675/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0038\n",
      "Epoch 676/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 677/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 678/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0057\n",
      "Epoch 679/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 680/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0042\n",
      "Epoch 681/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 682/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 683/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 684/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 685/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 686/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0052\n",
      "Epoch 687/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 688/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 689/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0047\n",
      "Epoch 690/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 691/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0039\n",
      "Epoch 692/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0046\n",
      "Epoch 693/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0054\n",
      "Epoch 694/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 695/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0053\n",
      "Epoch 696/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 697/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 698/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0044\n",
      "Epoch 699/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0049\n",
      "Epoch 700/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 701/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0047\n",
      "Epoch 702/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0016 - val_loss: 0.0037\n",
      "Epoch 703/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0047\n",
      "Epoch 704/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0067\n",
      "Epoch 705/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0039\n",
      "Epoch 706/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0015 - val_loss: 0.0039\n",
      "Epoch 707/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0046\n",
      "Epoch 708/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 709/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0018 - val_loss: 0.0046\n",
      "Epoch 710/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0053\n",
      "Epoch 711/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 712/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0017 - val_loss: 0.0042\n",
      "Epoch 713/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0017 - val_loss: 0.0039\n",
      "Epoch 714/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0041\n",
      "Epoch 715/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0021 - val_loss: 0.0053\n",
      "Epoch 716/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0016 - val_loss: 0.0047\n",
      "Epoch 717/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0036\n",
      "Epoch 718/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 719/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 720/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 721/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0012 - val_loss: 0.0043\n",
      "Epoch 722/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0041\n",
      "Epoch 723/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0042\n",
      "Epoch 724/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0013 - val_loss: 0.0040\n",
      "Epoch 725/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0057\n",
      "Epoch 726/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 727/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0015 - val_loss: 0.0039\n",
      "Epoch 728/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0012 - val_loss: 0.0045\n",
      "Epoch 729/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0042\n",
      "Epoch 730/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 731/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 732/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 0.0043\n",
      "Epoch 733/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0047\n",
      "Epoch 734/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 0.0049\n",
      "Epoch 735/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 736/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0044\n",
      "Epoch 737/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0045\n",
      "Epoch 738/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 739/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 740/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0012 - val_loss: 0.0049\n",
      "Epoch 741/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0046\n",
      "Epoch 742/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0016 - val_loss: 0.0040\n",
      "Epoch 743/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 744/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0017 - val_loss: 0.0062\n",
      "Epoch 745/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 746/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 747/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0040\n",
      "Epoch 748/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 0.0039\n",
      "Epoch 749/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0013 - val_loss: 0.0045\n",
      "Epoch 750/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 751/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0014 - val_loss: 0.0039\n",
      "Epoch 752/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0040\n",
      "Epoch 753/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0012 - val_loss: 0.0040\n",
      "Epoch 754/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0038\n",
      "Epoch 755/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 756/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0018 - val_loss: 0.0046\n",
      "Epoch 757/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0014 - val_loss: 0.0051\n",
      "Epoch 758/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 759/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 760/1000\n",
      "143/143 [==============================] - 0s 127us/step - loss: 0.0012 - val_loss: 0.0039\n",
      "Epoch 761/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0014 - val_loss: 0.0039\n",
      "Epoch 762/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0040\n",
      "Epoch 763/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0039\n",
      "Epoch 764/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0013 - val_loss: 0.0052\n",
      "Epoch 765/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0056\n",
      "Epoch 766/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0039\n",
      "Epoch 767/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0015 - val_loss: 0.0039\n",
      "Epoch 768/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0049\n",
      "Epoch 769/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0013 - val_loss: 0.0037\n",
      "Epoch 770/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 0.0037\n",
      "Epoch 771/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0040\n",
      "Epoch 772/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 773/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0047\n",
      "Epoch 774/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 775/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0011 - val_loss: 0.0044\n",
      "Epoch 776/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 777/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 778/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0013 - val_loss: 0.0046\n",
      "Epoch 779/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 0.0049\n",
      "Epoch 780/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0014 - val_loss: 0.0052\n",
      "Epoch 781/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0014 - val_loss: 0.0039\n",
      "Epoch 782/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 783/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 784/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0052\n",
      "Epoch 785/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0018 - val_loss: 0.0054\n",
      "Epoch 786/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0016 - val_loss: 0.0037\n",
      "Epoch 787/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 788/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 789/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0064\n",
      "Epoch 790/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0048\n",
      "Epoch 791/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0038\n",
      "Epoch 792/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 793/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0014 - val_loss: 0.0049\n",
      "Epoch 794/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 795/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0014 - val_loss: 0.0047\n",
      "Epoch 796/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0045\n",
      "Epoch 797/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0014 - val_loss: 0.0049\n",
      "Epoch 798/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0018 - val_loss: 0.0038\n",
      "Epoch 799/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0015 - val_loss: 0.0039\n",
      "Epoch 800/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 801/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0012 - val_loss: 0.0041\n",
      "Epoch 802/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0063\n",
      "Epoch 803/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Epoch 804/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0037\n",
      "Epoch 805/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0045\n",
      "Epoch 806/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0039\n",
      "Epoch 807/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0041\n",
      "Epoch 808/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0012 - val_loss: 0.0038\n",
      "Epoch 809/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0037\n",
      "Epoch 810/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 811/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0038\n",
      "Epoch 812/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0042\n",
      "Epoch 813/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0011 - val_loss: 0.0060\n",
      "Epoch 814/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0057\n",
      "Epoch 815/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 816/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 817/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0038\n",
      "Epoch 818/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0012 - val_loss: 0.0043\n",
      "Epoch 819/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0038\n",
      "Epoch 820/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0045\n",
      "Epoch 821/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0011 - val_loss: 0.0040\n",
      "Epoch 822/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0039\n",
      "Epoch 823/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0045\n",
      "Epoch 824/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0043\n",
      "Epoch 825/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0039\n",
      "Epoch 826/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0013 - val_loss: 0.0045\n",
      "Epoch 827/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 828/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0056\n",
      "Epoch 829/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0047\n",
      "Epoch 830/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0014 - val_loss: 0.0046\n",
      "Epoch 831/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 832/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 833/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 834/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0039\n",
      "Epoch 835/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0042\n",
      "Epoch 836/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0048\n",
      "Epoch 837/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0037\n",
      "Epoch 838/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0046\n",
      "Epoch 839/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0044\n",
      "Epoch 840/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0011 - val_loss: 0.0043\n",
      "Epoch 841/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0011 - val_loss: 0.0047\n",
      "Epoch 842/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0012 - val_loss: 0.0041\n",
      "Epoch 843/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0041\n",
      "Epoch 844/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0049\n",
      "Epoch 845/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0050\n",
      "Epoch 846/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 847/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0041\n",
      "Epoch 848/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0038\n",
      "Epoch 849/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0045\n",
      "Epoch 850/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0044\n",
      "Epoch 851/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0044\n",
      "Epoch 852/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0048\n",
      "Epoch 853/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0012 - val_loss: 0.0042\n",
      "Epoch 854/1000\n",
      "143/143 [==============================] - 0s 142us/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 855/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 856/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0014 - val_loss: 0.0049\n",
      "Epoch 857/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0010 - val_loss: 0.0040\n",
      "Epoch 858/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0012 - val_loss: 0.0040\n",
      "Epoch 859/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0037\n",
      "Epoch 860/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0012 - val_loss: 0.0043\n",
      "Epoch 861/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0012 - val_loss: 0.0044\n",
      "Epoch 862/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0011 - val_loss: 0.0038\n",
      "Epoch 863/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0010 - val_loss: 0.0045\n",
      "Epoch 864/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0053\n",
      "Epoch 865/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0012 - val_loss: 0.0042\n",
      "Epoch 866/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0010 - val_loss: 0.0042\n",
      "Epoch 867/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0043\n",
      "Epoch 868/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0042\n",
      "Epoch 869/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0015 - val_loss: 0.0046\n",
      "Epoch 870/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0018 - val_loss: 0.0042\n",
      "Epoch 871/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0024 - val_loss: 0.0048\n",
      "Epoch 872/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0047\n",
      "Epoch 873/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 874/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0039\n",
      "Epoch 875/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0013 - val_loss: 0.0038\n",
      "Epoch 876/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0012 - val_loss: 0.0052\n",
      "Epoch 877/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 0.0047\n",
      "Epoch 878/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0013 - val_loss: 0.0040\n",
      "Epoch 879/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0012 - val_loss: 0.0038\n",
      "Epoch 880/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0044\n",
      "Epoch 881/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 882/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0038\n",
      "Epoch 883/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0010 - val_loss: 0.0041\n",
      "Epoch 884/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0040\n",
      "Epoch 885/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0041\n",
      "Epoch 886/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0042\n",
      "Epoch 887/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0010 - val_loss: 0.0043\n",
      "Epoch 888/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0039\n",
      "Epoch 889/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 890/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0042\n",
      "Epoch 891/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0048\n",
      "Epoch 892/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0056\n",
      "Epoch 893/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0045\n",
      "Epoch 894/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0013 - val_loss: 0.0038\n",
      "Epoch 895/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0011 - val_loss: 0.0043\n",
      "Epoch 896/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0010 - val_loss: 0.0040\n",
      "Epoch 897/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0010 - val_loss: 0.0036\n",
      "Epoch 898/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0012 - val_loss: 0.0041\n",
      "Epoch 899/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0011 - val_loss: 0.0046\n",
      "Epoch 900/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 901/1000\n",
      "143/143 [==============================] - 0s 174us/step - loss: 0.0013 - val_loss: 0.0040\n",
      "Epoch 902/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0014 - val_loss: 0.0052\n",
      "Epoch 903/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 904/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0021 - val_loss: 0.0039\n",
      "Epoch 905/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 906/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0012 - val_loss: 0.0043\n",
      "Epoch 907/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0039\n",
      "Epoch 908/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0011 - val_loss: 0.0039\n",
      "Epoch 909/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0010 - val_loss: 0.0045\n",
      "Epoch 910/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0011 - val_loss: 0.0040\n",
      "Epoch 911/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0043\n",
      "Epoch 912/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0011 - val_loss: 0.0042\n",
      "Epoch 913/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0041\n",
      "Epoch 914/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0042\n",
      "Epoch 915/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0045\n",
      "Epoch 916/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0046\n",
      "Epoch 917/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0011 - val_loss: 0.0042\n",
      "Epoch 918/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 9.9435e-04 - val_loss: 0.0041\n",
      "Epoch 919/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 920/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0056\n",
      "Epoch 921/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0061\n",
      "Epoch 922/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0021 - val_loss: 0.0042\n",
      "Epoch 923/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 924/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0013 - val_loss: 0.0036\n",
      "Epoch 925/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0013 - val_loss: 0.0044\n",
      "Epoch 926/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0014 - val_loss: 0.0045\n",
      "Epoch 927/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0015 - val_loss: 0.0037\n",
      "Epoch 928/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0014 - val_loss: 0.0038\n",
      "Epoch 929/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0047\n",
      "Epoch 930/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0044\n",
      "Epoch 931/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0011 - val_loss: 0.0041\n",
      "Epoch 932/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0012 - val_loss: 0.0039\n",
      "Epoch 933/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0044\n",
      "Epoch 934/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0036\n",
      "Epoch 935/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 9.9066e-04 - val_loss: 0.0043\n",
      "Epoch 936/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0010 - val_loss: 0.0049\n",
      "Epoch 937/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0012 - val_loss: 0.0046\n",
      "Epoch 938/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0015 - val_loss: 0.0037\n",
      "Epoch 939/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0044\n",
      "Epoch 940/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0039\n",
      "Epoch 941/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0010 - val_loss: 0.0037\n",
      "Epoch 942/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0039\n",
      "Epoch 943/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 944/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 9.8753e-04 - val_loss: 0.0040\n",
      "Epoch 945/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 9.3622e-04 - val_loss: 0.0042\n",
      "Epoch 946/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0011 - val_loss: 0.0041\n",
      "Epoch 947/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0010 - val_loss: 0.0043\n",
      "Epoch 948/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0049\n",
      "Epoch 949/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0046\n",
      "Epoch 950/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0041\n",
      "Epoch 951/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 9.6935e-04 - val_loss: 0.0039\n",
      "Epoch 952/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0042\n",
      "Epoch 953/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 954/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0049\n",
      "Epoch 955/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 956/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0014 - val_loss: 0.0038\n",
      "Epoch 957/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 958/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0011 - val_loss: 0.0043\n",
      "Epoch 959/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0012 - val_loss: 0.0048\n",
      "Epoch 960/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0015 - val_loss: 0.0048\n",
      "Epoch 961/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0040\n",
      "Epoch 962/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0010 - val_loss: 0.0049\n",
      "Epoch 963/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 964/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0037\n",
      "Epoch 965/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0040\n",
      "Epoch 966/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0043\n",
      "Epoch 967/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0014 - val_loss: 0.0057\n",
      "Epoch 968/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0048\n",
      "Epoch 969/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0011 - val_loss: 0.0039\n",
      "Epoch 970/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0035\n",
      "Epoch 971/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0046\n",
      "Epoch 972/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0059\n",
      "Epoch 973/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0018 - val_loss: 0.0045\n",
      "Epoch 974/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0038\n",
      "Epoch 975/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 976/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0047\n",
      "Epoch 977/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 978/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0057\n",
      "Epoch 979/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0052\n",
      "Epoch 980/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 981/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0040\n",
      "Epoch 982/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0014 - val_loss: 0.0038\n",
      "Epoch 983/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0045\n",
      "Epoch 984/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0048\n",
      "Epoch 985/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 986/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0038\n",
      "Epoch 987/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0036\n",
      "Epoch 988/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0011 - val_loss: 0.0047\n",
      "Epoch 989/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0040\n",
      "Epoch 990/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 9.9391e-04 - val_loss: 0.0038\n",
      "Epoch 991/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0037\n",
      "Epoch 992/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0040\n",
      "Epoch 993/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0043\n",
      "Epoch 994/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0042\n",
      "Epoch 995/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 9.3383e-04 - val_loss: 0.0041\n",
      "Epoch 996/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 9.4684e-04 - val_loss: 0.0042\n",
      "Epoch 997/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 9.8327e-04 - val_loss: 0.0039\n",
      "Epoch 998/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 8.9740e-04 - val_loss: 0.0043\n",
      "Epoch 999/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 9.6440e-04 - val_loss: 0.0039\n",
      "Epoch 1000/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 9.5475e-04 - val_loss: 0.0039\n",
      "0.007109248079359531\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 0.26568326,  0.4342506 ,  0.36667058,  0.022689  , -0.33124462,\n",
       "          0.4357042 ,  0.9735705 ,  0.25583595,  0.405627  ,  0.8572842 ],\n",
       "        [ 0.07279145, -0.06734834, -0.7621755 , -0.46524894, -0.04930552,\n",
       "         -0.8873211 ,  0.4001797 , -0.36227265,  0.7401857 ,  0.30332628],\n",
       "        [-0.16432795, -0.2833461 , -0.03923907,  0.24485503,  0.1259899 ,\n",
       "         -0.43068945, -0.16862904,  0.3329162 , -0.49666277,  0.12314925],\n",
       "        [ 1.0148062 ,  0.01562084, -0.38034132,  0.05781981,  0.17653336,\n",
       "          0.22948806,  0.9483628 ,  0.10622626, -0.69160664, -1.0884848 ],\n",
       "        [ 0.4539218 , -0.29670238,  0.4275147 , -0.58270025, -0.7091275 ,\n",
       "          0.05065642,  0.02670469,  0.25055048,  0.55591536, -0.05906231],\n",
       "        [ 0.17577617,  0.01053759,  0.11207725, -0.47418842,  0.3137868 ,\n",
       "          0.30382705,  0.49177256, -0.03913935,  0.6670395 ,  0.05760032],\n",
       "        [ 0.40890336, -0.00532622, -1.3990468 , -0.27278847,  0.07344352,\n",
       "         -0.6309691 , -0.09341969,  0.00618747, -0.09155867, -0.25192094],\n",
       "        [ 0.09769863,  0.26673657, -0.41813082, -0.25625476,  1.1139697 ,\n",
       "         -0.21046689,  0.27425164, -0.34417412,  0.13730767, -0.39602834],\n",
       "        [ 0.49499464, -0.04884449,  0.15180685, -0.54348093,  0.8072692 ,\n",
       "          1.0577224 , -0.23144081, -0.27151033, -0.0262107 , -0.92756146],\n",
       "        [-0.13636489, -0.16693968, -0.9535856 ,  0.44478258,  0.27340567,\n",
       "         -0.37835118, -0.65064704, -0.3627592 ,  0.65124035, -0.64181054],\n",
       "        [-0.48325044, -0.07984683, -0.3798898 , -0.5655832 ,  0.16102038,\n",
       "          0.5326666 , -0.44923463,  0.46503735,  0.28274173, -0.3328155 ],\n",
       "        [-1.312007  ,  0.12723842,  0.8453281 ,  1.2580563 , -0.07473349,\n",
       "         -0.2887575 ,  0.7527569 , -0.25730276,  0.11595945,  0.4738606 ],\n",
       "        [-0.588696  ,  0.02417178,  0.3412036 ,  0.19967397, -0.46616095,\n",
       "         -0.66789985,  0.5836703 , -0.02298017,  0.15114886, -0.1745925 ],\n",
       "        [-1.3749615 ,  0.39860907, -0.4071089 ,  0.37912625,  0.27917448,\n",
       "          0.990917  , -0.1109358 , -0.44817376,  0.29520112, -0.3299641 ],\n",
       "        [ 0.093652  , -0.02276044, -0.06092026, -0.62818885, -0.07691117,\n",
       "         -0.30550382, -0.33929923, -0.40772256,  0.02789998, -0.43890232],\n",
       "        [-0.10714641, -0.1550549 , -0.20329575,  0.20428762,  0.07861821,\n",
       "          0.01454957,  0.06239533, -0.02473903,  0.16859502, -0.07857303],\n",
       "        [ 0.35386086, -0.13329935,  0.289274  , -0.2956224 ,  0.12424539,\n",
       "         -0.20600174,  0.29402778, -0.16114342, -0.24219024, -0.4610748 ],\n",
       "        [-0.18402147,  0.10699803,  0.03591891,  0.14928752,  0.9955241 ,\n",
       "         -0.173552  , -0.08532392,  0.05854278, -0.5713871 , -0.6740352 ],\n",
       "        [-0.01142632, -0.48538372,  1.002719  , -0.66795546,  0.4218817 ,\n",
       "          0.5842016 , -0.25768843,  0.2123984 ,  0.7298152 , -0.83599466],\n",
       "        [ 0.17186168,  0.44257063,  0.63205147, -0.07119855, -1.0275388 ,\n",
       "          0.7282071 , -0.11860041,  0.27792594, -0.16276856, -0.20748273],\n",
       "        [-0.04796221, -0.17855996, -0.09434494,  0.117638  , -0.14821216,\n",
       "         -0.6321865 ,  0.33703318,  0.22979762, -0.25141641, -0.06187972],\n",
       "        [-0.3290127 ,  0.3795382 ,  0.33718693,  0.1426068 , -0.25760934,\n",
       "         -0.4134447 , -0.07063079,  0.2374899 , -0.7857938 , -0.5700074 ]],\n",
       "       dtype=float32),\n",
       " array([ 0.13070743,  0.01518956,  0.1176709 ,  0.16375902, -0.08471629,\n",
       "        -0.2568812 ,  0.06891455, -0.03991974,  0.06908362, -0.06372029],\n",
       "       dtype=float32),\n",
       " array([[-0.5562844 ,  0.20026793, -0.01860762,  0.46308976,  0.31104645,\n",
       "          0.20755751, -0.14382888,  0.08603131, -0.09712793,  0.20733485,\n",
       "         -0.442446  , -0.23113118, -0.02651967, -0.61030036, -0.7425598 ],\n",
       "        [-0.38375574, -0.00250147,  0.23187257,  0.530807  ,  0.1929462 ,\n",
       "          0.09296916,  0.08295383,  0.0617147 ,  0.22068775,  0.00130766,\n",
       "          0.00880556,  0.19166267, -0.21668336,  0.37782222,  0.09156763],\n",
       "        [-0.26744196, -0.40633306, -0.21072279,  0.32150987,  0.19762424,\n",
       "          0.6560344 , -0.15878648,  0.41803807,  0.2051984 ,  0.0049231 ,\n",
       "         -0.4742001 , -0.22239314, -0.04473156, -0.01565869, -0.67581767],\n",
       "        [-0.48323575,  0.22926204, -0.24740191,  0.11656888,  0.2827395 ,\n",
       "          0.07848345,  0.03361377,  0.33777288,  0.1662454 , -0.05084639,\n",
       "         -0.22072035, -0.2698652 , -0.04993271, -0.33215535, -0.5793079 ],\n",
       "        [-0.13554019, -0.12844656, -0.04925397,  0.36967027, -0.11782215,\n",
       "          0.11095501, -0.11411982, -0.01688095, -0.01705266, -0.21000478,\n",
       "         -0.47703737,  0.03044694, -0.34561154, -0.12661181, -0.7086525 ],\n",
       "        [-0.02830197, -0.18855323, -0.30356646, -0.02532747, -0.08702552,\n",
       "         -0.31397784, -0.01442229, -0.16278489,  0.35670593, -0.4419683 ,\n",
       "          0.6566111 , -0.09407743,  0.12011548,  0.8880244 ,  0.54696673],\n",
       "        [ 0.22301452,  0.23115396,  0.39000082, -0.45328474,  0.2096681 ,\n",
       "         -0.5360306 , -0.07846653,  0.24373938,  0.06109278, -0.32964694,\n",
       "          0.6471781 ,  0.0893159 ,  0.01255614,  0.24130303,  0.3887464 ],\n",
       "        [ 0.27829498,  0.02629162,  0.01899059,  0.29691264, -0.29700288,\n",
       "         -0.02662492, -0.01684272, -0.7200168 , -0.44925323, -0.2033839 ,\n",
       "         -0.13124228,  0.45199597, -0.5490819 , -0.02033776,  0.04309698],\n",
       "        [-0.1943638 ,  0.40774164, -0.05719408,  0.24504337,  0.05108844,\n",
       "          0.26208958, -0.00484391, -0.11359493,  0.17540464,  0.5818648 ,\n",
       "         -0.0243976 , -0.01779595, -0.1337299 , -0.27484733, -0.2678593 ],\n",
       "        [ 0.02327617,  0.35037285,  0.25788057, -0.08938335,  0.34424862,\n",
       "          0.09452017, -0.33082852,  0.39523605,  0.27771363,  0.23864818,\n",
       "         -0.34822127,  0.05889659, -0.16034012, -0.06157458, -0.21606967]],\n",
       "       dtype=float32),\n",
       " array([-0.17775336, -0.0664849 , -0.27263108,  0.11693129,  0.15483761,\n",
       "         0.07270718, -0.19896474,  0.11206819,  0.2599845 , -0.09144939,\n",
       "        -0.03268834, -0.1364933 ,  0.01234812,  0.24569975, -0.07624525],\n",
       "       dtype=float32),\n",
       " array([[ 0.03640175],\n",
       "        [-0.02189679],\n",
       "        [ 0.00590953],\n",
       "        [-0.02327434],\n",
       "        [-0.03069658],\n",
       "        [-0.09584146],\n",
       "        [ 0.00737563],\n",
       "        [-0.05203006],\n",
       "        [-0.00990919],\n",
       "        [-0.0484693 ],\n",
       "        [ 0.34585017],\n",
       "        [ 0.01322471],\n",
       "        [ 0.01249988],\n",
       "        [ 0.06541921],\n",
       "        [ 0.13474788]], dtype=float32),\n",
       " array([0.05428855], dtype=float32)]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_automobile, history_automobile=NN_model_structure_regression_6(X_train_automobile, X_val_automobile, Y_train_automobile, Y_val_automobile, adam2, 32, 1000)\n",
    "model_automobile.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_automobile.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_automobile_structure6.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_55 (Dense)             (None, 5)                 20        \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 56\n",
      "Trainable params: 56\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 32 samples, validate on 7 samples\n",
      "Epoch 1/1000\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 35.7556 - val_loss: 33.8057\n",
      "Epoch 2/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 33.8845 - val_loss: 30.5680\n",
      "Epoch 3/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.3388 - val_loss: 26.4596\n",
      "Epoch 4/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 28.0630 - val_loss: 21.5154\n",
      "Epoch 5/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 24.0410 - val_loss: 16.0281\n",
      "Epoch 6/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 19.4929 - val_loss: 10.7034\n",
      "Epoch 7/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 14.8312 - val_loss: 6.5124\n",
      "Epoch 8/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 10.5650 - val_loss: 4.1345\n",
      "Epoch 9/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0803 - val_loss: 3.5285\n",
      "Epoch 10/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.6521 - val_loss: 4.0453\n",
      "Epoch 11/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4034 - val_loss: 4.4620\n",
      "Epoch 12/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8549 - val_loss: 4.0953\n",
      "Epoch 13/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 2.4588 - val_loss: 3.3482\n",
      "Epoch 14/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1296 - val_loss: 2.9412\n",
      "Epoch 15/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9899 - val_loss: 3.0700\n",
      "Epoch 16/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 2.0237 - val_loss: 3.3980\n",
      "Epoch 17/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.0769 - val_loss: 3.6054\n",
      "Epoch 18/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0690 - val_loss: 3.6019\n",
      "Epoch 19/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0156 - val_loss: 3.4141\n",
      "Epoch 20/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.9332 - val_loss: 3.0917\n",
      "Epoch 21/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.8108 - val_loss: 2.6800\n",
      "Epoch 22/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6328 - val_loss: 2.2159\n",
      "Epoch 23/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3990 - val_loss: 1.7315\n",
      "Epoch 24/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 1.1266 - val_loss: 1.2588\n",
      "Epoch 25/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.8427 - val_loss: 0.8322\n",
      "Epoch 26/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.5775 - val_loss: 0.4879\n",
      "Epoch 27/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.3593 - val_loss: 0.2573\n",
      "Epoch 28/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.2103 - val_loss: 0.1576\n",
      "Epoch 29/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.1417 - val_loss: 0.1815\n",
      "Epoch 30/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.1493 - val_loss: 0.2934\n",
      "Epoch 31/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.2121 - val_loss: 0.4366\n",
      "Epoch 32/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.2966 - val_loss: 0.5514\n",
      "Epoch 33/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.3675 - val_loss: 0.5959\n",
      "Epoch 34/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.4001 - val_loss: 0.5588\n",
      "Epoch 35/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.3875 - val_loss: 0.4587\n",
      "Epoch 36/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.3402 - val_loss: 0.3301\n",
      "Epoch 37/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.2774 - val_loss: 0.2078\n",
      "Epoch 38/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.2180 - val_loss: 0.1152\n",
      "Epoch 39/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1740 - val_loss: 0.0603\n",
      "Epoch 40/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.1482 - val_loss: 0.0385\n",
      "Epoch 41/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1369 - val_loss: 0.0386\n",
      "Epoch 42/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1331 - val_loss: 0.0481\n",
      "Epoch 43/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.1306 - val_loss: 0.0577\n",
      "Epoch 44/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1252 - val_loss: 0.0622\n",
      "Epoch 45/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.1157 - val_loss: 0.0605\n",
      "Epoch 46/1000\n",
      "32/32 [==============================] - 0s 196us/step - loss: 0.1033 - val_loss: 0.0545\n",
      "Epoch 47/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0904 - val_loss: 0.0470\n",
      "Epoch 48/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0797 - val_loss: 0.0409\n",
      "Epoch 49/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0731 - val_loss: 0.0375\n",
      "Epoch 50/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0715 - val_loss: 0.0372\n",
      "Epoch 51/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0743 - val_loss: 0.0388\n",
      "Epoch 52/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0793 - val_loss: 0.0405\n",
      "Epoch 53/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0841 - val_loss: 0.0408\n",
      "Epoch 54/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0860 - val_loss: 0.0389\n",
      "Epoch 55/1000\n",
      "32/32 [==============================] - 0s 190us/step - loss: 0.0838 - val_loss: 0.0347\n",
      "Epoch 56/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0773 - val_loss: 0.0293\n",
      "Epoch 57/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0680 - val_loss: 0.0240\n",
      "Epoch 58/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0579 - val_loss: 0.0199\n",
      "Epoch 59/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0489 - val_loss: 0.0178\n",
      "Epoch 60/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0424 - val_loss: 0.0175\n",
      "Epoch 61/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0387 - val_loss: 0.0184\n",
      "Epoch 62/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0372 - val_loss: 0.0198\n",
      "Epoch 63/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0372 - val_loss: 0.0208\n",
      "Epoch 64/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0376 - val_loss: 0.0209\n",
      "Epoch 65/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0379 - val_loss: 0.0199\n",
      "Epoch 66/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0375 - val_loss: 0.0180\n",
      "Epoch 67/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0366 - val_loss: 0.0156\n",
      "Epoch 68/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0354 - val_loss: 0.0134\n",
      "Epoch 69/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0339 - val_loss: 0.0117\n",
      "Epoch 70/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0326 - val_loss: 0.0108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0316 - val_loss: 0.0107\n",
      "Epoch 72/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0308 - val_loss: 0.0113\n",
      "Epoch 73/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0303 - val_loss: 0.0122\n",
      "Epoch 74/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0299 - val_loss: 0.0130\n",
      "Epoch 75/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0293 - val_loss: 0.0134\n",
      "Epoch 76/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0286 - val_loss: 0.0135\n",
      "Epoch 77/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0276 - val_loss: 0.0131\n",
      "Epoch 78/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0264 - val_loss: 0.0128\n",
      "Epoch 79/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0253 - val_loss: 0.0126\n",
      "Epoch 80/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0242 - val_loss: 0.0127\n",
      "Epoch 81/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0235 - val_loss: 0.0133\n",
      "Epoch 82/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0231 - val_loss: 0.0141\n",
      "Epoch 83/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0229 - val_loss: 0.0151\n",
      "Epoch 84/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0228 - val_loss: 0.0159\n",
      "Epoch 85/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0228 - val_loss: 0.0164\n",
      "Epoch 86/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0228 - val_loss: 0.0165\n",
      "Epoch 87/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0226 - val_loss: 0.0162\n",
      "Epoch 88/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0223 - val_loss: 0.0156\n",
      "Epoch 89/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0219 - val_loss: 0.0148\n",
      "Epoch 90/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0214 - val_loss: 0.0138\n",
      "Epoch 91/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0209 - val_loss: 0.0129\n",
      "Epoch 92/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0205 - val_loss: 0.0120\n",
      "Epoch 93/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0201 - val_loss: 0.0112\n",
      "Epoch 94/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0198 - val_loss: 0.0104\n",
      "Epoch 95/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0195 - val_loss: 0.0098\n",
      "Epoch 96/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0192 - val_loss: 0.0092\n",
      "Epoch 97/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0190 - val_loss: 0.0088\n",
      "Epoch 98/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0187 - val_loss: 0.0084\n",
      "Epoch 99/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0184 - val_loss: 0.0081\n",
      "Epoch 100/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0181 - val_loss: 0.0079\n",
      "Epoch 101/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0179 - val_loss: 0.0077\n",
      "Epoch 102/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0176 - val_loss: 0.0077\n",
      "Epoch 103/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0174 - val_loss: 0.0076\n",
      "Epoch 104/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0172 - val_loss: 0.0075\n",
      "Epoch 105/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0170 - val_loss: 0.0075\n",
      "Epoch 106/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0168 - val_loss: 0.0074\n",
      "Epoch 107/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0166 - val_loss: 0.0073\n",
      "Epoch 108/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0164 - val_loss: 0.0071\n",
      "Epoch 109/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0162 - val_loss: 0.0069\n",
      "Epoch 110/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 0.0160 - val_loss: 0.0067\n",
      "Epoch 111/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0158 - val_loss: 0.0065\n",
      "Epoch 112/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0156 - val_loss: 0.0063\n",
      "Epoch 113/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0154 - val_loss: 0.0061\n",
      "Epoch 114/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0152 - val_loss: 0.0060\n",
      "Epoch 115/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0150 - val_loss: 0.0059\n",
      "Epoch 116/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0148 - val_loss: 0.0058\n",
      "Epoch 117/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0147 - val_loss: 0.0057\n",
      "Epoch 118/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0145 - val_loss: 0.0056\n",
      "Epoch 119/1000\n",
      "32/32 [==============================] - 0s 191us/step - loss: 0.0144 - val_loss: 0.0055\n",
      "Epoch 120/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0142 - val_loss: 0.0055\n",
      "Epoch 121/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0141 - val_loss: 0.0054\n",
      "Epoch 122/1000\n",
      "32/32 [==============================] - 0s 163us/step - loss: 0.0139 - val_loss: 0.0054\n",
      "Epoch 123/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0137 - val_loss: 0.0053\n",
      "Epoch 124/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0136 - val_loss: 0.0053\n",
      "Epoch 125/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0135 - val_loss: 0.0052\n",
      "Epoch 126/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0133 - val_loss: 0.0051\n",
      "Epoch 127/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0132 - val_loss: 0.0050\n",
      "Epoch 128/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0130 - val_loss: 0.0049\n",
      "Epoch 129/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0129 - val_loss: 0.0048\n",
      "Epoch 130/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0128 - val_loss: 0.0047\n",
      "Epoch 131/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0127 - val_loss: 0.0046\n",
      "Epoch 132/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0125 - val_loss: 0.0045\n",
      "Epoch 133/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0124 - val_loss: 0.0043\n",
      "Epoch 134/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0123 - val_loss: 0.0042\n",
      "Epoch 135/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0122 - val_loss: 0.0041\n",
      "Epoch 136/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0120 - val_loss: 0.0040\n",
      "Epoch 137/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0119 - val_loss: 0.0039\n",
      "Epoch 138/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0118 - val_loss: 0.0038\n",
      "Epoch 139/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0117 - val_loss: 0.0038\n",
      "Epoch 140/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0116 - val_loss: 0.0037\n",
      "Epoch 141/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0115 - val_loss: 0.0037\n",
      "Epoch 142/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0114 - val_loss: 0.0036\n",
      "Epoch 143/1000\n",
      "32/32 [==============================] - 0s 217us/step - loss: 0.0113 - val_loss: 0.0036\n",
      "Epoch 144/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0112 - val_loss: 0.0036\n",
      "Epoch 145/1000\n",
      "32/32 [==============================] - 0s 120us/step - loss: 0.0111 - val_loss: 0.0036\n",
      "Epoch 146/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0110 - val_loss: 0.0035\n",
      "Epoch 147/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0109 - val_loss: 0.0035\n",
      "Epoch 148/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0108 - val_loss: 0.0035\n",
      "Epoch 149/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0107 - val_loss: 0.0035\n",
      "Epoch 150/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0106 - val_loss: 0.0034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0105 - val_loss: 0.0034\n",
      "Epoch 152/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0104 - val_loss: 0.0033\n",
      "Epoch 153/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0103 - val_loss: 0.0033\n",
      "Epoch 154/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0102 - val_loss: 0.0033\n",
      "Epoch 155/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0101 - val_loss: 0.0032\n",
      "Epoch 156/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0101 - val_loss: 0.0032\n",
      "Epoch 157/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0100 - val_loss: 0.0031\n",
      "Epoch 158/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0099 - val_loss: 0.0031\n",
      "Epoch 159/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0098 - val_loss: 0.0031\n",
      "Epoch 160/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 0.0097 - val_loss: 0.0030\n",
      "Epoch 161/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0097 - val_loss: 0.0030\n",
      "Epoch 162/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0096 - val_loss: 0.0030\n",
      "Epoch 163/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0095 - val_loss: 0.0029\n",
      "Epoch 164/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0094 - val_loss: 0.0029\n",
      "Epoch 165/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0093 - val_loss: 0.0029\n",
      "Epoch 166/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0093 - val_loss: 0.0029\n",
      "Epoch 167/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0092 - val_loss: 0.0028\n",
      "Epoch 168/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0091 - val_loss: 0.0028\n",
      "Epoch 169/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0091 - val_loss: 0.0028\n",
      "Epoch 170/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0090 - val_loss: 0.0028\n",
      "Epoch 171/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0089 - val_loss: 0.0027\n",
      "Epoch 172/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0088 - val_loss: 0.0027\n",
      "Epoch 173/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0088 - val_loss: 0.0027\n",
      "Epoch 174/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0087 - val_loss: 0.0027\n",
      "Epoch 175/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0086 - val_loss: 0.0026\n",
      "Epoch 176/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0086 - val_loss: 0.0026\n",
      "Epoch 177/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0085 - val_loss: 0.0026\n",
      "Epoch 178/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0084 - val_loss: 0.0026\n",
      "Epoch 179/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0084 - val_loss: 0.0025\n",
      "Epoch 180/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0083 - val_loss: 0.0025\n",
      "Epoch 181/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0083 - val_loss: 0.0025\n",
      "Epoch 182/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0082 - val_loss: 0.0025\n",
      "Epoch 183/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0081 - val_loss: 0.0025\n",
      "Epoch 184/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0081 - val_loss: 0.0024\n",
      "Epoch 185/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0080 - val_loss: 0.0024\n",
      "Epoch 186/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0080 - val_loss: 0.0024\n",
      "Epoch 187/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0079 - val_loss: 0.0024\n",
      "Epoch 188/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0078 - val_loss: 0.0024\n",
      "Epoch 189/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0078 - val_loss: 0.0023\n",
      "Epoch 190/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0077 - val_loss: 0.0023\n",
      "Epoch 191/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0077 - val_loss: 0.0023\n",
      "Epoch 192/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0076 - val_loss: 0.0023\n",
      "Epoch 193/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0076 - val_loss: 0.0023\n",
      "Epoch 194/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0075 - val_loss: 0.0023\n",
      "Epoch 195/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0075 - val_loss: 0.0022\n",
      "Epoch 196/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0074 - val_loss: 0.0022\n",
      "Epoch 197/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0074 - val_loss: 0.0022\n",
      "Epoch 198/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0073 - val_loss: 0.0022\n",
      "Epoch 199/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0073 - val_loss: 0.0022\n",
      "Epoch 200/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0072 - val_loss: 0.0021\n",
      "Epoch 201/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0072 - val_loss: 0.0021\n",
      "Epoch 202/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0071 - val_loss: 0.0021\n",
      "Epoch 203/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0071 - val_loss: 0.0021\n",
      "Epoch 204/1000\n",
      "32/32 [==============================] - 0s 182us/step - loss: 0.0070 - val_loss: 0.0021\n",
      "Epoch 205/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 0.0070 - val_loss: 0.0021\n",
      "Epoch 206/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0069 - val_loss: 0.0020\n",
      "Epoch 207/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0069 - val_loss: 0.0020\n",
      "Epoch 208/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0068 - val_loss: 0.0020\n",
      "Epoch 209/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0068 - val_loss: 0.0020\n",
      "Epoch 210/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0067 - val_loss: 0.0020\n",
      "Epoch 211/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0067 - val_loss: 0.0020\n",
      "Epoch 212/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0067 - val_loss: 0.0019\n",
      "Epoch 213/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0066 - val_loss: 0.0019\n",
      "Epoch 214/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0066 - val_loss: 0.0019\n",
      "Epoch 215/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0065 - val_loss: 0.0019\n",
      "Epoch 216/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0065 - val_loss: 0.0019\n",
      "Epoch 217/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0064 - val_loss: 0.0019\n",
      "Epoch 218/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0064 - val_loss: 0.0019\n",
      "Epoch 219/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0064 - val_loss: 0.0018\n",
      "Epoch 220/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0063 - val_loss: 0.0018\n",
      "Epoch 221/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0063 - val_loss: 0.0018\n",
      "Epoch 222/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 223/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 224/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 225/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0061 - val_loss: 0.0018\n",
      "Epoch 226/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0061 - val_loss: 0.0018\n",
      "Epoch 227/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0061 - val_loss: 0.0017\n",
      "Epoch 228/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0060 - val_loss: 0.0017\n",
      "Epoch 229/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0060 - val_loss: 0.0017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 230/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0059 - val_loss: 0.0017\n",
      "Epoch 231/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0059 - val_loss: 0.0017\n",
      "Epoch 232/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0059 - val_loss: 0.0017\n",
      "Epoch 233/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0058 - val_loss: 0.0017\n",
      "Epoch 234/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0058 - val_loss: 0.0017\n",
      "Epoch 235/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0058 - val_loss: 0.0016\n",
      "Epoch 236/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0057 - val_loss: 0.0016\n",
      "Epoch 237/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0057 - val_loss: 0.0016\n",
      "Epoch 238/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0057 - val_loss: 0.0016\n",
      "Epoch 239/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0056 - val_loss: 0.0016\n",
      "Epoch 240/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0056 - val_loss: 0.0016\n",
      "Epoch 241/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0056 - val_loss: 0.0016\n",
      "Epoch 242/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0055 - val_loss: 0.0016\n",
      "Epoch 243/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0055 - val_loss: 0.0015\n",
      "Epoch 244/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0055 - val_loss: 0.0015\n",
      "Epoch 245/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0054 - val_loss: 0.0015\n",
      "Epoch 246/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0054 - val_loss: 0.0015\n",
      "Epoch 247/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0054 - val_loss: 0.0015\n",
      "Epoch 248/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0053 - val_loss: 0.0015\n",
      "Epoch 249/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0053 - val_loss: 0.0015\n",
      "Epoch 250/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0053 - val_loss: 0.0015\n",
      "Epoch 251/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0052 - val_loss: 0.0015\n",
      "Epoch 252/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0052 - val_loss: 0.0015\n",
      "Epoch 253/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0052 - val_loss: 0.0014\n",
      "Epoch 254/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0052 - val_loss: 0.0014\n",
      "Epoch 255/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0051 - val_loss: 0.0014\n",
      "Epoch 256/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0051 - val_loss: 0.0014\n",
      "Epoch 257/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0051 - val_loss: 0.0014\n",
      "Epoch 258/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0050 - val_loss: 0.0014\n",
      "Epoch 259/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0050 - val_loss: 0.0014\n",
      "Epoch 260/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0050 - val_loss: 0.0014\n",
      "Epoch 261/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0050 - val_loss: 0.0014\n",
      "Epoch 262/1000\n",
      "32/32 [==============================] - 0s 133us/step - loss: 0.0049 - val_loss: 0.0014\n",
      "Epoch 263/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0049 - val_loss: 0.0013\n",
      "Epoch 264/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 0.0049 - val_loss: 0.0013\n",
      "Epoch 265/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0048 - val_loss: 0.0013\n",
      "Epoch 266/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0048 - val_loss: 0.0013\n",
      "Epoch 267/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0048 - val_loss: 0.0013\n",
      "Epoch 268/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 0.0048 - val_loss: 0.0013\n",
      "Epoch 269/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0047 - val_loss: 0.0013\n",
      "Epoch 270/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0047 - val_loss: 0.0013\n",
      "Epoch 271/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0047 - val_loss: 0.0013\n",
      "Epoch 272/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0047 - val_loss: 0.0013\n",
      "Epoch 273/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0046 - val_loss: 0.0013\n",
      "Epoch 274/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0046 - val_loss: 0.0013\n",
      "Epoch 275/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0046 - val_loss: 0.0012\n",
      "Epoch 276/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0046 - val_loss: 0.0012\n",
      "Epoch 277/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0045 - val_loss: 0.0012\n",
      "Epoch 278/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0045 - val_loss: 0.0012\n",
      "Epoch 279/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0045 - val_loss: 0.0012\n",
      "Epoch 280/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0045 - val_loss: 0.0012\n",
      "Epoch 281/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0044 - val_loss: 0.0012\n",
      "Epoch 282/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0044 - val_loss: 0.0012\n",
      "Epoch 283/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0044 - val_loss: 0.0012\n",
      "Epoch 284/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0044 - val_loss: 0.0012\n",
      "Epoch 285/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0043 - val_loss: 0.0012\n",
      "Epoch 286/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0043 - val_loss: 0.0012\n",
      "Epoch 287/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0043 - val_loss: 0.0011\n",
      "Epoch 288/1000\n",
      "32/32 [==============================] - 0s 343us/step - loss: 0.0043 - val_loss: 0.0011\n",
      "Epoch 289/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0043 - val_loss: 0.0011\n",
      "Epoch 290/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0042 - val_loss: 0.0011\n",
      "Epoch 291/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0042 - val_loss: 0.0011\n",
      "Epoch 292/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0042 - val_loss: 0.0011\n",
      "Epoch 293/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0042 - val_loss: 0.0011\n",
      "Epoch 294/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0042 - val_loss: 0.0011\n",
      "Epoch 295/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0041 - val_loss: 0.0011\n",
      "Epoch 296/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0041 - val_loss: 0.0011\n",
      "Epoch 297/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0041 - val_loss: 0.0011\n",
      "Epoch 298/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0041 - val_loss: 0.0011\n",
      "Epoch 299/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0040 - val_loss: 0.0011\n",
      "Epoch 300/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0040 - val_loss: 0.0011\n",
      "Epoch 301/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0040 - val_loss: 0.0011\n",
      "Epoch 302/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0040 - val_loss: 0.0010\n",
      "Epoch 303/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0040 - val_loss: 0.0010\n",
      "Epoch 304/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0039 - val_loss: 0.0010\n",
      "Epoch 305/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0039 - val_loss: 0.0010\n",
      "Epoch 306/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0039 - val_loss: 0.0010\n",
      "Epoch 307/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0039 - val_loss: 0.0010\n",
      "Epoch 308/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0039 - val_loss: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 309/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0038 - val_loss: 9.9969e-04\n",
      "Epoch 310/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0038 - val_loss: 9.9355e-04\n",
      "Epoch 311/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0038 - val_loss: 9.8748e-04\n",
      "Epoch 312/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0038 - val_loss: 9.8144e-04\n",
      "Epoch 313/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0038 - val_loss: 9.7545e-04\n",
      "Epoch 314/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0038 - val_loss: 9.6950e-04\n",
      "Epoch 315/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0037 - val_loss: 9.6363e-04\n",
      "Epoch 316/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0037 - val_loss: 9.5780e-04\n",
      "Epoch 317/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 0.0037 - val_loss: 9.5200e-04\n",
      "Epoch 318/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0037 - val_loss: 9.4625e-04\n",
      "Epoch 319/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0037 - val_loss: 9.4058e-04\n",
      "Epoch 320/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0037 - val_loss: 9.3497e-04\n",
      "Epoch 321/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0036 - val_loss: 9.2939e-04\n",
      "Epoch 322/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0036 - val_loss: 9.2385e-04\n",
      "Epoch 323/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0036 - val_loss: 9.1838e-04\n",
      "Epoch 324/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0036 - val_loss: 9.1294e-04\n",
      "Epoch 325/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0036 - val_loss: 9.0755e-04\n",
      "Epoch 326/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0035 - val_loss: 9.0221e-04\n",
      "Epoch 327/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0035 - val_loss: 8.9692e-04\n",
      "Epoch 328/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0035 - val_loss: 8.9167e-04\n",
      "Epoch 329/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0035 - val_loss: 8.8647e-04\n",
      "Epoch 330/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0035 - val_loss: 8.8131e-04\n",
      "Epoch 331/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0035 - val_loss: 8.7620e-04\n",
      "Epoch 332/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 0.0035 - val_loss: 8.7113e-04\n",
      "Epoch 333/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0034 - val_loss: 8.6611e-04\n",
      "Epoch 334/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0034 - val_loss: 8.6113e-04\n",
      "Epoch 335/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0034 - val_loss: 8.5621e-04\n",
      "Epoch 336/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0034 - val_loss: 8.5132e-04\n",
      "Epoch 337/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0034 - val_loss: 8.4649e-04\n",
      "Epoch 338/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0034 - val_loss: 8.4169e-04\n",
      "Epoch 339/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0033 - val_loss: 8.3692e-04\n",
      "Epoch 340/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 8.3222e-04\n",
      "Epoch 341/1000\n",
      "32/32 [==============================] - 0s 111us/step - loss: 0.0033 - val_loss: 8.2754e-04\n",
      "Epoch 342/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 8.2291e-04\n",
      "Epoch 343/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0033 - val_loss: 8.1832e-04\n",
      "Epoch 344/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0033 - val_loss: 8.1376e-04\n",
      "Epoch 345/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0033 - val_loss: 8.0926e-04\n",
      "Epoch 346/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 8.0477e-04\n",
      "Epoch 347/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0032 - val_loss: 8.0037e-04\n",
      "Epoch 348/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0032 - val_loss: 7.9594e-04\n",
      "Epoch 349/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 7.9161e-04\n",
      "Epoch 350/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 7.8728e-04\n",
      "Epoch 351/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0032 - val_loss: 7.8301e-04\n",
      "Epoch 352/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 7.7877e-04\n",
      "Epoch 353/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0031 - val_loss: 7.7455e-04\n",
      "Epoch 354/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0031 - val_loss: 7.7039e-04\n",
      "Epoch 355/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0031 - val_loss: 7.6625e-04\n",
      "Epoch 356/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0031 - val_loss: 7.6216e-04\n",
      "Epoch 357/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0031 - val_loss: 7.5812e-04\n",
      "Epoch 358/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0031 - val_loss: 7.5409e-04\n",
      "Epoch 359/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0031 - val_loss: 7.5013e-04\n",
      "Epoch 360/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0030 - val_loss: 7.4618e-04\n",
      "Epoch 361/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 7.4228e-04\n",
      "Epoch 362/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0030 - val_loss: 7.3840e-04\n",
      "Epoch 363/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 7.3457e-04\n",
      "Epoch 364/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0030 - val_loss: 7.3075e-04\n",
      "Epoch 365/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0030 - val_loss: 7.2699e-04\n",
      "Epoch 366/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 7.2324e-04\n",
      "Epoch 367/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0030 - val_loss: 7.1952e-04\n",
      "Epoch 368/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 7.1586e-04\n",
      "Epoch 369/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 7.1220e-04\n",
      "Epoch 370/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0029 - val_loss: 7.0859e-04\n",
      "Epoch 371/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0029 - val_loss: 7.0503e-04\n",
      "Epoch 372/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0029 - val_loss: 7.0148e-04\n",
      "Epoch 373/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 6.9796e-04\n",
      "Epoch 374/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 6.9448e-04\n",
      "Epoch 375/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 6.9103e-04\n",
      "Epoch 376/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0028 - val_loss: 6.8760e-04\n",
      "Epoch 377/1000\n",
      "32/32 [==============================] - 0s 161us/step - loss: 0.0028 - val_loss: 6.8423e-04\n",
      "Epoch 378/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0028 - val_loss: 6.8086e-04\n",
      "Epoch 379/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0028 - val_loss: 6.7753e-04\n",
      "Epoch 380/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 6.7424e-04\n",
      "Epoch 381/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0028 - val_loss: 6.7096e-04\n",
      "Epoch 382/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 6.6772e-04\n",
      "Epoch 383/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 6.6449e-04\n",
      "Epoch 384/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0028 - val_loss: 6.6133e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 385/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 6.5815e-04\n",
      "Epoch 386/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 6.5505e-04\n",
      "Epoch 387/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 6.5195e-04\n",
      "Epoch 388/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 6.4888e-04\n",
      "Epoch 389/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0027 - val_loss: 6.4585e-04\n",
      "Epoch 390/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 6.4283e-04\n",
      "Epoch 391/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 6.3984e-04\n",
      "Epoch 392/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 6.3687e-04\n",
      "Epoch 393/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 6.3392e-04\n",
      "Epoch 394/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 6.3101e-04\n",
      "Epoch 395/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 0.0026 - val_loss: 6.2812e-04\n",
      "Epoch 396/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 6.2525e-04\n",
      "Epoch 397/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 6.2243e-04\n",
      "Epoch 398/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 6.1964e-04\n",
      "Epoch 399/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 6.1682e-04\n",
      "Epoch 400/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 6.1408e-04\n",
      "Epoch 401/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 6.1134e-04\n",
      "Epoch 402/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 6.0863e-04\n",
      "Epoch 403/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0026 - val_loss: 6.0595e-04\n",
      "Epoch 404/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0025 - val_loss: 6.0328e-04\n",
      "Epoch 405/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 6.0065e-04\n",
      "Epoch 406/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0025 - val_loss: 5.9804e-04\n",
      "Epoch 407/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 5.9546e-04\n",
      "Epoch 408/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 5.9289e-04\n",
      "Epoch 409/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 5.9035e-04\n",
      "Epoch 410/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0025 - val_loss: 5.8781e-04\n",
      "Epoch 411/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 5.8532e-04\n",
      "Epoch 412/1000\n",
      "32/32 [==============================] - 0s 172us/step - loss: 0.0025 - val_loss: 5.8284e-04\n",
      "Epoch 413/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0025 - val_loss: 5.8039e-04\n",
      "Epoch 414/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 5.7795e-04\n",
      "Epoch 415/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0024 - val_loss: 5.7553e-04\n",
      "Epoch 416/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0024 - val_loss: 5.7313e-04\n",
      "Epoch 417/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0024 - val_loss: 5.7075e-04\n",
      "Epoch 418/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 5.6842e-04\n",
      "Epoch 419/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 5.6608e-04\n",
      "Epoch 420/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 5.6378e-04\n",
      "Epoch 421/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0024 - val_loss: 5.6150e-04\n",
      "Epoch 422/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 5.5924e-04\n",
      "Epoch 423/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 5.5698e-04\n",
      "Epoch 424/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0024 - val_loss: 5.5477e-04\n",
      "Epoch 425/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0024 - val_loss: 5.5255e-04\n",
      "Epoch 426/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0023 - val_loss: 5.5037e-04\n",
      "Epoch 427/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 5.4818e-04\n",
      "Epoch 428/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 5.4603e-04\n",
      "Epoch 429/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 5.4391e-04\n",
      "Epoch 430/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 0.0023 - val_loss: 5.4181e-04\n",
      "Epoch 431/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 0.0023 - val_loss: 5.3970e-04\n",
      "Epoch 432/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 5.3763e-04\n",
      "Epoch 433/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 5.3558e-04\n",
      "Epoch 434/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0023 - val_loss: 5.3353e-04\n",
      "Epoch 435/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 5.3153e-04\n",
      "Epoch 436/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0023 - val_loss: 5.2953e-04\n",
      "Epoch 437/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 5.2756e-04\n",
      "Epoch 438/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 5.2559e-04\n",
      "Epoch 439/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0022 - val_loss: 5.2365e-04\n",
      "Epoch 440/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0022 - val_loss: 5.2172e-04\n",
      "Epoch 441/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 5.1981e-04\n",
      "Epoch 442/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0022 - val_loss: 5.1790e-04\n",
      "Epoch 443/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 5.1600e-04\n",
      "Epoch 444/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 5.1414e-04\n",
      "Epoch 445/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0022 - val_loss: 5.1229e-04\n",
      "Epoch 446/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 5.1042e-04\n",
      "Epoch 447/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 5.0863e-04\n",
      "Epoch 448/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 5.0682e-04\n",
      "Epoch 449/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 5.0504e-04\n",
      "Epoch 450/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 5.0326e-04\n",
      "Epoch 451/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0021 - val_loss: 5.0152e-04\n",
      "Epoch 452/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 4.9979e-04\n",
      "Epoch 453/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 4.9808e-04\n",
      "Epoch 454/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0021 - val_loss: 4.9637e-04\n",
      "Epoch 455/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 4.9468e-04\n",
      "Epoch 456/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 4.9299e-04\n",
      "Epoch 457/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0021 - val_loss: 4.9133e-04\n",
      "Epoch 458/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 4.8967e-04\n",
      "Epoch 459/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0021 - val_loss: 4.8805e-04\n",
      "Epoch 460/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 4.8641e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 461/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 4.8480e-04\n",
      "Epoch 462/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 4.8322e-04\n",
      "Epoch 463/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0021 - val_loss: 4.8164e-04\n",
      "Epoch 464/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 4.8005e-04\n",
      "Epoch 465/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 4.7850e-04\n",
      "Epoch 466/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 4.7696e-04\n",
      "Epoch 467/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 4.7542e-04\n",
      "Epoch 468/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0020 - val_loss: 4.7392e-04\n",
      "Epoch 469/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 4.7240e-04\n",
      "Epoch 470/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 4.7092e-04\n",
      "Epoch 471/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0020 - val_loss: 4.6944e-04\n",
      "Epoch 472/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0020 - val_loss: 4.6800e-04\n",
      "Epoch 473/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0020 - val_loss: 4.6656e-04\n",
      "Epoch 474/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 4.6511e-04\n",
      "Epoch 475/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 4.6369e-04\n",
      "Epoch 476/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 4.6227e-04\n",
      "Epoch 477/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0020 - val_loss: 4.6088e-04\n",
      "Epoch 478/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 4.5950e-04\n",
      "Epoch 479/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 4.5813e-04\n",
      "Epoch 480/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0020 - val_loss: 4.5675e-04\n",
      "Epoch 481/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0019 - val_loss: 4.5540e-04\n",
      "Epoch 482/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0019 - val_loss: 4.5405e-04\n",
      "Epoch 483/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 4.5274e-04\n",
      "Epoch 484/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0019 - val_loss: 4.5141e-04\n",
      "Epoch 485/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 4.5010e-04\n",
      "Epoch 486/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 4.4878e-04\n",
      "Epoch 487/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 4.4751e-04\n",
      "Epoch 488/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0019 - val_loss: 4.4623e-04\n",
      "Epoch 489/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 4.4496e-04\n",
      "Epoch 490/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 4.4371e-04\n",
      "Epoch 491/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0019 - val_loss: 4.4247e-04\n",
      "Epoch 492/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0019 - val_loss: 4.4122e-04\n",
      "Epoch 493/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 4.4002e-04\n",
      "Epoch 494/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0019 - val_loss: 4.3879e-04\n",
      "Epoch 495/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 4.3758e-04\n",
      "Epoch 496/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0019 - val_loss: 4.3640e-04\n",
      "Epoch 497/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 4.3524e-04\n",
      "Epoch 498/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 4.3407e-04\n",
      "Epoch 499/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0018 - val_loss: 4.3289e-04\n",
      "Epoch 500/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 4.3175e-04\n",
      "Epoch 501/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 4.3061e-04\n",
      "Epoch 502/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0018 - val_loss: 4.2947e-04\n",
      "Epoch 503/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0018 - val_loss: 4.2833e-04\n",
      "Epoch 504/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 4.2721e-04\n",
      "Epoch 505/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0018 - val_loss: 4.2608e-04\n",
      "Epoch 506/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 4.2499e-04\n",
      "Epoch 507/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 4.2390e-04\n",
      "Epoch 508/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 4.2284e-04\n",
      "Epoch 509/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0018 - val_loss: 4.2178e-04\n",
      "Epoch 510/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 0.0018 - val_loss: 4.2072e-04\n",
      "Epoch 511/1000\n",
      "32/32 [==============================] - 0s 405us/step - loss: 0.0018 - val_loss: 4.1965e-04\n",
      "Epoch 512/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0018 - val_loss: 4.1862e-04\n",
      "Epoch 513/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0018 - val_loss: 4.1757e-04\n",
      "Epoch 514/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0018 - val_loss: 4.1655e-04\n",
      "Epoch 515/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 0.0018 - val_loss: 4.1552e-04\n",
      "Epoch 516/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0017 - val_loss: 4.1451e-04\n",
      "Epoch 517/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 4.1351e-04\n",
      "Epoch 518/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 4.1252e-04\n",
      "Epoch 519/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0017 - val_loss: 4.1153e-04\n",
      "Epoch 520/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0017 - val_loss: 4.1055e-04\n",
      "Epoch 521/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0017 - val_loss: 4.0958e-04\n",
      "Epoch 522/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 4.0861e-04\n",
      "Epoch 523/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0017 - val_loss: 4.0766e-04\n",
      "Epoch 524/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 4.0670e-04\n",
      "Epoch 525/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 4.0577e-04\n",
      "Epoch 526/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 4.0483e-04\n",
      "Epoch 527/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 4.0391e-04\n",
      "Epoch 528/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0017 - val_loss: 4.0299e-04\n",
      "Epoch 529/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 4.0208e-04\n",
      "Epoch 530/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 4.0117e-04\n",
      "Epoch 531/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 4.0027e-04\n",
      "Epoch 532/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0017 - val_loss: 3.9938e-04\n",
      "Epoch 533/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0017 - val_loss: 3.9851e-04\n",
      "Epoch 534/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0017 - val_loss: 3.9763e-04\n",
      "Epoch 535/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 3.9676e-04\n",
      "Epoch 536/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0016 - val_loss: 3.9591e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 537/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0016 - val_loss: 3.9504e-04\n",
      "Epoch 538/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 3.9419e-04\n",
      "Epoch 539/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0016 - val_loss: 3.9335e-04\n",
      "Epoch 540/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 3.9251e-04\n",
      "Epoch 541/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 3.9169e-04\n",
      "Epoch 542/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 3.9085e-04\n",
      "Epoch 543/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 3.9005e-04\n",
      "Epoch 544/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 3.8923e-04\n",
      "Epoch 545/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 3.8843e-04\n",
      "Epoch 546/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 3.8763e-04\n",
      "Epoch 547/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 3.8683e-04\n",
      "Epoch 548/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0016 - val_loss: 3.8605e-04\n",
      "Epoch 549/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0016 - val_loss: 3.8525e-04\n",
      "Epoch 550/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 3.8448e-04\n",
      "Epoch 551/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 3.8372e-04\n",
      "Epoch 552/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0016 - val_loss: 3.8296e-04\n",
      "Epoch 553/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0016 - val_loss: 3.8221e-04\n",
      "Epoch 554/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 3.8146e-04\n",
      "Epoch 555/1000\n",
      "32/32 [==============================] - 0s 779us/step - loss: 0.0016 - val_loss: 3.8071e-04\n",
      "Epoch 556/1000\n",
      "32/32 [==============================] - 0s 343us/step - loss: 0.0016 - val_loss: 3.7998e-04\n",
      "Epoch 557/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0016 - val_loss: 3.7924e-04\n",
      "Epoch 558/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 0.0016 - val_loss: 3.7852e-04\n",
      "Epoch 559/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0015 - val_loss: 3.7780e-04\n",
      "Epoch 560/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0015 - val_loss: 3.7706e-04\n",
      "Epoch 561/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 3.7636e-04\n",
      "Epoch 562/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 3.7564e-04\n",
      "Epoch 563/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0015 - val_loss: 3.7494e-04\n",
      "Epoch 564/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0015 - val_loss: 3.7424e-04\n",
      "Epoch 565/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 3.7355e-04\n",
      "Epoch 566/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0015 - val_loss: 3.7287e-04\n",
      "Epoch 567/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 3.7218e-04\n",
      "Epoch 568/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 3.7150e-04\n",
      "Epoch 569/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 3.7082e-04\n",
      "Epoch 570/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0015 - val_loss: 3.7017e-04\n",
      "Epoch 571/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0015 - val_loss: 3.6950e-04\n",
      "Epoch 572/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0015 - val_loss: 3.6884e-04\n",
      "Epoch 573/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0015 - val_loss: 3.6819e-04\n",
      "Epoch 574/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 3.6753e-04\n",
      "Epoch 575/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0015 - val_loss: 3.6691e-04\n",
      "Epoch 576/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 0.0015 - val_loss: 3.6627e-04\n",
      "Epoch 577/1000\n",
      "32/32 [==============================] - 0s 280us/step - loss: 0.0015 - val_loss: 3.6563e-04\n",
      "Epoch 578/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 3.6500e-04\n",
      "Epoch 579/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 3.6438e-04\n",
      "Epoch 580/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 3.6375e-04\n",
      "Epoch 581/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 3.6313e-04\n",
      "Epoch 582/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 3.6250e-04\n",
      "Epoch 583/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 3.6189e-04\n",
      "Epoch 584/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 3.6129e-04\n",
      "Epoch 585/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 3.6068e-04\n",
      "Epoch 586/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 3.6010e-04\n",
      "Epoch 587/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 3.5951e-04\n",
      "Epoch 588/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 3.5892e-04\n",
      "Epoch 589/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 3.5832e-04\n",
      "Epoch 590/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 3.5775e-04\n",
      "Epoch 591/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 3.5718e-04\n",
      "Epoch 592/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 3.5660e-04\n",
      "Epoch 593/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 3.5603e-04\n",
      "Epoch 594/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 3.5548e-04\n",
      "Epoch 595/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 0.0014 - val_loss: 3.5491e-04\n",
      "Epoch 596/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 3.5436e-04\n",
      "Epoch 597/1000\n",
      "32/32 [==============================] - 0s 177us/step - loss: 0.0014 - val_loss: 3.5380e-04\n",
      "Epoch 598/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 3.5325e-04\n",
      "Epoch 599/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 3.5270e-04\n",
      "Epoch 600/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0014 - val_loss: 3.5217e-04\n",
      "Epoch 601/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 3.5161e-04\n",
      "Epoch 602/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 3.5108e-04\n",
      "Epoch 603/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0014 - val_loss: 3.5054e-04\n",
      "Epoch 604/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 3.5002e-04\n",
      "Epoch 605/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 3.4950e-04\n",
      "Epoch 606/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 3.4897e-04\n",
      "Epoch 607/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 3.4846e-04\n",
      "Epoch 608/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 3.4794e-04\n",
      "Epoch 609/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 3.4743e-04\n",
      "Epoch 610/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 3.4692e-04\n",
      "Epoch 611/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 3.4643e-04\n",
      "Epoch 612/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0014 - val_loss: 3.4592e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 613/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 3.4540e-04\n",
      "Epoch 614/1000\n",
      "32/32 [==============================] - 0s 165us/step - loss: 0.0013 - val_loss: 3.4491e-04\n",
      "Epoch 615/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 3.4442e-04\n",
      "Epoch 616/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 3.4393e-04\n",
      "Epoch 617/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0013 - val_loss: 3.4345e-04\n",
      "Epoch 618/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 3.4296e-04\n",
      "Epoch 619/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 3.4249e-04\n",
      "Epoch 620/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 3.4201e-04\n",
      "Epoch 621/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 3.4154e-04\n",
      "Epoch 622/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 3.4106e-04\n",
      "Epoch 623/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 3.4058e-04\n",
      "Epoch 624/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 3.4012e-04\n",
      "Epoch 625/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 3.3964e-04\n",
      "Epoch 626/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0013 - val_loss: 3.3919e-04\n",
      "Epoch 627/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 3.3872e-04\n",
      "Epoch 628/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 3.3827e-04\n",
      "Epoch 629/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 3.3782e-04\n",
      "Epoch 630/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 3.3737e-04\n",
      "Epoch 631/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 3.3694e-04\n",
      "Epoch 632/1000\n",
      "32/32 [==============================] - 0s 165us/step - loss: 0.0013 - val_loss: 3.3649e-04\n",
      "Epoch 633/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 3.3603e-04\n",
      "Epoch 634/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 3.3559e-04\n",
      "Epoch 635/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 3.3516e-04\n",
      "Epoch 636/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 3.3473e-04\n",
      "Epoch 637/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0013 - val_loss: 3.3429e-04\n",
      "Epoch 638/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 3.3386e-04\n",
      "Epoch 639/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 3.3341e-04\n",
      "Epoch 640/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 3.3300e-04\n",
      "Epoch 641/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 3.3257e-04\n",
      "Epoch 642/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 3.3216e-04\n",
      "Epoch 643/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 3.3174e-04\n",
      "Epoch 644/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0013 - val_loss: 3.3133e-04\n",
      "Epoch 645/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 3.3092e-04\n",
      "Epoch 646/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 3.3052e-04\n",
      "Epoch 647/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 3.3010e-04\n",
      "Epoch 648/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 3.2970e-04\n",
      "Epoch 649/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 3.2928e-04\n",
      "Epoch 650/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 3.2888e-04\n",
      "Epoch 651/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 3.2847e-04\n",
      "Epoch 652/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 3.2808e-04\n",
      "Epoch 653/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 3.2769e-04\n",
      "Epoch 654/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 3.2729e-04\n",
      "Epoch 655/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 3.2690e-04\n",
      "Epoch 656/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 3.2650e-04\n",
      "Epoch 657/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 3.2612e-04\n",
      "Epoch 658/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 3.2575e-04\n",
      "Epoch 659/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 3.2536e-04\n",
      "Epoch 660/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 3.2497e-04\n",
      "Epoch 661/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 3.2460e-04\n",
      "Epoch 662/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 3.2421e-04\n",
      "Epoch 663/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 3.2384e-04\n",
      "Epoch 664/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 3.2346e-04\n",
      "Epoch 665/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 3.2309e-04\n",
      "Epoch 666/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 0.0012 - val_loss: 3.2271e-04\n",
      "Epoch 667/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 3.2235e-04\n",
      "Epoch 668/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 3.2199e-04\n",
      "Epoch 669/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 3.2164e-04\n",
      "Epoch 670/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 3.2127e-04\n",
      "Epoch 671/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 3.2091e-04\n",
      "Epoch 672/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 3.2055e-04\n",
      "Epoch 673/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 3.2019e-04\n",
      "Epoch 674/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 3.1983e-04\n",
      "Epoch 675/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 3.1947e-04\n",
      "Epoch 676/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 3.1911e-04\n",
      "Epoch 677/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 3.1875e-04\n",
      "Epoch 678/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 3.1842e-04\n",
      "Epoch 679/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 3.1805e-04\n",
      "Epoch 680/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 3.1771e-04\n",
      "Epoch 681/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 3.1736e-04\n",
      "Epoch 682/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 3.1703e-04\n",
      "Epoch 683/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 3.1669e-04\n",
      "Epoch 684/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 0.0011 - val_loss: 3.1635e-04\n",
      "Epoch 685/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 3.1602e-04\n",
      "Epoch 686/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0011 - val_loss: 3.1570e-04\n",
      "Epoch 687/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 3.1534e-04\n",
      "Epoch 688/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 3.1500e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 689/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 3.1467e-04\n",
      "Epoch 690/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 3.1435e-04\n",
      "Epoch 691/1000\n",
      "32/32 [==============================] - 0s 172us/step - loss: 0.0011 - val_loss: 3.1401e-04\n",
      "Epoch 692/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 3.1368e-04\n",
      "Epoch 693/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0011 - val_loss: 3.1337e-04\n",
      "Epoch 694/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0011 - val_loss: 3.1303e-04\n",
      "Epoch 695/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 3.1272e-04\n",
      "Epoch 696/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 3.1240e-04\n",
      "Epoch 697/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 3.1207e-04\n",
      "Epoch 698/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 3.1174e-04\n",
      "Epoch 699/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 3.1143e-04\n",
      "Epoch 700/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0011 - val_loss: 3.1110e-04\n",
      "Epoch 701/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0011 - val_loss: 3.1080e-04\n",
      "Epoch 702/1000\n",
      "32/32 [==============================] - 0s 127us/step - loss: 0.0011 - val_loss: 3.1047e-04\n",
      "Epoch 703/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 3.1016e-04\n",
      "Epoch 704/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0011 - val_loss: 3.0986e-04\n",
      "Epoch 705/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 3.0955e-04\n",
      "Epoch 706/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0011 - val_loss: 3.0923e-04\n",
      "Epoch 707/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 3.0892e-04\n",
      "Epoch 708/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 3.0861e-04\n",
      "Epoch 709/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 3.0830e-04\n",
      "Epoch 710/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0011 - val_loss: 3.0800e-04\n",
      "Epoch 711/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 3.0769e-04\n",
      "Epoch 712/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 3.0740e-04\n",
      "Epoch 713/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 3.0710e-04\n",
      "Epoch 714/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0011 - val_loss: 3.0680e-04\n",
      "Epoch 715/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 3.0649e-04\n",
      "Epoch 716/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 3.0620e-04\n",
      "Epoch 717/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 3.0590e-04\n",
      "Epoch 718/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 3.0560e-04\n",
      "Epoch 719/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 3.0531e-04\n",
      "Epoch 720/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 3.0501e-04\n",
      "Epoch 721/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0011 - val_loss: 3.0472e-04\n",
      "Epoch 722/1000\n",
      "32/32 [==============================] - 0s 169us/step - loss: 0.0011 - val_loss: 3.0442e-04\n",
      "Epoch 723/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 3.0413e-04\n",
      "Epoch 724/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 3.0384e-04\n",
      "Epoch 725/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0011 - val_loss: 3.0356e-04\n",
      "Epoch 726/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 3.0327e-04\n",
      "Epoch 727/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 3.0299e-04\n",
      "Epoch 728/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0010 - val_loss: 3.0271e-04\n",
      "Epoch 729/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 3.0242e-04\n",
      "Epoch 730/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 3.0213e-04\n",
      "Epoch 731/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0010 - val_loss: 3.0184e-04\n",
      "Epoch 732/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 3.0156e-04\n",
      "Epoch 733/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 3.0128e-04\n",
      "Epoch 734/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0010 - val_loss: 3.0100e-04\n",
      "Epoch 735/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 3.0073e-04\n",
      "Epoch 736/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0010 - val_loss: 3.0044e-04\n",
      "Epoch 737/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 3.0017e-04\n",
      "Epoch 738/1000\n",
      "32/32 [==============================] - 0s 162us/step - loss: 0.0010 - val_loss: 2.9990e-04\n",
      "Epoch 739/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 2.9963e-04\n",
      "Epoch 740/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 2.9935e-04\n",
      "Epoch 741/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 2.9907e-04\n",
      "Epoch 742/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 2.9881e-04\n",
      "Epoch 743/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0010 - val_loss: 2.9855e-04\n",
      "Epoch 744/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 2.9826e-04\n",
      "Epoch 745/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 2.9799e-04\n",
      "Epoch 746/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0010 - val_loss: 2.9771e-04\n",
      "Epoch 747/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0010 - val_loss: 2.9744e-04\n",
      "Epoch 748/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 2.9717e-04\n",
      "Epoch 749/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0010 - val_loss: 2.9691e-04\n",
      "Epoch 750/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.9988e-04 - val_loss: 2.9665e-04\n",
      "Epoch 751/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.9791e-04 - val_loss: 2.9637e-04\n",
      "Epoch 752/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.9593e-04 - val_loss: 2.9610e-04\n",
      "Epoch 753/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.9398e-04 - val_loss: 2.9585e-04\n",
      "Epoch 754/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.9201e-04 - val_loss: 2.9559e-04\n",
      "Epoch 755/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 9.9007e-04 - val_loss: 2.9534e-04\n",
      "Epoch 756/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.8813e-04 - val_loss: 2.9506e-04\n",
      "Epoch 757/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.8619e-04 - val_loss: 2.9481e-04\n",
      "Epoch 758/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.8427e-04 - val_loss: 2.9454e-04\n",
      "Epoch 759/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.8234e-04 - val_loss: 2.9429e-04\n",
      "Epoch 760/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.8042e-04 - val_loss: 2.9402e-04\n",
      "Epoch 761/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.7851e-04 - val_loss: 2.9376e-04\n",
      "Epoch 762/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.7660e-04 - val_loss: 2.9350e-04\n",
      "Epoch 763/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.7471e-04 - val_loss: 2.9324e-04\n",
      "Epoch 764/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.7281e-04 - val_loss: 2.9298e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 765/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 9.7091e-04 - val_loss: 2.9273e-04\n",
      "Epoch 766/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6903e-04 - val_loss: 2.9248e-04\n",
      "Epoch 767/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.6716e-04 - val_loss: 2.9222e-04\n",
      "Epoch 768/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 9.6529e-04 - val_loss: 2.9197e-04\n",
      "Epoch 769/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6343e-04 - val_loss: 2.9172e-04\n",
      "Epoch 770/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6157e-04 - val_loss: 2.9148e-04\n",
      "Epoch 771/1000\n",
      "32/32 [==============================] - 0s 183us/step - loss: 9.5972e-04 - val_loss: 2.9123e-04\n",
      "Epoch 772/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.5787e-04 - val_loss: 2.9098e-04\n",
      "Epoch 773/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 9.5603e-04 - val_loss: 2.9072e-04\n",
      "Epoch 774/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.5419e-04 - val_loss: 2.9047e-04\n",
      "Epoch 775/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.5235e-04 - val_loss: 2.9022e-04\n",
      "Epoch 776/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.5054e-04 - val_loss: 2.8996e-04\n",
      "Epoch 777/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4871e-04 - val_loss: 2.8971e-04\n",
      "Epoch 778/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4690e-04 - val_loss: 2.8947e-04\n",
      "Epoch 779/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4509e-04 - val_loss: 2.8922e-04\n",
      "Epoch 780/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4330e-04 - val_loss: 2.8898e-04\n",
      "Epoch 781/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4149e-04 - val_loss: 2.8874e-04\n",
      "Epoch 782/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3970e-04 - val_loss: 2.8849e-04\n",
      "Epoch 783/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.3791e-04 - val_loss: 2.8824e-04\n",
      "Epoch 784/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.3613e-04 - val_loss: 2.8800e-04\n",
      "Epoch 785/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3435e-04 - val_loss: 2.8776e-04\n",
      "Epoch 786/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3258e-04 - val_loss: 2.8751e-04\n",
      "Epoch 787/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.3081e-04 - val_loss: 2.8727e-04\n",
      "Epoch 788/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.2906e-04 - val_loss: 2.8703e-04\n",
      "Epoch 789/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.2730e-04 - val_loss: 2.8679e-04\n",
      "Epoch 790/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.2555e-04 - val_loss: 2.8655e-04\n",
      "Epoch 791/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.2381e-04 - val_loss: 2.8632e-04\n",
      "Epoch 792/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 9.2207e-04 - val_loss: 2.8607e-04\n",
      "Epoch 793/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.2033e-04 - val_loss: 2.8583e-04\n",
      "Epoch 794/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.1860e-04 - val_loss: 2.8558e-04\n",
      "Epoch 795/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.1688e-04 - val_loss: 2.8535e-04\n",
      "Epoch 796/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.1515e-04 - val_loss: 2.8512e-04\n",
      "Epoch 797/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1345e-04 - val_loss: 2.8488e-04\n",
      "Epoch 798/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.1174e-04 - val_loss: 2.8465e-04\n",
      "Epoch 799/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.1003e-04 - val_loss: 2.8440e-04\n",
      "Epoch 800/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.0833e-04 - val_loss: 2.8418e-04\n",
      "Epoch 801/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.0664e-04 - val_loss: 2.8394e-04\n",
      "Epoch 802/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.0496e-04 - val_loss: 2.8370e-04\n",
      "Epoch 803/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.0327e-04 - val_loss: 2.8347e-04\n",
      "Epoch 804/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.0158e-04 - val_loss: 2.8323e-04\n",
      "Epoch 805/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.9991e-04 - val_loss: 2.8299e-04\n",
      "Epoch 806/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.9823e-04 - val_loss: 2.8276e-04\n",
      "Epoch 807/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9657e-04 - val_loss: 2.8253e-04\n",
      "Epoch 808/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.9491e-04 - val_loss: 2.8230e-04\n",
      "Epoch 809/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.9326e-04 - val_loss: 2.8207e-04\n",
      "Epoch 810/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 8.9160e-04 - val_loss: 2.8183e-04\n",
      "Epoch 811/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.8996e-04 - val_loss: 2.8159e-04\n",
      "Epoch 812/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.8831e-04 - val_loss: 2.8137e-04\n",
      "Epoch 813/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 8.8668e-04 - val_loss: 2.8114e-04\n",
      "Epoch 814/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.8504e-04 - val_loss: 2.8091e-04\n",
      "Epoch 815/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 8.8341e-04 - val_loss: 2.8067e-04\n",
      "Epoch 816/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.8179e-04 - val_loss: 2.8046e-04\n",
      "Epoch 817/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.8017e-04 - val_loss: 2.8023e-04\n",
      "Epoch 818/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7856e-04 - val_loss: 2.8000e-04\n",
      "Epoch 819/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7694e-04 - val_loss: 2.7978e-04\n",
      "Epoch 820/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7535e-04 - val_loss: 2.7956e-04\n",
      "Epoch 821/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.7374e-04 - val_loss: 2.7933e-04\n",
      "Epoch 822/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.7214e-04 - val_loss: 2.7910e-04\n",
      "Epoch 823/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.7056e-04 - val_loss: 2.7887e-04\n",
      "Epoch 824/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 8.6897e-04 - val_loss: 2.7865e-04\n",
      "Epoch 825/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 8.6739e-04 - val_loss: 2.7841e-04\n",
      "Epoch 826/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.6580e-04 - val_loss: 2.7820e-04\n",
      "Epoch 827/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.6424e-04 - val_loss: 2.7796e-04\n",
      "Epoch 828/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.6266e-04 - val_loss: 2.7773e-04\n",
      "Epoch 829/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.6110e-04 - val_loss: 2.7751e-04\n",
      "Epoch 830/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5953e-04 - val_loss: 2.7729e-04\n",
      "Epoch 831/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5799e-04 - val_loss: 2.7707e-04\n",
      "Epoch 832/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.5643e-04 - val_loss: 2.7685e-04\n",
      "Epoch 833/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.5488e-04 - val_loss: 2.7662e-04\n",
      "Epoch 834/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.5334e-04 - val_loss: 2.7640e-04\n",
      "Epoch 835/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.5180e-04 - val_loss: 2.7618e-04\n",
      "Epoch 836/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.5027e-04 - val_loss: 2.7597e-04\n",
      "Epoch 837/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.4874e-04 - val_loss: 2.7575e-04\n",
      "Epoch 838/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.4720e-04 - val_loss: 2.7552e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 839/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.4568e-04 - val_loss: 2.7530e-04\n",
      "Epoch 840/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 8.4416e-04 - val_loss: 2.7507e-04\n",
      "Epoch 841/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.4265e-04 - val_loss: 2.7485e-04\n",
      "Epoch 842/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.4114e-04 - val_loss: 2.7463e-04\n",
      "Epoch 843/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.3962e-04 - val_loss: 2.7441e-04\n",
      "Epoch 844/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.3813e-04 - val_loss: 2.7419e-04\n",
      "Epoch 845/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3663e-04 - val_loss: 2.7397e-04\n",
      "Epoch 846/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3514e-04 - val_loss: 2.7377e-04\n",
      "Epoch 847/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.3364e-04 - val_loss: 2.7354e-04\n",
      "Epoch 848/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3217e-04 - val_loss: 2.7332e-04\n",
      "Epoch 849/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3067e-04 - val_loss: 2.7309e-04\n",
      "Epoch 850/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2919e-04 - val_loss: 2.7288e-04\n",
      "Epoch 851/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2773e-04 - val_loss: 2.7267e-04\n",
      "Epoch 852/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2626e-04 - val_loss: 2.7244e-04\n",
      "Epoch 853/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2479e-04 - val_loss: 2.7223e-04\n",
      "Epoch 854/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2332e-04 - val_loss: 2.7202e-04\n",
      "Epoch 855/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 8.2186e-04 - val_loss: 2.7181e-04\n",
      "Epoch 856/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.2041e-04 - val_loss: 2.7158e-04\n",
      "Epoch 857/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.1896e-04 - val_loss: 2.7137e-04\n",
      "Epoch 858/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.1751e-04 - val_loss: 2.7116e-04\n",
      "Epoch 859/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.1607e-04 - val_loss: 2.7094e-04\n",
      "Epoch 860/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.1463e-04 - val_loss: 2.7072e-04\n",
      "Epoch 861/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.1320e-04 - val_loss: 2.7050e-04\n",
      "Epoch 862/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.1176e-04 - val_loss: 2.7028e-04\n",
      "Epoch 863/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.1033e-04 - val_loss: 2.7007e-04\n",
      "Epoch 864/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.0890e-04 - val_loss: 2.6986e-04\n",
      "Epoch 865/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 8.0748e-04 - val_loss: 2.6965e-04\n",
      "Epoch 866/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.0608e-04 - val_loss: 2.6943e-04\n",
      "Epoch 867/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0465e-04 - val_loss: 2.6923e-04\n",
      "Epoch 868/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.0324e-04 - val_loss: 2.6901e-04\n",
      "Epoch 869/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.0184e-04 - val_loss: 2.6881e-04\n",
      "Epoch 870/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0044e-04 - val_loss: 2.6860e-04\n",
      "Epoch 871/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9904e-04 - val_loss: 2.6838e-04\n",
      "Epoch 872/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9764e-04 - val_loss: 2.6816e-04\n",
      "Epoch 873/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.9624e-04 - val_loss: 2.6794e-04\n",
      "Epoch 874/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.9486e-04 - val_loss: 2.6773e-04\n",
      "Epoch 875/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9347e-04 - val_loss: 2.6752e-04\n",
      "Epoch 876/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9210e-04 - val_loss: 2.6731e-04\n",
      "Epoch 877/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.9072e-04 - val_loss: 2.6710e-04\n",
      "Epoch 878/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8934e-04 - val_loss: 2.6689e-04\n",
      "Epoch 879/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8797e-04 - val_loss: 2.6668e-04\n",
      "Epoch 880/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.8660e-04 - val_loss: 2.6647e-04\n",
      "Epoch 881/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8524e-04 - val_loss: 2.6625e-04\n",
      "Epoch 882/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.8387e-04 - val_loss: 2.6603e-04\n",
      "Epoch 883/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8252e-04 - val_loss: 2.6582e-04\n",
      "Epoch 884/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8117e-04 - val_loss: 2.6561e-04\n",
      "Epoch 885/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 7.7982e-04 - val_loss: 2.6540e-04\n",
      "Epoch 886/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7847e-04 - val_loss: 2.6520e-04\n",
      "Epoch 887/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.7713e-04 - val_loss: 2.6499e-04\n",
      "Epoch 888/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 7.7578e-04 - val_loss: 2.6479e-04\n",
      "Epoch 889/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.7445e-04 - val_loss: 2.6458e-04\n",
      "Epoch 890/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.7311e-04 - val_loss: 2.6437e-04\n",
      "Epoch 891/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7178e-04 - val_loss: 2.6416e-04\n",
      "Epoch 892/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.7046e-04 - val_loss: 2.6395e-04\n",
      "Epoch 893/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6914e-04 - val_loss: 2.6375e-04\n",
      "Epoch 894/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 7.6781e-04 - val_loss: 2.6354e-04\n",
      "Epoch 895/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.6651e-04 - val_loss: 2.6333e-04\n",
      "Epoch 896/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.6518e-04 - val_loss: 2.6313e-04\n",
      "Epoch 897/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6387e-04 - val_loss: 2.6292e-04\n",
      "Epoch 898/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6257e-04 - val_loss: 2.6271e-04\n",
      "Epoch 899/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.6127e-04 - val_loss: 2.6250e-04\n",
      "Epoch 900/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5997e-04 - val_loss: 2.6229e-04\n",
      "Epoch 901/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5867e-04 - val_loss: 2.6209e-04\n",
      "Epoch 902/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5736e-04 - val_loss: 2.6188e-04\n",
      "Epoch 903/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.5608e-04 - val_loss: 2.6167e-04\n",
      "Epoch 904/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 7.5479e-04 - val_loss: 2.6147e-04\n",
      "Epoch 905/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.5351e-04 - val_loss: 2.6127e-04\n",
      "Epoch 906/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5222e-04 - val_loss: 2.6106e-04\n",
      "Epoch 907/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.5096e-04 - val_loss: 2.6085e-04\n",
      "Epoch 908/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 7.4967e-04 - val_loss: 2.6065e-04\n",
      "Epoch 909/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.4840e-04 - val_loss: 2.6044e-04\n",
      "Epoch 910/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.4713e-04 - val_loss: 2.6024e-04\n",
      "Epoch 911/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.4587e-04 - val_loss: 2.6003e-04\n",
      "Epoch 912/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4460e-04 - val_loss: 2.5983e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 913/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.4334e-04 - val_loss: 2.5963e-04\n",
      "Epoch 914/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.4208e-04 - val_loss: 2.5943e-04\n",
      "Epoch 915/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.4082e-04 - val_loss: 2.5922e-04\n",
      "Epoch 916/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.3957e-04 - val_loss: 2.5902e-04\n",
      "Epoch 917/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3833e-04 - val_loss: 2.5882e-04\n",
      "Epoch 918/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3709e-04 - val_loss: 2.5861e-04\n",
      "Epoch 919/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.3584e-04 - val_loss: 2.5840e-04\n",
      "Epoch 920/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.3460e-04 - val_loss: 2.5819e-04\n",
      "Epoch 921/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.3337e-04 - val_loss: 2.5799e-04\n",
      "Epoch 922/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3213e-04 - val_loss: 2.5778e-04\n",
      "Epoch 923/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.3090e-04 - val_loss: 2.5756e-04\n",
      "Epoch 924/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2967e-04 - val_loss: 2.5737e-04\n",
      "Epoch 925/1000\n",
      "32/32 [==============================] - 0s 217us/step - loss: 7.2844e-04 - val_loss: 2.5717e-04\n",
      "Epoch 926/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.2723e-04 - val_loss: 2.5696e-04\n",
      "Epoch 927/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.2601e-04 - val_loss: 2.5676e-04\n",
      "Epoch 928/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2480e-04 - val_loss: 2.5655e-04\n",
      "Epoch 929/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.2359e-04 - val_loss: 2.5637e-04\n",
      "Epoch 930/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2236e-04 - val_loss: 2.5616e-04\n",
      "Epoch 931/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.2116e-04 - val_loss: 2.5597e-04\n",
      "Epoch 932/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.1996e-04 - val_loss: 2.5577e-04\n",
      "Epoch 933/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1875e-04 - val_loss: 2.5556e-04\n",
      "Epoch 934/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1757e-04 - val_loss: 2.5536e-04\n",
      "Epoch 935/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.1637e-04 - val_loss: 2.5515e-04\n",
      "Epoch 936/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.1518e-04 - val_loss: 2.5495e-04\n",
      "Epoch 937/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1398e-04 - val_loss: 2.5474e-04\n",
      "Epoch 938/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1279e-04 - val_loss: 2.5453e-04\n",
      "Epoch 939/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.1161e-04 - val_loss: 2.5433e-04\n",
      "Epoch 940/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1043e-04 - val_loss: 2.5412e-04\n",
      "Epoch 941/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0925e-04 - val_loss: 2.5393e-04\n",
      "Epoch 942/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.0807e-04 - val_loss: 2.5372e-04\n",
      "Epoch 943/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0689e-04 - val_loss: 2.5353e-04\n",
      "Epoch 944/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0572e-04 - val_loss: 2.5332e-04\n",
      "Epoch 945/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0455e-04 - val_loss: 2.5313e-04\n",
      "Epoch 946/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0339e-04 - val_loss: 2.5292e-04\n",
      "Epoch 947/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 7.0223e-04 - val_loss: 2.5272e-04\n",
      "Epoch 948/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.0106e-04 - val_loss: 2.5253e-04\n",
      "Epoch 949/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.9991e-04 - val_loss: 2.5232e-04\n",
      "Epoch 950/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.9875e-04 - val_loss: 2.5213e-04\n",
      "Epoch 951/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9761e-04 - val_loss: 2.5192e-04\n",
      "Epoch 952/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.9646e-04 - val_loss: 2.5172e-04\n",
      "Epoch 953/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9530e-04 - val_loss: 2.5152e-04\n",
      "Epoch 954/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9415e-04 - val_loss: 2.5132e-04\n",
      "Epoch 955/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9301e-04 - val_loss: 2.5111e-04\n",
      "Epoch 956/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9187e-04 - val_loss: 2.5091e-04\n",
      "Epoch 957/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.9074e-04 - val_loss: 2.5071e-04\n",
      "Epoch 958/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8960e-04 - val_loss: 2.5051e-04\n",
      "Epoch 959/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.8848e-04 - val_loss: 2.5031e-04\n",
      "Epoch 960/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.8735e-04 - val_loss: 2.5011e-04\n",
      "Epoch 961/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8622e-04 - val_loss: 2.4991e-04\n",
      "Epoch 962/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8509e-04 - val_loss: 2.4973e-04\n",
      "Epoch 963/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.8397e-04 - val_loss: 2.4952e-04\n",
      "Epoch 964/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8285e-04 - val_loss: 2.4933e-04\n",
      "Epoch 965/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 6.8173e-04 - val_loss: 2.4913e-04\n",
      "Epoch 966/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8062e-04 - val_loss: 2.4893e-04\n",
      "Epoch 967/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.7951e-04 - val_loss: 2.4872e-04\n",
      "Epoch 968/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7840e-04 - val_loss: 2.4851e-04\n",
      "Epoch 969/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.7729e-04 - val_loss: 2.4831e-04\n",
      "Epoch 970/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7619e-04 - val_loss: 2.4812e-04\n",
      "Epoch 971/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.7510e-04 - val_loss: 2.4791e-04\n",
      "Epoch 972/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7399e-04 - val_loss: 2.4771e-04\n",
      "Epoch 973/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7290e-04 - val_loss: 2.4752e-04\n",
      "Epoch 974/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.7180e-04 - val_loss: 2.4732e-04\n",
      "Epoch 975/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7071e-04 - val_loss: 2.4713e-04\n",
      "Epoch 976/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.6962e-04 - val_loss: 2.4694e-04\n",
      "Epoch 977/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6853e-04 - val_loss: 2.4674e-04\n",
      "Epoch 978/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6744e-04 - val_loss: 2.4654e-04\n",
      "Epoch 979/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.6635e-04 - val_loss: 2.4634e-04\n",
      "Epoch 980/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6528e-04 - val_loss: 2.4614e-04\n",
      "Epoch 981/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 6.6421e-04 - val_loss: 2.4594e-04\n",
      "Epoch 982/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.6313e-04 - val_loss: 2.4575e-04\n",
      "Epoch 983/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.6205e-04 - val_loss: 2.4554e-04\n",
      "Epoch 984/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6098e-04 - val_loss: 2.4534e-04\n",
      "Epoch 985/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.5991e-04 - val_loss: 2.4513e-04\n",
      "Epoch 986/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.5885e-04 - val_loss: 2.4495e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 987/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5779e-04 - val_loss: 2.4475e-04\n",
      "Epoch 988/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.5672e-04 - val_loss: 2.4454e-04\n",
      "Epoch 989/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5566e-04 - val_loss: 2.4435e-04\n",
      "Epoch 990/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5461e-04 - val_loss: 2.4414e-04\n",
      "Epoch 991/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.5355e-04 - val_loss: 2.4396e-04\n",
      "Epoch 992/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.5250e-04 - val_loss: 2.4377e-04\n",
      "Epoch 993/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.5145e-04 - val_loss: 2.4357e-04\n",
      "Epoch 994/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.5041e-04 - val_loss: 2.4337e-04\n",
      "Epoch 995/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4936e-04 - val_loss: 2.4318e-04\n",
      "Epoch 996/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.4830e-04 - val_loss: 2.4299e-04\n",
      "Epoch 997/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.4728e-04 - val_loss: 2.4279e-04\n",
      "Epoch 998/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4624e-04 - val_loss: 2.4257e-04\n",
      "Epoch 999/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.4520e-04 - val_loss: 2.4238e-04\n",
      "Epoch 1000/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4417e-04 - val_loss: 2.4218e-04\n",
      "9.194800077239051e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.54972893, -0.678983  ,  0.63555014,  1.0720394 ,  0.40174437],\n",
       "        [ 0.8432477 , -0.3559134 , -0.84869003,  0.00250493, -0.81218654],\n",
       "        [ 1.0256863 , -1.6136305 ,  1.1682248 ,  0.6581044 ,  1.0225453 ]],\n",
       "       dtype=float32),\n",
       " array([-0.9119816 , -0.58590555, -0.7766057 ,  0.75616705, -0.90602237],\n",
       "       dtype=float32),\n",
       " array([[ 0.2402422 , -0.9074045 , -0.48534715, -0.6994538 , -0.5002308 ],\n",
       "        [-0.8628928 , -0.5048205 , -0.7996956 , -0.5149932 , -0.60349137],\n",
       "        [ 0.5182076 , -0.5165274 , -0.60075426, -0.9451504 , -0.33365694],\n",
       "        [ 0.01527457, -0.46545038,  0.5315274 ,  0.05733462, -0.73718655],\n",
       "        [ 0.6223832 , -0.24265811,  0.57777816, -0.48810044, -0.39313772]],\n",
       "       dtype=float32),\n",
       " array([1.0144831 , 1.0199761 , 1.0346524 , 1.0254389 , 0.59769267],\n",
       "       dtype=float32),\n",
       " array([[0.48527893],\n",
       "        [0.98558635],\n",
       "        [0.5632267 ],\n",
       "        [1.0210392 ],\n",
       "        [0.15988076]], dtype=float32),\n",
       " array([1.003348], dtype=float32)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_challenger, history_challenger, evaluate_challenger=NN_model_structure_regression_1(X_train_challenger, X_val_challenger, Y_train_challenger, Y_val_challenger, adam2, 32, 1000, x_test_challenger, y_test_challenger)\n",
    "model_challenger.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_challenger.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_challenger_structure1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_58 (Dense)             (None, 5)                 20        \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 91\n",
      "Trainable params: 91\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 32 samples, validate on 7 samples\n",
      "Epoch 1/1000\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 36.5867 - val_loss: 31.7859\n",
      "Epoch 2/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 33.7386 - val_loss: 28.9485\n",
      "Epoch 3/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 30.3846 - val_loss: 25.0003\n",
      "Epoch 4/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 26.4157 - val_loss: 19.8764\n",
      "Epoch 5/1000\n",
      "32/32 [==============================] - 0s 131us/step - loss: 21.4723 - val_loss: 13.9930\n",
      "Epoch 6/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 15.6365 - val_loss: 8.4758\n",
      "Epoch 7/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.6176 - val_loss: 4.8566\n",
      "Epoch 8/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 4.5940 - val_loss: 4.2294\n",
      "Epoch 9/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0761 - val_loss: 5.9423\n",
      "Epoch 10/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9690 - val_loss: 7.1175\n",
      "Epoch 11/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4219 - val_loss: 6.1465\n",
      "Epoch 12/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.2034 - val_loss: 3.9996\n",
      "Epoch 13/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.7851 - val_loss: 1.9111\n",
      "Epoch 14/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.5874 - val_loss: 0.5824\n",
      "Epoch 15/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.8824 - val_loss: 0.1399\n",
      "Epoch 16/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1469 - val_loss: 0.3663\n",
      "Epoch 17/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.2499 - val_loss: 0.9229\n",
      "Epoch 18/1000\n",
      "32/32 [==============================] - 0s 131us/step - loss: 0.7814 - val_loss: 1.4950\n",
      "Epoch 19/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.3298 - val_loss: 1.8727\n",
      "Epoch 20/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.6549 - val_loss: 1.9735\n",
      "Epoch 21/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 1.7008 - val_loss: 1.8178\n",
      "Epoch 22/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5194 - val_loss: 1.4849\n",
      "Epoch 23/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.2017 - val_loss: 1.0751\n",
      "Epoch 24/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.8400 - val_loss: 0.6837\n",
      "Epoch 25/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.5133 - val_loss: 0.3846\n",
      "Epoch 26/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.2805 - val_loss: 0.2206\n",
      "Epoch 27/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.1756 - val_loss: 0.1948\n",
      "Epoch 28/1000\n",
      "32/32 [==============================] - 0s 145us/step - loss: 0.2001 - val_loss: 0.2684\n",
      "Epoch 29/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.3158 - val_loss: 0.3719\n",
      "Epoch 30/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.4497 - val_loss: 0.4340\n",
      "Epoch 31/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.5248 - val_loss: 0.4160\n",
      "Epoch 32/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.5015 - val_loss: 0.3261\n",
      "Epoch 33/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.3955 - val_loss: 0.2046\n",
      "Epoch 34/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.2595 - val_loss: 0.0959\n",
      "Epoch 35/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.1467 - val_loss: 0.0281\n",
      "Epoch 36/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0872 - val_loss: 0.0068\n",
      "Epoch 37/1000\n",
      "32/32 [==============================] - 0s 190us/step - loss: 0.0823 - val_loss: 0.0211\n",
      "Epoch 38/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1137 - val_loss: 0.0524\n",
      "Epoch 39/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1566 - val_loss: 0.0829\n",
      "Epoch 40/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1901 - val_loss: 0.1006\n",
      "Epoch 41/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.2021 - val_loss: 0.1011\n",
      "Epoch 42/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.1898 - val_loss: 0.0868\n",
      "Epoch 43/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1584 - val_loss: 0.0647\n",
      "Epoch 44/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1175 - val_loss: 0.0432\n",
      "Epoch 45/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0785 - val_loss: 0.0294\n",
      "Epoch 46/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0505 - val_loss: 0.0267\n",
      "Epoch 47/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0383 - val_loss: 0.0344\n",
      "Epoch 48/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 0.0414 - val_loss: 0.0480\n",
      "Epoch 49/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0542 - val_loss: 0.0618\n",
      "Epoch 50/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0690 - val_loss: 0.0701\n",
      "Epoch 51/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0786 - val_loss: 0.0703\n",
      "Epoch 52/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0790 - val_loss: 0.0623\n",
      "Epoch 53/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 0.0704 - val_loss: 0.0489\n",
      "Epoch 54/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0559 - val_loss: 0.0340\n",
      "Epoch 55/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0406 - val_loss: 0.0213\n",
      "Epoch 56/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0285 - val_loss: 0.0129\n",
      "Epoch 57/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0219 - val_loss: 0.0093\n",
      "Epoch 58/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0209 - val_loss: 0.0092\n",
      "Epoch 59/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0238 - val_loss: 0.0108\n",
      "Epoch 60/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0281 - val_loss: 0.0121\n",
      "Epoch 61/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 0.0315 - val_loss: 0.0120\n",
      "Epoch 62/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0324 - val_loss: 0.0103\n",
      "Epoch 63/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0305 - val_loss: 0.0074\n",
      "Epoch 64/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0264 - val_loss: 0.0044\n",
      "Epoch 65/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0213 - val_loss: 0.0024\n",
      "Epoch 66/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0166 - val_loss: 0.0019\n",
      "Epoch 67/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 0.0133 - val_loss: 0.0030\n",
      "Epoch 68/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0118 - val_loss: 0.0050\n",
      "Epoch 69/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0120 - val_loss: 0.0071\n",
      "Epoch 70/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0131 - val_loss: 0.0087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0143 - val_loss: 0.0093\n",
      "Epoch 72/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0149 - val_loss: 0.0087\n",
      "Epoch 73/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0146 - val_loss: 0.0072\n",
      "Epoch 74/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0134 - val_loss: 0.0054\n",
      "Epoch 75/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0117 - val_loss: 0.0036\n",
      "Epoch 76/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0099 - val_loss: 0.0021\n",
      "Epoch 77/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0084 - val_loss: 0.0012\n",
      "Epoch 78/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0075 - val_loss: 7.0427e-04\n",
      "Epoch 79/1000\n",
      "32/32 [==============================] - 0s 137us/step - loss: 0.0072 - val_loss: 6.0947e-04\n",
      "Epoch 80/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0073 - val_loss: 7.1824e-04\n",
      "Epoch 81/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0076 - val_loss: 8.8676e-04\n",
      "Epoch 82/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0078 - val_loss: 0.0010\n",
      "Epoch 83/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0077 - val_loss: 0.0011\n",
      "Epoch 84/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0073 - val_loss: 0.0011\n",
      "Epoch 85/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0067 - val_loss: 0.0011\n",
      "Epoch 86/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 0.0060 - val_loss: 0.0011\n",
      "Epoch 87/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0053 - val_loss: 0.0012\n",
      "Epoch 88/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0048 - val_loss: 0.0014\n",
      "Epoch 89/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0046 - val_loss: 0.0016\n",
      "Epoch 90/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0045 - val_loss: 0.0019\n",
      "Epoch 91/1000\n",
      "32/32 [==============================] - 0s 161us/step - loss: 0.0045 - val_loss: 0.0020\n",
      "Epoch 92/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0046 - val_loss: 0.0020\n",
      "Epoch 93/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0045 - val_loss: 0.0020\n",
      "Epoch 94/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0043 - val_loss: 0.0018\n",
      "Epoch 95/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0041 - val_loss: 0.0015\n",
      "Epoch 96/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0037 - val_loss: 0.0013\n",
      "Epoch 97/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0034 - val_loss: 0.0011\n",
      "Epoch 98/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0032 - val_loss: 8.9202e-04\n",
      "Epoch 99/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 7.7776e-04\n",
      "Epoch 100/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0030 - val_loss: 7.0659e-04\n",
      "Epoch 101/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0029 - val_loss: 6.6065e-04\n",
      "Epoch 102/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0029 - val_loss: 6.2392e-04\n",
      "Epoch 103/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 5.8753e-04\n",
      "Epoch 104/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0027 - val_loss: 5.5099e-04\n",
      "Epoch 105/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0026 - val_loss: 5.2010e-04\n",
      "Epoch 106/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0024 - val_loss: 5.0250e-04\n",
      "Epoch 107/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 5.0346e-04\n",
      "Epoch 108/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 5.2304e-04\n",
      "Epoch 109/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 5.5546e-04\n",
      "Epoch 110/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0020 - val_loss: 5.9098e-04\n",
      "Epoch 111/1000\n",
      "32/32 [==============================] - 0s 113us/step - loss: 0.0019 - val_loss: 6.1877e-04\n",
      "Epoch 112/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 6.3000e-04\n",
      "Epoch 113/1000\n",
      "32/32 [==============================] - 0s 184us/step - loss: 0.0018 - val_loss: 6.2009e-04\n",
      "Epoch 114/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0018 - val_loss: 5.8926e-04\n",
      "Epoch 115/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 5.4172e-04\n",
      "Epoch 116/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0016 - val_loss: 4.8406e-04\n",
      "Epoch 117/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0015 - val_loss: 4.2319e-04\n",
      "Epoch 118/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0014 - val_loss: 3.6488e-04\n",
      "Epoch 119/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 0.0014 - val_loss: 3.1293e-04\n",
      "Epoch 120/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0013 - val_loss: 2.6920e-04\n",
      "Epoch 121/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0013 - val_loss: 2.3410e-04\n",
      "Epoch 122/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0013 - val_loss: 2.0724e-04\n",
      "Epoch 123/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 1.8799e-04\n",
      "Epoch 124/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0012 - val_loss: 1.7578e-04\n",
      "Epoch 125/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0011 - val_loss: 1.7012e-04\n",
      "Epoch 126/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 1.7036e-04\n",
      "Epoch 127/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 1.7546e-04\n",
      "Epoch 128/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.9238e-04 - val_loss: 1.8389e-04\n",
      "Epoch 129/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.5451e-04 - val_loss: 1.9368e-04\n",
      "Epoch 130/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 9.2110e-04 - val_loss: 2.0257e-04\n",
      "Epoch 131/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.9117e-04 - val_loss: 2.0855e-04\n",
      "Epoch 132/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.6326e-04 - val_loss: 2.1002e-04\n",
      "Epoch 133/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3594e-04 - val_loss: 2.0621e-04\n",
      "Epoch 134/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0833e-04 - val_loss: 1.9726e-04\n",
      "Epoch 135/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.8027e-04 - val_loss: 1.8415e-04\n",
      "Epoch 136/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5224e-04 - val_loss: 1.6842e-04\n",
      "Epoch 137/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2501e-04 - val_loss: 1.5182e-04\n",
      "Epoch 138/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.9935e-04 - val_loss: 1.3597e-04\n",
      "Epoch 139/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7573e-04 - val_loss: 1.2205e-04\n",
      "Epoch 140/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.5417e-04 - val_loss: 1.1066e-04\n",
      "Epoch 141/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 6.3431e-04 - val_loss: 1.0191e-04\n",
      "Epoch 142/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1559e-04 - val_loss: 9.5552e-05\n",
      "Epoch 143/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.9752e-04 - val_loss: 9.1151e-05\n",
      "Epoch 144/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7968e-04 - val_loss: 8.8294e-05\n",
      "Epoch 145/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6203e-04 - val_loss: 8.6651e-05\n",
      "Epoch 146/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4470e-04 - val_loss: 8.5959e-05\n",
      "Epoch 147/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.2800e-04 - val_loss: 8.5987e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 148/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1219e-04 - val_loss: 8.6425e-05\n",
      "Epoch 149/1000\n",
      "32/32 [==============================] - 0s 199us/step - loss: 4.9743e-04 - val_loss: 8.6929e-05\n",
      "Epoch 150/1000\n",
      "32/32 [==============================] - 0s 165us/step - loss: 4.8374e-04 - val_loss: 8.7117e-05\n",
      "Epoch 151/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 4.7094e-04 - val_loss: 8.6641e-05\n",
      "Epoch 152/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.5880e-04 - val_loss: 8.5313e-05\n",
      "Epoch 153/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4712e-04 - val_loss: 8.3105e-05\n",
      "Epoch 154/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3575e-04 - val_loss: 8.0178e-05\n",
      "Epoch 155/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2468e-04 - val_loss: 7.6822e-05\n",
      "Epoch 156/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1397e-04 - val_loss: 7.3371e-05\n",
      "Epoch 157/1000\n",
      "32/32 [==============================] - 0s 166us/step - loss: 4.0372e-04 - val_loss: 7.0112e-05\n",
      "Epoch 158/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9400e-04 - val_loss: 6.7271e-05\n",
      "Epoch 159/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.8484e-04 - val_loss: 6.4975e-05\n",
      "Epoch 160/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 3.7624e-04 - val_loss: 6.3255e-05\n",
      "Epoch 161/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.6812e-04 - val_loss: 6.2085e-05\n",
      "Epoch 162/1000\n",
      "32/32 [==============================] - 0s 158us/step - loss: 3.6039e-04 - val_loss: 6.1403e-05\n",
      "Epoch 163/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5298e-04 - val_loss: 6.1156e-05\n",
      "Epoch 164/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4583e-04 - val_loss: 6.1257e-05\n",
      "Epoch 165/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 3.3893e-04 - val_loss: 6.1644e-05\n",
      "Epoch 166/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3231e-04 - val_loss: 6.2259e-05\n",
      "Epoch 167/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.2598e-04 - val_loss: 6.3026e-05\n",
      "Epoch 168/1000\n",
      "32/32 [==============================] - 0s 208us/step - loss: 3.1997e-04 - val_loss: 6.3886e-05\n",
      "Epoch 169/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.1428e-04 - val_loss: 6.4758e-05\n",
      "Epoch 170/1000\n",
      "32/32 [==============================] - 0s 209us/step - loss: 3.0890e-04 - val_loss: 6.5600e-05\n",
      "Epoch 171/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0379e-04 - val_loss: 6.6353e-05\n",
      "Epoch 172/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 2.9891e-04 - val_loss: 6.7000e-05\n",
      "Epoch 173/1000\n",
      "32/32 [==============================] - 0s 208us/step - loss: 2.9425e-04 - val_loss: 6.7544e-05\n",
      "Epoch 174/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8978e-04 - val_loss: 6.7987e-05\n",
      "Epoch 175/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.8548e-04 - val_loss: 6.8356e-05\n",
      "Epoch 176/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 2.8137e-04 - val_loss: 6.8669e-05\n",
      "Epoch 177/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.7744e-04 - val_loss: 6.8957e-05\n",
      "Epoch 178/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7371e-04 - val_loss: 6.9251e-05\n",
      "Epoch 179/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.7015e-04 - val_loss: 6.9555e-05\n",
      "Epoch 180/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.6678e-04 - val_loss: 6.9898e-05\n",
      "Epoch 181/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.6357e-04 - val_loss: 7.0271e-05\n",
      "Epoch 182/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.6050e-04 - val_loss: 7.0687e-05\n",
      "Epoch 183/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 2.5757e-04 - val_loss: 7.1155e-05\n",
      "Epoch 184/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 2.5476e-04 - val_loss: 7.1678e-05\n",
      "Epoch 185/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.5207e-04 - val_loss: 7.2224e-05\n",
      "Epoch 186/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.4949e-04 - val_loss: 7.2816e-05\n",
      "Epoch 187/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.4703e-04 - val_loss: 7.3421e-05\n",
      "Epoch 188/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.4467e-04 - val_loss: 7.4027e-05\n",
      "Epoch 189/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4243e-04 - val_loss: 7.4623e-05\n",
      "Epoch 190/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4030e-04 - val_loss: 7.5189e-05\n",
      "Epoch 191/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.3825e-04 - val_loss: 7.5711e-05\n",
      "Epoch 192/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3630e-04 - val_loss: 7.6180e-05\n",
      "Epoch 193/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3443e-04 - val_loss: 7.6596e-05\n",
      "Epoch 194/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3263e-04 - val_loss: 7.6973e-05\n",
      "Epoch 195/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3092e-04 - val_loss: 7.7310e-05\n",
      "Epoch 196/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.2927e-04 - val_loss: 7.7617e-05\n",
      "Epoch 197/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.2769e-04 - val_loss: 7.7908e-05\n",
      "Epoch 198/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.2618e-04 - val_loss: 7.8203e-05\n",
      "Epoch 199/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2473e-04 - val_loss: 7.8508e-05\n",
      "Epoch 200/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.2335e-04 - val_loss: 7.8821e-05\n",
      "Epoch 201/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2202e-04 - val_loss: 7.9155e-05\n",
      "Epoch 202/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2075e-04 - val_loss: 7.9511e-05\n",
      "Epoch 203/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1952e-04 - val_loss: 7.9889e-05\n",
      "Epoch 204/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 2.1835e-04 - val_loss: 8.0293e-05\n",
      "Epoch 205/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.1722e-04 - val_loss: 8.0695e-05\n",
      "Epoch 206/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.1613e-04 - val_loss: 8.1095e-05\n",
      "Epoch 207/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.1509e-04 - val_loss: 8.1500e-05\n",
      "Epoch 208/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.1408e-04 - val_loss: 8.1884e-05\n",
      "Epoch 209/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.1311e-04 - val_loss: 8.2259e-05\n",
      "Epoch 210/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.1218e-04 - val_loss: 8.2606e-05\n",
      "Epoch 211/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.1129e-04 - val_loss: 8.2941e-05\n",
      "Epoch 212/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.1043e-04 - val_loss: 8.3254e-05\n",
      "Epoch 213/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0959e-04 - val_loss: 8.3549e-05\n",
      "Epoch 214/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.0879e-04 - val_loss: 8.3831e-05\n",
      "Epoch 215/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.0802e-04 - val_loss: 8.4097e-05\n",
      "Epoch 216/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0726e-04 - val_loss: 8.4364e-05\n",
      "Epoch 217/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.0654e-04 - val_loss: 8.4617e-05\n",
      "Epoch 218/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0584e-04 - val_loss: 8.4874e-05\n",
      "Epoch 219/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0516e-04 - val_loss: 8.5139e-05\n",
      "Epoch 220/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.0450e-04 - val_loss: 8.5397e-05\n",
      "Epoch 221/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.0387e-04 - val_loss: 8.5645e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 222/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.0325e-04 - val_loss: 8.5897e-05\n",
      "Epoch 223/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.0266e-04 - val_loss: 8.6130e-05\n",
      "Epoch 224/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.0208e-04 - val_loss: 8.6362e-05\n",
      "Epoch 225/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0152e-04 - val_loss: 8.6575e-05\n",
      "Epoch 226/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.0097e-04 - val_loss: 8.6770e-05\n",
      "Epoch 227/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.0044e-04 - val_loss: 8.6950e-05\n",
      "Epoch 228/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.9992e-04 - val_loss: 8.7114e-05\n",
      "Epoch 229/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 1.9942e-04 - val_loss: 8.7268e-05\n",
      "Epoch 230/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9893e-04 - val_loss: 8.7406e-05\n",
      "Epoch 231/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.9846e-04 - val_loss: 8.7536e-05\n",
      "Epoch 232/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 1.9799e-04 - val_loss: 8.7658e-05\n",
      "Epoch 233/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.9754e-04 - val_loss: 8.7777e-05\n",
      "Epoch 234/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.9710e-04 - val_loss: 8.7891e-05\n",
      "Epoch 235/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.9666e-04 - val_loss: 8.8006e-05\n",
      "Epoch 236/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.9624e-04 - val_loss: 8.8113e-05\n",
      "Epoch 237/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9583e-04 - val_loss: 8.8223e-05\n",
      "Epoch 238/1000\n",
      "32/32 [==============================] - 0s 132us/step - loss: 1.9542e-04 - val_loss: 8.8318e-05\n",
      "Epoch 239/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.9503e-04 - val_loss: 8.8415e-05\n",
      "Epoch 240/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.9464e-04 - val_loss: 8.8499e-05\n",
      "Epoch 241/1000\n",
      "32/32 [==============================] - 0s 168us/step - loss: 1.9427e-04 - val_loss: 8.8586e-05\n",
      "Epoch 242/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9390e-04 - val_loss: 8.8669e-05\n",
      "Epoch 243/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9354e-04 - val_loss: 8.8732e-05\n",
      "Epoch 244/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9317e-04 - val_loss: 8.8794e-05\n",
      "Epoch 245/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9283e-04 - val_loss: 8.8845e-05\n",
      "Epoch 246/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.9248e-04 - val_loss: 8.8898e-05\n",
      "Epoch 247/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9215e-04 - val_loss: 8.8939e-05\n",
      "Epoch 248/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.9181e-04 - val_loss: 8.8981e-05\n",
      "Epoch 249/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.9149e-04 - val_loss: 8.9020e-05\n",
      "Epoch 250/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.9117e-04 - val_loss: 8.9051e-05\n",
      "Epoch 251/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9085e-04 - val_loss: 8.9086e-05\n",
      "Epoch 252/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.9054e-04 - val_loss: 8.9111e-05\n",
      "Epoch 253/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.9023e-04 - val_loss: 8.9145e-05\n",
      "Epoch 254/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.8992e-04 - val_loss: 8.9171e-05\n",
      "Epoch 255/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8963e-04 - val_loss: 8.9206e-05\n",
      "Epoch 256/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.8934e-04 - val_loss: 8.9223e-05\n",
      "Epoch 257/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8904e-04 - val_loss: 8.9249e-05\n",
      "Epoch 258/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.8876e-04 - val_loss: 8.9256e-05\n",
      "Epoch 259/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.8848e-04 - val_loss: 8.9271e-05\n",
      "Epoch 260/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8820e-04 - val_loss: 8.9281e-05\n",
      "Epoch 261/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8793e-04 - val_loss: 8.9284e-05\n",
      "Epoch 262/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.8765e-04 - val_loss: 8.9276e-05\n",
      "Epoch 263/1000\n",
      "32/32 [==============================] - 0s 173us/step - loss: 1.8738e-04 - val_loss: 8.9276e-05\n",
      "Epoch 264/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8712e-04 - val_loss: 8.9272e-05\n",
      "Epoch 265/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.8686e-04 - val_loss: 8.9250e-05\n",
      "Epoch 266/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.8660e-04 - val_loss: 8.9238e-05\n",
      "Epoch 267/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8634e-04 - val_loss: 8.9226e-05\n",
      "Epoch 268/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8608e-04 - val_loss: 8.9208e-05\n",
      "Epoch 269/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8583e-04 - val_loss: 8.9189e-05\n",
      "Epoch 270/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8558e-04 - val_loss: 8.9168e-05\n",
      "Epoch 271/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8534e-04 - val_loss: 8.9143e-05\n",
      "Epoch 272/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8509e-04 - val_loss: 8.9118e-05\n",
      "Epoch 273/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8485e-04 - val_loss: 8.9088e-05\n",
      "Epoch 274/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8461e-04 - val_loss: 8.9065e-05\n",
      "Epoch 275/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8437e-04 - val_loss: 8.9026e-05\n",
      "Epoch 276/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8414e-04 - val_loss: 8.8999e-05\n",
      "Epoch 277/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.8390e-04 - val_loss: 8.8964e-05\n",
      "Epoch 278/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.8367e-04 - val_loss: 8.8923e-05\n",
      "Epoch 279/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.8344e-04 - val_loss: 8.8879e-05\n",
      "Epoch 280/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.8321e-04 - val_loss: 8.8850e-05\n",
      "Epoch 281/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.8299e-04 - val_loss: 8.8795e-05\n",
      "Epoch 282/1000\n",
      "32/32 [==============================] - 0s 192us/step - loss: 1.8277e-04 - val_loss: 8.8752e-05\n",
      "Epoch 283/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8254e-04 - val_loss: 8.8716e-05\n",
      "Epoch 284/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8232e-04 - val_loss: 8.8663e-05\n",
      "Epoch 285/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8210e-04 - val_loss: 8.8610e-05\n",
      "Epoch 286/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8189e-04 - val_loss: 8.8558e-05\n",
      "Epoch 287/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8167e-04 - val_loss: 8.8508e-05\n",
      "Epoch 288/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8146e-04 - val_loss: 8.8453e-05\n",
      "Epoch 289/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8124e-04 - val_loss: 8.8406e-05\n",
      "Epoch 290/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8103e-04 - val_loss: 8.8348e-05\n",
      "Epoch 291/1000\n",
      "32/32 [==============================] - 0s 198us/step - loss: 1.8082e-04 - val_loss: 8.8293e-05\n",
      "Epoch 292/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8061e-04 - val_loss: 8.8245e-05\n",
      "Epoch 293/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8040e-04 - val_loss: 8.8185e-05\n",
      "Epoch 294/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.8020e-04 - val_loss: 8.8128e-05\n",
      "Epoch 295/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.8000e-04 - val_loss: 8.8070e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 296/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7979e-04 - val_loss: 8.8012e-05\n",
      "Epoch 297/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.7959e-04 - val_loss: 8.7959e-05\n",
      "Epoch 298/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7939e-04 - val_loss: 8.7888e-05\n",
      "Epoch 299/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7919e-04 - val_loss: 8.7831e-05\n",
      "Epoch 300/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.7899e-04 - val_loss: 8.7762e-05\n",
      "Epoch 301/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7880e-04 - val_loss: 8.7701e-05\n",
      "Epoch 302/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.7860e-04 - val_loss: 8.7640e-05\n",
      "Epoch 303/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 1.7841e-04 - val_loss: 8.7573e-05\n",
      "Epoch 304/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7821e-04 - val_loss: 8.7513e-05\n",
      "Epoch 305/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 1.7802e-04 - val_loss: 8.7442e-05\n",
      "Epoch 306/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 1.7783e-04 - val_loss: 8.7383e-05\n",
      "Epoch 307/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.7764e-04 - val_loss: 8.7316e-05\n",
      "Epoch 308/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.7745e-04 - val_loss: 8.7247e-05\n",
      "Epoch 309/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.7727e-04 - val_loss: 8.7179e-05\n",
      "Epoch 310/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7707e-04 - val_loss: 8.7119e-05\n",
      "Epoch 311/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.7689e-04 - val_loss: 8.7045e-05\n",
      "Epoch 312/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7671e-04 - val_loss: 8.6976e-05\n",
      "Epoch 313/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.7653e-04 - val_loss: 8.6903e-05\n",
      "Epoch 314/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.7634e-04 - val_loss: 8.6838e-05\n",
      "Epoch 315/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7616e-04 - val_loss: 8.6768e-05\n",
      "Epoch 316/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7598e-04 - val_loss: 8.6695e-05\n",
      "Epoch 317/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7580e-04 - val_loss: 8.6620e-05\n",
      "Epoch 318/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7562e-04 - val_loss: 8.6557e-05\n",
      "Epoch 319/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7544e-04 - val_loss: 8.6484e-05\n",
      "Epoch 320/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.7527e-04 - val_loss: 8.6406e-05\n",
      "Epoch 321/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7509e-04 - val_loss: 8.6339e-05\n",
      "Epoch 322/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7491e-04 - val_loss: 8.6267e-05\n",
      "Epoch 323/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7474e-04 - val_loss: 8.6200e-05\n",
      "Epoch 324/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7457e-04 - val_loss: 8.6122e-05\n",
      "Epoch 325/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7439e-04 - val_loss: 8.6043e-05\n",
      "Epoch 326/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.7422e-04 - val_loss: 8.5967e-05\n",
      "Epoch 327/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7405e-04 - val_loss: 8.5899e-05\n",
      "Epoch 328/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7388e-04 - val_loss: 8.5831e-05\n",
      "Epoch 329/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7371e-04 - val_loss: 8.5746e-05\n",
      "Epoch 330/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.7354e-04 - val_loss: 8.5682e-05\n",
      "Epoch 331/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7337e-04 - val_loss: 8.5611e-05\n",
      "Epoch 332/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7321e-04 - val_loss: 8.5532e-05\n",
      "Epoch 333/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.7304e-04 - val_loss: 8.5464e-05\n",
      "Epoch 334/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7288e-04 - val_loss: 8.5380e-05\n",
      "Epoch 335/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7271e-04 - val_loss: 8.5303e-05\n",
      "Epoch 336/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 1.7254e-04 - val_loss: 8.5232e-05\n",
      "Epoch 337/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.7238e-04 - val_loss: 8.5161e-05\n",
      "Epoch 338/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7222e-04 - val_loss: 8.5078e-05\n",
      "Epoch 339/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7206e-04 - val_loss: 8.5004e-05\n",
      "Epoch 340/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7190e-04 - val_loss: 8.4938e-05\n",
      "Epoch 341/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7174e-04 - val_loss: 8.4858e-05\n",
      "Epoch 342/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7157e-04 - val_loss: 8.4780e-05\n",
      "Epoch 343/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.7141e-04 - val_loss: 8.4702e-05\n",
      "Epoch 344/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7126e-04 - val_loss: 8.4626e-05\n",
      "Epoch 345/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7110e-04 - val_loss: 8.4552e-05\n",
      "Epoch 346/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.7095e-04 - val_loss: 8.4473e-05\n",
      "Epoch 347/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7079e-04 - val_loss: 8.4400e-05\n",
      "Epoch 348/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7063e-04 - val_loss: 8.4320e-05\n",
      "Epoch 349/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7048e-04 - val_loss: 8.4254e-05\n",
      "Epoch 350/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7032e-04 - val_loss: 8.4179e-05\n",
      "Epoch 351/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7017e-04 - val_loss: 8.4103e-05\n",
      "Epoch 352/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.7002e-04 - val_loss: 8.4029e-05\n",
      "Epoch 353/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6986e-04 - val_loss: 8.3951e-05\n",
      "Epoch 354/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6971e-04 - val_loss: 8.3873e-05\n",
      "Epoch 355/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.6956e-04 - val_loss: 8.3800e-05\n",
      "Epoch 356/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.6941e-04 - val_loss: 8.3722e-05\n",
      "Epoch 357/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6926e-04 - val_loss: 8.3645e-05\n",
      "Epoch 358/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.6911e-04 - val_loss: 8.3562e-05\n",
      "Epoch 359/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6896e-04 - val_loss: 8.3491e-05\n",
      "Epoch 360/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6881e-04 - val_loss: 8.3413e-05\n",
      "Epoch 361/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6866e-04 - val_loss: 8.3337e-05\n",
      "Epoch 362/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6851e-04 - val_loss: 8.3265e-05\n",
      "Epoch 363/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6837e-04 - val_loss: 8.3189e-05\n",
      "Epoch 364/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.6823e-04 - val_loss: 8.3120e-05\n",
      "Epoch 365/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6808e-04 - val_loss: 8.3038e-05\n",
      "Epoch 366/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.6793e-04 - val_loss: 8.2966e-05\n",
      "Epoch 367/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.6779e-04 - val_loss: 8.2890e-05\n",
      "Epoch 368/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6764e-04 - val_loss: 8.2817e-05\n",
      "Epoch 369/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.6750e-04 - val_loss: 8.2740e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 370/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6736e-04 - val_loss: 8.2665e-05\n",
      "Epoch 371/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6721e-04 - val_loss: 8.2583e-05\n",
      "Epoch 372/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.6707e-04 - val_loss: 8.2503e-05\n",
      "Epoch 373/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6693e-04 - val_loss: 8.2433e-05\n",
      "Epoch 374/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6679e-04 - val_loss: 8.2347e-05\n",
      "Epoch 375/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6665e-04 - val_loss: 8.2282e-05\n",
      "Epoch 376/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 1.6651e-04 - val_loss: 8.2203e-05\n",
      "Epoch 377/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6637e-04 - val_loss: 8.2122e-05\n",
      "Epoch 378/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 1.6623e-04 - val_loss: 8.2048e-05\n",
      "Epoch 379/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6610e-04 - val_loss: 8.1971e-05\n",
      "Epoch 380/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 1.6596e-04 - val_loss: 8.1895e-05\n",
      "Epoch 381/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.6581e-04 - val_loss: 8.1827e-05\n",
      "Epoch 382/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.6568e-04 - val_loss: 8.1745e-05\n",
      "Epoch 383/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.6554e-04 - val_loss: 8.1671e-05\n",
      "Epoch 384/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.6541e-04 - val_loss: 8.1597e-05\n",
      "Epoch 385/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6527e-04 - val_loss: 8.1525e-05\n",
      "Epoch 386/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.6513e-04 - val_loss: 8.1451e-05\n",
      "Epoch 387/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6500e-04 - val_loss: 8.1377e-05\n",
      "Epoch 388/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6487e-04 - val_loss: 8.1302e-05\n",
      "Epoch 389/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.6473e-04 - val_loss: 8.1224e-05\n",
      "Epoch 390/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6460e-04 - val_loss: 8.1153e-05\n",
      "Epoch 391/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 1.6447e-04 - val_loss: 8.1076e-05\n",
      "Epoch 392/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6433e-04 - val_loss: 8.1001e-05\n",
      "Epoch 393/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.6420e-04 - val_loss: 8.0932e-05\n",
      "Epoch 394/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.6407e-04 - val_loss: 8.0849e-05\n",
      "Epoch 395/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6393e-04 - val_loss: 8.0774e-05\n",
      "Epoch 396/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6381e-04 - val_loss: 8.0709e-05\n",
      "Epoch 397/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.6368e-04 - val_loss: 8.0623e-05\n",
      "Epoch 398/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6354e-04 - val_loss: 8.0558e-05\n",
      "Epoch 399/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6342e-04 - val_loss: 8.0486e-05\n",
      "Epoch 400/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6329e-04 - val_loss: 8.0412e-05\n",
      "Epoch 401/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6315e-04 - val_loss: 8.0330e-05\n",
      "Epoch 402/1000\n",
      "32/32 [==============================] - 0s 132us/step - loss: 1.6303e-04 - val_loss: 8.0259e-05\n",
      "Epoch 403/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.6290e-04 - val_loss: 8.0184e-05\n",
      "Epoch 404/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.6277e-04 - val_loss: 8.0111e-05\n",
      "Epoch 405/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6264e-04 - val_loss: 8.0034e-05\n",
      "Epoch 406/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.6252e-04 - val_loss: 7.9971e-05\n",
      "Epoch 407/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6239e-04 - val_loss: 7.9892e-05\n",
      "Epoch 408/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6226e-04 - val_loss: 7.9815e-05\n",
      "Epoch 409/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6214e-04 - val_loss: 7.9739e-05\n",
      "Epoch 410/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6201e-04 - val_loss: 7.9667e-05\n",
      "Epoch 411/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6189e-04 - val_loss: 7.9590e-05\n",
      "Epoch 412/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6176e-04 - val_loss: 7.9522e-05\n",
      "Epoch 413/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6164e-04 - val_loss: 7.9446e-05\n",
      "Epoch 414/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6151e-04 - val_loss: 7.9373e-05\n",
      "Epoch 415/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.6139e-04 - val_loss: 7.9305e-05\n",
      "Epoch 416/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6126e-04 - val_loss: 7.9234e-05\n",
      "Epoch 417/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 1.6114e-04 - val_loss: 7.9154e-05\n",
      "Epoch 418/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.6101e-04 - val_loss: 7.9083e-05\n",
      "Epoch 419/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6090e-04 - val_loss: 7.9010e-05\n",
      "Epoch 420/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6077e-04 - val_loss: 7.8943e-05\n",
      "Epoch 421/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6065e-04 - val_loss: 7.8863e-05\n",
      "Epoch 422/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6053e-04 - val_loss: 7.8792e-05\n",
      "Epoch 423/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6041e-04 - val_loss: 7.8724e-05\n",
      "Epoch 424/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6028e-04 - val_loss: 7.8648e-05\n",
      "Epoch 425/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6016e-04 - val_loss: 7.8577e-05\n",
      "Epoch 426/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6004e-04 - val_loss: 7.8501e-05\n",
      "Epoch 427/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5992e-04 - val_loss: 7.8425e-05\n",
      "Epoch 428/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5980e-04 - val_loss: 7.8358e-05\n",
      "Epoch 429/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5968e-04 - val_loss: 7.8285e-05\n",
      "Epoch 430/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.5957e-04 - val_loss: 7.8209e-05\n",
      "Epoch 431/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5944e-04 - val_loss: 7.8138e-05\n",
      "Epoch 432/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5932e-04 - val_loss: 7.8069e-05\n",
      "Epoch 433/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5921e-04 - val_loss: 7.7993e-05\n",
      "Epoch 434/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5909e-04 - val_loss: 7.7923e-05\n",
      "Epoch 435/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.5897e-04 - val_loss: 7.7847e-05\n",
      "Epoch 436/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5885e-04 - val_loss: 7.7784e-05\n",
      "Epoch 437/1000\n",
      "32/32 [==============================] - 0s 175us/step - loss: 1.5874e-04 - val_loss: 7.7702e-05\n",
      "Epoch 438/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5862e-04 - val_loss: 7.7640e-05\n",
      "Epoch 439/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5850e-04 - val_loss: 7.7566e-05\n",
      "Epoch 440/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5839e-04 - val_loss: 7.7492e-05\n",
      "Epoch 441/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5827e-04 - val_loss: 7.7429e-05\n",
      "Epoch 442/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5815e-04 - val_loss: 7.7352e-05\n",
      "Epoch 443/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.5804e-04 - val_loss: 7.7281e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 444/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5792e-04 - val_loss: 7.7215e-05\n",
      "Epoch 445/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5780e-04 - val_loss: 7.7142e-05\n",
      "Epoch 446/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 1.5769e-04 - val_loss: 7.7068e-05\n",
      "Epoch 447/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.5757e-04 - val_loss: 7.6999e-05\n",
      "Epoch 448/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.5746e-04 - val_loss: 7.6921e-05\n",
      "Epoch 449/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5735e-04 - val_loss: 7.6851e-05\n",
      "Epoch 450/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 1.5723e-04 - val_loss: 7.6779e-05\n",
      "Epoch 451/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5712e-04 - val_loss: 7.6709e-05\n",
      "Epoch 452/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5700e-04 - val_loss: 7.6644e-05\n",
      "Epoch 453/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5689e-04 - val_loss: 7.6575e-05\n",
      "Epoch 454/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5678e-04 - val_loss: 7.6511e-05\n",
      "Epoch 455/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.5666e-04 - val_loss: 7.6436e-05\n",
      "Epoch 456/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.5655e-04 - val_loss: 7.6364e-05\n",
      "Epoch 457/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5644e-04 - val_loss: 7.6297e-05\n",
      "Epoch 458/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5633e-04 - val_loss: 7.6222e-05\n",
      "Epoch 459/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5622e-04 - val_loss: 7.6157e-05\n",
      "Epoch 460/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5611e-04 - val_loss: 7.6087e-05\n",
      "Epoch 461/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 1.5600e-04 - val_loss: 7.6015e-05\n",
      "Epoch 462/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5588e-04 - val_loss: 7.5941e-05\n",
      "Epoch 463/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5577e-04 - val_loss: 7.5879e-05\n",
      "Epoch 464/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.5566e-04 - val_loss: 7.5805e-05\n",
      "Epoch 465/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 1.5555e-04 - val_loss: 7.5737e-05\n",
      "Epoch 466/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.5544e-04 - val_loss: 7.5666e-05\n",
      "Epoch 467/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.5533e-04 - val_loss: 7.5596e-05\n",
      "Epoch 468/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5522e-04 - val_loss: 7.5537e-05\n",
      "Epoch 469/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5511e-04 - val_loss: 7.5465e-05\n",
      "Epoch 470/1000\n",
      "32/32 [==============================] - 0s 172us/step - loss: 1.5500e-04 - val_loss: 7.5396e-05\n",
      "Epoch 471/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 1.5489e-04 - val_loss: 7.5324e-05\n",
      "Epoch 472/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 1.5478e-04 - val_loss: 7.5260e-05\n",
      "Epoch 473/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5467e-04 - val_loss: 7.5188e-05\n",
      "Epoch 474/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 1.5457e-04 - val_loss: 7.5117e-05\n",
      "Epoch 475/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5445e-04 - val_loss: 7.5054e-05\n",
      "Epoch 476/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 1.5435e-04 - val_loss: 7.4981e-05\n",
      "Epoch 477/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5424e-04 - val_loss: 7.4914e-05\n",
      "Epoch 478/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.5413e-04 - val_loss: 7.4846e-05\n",
      "Epoch 479/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.5402e-04 - val_loss: 7.4775e-05\n",
      "Epoch 480/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5392e-04 - val_loss: 7.4704e-05\n",
      "Epoch 481/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5381e-04 - val_loss: 7.4640e-05\n",
      "Epoch 482/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5370e-04 - val_loss: 7.4570e-05\n",
      "Epoch 483/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5360e-04 - val_loss: 7.4501e-05\n",
      "Epoch 484/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5349e-04 - val_loss: 7.4438e-05\n",
      "Epoch 485/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.5338e-04 - val_loss: 7.4372e-05\n",
      "Epoch 486/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5328e-04 - val_loss: 7.4305e-05\n",
      "Epoch 487/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.5317e-04 - val_loss: 7.4237e-05\n",
      "Epoch 488/1000\n",
      "32/32 [==============================] - 0s 174us/step - loss: 1.5306e-04 - val_loss: 7.4166e-05\n",
      "Epoch 489/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5295e-04 - val_loss: 7.4096e-05\n",
      "Epoch 490/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5285e-04 - val_loss: 7.4025e-05\n",
      "Epoch 491/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.5275e-04 - val_loss: 7.3962e-05\n",
      "Epoch 492/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.5264e-04 - val_loss: 7.3896e-05\n",
      "Epoch 493/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 1.5253e-04 - val_loss: 7.3830e-05\n",
      "Epoch 494/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5243e-04 - val_loss: 7.3758e-05\n",
      "Epoch 495/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5232e-04 - val_loss: 7.3696e-05\n",
      "Epoch 496/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5222e-04 - val_loss: 7.3625e-05\n",
      "Epoch 497/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5212e-04 - val_loss: 7.3563e-05\n",
      "Epoch 498/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5201e-04 - val_loss: 7.3493e-05\n",
      "Epoch 499/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.5191e-04 - val_loss: 7.3431e-05\n",
      "Epoch 500/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5180e-04 - val_loss: 7.3368e-05\n",
      "Epoch 501/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5170e-04 - val_loss: 7.3294e-05\n",
      "Epoch 502/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5160e-04 - val_loss: 7.3233e-05\n",
      "Epoch 503/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5149e-04 - val_loss: 7.3167e-05\n",
      "Epoch 504/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5139e-04 - val_loss: 7.3101e-05\n",
      "Epoch 505/1000\n",
      "32/32 [==============================] - 0s 195us/step - loss: 1.5129e-04 - val_loss: 7.3034e-05\n",
      "Epoch 506/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5118e-04 - val_loss: 7.2961e-05\n",
      "Epoch 507/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.5108e-04 - val_loss: 7.2903e-05\n",
      "Epoch 508/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5098e-04 - val_loss: 7.2833e-05\n",
      "Epoch 509/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5088e-04 - val_loss: 7.2764e-05\n",
      "Epoch 510/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5077e-04 - val_loss: 7.2703e-05\n",
      "Epoch 511/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5067e-04 - val_loss: 7.2633e-05\n",
      "Epoch 512/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5057e-04 - val_loss: 7.2563e-05\n",
      "Epoch 513/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.5046e-04 - val_loss: 7.2497e-05\n",
      "Epoch 514/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5036e-04 - val_loss: 7.2434e-05\n",
      "Epoch 515/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.5026e-04 - val_loss: 7.2367e-05\n",
      "Epoch 516/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.5016e-04 - val_loss: 7.2306e-05\n",
      "Epoch 517/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5006e-04 - val_loss: 7.2241e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 518/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4996e-04 - val_loss: 7.2180e-05\n",
      "Epoch 519/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4986e-04 - val_loss: 7.2110e-05\n",
      "Epoch 520/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 1.4975e-04 - val_loss: 7.2045e-05\n",
      "Epoch 521/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.4965e-04 - val_loss: 7.1988e-05\n",
      "Epoch 522/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.4955e-04 - val_loss: 7.1916e-05\n",
      "Epoch 523/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.4945e-04 - val_loss: 7.1847e-05\n",
      "Epoch 524/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.4935e-04 - val_loss: 7.1785e-05\n",
      "Epoch 525/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.4925e-04 - val_loss: 7.1722e-05\n",
      "Epoch 526/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4915e-04 - val_loss: 7.1657e-05\n",
      "Epoch 527/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.4905e-04 - val_loss: 7.1591e-05\n",
      "Epoch 528/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.4895e-04 - val_loss: 7.1531e-05\n",
      "Epoch 529/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.4885e-04 - val_loss: 7.1469e-05\n",
      "Epoch 530/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4875e-04 - val_loss: 7.1398e-05\n",
      "Epoch 531/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.4865e-04 - val_loss: 7.1338e-05\n",
      "Epoch 532/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4855e-04 - val_loss: 7.1266e-05\n",
      "Epoch 533/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 1.4846e-04 - val_loss: 7.1205e-05\n",
      "Epoch 534/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 1.4835e-04 - val_loss: 7.1141e-05\n",
      "Epoch 535/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4826e-04 - val_loss: 7.1077e-05\n",
      "Epoch 536/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4816e-04 - val_loss: 7.1012e-05\n",
      "Epoch 537/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.4805e-04 - val_loss: 7.0953e-05\n",
      "Epoch 538/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4796e-04 - val_loss: 7.0888e-05\n",
      "Epoch 539/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4786e-04 - val_loss: 7.0820e-05\n",
      "Epoch 540/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.4776e-04 - val_loss: 7.0760e-05\n",
      "Epoch 541/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4766e-04 - val_loss: 7.0700e-05\n",
      "Epoch 542/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.4756e-04 - val_loss: 7.0629e-05\n",
      "Epoch 543/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 1.4747e-04 - val_loss: 7.0564e-05\n",
      "Epoch 544/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4737e-04 - val_loss: 7.0502e-05\n",
      "Epoch 545/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.4727e-04 - val_loss: 7.0445e-05\n",
      "Epoch 546/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.4717e-04 - val_loss: 7.0381e-05\n",
      "Epoch 547/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4708e-04 - val_loss: 7.0318e-05\n",
      "Epoch 548/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4698e-04 - val_loss: 7.0250e-05\n",
      "Epoch 549/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4688e-04 - val_loss: 7.0191e-05\n",
      "Epoch 550/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4678e-04 - val_loss: 7.0127e-05\n",
      "Epoch 551/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4669e-04 - val_loss: 7.0068e-05\n",
      "Epoch 552/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4659e-04 - val_loss: 7.0009e-05\n",
      "Epoch 553/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4649e-04 - val_loss: 6.9938e-05\n",
      "Epoch 554/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4639e-04 - val_loss: 6.9882e-05\n",
      "Epoch 555/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4630e-04 - val_loss: 6.9816e-05\n",
      "Epoch 556/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 1.4620e-04 - val_loss: 6.9756e-05\n",
      "Epoch 557/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.4610e-04 - val_loss: 6.9693e-05\n",
      "Epoch 558/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.4601e-04 - val_loss: 6.9630e-05\n",
      "Epoch 559/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.4591e-04 - val_loss: 6.9567e-05\n",
      "Epoch 560/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4582e-04 - val_loss: 6.9495e-05\n",
      "Epoch 561/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4572e-04 - val_loss: 6.9437e-05\n",
      "Epoch 562/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4562e-04 - val_loss: 6.9378e-05\n",
      "Epoch 563/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4552e-04 - val_loss: 6.9319e-05\n",
      "Epoch 564/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4543e-04 - val_loss: 6.9256e-05\n",
      "Epoch 565/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4533e-04 - val_loss: 6.9194e-05\n",
      "Epoch 566/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.4524e-04 - val_loss: 6.9135e-05\n",
      "Epoch 567/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4514e-04 - val_loss: 6.9068e-05\n",
      "Epoch 568/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4505e-04 - val_loss: 6.9009e-05\n",
      "Epoch 569/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4495e-04 - val_loss: 6.8947e-05\n",
      "Epoch 570/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.4486e-04 - val_loss: 6.8888e-05\n",
      "Epoch 571/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.4476e-04 - val_loss: 6.8822e-05\n",
      "Epoch 572/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4467e-04 - val_loss: 6.8764e-05\n",
      "Epoch 573/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4457e-04 - val_loss: 6.8702e-05\n",
      "Epoch 574/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4448e-04 - val_loss: 6.8638e-05\n",
      "Epoch 575/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4438e-04 - val_loss: 6.8581e-05\n",
      "Epoch 576/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 1.4428e-04 - val_loss: 6.8522e-05\n",
      "Epoch 577/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.4419e-04 - val_loss: 6.8457e-05\n",
      "Epoch 578/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4410e-04 - val_loss: 6.8394e-05\n",
      "Epoch 579/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.4400e-04 - val_loss: 6.8336e-05\n",
      "Epoch 580/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4391e-04 - val_loss: 6.8270e-05\n",
      "Epoch 581/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4382e-04 - val_loss: 6.8209e-05\n",
      "Epoch 582/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4372e-04 - val_loss: 6.8154e-05\n",
      "Epoch 583/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4363e-04 - val_loss: 6.8089e-05\n",
      "Epoch 584/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.4353e-04 - val_loss: 6.8030e-05\n",
      "Epoch 585/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4344e-04 - val_loss: 6.7968e-05\n",
      "Epoch 586/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.4334e-04 - val_loss: 6.7914e-05\n",
      "Epoch 587/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.4325e-04 - val_loss: 6.7849e-05\n",
      "Epoch 588/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4316e-04 - val_loss: 6.7795e-05\n",
      "Epoch 589/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 1.4306e-04 - val_loss: 6.7730e-05\n",
      "Epoch 590/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4297e-04 - val_loss: 6.7672e-05\n",
      "Epoch 591/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.4288e-04 - val_loss: 6.7614e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 592/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.4279e-04 - val_loss: 6.7557e-05\n",
      "Epoch 593/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.4269e-04 - val_loss: 6.7488e-05\n",
      "Epoch 594/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 1.4260e-04 - val_loss: 6.7435e-05\n",
      "Epoch 595/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.4251e-04 - val_loss: 6.7369e-05\n",
      "Epoch 596/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4241e-04 - val_loss: 6.7311e-05\n",
      "Epoch 597/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 1.4232e-04 - val_loss: 6.7254e-05\n",
      "Epoch 598/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 1.4223e-04 - val_loss: 6.7188e-05\n",
      "Epoch 599/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4213e-04 - val_loss: 6.7136e-05\n",
      "Epoch 600/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4204e-04 - val_loss: 6.7070e-05\n",
      "Epoch 601/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4195e-04 - val_loss: 6.7017e-05\n",
      "Epoch 602/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4186e-04 - val_loss: 6.6956e-05\n",
      "Epoch 603/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4176e-04 - val_loss: 6.6900e-05\n",
      "Epoch 604/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4167e-04 - val_loss: 6.6837e-05\n",
      "Epoch 605/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4158e-04 - val_loss: 6.6785e-05\n",
      "Epoch 606/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.4149e-04 - val_loss: 6.6728e-05\n",
      "Epoch 607/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4140e-04 - val_loss: 6.6660e-05\n",
      "Epoch 608/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4130e-04 - val_loss: 6.6602e-05\n",
      "Epoch 609/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.4121e-04 - val_loss: 6.6547e-05\n",
      "Epoch 610/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4112e-04 - val_loss: 6.6485e-05\n",
      "Epoch 611/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4103e-04 - val_loss: 6.6425e-05\n",
      "Epoch 612/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.4094e-04 - val_loss: 6.6372e-05\n",
      "Epoch 613/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4085e-04 - val_loss: 6.6312e-05\n",
      "Epoch 614/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4075e-04 - val_loss: 6.6258e-05\n",
      "Epoch 615/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 1.4066e-04 - val_loss: 6.6193e-05\n",
      "Epoch 616/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 1.4057e-04 - val_loss: 6.6136e-05\n",
      "Epoch 617/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4048e-04 - val_loss: 6.6084e-05\n",
      "Epoch 618/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.4039e-04 - val_loss: 6.6023e-05\n",
      "Epoch 619/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4030e-04 - val_loss: 6.5968e-05\n",
      "Epoch 620/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4020e-04 - val_loss: 6.5906e-05\n",
      "Epoch 621/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.4011e-04 - val_loss: 6.5847e-05\n",
      "Epoch 622/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4002e-04 - val_loss: 6.5795e-05\n",
      "Epoch 623/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3993e-04 - val_loss: 6.5731e-05\n",
      "Epoch 624/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3984e-04 - val_loss: 6.5674e-05\n",
      "Epoch 625/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3975e-04 - val_loss: 6.5618e-05\n",
      "Epoch 626/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.3966e-04 - val_loss: 6.5562e-05\n",
      "Epoch 627/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3957e-04 - val_loss: 6.5506e-05\n",
      "Epoch 628/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3948e-04 - val_loss: 6.5445e-05\n",
      "Epoch 629/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3939e-04 - val_loss: 6.5394e-05\n",
      "Epoch 630/1000\n",
      "32/32 [==============================] - 0s 138us/step - loss: 1.3930e-04 - val_loss: 6.5333e-05\n",
      "Epoch 631/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3921e-04 - val_loss: 6.5274e-05\n",
      "Epoch 632/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3912e-04 - val_loss: 6.5220e-05\n",
      "Epoch 633/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3903e-04 - val_loss: 6.5162e-05\n",
      "Epoch 634/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 1.3894e-04 - val_loss: 6.5106e-05\n",
      "Epoch 635/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3885e-04 - val_loss: 6.5043e-05\n",
      "Epoch 636/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.3876e-04 - val_loss: 6.4994e-05\n",
      "Epoch 637/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.3867e-04 - val_loss: 6.4943e-05\n",
      "Epoch 638/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 1.3858e-04 - val_loss: 6.4887e-05\n",
      "Epoch 639/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3849e-04 - val_loss: 6.4819e-05\n",
      "Epoch 640/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3840e-04 - val_loss: 6.4764e-05\n",
      "Epoch 641/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3831e-04 - val_loss: 6.4705e-05\n",
      "Epoch 642/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3822e-04 - val_loss: 6.4650e-05\n",
      "Epoch 643/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.3813e-04 - val_loss: 6.4594e-05\n",
      "Epoch 644/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3804e-04 - val_loss: 6.4539e-05\n",
      "Epoch 645/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3795e-04 - val_loss: 6.4483e-05\n",
      "Epoch 646/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3786e-04 - val_loss: 6.4430e-05\n",
      "Epoch 647/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3777e-04 - val_loss: 6.4372e-05\n",
      "Epoch 648/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3768e-04 - val_loss: 6.4316e-05\n",
      "Epoch 649/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3759e-04 - val_loss: 6.4264e-05\n",
      "Epoch 650/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3751e-04 - val_loss: 6.4202e-05\n",
      "Epoch 651/1000\n",
      "32/32 [==============================] - 0s 129us/step - loss: 1.3742e-04 - val_loss: 6.4147e-05\n",
      "Epoch 652/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3733e-04 - val_loss: 6.4096e-05\n",
      "Epoch 653/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3724e-04 - val_loss: 6.4036e-05\n",
      "Epoch 654/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.3715e-04 - val_loss: 6.3983e-05\n",
      "Epoch 655/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.3706e-04 - val_loss: 6.3922e-05\n",
      "Epoch 656/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.3698e-04 - val_loss: 6.3868e-05\n",
      "Epoch 657/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3689e-04 - val_loss: 6.3819e-05\n",
      "Epoch 658/1000\n",
      "32/32 [==============================] - 0s 130us/step - loss: 1.3680e-04 - val_loss: 6.3758e-05\n",
      "Epoch 659/1000\n",
      "32/32 [==============================] - 0s 170us/step - loss: 1.3670e-04 - val_loss: 6.3707e-05\n",
      "Epoch 660/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.3662e-04 - val_loss: 6.3643e-05\n",
      "Epoch 661/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 1.3653e-04 - val_loss: 6.3593e-05\n",
      "Epoch 662/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.3644e-04 - val_loss: 6.3538e-05\n",
      "Epoch 663/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3636e-04 - val_loss: 6.3491e-05\n",
      "Epoch 664/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.3627e-04 - val_loss: 6.3428e-05\n",
      "Epoch 665/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3618e-04 - val_loss: 6.3381e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 666/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3609e-04 - val_loss: 6.3319e-05\n",
      "Epoch 667/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.3600e-04 - val_loss: 6.3273e-05\n",
      "Epoch 668/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 1.3592e-04 - val_loss: 6.3212e-05\n",
      "Epoch 669/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3583e-04 - val_loss: 6.3155e-05\n",
      "Epoch 670/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.3574e-04 - val_loss: 6.3100e-05\n",
      "Epoch 671/1000\n",
      "32/32 [==============================] - 0s 132us/step - loss: 1.3565e-04 - val_loss: 6.3045e-05\n",
      "Epoch 672/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.3556e-04 - val_loss: 6.2991e-05\n",
      "Epoch 673/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.3548e-04 - val_loss: 6.2940e-05\n",
      "Epoch 674/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 1.3539e-04 - val_loss: 6.2889e-05\n",
      "Epoch 675/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3530e-04 - val_loss: 6.2835e-05\n",
      "Epoch 676/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 1.3521e-04 - val_loss: 6.2784e-05\n",
      "Epoch 677/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.3512e-04 - val_loss: 6.2727e-05\n",
      "Epoch 678/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3504e-04 - val_loss: 6.2672e-05\n",
      "Epoch 679/1000\n",
      "32/32 [==============================] - 0s 130us/step - loss: 1.3495e-04 - val_loss: 6.2618e-05\n",
      "Epoch 680/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.3486e-04 - val_loss: 6.2564e-05\n",
      "Epoch 681/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3478e-04 - val_loss: 6.2514e-05\n",
      "Epoch 682/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.3469e-04 - val_loss: 6.2456e-05\n",
      "Epoch 683/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3460e-04 - val_loss: 6.2398e-05\n",
      "Epoch 684/1000\n",
      "32/32 [==============================] - 0s 129us/step - loss: 1.3451e-04 - val_loss: 6.2348e-05\n",
      "Epoch 685/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3443e-04 - val_loss: 6.2294e-05\n",
      "Epoch 686/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3434e-04 - val_loss: 6.2240e-05\n",
      "Epoch 687/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3425e-04 - val_loss: 6.2186e-05\n",
      "Epoch 688/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.3417e-04 - val_loss: 6.2136e-05\n",
      "Epoch 689/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3408e-04 - val_loss: 6.2081e-05\n",
      "Epoch 690/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3400e-04 - val_loss: 6.2028e-05\n",
      "Epoch 691/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3391e-04 - val_loss: 6.1977e-05\n",
      "Epoch 692/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3382e-04 - val_loss: 6.1923e-05\n",
      "Epoch 693/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3373e-04 - val_loss: 6.1870e-05\n",
      "Epoch 694/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.3365e-04 - val_loss: 6.1820e-05\n",
      "Epoch 695/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3356e-04 - val_loss: 6.1763e-05\n",
      "Epoch 696/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3347e-04 - val_loss: 6.1713e-05\n",
      "Epoch 697/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3339e-04 - val_loss: 6.1658e-05\n",
      "Epoch 698/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.3330e-04 - val_loss: 6.1605e-05\n",
      "Epoch 699/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3322e-04 - val_loss: 6.1552e-05\n",
      "Epoch 700/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3313e-04 - val_loss: 6.1502e-05\n",
      "Epoch 701/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3304e-04 - val_loss: 6.1449e-05\n",
      "Epoch 702/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3296e-04 - val_loss: 6.1398e-05\n",
      "Epoch 703/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.3288e-04 - val_loss: 6.1346e-05\n",
      "Epoch 704/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.3279e-04 - val_loss: 6.1296e-05\n",
      "Epoch 705/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.3270e-04 - val_loss: 6.1243e-05\n",
      "Epoch 706/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3262e-04 - val_loss: 6.1189e-05\n",
      "Epoch 707/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.3253e-04 - val_loss: 6.1136e-05\n",
      "Epoch 708/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3244e-04 - val_loss: 6.1083e-05\n",
      "Epoch 709/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3236e-04 - val_loss: 6.1037e-05\n",
      "Epoch 710/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3227e-04 - val_loss: 6.0984e-05\n",
      "Epoch 711/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.3219e-04 - val_loss: 6.0926e-05\n",
      "Epoch 712/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3210e-04 - val_loss: 6.0877e-05\n",
      "Epoch 713/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3202e-04 - val_loss: 6.0828e-05\n",
      "Epoch 714/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.3193e-04 - val_loss: 6.0779e-05\n",
      "Epoch 715/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.3185e-04 - val_loss: 6.0725e-05\n",
      "Epoch 716/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.3176e-04 - val_loss: 6.0679e-05\n",
      "Epoch 717/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 1.3168e-04 - val_loss: 6.0627e-05\n",
      "Epoch 718/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3159e-04 - val_loss: 6.0573e-05\n",
      "Epoch 719/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3151e-04 - val_loss: 6.0521e-05\n",
      "Epoch 720/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3142e-04 - val_loss: 6.0467e-05\n",
      "Epoch 721/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3134e-04 - val_loss: 6.0418e-05\n",
      "Epoch 722/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3125e-04 - val_loss: 6.0362e-05\n",
      "Epoch 723/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3117e-04 - val_loss: 6.0309e-05\n",
      "Epoch 724/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3108e-04 - val_loss: 6.0256e-05\n",
      "Epoch 725/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.3099e-04 - val_loss: 6.0216e-05\n",
      "Epoch 726/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 1.3091e-04 - val_loss: 6.0162e-05\n",
      "Epoch 727/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.3083e-04 - val_loss: 6.0114e-05\n",
      "Epoch 728/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.3074e-04 - val_loss: 6.0061e-05\n",
      "Epoch 729/1000\n",
      "32/32 [==============================] - 0s 131us/step - loss: 1.3066e-04 - val_loss: 6.0012e-05\n",
      "Epoch 730/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3057e-04 - val_loss: 5.9955e-05\n",
      "Epoch 731/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.3049e-04 - val_loss: 5.9914e-05\n",
      "Epoch 732/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 1.3040e-04 - val_loss: 5.9865e-05\n",
      "Epoch 733/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3032e-04 - val_loss: 5.9809e-05\n",
      "Epoch 734/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.3024e-04 - val_loss: 5.9760e-05\n",
      "Epoch 735/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3015e-04 - val_loss: 5.9704e-05\n",
      "Epoch 736/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3006e-04 - val_loss: 5.9656e-05\n",
      "Epoch 737/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2998e-04 - val_loss: 5.9607e-05\n",
      "Epoch 738/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2990e-04 - val_loss: 5.9559e-05\n",
      "Epoch 739/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2981e-04 - val_loss: 5.9505e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 740/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2973e-04 - val_loss: 5.9461e-05\n",
      "Epoch 741/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2965e-04 - val_loss: 5.9412e-05\n",
      "Epoch 742/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2956e-04 - val_loss: 5.9363e-05\n",
      "Epoch 743/1000\n",
      "32/32 [==============================] - 0s 137us/step - loss: 1.2948e-04 - val_loss: 5.9312e-05\n",
      "Epoch 744/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2939e-04 - val_loss: 5.9267e-05\n",
      "Epoch 745/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2931e-04 - val_loss: 5.9215e-05\n",
      "Epoch 746/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2923e-04 - val_loss: 5.9167e-05\n",
      "Epoch 747/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2914e-04 - val_loss: 5.9114e-05\n",
      "Epoch 748/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2906e-04 - val_loss: 5.9065e-05\n",
      "Epoch 749/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 1.2898e-04 - val_loss: 5.9013e-05\n",
      "Epoch 750/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 1.2889e-04 - val_loss: 5.8961e-05\n",
      "Epoch 751/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.2881e-04 - val_loss: 5.8914e-05\n",
      "Epoch 752/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.2873e-04 - val_loss: 5.8862e-05\n",
      "Epoch 753/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.2864e-04 - val_loss: 5.8817e-05\n",
      "Epoch 754/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 1.2856e-04 - val_loss: 5.8766e-05\n",
      "Epoch 755/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2847e-04 - val_loss: 5.8721e-05\n",
      "Epoch 756/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2839e-04 - val_loss: 5.8673e-05\n",
      "Epoch 757/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2831e-04 - val_loss: 5.8624e-05\n",
      "Epoch 758/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2823e-04 - val_loss: 5.8576e-05\n",
      "Epoch 759/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.2814e-04 - val_loss: 5.8529e-05\n",
      "Epoch 760/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2806e-04 - val_loss: 5.8477e-05\n",
      "Epoch 761/1000\n",
      "32/32 [==============================] - 0s 138us/step - loss: 1.2798e-04 - val_loss: 5.8428e-05\n",
      "Epoch 762/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.2789e-04 - val_loss: 5.8377e-05\n",
      "Epoch 763/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2781e-04 - val_loss: 5.8333e-05\n",
      "Epoch 764/1000\n",
      "32/32 [==============================] - 0s 113us/step - loss: 1.2773e-04 - val_loss: 5.8281e-05\n",
      "Epoch 765/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2764e-04 - val_loss: 5.8230e-05\n",
      "Epoch 766/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2756e-04 - val_loss: 5.8185e-05\n",
      "Epoch 767/1000\n",
      "32/32 [==============================] - 0s 128us/step - loss: 1.2748e-04 - val_loss: 5.8134e-05\n",
      "Epoch 768/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2739e-04 - val_loss: 5.8090e-05\n",
      "Epoch 769/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.2731e-04 - val_loss: 5.8039e-05\n",
      "Epoch 770/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2723e-04 - val_loss: 5.7994e-05\n",
      "Epoch 771/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 1.2715e-04 - val_loss: 5.7939e-05\n",
      "Epoch 772/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2706e-04 - val_loss: 5.7899e-05\n",
      "Epoch 773/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.2698e-04 - val_loss: 5.7843e-05\n",
      "Epoch 774/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.2690e-04 - val_loss: 5.7799e-05\n",
      "Epoch 775/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2682e-04 - val_loss: 5.7749e-05\n",
      "Epoch 776/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2673e-04 - val_loss: 5.7704e-05\n",
      "Epoch 777/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.2665e-04 - val_loss: 5.7653e-05\n",
      "Epoch 778/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2657e-04 - val_loss: 5.7607e-05\n",
      "Epoch 779/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.2649e-04 - val_loss: 5.7562e-05\n",
      "Epoch 780/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2641e-04 - val_loss: 5.7511e-05\n",
      "Epoch 781/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2632e-04 - val_loss: 5.7464e-05\n",
      "Epoch 782/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2624e-04 - val_loss: 5.7420e-05\n",
      "Epoch 783/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.2616e-04 - val_loss: 5.7365e-05\n",
      "Epoch 784/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2608e-04 - val_loss: 5.7321e-05\n",
      "Epoch 785/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.2600e-04 - val_loss: 5.7273e-05\n",
      "Epoch 786/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2591e-04 - val_loss: 5.7222e-05\n",
      "Epoch 787/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2583e-04 - val_loss: 5.7178e-05\n",
      "Epoch 788/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2575e-04 - val_loss: 5.7131e-05\n",
      "Epoch 789/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2567e-04 - val_loss: 5.7085e-05\n",
      "Epoch 790/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.2558e-04 - val_loss: 5.7037e-05\n",
      "Epoch 791/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2550e-04 - val_loss: 5.6987e-05\n",
      "Epoch 792/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2542e-04 - val_loss: 5.6943e-05\n",
      "Epoch 793/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.2534e-04 - val_loss: 5.6899e-05\n",
      "Epoch 794/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2526e-04 - val_loss: 5.6845e-05\n",
      "Epoch 795/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2517e-04 - val_loss: 5.6801e-05\n",
      "Epoch 796/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 1.2510e-04 - val_loss: 5.6755e-05\n",
      "Epoch 797/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2501e-04 - val_loss: 5.6707e-05\n",
      "Epoch 798/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2493e-04 - val_loss: 5.6660e-05\n",
      "Epoch 799/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.2485e-04 - val_loss: 5.6607e-05\n",
      "Epoch 800/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2477e-04 - val_loss: 5.6566e-05\n",
      "Epoch 801/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2469e-04 - val_loss: 5.6518e-05\n",
      "Epoch 802/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.2460e-04 - val_loss: 5.6473e-05\n",
      "Epoch 803/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 1.2452e-04 - val_loss: 5.6425e-05\n",
      "Epoch 804/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.2444e-04 - val_loss: 5.6386e-05\n",
      "Epoch 805/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2436e-04 - val_loss: 5.6336e-05\n",
      "Epoch 806/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2428e-04 - val_loss: 5.6292e-05\n",
      "Epoch 807/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2420e-04 - val_loss: 5.6241e-05\n",
      "Epoch 808/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 1.2412e-04 - val_loss: 5.6199e-05\n",
      "Epoch 809/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.2404e-04 - val_loss: 5.6152e-05\n",
      "Epoch 810/1000\n",
      "32/32 [==============================] - 0s 122us/step - loss: 1.2396e-04 - val_loss: 5.6105e-05\n",
      "Epoch 811/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.2388e-04 - val_loss: 5.6059e-05\n",
      "Epoch 812/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2380e-04 - val_loss: 5.6011e-05\n",
      "Epoch 813/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.2372e-04 - val_loss: 5.5962e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 814/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.2364e-04 - val_loss: 5.5922e-05\n",
      "Epoch 815/1000\n",
      "32/32 [==============================] - 0s 133us/step - loss: 1.2356e-04 - val_loss: 5.5873e-05\n",
      "Epoch 816/1000\n",
      "32/32 [==============================] - 0s 116us/step - loss: 1.2347e-04 - val_loss: 5.5825e-05\n",
      "Epoch 817/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2339e-04 - val_loss: 5.5789e-05\n",
      "Epoch 818/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2331e-04 - val_loss: 5.5739e-05\n",
      "Epoch 819/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2323e-04 - val_loss: 5.5695e-05\n",
      "Epoch 820/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.2315e-04 - val_loss: 5.5645e-05\n",
      "Epoch 821/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2307e-04 - val_loss: 5.5603e-05\n",
      "Epoch 822/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.2299e-04 - val_loss: 5.5564e-05\n",
      "Epoch 823/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2291e-04 - val_loss: 5.5514e-05\n",
      "Epoch 824/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.2283e-04 - val_loss: 5.5468e-05\n",
      "Epoch 825/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 1.2275e-04 - val_loss: 5.5417e-05\n",
      "Epoch 826/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.2267e-04 - val_loss: 5.5375e-05\n",
      "Epoch 827/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2259e-04 - val_loss: 5.5332e-05\n",
      "Epoch 828/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.2251e-04 - val_loss: 5.5289e-05\n",
      "Epoch 829/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.2243e-04 - val_loss: 5.5243e-05\n",
      "Epoch 830/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2235e-04 - val_loss: 5.5200e-05\n",
      "Epoch 831/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.2227e-04 - val_loss: 5.5151e-05\n",
      "Epoch 832/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.2219e-04 - val_loss: 5.5111e-05\n",
      "Epoch 833/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2211e-04 - val_loss: 5.5069e-05\n",
      "Epoch 834/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.2203e-04 - val_loss: 5.5019e-05\n",
      "Epoch 835/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.2195e-04 - val_loss: 5.4977e-05\n",
      "Epoch 836/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 1.2186e-04 - val_loss: 5.4934e-05\n",
      "Epoch 837/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.2179e-04 - val_loss: 5.4888e-05\n",
      "Epoch 838/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 1.2171e-04 - val_loss: 5.4842e-05\n",
      "Epoch 839/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.2163e-04 - val_loss: 5.4797e-05\n",
      "Epoch 840/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2155e-04 - val_loss: 5.4754e-05\n",
      "Epoch 841/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.2147e-04 - val_loss: 5.4711e-05\n",
      "Epoch 842/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2139e-04 - val_loss: 5.4665e-05\n",
      "Epoch 843/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2131e-04 - val_loss: 5.4619e-05\n",
      "Epoch 844/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.2123e-04 - val_loss: 5.4580e-05\n",
      "Epoch 845/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2115e-04 - val_loss: 5.4534e-05\n",
      "Epoch 846/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 1.2107e-04 - val_loss: 5.4488e-05\n",
      "Epoch 847/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2099e-04 - val_loss: 5.4444e-05\n",
      "Epoch 848/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.2091e-04 - val_loss: 5.4404e-05\n",
      "Epoch 849/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.2083e-04 - val_loss: 5.4365e-05\n",
      "Epoch 850/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2075e-04 - val_loss: 5.4316e-05\n",
      "Epoch 851/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2067e-04 - val_loss: 5.4274e-05\n",
      "Epoch 852/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.2059e-04 - val_loss: 5.4229e-05\n",
      "Epoch 853/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2052e-04 - val_loss: 5.4186e-05\n",
      "Epoch 854/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 1.2043e-04 - val_loss: 5.4136e-05\n",
      "Epoch 855/1000\n",
      "32/32 [==============================] - 0s 217us/step - loss: 1.2036e-04 - val_loss: 5.4092e-05\n",
      "Epoch 856/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2028e-04 - val_loss: 5.4050e-05\n",
      "Epoch 857/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2020e-04 - val_loss: 5.4004e-05\n",
      "Epoch 858/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2012e-04 - val_loss: 5.3962e-05\n",
      "Epoch 859/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2005e-04 - val_loss: 5.3920e-05\n",
      "Epoch 860/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1996e-04 - val_loss: 5.3879e-05\n",
      "Epoch 861/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1989e-04 - val_loss: 5.3828e-05\n",
      "Epoch 862/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1981e-04 - val_loss: 5.3790e-05\n",
      "Epoch 863/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1973e-04 - val_loss: 5.3748e-05\n",
      "Epoch 864/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1965e-04 - val_loss: 5.3709e-05\n",
      "Epoch 865/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1957e-04 - val_loss: 5.3661e-05\n",
      "Epoch 866/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 1.1949e-04 - val_loss: 5.3616e-05\n",
      "Epoch 867/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1941e-04 - val_loss: 5.3577e-05\n",
      "Epoch 868/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1933e-04 - val_loss: 5.3536e-05\n",
      "Epoch 869/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1926e-04 - val_loss: 5.3490e-05\n",
      "Epoch 870/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.1918e-04 - val_loss: 5.3444e-05\n",
      "Epoch 871/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1910e-04 - val_loss: 5.3404e-05\n",
      "Epoch 872/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1902e-04 - val_loss: 5.3366e-05\n",
      "Epoch 873/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1894e-04 - val_loss: 5.3323e-05\n",
      "Epoch 874/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1886e-04 - val_loss: 5.3279e-05\n",
      "Epoch 875/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1879e-04 - val_loss: 5.3239e-05\n",
      "Epoch 876/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 1.1871e-04 - val_loss: 5.3194e-05\n",
      "Epoch 877/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1863e-04 - val_loss: 5.3149e-05\n",
      "Epoch 878/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1855e-04 - val_loss: 5.3115e-05\n",
      "Epoch 879/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1847e-04 - val_loss: 5.3066e-05\n",
      "Epoch 880/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1840e-04 - val_loss: 5.3025e-05\n",
      "Epoch 881/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1832e-04 - val_loss: 5.2984e-05\n",
      "Epoch 882/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1824e-04 - val_loss: 5.2935e-05\n",
      "Epoch 883/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 1.1816e-04 - val_loss: 5.2890e-05\n",
      "Epoch 884/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1808e-04 - val_loss: 5.2855e-05\n",
      "Epoch 885/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1800e-04 - val_loss: 5.2813e-05\n",
      "Epoch 886/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1793e-04 - val_loss: 5.2772e-05\n",
      "Epoch 887/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1785e-04 - val_loss: 5.2724e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 888/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1777e-04 - val_loss: 5.2682e-05\n",
      "Epoch 889/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1769e-04 - val_loss: 5.2647e-05\n",
      "Epoch 890/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1762e-04 - val_loss: 5.2604e-05\n",
      "Epoch 891/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1754e-04 - val_loss: 5.2562e-05\n",
      "Epoch 892/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1746e-04 - val_loss: 5.2517e-05\n",
      "Epoch 893/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1738e-04 - val_loss: 5.2472e-05\n",
      "Epoch 894/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1731e-04 - val_loss: 5.2438e-05\n",
      "Epoch 895/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1723e-04 - val_loss: 5.2390e-05\n",
      "Epoch 896/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1715e-04 - val_loss: 5.2348e-05\n",
      "Epoch 897/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1707e-04 - val_loss: 5.2307e-05\n",
      "Epoch 898/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 1.1699e-04 - val_loss: 5.2265e-05\n",
      "Epoch 899/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1692e-04 - val_loss: 5.2225e-05\n",
      "Epoch 900/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1684e-04 - val_loss: 5.2181e-05\n",
      "Epoch 901/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 1.1677e-04 - val_loss: 5.2142e-05\n",
      "Epoch 902/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1669e-04 - val_loss: 5.2101e-05\n",
      "Epoch 903/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1661e-04 - val_loss: 5.2057e-05\n",
      "Epoch 904/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1653e-04 - val_loss: 5.2019e-05\n",
      "Epoch 905/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1646e-04 - val_loss: 5.1978e-05\n",
      "Epoch 906/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1638e-04 - val_loss: 5.1930e-05\n",
      "Epoch 907/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1630e-04 - val_loss: 5.1891e-05\n",
      "Epoch 908/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1622e-04 - val_loss: 5.1845e-05\n",
      "Epoch 909/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1615e-04 - val_loss: 5.1811e-05\n",
      "Epoch 910/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1607e-04 - val_loss: 5.1772e-05\n",
      "Epoch 911/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1600e-04 - val_loss: 5.1729e-05\n",
      "Epoch 912/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1591e-04 - val_loss: 5.1691e-05\n",
      "Epoch 913/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1584e-04 - val_loss: 5.1650e-05\n",
      "Epoch 914/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1576e-04 - val_loss: 5.1613e-05\n",
      "Epoch 915/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1568e-04 - val_loss: 5.1572e-05\n",
      "Epoch 916/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1561e-04 - val_loss: 5.1530e-05\n",
      "Epoch 917/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1553e-04 - val_loss: 5.1490e-05\n",
      "Epoch 918/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1546e-04 - val_loss: 5.1449e-05\n",
      "Epoch 919/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1538e-04 - val_loss: 5.1401e-05\n",
      "Epoch 920/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1530e-04 - val_loss: 5.1365e-05\n",
      "Epoch 921/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1523e-04 - val_loss: 5.1327e-05\n",
      "Epoch 922/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1515e-04 - val_loss: 5.1287e-05\n",
      "Epoch 923/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1507e-04 - val_loss: 5.1246e-05\n",
      "Epoch 924/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1500e-04 - val_loss: 5.1205e-05\n",
      "Epoch 925/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1492e-04 - val_loss: 5.1164e-05\n",
      "Epoch 926/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1485e-04 - val_loss: 5.1127e-05\n",
      "Epoch 927/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1477e-04 - val_loss: 5.1084e-05\n",
      "Epoch 928/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1469e-04 - val_loss: 5.1039e-05\n",
      "Epoch 929/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1462e-04 - val_loss: 5.1006e-05\n",
      "Epoch 930/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1454e-04 - val_loss: 5.0965e-05\n",
      "Epoch 931/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1446e-04 - val_loss: 5.0924e-05\n",
      "Epoch 932/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1439e-04 - val_loss: 5.0880e-05\n",
      "Epoch 933/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1431e-04 - val_loss: 5.0843e-05\n",
      "Epoch 934/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1423e-04 - val_loss: 5.0806e-05\n",
      "Epoch 935/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1416e-04 - val_loss: 5.0759e-05\n",
      "Epoch 936/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1408e-04 - val_loss: 5.0729e-05\n",
      "Epoch 937/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1401e-04 - val_loss: 5.0688e-05\n",
      "Epoch 938/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1393e-04 - val_loss: 5.0645e-05\n",
      "Epoch 939/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1385e-04 - val_loss: 5.0607e-05\n",
      "Epoch 940/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1378e-04 - val_loss: 5.0564e-05\n",
      "Epoch 941/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1370e-04 - val_loss: 5.0527e-05\n",
      "Epoch 942/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1363e-04 - val_loss: 5.0486e-05\n",
      "Epoch 943/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1355e-04 - val_loss: 5.0443e-05\n",
      "Epoch 944/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1348e-04 - val_loss: 5.0406e-05\n",
      "Epoch 945/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1340e-04 - val_loss: 5.0372e-05\n",
      "Epoch 946/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1333e-04 - val_loss: 5.0326e-05\n",
      "Epoch 947/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1325e-04 - val_loss: 5.0285e-05\n",
      "Epoch 948/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1317e-04 - val_loss: 5.0249e-05\n",
      "Epoch 949/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1310e-04 - val_loss: 5.0205e-05\n",
      "Epoch 950/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1302e-04 - val_loss: 5.0168e-05\n",
      "Epoch 951/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1295e-04 - val_loss: 5.0128e-05\n",
      "Epoch 952/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1287e-04 - val_loss: 5.0091e-05\n",
      "Epoch 953/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1280e-04 - val_loss: 5.0050e-05\n",
      "Epoch 954/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1272e-04 - val_loss: 5.0015e-05\n",
      "Epoch 955/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 1.1265e-04 - val_loss: 4.9973e-05\n",
      "Epoch 956/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1257e-04 - val_loss: 4.9934e-05\n",
      "Epoch 957/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1250e-04 - val_loss: 4.9894e-05\n",
      "Epoch 958/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1242e-04 - val_loss: 4.9857e-05\n",
      "Epoch 959/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1234e-04 - val_loss: 4.9820e-05\n",
      "Epoch 960/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1227e-04 - val_loss: 4.9784e-05\n",
      "Epoch 961/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1219e-04 - val_loss: 4.9744e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 962/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1212e-04 - val_loss: 4.9701e-05\n",
      "Epoch 963/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1205e-04 - val_loss: 4.9664e-05\n",
      "Epoch 964/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1197e-04 - val_loss: 4.9628e-05\n",
      "Epoch 965/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1190e-04 - val_loss: 4.9588e-05\n",
      "Epoch 966/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1182e-04 - val_loss: 4.9551e-05\n",
      "Epoch 967/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1175e-04 - val_loss: 4.9508e-05\n",
      "Epoch 968/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1167e-04 - val_loss: 4.9467e-05\n",
      "Epoch 969/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1160e-04 - val_loss: 4.9435e-05\n",
      "Epoch 970/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.1152e-04 - val_loss: 4.9395e-05\n",
      "Epoch 971/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1145e-04 - val_loss: 4.9351e-05\n",
      "Epoch 972/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1137e-04 - val_loss: 4.9315e-05\n",
      "Epoch 973/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1130e-04 - val_loss: 4.9276e-05\n",
      "Epoch 974/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1122e-04 - val_loss: 4.9240e-05\n",
      "Epoch 975/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1115e-04 - val_loss: 4.9201e-05\n",
      "Epoch 976/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 1.1108e-04 - val_loss: 4.9164e-05\n",
      "Epoch 977/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1100e-04 - val_loss: 4.9126e-05\n",
      "Epoch 978/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 1.1092e-04 - val_loss: 4.9094e-05\n",
      "Epoch 979/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1085e-04 - val_loss: 4.9054e-05\n",
      "Epoch 980/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 1.1078e-04 - val_loss: 4.9018e-05\n",
      "Epoch 981/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1071e-04 - val_loss: 4.8975e-05\n",
      "Epoch 982/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1063e-04 - val_loss: 4.8939e-05\n",
      "Epoch 983/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1055e-04 - val_loss: 4.8893e-05\n",
      "Epoch 984/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1048e-04 - val_loss: 4.8856e-05\n",
      "Epoch 985/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1041e-04 - val_loss: 4.8827e-05\n",
      "Epoch 986/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1033e-04 - val_loss: 4.8784e-05\n",
      "Epoch 987/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1026e-04 - val_loss: 4.8747e-05\n",
      "Epoch 988/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1018e-04 - val_loss: 4.8708e-05\n",
      "Epoch 989/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1011e-04 - val_loss: 4.8673e-05\n",
      "Epoch 990/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1004e-04 - val_loss: 4.8636e-05\n",
      "Epoch 991/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0996e-04 - val_loss: 4.8600e-05\n",
      "Epoch 992/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0989e-04 - val_loss: 4.8561e-05\n",
      "Epoch 993/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0981e-04 - val_loss: 4.8525e-05\n",
      "Epoch 994/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0974e-04 - val_loss: 4.8486e-05\n",
      "Epoch 995/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0967e-04 - val_loss: 4.8447e-05\n",
      "Epoch 996/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0959e-04 - val_loss: 4.8407e-05\n",
      "Epoch 997/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0952e-04 - val_loss: 4.8374e-05\n",
      "Epoch 998/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0944e-04 - val_loss: 4.8338e-05\n",
      "Epoch 999/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0937e-04 - val_loss: 4.8299e-05\n",
      "Epoch 1000/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 1.0930e-04 - val_loss: 4.8262e-05\n",
      "2.495749868103303e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-1.1731365 , -1.0928568 , -0.65612894, -0.4138755 ,  0.71974915],\n",
       "        [ 0.08791504,  0.27462038, -0.03303109,  0.06003816,  0.52427894],\n",
       "        [ 1.2347534 , -0.51848215, -0.9254643 ,  0.10201246,  0.53958184]],\n",
       "       dtype=float32),\n",
       " array([-0.40893486,  0.6113161 , -0.5411161 ,  0.2468039 , -0.04456357],\n",
       "       dtype=float32),\n",
       " array([[ 0.56758225, -0.08212385, -0.1566527 ,  0.10075039,  0.21810928,\n",
       "          0.33117977, -0.16311736, -0.6014744 , -0.68491024,  0.8506684 ],\n",
       "        [-0.5882047 , -0.7475559 , -0.45515734,  0.04794963,  0.3319468 ,\n",
       "         -0.06464512,  0.10279346,  0.23261534,  0.42378843, -0.47234806],\n",
       "        [ 0.14885715, -0.1511121 ,  0.50857896,  0.38196126,  0.24780093,\n",
       "         -0.8838558 , -0.3084874 , -0.04967599,  0.48106587,  0.81422985],\n",
       "        [ 0.06306236,  0.33022505,  0.32202426, -0.94480294,  0.59045815,\n",
       "          0.3635264 , -0.2439131 ,  0.2627529 ,  0.6648691 , -0.21039443],\n",
       "        [ 0.17621878,  0.04984105, -0.26300627,  0.63585603, -0.36939865,\n",
       "         -0.3475223 , -0.56149954,  0.05772226,  0.03162542, -0.27444434]],\n",
       "       dtype=float32),\n",
       " array([-0.7474518 ,  0.5237049 , -0.7500477 ,  0.19706519,  0.6294157 ,\n",
       "         0.75959945,  0.73916507,  0.75586605,  0.5595921 , -0.7297604 ],\n",
       "       dtype=float32),\n",
       " array([[-0.70389026],\n",
       "        [ 0.38977107],\n",
       "        [-0.7216018 ],\n",
       "        [ 0.25173187],\n",
       "        [ 0.3293445 ],\n",
       "        [ 0.8691077 ],\n",
       "        [ 0.62349236],\n",
       "        [ 0.83091134],\n",
       "        [ 0.28239223],\n",
       "        [-0.6586908 ]], dtype=float32),\n",
       " array([0.82468367], dtype=float32)]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_challenger, history_challenger, evaluate_challenger=NN_model_structure_regression_2(X_train_challenger, X_val_challenger, Y_train_challenger, Y_val_challenger, adam2, 32, 1000, x_test_challenger, y_test_challenger)\n",
    "model_challenger.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_challenger.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_challenger_structure2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_61 (Dense)             (None, 5)                 20        \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 15)                90        \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 126\n",
      "Trainable params: 126\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 32 samples, validate on 7 samples\n",
      "Epoch 1/1000\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 36.1001 - val_loss: 34.1963\n",
      "Epoch 2/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 32.9808 - val_loss: 29.1769\n",
      "Epoch 3/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 28.6792 - val_loss: 22.8550\n",
      "Epoch 4/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 23.2607 - val_loss: 15.6372\n",
      "Epoch 5/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 16.9970 - val_loss: 8.6786\n",
      "Epoch 6/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 10.2299 - val_loss: 3.4408\n",
      "Epoch 7/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9294 - val_loss: 1.3878\n",
      "Epoch 8/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.7060 - val_loss: 3.1620\n",
      "Epoch 9/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.7925 - val_loss: 5.3365\n",
      "Epoch 10/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.3873 - val_loss: 5.0100\n",
      "Epoch 11/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.8399 - val_loss: 3.0724\n",
      "Epoch 12/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8373 - val_loss: 1.1718\n",
      "Epoch 13/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.3442 - val_loss: 0.3328\n",
      "Epoch 14/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.6879 - val_loss: 0.6716\n",
      "Epoch 15/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.2579 - val_loss: 1.6135\n",
      "Epoch 16/1000\n",
      "32/32 [==============================] - 0s 160us/step - loss: 0.6839 - val_loss: 2.4762\n",
      "Epoch 17/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3590 - val_loss: 2.9047\n",
      "Epoch 18/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.8744 - val_loss: 2.8771\n",
      "Epoch 19/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 2.0903 - val_loss: 2.5288\n",
      "Epoch 20/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.0209 - val_loss: 2.0153\n",
      "Epoch 21/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.7295 - val_loss: 1.4534\n",
      "Epoch 22/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2902 - val_loss: 0.9218\n",
      "Epoch 23/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.7981 - val_loss: 0.4828\n",
      "Epoch 24/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.3742 - val_loss: 0.1891\n",
      "Epoch 25/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1336 - val_loss: 0.0645\n",
      "Epoch 26/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1206 - val_loss: 0.0820\n",
      "Epoch 27/1000\n",
      "32/32 [==============================] - 0s 166us/step - loss: 0.2706 - val_loss: 0.1786\n",
      "Epoch 28/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.4572 - val_loss: 0.2906\n",
      "Epoch 29/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.5862 - val_loss: 0.3645\n",
      "Epoch 30/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.6238 - val_loss: 0.3558\n",
      "Epoch 31/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.5631 - val_loss: 0.2563\n",
      "Epoch 32/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.4163 - val_loss: 0.1201\n",
      "Epoch 33/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.2367 - val_loss: 0.0272\n",
      "Epoch 34/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0999 - val_loss: 0.0175\n",
      "Epoch 35/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0491 - val_loss: 0.0703\n",
      "Epoch 36/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0720 - val_loss: 0.1375\n",
      "Epoch 37/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1280 - val_loss: 0.1847\n",
      "Epoch 38/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1831 - val_loss: 0.2034\n",
      "Epoch 39/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.2216 - val_loss: 0.1991\n",
      "Epoch 40/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.2367 - val_loss: 0.1776\n",
      "Epoch 41/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.2236 - val_loss: 0.1424\n",
      "Epoch 42/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1819 - val_loss: 0.0997\n",
      "Epoch 43/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.1233 - val_loss: 0.0597\n",
      "Epoch 44/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0685 - val_loss: 0.0316\n",
      "Epoch 45/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0356 - val_loss: 0.0184\n",
      "Epoch 46/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0290 - val_loss: 0.0170\n",
      "Epoch 47/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0403 - val_loss: 0.0233\n",
      "Epoch 48/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0582 - val_loss: 0.0342\n",
      "Epoch 49/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 0.0748 - val_loss: 0.0450\n",
      "Epoch 50/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0854 - val_loss: 0.0489\n",
      "Epoch 51/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0853 - val_loss: 0.0417\n",
      "Epoch 52/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0727 - val_loss: 0.0267\n",
      "Epoch 53/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0519 - val_loss: 0.0124\n",
      "Epoch 54/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0317 - val_loss: 0.0061\n",
      "Epoch 55/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0194 - val_loss: 0.0087\n",
      "Epoch 56/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0163 - val_loss: 0.0163\n",
      "Epoch 57/1000\n",
      "32/32 [==============================] - 0s 145us/step - loss: 0.0193 - val_loss: 0.0243\n",
      "Epoch 58/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 0.0248 - val_loss: 0.0301\n",
      "Epoch 59/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0303 - val_loss: 0.0331\n",
      "Epoch 60/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0344 - val_loss: 0.0331\n",
      "Epoch 61/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 0.0354 - val_loss: 0.0303\n",
      "Epoch 62/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0325 - val_loss: 0.0257\n",
      "Epoch 63/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 0.0264 - val_loss: 0.0207\n",
      "Epoch 64/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0196 - val_loss: 0.0165\n",
      "Epoch 65/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0147 - val_loss: 0.0133\n",
      "Epoch 66/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0127 - val_loss: 0.0109\n",
      "Epoch 67/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0130 - val_loss: 0.0089\n",
      "Epoch 68/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0144 - val_loss: 0.0076\n",
      "Epoch 69/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0162 - val_loss: 0.0072\n",
      "Epoch 70/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0177 - val_loss: 0.0072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0183 - val_loss: 0.0070\n",
      "Epoch 72/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0176 - val_loss: 0.0063\n",
      "Epoch 73/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0157 - val_loss: 0.0054\n",
      "Epoch 74/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0133 - val_loss: 0.0050\n",
      "Epoch 75/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0115 - val_loss: 0.0054\n",
      "Epoch 76/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0106 - val_loss: 0.0066\n",
      "Epoch 77/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0106 - val_loss: 0.0079\n",
      "Epoch 78/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0109 - val_loss: 0.0091\n",
      "Epoch 79/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0113 - val_loss: 0.0097\n",
      "Epoch 80/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0117 - val_loss: 0.0099\n",
      "Epoch 81/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0118 - val_loss: 0.0095\n",
      "Epoch 82/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0115 - val_loss: 0.0087\n",
      "Epoch 83/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0109 - val_loss: 0.0078\n",
      "Epoch 84/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0101 - val_loss: 0.0068\n",
      "Epoch 85/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0094 - val_loss: 0.0059\n",
      "Epoch 86/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 0.0090 - val_loss: 0.0050\n",
      "Epoch 87/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0089 - val_loss: 0.0041\n",
      "Epoch 88/1000\n",
      "32/32 [==============================] - 0s 119us/step - loss: 0.0090 - val_loss: 0.0032\n",
      "Epoch 89/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0091 - val_loss: 0.0025\n",
      "Epoch 90/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0091 - val_loss: 0.0021\n",
      "Epoch 91/1000\n",
      "32/32 [==============================] - 0s 166us/step - loss: 0.0091 - val_loss: 0.0018\n",
      "Epoch 92/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0089 - val_loss: 0.0018\n",
      "Epoch 93/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0087 - val_loss: 0.0019\n",
      "Epoch 94/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 0.0084 - val_loss: 0.0021\n",
      "Epoch 95/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0081 - val_loss: 0.0023\n",
      "Epoch 96/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 0.0080 - val_loss: 0.0027\n",
      "Epoch 97/1000\n",
      "32/32 [==============================] - 0s 128us/step - loss: 0.0079 - val_loss: 0.0030\n",
      "Epoch 98/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0079 - val_loss: 0.0032\n",
      "Epoch 99/1000\n",
      "32/32 [==============================] - 0s 166us/step - loss: 0.0079 - val_loss: 0.0033\n",
      "Epoch 100/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0078 - val_loss: 0.0033\n",
      "Epoch 101/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0078 - val_loss: 0.0032\n",
      "Epoch 102/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0077 - val_loss: 0.0030\n",
      "Epoch 103/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0075 - val_loss: 0.0028\n",
      "Epoch 104/1000\n",
      "32/32 [==============================] - 0s 183us/step - loss: 0.0074 - val_loss: 0.0025\n",
      "Epoch 105/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 0.0073 - val_loss: 0.0023\n",
      "Epoch 106/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0072 - val_loss: 0.0021\n",
      "Epoch 107/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0071 - val_loss: 0.0019\n",
      "Epoch 108/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0071 - val_loss: 0.0017\n",
      "Epoch 109/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0070 - val_loss: 0.0016\n",
      "Epoch 110/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0070 - val_loss: 0.0014\n",
      "Epoch 111/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0069 - val_loss: 0.0014\n",
      "Epoch 112/1000\n",
      "32/32 [==============================] - 0s 145us/step - loss: 0.0069 - val_loss: 0.0014\n",
      "Epoch 113/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0068 - val_loss: 0.0014\n",
      "Epoch 114/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0067 - val_loss: 0.0015\n",
      "Epoch 115/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0066 - val_loss: 0.0015\n",
      "Epoch 116/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0065 - val_loss: 0.0016\n",
      "Epoch 117/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0065 - val_loss: 0.0017\n",
      "Epoch 118/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0064 - val_loss: 0.0017\n",
      "Epoch 119/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0064 - val_loss: 0.0017\n",
      "Epoch 120/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 0.0063 - val_loss: 0.0017\n",
      "Epoch 121/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0063 - val_loss: 0.0017\n",
      "Epoch 122/1000\n",
      "32/32 [==============================] - 0s 182us/step - loss: 0.0062 - val_loss: 0.0016\n",
      "Epoch 123/1000\n",
      "32/32 [==============================] - 0s 165us/step - loss: 0.0061 - val_loss: 0.0016\n",
      "Epoch 124/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0061 - val_loss: 0.0015\n",
      "Epoch 125/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0060 - val_loss: 0.0014\n",
      "Epoch 126/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0060 - val_loss: 0.0014\n",
      "Epoch 127/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0059 - val_loss: 0.0013\n",
      "Epoch 128/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0059 - val_loss: 0.0013\n",
      "Epoch 129/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0058 - val_loss: 0.0012\n",
      "Epoch 130/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0058 - val_loss: 0.0012\n",
      "Epoch 131/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0057 - val_loss: 0.0012\n",
      "Epoch 132/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0057 - val_loss: 0.0012\n",
      "Epoch 133/1000\n",
      "32/32 [==============================] - 0s 122us/step - loss: 0.0056 - val_loss: 0.0012\n",
      "Epoch 134/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0056 - val_loss: 0.0012\n",
      "Epoch 135/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 0.0055 - val_loss: 0.0012\n",
      "Epoch 136/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0055 - val_loss: 0.0012\n",
      "Epoch 137/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0054 - val_loss: 0.0012\n",
      "Epoch 138/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0054 - val_loss: 0.0012\n",
      "Epoch 139/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0053 - val_loss: 0.0012\n",
      "Epoch 140/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0053 - val_loss: 0.0012\n",
      "Epoch 141/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 0.0052 - val_loss: 0.0011\n",
      "Epoch 142/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0052 - val_loss: 0.0011\n",
      "Epoch 143/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0052 - val_loss: 0.0011\n",
      "Epoch 144/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 0.0051 - val_loss: 0.0010\n",
      "Epoch 145/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0051 - val_loss: 0.0010\n",
      "Epoch 146/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0050 - val_loss: 9.9988e-04\n",
      "Epoch 147/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0050 - val_loss: 9.7919e-04\n",
      "Epoch 148/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0049 - val_loss: 9.5987e-04\n",
      "Epoch 149/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0049 - val_loss: 9.4208e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0049 - val_loss: 9.2657e-04\n",
      "Epoch 151/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 0.0048 - val_loss: 9.1403e-04\n",
      "Epoch 152/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0048 - val_loss: 9.0487e-04\n",
      "Epoch 153/1000\n",
      "32/32 [==============================] - 0s 132us/step - loss: 0.0047 - val_loss: 8.9870e-04\n",
      "Epoch 154/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0047 - val_loss: 8.9466e-04\n",
      "Epoch 155/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0047 - val_loss: 8.9130e-04\n",
      "Epoch 156/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0046 - val_loss: 8.8707e-04\n",
      "Epoch 157/1000\n",
      "32/32 [==============================] - 0s 131us/step - loss: 0.0046 - val_loss: 8.8074e-04\n",
      "Epoch 158/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0045 - val_loss: 8.7165e-04\n",
      "Epoch 159/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0045 - val_loss: 8.5986e-04\n",
      "Epoch 160/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0045 - val_loss: 8.4599e-04\n",
      "Epoch 161/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0044 - val_loss: 8.3099e-04\n",
      "Epoch 162/1000\n",
      "32/32 [==============================] - 0s 145us/step - loss: 0.0044 - val_loss: 8.1590e-04\n",
      "Epoch 163/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0044 - val_loss: 8.0149e-04\n",
      "Epoch 164/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0043 - val_loss: 7.8831e-04\n",
      "Epoch 165/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0043 - val_loss: 7.7651e-04\n",
      "Epoch 166/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0043 - val_loss: 7.6600e-04\n",
      "Epoch 167/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0042 - val_loss: 7.5655e-04\n",
      "Epoch 168/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0042 - val_loss: 7.4794e-04\n",
      "Epoch 169/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0041 - val_loss: 7.4020e-04\n",
      "Epoch 170/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0041 - val_loss: 7.3333e-04\n",
      "Epoch 171/1000\n",
      "32/32 [==============================] - 0s 158us/step - loss: 0.0041 - val_loss: 7.2752e-04\n",
      "Epoch 172/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 0.0040 - val_loss: 7.2278e-04\n",
      "Epoch 173/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0040 - val_loss: 7.1903e-04\n",
      "Epoch 174/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0040 - val_loss: 7.1590e-04\n",
      "Epoch 175/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 0.0039 - val_loss: 7.1295e-04\n",
      "Epoch 176/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0039 - val_loss: 7.0955e-04\n",
      "Epoch 177/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0039 - val_loss: 7.0538e-04\n",
      "Epoch 178/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0039 - val_loss: 7.0019e-04\n",
      "Epoch 179/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0038 - val_loss: 6.9401e-04\n",
      "Epoch 180/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0038 - val_loss: 6.8719e-04\n",
      "Epoch 181/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0038 - val_loss: 6.8004e-04\n",
      "Epoch 182/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0037 - val_loss: 6.7310e-04\n",
      "Epoch 183/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0037 - val_loss: 6.6662e-04\n",
      "Epoch 184/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0037 - val_loss: 6.6084e-04\n",
      "Epoch 185/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0036 - val_loss: 6.5581e-04\n",
      "Epoch 186/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0036 - val_loss: 6.5144e-04\n",
      "Epoch 187/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0036 - val_loss: 6.4761e-04\n",
      "Epoch 188/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0036 - val_loss: 6.4415e-04\n",
      "Epoch 189/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0035 - val_loss: 6.4110e-04\n",
      "Epoch 190/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0035 - val_loss: 6.3840e-04\n",
      "Epoch 191/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0035 - val_loss: 6.3612e-04\n",
      "Epoch 192/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0034 - val_loss: 6.3427e-04\n",
      "Epoch 193/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0034 - val_loss: 6.3280e-04\n",
      "Epoch 194/1000\n",
      "32/32 [==============================] - 0s 185us/step - loss: 0.0034 - val_loss: 6.3160e-04\n",
      "Epoch 195/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0034 - val_loss: 6.3053e-04\n",
      "Epoch 196/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 6.2936e-04\n",
      "Epoch 197/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 6.2795e-04\n",
      "Epoch 198/1000\n",
      "32/32 [==============================] - 0s 161us/step - loss: 0.0033 - val_loss: 6.2621e-04\n",
      "Epoch 199/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 6.2421e-04\n",
      "Epoch 200/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0032 - val_loss: 6.2202e-04\n",
      "Epoch 201/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 0.0032 - val_loss: 6.1980e-04\n",
      "Epoch 202/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 0.0032 - val_loss: 6.1778e-04\n",
      "Epoch 203/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0032 - val_loss: 6.1601e-04\n",
      "Epoch 204/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0031 - val_loss: 6.1463e-04\n",
      "Epoch 205/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0031 - val_loss: 6.1362e-04\n",
      "Epoch 206/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0031 - val_loss: 6.1294e-04\n",
      "Epoch 207/1000\n",
      "32/32 [==============================] - 0s 178us/step - loss: 0.0031 - val_loss: 6.1254e-04\n",
      "Epoch 208/1000\n",
      "32/32 [==============================] - 0s 165us/step - loss: 0.0031 - val_loss: 6.1242e-04\n",
      "Epoch 209/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0030 - val_loss: 6.1245e-04\n",
      "Epoch 210/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0030 - val_loss: 6.1268e-04\n",
      "Epoch 211/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0030 - val_loss: 6.1320e-04\n",
      "Epoch 212/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 0.0030 - val_loss: 6.1390e-04\n",
      "Epoch 213/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 6.1481e-04\n",
      "Epoch 214/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0029 - val_loss: 6.1593e-04\n",
      "Epoch 215/1000\n",
      "32/32 [==============================] - 0s 122us/step - loss: 0.0029 - val_loss: 6.1714e-04\n",
      "Epoch 216/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 6.1840e-04\n",
      "Epoch 217/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 6.1969e-04\n",
      "Epoch 218/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 6.2094e-04\n",
      "Epoch 219/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 0.0028 - val_loss: 6.2213e-04\n",
      "Epoch 220/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 6.2334e-04\n",
      "Epoch 221/1000\n",
      "32/32 [==============================] - 0s 217us/step - loss: 0.0028 - val_loss: 6.2461e-04\n",
      "Epoch 222/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 6.2602e-04\n",
      "Epoch 223/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0027 - val_loss: 6.2758e-04\n",
      "Epoch 224/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0027 - val_loss: 6.2936e-04\n",
      "Epoch 225/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 6.3135e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 226/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0027 - val_loss: 6.3351e-04\n",
      "Epoch 227/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 6.3581e-04\n",
      "Epoch 228/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 6.3826e-04\n",
      "Epoch 229/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 6.4084e-04\n",
      "Epoch 230/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0026 - val_loss: 6.4351e-04\n",
      "Epoch 231/1000\n",
      "32/32 [==============================] - 0s 133us/step - loss: 0.0026 - val_loss: 6.4631e-04\n",
      "Epoch 232/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0026 - val_loss: 6.4924e-04\n",
      "Epoch 233/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0026 - val_loss: 6.5230e-04\n",
      "Epoch 234/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 0.0026 - val_loss: 6.5544e-04\n",
      "Epoch 235/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0025 - val_loss: 6.5870e-04\n",
      "Epoch 236/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0025 - val_loss: 6.6199e-04\n",
      "Epoch 237/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0025 - val_loss: 6.6534e-04\n",
      "Epoch 238/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0025 - val_loss: 6.6869e-04\n",
      "Epoch 239/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 6.7204e-04\n",
      "Epoch 240/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0025 - val_loss: 6.7546e-04\n",
      "Epoch 241/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0024 - val_loss: 6.7889e-04\n",
      "Epoch 242/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 6.8236e-04\n",
      "Epoch 243/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0024 - val_loss: 6.8598e-04\n",
      "Epoch 244/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0024 - val_loss: 6.8965e-04\n",
      "Epoch 245/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0024 - val_loss: 6.9338e-04\n",
      "Epoch 246/1000\n",
      "32/32 [==============================] - 0s 129us/step - loss: 0.0024 - val_loss: 6.9720e-04\n",
      "Epoch 247/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 7.0107e-04\n",
      "Epoch 248/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0023 - val_loss: 7.0499e-04\n",
      "Epoch 249/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0023 - val_loss: 7.0895e-04\n",
      "Epoch 250/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0023 - val_loss: 7.1294e-04\n",
      "Epoch 251/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0023 - val_loss: 7.1701e-04\n",
      "Epoch 252/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0023 - val_loss: 7.2106e-04\n",
      "Epoch 253/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 7.2518e-04\n",
      "Epoch 254/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0023 - val_loss: 7.2931e-04\n",
      "Epoch 255/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 7.3346e-04\n",
      "Epoch 256/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0022 - val_loss: 7.3763e-04\n",
      "Epoch 257/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 7.4179e-04\n",
      "Epoch 258/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0022 - val_loss: 7.4596e-04\n",
      "Epoch 259/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0022 - val_loss: 7.5010e-04\n",
      "Epoch 260/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 0.0022 - val_loss: 7.5424e-04\n",
      "Epoch 261/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 0.0022 - val_loss: 7.5838e-04\n",
      "Epoch 262/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0022 - val_loss: 7.6249e-04\n",
      "Epoch 263/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0022 - val_loss: 7.6662e-04\n",
      "Epoch 264/1000\n",
      "32/32 [==============================] - 0s 116us/step - loss: 0.0021 - val_loss: 7.7077e-04\n",
      "Epoch 265/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0021 - val_loss: 7.7491e-04\n",
      "Epoch 266/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 7.7902e-04\n",
      "Epoch 267/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 7.8313e-04\n",
      "Epoch 268/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 7.8727e-04\n",
      "Epoch 269/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 0.0021 - val_loss: 7.9135e-04\n",
      "Epoch 270/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0021 - val_loss: 7.9541e-04\n",
      "Epoch 271/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 7.9944e-04\n",
      "Epoch 272/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0021 - val_loss: 8.0346e-04\n",
      "Epoch 273/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0020 - val_loss: 8.0743e-04\n",
      "Epoch 274/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0020 - val_loss: 8.1140e-04\n",
      "Epoch 275/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0020 - val_loss: 8.1535e-04\n",
      "Epoch 276/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0020 - val_loss: 8.1925e-04\n",
      "Epoch 277/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0020 - val_loss: 8.2314e-04\n",
      "Epoch 278/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 0.0020 - val_loss: 8.2696e-04\n",
      "Epoch 279/1000\n",
      "32/32 [==============================] - 0s 128us/step - loss: 0.0020 - val_loss: 8.3075e-04\n",
      "Epoch 280/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0020 - val_loss: 8.3448e-04\n",
      "Epoch 281/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0020 - val_loss: 8.3817e-04\n",
      "Epoch 282/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 0.0020 - val_loss: 8.4184e-04\n",
      "Epoch 283/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 8.4547e-04\n",
      "Epoch 284/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 0.0019 - val_loss: 8.4905e-04\n",
      "Epoch 285/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0019 - val_loss: 8.5258e-04\n",
      "Epoch 286/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0019 - val_loss: 8.5609e-04\n",
      "Epoch 287/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0019 - val_loss: 8.5956e-04\n",
      "Epoch 288/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0019 - val_loss: 8.6292e-04\n",
      "Epoch 289/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0019 - val_loss: 8.6628e-04\n",
      "Epoch 290/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 8.6959e-04\n",
      "Epoch 291/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0019 - val_loss: 8.7282e-04\n",
      "Epoch 292/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 8.7601e-04\n",
      "Epoch 293/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 8.7917e-04\n",
      "Epoch 294/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 8.8226e-04\n",
      "Epoch 295/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0018 - val_loss: 8.8531e-04\n",
      "Epoch 296/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 8.8830e-04\n",
      "Epoch 297/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 8.9125e-04\n",
      "Epoch 298/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0018 - val_loss: 8.9414e-04\n",
      "Epoch 299/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 8.9697e-04\n",
      "Epoch 300/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 8.9972e-04\n",
      "Epoch 301/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0018 - val_loss: 9.0241e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 302/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 9.0508e-04\n",
      "Epoch 303/1000\n",
      "32/32 [==============================] - 0s 129us/step - loss: 0.0018 - val_loss: 9.0770e-04\n",
      "Epoch 304/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0018 - val_loss: 9.1024e-04\n",
      "Epoch 305/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0018 - val_loss: 9.1273e-04\n",
      "Epoch 306/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 0.0017 - val_loss: 9.1517e-04\n",
      "Epoch 307/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 9.1758e-04\n",
      "Epoch 308/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 9.1990e-04\n",
      "Epoch 309/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 0.0017 - val_loss: 9.2216e-04\n",
      "Epoch 310/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 9.2438e-04\n",
      "Epoch 311/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 9.2653e-04\n",
      "Epoch 312/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 9.2866e-04\n",
      "Epoch 313/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 9.3070e-04\n",
      "Epoch 314/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 0.0017 - val_loss: 9.3271e-04\n",
      "Epoch 315/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 9.3463e-04\n",
      "Epoch 316/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 9.3653e-04\n",
      "Epoch 317/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 9.3836e-04\n",
      "Epoch 318/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 9.4015e-04\n",
      "Epoch 319/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0016 - val_loss: 9.4185e-04\n",
      "Epoch 320/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 9.4357e-04\n",
      "Epoch 321/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0016 - val_loss: 9.4516e-04\n",
      "Epoch 322/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 9.4674e-04\n",
      "Epoch 323/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 9.4826e-04\n",
      "Epoch 324/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 9.4973e-04\n",
      "Epoch 325/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0016 - val_loss: 9.5115e-04\n",
      "Epoch 326/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 9.5250e-04\n",
      "Epoch 327/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 9.5383e-04\n",
      "Epoch 328/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 9.5509e-04\n",
      "Epoch 329/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 9.5633e-04\n",
      "Epoch 330/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 9.5751e-04\n",
      "Epoch 331/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0016 - val_loss: 9.5863e-04\n",
      "Epoch 332/1000\n",
      "32/32 [==============================] - 0s 170us/step - loss: 0.0016 - val_loss: 9.5975e-04\n",
      "Epoch 333/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0016 - val_loss: 9.6075e-04\n",
      "Epoch 334/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 9.6177e-04\n",
      "Epoch 335/1000\n",
      "32/32 [==============================] - 0s 165us/step - loss: 0.0015 - val_loss: 9.6271e-04\n",
      "Epoch 336/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0015 - val_loss: 9.6360e-04\n",
      "Epoch 337/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0015 - val_loss: 9.6445e-04\n",
      "Epoch 338/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 9.6527e-04\n",
      "Epoch 339/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0015 - val_loss: 9.6604e-04\n",
      "Epoch 340/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0015 - val_loss: 9.6681e-04\n",
      "Epoch 341/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 9.6749e-04\n",
      "Epoch 342/1000\n",
      "32/32 [==============================] - 0s 121us/step - loss: 0.0015 - val_loss: 9.6809e-04\n",
      "Epoch 343/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0015 - val_loss: 9.6872e-04\n",
      "Epoch 344/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 0.0015 - val_loss: 9.6930e-04\n",
      "Epoch 345/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 0.0015 - val_loss: 9.6984e-04\n",
      "Epoch 346/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 0.0015 - val_loss: 9.7034e-04\n",
      "Epoch 347/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 9.7079e-04\n",
      "Epoch 348/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 9.7120e-04\n",
      "Epoch 349/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 9.7160e-04\n",
      "Epoch 350/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 9.7195e-04\n",
      "Epoch 351/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 9.7224e-04\n",
      "Epoch 352/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 9.7251e-04\n",
      "Epoch 353/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 9.7274e-04\n",
      "Epoch 354/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0014 - val_loss: 9.7297e-04\n",
      "Epoch 355/1000\n",
      "32/32 [==============================] - 0s 167us/step - loss: 0.0014 - val_loss: 9.7316e-04\n",
      "Epoch 356/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0014 - val_loss: 9.7328e-04\n",
      "Epoch 357/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 9.7340e-04\n",
      "Epoch 358/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 0.0014 - val_loss: 9.7352e-04\n",
      "Epoch 359/1000\n",
      "32/32 [==============================] - 0s 117us/step - loss: 0.0014 - val_loss: 9.7353e-04\n",
      "Epoch 360/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0014 - val_loss: 9.7356e-04\n",
      "Epoch 361/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 9.7353e-04\n",
      "Epoch 362/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 9.7350e-04\n",
      "Epoch 363/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0014 - val_loss: 9.7344e-04\n",
      "Epoch 364/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 9.7334e-04\n",
      "Epoch 365/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 0.0014 - val_loss: 9.7321e-04\n",
      "Epoch 366/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 9.7308e-04\n",
      "Epoch 367/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 9.7287e-04\n",
      "Epoch 368/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 9.7272e-04\n",
      "Epoch 369/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0013 - val_loss: 9.7249e-04\n",
      "Epoch 370/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 9.7224e-04\n",
      "Epoch 371/1000\n",
      "32/32 [==============================] - 0s 133us/step - loss: 0.0013 - val_loss: 9.7196e-04\n",
      "Epoch 372/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0013 - val_loss: 9.7167e-04\n",
      "Epoch 373/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 9.7134e-04\n",
      "Epoch 374/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 9.7103e-04\n",
      "Epoch 375/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0013 - val_loss: 9.7063e-04\n",
      "Epoch 376/1000\n",
      "32/32 [==============================] - 0s 161us/step - loss: 0.0013 - val_loss: 9.7025e-04\n",
      "Epoch 377/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 9.6987e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 378/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 9.6946e-04\n",
      "Epoch 379/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 0.0013 - val_loss: 9.6900e-04\n",
      "Epoch 380/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0013 - val_loss: 9.6852e-04\n",
      "Epoch 381/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 0.0013 - val_loss: 9.6804e-04\n",
      "Epoch 382/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 9.6754e-04\n",
      "Epoch 383/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 9.6702e-04\n",
      "Epoch 384/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 9.6647e-04\n",
      "Epoch 385/1000\n",
      "32/32 [==============================] - 0s 127us/step - loss: 0.0013 - val_loss: 9.6588e-04\n",
      "Epoch 386/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 9.6532e-04\n",
      "Epoch 387/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 9.6472e-04\n",
      "Epoch 388/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 9.6411e-04\n",
      "Epoch 389/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 9.6350e-04\n",
      "Epoch 390/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 9.6289e-04\n",
      "Epoch 391/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 9.6223e-04\n",
      "Epoch 392/1000\n",
      "32/32 [==============================] - 0s 162us/step - loss: 0.0012 - val_loss: 9.6154e-04\n",
      "Epoch 393/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 0.0012 - val_loss: 9.6086e-04\n",
      "Epoch 394/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0012 - val_loss: 9.6015e-04\n",
      "Epoch 395/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 9.5947e-04\n",
      "Epoch 396/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 9.5872e-04\n",
      "Epoch 397/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 9.5795e-04\n",
      "Epoch 398/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 0.0012 - val_loss: 9.5720e-04\n",
      "Epoch 399/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 9.5644e-04\n",
      "Epoch 400/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 9.5566e-04\n",
      "Epoch 401/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 9.5489e-04\n",
      "Epoch 402/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 9.5408e-04\n",
      "Epoch 403/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 0.0012 - val_loss: 9.5326e-04\n",
      "Epoch 404/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 9.5244e-04\n",
      "Epoch 405/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 9.5160e-04\n",
      "Epoch 406/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 9.5077e-04\n",
      "Epoch 407/1000\n",
      "32/32 [==============================] - 0s 137us/step - loss: 0.0012 - val_loss: 9.4992e-04\n",
      "Epoch 408/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 9.4904e-04\n",
      "Epoch 409/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 9.4819e-04\n",
      "Epoch 410/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0012 - val_loss: 9.4730e-04\n",
      "Epoch 411/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 9.4641e-04\n",
      "Epoch 412/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 9.4549e-04\n",
      "Epoch 413/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 9.4457e-04\n",
      "Epoch 414/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 9.4365e-04\n",
      "Epoch 415/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 0.0011 - val_loss: 9.4272e-04\n",
      "Epoch 416/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 9.4179e-04\n",
      "Epoch 417/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 9.4082e-04\n",
      "Epoch 418/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 9.3988e-04\n",
      "Epoch 419/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 9.3895e-04\n",
      "Epoch 420/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 9.3795e-04\n",
      "Epoch 421/1000\n",
      "32/32 [==============================] - 0s 120us/step - loss: 0.0011 - val_loss: 9.3698e-04\n",
      "Epoch 422/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 9.3600e-04\n",
      "Epoch 423/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 9.3503e-04\n",
      "Epoch 424/1000\n",
      "32/32 [==============================] - 0s 116us/step - loss: 0.0011 - val_loss: 9.3402e-04\n",
      "Epoch 425/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0011 - val_loss: 9.3305e-04\n",
      "Epoch 426/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 9.3202e-04\n",
      "Epoch 427/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0011 - val_loss: 9.3103e-04\n",
      "Epoch 428/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 9.2998e-04\n",
      "Epoch 429/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 9.2900e-04\n",
      "Epoch 430/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 0.0011 - val_loss: 9.2795e-04\n",
      "Epoch 431/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 9.2693e-04\n",
      "Epoch 432/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0011 - val_loss: 9.2590e-04\n",
      "Epoch 433/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 9.2487e-04\n",
      "Epoch 434/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 9.2381e-04\n",
      "Epoch 435/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 9.2277e-04\n",
      "Epoch 436/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 9.2171e-04\n",
      "Epoch 437/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0010 - val_loss: 9.2065e-04\n",
      "Epoch 438/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0010 - val_loss: 9.1960e-04\n",
      "Epoch 439/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 9.1852e-04\n",
      "Epoch 440/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 9.1748e-04\n",
      "Epoch 441/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0010 - val_loss: 9.1639e-04\n",
      "Epoch 442/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0010 - val_loss: 9.1531e-04\n",
      "Epoch 443/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 9.1424e-04\n",
      "Epoch 444/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0010 - val_loss: 9.1316e-04\n",
      "Epoch 445/1000\n",
      "32/32 [==============================] - 0s 122us/step - loss: 0.0010 - val_loss: 9.1205e-04\n",
      "Epoch 446/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0010 - val_loss: 9.1098e-04\n",
      "Epoch 447/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0010 - val_loss: 9.0987e-04\n",
      "Epoch 448/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 9.0881e-04\n",
      "Epoch 449/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 9.0768e-04\n",
      "Epoch 450/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0010 - val_loss: 9.0659e-04\n",
      "Epoch 451/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.9931e-04 - val_loss: 9.0549e-04\n",
      "Epoch 452/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.9593e-04 - val_loss: 9.0436e-04\n",
      "Epoch 453/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.9256e-04 - val_loss: 9.0329e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 454/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.8920e-04 - val_loss: 9.0218e-04\n",
      "Epoch 455/1000\n",
      "32/32 [==============================] - 0s 122us/step - loss: 9.8586e-04 - val_loss: 9.0104e-04\n",
      "Epoch 456/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.8253e-04 - val_loss: 8.9994e-04\n",
      "Epoch 457/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 9.7923e-04 - val_loss: 8.9883e-04\n",
      "Epoch 458/1000\n",
      "32/32 [==============================] - 0s 117us/step - loss: 9.7594e-04 - val_loss: 8.9771e-04\n",
      "Epoch 459/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.7266e-04 - val_loss: 8.9661e-04\n",
      "Epoch 460/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6940e-04 - val_loss: 8.9549e-04\n",
      "Epoch 461/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 9.6615e-04 - val_loss: 8.9438e-04\n",
      "Epoch 462/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6291e-04 - val_loss: 8.9326e-04\n",
      "Epoch 463/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.5970e-04 - val_loss: 8.9215e-04\n",
      "Epoch 464/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.5650e-04 - val_loss: 8.9104e-04\n",
      "Epoch 465/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.5331e-04 - val_loss: 8.8990e-04\n",
      "Epoch 466/1000\n",
      "32/32 [==============================] - 0s 132us/step - loss: 9.5014e-04 - val_loss: 8.8877e-04\n",
      "Epoch 467/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.4698e-04 - val_loss: 8.8763e-04\n",
      "Epoch 468/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.4383e-04 - val_loss: 8.8653e-04\n",
      "Epoch 469/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4070e-04 - val_loss: 8.8538e-04\n",
      "Epoch 470/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.3759e-04 - val_loss: 8.8424e-04\n",
      "Epoch 471/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.3448e-04 - val_loss: 8.8313e-04\n",
      "Epoch 472/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.3140e-04 - val_loss: 8.8201e-04\n",
      "Epoch 473/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.2832e-04 - val_loss: 8.8088e-04\n",
      "Epoch 474/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 9.2527e-04 - val_loss: 8.7973e-04\n",
      "Epoch 475/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.2222e-04 - val_loss: 8.7861e-04\n",
      "Epoch 476/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.1918e-04 - val_loss: 8.7749e-04\n",
      "Epoch 477/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 9.1617e-04 - val_loss: 8.7636e-04\n",
      "Epoch 478/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1317e-04 - val_loss: 8.7523e-04\n",
      "Epoch 479/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.1016e-04 - val_loss: 8.7411e-04\n",
      "Epoch 480/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.0719e-04 - val_loss: 8.7296e-04\n",
      "Epoch 481/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 9.0422e-04 - val_loss: 8.7183e-04\n",
      "Epoch 482/1000\n",
      "32/32 [==============================] - 0s 132us/step - loss: 9.0127e-04 - val_loss: 8.7072e-04\n",
      "Epoch 483/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9834e-04 - val_loss: 8.6958e-04\n",
      "Epoch 484/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9540e-04 - val_loss: 8.6846e-04\n",
      "Epoch 485/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9250e-04 - val_loss: 8.6735e-04\n",
      "Epoch 486/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.8959e-04 - val_loss: 8.6619e-04\n",
      "Epoch 487/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.8671e-04 - val_loss: 8.6508e-04\n",
      "Epoch 488/1000\n",
      "32/32 [==============================] - 0s 121us/step - loss: 8.8384e-04 - val_loss: 8.6391e-04\n",
      "Epoch 489/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.8097e-04 - val_loss: 8.6278e-04\n",
      "Epoch 490/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7811e-04 - val_loss: 8.6167e-04\n",
      "Epoch 491/1000\n",
      "32/32 [==============================] - 0s 137us/step - loss: 8.7528e-04 - val_loss: 8.6054e-04\n",
      "Epoch 492/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7246e-04 - val_loss: 8.5943e-04\n",
      "Epoch 493/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 8.6964e-04 - val_loss: 8.5830e-04\n",
      "Epoch 494/1000\n",
      "32/32 [==============================] - 0s 120us/step - loss: 8.6684e-04 - val_loss: 8.5720e-04\n",
      "Epoch 495/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.6407e-04 - val_loss: 8.5606e-04\n",
      "Epoch 496/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.6128e-04 - val_loss: 8.5492e-04\n",
      "Epoch 497/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.5852e-04 - val_loss: 8.5382e-04\n",
      "Epoch 498/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5576e-04 - val_loss: 8.5265e-04\n",
      "Epoch 499/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 8.5302e-04 - val_loss: 8.5156e-04\n",
      "Epoch 500/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.5029e-04 - val_loss: 8.5044e-04\n",
      "Epoch 501/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.4759e-04 - val_loss: 8.4933e-04\n",
      "Epoch 502/1000\n",
      "32/32 [==============================] - 0s 133us/step - loss: 8.4487e-04 - val_loss: 8.4821e-04\n",
      "Epoch 503/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.4218e-04 - val_loss: 8.4709e-04\n",
      "Epoch 504/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.3950e-04 - val_loss: 8.4596e-04\n",
      "Epoch 505/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3684e-04 - val_loss: 8.4485e-04\n",
      "Epoch 506/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.3417e-04 - val_loss: 8.4373e-04\n",
      "Epoch 507/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3152e-04 - val_loss: 8.4261e-04\n",
      "Epoch 508/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2888e-04 - val_loss: 8.4150e-04\n",
      "Epoch 509/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.2626e-04 - val_loss: 8.4042e-04\n",
      "Epoch 510/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2365e-04 - val_loss: 8.3929e-04\n",
      "Epoch 511/1000\n",
      "32/32 [==============================] - 0s 137us/step - loss: 8.2104e-04 - val_loss: 8.3818e-04\n",
      "Epoch 512/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.1845e-04 - val_loss: 8.3707e-04\n",
      "Epoch 513/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.1588e-04 - val_loss: 8.3596e-04\n",
      "Epoch 514/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.1330e-04 - val_loss: 8.3486e-04\n",
      "Epoch 515/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.1075e-04 - val_loss: 8.3374e-04\n",
      "Epoch 516/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 8.0820e-04 - val_loss: 8.3265e-04\n",
      "Epoch 517/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 8.0566e-04 - val_loss: 8.3153e-04\n",
      "Epoch 518/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 8.0313e-04 - val_loss: 8.3046e-04\n",
      "Epoch 519/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0063e-04 - val_loss: 8.2936e-04\n",
      "Epoch 520/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.9812e-04 - val_loss: 8.2825e-04\n",
      "Epoch 521/1000\n",
      "32/32 [==============================] - 0s 217us/step - loss: 7.9561e-04 - val_loss: 8.2716e-04\n",
      "Epoch 522/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9313e-04 - val_loss: 8.2606e-04\n",
      "Epoch 523/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.9066e-04 - val_loss: 8.2497e-04\n",
      "Epoch 524/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 7.8819e-04 - val_loss: 8.2387e-04\n",
      "Epoch 525/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.8574e-04 - val_loss: 8.2276e-04\n",
      "Epoch 526/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.8330e-04 - val_loss: 8.2168e-04\n",
      "Epoch 527/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8086e-04 - val_loss: 8.2059e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 528/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7845e-04 - val_loss: 8.1952e-04\n",
      "Epoch 529/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.7603e-04 - val_loss: 8.1843e-04\n",
      "Epoch 530/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7363e-04 - val_loss: 8.1735e-04\n",
      "Epoch 531/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 7.7124e-04 - val_loss: 8.1625e-04\n",
      "Epoch 532/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.6885e-04 - val_loss: 8.1517e-04\n",
      "Epoch 533/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 7.6648e-04 - val_loss: 8.1411e-04\n",
      "Epoch 534/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6412e-04 - val_loss: 8.1304e-04\n",
      "Epoch 535/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.6177e-04 - val_loss: 8.1196e-04\n",
      "Epoch 536/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5943e-04 - val_loss: 8.1088e-04\n",
      "Epoch 537/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.5709e-04 - val_loss: 8.0983e-04\n",
      "Epoch 538/1000\n",
      "32/32 [==============================] - 0s 182us/step - loss: 7.5475e-04 - val_loss: 8.0874e-04\n",
      "Epoch 539/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.5245e-04 - val_loss: 8.0768e-04\n",
      "Epoch 540/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.5015e-04 - val_loss: 8.0660e-04\n",
      "Epoch 541/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 7.4785e-04 - val_loss: 8.0555e-04\n",
      "Epoch 542/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.4557e-04 - val_loss: 8.0448e-04\n",
      "Epoch 543/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 7.4328e-04 - val_loss: 8.0338e-04\n",
      "Epoch 544/1000\n",
      "32/32 [==============================] - 0s 165us/step - loss: 7.4102e-04 - val_loss: 8.0234e-04\n",
      "Epoch 545/1000\n",
      "32/32 [==============================] - 0s 115us/step - loss: 7.3876e-04 - val_loss: 8.0128e-04\n",
      "Epoch 546/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.3650e-04 - val_loss: 8.0025e-04\n",
      "Epoch 547/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3427e-04 - val_loss: 7.9921e-04\n",
      "Epoch 548/1000\n",
      "32/32 [==============================] - 0s 129us/step - loss: 7.3204e-04 - val_loss: 7.9815e-04\n",
      "Epoch 549/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.2981e-04 - val_loss: 7.9711e-04\n",
      "Epoch 550/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2760e-04 - val_loss: 7.9607e-04\n",
      "Epoch 551/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2540e-04 - val_loss: 7.9499e-04\n",
      "Epoch 552/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.2321e-04 - val_loss: 7.9392e-04\n",
      "Epoch 553/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.2102e-04 - val_loss: 7.9289e-04\n",
      "Epoch 554/1000\n",
      "32/32 [==============================] - 0s 127us/step - loss: 7.1884e-04 - val_loss: 7.9184e-04\n",
      "Epoch 555/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1667e-04 - val_loss: 7.9082e-04\n",
      "Epoch 556/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.1451e-04 - val_loss: 7.8981e-04\n",
      "Epoch 557/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 7.1236e-04 - val_loss: 7.8877e-04\n",
      "Epoch 558/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.1023e-04 - val_loss: 7.8771e-04\n",
      "Epoch 559/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0808e-04 - val_loss: 7.8667e-04\n",
      "Epoch 560/1000\n",
      "32/32 [==============================] - 0s 130us/step - loss: 7.0596e-04 - val_loss: 7.8565e-04\n",
      "Epoch 561/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.0385e-04 - val_loss: 7.8463e-04\n",
      "Epoch 562/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0173e-04 - val_loss: 7.8360e-04\n",
      "Epoch 563/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.9963e-04 - val_loss: 7.8258e-04\n",
      "Epoch 564/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.9755e-04 - val_loss: 7.8154e-04\n",
      "Epoch 565/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9546e-04 - val_loss: 7.8052e-04\n",
      "Epoch 566/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 6.9339e-04 - val_loss: 7.7951e-04\n",
      "Epoch 567/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.9132e-04 - val_loss: 7.7850e-04\n",
      "Epoch 568/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.8927e-04 - val_loss: 7.7748e-04\n",
      "Epoch 569/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.8722e-04 - val_loss: 7.7648e-04\n",
      "Epoch 570/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.8517e-04 - val_loss: 7.7544e-04\n",
      "Epoch 571/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8314e-04 - val_loss: 7.7446e-04\n",
      "Epoch 572/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.8112e-04 - val_loss: 7.7343e-04\n",
      "Epoch 573/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7910e-04 - val_loss: 7.7242e-04\n",
      "Epoch 574/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7709e-04 - val_loss: 7.7144e-04\n",
      "Epoch 575/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.7509e-04 - val_loss: 7.7043e-04\n",
      "Epoch 576/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7310e-04 - val_loss: 7.6944e-04\n",
      "Epoch 577/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.7112e-04 - val_loss: 7.6844e-04\n",
      "Epoch 578/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6914e-04 - val_loss: 7.6745e-04\n",
      "Epoch 579/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6717e-04 - val_loss: 7.6647e-04\n",
      "Epoch 580/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.6520e-04 - val_loss: 7.6548e-04\n",
      "Epoch 581/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6325e-04 - val_loss: 7.6447e-04\n",
      "Epoch 582/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.6131e-04 - val_loss: 7.6349e-04\n",
      "Epoch 583/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.5937e-04 - val_loss: 7.6249e-04\n",
      "Epoch 584/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5744e-04 - val_loss: 7.6152e-04\n",
      "Epoch 585/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5553e-04 - val_loss: 7.6054e-04\n",
      "Epoch 586/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 6.5360e-04 - val_loss: 7.5956e-04\n",
      "Epoch 587/1000\n",
      "32/32 [==============================] - 0s 165us/step - loss: 6.5170e-04 - val_loss: 7.5859e-04\n",
      "Epoch 588/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 6.4979e-04 - val_loss: 7.5761e-04\n",
      "Epoch 589/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 6.4791e-04 - val_loss: 7.5664e-04\n",
      "Epoch 590/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4602e-04 - val_loss: 7.5565e-04\n",
      "Epoch 591/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4414e-04 - val_loss: 7.5470e-04\n",
      "Epoch 592/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4227e-04 - val_loss: 7.5374e-04\n",
      "Epoch 593/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4041e-04 - val_loss: 7.5277e-04\n",
      "Epoch 594/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.3855e-04 - val_loss: 7.5179e-04\n",
      "Epoch 595/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 6.3670e-04 - val_loss: 7.5086e-04\n",
      "Epoch 596/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.3487e-04 - val_loss: 7.4991e-04\n",
      "Epoch 597/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.3302e-04 - val_loss: 7.4895e-04\n",
      "Epoch 598/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.3120e-04 - val_loss: 7.4799e-04\n",
      "Epoch 599/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.2938e-04 - val_loss: 7.4704e-04\n",
      "Epoch 600/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 6.2758e-04 - val_loss: 7.4609e-04\n",
      "Epoch 601/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.2577e-04 - val_loss: 7.4514e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 602/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2398e-04 - val_loss: 7.4417e-04\n",
      "Epoch 603/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.2217e-04 - val_loss: 7.4326e-04\n",
      "Epoch 604/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.2039e-04 - val_loss: 7.4231e-04\n",
      "Epoch 605/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.1862e-04 - val_loss: 7.4138e-04\n",
      "Epoch 606/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.1684e-04 - val_loss: 7.4043e-04\n",
      "Epoch 607/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.1508e-04 - val_loss: 7.3950e-04\n",
      "Epoch 608/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.1333e-04 - val_loss: 7.3855e-04\n",
      "Epoch 609/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1158e-04 - val_loss: 7.3762e-04\n",
      "Epoch 610/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0983e-04 - val_loss: 7.3669e-04\n",
      "Epoch 611/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0809e-04 - val_loss: 7.3578e-04\n",
      "Epoch 612/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.0637e-04 - val_loss: 7.3487e-04\n",
      "Epoch 613/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.0465e-04 - val_loss: 7.3394e-04\n",
      "Epoch 614/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.0294e-04 - val_loss: 7.3301e-04\n",
      "Epoch 615/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.0123e-04 - val_loss: 7.3209e-04\n",
      "Epoch 616/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.9953e-04 - val_loss: 7.3116e-04\n",
      "Epoch 617/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.9783e-04 - val_loss: 7.3026e-04\n",
      "Epoch 618/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.9614e-04 - val_loss: 7.2934e-04\n",
      "Epoch 619/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.9446e-04 - val_loss: 7.2843e-04\n",
      "Epoch 620/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9279e-04 - val_loss: 7.2753e-04\n",
      "Epoch 621/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 5.9111e-04 - val_loss: 7.2664e-04\n",
      "Epoch 622/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8946e-04 - val_loss: 7.2573e-04\n",
      "Epoch 623/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.8780e-04 - val_loss: 7.2480e-04\n",
      "Epoch 624/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.8615e-04 - val_loss: 7.2392e-04\n",
      "Epoch 625/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.8451e-04 - val_loss: 7.2301e-04\n",
      "Epoch 626/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 5.8287e-04 - val_loss: 7.2213e-04\n",
      "Epoch 627/1000\n",
      "32/32 [==============================] - 0s 121us/step - loss: 5.8124e-04 - val_loss: 7.2124e-04\n",
      "Epoch 628/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.7961e-04 - val_loss: 7.2037e-04\n",
      "Epoch 629/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 5.7801e-04 - val_loss: 7.1947e-04\n",
      "Epoch 630/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.7639e-04 - val_loss: 7.1857e-04\n",
      "Epoch 631/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 5.7479e-04 - val_loss: 7.1767e-04\n",
      "Epoch 632/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.7318e-04 - val_loss: 7.1678e-04\n",
      "Epoch 633/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7159e-04 - val_loss: 7.1591e-04\n",
      "Epoch 634/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7001e-04 - val_loss: 7.1502e-04\n",
      "Epoch 635/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.6842e-04 - val_loss: 7.1419e-04\n",
      "Epoch 636/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.6686e-04 - val_loss: 7.1333e-04\n",
      "Epoch 637/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 5.6528e-04 - val_loss: 7.1243e-04\n",
      "Epoch 638/1000\n",
      "32/32 [==============================] - 0s 217us/step - loss: 5.6371e-04 - val_loss: 7.1156e-04\n",
      "Epoch 639/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.6216e-04 - val_loss: 7.1069e-04\n",
      "Epoch 640/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6061e-04 - val_loss: 7.0981e-04\n",
      "Epoch 641/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 5.5907e-04 - val_loss: 7.0894e-04\n",
      "Epoch 642/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 5.5754e-04 - val_loss: 7.0807e-04\n",
      "Epoch 643/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.5600e-04 - val_loss: 7.0723e-04\n",
      "Epoch 644/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.5448e-04 - val_loss: 7.0639e-04\n",
      "Epoch 645/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.5295e-04 - val_loss: 7.0554e-04\n",
      "Epoch 646/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.5144e-04 - val_loss: 7.0467e-04\n",
      "Epoch 647/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.4993e-04 - val_loss: 7.0379e-04\n",
      "Epoch 648/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.4842e-04 - val_loss: 7.0297e-04\n",
      "Epoch 649/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.4693e-04 - val_loss: 7.0210e-04\n",
      "Epoch 650/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.4544e-04 - val_loss: 7.0125e-04\n",
      "Epoch 651/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.4395e-04 - val_loss: 7.0043e-04\n",
      "Epoch 652/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4248e-04 - val_loss: 6.9960e-04\n",
      "Epoch 653/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 5.4100e-04 - val_loss: 6.9875e-04\n",
      "Epoch 654/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3954e-04 - val_loss: 6.9793e-04\n",
      "Epoch 655/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 5.3807e-04 - val_loss: 6.9707e-04\n",
      "Epoch 656/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.3662e-04 - val_loss: 6.9624e-04\n",
      "Epoch 657/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.3518e-04 - val_loss: 6.9539e-04\n",
      "Epoch 658/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.3372e-04 - val_loss: 6.9457e-04\n",
      "Epoch 659/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.3227e-04 - val_loss: 6.9376e-04\n",
      "Epoch 660/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.3085e-04 - val_loss: 6.9292e-04\n",
      "Epoch 661/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.2942e-04 - val_loss: 6.9210e-04\n",
      "Epoch 662/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.2800e-04 - val_loss: 6.9128e-04\n",
      "Epoch 663/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 5.2658e-04 - val_loss: 6.9048e-04\n",
      "Epoch 664/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 5.2516e-04 - val_loss: 6.8962e-04\n",
      "Epoch 665/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.2375e-04 - val_loss: 6.8882e-04\n",
      "Epoch 666/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 5.2236e-04 - val_loss: 6.8801e-04\n",
      "Epoch 667/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.2096e-04 - val_loss: 6.8719e-04\n",
      "Epoch 668/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.1957e-04 - val_loss: 6.8641e-04\n",
      "Epoch 669/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 5.1819e-04 - val_loss: 6.8558e-04\n",
      "Epoch 670/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 5.1680e-04 - val_loss: 6.8480e-04\n",
      "Epoch 671/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.1543e-04 - val_loss: 6.8399e-04\n",
      "Epoch 672/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1406e-04 - val_loss: 6.8316e-04\n",
      "Epoch 673/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.1269e-04 - val_loss: 6.8235e-04\n",
      "Epoch 674/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.1134e-04 - val_loss: 6.8156e-04\n",
      "Epoch 675/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.0998e-04 - val_loss: 6.8077e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 676/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.0863e-04 - val_loss: 6.7997e-04\n",
      "Epoch 677/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 5.0729e-04 - val_loss: 6.7920e-04\n",
      "Epoch 678/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 5.0595e-04 - val_loss: 6.7839e-04\n",
      "Epoch 679/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.0462e-04 - val_loss: 6.7763e-04\n",
      "Epoch 680/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0330e-04 - val_loss: 6.7683e-04\n",
      "Epoch 681/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.0197e-04 - val_loss: 6.7606e-04\n",
      "Epoch 682/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0066e-04 - val_loss: 6.7525e-04\n",
      "Epoch 683/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9934e-04 - val_loss: 6.7449e-04\n",
      "Epoch 684/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.9803e-04 - val_loss: 6.7370e-04\n",
      "Epoch 685/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.9674e-04 - val_loss: 6.7292e-04\n",
      "Epoch 686/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 4.9543e-04 - val_loss: 6.7214e-04\n",
      "Epoch 687/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9414e-04 - val_loss: 6.7138e-04\n",
      "Epoch 688/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 4.9286e-04 - val_loss: 6.7061e-04\n",
      "Epoch 689/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.9157e-04 - val_loss: 6.6982e-04\n",
      "Epoch 690/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9030e-04 - val_loss: 6.6906e-04\n",
      "Epoch 691/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.8902e-04 - val_loss: 6.6831e-04\n",
      "Epoch 692/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.8777e-04 - val_loss: 6.6755e-04\n",
      "Epoch 693/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8650e-04 - val_loss: 6.6680e-04\n",
      "Epoch 694/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.8524e-04 - val_loss: 6.6604e-04\n",
      "Epoch 695/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.8398e-04 - val_loss: 6.6529e-04\n",
      "Epoch 696/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8274e-04 - val_loss: 6.6453e-04\n",
      "Epoch 697/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8149e-04 - val_loss: 6.6376e-04\n",
      "Epoch 698/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 4.8025e-04 - val_loss: 6.6302e-04\n",
      "Epoch 699/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.7902e-04 - val_loss: 6.6228e-04\n",
      "Epoch 700/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.7779e-04 - val_loss: 6.6152e-04\n",
      "Epoch 701/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.7657e-04 - val_loss: 6.6079e-04\n",
      "Epoch 702/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7535e-04 - val_loss: 6.6005e-04\n",
      "Epoch 703/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7413e-04 - val_loss: 6.5928e-04\n",
      "Epoch 704/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.7292e-04 - val_loss: 6.5856e-04\n",
      "Epoch 705/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.7172e-04 - val_loss: 6.5783e-04\n",
      "Epoch 706/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 4.7052e-04 - val_loss: 6.5707e-04\n",
      "Epoch 707/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6932e-04 - val_loss: 6.5634e-04\n",
      "Epoch 708/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6813e-04 - val_loss: 6.5561e-04\n",
      "Epoch 709/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.6695e-04 - val_loss: 6.5490e-04\n",
      "Epoch 710/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.6576e-04 - val_loss: 6.5414e-04\n",
      "Epoch 711/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 4.6458e-04 - val_loss: 6.5344e-04\n",
      "Epoch 712/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.6341e-04 - val_loss: 6.5272e-04\n",
      "Epoch 713/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6224e-04 - val_loss: 6.5200e-04\n",
      "Epoch 714/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6107e-04 - val_loss: 6.5127e-04\n",
      "Epoch 715/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.5992e-04 - val_loss: 6.5056e-04\n",
      "Epoch 716/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5876e-04 - val_loss: 6.4981e-04\n",
      "Epoch 717/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 4.5761e-04 - val_loss: 6.4911e-04\n",
      "Epoch 718/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.5647e-04 - val_loss: 6.4839e-04\n",
      "Epoch 719/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.5533e-04 - val_loss: 6.4768e-04\n",
      "Epoch 720/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5419e-04 - val_loss: 6.4698e-04\n",
      "Epoch 721/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.5306e-04 - val_loss: 6.4627e-04\n",
      "Epoch 722/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 4.5193e-04 - val_loss: 6.4556e-04\n",
      "Epoch 723/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5080e-04 - val_loss: 6.4485e-04\n",
      "Epoch 724/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4968e-04 - val_loss: 6.4417e-04\n",
      "Epoch 725/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 4.4857e-04 - val_loss: 6.4346e-04\n",
      "Epoch 726/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4745e-04 - val_loss: 6.4275e-04\n",
      "Epoch 727/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.4635e-04 - val_loss: 6.4206e-04\n",
      "Epoch 728/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 4.4525e-04 - val_loss: 6.4137e-04\n",
      "Epoch 729/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4414e-04 - val_loss: 6.4066e-04\n",
      "Epoch 730/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4305e-04 - val_loss: 6.3997e-04\n",
      "Epoch 731/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4196e-04 - val_loss: 6.3929e-04\n",
      "Epoch 732/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4087e-04 - val_loss: 6.3859e-04\n",
      "Epoch 733/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.3979e-04 - val_loss: 6.3790e-04\n",
      "Epoch 734/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 4.3872e-04 - val_loss: 6.3721e-04\n",
      "Epoch 735/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.3765e-04 - val_loss: 6.3653e-04\n",
      "Epoch 736/1000\n",
      "32/32 [==============================] - 0s 132us/step - loss: 4.3657e-04 - val_loss: 6.3584e-04\n",
      "Epoch 737/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.3551e-04 - val_loss: 6.3517e-04\n",
      "Epoch 738/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.3444e-04 - val_loss: 6.3450e-04\n",
      "Epoch 739/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.3338e-04 - val_loss: 6.3382e-04\n",
      "Epoch 740/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 4.3233e-04 - val_loss: 6.3315e-04\n",
      "Epoch 741/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.3129e-04 - val_loss: 6.3249e-04\n",
      "Epoch 742/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.3025e-04 - val_loss: 6.3181e-04\n",
      "Epoch 743/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 4.2919e-04 - val_loss: 6.3114e-04\n",
      "Epoch 744/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.2816e-04 - val_loss: 6.3048e-04\n",
      "Epoch 745/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.2714e-04 - val_loss: 6.2982e-04\n",
      "Epoch 746/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2610e-04 - val_loss: 6.2915e-04\n",
      "Epoch 747/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2508e-04 - val_loss: 6.2848e-04\n",
      "Epoch 748/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.2406e-04 - val_loss: 6.2782e-04\n",
      "Epoch 749/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.2304e-04 - val_loss: 6.2716e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 750/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.2202e-04 - val_loss: 6.2651e-04\n",
      "Epoch 751/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2103e-04 - val_loss: 6.2585e-04\n",
      "Epoch 752/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2001e-04 - val_loss: 6.2519e-04\n",
      "Epoch 753/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.1902e-04 - val_loss: 6.2453e-04\n",
      "Epoch 754/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 4.1801e-04 - val_loss: 6.2389e-04\n",
      "Epoch 755/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 4.1702e-04 - val_loss: 6.2323e-04\n",
      "Epoch 756/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.1603e-04 - val_loss: 6.2261e-04\n",
      "Epoch 757/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.1505e-04 - val_loss: 6.2196e-04\n",
      "Epoch 758/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1406e-04 - val_loss: 6.2130e-04\n",
      "Epoch 759/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.1308e-04 - val_loss: 6.2067e-04\n",
      "Epoch 760/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.1210e-04 - val_loss: 6.1999e-04\n",
      "Epoch 761/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 4.1114e-04 - val_loss: 6.1938e-04\n",
      "Epoch 762/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.1018e-04 - val_loss: 6.1874e-04\n",
      "Epoch 763/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.0921e-04 - val_loss: 6.1811e-04\n",
      "Epoch 764/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0825e-04 - val_loss: 6.1747e-04\n",
      "Epoch 765/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.0729e-04 - val_loss: 6.1686e-04\n",
      "Epoch 766/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.0634e-04 - val_loss: 6.1620e-04\n",
      "Epoch 767/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 4.0540e-04 - val_loss: 6.1556e-04\n",
      "Epoch 768/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.0444e-04 - val_loss: 6.1493e-04\n",
      "Epoch 769/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 4.0351e-04 - val_loss: 6.1431e-04\n",
      "Epoch 770/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0257e-04 - val_loss: 6.1368e-04\n",
      "Epoch 771/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.0163e-04 - val_loss: 6.1309e-04\n",
      "Epoch 772/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.0071e-04 - val_loss: 6.1246e-04\n",
      "Epoch 773/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 3.9977e-04 - val_loss: 6.1183e-04\n",
      "Epoch 774/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.9886e-04 - val_loss: 6.1121e-04\n",
      "Epoch 775/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.9793e-04 - val_loss: 6.1060e-04\n",
      "Epoch 776/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 3.9702e-04 - val_loss: 6.0997e-04\n",
      "Epoch 777/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 3.9611e-04 - val_loss: 6.0936e-04\n",
      "Epoch 778/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9520e-04 - val_loss: 6.0876e-04\n",
      "Epoch 779/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.9429e-04 - val_loss: 6.0816e-04\n",
      "Epoch 780/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.9339e-04 - val_loss: 6.0754e-04\n",
      "Epoch 781/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.9249e-04 - val_loss: 6.0694e-04\n",
      "Epoch 782/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9160e-04 - val_loss: 6.0632e-04\n",
      "Epoch 783/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.9071e-04 - val_loss: 6.0573e-04\n",
      "Epoch 784/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.8982e-04 - val_loss: 6.0510e-04\n",
      "Epoch 785/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.8894e-04 - val_loss: 6.0450e-04\n",
      "Epoch 786/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.8805e-04 - val_loss: 6.0392e-04\n",
      "Epoch 787/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8718e-04 - val_loss: 6.0333e-04\n",
      "Epoch 788/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8630e-04 - val_loss: 6.0272e-04\n",
      "Epoch 789/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.8543e-04 - val_loss: 6.0211e-04\n",
      "Epoch 790/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.8456e-04 - val_loss: 6.0154e-04\n",
      "Epoch 791/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.8370e-04 - val_loss: 6.0093e-04\n",
      "Epoch 792/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.8283e-04 - val_loss: 6.0035e-04\n",
      "Epoch 793/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 3.8198e-04 - val_loss: 5.9976e-04\n",
      "Epoch 794/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.8112e-04 - val_loss: 5.9918e-04\n",
      "Epoch 795/1000\n",
      "32/32 [==============================] - 0s 115us/step - loss: 3.8027e-04 - val_loss: 5.9858e-04\n",
      "Epoch 796/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.7943e-04 - val_loss: 5.9800e-04\n",
      "Epoch 797/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7859e-04 - val_loss: 5.9742e-04\n",
      "Epoch 798/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.7774e-04 - val_loss: 5.9686e-04\n",
      "Epoch 799/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.7690e-04 - val_loss: 5.9626e-04\n",
      "Epoch 800/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7607e-04 - val_loss: 5.9567e-04\n",
      "Epoch 801/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.7523e-04 - val_loss: 5.9509e-04\n",
      "Epoch 802/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7441e-04 - val_loss: 5.9454e-04\n",
      "Epoch 803/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.7358e-04 - val_loss: 5.9394e-04\n",
      "Epoch 804/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.7276e-04 - val_loss: 5.9339e-04\n",
      "Epoch 805/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.7194e-04 - val_loss: 5.9282e-04\n",
      "Epoch 806/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.7113e-04 - val_loss: 5.9224e-04\n",
      "Epoch 807/1000\n",
      "32/32 [==============================] - 0s 131us/step - loss: 3.7032e-04 - val_loss: 5.9167e-04\n",
      "Epoch 808/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 3.6950e-04 - val_loss: 5.9110e-04\n",
      "Epoch 809/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6870e-04 - val_loss: 5.9056e-04\n",
      "Epoch 810/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.6790e-04 - val_loss: 5.8999e-04\n",
      "Epoch 811/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6710e-04 - val_loss: 5.8939e-04\n",
      "Epoch 812/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6630e-04 - val_loss: 5.8884e-04\n",
      "Epoch 813/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.6550e-04 - val_loss: 5.8826e-04\n",
      "Epoch 814/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 3.6471e-04 - val_loss: 5.8772e-04\n",
      "Epoch 815/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.6392e-04 - val_loss: 5.8718e-04\n",
      "Epoch 816/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6315e-04 - val_loss: 5.8661e-04\n",
      "Epoch 817/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 3.6236e-04 - val_loss: 5.8606e-04\n",
      "Epoch 818/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.6158e-04 - val_loss: 5.8551e-04\n",
      "Epoch 819/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6081e-04 - val_loss: 5.8495e-04\n",
      "Epoch 820/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.6004e-04 - val_loss: 5.8440e-04\n",
      "Epoch 821/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5926e-04 - val_loss: 5.8387e-04\n",
      "Epoch 822/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.5849e-04 - val_loss: 5.8332e-04\n",
      "Epoch 823/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5773e-04 - val_loss: 5.8278e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 824/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.5697e-04 - val_loss: 5.8224e-04\n",
      "Epoch 825/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.5622e-04 - val_loss: 5.8169e-04\n",
      "Epoch 826/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.5546e-04 - val_loss: 5.8115e-04\n",
      "Epoch 827/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5470e-04 - val_loss: 5.8061e-04\n",
      "Epoch 828/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.5396e-04 - val_loss: 5.8008e-04\n",
      "Epoch 829/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5322e-04 - val_loss: 5.7952e-04\n",
      "Epoch 830/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5247e-04 - val_loss: 5.7899e-04\n",
      "Epoch 831/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5173e-04 - val_loss: 5.7845e-04\n",
      "Epoch 832/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 3.5099e-04 - val_loss: 5.7791e-04\n",
      "Epoch 833/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.5026e-04 - val_loss: 5.7736e-04\n",
      "Epoch 834/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 3.4952e-04 - val_loss: 5.7685e-04\n",
      "Epoch 835/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4880e-04 - val_loss: 5.7631e-04\n",
      "Epoch 836/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.4808e-04 - val_loss: 5.7577e-04\n",
      "Epoch 837/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.4735e-04 - val_loss: 5.7524e-04\n",
      "Epoch 838/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4662e-04 - val_loss: 5.7473e-04\n",
      "Epoch 839/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 3.4591e-04 - val_loss: 5.7420e-04\n",
      "Epoch 840/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4520e-04 - val_loss: 5.7369e-04\n",
      "Epoch 841/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 3.4448e-04 - val_loss: 5.7315e-04\n",
      "Epoch 842/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4377e-04 - val_loss: 5.7265e-04\n",
      "Epoch 843/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4306e-04 - val_loss: 5.7211e-04\n",
      "Epoch 844/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4236e-04 - val_loss: 5.7161e-04\n",
      "Epoch 845/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4166e-04 - val_loss: 5.7108e-04\n",
      "Epoch 846/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4096e-04 - val_loss: 5.7057e-04\n",
      "Epoch 847/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 3.4026e-04 - val_loss: 5.7005e-04\n",
      "Epoch 848/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.3957e-04 - val_loss: 5.6955e-04\n",
      "Epoch 849/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3888e-04 - val_loss: 5.6901e-04\n",
      "Epoch 850/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3819e-04 - val_loss: 5.6853e-04\n",
      "Epoch 851/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.3751e-04 - val_loss: 5.6802e-04\n",
      "Epoch 852/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3683e-04 - val_loss: 5.6751e-04\n",
      "Epoch 853/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.3614e-04 - val_loss: 5.6699e-04\n",
      "Epoch 854/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3547e-04 - val_loss: 5.6650e-04\n",
      "Epoch 855/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3480e-04 - val_loss: 5.6596e-04\n",
      "Epoch 856/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3412e-04 - val_loss: 5.6547e-04\n",
      "Epoch 857/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.3345e-04 - val_loss: 5.6499e-04\n",
      "Epoch 858/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3278e-04 - val_loss: 5.6447e-04\n",
      "Epoch 859/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3212e-04 - val_loss: 5.6396e-04\n",
      "Epoch 860/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3146e-04 - val_loss: 5.6347e-04\n",
      "Epoch 861/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 3.3080e-04 - val_loss: 5.6297e-04\n",
      "Epoch 862/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 3.3014e-04 - val_loss: 5.6247e-04\n",
      "Epoch 863/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 3.2948e-04 - val_loss: 5.6198e-04\n",
      "Epoch 864/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2884e-04 - val_loss: 5.6149e-04\n",
      "Epoch 865/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2819e-04 - val_loss: 5.6100e-04\n",
      "Epoch 866/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2754e-04 - val_loss: 5.6050e-04\n",
      "Epoch 867/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.2689e-04 - val_loss: 5.6001e-04\n",
      "Epoch 868/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2625e-04 - val_loss: 5.5951e-04\n",
      "Epoch 869/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2561e-04 - val_loss: 5.5903e-04\n",
      "Epoch 870/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2498e-04 - val_loss: 5.5854e-04\n",
      "Epoch 871/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 3.2434e-04 - val_loss: 5.5807e-04\n",
      "Epoch 872/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2371e-04 - val_loss: 5.5758e-04\n",
      "Epoch 873/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2308e-04 - val_loss: 5.5709e-04\n",
      "Epoch 874/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2244e-04 - val_loss: 5.5661e-04\n",
      "Epoch 875/1000\n",
      "32/32 [==============================] - 0s 138us/step - loss: 3.2183e-04 - val_loss: 5.5614e-04\n",
      "Epoch 876/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2120e-04 - val_loss: 5.5564e-04\n",
      "Epoch 877/1000\n",
      "32/32 [==============================] - 0s 145us/step - loss: 3.2058e-04 - val_loss: 5.5518e-04\n",
      "Epoch 878/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 3.1997e-04 - val_loss: 5.5469e-04\n",
      "Epoch 879/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1935e-04 - val_loss: 5.5421e-04\n",
      "Epoch 880/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1874e-04 - val_loss: 5.5374e-04\n",
      "Epoch 881/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 3.1812e-04 - val_loss: 5.5325e-04\n",
      "Epoch 882/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.1751e-04 - val_loss: 5.5279e-04\n",
      "Epoch 883/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1692e-04 - val_loss: 5.5230e-04\n",
      "Epoch 884/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 3.1630e-04 - val_loss: 5.5184e-04\n",
      "Epoch 885/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1570e-04 - val_loss: 5.5136e-04\n",
      "Epoch 886/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1511e-04 - val_loss: 5.5089e-04\n",
      "Epoch 887/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.1451e-04 - val_loss: 5.5045e-04\n",
      "Epoch 888/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1391e-04 - val_loss: 5.4998e-04\n",
      "Epoch 889/1000\n",
      "32/32 [==============================] - 0s 131us/step - loss: 3.1332e-04 - val_loss: 5.4951e-04\n",
      "Epoch 890/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1273e-04 - val_loss: 5.4904e-04\n",
      "Epoch 891/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1214e-04 - val_loss: 5.4859e-04\n",
      "Epoch 892/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1156e-04 - val_loss: 5.4811e-04\n",
      "Epoch 893/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1097e-04 - val_loss: 5.4765e-04\n",
      "Epoch 894/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.1039e-04 - val_loss: 5.4719e-04\n",
      "Epoch 895/1000\n",
      "32/32 [==============================] - 0s 161us/step - loss: 3.0981e-04 - val_loss: 5.4673e-04\n",
      "Epoch 896/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0923e-04 - val_loss: 5.4626e-04\n",
      "Epoch 897/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.0866e-04 - val_loss: 5.4581e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 898/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0809e-04 - val_loss: 5.4535e-04\n",
      "Epoch 899/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0752e-04 - val_loss: 5.4490e-04\n",
      "Epoch 900/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.0696e-04 - val_loss: 5.4444e-04\n",
      "Epoch 901/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0639e-04 - val_loss: 5.4398e-04\n",
      "Epoch 902/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0582e-04 - val_loss: 5.4355e-04\n",
      "Epoch 903/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 3.0526e-04 - val_loss: 5.4309e-04\n",
      "Epoch 904/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0470e-04 - val_loss: 5.4263e-04\n",
      "Epoch 905/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0415e-04 - val_loss: 5.4219e-04\n",
      "Epoch 906/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0359e-04 - val_loss: 5.4174e-04\n",
      "Epoch 907/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0303e-04 - val_loss: 5.4130e-04\n",
      "Epoch 908/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0249e-04 - val_loss: 5.4083e-04\n",
      "Epoch 909/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.0193e-04 - val_loss: 5.4040e-04\n",
      "Epoch 910/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 3.0139e-04 - val_loss: 5.3996e-04\n",
      "Epoch 911/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0085e-04 - val_loss: 5.3951e-04\n",
      "Epoch 912/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 3.0030e-04 - val_loss: 5.3906e-04\n",
      "Epoch 913/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 2.9976e-04 - val_loss: 5.3862e-04\n",
      "Epoch 914/1000\n",
      "32/32 [==============================] - 0s 120us/step - loss: 2.9922e-04 - val_loss: 5.3819e-04\n",
      "Epoch 915/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9868e-04 - val_loss: 5.3776e-04\n",
      "Epoch 916/1000\n",
      "32/32 [==============================] - 0s 162us/step - loss: 2.9815e-04 - val_loss: 5.3729e-04\n",
      "Epoch 917/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.9761e-04 - val_loss: 5.3688e-04\n",
      "Epoch 918/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.9709e-04 - val_loss: 5.3644e-04\n",
      "Epoch 919/1000\n",
      "32/32 [==============================] - 0s 129us/step - loss: 2.9656e-04 - val_loss: 5.3599e-04\n",
      "Epoch 920/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 2.9603e-04 - val_loss: 5.3554e-04\n",
      "Epoch 921/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9550e-04 - val_loss: 5.3511e-04\n",
      "Epoch 922/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 2.9498e-04 - val_loss: 5.3469e-04\n",
      "Epoch 923/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9446e-04 - val_loss: 5.3425e-04\n",
      "Epoch 924/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.9394e-04 - val_loss: 5.3384e-04\n",
      "Epoch 925/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9343e-04 - val_loss: 5.3341e-04\n",
      "Epoch 926/1000\n",
      "32/32 [==============================] - 0s 131us/step - loss: 2.9291e-04 - val_loss: 5.3297e-04\n",
      "Epoch 927/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.9240e-04 - val_loss: 5.3253e-04\n",
      "Epoch 928/1000\n",
      "32/32 [==============================] - 0s 118us/step - loss: 2.9189e-04 - val_loss: 5.3209e-04\n",
      "Epoch 929/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9138e-04 - val_loss: 5.3168e-04\n",
      "Epoch 930/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9087e-04 - val_loss: 5.3127e-04\n",
      "Epoch 931/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 2.9036e-04 - val_loss: 5.3084e-04\n",
      "Epoch 932/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8986e-04 - val_loss: 5.3041e-04\n",
      "Epoch 933/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.8935e-04 - val_loss: 5.2999e-04\n",
      "Epoch 934/1000\n",
      "32/32 [==============================] - 0s 137us/step - loss: 2.8886e-04 - val_loss: 5.2957e-04\n",
      "Epoch 935/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8836e-04 - val_loss: 5.2914e-04\n",
      "Epoch 936/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.8786e-04 - val_loss: 5.2871e-04\n",
      "Epoch 937/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8737e-04 - val_loss: 5.2832e-04\n",
      "Epoch 938/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8687e-04 - val_loss: 5.2790e-04\n",
      "Epoch 939/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.8638e-04 - val_loss: 5.2748e-04\n",
      "Epoch 940/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 2.8589e-04 - val_loss: 5.2707e-04\n",
      "Epoch 941/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 2.8541e-04 - val_loss: 5.2665e-04\n",
      "Epoch 942/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.8493e-04 - val_loss: 5.2623e-04\n",
      "Epoch 943/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 2.8444e-04 - val_loss: 5.2581e-04\n",
      "Epoch 944/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8395e-04 - val_loss: 5.2539e-04\n",
      "Epoch 945/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.8348e-04 - val_loss: 5.2497e-04\n",
      "Epoch 946/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 2.8300e-04 - val_loss: 5.2457e-04\n",
      "Epoch 947/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.8253e-04 - val_loss: 5.2418e-04\n",
      "Epoch 948/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8205e-04 - val_loss: 5.2375e-04\n",
      "Epoch 949/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8158e-04 - val_loss: 5.2336e-04\n",
      "Epoch 950/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.8111e-04 - val_loss: 5.2295e-04\n",
      "Epoch 951/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8063e-04 - val_loss: 5.2252e-04\n",
      "Epoch 952/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8017e-04 - val_loss: 5.2210e-04\n",
      "Epoch 953/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.7970e-04 - val_loss: 5.2171e-04\n",
      "Epoch 954/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7924e-04 - val_loss: 5.2131e-04\n",
      "Epoch 955/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 2.7878e-04 - val_loss: 5.2092e-04\n",
      "Epoch 956/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.7831e-04 - val_loss: 5.2052e-04\n",
      "Epoch 957/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 2.7786e-04 - val_loss: 5.2011e-04\n",
      "Epoch 958/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7740e-04 - val_loss: 5.1970e-04\n",
      "Epoch 959/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7694e-04 - val_loss: 5.1929e-04\n",
      "Epoch 960/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7649e-04 - val_loss: 5.1889e-04\n",
      "Epoch 961/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.7603e-04 - val_loss: 5.1849e-04\n",
      "Epoch 962/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7558e-04 - val_loss: 5.1809e-04\n",
      "Epoch 963/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7514e-04 - val_loss: 5.1771e-04\n",
      "Epoch 964/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7469e-04 - val_loss: 5.1729e-04\n",
      "Epoch 965/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7424e-04 - val_loss: 5.1690e-04\n",
      "Epoch 966/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.7380e-04 - val_loss: 5.1651e-04\n",
      "Epoch 967/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.7335e-04 - val_loss: 5.1611e-04\n",
      "Epoch 968/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.7291e-04 - val_loss: 5.1571e-04\n",
      "Epoch 969/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 2.7247e-04 - val_loss: 5.1531e-04\n",
      "Epoch 970/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.7203e-04 - val_loss: 5.1492e-04\n",
      "Epoch 971/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.7160e-04 - val_loss: 5.1453e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 972/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.7116e-04 - val_loss: 5.1417e-04\n",
      "Epoch 973/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7073e-04 - val_loss: 5.1377e-04\n",
      "Epoch 974/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7030e-04 - val_loss: 5.1338e-04\n",
      "Epoch 975/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.6987e-04 - val_loss: 5.1298e-04\n",
      "Epoch 976/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.6944e-04 - val_loss: 5.1260e-04\n",
      "Epoch 977/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.6902e-04 - val_loss: 5.1221e-04\n",
      "Epoch 978/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6859e-04 - val_loss: 5.1183e-04\n",
      "Epoch 979/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6817e-04 - val_loss: 5.1144e-04\n",
      "Epoch 980/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6774e-04 - val_loss: 5.1106e-04\n",
      "Epoch 981/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6732e-04 - val_loss: 5.1068e-04\n",
      "Epoch 982/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.6690e-04 - val_loss: 5.1030e-04\n",
      "Epoch 983/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.6649e-04 - val_loss: 5.0991e-04\n",
      "Epoch 984/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6607e-04 - val_loss: 5.0951e-04\n",
      "Epoch 985/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6566e-04 - val_loss: 5.0915e-04\n",
      "Epoch 986/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.6524e-04 - val_loss: 5.0876e-04\n",
      "Epoch 987/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6483e-04 - val_loss: 5.0839e-04\n",
      "Epoch 988/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6442e-04 - val_loss: 5.0799e-04\n",
      "Epoch 989/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.6401e-04 - val_loss: 5.0763e-04\n",
      "Epoch 990/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6360e-04 - val_loss: 5.0725e-04\n",
      "Epoch 991/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.6320e-04 - val_loss: 5.0688e-04\n",
      "Epoch 992/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6279e-04 - val_loss: 5.0650e-04\n",
      "Epoch 993/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.6239e-04 - val_loss: 5.0613e-04\n",
      "Epoch 994/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.6199e-04 - val_loss: 5.0575e-04\n",
      "Epoch 995/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6159e-04 - val_loss: 5.0539e-04\n",
      "Epoch 996/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6119e-04 - val_loss: 5.0501e-04\n",
      "Epoch 997/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.6079e-04 - val_loss: 5.0464e-04\n",
      "Epoch 998/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6039e-04 - val_loss: 5.0428e-04\n",
      "Epoch 999/1000\n",
      "32/32 [==============================] - 0s 167us/step - loss: 2.6001e-04 - val_loss: 5.0392e-04\n",
      "Epoch 1000/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.5961e-04 - val_loss: 5.0352e-04\n",
      "0.00033181512844748795\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 1.1581059e+00,  6.3869971e-01,  7.7265894e-01,  1.2397592e+00,\n",
       "         -6.4233893e-01],\n",
       "        [-1.0345707e+00, -1.4063919e-01, -5.3761059e-01, -2.3501703e-01,\n",
       "         -3.5349315e-01],\n",
       "        [ 4.7792643e-01,  4.2390421e-01, -9.0355414e-01,  1.0373666e-03,\n",
       "         -1.1366388e+00]], dtype=float32),\n",
       " array([-0.64040315, -0.44148642,  0.5906181 , -0.47602898, -0.58039093],\n",
       "       dtype=float32),\n",
       " array([[-1.92478508e-01, -4.01316196e-01,  6.07602119e-01,\n",
       "          8.09499741e-01,  3.58353317e-01,  7.25540891e-02,\n",
       "          6.19982839e-01,  6.74844757e-02, -4.07430887e-01,\n",
       "         -5.09212017e-01,  1.59765616e-01,  5.48962355e-01,\n",
       "          2.87529469e-01,  2.87123352e-01, -5.05611636e-02],\n",
       "        [-4.31572646e-01, -3.09531599e-01, -2.21672595e-01,\n",
       "          1.39170483e-01, -1.19934820e-01,  3.94964814e-01,\n",
       "          4.50524658e-01,  5.79960234e-02,  8.08351710e-02,\n",
       "         -6.52391613e-02, -6.13993227e-01, -1.94198534e-01,\n",
       "          1.30490154e-01,  1.21540479e-01, -1.11307821e-03],\n",
       "        [ 3.12649339e-01, -3.39696437e-01, -5.31668961e-01,\n",
       "          4.09899175e-01,  4.51478630e-01, -4.62306559e-01,\n",
       "          9.28491876e-02, -1.53415382e-01, -4.16160673e-01,\n",
       "          3.14039797e-01,  1.42574608e-01, -7.73174703e-01,\n",
       "         -3.78787853e-02, -4.18933183e-01, -3.80386978e-01],\n",
       "        [-7.72401392e-02,  5.15160561e-01, -5.44431329e-01,\n",
       "         -2.19887063e-01, -1.81204304e-01, -7.11185455e-01,\n",
       "          6.29181834e-03, -1.20594501e+00, -1.24750130e-01,\n",
       "         -2.73923367e-01, -1.76383890e-02, -2.58803964e-01,\n",
       "          3.37674826e-01, -7.81901598e-01,  6.51007742e-02],\n",
       "        [ 3.05523545e-01,  1.29730374e-01, -1.82914257e-01,\n",
       "         -1.43028930e-01, -1.73425734e-01, -1.44061595e-01,\n",
       "          7.45106757e-01, -1.19483694e-01,  7.16245234e-01,\n",
       "         -1.29646838e-01, -5.61857164e-01,  5.16777158e-01,\n",
       "          3.96964610e-01, -1.50291631e-02,  5.21967888e-01]], dtype=float32),\n",
       " array([ 0.6327076 ,  0.3033525 , -0.599245  , -0.44588444,  0.46508688,\n",
       "        -0.56562376, -0.6333901 ,  0.17950012, -0.6026538 ,  0.605122  ,\n",
       "         0.6133859 , -0.6779005 , -0.68417794, -0.52244645, -0.66540504],\n",
       "       dtype=float32),\n",
       " array([[ 0.4505172 ],\n",
       "        [-0.05903852],\n",
       "        [-0.29626316],\n",
       "        [ 0.02629004],\n",
       "        [ 0.23020382],\n",
       "        [-0.3446847 ],\n",
       "        [-0.49996102],\n",
       "        [ 0.30899033],\n",
       "        [-0.44175747],\n",
       "        [ 0.4057372 ],\n",
       "        [ 0.4848972 ],\n",
       "        [-0.74213237],\n",
       "        [-0.7675773 ],\n",
       "        [-0.24600922],\n",
       "        [-0.64657307]], dtype=float32),\n",
       " array([0.7558579], dtype=float32)]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_challenger, history_challenger, evaluate_challenger=NN_model_structure_regression_3(X_train_challenger, X_val_challenger, Y_train_challenger, Y_val_challenger, adam2, 32, 1000, x_test_challenger, y_test_challenger)\n",
    "model_challenger.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_challenger.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_challenger_structure3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_64 (Dense)             (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 101\n",
      "Trainable params: 101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 32 samples, validate on 7 samples\n",
      "Epoch 1/1000\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 36.5923 - val_loss: 35.8282\n",
      "Epoch 2/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 33.5816 - val_loss: 31.9726\n",
      "Epoch 3/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 29.7880 - val_loss: 27.2681\n",
      "Epoch 4/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 24.9621 - val_loss: 20.9078\n",
      "Epoch 5/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 18.8254 - val_loss: 13.0141\n",
      "Epoch 6/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 11.7268 - val_loss: 5.2532\n",
      "Epoch 7/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 5.0029 - val_loss: 0.8292\n",
      "Epoch 8/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.9248 - val_loss: 2.4526\n",
      "Epoch 9/1000\n",
      "32/32 [==============================] - 0s 138us/step - loss: 1.7233 - val_loss: 6.7628\n",
      "Epoch 10/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.6736 - val_loss: 7.2791\n",
      "Epoch 11/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.8698 - val_loss: 5.2239\n",
      "Epoch 12/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.2874 - val_loss: 2.9849\n",
      "Epoch 13/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.0328 - val_loss: 1.3545\n",
      "Epoch 14/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2878 - val_loss: 0.5015\n",
      "Epoch 15/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.5070 - val_loss: 0.3363\n",
      "Epoch 16/1000\n",
      "32/32 [==============================] - 0s 138us/step - loss: 0.6170 - val_loss: 0.5848\n",
      "Epoch 17/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.2122 - val_loss: 0.9427\n",
      "Epoch 18/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 1.8507 - val_loss: 1.1995\n",
      "Epoch 19/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.2509 - val_loss: 1.2677\n",
      "Epoch 20/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.3227 - val_loss: 1.1510\n",
      "Epoch 21/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 2.1056 - val_loss: 0.9042\n",
      "Epoch 22/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.7005 - val_loss: 0.6031\n",
      "Epoch 23/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.2216 - val_loss: 0.3245\n",
      "Epoch 24/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 0.7704 - val_loss: 0.1320\n",
      "Epoch 25/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.4229 - val_loss: 0.0629\n",
      "Epoch 26/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.2278 - val_loss: 0.1195\n",
      "Epoch 27/1000\n",
      "32/32 [==============================] - 0s 160us/step - loss: 0.2050 - val_loss: 0.2645\n",
      "Epoch 28/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.3348 - val_loss: 0.4291\n",
      "Epoch 29/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.5437 - val_loss: 0.5394\n",
      "Epoch 30/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.7175 - val_loss: 0.5510\n",
      "Epoch 31/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.7621 - val_loss: 0.4678\n",
      "Epoch 32/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.6602 - val_loss: 0.3302\n",
      "Epoch 33/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.4692 - val_loss: 0.1891\n",
      "Epoch 34/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 0.2732 - val_loss: 0.0828\n",
      "Epoch 35/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1355 - val_loss: 0.0276\n",
      "Epoch 36/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0779 - val_loss: 0.0195\n",
      "Epoch 37/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 0.0877 - val_loss: 0.0426\n",
      "Epoch 38/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1356 - val_loss: 0.0780\n",
      "Epoch 39/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1918 - val_loss: 0.1099\n",
      "Epoch 40/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.2349 - val_loss: 0.1281\n",
      "Epoch 41/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.2537 - val_loss: 0.1287\n",
      "Epoch 42/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.2459 - val_loss: 0.1134\n",
      "Epoch 43/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 0.2159 - val_loss: 0.0874\n",
      "Epoch 44/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.1722 - val_loss: 0.0580\n",
      "Epoch 45/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1251 - val_loss: 0.0323\n",
      "Epoch 46/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0848 - val_loss: 0.0155\n",
      "Epoch 47/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0585 - val_loss: 0.0095\n",
      "Epoch 48/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 0.0496 - val_loss: 0.0129\n",
      "Epoch 49/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0561 - val_loss: 0.0215\n",
      "Epoch 50/1000\n",
      "32/32 [==============================] - 0s 145us/step - loss: 0.0715 - val_loss: 0.0303\n",
      "Epoch 51/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0876 - val_loss: 0.0353\n",
      "Epoch 52/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0972 - val_loss: 0.0346\n",
      "Epoch 53/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0963 - val_loss: 0.0287\n",
      "Epoch 54/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 0.0857 - val_loss: 0.0202\n",
      "Epoch 55/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0693 - val_loss: 0.0123\n",
      "Epoch 56/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0523 - val_loss: 0.0075\n",
      "Epoch 57/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0391 - val_loss: 0.0074\n",
      "Epoch 58/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0318 - val_loss: 0.0119\n",
      "Epoch 59/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0304 - val_loss: 0.0197\n",
      "Epoch 60/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0333 - val_loss: 0.0289\n",
      "Epoch 61/1000\n",
      "32/32 [==============================] - 0s 160us/step - loss: 0.0381 - val_loss: 0.0372\n",
      "Epoch 62/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 0.0425 - val_loss: 0.0428\n",
      "Epoch 63/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0450 - val_loss: 0.0446\n",
      "Epoch 64/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0446 - val_loss: 0.0424\n",
      "Epoch 65/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0416 - val_loss: 0.0369\n",
      "Epoch 66/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 0.0368 - val_loss: 0.0295\n",
      "Epoch 67/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0314 - val_loss: 0.0217\n",
      "Epoch 68/1000\n",
      "32/32 [==============================] - 0s 189us/step - loss: 0.0266 - val_loss: 0.0150\n",
      "Epoch 69/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0233 - val_loss: 0.0100\n",
      "Epoch 70/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0221 - val_loss: 0.0071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0226 - val_loss: 0.0056\n",
      "Epoch 72/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0239 - val_loss: 0.0051\n",
      "Epoch 73/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0253 - val_loss: 0.0048\n",
      "Epoch 74/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0260 - val_loss: 0.0045\n",
      "Epoch 75/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0255 - val_loss: 0.0041\n",
      "Epoch 76/1000\n",
      "32/32 [==============================] - 0s 182us/step - loss: 0.0241 - val_loss: 0.0039\n",
      "Epoch 77/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0221 - val_loss: 0.0041\n",
      "Epoch 78/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0201 - val_loss: 0.0049\n",
      "Epoch 79/1000\n",
      "32/32 [==============================] - 0s 177us/step - loss: 0.0186 - val_loss: 0.0062\n",
      "Epoch 80/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0176 - val_loss: 0.0077\n",
      "Epoch 81/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0173 - val_loss: 0.0093\n",
      "Epoch 82/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0174 - val_loss: 0.0105\n",
      "Epoch 83/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0176 - val_loss: 0.0113\n",
      "Epoch 84/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0178 - val_loss: 0.0115\n",
      "Epoch 85/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0178 - val_loss: 0.0112\n",
      "Epoch 86/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0175 - val_loss: 0.0104\n",
      "Epoch 87/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0170 - val_loss: 0.0094\n",
      "Epoch 88/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0163 - val_loss: 0.0082\n",
      "Epoch 89/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0156 - val_loss: 0.0070\n",
      "Epoch 90/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 0.0149 - val_loss: 0.0060\n",
      "Epoch 91/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0145 - val_loss: 0.0052\n",
      "Epoch 92/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0142 - val_loss: 0.0047\n",
      "Epoch 93/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0141 - val_loss: 0.0043\n",
      "Epoch 94/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0141 - val_loss: 0.0042\n",
      "Epoch 95/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0141 - val_loss: 0.0043\n",
      "Epoch 96/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0140 - val_loss: 0.0045\n",
      "Epoch 97/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0138 - val_loss: 0.0048\n",
      "Epoch 98/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0135 - val_loss: 0.0051\n",
      "Epoch 99/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0132 - val_loss: 0.0056\n",
      "Epoch 100/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0129 - val_loss: 0.0060\n",
      "Epoch 101/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0126 - val_loss: 0.0065\n",
      "Epoch 102/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0124 - val_loss: 0.0069\n",
      "Epoch 103/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0122 - val_loss: 0.0073\n",
      "Epoch 104/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0121 - val_loss: 0.0076\n",
      "Epoch 105/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 0.0120 - val_loss: 0.0077\n",
      "Epoch 106/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0119 - val_loss: 0.0077\n",
      "Epoch 107/1000\n",
      "32/32 [==============================] - 0s 145us/step - loss: 0.0118 - val_loss: 0.0076\n",
      "Epoch 108/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0117 - val_loss: 0.0074\n",
      "Epoch 109/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0115 - val_loss: 0.0071\n",
      "Epoch 110/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0113 - val_loss: 0.0068\n",
      "Epoch 111/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0112 - val_loss: 0.0065\n",
      "Epoch 112/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0110 - val_loss: 0.0062\n",
      "Epoch 113/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0109 - val_loss: 0.0059\n",
      "Epoch 114/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0108 - val_loss: 0.0057\n",
      "Epoch 115/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0107 - val_loss: 0.0055\n",
      "Epoch 116/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0106 - val_loss: 0.0053\n",
      "Epoch 117/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0105 - val_loss: 0.0052\n",
      "Epoch 118/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0104 - val_loss: 0.0052\n",
      "Epoch 119/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 0.0103 - val_loss: 0.0052\n",
      "Epoch 120/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 0.0102 - val_loss: 0.0052\n",
      "Epoch 121/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0100 - val_loss: 0.0053\n",
      "Epoch 122/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0099 - val_loss: 0.0054\n",
      "Epoch 123/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0098 - val_loss: 0.0056\n",
      "Epoch 124/1000\n",
      "32/32 [==============================] - 0s 201us/step - loss: 0.0097 - val_loss: 0.0057\n",
      "Epoch 125/1000\n",
      "32/32 [==============================] - 0s 138us/step - loss: 0.0096 - val_loss: 0.0058\n",
      "Epoch 126/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0095 - val_loss: 0.0059\n",
      "Epoch 127/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0095 - val_loss: 0.0060\n",
      "Epoch 128/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0094 - val_loss: 0.0060\n",
      "Epoch 129/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0093 - val_loss: 0.0060\n",
      "Epoch 130/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0092 - val_loss: 0.0060\n",
      "Epoch 131/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0091 - val_loss: 0.0059\n",
      "Epoch 132/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0090 - val_loss: 0.0058\n",
      "Epoch 133/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0089 - val_loss: 0.0057\n",
      "Epoch 134/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0088 - val_loss: 0.0056\n",
      "Epoch 135/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0087 - val_loss: 0.0055\n",
      "Epoch 136/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0087 - val_loss: 0.0055\n",
      "Epoch 137/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 0.0086 - val_loss: 0.0054\n",
      "Epoch 138/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0085 - val_loss: 0.0054\n",
      "Epoch 139/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0084 - val_loss: 0.0054\n",
      "Epoch 140/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0084 - val_loss: 0.0054\n",
      "Epoch 141/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0083 - val_loss: 0.0054\n",
      "Epoch 142/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0082 - val_loss: 0.0054\n",
      "Epoch 143/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0081 - val_loss: 0.0055\n",
      "Epoch 144/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0081 - val_loss: 0.0055\n",
      "Epoch 145/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0080 - val_loss: 0.0056\n",
      "Epoch 146/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0079 - val_loss: 0.0056\n",
      "Epoch 147/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0078 - val_loss: 0.0056\n",
      "Epoch 148/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0078 - val_loss: 0.0056\n",
      "Epoch 149/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0077 - val_loss: 0.0056\n",
      "Epoch 150/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0076 - val_loss: 0.0056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0076 - val_loss: 0.0055\n",
      "Epoch 152/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0075 - val_loss: 0.0055\n",
      "Epoch 153/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0074 - val_loss: 0.0054\n",
      "Epoch 154/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0074 - val_loss: 0.0053\n",
      "Epoch 155/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0073 - val_loss: 0.0053\n",
      "Epoch 156/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0072 - val_loss: 0.0052\n",
      "Epoch 157/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0072 - val_loss: 0.0052\n",
      "Epoch 158/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 0.0071 - val_loss: 0.0051\n",
      "Epoch 159/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 0.0071 - val_loss: 0.0051\n",
      "Epoch 160/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0070 - val_loss: 0.0051\n",
      "Epoch 161/1000\n",
      "32/32 [==============================] - 0s 163us/step - loss: 0.0069 - val_loss: 0.0051\n",
      "Epoch 162/1000\n",
      "32/32 [==============================] - 0s 138us/step - loss: 0.0069 - val_loss: 0.0050\n",
      "Epoch 163/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 0.0068 - val_loss: 0.0050\n",
      "Epoch 164/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0068 - val_loss: 0.0050\n",
      "Epoch 165/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0067 - val_loss: 0.0050\n",
      "Epoch 166/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0066 - val_loss: 0.0050\n",
      "Epoch 167/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0066 - val_loss: 0.0050\n",
      "Epoch 168/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0065 - val_loss: 0.0050\n",
      "Epoch 169/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0065 - val_loss: 0.0049\n",
      "Epoch 170/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0064 - val_loss: 0.0049\n",
      "Epoch 171/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0064 - val_loss: 0.0049\n",
      "Epoch 172/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0063 - val_loss: 0.0049\n",
      "Epoch 173/1000\n",
      "32/32 [==============================] - 0s 163us/step - loss: 0.0063 - val_loss: 0.0048\n",
      "Epoch 174/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 0.0062 - val_loss: 0.0048\n",
      "Epoch 175/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0062 - val_loss: 0.0048\n",
      "Epoch 176/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0061 - val_loss: 0.0047\n",
      "Epoch 177/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 0.0060 - val_loss: 0.0047\n",
      "Epoch 178/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0060 - val_loss: 0.0047\n",
      "Epoch 179/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0059 - val_loss: 0.0046\n",
      "Epoch 180/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 0.0059 - val_loss: 0.0046\n",
      "Epoch 181/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 0.0058 - val_loss: 0.0046\n",
      "Epoch 182/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0058 - val_loss: 0.0045\n",
      "Epoch 183/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 0.0058 - val_loss: 0.0045\n",
      "Epoch 184/1000\n",
      "32/32 [==============================] - 0s 131us/step - loss: 0.0057 - val_loss: 0.0045\n",
      "Epoch 185/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0057 - val_loss: 0.0045\n",
      "Epoch 186/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0056 - val_loss: 0.0044\n",
      "Epoch 187/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0056 - val_loss: 0.0044\n",
      "Epoch 188/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0055 - val_loss: 0.0044\n",
      "Epoch 189/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0055 - val_loss: 0.0044\n",
      "Epoch 190/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0054 - val_loss: 0.0043\n",
      "Epoch 191/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0054 - val_loss: 0.0043\n",
      "Epoch 192/1000\n",
      "32/32 [==============================] - 0s 170us/step - loss: 0.0053 - val_loss: 0.0043\n",
      "Epoch 193/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0053 - val_loss: 0.0042\n",
      "Epoch 194/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0052 - val_loss: 0.0042\n",
      "Epoch 195/1000\n",
      "32/32 [==============================] - 0s 145us/step - loss: 0.0052 - val_loss: 0.0042\n",
      "Epoch 196/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 0.0052 - val_loss: 0.0042\n",
      "Epoch 197/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0051 - val_loss: 0.0041\n",
      "Epoch 198/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0051 - val_loss: 0.0041\n",
      "Epoch 199/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0050 - val_loss: 0.0041\n",
      "Epoch 200/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0050 - val_loss: 0.0040\n",
      "Epoch 201/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0050 - val_loss: 0.0040\n",
      "Epoch 202/1000\n",
      "32/32 [==============================] - 0s 121us/step - loss: 0.0049 - val_loss: 0.0040\n",
      "Epoch 203/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0049 - val_loss: 0.0039\n",
      "Epoch 204/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0048 - val_loss: 0.0039\n",
      "Epoch 205/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0048 - val_loss: 0.0039\n",
      "Epoch 206/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0048 - val_loss: 0.0039\n",
      "Epoch 207/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0047 - val_loss: 0.0038\n",
      "Epoch 208/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 0.0047 - val_loss: 0.0038\n",
      "Epoch 209/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0046 - val_loss: 0.0038\n",
      "Epoch 210/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0046 - val_loss: 0.0038\n",
      "Epoch 211/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0046 - val_loss: 0.0037\n",
      "Epoch 212/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0045 - val_loss: 0.0037\n",
      "Epoch 213/1000\n",
      "32/32 [==============================] - 0s 132us/step - loss: 0.0045 - val_loss: 0.0037\n",
      "Epoch 214/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0045 - val_loss: 0.0037\n",
      "Epoch 215/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0044 - val_loss: 0.0036\n",
      "Epoch 216/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0044 - val_loss: 0.0036\n",
      "Epoch 217/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0044 - val_loss: 0.0036\n",
      "Epoch 218/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0043 - val_loss: 0.0036\n",
      "Epoch 219/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0043 - val_loss: 0.0035\n",
      "Epoch 220/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0043 - val_loss: 0.0035\n",
      "Epoch 221/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0042 - val_loss: 0.0035\n",
      "Epoch 222/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0042 - val_loss: 0.0035\n",
      "Epoch 223/1000\n",
      "32/32 [==============================] - 0s 121us/step - loss: 0.0042 - val_loss: 0.0034\n",
      "Epoch 224/1000\n",
      "32/32 [==============================] - 0s 197us/step - loss: 0.0041 - val_loss: 0.0034\n",
      "Epoch 225/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0041 - val_loss: 0.0034\n",
      "Epoch 226/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0041 - val_loss: 0.0034\n",
      "Epoch 227/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0040 - val_loss: 0.0033\n",
      "Epoch 228/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0040 - val_loss: 0.0033\n",
      "Epoch 229/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0040 - val_loss: 0.0033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 230/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0039 - val_loss: 0.0033\n",
      "Epoch 231/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0039 - val_loss: 0.0033\n",
      "Epoch 232/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0039 - val_loss: 0.0032\n",
      "Epoch 233/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0039 - val_loss: 0.0032\n",
      "Epoch 234/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0038 - val_loss: 0.0032\n",
      "Epoch 235/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0038 - val_loss: 0.0032\n",
      "Epoch 236/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0038 - val_loss: 0.0031\n",
      "Epoch 237/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0037 - val_loss: 0.0031\n",
      "Epoch 238/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0037 - val_loss: 0.0031\n",
      "Epoch 239/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0037 - val_loss: 0.0031\n",
      "Epoch 240/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0037 - val_loss: 0.0031\n",
      "Epoch 241/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0036 - val_loss: 0.0030\n",
      "Epoch 242/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0036 - val_loss: 0.0030\n",
      "Epoch 243/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0036 - val_loss: 0.0030\n",
      "Epoch 244/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0036 - val_loss: 0.0030\n",
      "Epoch 245/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 246/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 247/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 248/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 249/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0034 - val_loss: 0.0029\n",
      "Epoch 250/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0034 - val_loss: 0.0029\n",
      "Epoch 251/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0034 - val_loss: 0.0028\n",
      "Epoch 252/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0034 - val_loss: 0.0028\n",
      "Epoch 253/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 0.0028\n",
      "Epoch 254/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 0.0028\n",
      "Epoch 255/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 0.0028\n",
      "Epoch 256/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 0.0028\n",
      "Epoch 257/1000\n",
      "32/32 [==============================] - 0s 176us/step - loss: 0.0032 - val_loss: 0.0027\n",
      "Epoch 258/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0032 - val_loss: 0.0027\n",
      "Epoch 259/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 0.0027\n",
      "Epoch 260/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0032 - val_loss: 0.0027\n",
      "Epoch 261/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0031 - val_loss: 0.0027\n",
      "Epoch 262/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 0.0031 - val_loss: 0.0027\n",
      "Epoch 263/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0031 - val_loss: 0.0026\n",
      "Epoch 264/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0031 - val_loss: 0.0026\n",
      "Epoch 265/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0031 - val_loss: 0.0026\n",
      "Epoch 266/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 0.0030 - val_loss: 0.0026\n",
      "Epoch 267/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0030 - val_loss: 0.0026\n",
      "Epoch 268/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0030 - val_loss: 0.0026\n",
      "Epoch 269/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 0.0025\n",
      "Epoch 270/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0030 - val_loss: 0.0025\n",
      "Epoch 271/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0029 - val_loss: 0.0025\n",
      "Epoch 272/1000\n",
      "32/32 [==============================] - 0s 122us/step - loss: 0.0029 - val_loss: 0.0025\n",
      "Epoch 273/1000\n",
      "32/32 [==============================] - 0s 127us/step - loss: 0.0029 - val_loss: 0.0025\n",
      "Epoch 274/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0029 - val_loss: 0.0025\n",
      "Epoch 275/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 0.0029 - val_loss: 0.0024\n",
      "Epoch 276/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0028 - val_loss: 0.0024\n",
      "Epoch 277/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 0.0024\n",
      "Epoch 278/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 0.0024\n",
      "Epoch 279/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 0.0028 - val_loss: 0.0024\n",
      "Epoch 280/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 0.0024\n",
      "Epoch 281/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 0.0024\n",
      "Epoch 282/1000\n",
      "32/32 [==============================] - 0s 137us/step - loss: 0.0027 - val_loss: 0.0023\n",
      "Epoch 283/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0027 - val_loss: 0.0023\n",
      "Epoch 284/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 0.0027 - val_loss: 0.0023\n",
      "Epoch 285/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 0.0027 - val_loss: 0.0023\n",
      "Epoch 286/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0027 - val_loss: 0.0023\n",
      "Epoch 287/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 288/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 289/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 290/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 291/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 292/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 293/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0025 - val_loss: 0.0022\n",
      "Epoch 294/1000\n",
      "32/32 [==============================] - 0s 131us/step - loss: 0.0025 - val_loss: 0.0022\n",
      "Epoch 295/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0025 - val_loss: 0.0022\n",
      "Epoch 296/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0025 - val_loss: 0.0022\n",
      "Epoch 297/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0025 - val_loss: 0.0022\n",
      "Epoch 298/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 0.0025 - val_loss: 0.0021\n",
      "Epoch 299/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0025 - val_loss: 0.0021\n",
      "Epoch 300/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 301/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 302/1000\n",
      "32/32 [==============================] - 0s 122us/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 303/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 304/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 305/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 306/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 307/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 308/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0023 - val_loss: 0.0020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 309/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 310/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 311/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 312/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 313/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 314/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 315/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 316/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 317/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 318/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 319/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 320/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 321/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 322/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 323/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 324/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 325/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 326/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 327/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 328/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 329/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 330/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 331/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 332/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 333/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 334/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 335/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 336/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 337/1000\n",
      "32/32 [==============================] - 0s 173us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 338/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 339/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 340/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 341/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 342/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 343/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 344/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 345/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 346/1000\n",
      "32/32 [==============================] - 0s 162us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 347/1000\n",
      "32/32 [==============================] - 0s 117us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 348/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 349/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 350/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 351/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 352/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 353/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 354/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 355/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 356/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 357/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 358/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 359/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 360/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 361/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 362/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 363/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 364/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 365/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 366/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 367/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 368/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 369/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 370/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 371/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 372/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 373/1000\n",
      "32/32 [==============================] - 0s 132us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 374/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 375/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 376/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 377/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 378/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 379/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 380/1000\n",
      "32/32 [==============================] - 0s 162us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 381/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 382/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 383/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 384/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 385/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 386/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 387/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 388/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 389/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 390/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 391/1000\n",
      "32/32 [==============================] - 0s 179us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 392/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 393/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 394/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 395/1000\n",
      "32/32 [==============================] - 0s 114us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 396/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 397/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 398/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 399/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 400/1000\n",
      "32/32 [==============================] - 0s 133us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 401/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 402/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 403/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 404/1000\n",
      "32/32 [==============================] - 0s 129us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 405/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 406/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 407/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 408/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 409/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 410/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 411/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 412/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 413/1000\n",
      "32/32 [==============================] - 0s 170us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 414/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 415/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 416/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 417/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 418/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 419/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 420/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 421/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 422/1000\n",
      "32/32 [==============================] - 0s 217us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 423/1000\n",
      "32/32 [==============================] - 0s 132us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 424/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 425/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 426/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 427/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 428/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 429/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 430/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 431/1000\n",
      "32/32 [==============================] - 0s 167us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 432/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 433/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 434/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 435/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 436/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 437/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 438/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 439/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 440/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 441/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 442/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 443/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 444/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 445/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 446/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 447/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 448/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 449/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 450/1000\n",
      "32/32 [==============================] - 0s 121us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 451/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 452/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 453/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 454/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 455/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 456/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 457/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 458/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 459/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 460/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 461/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 462/1000\n",
      "32/32 [==============================] - 0s 173us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 463/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 464/1000\n",
      "32/32 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 465/1000\n",
      "32/32 [==============================] - 0s 166us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 466/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0011 - val_loss: 0.0011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 467/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 468/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 469/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 470/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 471/1000\n",
      "32/32 [==============================] - 0s 160us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 472/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 473/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 474/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 475/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 476/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 477/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 478/1000\n",
      "32/32 [==============================] - 0s 172us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 479/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 480/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 481/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 482/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 483/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 484/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 485/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 486/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 487/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 488/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 489/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 490/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 491/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 492/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 493/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.9933e-04 - val_loss: 0.0010\n",
      "Epoch 494/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.9589e-04 - val_loss: 0.0010\n",
      "Epoch 495/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.9247e-04 - val_loss: 0.0010\n",
      "Epoch 496/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.8906e-04 - val_loss: 0.0010\n",
      "Epoch 497/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.8569e-04 - val_loss: 0.0010\n",
      "Epoch 498/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.8232e-04 - val_loss: 0.0010\n",
      "Epoch 499/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.7897e-04 - val_loss: 0.0010\n",
      "Epoch 500/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.7565e-04 - val_loss: 0.0010\n",
      "Epoch 501/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.7234e-04 - val_loss: 0.0010\n",
      "Epoch 502/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.6905e-04 - val_loss: 0.0010\n",
      "Epoch 503/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6579e-04 - val_loss: 0.0010\n",
      "Epoch 504/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6254e-04 - val_loss: 0.0010\n",
      "Epoch 505/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.5931e-04 - val_loss: 0.0010\n",
      "Epoch 506/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.5610e-04 - val_loss: 0.0010\n",
      "Epoch 507/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.5290e-04 - val_loss: 0.0010\n",
      "Epoch 508/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.4973e-04 - val_loss: 9.9876e-04\n",
      "Epoch 509/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.4656e-04 - val_loss: 9.9635e-04\n",
      "Epoch 510/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4343e-04 - val_loss: 9.9390e-04\n",
      "Epoch 511/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.4029e-04 - val_loss: 9.9151e-04\n",
      "Epoch 512/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 9.3720e-04 - val_loss: 9.8911e-04\n",
      "Epoch 513/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.3411e-04 - val_loss: 9.8672e-04\n",
      "Epoch 514/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.3103e-04 - val_loss: 9.8432e-04\n",
      "Epoch 515/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 9.2798e-04 - val_loss: 9.8197e-04\n",
      "Epoch 516/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.2494e-04 - val_loss: 9.7959e-04\n",
      "Epoch 517/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 9.2191e-04 - val_loss: 9.7727e-04\n",
      "Epoch 518/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 9.1890e-04 - val_loss: 9.7492e-04\n",
      "Epoch 519/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1592e-04 - val_loss: 9.7260e-04\n",
      "Epoch 520/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1295e-04 - val_loss: 9.7028e-04\n",
      "Epoch 521/1000\n",
      "32/32 [==============================] - 0s 122us/step - loss: 9.0998e-04 - val_loss: 9.6800e-04\n",
      "Epoch 522/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.0705e-04 - val_loss: 9.6569e-04\n",
      "Epoch 523/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.0412e-04 - val_loss: 9.6340e-04\n",
      "Epoch 524/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.0121e-04 - val_loss: 9.6114e-04\n",
      "Epoch 525/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.9831e-04 - val_loss: 9.5887e-04\n",
      "Epoch 526/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9544e-04 - val_loss: 9.5662e-04\n",
      "Epoch 527/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 8.9257e-04 - val_loss: 9.5440e-04\n",
      "Epoch 528/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.8973e-04 - val_loss: 9.5215e-04\n",
      "Epoch 529/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.8689e-04 - val_loss: 9.4995e-04\n",
      "Epoch 530/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.8408e-04 - val_loss: 9.4773e-04\n",
      "Epoch 531/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.8128e-04 - val_loss: 9.4552e-04\n",
      "Epoch 532/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7849e-04 - val_loss: 9.4331e-04\n",
      "Epoch 533/1000\n",
      "32/32 [==============================] - 0s 121us/step - loss: 8.7571e-04 - val_loss: 9.4114e-04\n",
      "Epoch 534/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.7295e-04 - val_loss: 9.3896e-04\n",
      "Epoch 535/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 8.7021e-04 - val_loss: 9.3678e-04\n",
      "Epoch 536/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.6747e-04 - val_loss: 9.3464e-04\n",
      "Epoch 537/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.6475e-04 - val_loss: 9.3250e-04\n",
      "Epoch 538/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 8.6205e-04 - val_loss: 9.3036e-04\n",
      "Epoch 539/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.5936e-04 - val_loss: 9.2824e-04\n",
      "Epoch 540/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.5669e-04 - val_loss: 9.2611e-04\n",
      "Epoch 541/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5403e-04 - val_loss: 9.2401e-04\n",
      "Epoch 542/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5139e-04 - val_loss: 9.2190e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 543/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.4875e-04 - val_loss: 9.1982e-04\n",
      "Epoch 544/1000\n",
      "32/32 [==============================] - 0s 129us/step - loss: 8.4613e-04 - val_loss: 9.1770e-04\n",
      "Epoch 545/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.4352e-04 - val_loss: 9.1563e-04\n",
      "Epoch 546/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.4093e-04 - val_loss: 9.1357e-04\n",
      "Epoch 547/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.3835e-04 - val_loss: 9.1151e-04\n",
      "Epoch 548/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.3578e-04 - val_loss: 9.0946e-04\n",
      "Epoch 549/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.3323e-04 - val_loss: 9.0741e-04\n",
      "Epoch 550/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.3068e-04 - val_loss: 9.0536e-04\n",
      "Epoch 551/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.2815e-04 - val_loss: 9.0337e-04\n",
      "Epoch 552/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.2564e-04 - val_loss: 9.0134e-04\n",
      "Epoch 553/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.2314e-04 - val_loss: 8.9932e-04\n",
      "Epoch 554/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.2063e-04 - val_loss: 8.9733e-04\n",
      "Epoch 555/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.1816e-04 - val_loss: 8.9536e-04\n",
      "Epoch 556/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.1570e-04 - val_loss: 8.9334e-04\n",
      "Epoch 557/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.1324e-04 - val_loss: 8.9136e-04\n",
      "Epoch 558/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.1080e-04 - val_loss: 8.8939e-04\n",
      "Epoch 559/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0837e-04 - val_loss: 8.8742e-04\n",
      "Epoch 560/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0595e-04 - val_loss: 8.8548e-04\n",
      "Epoch 561/1000\n",
      "32/32 [==============================] - 0s 185us/step - loss: 8.0355e-04 - val_loss: 8.8351e-04\n",
      "Epoch 562/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.0115e-04 - val_loss: 8.8158e-04\n",
      "Epoch 563/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.9877e-04 - val_loss: 8.7963e-04\n",
      "Epoch 564/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 7.9640e-04 - val_loss: 8.7768e-04\n",
      "Epoch 565/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.9403e-04 - val_loss: 8.7578e-04\n",
      "Epoch 566/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.9169e-04 - val_loss: 8.7387e-04\n",
      "Epoch 567/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.8935e-04 - val_loss: 8.7195e-04\n",
      "Epoch 568/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8703e-04 - val_loss: 8.7008e-04\n",
      "Epoch 569/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.8471e-04 - val_loss: 8.6818e-04\n",
      "Epoch 570/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8241e-04 - val_loss: 8.6629e-04\n",
      "Epoch 571/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.8012e-04 - val_loss: 8.6440e-04\n",
      "Epoch 572/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7782e-04 - val_loss: 8.6254e-04\n",
      "Epoch 573/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7555e-04 - val_loss: 8.6067e-04\n",
      "Epoch 574/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7330e-04 - val_loss: 8.5884e-04\n",
      "Epoch 575/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.7106e-04 - val_loss: 8.5696e-04\n",
      "Epoch 576/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.6881e-04 - val_loss: 8.5513e-04\n",
      "Epoch 577/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6658e-04 - val_loss: 8.5329e-04\n",
      "Epoch 578/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6437e-04 - val_loss: 8.5144e-04\n",
      "Epoch 579/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 7.6217e-04 - val_loss: 8.4961e-04\n",
      "Epoch 580/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.5996e-04 - val_loss: 8.4781e-04\n",
      "Epoch 581/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.5777e-04 - val_loss: 8.4598e-04\n",
      "Epoch 582/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 7.5560e-04 - val_loss: 8.4417e-04\n",
      "Epoch 583/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.5344e-04 - val_loss: 8.4237e-04\n",
      "Epoch 584/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.5128e-04 - val_loss: 8.4057e-04\n",
      "Epoch 585/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 7.4914e-04 - val_loss: 8.3879e-04\n",
      "Epoch 586/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 7.4700e-04 - val_loss: 8.3702e-04\n",
      "Epoch 587/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.4487e-04 - val_loss: 8.3523e-04\n",
      "Epoch 588/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4276e-04 - val_loss: 8.3347e-04\n",
      "Epoch 589/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.4065e-04 - val_loss: 8.3169e-04\n",
      "Epoch 590/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3855e-04 - val_loss: 8.2993e-04\n",
      "Epoch 591/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3646e-04 - val_loss: 8.2819e-04\n",
      "Epoch 592/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.3439e-04 - val_loss: 8.2643e-04\n",
      "Epoch 593/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.3232e-04 - val_loss: 8.2467e-04\n",
      "Epoch 594/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.3025e-04 - val_loss: 8.2297e-04\n",
      "Epoch 595/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2821e-04 - val_loss: 8.2122e-04\n",
      "Epoch 596/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2616e-04 - val_loss: 8.1952e-04\n",
      "Epoch 597/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 7.2414e-04 - val_loss: 8.1779e-04\n",
      "Epoch 598/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.2212e-04 - val_loss: 8.1608e-04\n",
      "Epoch 599/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.2011e-04 - val_loss: 8.1436e-04\n",
      "Epoch 600/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1810e-04 - val_loss: 8.1266e-04\n",
      "Epoch 601/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1611e-04 - val_loss: 8.1096e-04\n",
      "Epoch 602/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.1412e-04 - val_loss: 8.0927e-04\n",
      "Epoch 603/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1214e-04 - val_loss: 8.0757e-04\n",
      "Epoch 604/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.1017e-04 - val_loss: 8.0589e-04\n",
      "Epoch 605/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 7.0821e-04 - val_loss: 8.0424e-04\n",
      "Epoch 606/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0627e-04 - val_loss: 8.0255e-04\n",
      "Epoch 607/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.0433e-04 - val_loss: 8.0089e-04\n",
      "Epoch 608/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.0239e-04 - val_loss: 7.9924e-04\n",
      "Epoch 609/1000\n",
      "32/32 [==============================] - 0s 161us/step - loss: 7.0047e-04 - val_loss: 7.9757e-04\n",
      "Epoch 610/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.9855e-04 - val_loss: 7.9591e-04\n",
      "Epoch 611/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9664e-04 - val_loss: 7.9426e-04\n",
      "Epoch 612/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9474e-04 - val_loss: 7.9263e-04\n",
      "Epoch 613/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 6.9284e-04 - val_loss: 7.9100e-04\n",
      "Epoch 614/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 6.9097e-04 - val_loss: 7.8938e-04\n",
      "Epoch 615/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8910e-04 - val_loss: 7.8776e-04\n",
      "Epoch 616/1000\n",
      "32/32 [==============================] - 0s 128us/step - loss: 6.8723e-04 - val_loss: 7.8614e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 617/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.8537e-04 - val_loss: 7.8452e-04\n",
      "Epoch 618/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 6.8352e-04 - val_loss: 7.8290e-04\n",
      "Epoch 619/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.8168e-04 - val_loss: 7.8128e-04\n",
      "Epoch 620/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.7984e-04 - val_loss: 7.7970e-04\n",
      "Epoch 621/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7802e-04 - val_loss: 7.7808e-04\n",
      "Epoch 622/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7619e-04 - val_loss: 7.7650e-04\n",
      "Epoch 623/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7439e-04 - val_loss: 7.7491e-04\n",
      "Epoch 624/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.7258e-04 - val_loss: 7.7334e-04\n",
      "Epoch 625/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.7079e-04 - val_loss: 7.7175e-04\n",
      "Epoch 626/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 6.6900e-04 - val_loss: 7.7017e-04\n",
      "Epoch 627/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 6.6722e-04 - val_loss: 7.6862e-04\n",
      "Epoch 628/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.6545e-04 - val_loss: 7.6704e-04\n",
      "Epoch 629/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.6368e-04 - val_loss: 7.6549e-04\n",
      "Epoch 630/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6192e-04 - val_loss: 7.6393e-04\n",
      "Epoch 631/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6018e-04 - val_loss: 7.6237e-04\n",
      "Epoch 632/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 6.5844e-04 - val_loss: 7.6081e-04\n",
      "Epoch 633/1000\n",
      "32/32 [==============================] - 0s 119us/step - loss: 6.5670e-04 - val_loss: 7.5928e-04\n",
      "Epoch 634/1000\n",
      "32/32 [==============================] - 0s 130us/step - loss: 6.5497e-04 - val_loss: 7.5775e-04\n",
      "Epoch 635/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.5325e-04 - val_loss: 7.5623e-04\n",
      "Epoch 636/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.5153e-04 - val_loss: 7.5469e-04\n",
      "Epoch 637/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4983e-04 - val_loss: 7.5316e-04\n",
      "Epoch 638/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4813e-04 - val_loss: 7.5165e-04\n",
      "Epoch 639/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4644e-04 - val_loss: 7.5013e-04\n",
      "Epoch 640/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4475e-04 - val_loss: 7.4860e-04\n",
      "Epoch 641/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 6.4308e-04 - val_loss: 7.4709e-04\n",
      "Epoch 642/1000\n",
      "32/32 [==============================] - 0s 137us/step - loss: 6.4140e-04 - val_loss: 7.4559e-04\n",
      "Epoch 643/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3973e-04 - val_loss: 7.4409e-04\n",
      "Epoch 644/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 6.3808e-04 - val_loss: 7.4259e-04\n",
      "Epoch 645/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3643e-04 - val_loss: 7.4109e-04\n",
      "Epoch 646/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3479e-04 - val_loss: 7.3962e-04\n",
      "Epoch 647/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3315e-04 - val_loss: 7.3811e-04\n",
      "Epoch 648/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.3152e-04 - val_loss: 7.3665e-04\n",
      "Epoch 649/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2989e-04 - val_loss: 7.3518e-04\n",
      "Epoch 650/1000\n",
      "32/32 [==============================] - 0s 145us/step - loss: 6.2828e-04 - val_loss: 7.3372e-04\n",
      "Epoch 651/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2667e-04 - val_loss: 7.3225e-04\n",
      "Epoch 652/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2507e-04 - val_loss: 7.3076e-04\n",
      "Epoch 653/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2347e-04 - val_loss: 7.2930e-04\n",
      "Epoch 654/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.2187e-04 - val_loss: 7.2784e-04\n",
      "Epoch 655/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2029e-04 - val_loss: 7.2639e-04\n",
      "Epoch 656/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1871e-04 - val_loss: 7.2493e-04\n",
      "Epoch 657/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.1714e-04 - val_loss: 7.2349e-04\n",
      "Epoch 658/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.1558e-04 - val_loss: 7.2205e-04\n",
      "Epoch 659/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1402e-04 - val_loss: 7.2062e-04\n",
      "Epoch 660/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.1247e-04 - val_loss: 7.1917e-04\n",
      "Epoch 661/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.1092e-04 - val_loss: 7.1773e-04\n",
      "Epoch 662/1000\n",
      "32/32 [==============================] - 0s 158us/step - loss: 6.0938e-04 - val_loss: 7.1631e-04\n",
      "Epoch 663/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0784e-04 - val_loss: 7.1489e-04\n",
      "Epoch 664/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 6.0632e-04 - val_loss: 7.1346e-04\n",
      "Epoch 665/1000\n",
      "32/32 [==============================] - 0s 133us/step - loss: 6.0480e-04 - val_loss: 7.1205e-04\n",
      "Epoch 666/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.0328e-04 - val_loss: 7.1064e-04\n",
      "Epoch 667/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0177e-04 - val_loss: 7.0922e-04\n",
      "Epoch 668/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0027e-04 - val_loss: 7.0781e-04\n",
      "Epoch 669/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.9876e-04 - val_loss: 7.0640e-04\n",
      "Epoch 670/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9728e-04 - val_loss: 7.0499e-04\n",
      "Epoch 671/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 5.9579e-04 - val_loss: 7.0360e-04\n",
      "Epoch 672/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9431e-04 - val_loss: 7.0222e-04\n",
      "Epoch 673/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 5.9284e-04 - val_loss: 7.0083e-04\n",
      "Epoch 674/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9137e-04 - val_loss: 6.9946e-04\n",
      "Epoch 675/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 5.8991e-04 - val_loss: 6.9807e-04\n",
      "Epoch 676/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.8845e-04 - val_loss: 6.9668e-04\n",
      "Epoch 677/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.8700e-04 - val_loss: 6.9531e-04\n",
      "Epoch 678/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8555e-04 - val_loss: 6.9393e-04\n",
      "Epoch 679/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.8411e-04 - val_loss: 6.9256e-04\n",
      "Epoch 680/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 5.8267e-04 - val_loss: 6.9119e-04\n",
      "Epoch 681/1000\n",
      "32/32 [==============================] - 0s 717us/step - loss: 5.8125e-04 - val_loss: 6.8983e-04\n",
      "Epoch 682/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 5.7983e-04 - val_loss: 6.8847e-04\n",
      "Epoch 683/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 5.7841e-04 - val_loss: 6.8710e-04\n",
      "Epoch 684/1000\n",
      "32/32 [==============================] - 0s 281us/step - loss: 5.7699e-04 - val_loss: 6.8576e-04\n",
      "Epoch 685/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 5.7559e-04 - val_loss: 6.8441e-04\n",
      "Epoch 686/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.7419e-04 - val_loss: 6.8305e-04\n",
      "Epoch 687/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 5.7279e-04 - val_loss: 6.8172e-04\n",
      "Epoch 688/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.7141e-04 - val_loss: 6.8037e-04\n",
      "Epoch 689/1000\n",
      "32/32 [==============================] - 0s 312us/step - loss: 5.7002e-04 - val_loss: 6.7903e-04\n",
      "Epoch 690/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 5.6863e-04 - val_loss: 6.7770e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 691/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.6726e-04 - val_loss: 6.7638e-04\n",
      "Epoch 692/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.6589e-04 - val_loss: 6.7504e-04\n",
      "Epoch 693/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.6453e-04 - val_loss: 6.7371e-04\n",
      "Epoch 694/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.6317e-04 - val_loss: 6.7239e-04\n",
      "Epoch 695/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.6182e-04 - val_loss: 6.7106e-04\n",
      "Epoch 696/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.6046e-04 - val_loss: 6.6975e-04\n",
      "Epoch 697/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5912e-04 - val_loss: 6.6844e-04\n",
      "Epoch 698/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.5779e-04 - val_loss: 6.6712e-04\n",
      "Epoch 699/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.5645e-04 - val_loss: 6.6582e-04\n",
      "Epoch 700/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.5512e-04 - val_loss: 6.6453e-04\n",
      "Epoch 701/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.5380e-04 - val_loss: 6.6323e-04\n",
      "Epoch 702/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.5248e-04 - val_loss: 6.6191e-04\n",
      "Epoch 703/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5117e-04 - val_loss: 6.6062e-04\n",
      "Epoch 704/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.4986e-04 - val_loss: 6.5933e-04\n",
      "Epoch 705/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4856e-04 - val_loss: 6.5802e-04\n",
      "Epoch 706/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.4726e-04 - val_loss: 6.5675e-04\n",
      "Epoch 707/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.4597e-04 - val_loss: 6.5548e-04\n",
      "Epoch 708/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.4467e-04 - val_loss: 6.5418e-04\n",
      "Epoch 709/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.4339e-04 - val_loss: 6.5291e-04\n",
      "Epoch 710/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.4212e-04 - val_loss: 6.5164e-04\n",
      "Epoch 711/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4084e-04 - val_loss: 6.5035e-04\n",
      "Epoch 712/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.3957e-04 - val_loss: 6.4909e-04\n",
      "Epoch 713/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.3831e-04 - val_loss: 6.4781e-04\n",
      "Epoch 714/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.3705e-04 - val_loss: 6.4655e-04\n",
      "Epoch 715/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.3579e-04 - val_loss: 6.4528e-04\n",
      "Epoch 716/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.3454e-04 - val_loss: 6.4401e-04\n",
      "Epoch 717/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.3329e-04 - val_loss: 6.4277e-04\n",
      "Epoch 718/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.3205e-04 - val_loss: 6.4154e-04\n",
      "Epoch 719/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.3081e-04 - val_loss: 6.4027e-04\n",
      "Epoch 720/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2957e-04 - val_loss: 6.3904e-04\n",
      "Epoch 721/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2835e-04 - val_loss: 6.3780e-04\n",
      "Epoch 722/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.2712e-04 - val_loss: 6.3654e-04\n",
      "Epoch 723/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2590e-04 - val_loss: 6.3530e-04\n",
      "Epoch 724/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.2469e-04 - val_loss: 6.3406e-04\n",
      "Epoch 725/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.2348e-04 - val_loss: 6.3284e-04\n",
      "Epoch 726/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2228e-04 - val_loss: 6.3158e-04\n",
      "Epoch 727/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.2107e-04 - val_loss: 6.3036e-04\n",
      "Epoch 728/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.1988e-04 - val_loss: 6.2913e-04\n",
      "Epoch 729/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 5.1868e-04 - val_loss: 6.2789e-04\n",
      "Epoch 730/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.1750e-04 - val_loss: 6.2669e-04\n",
      "Epoch 731/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.1631e-04 - val_loss: 6.2548e-04\n",
      "Epoch 732/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 5.1513e-04 - val_loss: 6.2427e-04\n",
      "Epoch 733/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1395e-04 - val_loss: 6.2305e-04\n",
      "Epoch 734/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1278e-04 - val_loss: 6.2185e-04\n",
      "Epoch 735/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 5.1162e-04 - val_loss: 6.2063e-04\n",
      "Epoch 736/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.1045e-04 - val_loss: 6.1942e-04\n",
      "Epoch 737/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.0929e-04 - val_loss: 6.1822e-04\n",
      "Epoch 738/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.0814e-04 - val_loss: 6.1700e-04\n",
      "Epoch 739/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.0699e-04 - val_loss: 6.1580e-04\n",
      "Epoch 740/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.0584e-04 - val_loss: 6.1461e-04\n",
      "Epoch 741/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 5.0470e-04 - val_loss: 6.1342e-04\n",
      "Epoch 742/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 5.0356e-04 - val_loss: 6.1223e-04\n",
      "Epoch 743/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 5.0243e-04 - val_loss: 6.1106e-04\n",
      "Epoch 744/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.0130e-04 - val_loss: 6.0988e-04\n",
      "Epoch 745/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0017e-04 - val_loss: 6.0868e-04\n",
      "Epoch 746/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9905e-04 - val_loss: 6.0750e-04\n",
      "Epoch 747/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9793e-04 - val_loss: 6.0631e-04\n",
      "Epoch 748/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.9681e-04 - val_loss: 6.0514e-04\n",
      "Epoch 749/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9570e-04 - val_loss: 6.0394e-04\n",
      "Epoch 750/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9460e-04 - val_loss: 6.0278e-04\n",
      "Epoch 751/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 4.9350e-04 - val_loss: 6.0161e-04\n",
      "Epoch 752/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.9240e-04 - val_loss: 6.0044e-04\n",
      "Epoch 753/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.9130e-04 - val_loss: 5.9929e-04\n",
      "Epoch 754/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9021e-04 - val_loss: 5.9813e-04\n",
      "Epoch 755/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.8912e-04 - val_loss: 5.9698e-04\n",
      "Epoch 756/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 4.8805e-04 - val_loss: 5.9582e-04\n",
      "Epoch 757/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.8697e-04 - val_loss: 5.9466e-04\n",
      "Epoch 758/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.8589e-04 - val_loss: 5.9351e-04\n",
      "Epoch 759/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.8482e-04 - val_loss: 5.9236e-04\n",
      "Epoch 760/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.8375e-04 - val_loss: 5.9119e-04\n",
      "Epoch 761/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.8268e-04 - val_loss: 5.9006e-04\n",
      "Epoch 762/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8163e-04 - val_loss: 5.8890e-04\n",
      "Epoch 763/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.8057e-04 - val_loss: 5.8777e-04\n",
      "Epoch 764/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.7951e-04 - val_loss: 5.8663e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 765/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7847e-04 - val_loss: 5.8550e-04\n",
      "Epoch 766/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7742e-04 - val_loss: 5.8436e-04\n",
      "Epoch 767/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.7638e-04 - val_loss: 5.8323e-04\n",
      "Epoch 768/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7534e-04 - val_loss: 5.8209e-04\n",
      "Epoch 769/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 4.7431e-04 - val_loss: 5.8097e-04\n",
      "Epoch 770/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.7327e-04 - val_loss: 5.7985e-04\n",
      "Epoch 771/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.7224e-04 - val_loss: 5.7873e-04\n",
      "Epoch 772/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.7122e-04 - val_loss: 5.7761e-04\n",
      "Epoch 773/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.7020e-04 - val_loss: 5.7648e-04\n",
      "Epoch 774/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.6918e-04 - val_loss: 5.7537e-04\n",
      "Epoch 775/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6817e-04 - val_loss: 5.7426e-04\n",
      "Epoch 776/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.6716e-04 - val_loss: 5.7314e-04\n",
      "Epoch 777/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6615e-04 - val_loss: 5.7203e-04\n",
      "Epoch 778/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.6515e-04 - val_loss: 5.7090e-04\n",
      "Epoch 779/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6415e-04 - val_loss: 5.6981e-04\n",
      "Epoch 780/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6315e-04 - val_loss: 5.6872e-04\n",
      "Epoch 781/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6216e-04 - val_loss: 5.6760e-04\n",
      "Epoch 782/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.6116e-04 - val_loss: 5.6651e-04\n",
      "Epoch 783/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 4.6018e-04 - val_loss: 5.6542e-04\n",
      "Epoch 784/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.5919e-04 - val_loss: 5.6432e-04\n",
      "Epoch 785/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5822e-04 - val_loss: 5.6322e-04\n",
      "Epoch 786/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 4.5724e-04 - val_loss: 5.6214e-04\n",
      "Epoch 787/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.5627e-04 - val_loss: 5.6104e-04\n",
      "Epoch 788/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5530e-04 - val_loss: 5.5996e-04\n",
      "Epoch 789/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5433e-04 - val_loss: 5.5888e-04\n",
      "Epoch 790/1000\n",
      "32/32 [==============================] - 0s 128us/step - loss: 4.5337e-04 - val_loss: 5.5779e-04\n",
      "Epoch 791/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 4.5241e-04 - val_loss: 5.5672e-04\n",
      "Epoch 792/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.5145e-04 - val_loss: 5.5563e-04\n",
      "Epoch 793/1000\n",
      "32/32 [==============================] - 0s 133us/step - loss: 4.5050e-04 - val_loss: 5.5456e-04\n",
      "Epoch 794/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.4955e-04 - val_loss: 5.5349e-04\n",
      "Epoch 795/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 4.4861e-04 - val_loss: 5.5240e-04\n",
      "Epoch 796/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.4766e-04 - val_loss: 5.5133e-04\n",
      "Epoch 797/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4672e-04 - val_loss: 5.5025e-04\n",
      "Epoch 798/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.4578e-04 - val_loss: 5.4919e-04\n",
      "Epoch 799/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.4485e-04 - val_loss: 5.4813e-04\n",
      "Epoch 800/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 4.4391e-04 - val_loss: 5.4707e-04\n",
      "Epoch 801/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.4299e-04 - val_loss: 5.4601e-04\n",
      "Epoch 802/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.4206e-04 - val_loss: 5.4497e-04\n",
      "Epoch 803/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4114e-04 - val_loss: 5.4391e-04\n",
      "Epoch 804/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.4022e-04 - val_loss: 5.4285e-04\n",
      "Epoch 805/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.3930e-04 - val_loss: 5.4179e-04\n",
      "Epoch 806/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3839e-04 - val_loss: 5.4075e-04\n",
      "Epoch 807/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.3748e-04 - val_loss: 5.3970e-04\n",
      "Epoch 808/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 4.3658e-04 - val_loss: 5.3866e-04\n",
      "Epoch 809/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3567e-04 - val_loss: 5.3760e-04\n",
      "Epoch 810/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.3477e-04 - val_loss: 5.3657e-04\n",
      "Epoch 811/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 4.3388e-04 - val_loss: 5.3553e-04\n",
      "Epoch 812/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.3298e-04 - val_loss: 5.3451e-04\n",
      "Epoch 813/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 4.3209e-04 - val_loss: 5.3347e-04\n",
      "Epoch 814/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 4.3120e-04 - val_loss: 5.3244e-04\n",
      "Epoch 815/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 4.3031e-04 - val_loss: 5.3140e-04\n",
      "Epoch 816/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2943e-04 - val_loss: 5.3036e-04\n",
      "Epoch 817/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 4.2855e-04 - val_loss: 5.2934e-04\n",
      "Epoch 818/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 4.2767e-04 - val_loss: 5.2831e-04\n",
      "Epoch 819/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.2680e-04 - val_loss: 5.2729e-04\n",
      "Epoch 820/1000\n",
      "32/32 [==============================] - 0s 219us/step - loss: 4.2593e-04 - val_loss: 5.2626e-04\n",
      "Epoch 821/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2506e-04 - val_loss: 5.2524e-04\n",
      "Epoch 822/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.2419e-04 - val_loss: 5.2422e-04\n",
      "Epoch 823/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.2333e-04 - val_loss: 5.2322e-04\n",
      "Epoch 824/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.2247e-04 - val_loss: 5.2220e-04\n",
      "Epoch 825/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.2161e-04 - val_loss: 5.2119e-04\n",
      "Epoch 826/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2076e-04 - val_loss: 5.2018e-04\n",
      "Epoch 827/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.1991e-04 - val_loss: 5.1918e-04\n",
      "Epoch 828/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1906e-04 - val_loss: 5.1817e-04\n",
      "Epoch 829/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.1821e-04 - val_loss: 5.1717e-04\n",
      "Epoch 830/1000\n",
      "32/32 [==============================] - 0s 120us/step - loss: 4.1737e-04 - val_loss: 5.1616e-04\n",
      "Epoch 831/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 4.1653e-04 - val_loss: 5.1516e-04\n",
      "Epoch 832/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.1569e-04 - val_loss: 5.1417e-04\n",
      "Epoch 833/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.1485e-04 - val_loss: 5.1316e-04\n",
      "Epoch 834/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.1402e-04 - val_loss: 5.1217e-04\n",
      "Epoch 835/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.1320e-04 - val_loss: 5.1118e-04\n",
      "Epoch 836/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.1237e-04 - val_loss: 5.1019e-04\n",
      "Epoch 837/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.1154e-04 - val_loss: 5.0919e-04\n",
      "Epoch 838/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.1072e-04 - val_loss: 5.0821e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 839/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.0990e-04 - val_loss: 5.0721e-04\n",
      "Epoch 840/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0908e-04 - val_loss: 5.0624e-04\n",
      "Epoch 841/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.0827e-04 - val_loss: 5.0525e-04\n",
      "Epoch 842/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.0745e-04 - val_loss: 5.0428e-04\n",
      "Epoch 843/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 4.0665e-04 - val_loss: 5.0331e-04\n",
      "Epoch 844/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0584e-04 - val_loss: 5.0232e-04\n",
      "Epoch 845/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.0504e-04 - val_loss: 5.0137e-04\n",
      "Epoch 846/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0424e-04 - val_loss: 5.0039e-04\n",
      "Epoch 847/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.0344e-04 - val_loss: 4.9941e-04\n",
      "Epoch 848/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0265e-04 - val_loss: 4.9843e-04\n",
      "Epoch 849/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0185e-04 - val_loss: 4.9747e-04\n",
      "Epoch 850/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0106e-04 - val_loss: 4.9650e-04\n",
      "Epoch 851/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0027e-04 - val_loss: 4.9555e-04\n",
      "Epoch 852/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9949e-04 - val_loss: 4.9458e-04\n",
      "Epoch 853/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.9871e-04 - val_loss: 4.9361e-04\n",
      "Epoch 854/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 3.9793e-04 - val_loss: 4.9265e-04\n",
      "Epoch 855/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9714e-04 - val_loss: 4.9169e-04\n",
      "Epoch 856/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.9637e-04 - val_loss: 4.9074e-04\n",
      "Epoch 857/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 3.9560e-04 - val_loss: 4.8980e-04\n",
      "Epoch 858/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9483e-04 - val_loss: 4.8884e-04\n",
      "Epoch 859/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9406e-04 - val_loss: 4.8790e-04\n",
      "Epoch 860/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9329e-04 - val_loss: 4.8695e-04\n",
      "Epoch 861/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.9253e-04 - val_loss: 4.8601e-04\n",
      "Epoch 862/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.9177e-04 - val_loss: 4.8507e-04\n",
      "Epoch 863/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9102e-04 - val_loss: 4.8414e-04\n",
      "Epoch 864/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.9026e-04 - val_loss: 4.8318e-04\n",
      "Epoch 865/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8950e-04 - val_loss: 4.8224e-04\n",
      "Epoch 866/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.8875e-04 - val_loss: 4.8130e-04\n",
      "Epoch 867/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.8800e-04 - val_loss: 4.8038e-04\n",
      "Epoch 868/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.8726e-04 - val_loss: 4.7943e-04\n",
      "Epoch 869/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.8651e-04 - val_loss: 4.7850e-04\n",
      "Epoch 870/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.8577e-04 - val_loss: 4.7756e-04\n",
      "Epoch 871/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8503e-04 - val_loss: 4.7664e-04\n",
      "Epoch 872/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.8429e-04 - val_loss: 4.7571e-04\n",
      "Epoch 873/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8356e-04 - val_loss: 4.7480e-04\n",
      "Epoch 874/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 3.8282e-04 - val_loss: 4.7387e-04\n",
      "Epoch 875/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.8210e-04 - val_loss: 4.7296e-04\n",
      "Epoch 876/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.8137e-04 - val_loss: 4.7203e-04\n",
      "Epoch 877/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8064e-04 - val_loss: 4.7112e-04\n",
      "Epoch 878/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.7992e-04 - val_loss: 4.7019e-04\n",
      "Epoch 879/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.7920e-04 - val_loss: 4.6928e-04\n",
      "Epoch 880/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7848e-04 - val_loss: 4.6837e-04\n",
      "Epoch 881/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.7776e-04 - val_loss: 4.6745e-04\n",
      "Epoch 882/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7704e-04 - val_loss: 4.6655e-04\n",
      "Epoch 883/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.7633e-04 - val_loss: 4.6565e-04\n",
      "Epoch 884/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7562e-04 - val_loss: 4.6474e-04\n",
      "Epoch 885/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7491e-04 - val_loss: 4.6384e-04\n",
      "Epoch 886/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.7421e-04 - val_loss: 4.6294e-04\n",
      "Epoch 887/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 3.7350e-04 - val_loss: 4.6203e-04\n",
      "Epoch 888/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.7280e-04 - val_loss: 4.6114e-04\n",
      "Epoch 889/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.7210e-04 - val_loss: 4.6023e-04\n",
      "Epoch 890/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.7141e-04 - val_loss: 4.5934e-04\n",
      "Epoch 891/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 3.7071e-04 - val_loss: 4.5843e-04\n",
      "Epoch 892/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.7002e-04 - val_loss: 4.5755e-04\n",
      "Epoch 893/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 3.6933e-04 - val_loss: 4.5665e-04\n",
      "Epoch 894/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6864e-04 - val_loss: 4.5578e-04\n",
      "Epoch 895/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6796e-04 - val_loss: 4.5488e-04\n",
      "Epoch 896/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.6727e-04 - val_loss: 4.5401e-04\n",
      "Epoch 897/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6659e-04 - val_loss: 4.5312e-04\n",
      "Epoch 898/1000\n",
      "32/32 [==============================] - 0s 115us/step - loss: 3.6591e-04 - val_loss: 4.5223e-04\n",
      "Epoch 899/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 3.6524e-04 - val_loss: 4.5136e-04\n",
      "Epoch 900/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6455e-04 - val_loss: 4.5048e-04\n",
      "Epoch 901/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6388e-04 - val_loss: 4.4959e-04\n",
      "Epoch 902/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 3.6321e-04 - val_loss: 4.4872e-04\n",
      "Epoch 903/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6254e-04 - val_loss: 4.4784e-04\n",
      "Epoch 904/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6187e-04 - val_loss: 4.4698e-04\n",
      "Epoch 905/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6121e-04 - val_loss: 4.4609e-04\n",
      "Epoch 906/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6054e-04 - val_loss: 4.4523e-04\n",
      "Epoch 907/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5988e-04 - val_loss: 4.4437e-04\n",
      "Epoch 908/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.5922e-04 - val_loss: 4.4351e-04\n",
      "Epoch 909/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5857e-04 - val_loss: 4.4265e-04\n",
      "Epoch 910/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5791e-04 - val_loss: 4.4177e-04\n",
      "Epoch 911/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.5726e-04 - val_loss: 4.4091e-04\n",
      "Epoch 912/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5661e-04 - val_loss: 4.4006e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 913/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.5596e-04 - val_loss: 4.3918e-04\n",
      "Epoch 914/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5531e-04 - val_loss: 4.3833e-04\n",
      "Epoch 915/1000\n",
      "32/32 [==============================] - 0s 120us/step - loss: 3.5467e-04 - val_loss: 4.3747e-04\n",
      "Epoch 916/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 3.5402e-04 - val_loss: 4.3665e-04\n",
      "Epoch 917/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5338e-04 - val_loss: 4.3579e-04\n",
      "Epoch 918/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.5274e-04 - val_loss: 4.3494e-04\n",
      "Epoch 919/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 3.5210e-04 - val_loss: 4.3408e-04\n",
      "Epoch 920/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5146e-04 - val_loss: 4.3324e-04\n",
      "Epoch 921/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.5083e-04 - val_loss: 4.3239e-04\n",
      "Epoch 922/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.5020e-04 - val_loss: 4.3155e-04\n",
      "Epoch 923/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.4957e-04 - val_loss: 4.3071e-04\n",
      "Epoch 924/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.4894e-04 - val_loss: 4.2986e-04\n",
      "Epoch 925/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4831e-04 - val_loss: 4.2904e-04\n",
      "Epoch 926/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 3.4769e-04 - val_loss: 4.2818e-04\n",
      "Epoch 927/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4707e-04 - val_loss: 4.2735e-04\n",
      "Epoch 928/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4644e-04 - val_loss: 4.2651e-04\n",
      "Epoch 929/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.4583e-04 - val_loss: 4.2569e-04\n",
      "Epoch 930/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 3.4521e-04 - val_loss: 4.2485e-04\n",
      "Epoch 931/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.4460e-04 - val_loss: 4.2403e-04\n",
      "Epoch 932/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.4398e-04 - val_loss: 4.2321e-04\n",
      "Epoch 933/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4337e-04 - val_loss: 4.2238e-04\n",
      "Epoch 934/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4277e-04 - val_loss: 4.2156e-04\n",
      "Epoch 935/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.4215e-04 - val_loss: 4.2074e-04\n",
      "Epoch 936/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.4155e-04 - val_loss: 4.1991e-04\n",
      "Epoch 937/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 3.4095e-04 - val_loss: 4.1907e-04\n",
      "Epoch 938/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4034e-04 - val_loss: 4.1827e-04\n",
      "Epoch 939/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3974e-04 - val_loss: 4.1745e-04\n",
      "Epoch 940/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 3.3915e-04 - val_loss: 4.1663e-04\n",
      "Epoch 941/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3855e-04 - val_loss: 4.1582e-04\n",
      "Epoch 942/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3795e-04 - val_loss: 4.1500e-04\n",
      "Epoch 943/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.3736e-04 - val_loss: 4.1420e-04\n",
      "Epoch 944/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.3677e-04 - val_loss: 4.1340e-04\n",
      "Epoch 945/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.3618e-04 - val_loss: 4.1259e-04\n",
      "Epoch 946/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3559e-04 - val_loss: 4.1178e-04\n",
      "Epoch 947/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.3500e-04 - val_loss: 4.1097e-04\n",
      "Epoch 948/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.3442e-04 - val_loss: 4.1017e-04\n",
      "Epoch 949/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 3.3384e-04 - val_loss: 4.0937e-04\n",
      "Epoch 950/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.3326e-04 - val_loss: 4.0856e-04\n",
      "Epoch 951/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3267e-04 - val_loss: 4.0776e-04\n",
      "Epoch 952/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3210e-04 - val_loss: 4.0697e-04\n",
      "Epoch 953/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3152e-04 - val_loss: 4.0617e-04\n",
      "Epoch 954/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.3095e-04 - val_loss: 4.0538e-04\n",
      "Epoch 955/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.3038e-04 - val_loss: 4.0459e-04\n",
      "Epoch 956/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2980e-04 - val_loss: 4.0380e-04\n",
      "Epoch 957/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2924e-04 - val_loss: 4.0302e-04\n",
      "Epoch 958/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2867e-04 - val_loss: 4.0222e-04\n",
      "Epoch 959/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 3.2810e-04 - val_loss: 4.0145e-04\n",
      "Epoch 960/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.2754e-04 - val_loss: 4.0066e-04\n",
      "Epoch 961/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.2698e-04 - val_loss: 3.9988e-04\n",
      "Epoch 962/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.2641e-04 - val_loss: 3.9908e-04\n",
      "Epoch 963/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.2586e-04 - val_loss: 3.9831e-04\n",
      "Epoch 964/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.2530e-04 - val_loss: 3.9753e-04\n",
      "Epoch 965/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2474e-04 - val_loss: 3.9674e-04\n",
      "Epoch 966/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2419e-04 - val_loss: 3.9598e-04\n",
      "Epoch 967/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2364e-04 - val_loss: 3.9520e-04\n",
      "Epoch 968/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2309e-04 - val_loss: 3.9443e-04\n",
      "Epoch 969/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2254e-04 - val_loss: 3.9367e-04\n",
      "Epoch 970/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2199e-04 - val_loss: 3.9289e-04\n",
      "Epoch 971/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 3.2144e-04 - val_loss: 3.9214e-04\n",
      "Epoch 972/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2090e-04 - val_loss: 3.9136e-04\n",
      "Epoch 973/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.2036e-04 - val_loss: 3.9058e-04\n",
      "Epoch 974/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1982e-04 - val_loss: 3.8983e-04\n",
      "Epoch 975/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.1928e-04 - val_loss: 3.8906e-04\n",
      "Epoch 976/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1874e-04 - val_loss: 3.8830e-04\n",
      "Epoch 977/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.1820e-04 - val_loss: 3.8754e-04\n",
      "Epoch 978/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1767e-04 - val_loss: 3.8678e-04\n",
      "Epoch 979/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.1713e-04 - val_loss: 3.8601e-04\n",
      "Epoch 980/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1660e-04 - val_loss: 3.8527e-04\n",
      "Epoch 981/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.1607e-04 - val_loss: 3.8451e-04\n",
      "Epoch 982/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.1555e-04 - val_loss: 3.8377e-04\n",
      "Epoch 983/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1501e-04 - val_loss: 3.8301e-04\n",
      "Epoch 984/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1449e-04 - val_loss: 3.8227e-04\n",
      "Epoch 985/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1397e-04 - val_loss: 3.8152e-04\n",
      "Epoch 986/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.1345e-04 - val_loss: 3.8076e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 987/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.1292e-04 - val_loss: 3.8002e-04\n",
      "Epoch 988/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1240e-04 - val_loss: 3.7928e-04\n",
      "Epoch 989/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.1189e-04 - val_loss: 3.7853e-04\n",
      "Epoch 990/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.1137e-04 - val_loss: 3.7779e-04\n",
      "Epoch 991/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1085e-04 - val_loss: 3.7705e-04\n",
      "Epoch 992/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 3.1033e-04 - val_loss: 3.7632e-04\n",
      "Epoch 993/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 3.0982e-04 - val_loss: 3.7559e-04\n",
      "Epoch 994/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0932e-04 - val_loss: 3.7485e-04\n",
      "Epoch 995/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.0881e-04 - val_loss: 3.7411e-04\n",
      "Epoch 996/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.0830e-04 - val_loss: 3.7339e-04\n",
      "Epoch 997/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.0780e-04 - val_loss: 3.7265e-04\n",
      "Epoch 998/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0729e-04 - val_loss: 3.7193e-04\n",
      "Epoch 999/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0678e-04 - val_loss: 3.7120e-04\n",
      "Epoch 1000/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.0628e-04 - val_loss: 3.7046e-04\n",
      "0.0007226005545817316\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.12655033,  0.76124   , -0.1056475 ,  0.3738104 ,  0.73713744,\n",
       "         -0.8957579 ,  0.41234156,  0.6047862 , -0.69958353,  1.1099483 ],\n",
       "        [-0.7499556 , -0.2970074 , -0.50185335,  0.23400494, -0.42433923,\n",
       "          0.21782087, -0.8553799 , -0.67974263,  0.4196289 ,  0.12673292],\n",
       "        [-0.81490064,  0.7082258 , -1.5542495 ,  0.40232897, -0.46948665,\n",
       "         -0.13122715,  0.43894076, -1.0009674 ,  0.5873346 ,  1.5751377 ]],\n",
       "       dtype=float32),\n",
       " array([ 0.3975633 , -0.1501335 , -0.56929475,  0.57183945,  0.5495596 ,\n",
       "         0.49859458, -0.56042725,  0.42125994, -0.08397902,  0.2904021 ],\n",
       "       dtype=float32),\n",
       " array([[-0.8248251 ,  0.01927135,  0.1301535 ,  0.1875432 ,  0.3385841 ],\n",
       "        [ 0.7041947 ,  0.37417302,  0.34721392,  0.3177513 , -0.82020533],\n",
       "        [ 0.84026134, -0.7273104 ,  0.4327214 , -0.655121  , -0.8331828 ],\n",
       "        [-0.48471057, -0.5806327 , -0.41717204,  0.07953556,  0.29877815],\n",
       "        [-0.2433252 , -0.20676278, -0.26414007,  0.59842104,  0.6243302 ],\n",
       "        [ 0.19080387,  0.443045  , -0.557886  ,  0.29642972,  0.43474573],\n",
       "        [ 0.19038104,  0.02739269,  0.552731  , -0.8970661 , -0.7058305 ],\n",
       "        [-0.3176161 ,  0.14606157, -0.14355797,  0.5934507 ,  0.1208745 ],\n",
       "        [ 0.30357796,  0.4952987 , -0.23229729, -0.39027297,  0.05879638],\n",
       "        [-0.12190179, -0.65621394,  0.14233053,  0.5323847 ,  0.41059744]],\n",
       "       dtype=float32),\n",
       " array([-0.7626225 ,  0.4375089 , -0.7469979 ,  0.7584819 ,  0.72639346],\n",
       "       dtype=float32),\n",
       " array([[-0.9130248 ],\n",
       "        [ 0.07032992],\n",
       "        [-0.6378258 ],\n",
       "        [ 0.84308803],\n",
       "        [ 0.55249804]], dtype=float32),\n",
       " array([0.8217692], dtype=float32)]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_challenger, history_challenger, evaluate_challenger=NN_model_structure_regression_4(X_train_challenger, X_val_challenger, Y_train_challenger, Y_val_challenger, adam2, 32, 1000, x_test_challenger, y_test_challenger)\n",
    "model_challenger.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_challenger.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_challenger_structure4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_67 (Dense)             (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 161\n",
      "Trainable params: 161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 32 samples, validate on 7 samples\n",
      "Epoch 1/1000\n",
      "32/32 [==============================] - 0s 15ms/step - loss: 35.8785 - val_loss: 31.8713\n",
      "Epoch 2/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 32.9093 - val_loss: 26.1831\n",
      "Epoch 3/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 28.1698 - val_loss: 18.8138\n",
      "Epoch 4/1000\n",
      "32/32 [==============================] - 0s 173us/step - loss: 21.5692 - val_loss: 11.0369\n",
      "Epoch 5/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 13.8448 - val_loss: 4.7601\n",
      "Epoch 6/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3917 - val_loss: 1.7522\n",
      "Epoch 7/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5751 - val_loss: 3.3562\n",
      "Epoch 8/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8121 - val_loss: 5.2511\n",
      "Epoch 9/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.6969 - val_loss: 4.1204\n",
      "Epoch 10/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1124 - val_loss: 2.0068\n",
      "Epoch 11/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.1302 - val_loss: 0.9271\n",
      "Epoch 12/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.8674 - val_loss: 1.1628\n",
      "Epoch 13/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.3337 - val_loss: 1.9134\n",
      "Epoch 14/1000\n",
      "32/32 [==============================] - 0s 130us/step - loss: 0.8926 - val_loss: 2.3652\n",
      "Epoch 15/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 1.5763 - val_loss: 2.2787\n",
      "Epoch 16/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.9086 - val_loss: 1.8512\n",
      "Epoch 17/1000\n",
      "32/32 [==============================] - 0s 163us/step - loss: 1.8717 - val_loss: 1.3786\n",
      "Epoch 18/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5994 - val_loss: 1.0352\n",
      "Epoch 19/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.2220 - val_loss: 0.8166\n",
      "Epoch 20/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.8425 - val_loss: 0.6222\n",
      "Epoch 21/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.5172 - val_loss: 0.3918\n",
      "Epoch 22/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.2677 - val_loss: 0.1932\n",
      "Epoch 23/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.1355 - val_loss: 0.1543\n",
      "Epoch 24/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.1691 - val_loss: 0.3025\n",
      "Epoch 25/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.3390 - val_loss: 0.5051\n",
      "Epoch 26/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.5174 - val_loss: 0.6019\n",
      "Epoch 27/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.5841 - val_loss: 0.5474\n",
      "Epoch 28/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.5184 - val_loss: 0.4001\n",
      "Epoch 29/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.3746 - val_loss: 0.2400\n",
      "Epoch 30/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.2198 - val_loss: 0.1186\n",
      "Epoch 31/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1026 - val_loss: 0.0529\n",
      "Epoch 32/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0466 - val_loss: 0.0374\n",
      "Epoch 33/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0488 - val_loss: 0.0558\n",
      "Epoch 34/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0860 - val_loss: 0.0898\n",
      "Epoch 35/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.1309 - val_loss: 0.1245\n",
      "Epoch 36/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.1658 - val_loss: 0.1489\n",
      "Epoch 37/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1834 - val_loss: 0.1560\n",
      "Epoch 38/1000\n",
      "32/32 [==============================] - 0s 129us/step - loss: 0.1825 - val_loss: 0.1446\n",
      "Epoch 39/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1643 - val_loss: 0.1200\n",
      "Epoch 40/1000\n",
      "32/32 [==============================] - 0s 185us/step - loss: 0.1340 - val_loss: 0.0915\n",
      "Epoch 41/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0995 - val_loss: 0.0678\n",
      "Epoch 42/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0683 - val_loss: 0.0530\n",
      "Epoch 43/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0446 - val_loss: 0.0470\n",
      "Epoch 44/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0304 - val_loss: 0.0478\n",
      "Epoch 45/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0264 - val_loss: 0.0527\n",
      "Epoch 46/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 0.0317 - val_loss: 0.0588\n",
      "Epoch 47/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 0.0426 - val_loss: 0.0636\n",
      "Epoch 48/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0537 - val_loss: 0.0654\n",
      "Epoch 49/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 0.0609 - val_loss: 0.0636\n",
      "Epoch 50/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0624 - val_loss: 0.0583\n",
      "Epoch 51/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 0.0583 - val_loss: 0.0504\n",
      "Epoch 52/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 0.0498 - val_loss: 0.0415\n",
      "Epoch 53/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 0.0392 - val_loss: 0.0337\n",
      "Epoch 54/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0295 - val_loss: 0.0282\n",
      "Epoch 55/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0228 - val_loss: 0.0252\n",
      "Epoch 56/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0194 - val_loss: 0.0239\n",
      "Epoch 57/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0190 - val_loss: 0.0236\n",
      "Epoch 58/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0205 - val_loss: 0.0238\n",
      "Epoch 59/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0230 - val_loss: 0.0242\n",
      "Epoch 60/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0254 - val_loss: 0.0248\n",
      "Epoch 61/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 0.0268 - val_loss: 0.0253\n",
      "Epoch 62/1000\n",
      "32/32 [==============================] - 0s 130us/step - loss: 0.0269 - val_loss: 0.0254\n",
      "Epoch 63/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0258 - val_loss: 0.0247\n",
      "Epoch 64/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0238 - val_loss: 0.0230\n",
      "Epoch 65/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0213 - val_loss: 0.0208\n",
      "Epoch 66/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0186 - val_loss: 0.0186\n",
      "Epoch 67/1000\n",
      "32/32 [==============================] - 0s 129us/step - loss: 0.0163 - val_loss: 0.0172\n",
      "Epoch 68/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0148 - val_loss: 0.0170\n",
      "Epoch 69/1000\n",
      "32/32 [==============================] - 0s 192us/step - loss: 0.0141 - val_loss: 0.0179\n",
      "Epoch 70/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0141 - val_loss: 0.0192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0145 - val_loss: 0.0204\n",
      "Epoch 72/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0152 - val_loss: 0.0211\n",
      "Epoch 73/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0157 - val_loss: 0.0209\n",
      "Epoch 74/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0159 - val_loss: 0.0198\n",
      "Epoch 75/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0156 - val_loss: 0.0182\n",
      "Epoch 76/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0149 - val_loss: 0.0163\n",
      "Epoch 77/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0141 - val_loss: 0.0144\n",
      "Epoch 78/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0132 - val_loss: 0.0128\n",
      "Epoch 79/1000\n",
      "32/32 [==============================] - 0s 175us/step - loss: 0.0124 - val_loss: 0.0117\n",
      "Epoch 80/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0118 - val_loss: 0.0110\n",
      "Epoch 81/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0115 - val_loss: 0.0105\n",
      "Epoch 82/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0114 - val_loss: 0.0102\n",
      "Epoch 83/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0113 - val_loss: 0.0100\n",
      "Epoch 84/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0114 - val_loss: 0.0098\n",
      "Epoch 85/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0114 - val_loss: 0.0097\n",
      "Epoch 86/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0114 - val_loss: 0.0097\n",
      "Epoch 87/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0113 - val_loss: 0.0098\n",
      "Epoch 88/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0111 - val_loss: 0.0098\n",
      "Epoch 89/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0108 - val_loss: 0.0098\n",
      "Epoch 90/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0104 - val_loss: 0.0097\n",
      "Epoch 91/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0101 - val_loss: 0.0095\n",
      "Epoch 92/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0098 - val_loss: 0.0094\n",
      "Epoch 93/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0096 - val_loss: 0.0093\n",
      "Epoch 94/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0095 - val_loss: 0.0092\n",
      "Epoch 95/1000\n",
      "32/32 [==============================] - 0s 166us/step - loss: 0.0094 - val_loss: 0.0093\n",
      "Epoch 96/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0093 - val_loss: 0.0094\n",
      "Epoch 97/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0093 - val_loss: 0.0095\n",
      "Epoch 98/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 0.0092 - val_loss: 0.0095\n",
      "Epoch 99/1000\n",
      "32/32 [==============================] - 0s 199us/step - loss: 0.0091 - val_loss: 0.0095\n",
      "Epoch 100/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0090 - val_loss: 0.0095\n",
      "Epoch 101/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0088 - val_loss: 0.0094\n",
      "Epoch 102/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0087 - val_loss: 0.0093\n",
      "Epoch 103/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0085 - val_loss: 0.0091\n",
      "Epoch 104/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 0.0084 - val_loss: 0.0090\n",
      "Epoch 105/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0082 - val_loss: 0.0089\n",
      "Epoch 106/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0081 - val_loss: 0.0087\n",
      "Epoch 107/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0080 - val_loss: 0.0086\n",
      "Epoch 108/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0079 - val_loss: 0.0084\n",
      "Epoch 109/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0078 - val_loss: 0.0082\n",
      "Epoch 110/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0078 - val_loss: 0.0080\n",
      "Epoch 111/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0077 - val_loss: 0.0078\n",
      "Epoch 112/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0076 - val_loss: 0.0077\n",
      "Epoch 113/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0075 - val_loss: 0.0077\n",
      "Epoch 114/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0074 - val_loss: 0.0076\n",
      "Epoch 115/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0073 - val_loss: 0.0076\n",
      "Epoch 116/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0072 - val_loss: 0.0075\n",
      "Epoch 117/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0071 - val_loss: 0.0075\n",
      "Epoch 118/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0070 - val_loss: 0.0074\n",
      "Epoch 119/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0070 - val_loss: 0.0073\n",
      "Epoch 120/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0069 - val_loss: 0.0073\n",
      "Epoch 121/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0068 - val_loss: 0.0072\n",
      "Epoch 122/1000\n",
      "32/32 [==============================] - 0s 192us/step - loss: 0.0067 - val_loss: 0.0071\n",
      "Epoch 123/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0067 - val_loss: 0.0070\n",
      "Epoch 124/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0066 - val_loss: 0.0070\n",
      "Epoch 125/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0065 - val_loss: 0.0069\n",
      "Epoch 126/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0065 - val_loss: 0.0068\n",
      "Epoch 127/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0064 - val_loss: 0.0067\n",
      "Epoch 128/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0063 - val_loss: 0.0066\n",
      "Epoch 129/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0062 - val_loss: 0.0066\n",
      "Epoch 130/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0062 - val_loss: 0.0065\n",
      "Epoch 131/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0061 - val_loss: 0.0065\n",
      "Epoch 132/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0060 - val_loss: 0.0064\n",
      "Epoch 133/1000\n",
      "32/32 [==============================] - 0s 219us/step - loss: 0.0060 - val_loss: 0.0063\n",
      "Epoch 134/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0059 - val_loss: 0.0063\n",
      "Epoch 135/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0059 - val_loss: 0.0062\n",
      "Epoch 136/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0058 - val_loss: 0.0061\n",
      "Epoch 137/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0058 - val_loss: 0.0060\n",
      "Epoch 138/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0057 - val_loss: 0.0060\n",
      "Epoch 139/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0056 - val_loss: 0.0059\n",
      "Epoch 140/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0056 - val_loss: 0.0058\n",
      "Epoch 141/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0055 - val_loss: 0.0057\n",
      "Epoch 142/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0055 - val_loss: 0.0057\n",
      "Epoch 143/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0054 - val_loss: 0.0056\n",
      "Epoch 144/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0054 - val_loss: 0.0055\n",
      "Epoch 145/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0053 - val_loss: 0.0055\n",
      "Epoch 146/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0053 - val_loss: 0.0054\n",
      "Epoch 147/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0052 - val_loss: 0.0054\n",
      "Epoch 148/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0052 - val_loss: 0.0053\n",
      "Epoch 149/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0051 - val_loss: 0.0053\n",
      "Epoch 150/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0051 - val_loss: 0.0052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 0.0050 - val_loss: 0.0052\n",
      "Epoch 152/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0050 - val_loss: 0.0051\n",
      "Epoch 153/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0050 - val_loss: 0.0051\n",
      "Epoch 154/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 155/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 156/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0048 - val_loss: 0.0050\n",
      "Epoch 157/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 158/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 159/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 160/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 161/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 162/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 163/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 164/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 165/1000\n",
      "32/32 [==============================] - 0s 160us/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 166/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 167/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 168/1000\n",
      "32/32 [==============================] - 0s 130us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 169/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 170/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 171/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 172/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 173/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 174/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 175/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0041 - val_loss: 0.0042\n",
      "Epoch 176/1000\n",
      "32/32 [==============================] - 0s 189us/step - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 177/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 178/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 179/1000\n",
      "32/32 [==============================] - 0s 158us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 180/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 181/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 182/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 183/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 184/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 185/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0039 - val_loss: 0.0038\n",
      "Epoch 186/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 187/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 188/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0038 - val_loss: 0.0037\n",
      "Epoch 189/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 190/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 191/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0037 - val_loss: 0.0036\n",
      "Epoch 192/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 0.0037 - val_loss: 0.0036\n",
      "Epoch 193/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 194/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0036 - val_loss: 0.0035\n",
      "Epoch 195/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0036 - val_loss: 0.0035\n",
      "Epoch 196/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0036 - val_loss: 0.0035\n",
      "Epoch 197/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 198/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0035 - val_loss: 0.0034\n",
      "Epoch 199/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0035 - val_loss: 0.0034\n",
      "Epoch 200/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 0.0035 - val_loss: 0.0034\n",
      "Epoch 201/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0035 - val_loss: 0.0033\n",
      "Epoch 202/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 203/1000\n",
      "32/32 [==============================] - 0s 158us/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 204/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 205/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 206/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 207/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 208/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 209/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 210/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 211/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 0.0031\n",
      "Epoch 212/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0032 - val_loss: 0.0030\n",
      "Epoch 213/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 0.0030\n",
      "Epoch 214/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 0.0030\n",
      "Epoch 215/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0032 - val_loss: 0.0030\n",
      "Epoch 216/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0031 - val_loss: 0.0029\n",
      "Epoch 217/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0031 - val_loss: 0.0029\n",
      "Epoch 218/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0031 - val_loss: 0.0029\n",
      "Epoch 219/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0031 - val_loss: 0.0029\n",
      "Epoch 220/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0031 - val_loss: 0.0028\n",
      "Epoch 221/1000\n",
      "32/32 [==============================] - 0s 181us/step - loss: 0.0030 - val_loss: 0.0028\n",
      "Epoch 222/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0030 - val_loss: 0.0028\n",
      "Epoch 223/1000\n",
      "32/32 [==============================] - 0s 167us/step - loss: 0.0030 - val_loss: 0.0028\n",
      "Epoch 224/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 0.0028\n",
      "Epoch 225/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 0.0027\n",
      "Epoch 226/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 0.0027\n",
      "Epoch 227/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0029 - val_loss: 0.0027\n",
      "Epoch 228/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 0.0027\n",
      "Epoch 229/1000\n",
      "32/32 [==============================] - 0s 158us/step - loss: 0.0029 - val_loss: 0.0026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 230/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 0.0026\n",
      "Epoch 231/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 0.0026\n",
      "Epoch 232/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0029 - val_loss: 0.0026\n",
      "Epoch 233/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0028 - val_loss: 0.0026\n",
      "Epoch 234/1000\n",
      "32/32 [==============================] - 0s 137us/step - loss: 0.0028 - val_loss: 0.0025\n",
      "Epoch 235/1000\n",
      "32/32 [==============================] - 0s 130us/step - loss: 0.0028 - val_loss: 0.0025\n",
      "Epoch 236/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0028 - val_loss: 0.0025\n",
      "Epoch 237/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 0.0028 - val_loss: 0.0025\n",
      "Epoch 238/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 0.0024\n",
      "Epoch 239/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 0.0024\n",
      "Epoch 240/1000\n",
      "32/32 [==============================] - 0s 169us/step - loss: 0.0027 - val_loss: 0.0024\n",
      "Epoch 241/1000\n",
      "32/32 [==============================] - 0s 171us/step - loss: 0.0027 - val_loss: 0.0024\n",
      "Epoch 242/1000\n",
      "32/32 [==============================] - 0s 171us/step - loss: 0.0027 - val_loss: 0.0024\n",
      "Epoch 243/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 0.0023\n",
      "Epoch 244/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 0.0023\n",
      "Epoch 245/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0027 - val_loss: 0.0023\n",
      "Epoch 246/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 247/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 248/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 249/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 250/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 251/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 252/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 253/1000\n",
      "32/32 [==============================] - 0s 130us/step - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 254/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0025 - val_loss: 0.0021\n",
      "Epoch 255/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0025 - val_loss: 0.0021\n",
      "Epoch 256/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 0.0025 - val_loss: 0.0021\n",
      "Epoch 257/1000\n",
      "32/32 [==============================] - 0s 176us/step - loss: 0.0025 - val_loss: 0.0021\n",
      "Epoch 258/1000\n",
      "32/32 [==============================] - 0s 162us/step - loss: 0.0025 - val_loss: 0.0021\n",
      "Epoch 259/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 0.0021\n",
      "Epoch 260/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 0.0020\n",
      "Epoch 261/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0024 - val_loss: 0.0020\n",
      "Epoch 262/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.0020\n",
      "Epoch 263/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0024 - val_loss: 0.0020\n",
      "Epoch 264/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.0020\n",
      "Epoch 265/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.0019\n",
      "Epoch 266/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0024 - val_loss: 0.0019\n",
      "Epoch 267/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.0019\n",
      "Epoch 268/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 0.0024 - val_loss: 0.0019\n",
      "Epoch 269/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 270/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 271/1000\n",
      "32/32 [==============================] - 0s 133us/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 272/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 273/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 274/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 275/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 276/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 277/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 278/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 279/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 280/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 281/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 282/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 283/1000\n",
      "32/32 [==============================] - 0s 161us/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 284/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 285/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 286/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 287/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 288/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 289/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 290/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 291/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 292/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 293/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 294/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 295/1000\n",
      "32/32 [==============================] - 0s 184us/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 296/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 297/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 298/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 299/1000\n",
      "32/32 [==============================] - 0s 174us/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 300/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 301/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 302/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 303/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 304/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 305/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 306/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 307/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 308/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 0.0019 - val_loss: 0.0013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 309/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 310/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 311/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 312/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 313/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 314/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 315/1000\n",
      "32/32 [==============================] - 0s 184us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 316/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 317/1000\n",
      "32/32 [==============================] - 0s 170us/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 318/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 319/1000\n",
      "32/32 [==============================] - 0s 131us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 320/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 321/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 322/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 323/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 324/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 325/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 326/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 327/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 328/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 329/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 330/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 331/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 332/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 333/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 334/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 335/1000\n",
      "32/32 [==============================] - 0s 132us/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 336/1000\n",
      "32/32 [==============================] - 0s 177us/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 337/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 338/1000\n",
      "32/32 [==============================] - 0s 185us/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 339/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 340/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0017 - val_loss: 9.9486e-04\n",
      "Epoch 341/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 9.8542e-04\n",
      "Epoch 342/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 9.7605e-04\n",
      "Epoch 343/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0017 - val_loss: 9.6678e-04\n",
      "Epoch 344/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 9.5754e-04\n",
      "Epoch 345/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 9.4842e-04\n",
      "Epoch 346/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0016 - val_loss: 9.3933e-04\n",
      "Epoch 347/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0016 - val_loss: 9.3035e-04\n",
      "Epoch 348/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0016 - val_loss: 9.2140e-04\n",
      "Epoch 349/1000\n",
      "32/32 [==============================] - 0s 128us/step - loss: 0.0016 - val_loss: 9.1254e-04\n",
      "Epoch 350/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 0.0016 - val_loss: 9.0376e-04\n",
      "Epoch 351/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0016 - val_loss: 8.9503e-04\n",
      "Epoch 352/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0016 - val_loss: 8.8638e-04\n",
      "Epoch 353/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0016 - val_loss: 8.7778e-04\n",
      "Epoch 354/1000\n",
      "32/32 [==============================] - 0s 161us/step - loss: 0.0016 - val_loss: 8.6925e-04\n",
      "Epoch 355/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0016 - val_loss: 8.6081e-04\n",
      "Epoch 356/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 8.5242e-04\n",
      "Epoch 357/1000\n",
      "32/32 [==============================] - 0s 158us/step - loss: 0.0016 - val_loss: 8.4408e-04\n",
      "Epoch 358/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0016 - val_loss: 8.3582e-04\n",
      "Epoch 359/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 8.2763e-04\n",
      "Epoch 360/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 8.1951e-04\n",
      "Epoch 361/1000\n",
      "32/32 [==============================] - 0s 189us/step - loss: 0.0015 - val_loss: 8.1145e-04\n",
      "Epoch 362/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 8.0344e-04\n",
      "Epoch 363/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 7.9551e-04\n",
      "Epoch 364/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 0.0015 - val_loss: 7.8766e-04\n",
      "Epoch 365/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 7.7985e-04\n",
      "Epoch 366/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 7.7209e-04\n",
      "Epoch 367/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 7.6443e-04\n",
      "Epoch 368/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 7.5681e-04\n",
      "Epoch 369/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 0.0015 - val_loss: 7.4925e-04\n",
      "Epoch 370/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0015 - val_loss: 7.4174e-04\n",
      "Epoch 371/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0015 - val_loss: 7.3432e-04\n",
      "Epoch 372/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0015 - val_loss: 7.2695e-04\n",
      "Epoch 373/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 7.1965e-04\n",
      "Epoch 374/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0015 - val_loss: 7.1238e-04\n",
      "Epoch 375/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 7.0521e-04\n",
      "Epoch 376/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 6.9806e-04\n",
      "Epoch 377/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0014 - val_loss: 6.9099e-04\n",
      "Epoch 378/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 6.8397e-04\n",
      "Epoch 379/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 0.0014 - val_loss: 6.7702e-04\n",
      "Epoch 380/1000\n",
      "32/32 [==============================] - 0s 175us/step - loss: 0.0014 - val_loss: 6.7010e-04\n",
      "Epoch 381/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 6.6326e-04\n",
      "Epoch 382/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 0.0014 - val_loss: 6.5646e-04\n",
      "Epoch 383/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0014 - val_loss: 6.4974e-04\n",
      "Epoch 384/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 6.4305e-04\n",
      "Epoch 385/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0014 - val_loss: 6.3644e-04\n",
      "Epoch 386/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 6.2987e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 387/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0014 - val_loss: 6.2336e-04\n",
      "Epoch 388/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0014 - val_loss: 6.1692e-04\n",
      "Epoch 389/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 6.1051e-04\n",
      "Epoch 390/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0014 - val_loss: 6.0415e-04\n",
      "Epoch 391/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0014 - val_loss: 5.9788e-04\n",
      "Epoch 392/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 0.0013 - val_loss: 5.9164e-04\n",
      "Epoch 393/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 5.8545e-04\n",
      "Epoch 394/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 5.7932e-04\n",
      "Epoch 395/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 5.7324e-04\n",
      "Epoch 396/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 5.6721e-04\n",
      "Epoch 397/1000\n",
      "32/32 [==============================] - 0s 170us/step - loss: 0.0013 - val_loss: 5.6124e-04\n",
      "Epoch 398/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 0.0013 - val_loss: 5.5532e-04\n",
      "Epoch 399/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 0.0013 - val_loss: 5.4944e-04\n",
      "Epoch 400/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 5.4361e-04\n",
      "Epoch 401/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0013 - val_loss: 5.3786e-04\n",
      "Epoch 402/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0013 - val_loss: 5.3212e-04\n",
      "Epoch 403/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 5.2646e-04\n",
      "Epoch 404/1000\n",
      "32/32 [==============================] - 0s 198us/step - loss: 0.0013 - val_loss: 5.2084e-04\n",
      "Epoch 405/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0013 - val_loss: 5.1528e-04\n",
      "Epoch 406/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 5.0975e-04\n",
      "Epoch 407/1000\n",
      "32/32 [==============================] - 0s 158us/step - loss: 0.0013 - val_loss: 5.0427e-04\n",
      "Epoch 408/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 4.9884e-04\n",
      "Epoch 409/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0013 - val_loss: 4.9348e-04\n",
      "Epoch 410/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0013 - val_loss: 4.8815e-04\n",
      "Epoch 411/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 4.8286e-04\n",
      "Epoch 412/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 4.7761e-04\n",
      "Epoch 413/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 4.7244e-04\n",
      "Epoch 414/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 4.6728e-04\n",
      "Epoch 415/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 4.6218e-04\n",
      "Epoch 416/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 4.5713e-04\n",
      "Epoch 417/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 4.5213e-04\n",
      "Epoch 418/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 4.4717e-04\n",
      "Epoch 419/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 4.4226e-04\n",
      "Epoch 420/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 4.3737e-04\n",
      "Epoch 421/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0012 - val_loss: 4.3256e-04\n",
      "Epoch 422/1000\n",
      "32/32 [==============================] - 0s 158us/step - loss: 0.0012 - val_loss: 4.2777e-04\n",
      "Epoch 423/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0012 - val_loss: 4.2304e-04\n",
      "Epoch 424/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 4.1834e-04\n",
      "Epoch 425/1000\n",
      "32/32 [==============================] - 0s 132us/step - loss: 0.0012 - val_loss: 4.1370e-04\n",
      "Epoch 426/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 4.0908e-04\n",
      "Epoch 427/1000\n",
      "32/32 [==============================] - 0s 194us/step - loss: 0.0012 - val_loss: 4.0453e-04\n",
      "Epoch 428/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0012 - val_loss: 3.9999e-04\n",
      "Epoch 429/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 0.0012 - val_loss: 3.9552e-04\n",
      "Epoch 430/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 3.9107e-04\n",
      "Epoch 431/1000\n",
      "32/32 [==============================] - 0s 165us/step - loss: 0.0012 - val_loss: 3.8668e-04\n",
      "Epoch 432/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0011 - val_loss: 3.8232e-04\n",
      "Epoch 433/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 3.7802e-04\n",
      "Epoch 434/1000\n",
      "32/32 [==============================] - 0s 182us/step - loss: 0.0011 - val_loss: 3.7373e-04\n",
      "Epoch 435/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 3.6949e-04\n",
      "Epoch 436/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 0.0011 - val_loss: 3.6530e-04\n",
      "Epoch 437/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0011 - val_loss: 3.6115e-04\n",
      "Epoch 438/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 3.5704e-04\n",
      "Epoch 439/1000\n",
      "32/32 [==============================] - 0s 162us/step - loss: 0.0011 - val_loss: 3.5296e-04\n",
      "Epoch 440/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 0.0011 - val_loss: 3.4892e-04\n",
      "Epoch 441/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0011 - val_loss: 3.4491e-04\n",
      "Epoch 442/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0011 - val_loss: 3.4096e-04\n",
      "Epoch 443/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 3.3704e-04\n",
      "Epoch 444/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 3.3315e-04\n",
      "Epoch 445/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 3.2930e-04\n",
      "Epoch 446/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 3.2549e-04\n",
      "Epoch 447/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 3.2171e-04\n",
      "Epoch 448/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 3.1796e-04\n",
      "Epoch 449/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 3.1427e-04\n",
      "Epoch 450/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 3.1061e-04\n",
      "Epoch 451/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 3.0697e-04\n",
      "Epoch 452/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 3.0338e-04\n",
      "Epoch 453/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 2.9985e-04\n",
      "Epoch 454/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0011 - val_loss: 2.9632e-04\n",
      "Epoch 455/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 2.9282e-04\n",
      "Epoch 456/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 2.8937e-04\n",
      "Epoch 457/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 2.8596e-04\n",
      "Epoch 458/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0010 - val_loss: 2.8256e-04\n",
      "Epoch 459/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 0.0010 - val_loss: 2.7922e-04\n",
      "Epoch 460/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0010 - val_loss: 2.7590e-04\n",
      "Epoch 461/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 2.7261e-04\n",
      "Epoch 462/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0010 - val_loss: 2.6936e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 463/1000\n",
      "32/32 [==============================] - 0s 200us/step - loss: 0.0010 - val_loss: 2.6614e-04\n",
      "Epoch 464/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 2.6298e-04\n",
      "Epoch 465/1000\n",
      "32/32 [==============================] - 0s 163us/step - loss: 0.0010 - val_loss: 2.5981e-04\n",
      "Epoch 466/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0010 - val_loss: 2.5670e-04\n",
      "Epoch 467/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0010 - val_loss: 2.5362e-04\n",
      "Epoch 468/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0010 - val_loss: 2.5056e-04\n",
      "Epoch 469/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 2.4754e-04\n",
      "Epoch 470/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.9774e-04 - val_loss: 2.4454e-04\n",
      "Epoch 471/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.9413e-04 - val_loss: 2.4157e-04\n",
      "Epoch 472/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.9055e-04 - val_loss: 2.3864e-04\n",
      "Epoch 473/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.8698e-04 - val_loss: 2.3573e-04\n",
      "Epoch 474/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.8343e-04 - val_loss: 2.3287e-04\n",
      "Epoch 475/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.7991e-04 - val_loss: 2.3001e-04\n",
      "Epoch 476/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 9.7640e-04 - val_loss: 2.2720e-04\n",
      "Epoch 477/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.7290e-04 - val_loss: 2.2442e-04\n",
      "Epoch 478/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.6943e-04 - val_loss: 2.2166e-04\n",
      "Epoch 479/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6597e-04 - val_loss: 2.1894e-04\n",
      "Epoch 480/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.6253e-04 - val_loss: 2.1623e-04\n",
      "Epoch 481/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 9.5910e-04 - val_loss: 2.1357e-04\n",
      "Epoch 482/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 9.5570e-04 - val_loss: 2.1094e-04\n",
      "Epoch 483/1000\n",
      "32/32 [==============================] - 0s 182us/step - loss: 9.5232e-04 - val_loss: 2.0833e-04\n",
      "Epoch 484/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4895e-04 - val_loss: 2.0574e-04\n",
      "Epoch 485/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.4561e-04 - val_loss: 2.0320e-04\n",
      "Epoch 486/1000\n",
      "32/32 [==============================] - 0s 194us/step - loss: 9.4226e-04 - val_loss: 2.0067e-04\n",
      "Epoch 487/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3895e-04 - val_loss: 1.9816e-04\n",
      "Epoch 488/1000\n",
      "32/32 [==============================] - 0s 196us/step - loss: 9.3566e-04 - val_loss: 1.9569e-04\n",
      "Epoch 489/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.3237e-04 - val_loss: 1.9324e-04\n",
      "Epoch 490/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.2912e-04 - val_loss: 1.9082e-04\n",
      "Epoch 491/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.2586e-04 - val_loss: 1.8842e-04\n",
      "Epoch 492/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 9.2262e-04 - val_loss: 1.8605e-04\n",
      "Epoch 493/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.1942e-04 - val_loss: 1.8371e-04\n",
      "Epoch 494/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 9.1622e-04 - val_loss: 1.8139e-04\n",
      "Epoch 495/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1304e-04 - val_loss: 1.7910e-04\n",
      "Epoch 496/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.0988e-04 - val_loss: 1.7683e-04\n",
      "Epoch 497/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.0672e-04 - val_loss: 1.7459e-04\n",
      "Epoch 498/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 9.0359e-04 - val_loss: 1.7237e-04\n",
      "Epoch 499/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 9.0048e-04 - val_loss: 1.7018e-04\n",
      "Epoch 500/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.9737e-04 - val_loss: 1.6801e-04\n",
      "Epoch 501/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.9429e-04 - val_loss: 1.6587e-04\n",
      "Epoch 502/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9122e-04 - val_loss: 1.6375e-04\n",
      "Epoch 503/1000\n",
      "32/32 [==============================] - 0s 131us/step - loss: 8.8816e-04 - val_loss: 1.6165e-04\n",
      "Epoch 504/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.8513e-04 - val_loss: 1.5957e-04\n",
      "Epoch 505/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.8210e-04 - val_loss: 1.5753e-04\n",
      "Epoch 506/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 8.7909e-04 - val_loss: 1.5550e-04\n",
      "Epoch 507/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 8.7610e-04 - val_loss: 1.5349e-04\n",
      "Epoch 508/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 8.7313e-04 - val_loss: 1.5151e-04\n",
      "Epoch 509/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.7016e-04 - val_loss: 1.4955e-04\n",
      "Epoch 510/1000\n",
      "32/32 [==============================] - 0s 183us/step - loss: 8.6721e-04 - val_loss: 1.4761e-04\n",
      "Epoch 511/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.6428e-04 - val_loss: 1.4570e-04\n",
      "Epoch 512/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.6136e-04 - val_loss: 1.4381e-04\n",
      "Epoch 513/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 8.5845e-04 - val_loss: 1.4194e-04\n",
      "Epoch 514/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5558e-04 - val_loss: 1.4009e-04\n",
      "Epoch 515/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5270e-04 - val_loss: 1.3826e-04\n",
      "Epoch 516/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.4983e-04 - val_loss: 1.3645e-04\n",
      "Epoch 517/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.4699e-04 - val_loss: 1.3467e-04\n",
      "Epoch 518/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 8.4416e-04 - val_loss: 1.3291e-04\n",
      "Epoch 519/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.4133e-04 - val_loss: 1.3115e-04\n",
      "Epoch 520/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.3853e-04 - val_loss: 1.2943e-04\n",
      "Epoch 521/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3575e-04 - val_loss: 1.2772e-04\n",
      "Epoch 522/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.3298e-04 - val_loss: 1.2604e-04\n",
      "Epoch 523/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.3021e-04 - val_loss: 1.2438e-04\n",
      "Epoch 524/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 8.2746e-04 - val_loss: 1.2273e-04\n",
      "Epoch 525/1000\n",
      "32/32 [==============================] - 0s 185us/step - loss: 8.2473e-04 - val_loss: 1.2111e-04\n",
      "Epoch 526/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.2201e-04 - val_loss: 1.1950e-04\n",
      "Epoch 527/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.1930e-04 - val_loss: 1.1792e-04\n",
      "Epoch 528/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.1660e-04 - val_loss: 1.1635e-04\n",
      "Epoch 529/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 8.1392e-04 - val_loss: 1.1480e-04\n",
      "Epoch 530/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.1124e-04 - val_loss: 1.1327e-04\n",
      "Epoch 531/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0859e-04 - val_loss: 1.1175e-04\n",
      "Epoch 532/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.0594e-04 - val_loss: 1.1026e-04\n",
      "Epoch 533/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0332e-04 - val_loss: 1.0878e-04\n",
      "Epoch 534/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0070e-04 - val_loss: 1.0732e-04\n",
      "Epoch 535/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.9809e-04 - val_loss: 1.0587e-04\n",
      "Epoch 536/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.9551e-04 - val_loss: 1.0446e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 537/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9291e-04 - val_loss: 1.0305e-04\n",
      "Epoch 538/1000\n",
      "32/32 [==============================] - 0s 168us/step - loss: 7.9036e-04 - val_loss: 1.0166e-04\n",
      "Epoch 539/1000\n",
      "32/32 [==============================] - 0s 130us/step - loss: 7.8780e-04 - val_loss: 1.0029e-04\n",
      "Epoch 540/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.8526e-04 - val_loss: 9.8933e-05\n",
      "Epoch 541/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8273e-04 - val_loss: 9.7600e-05\n",
      "Epoch 542/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8022e-04 - val_loss: 9.6278e-05\n",
      "Epoch 543/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 7.7771e-04 - val_loss: 9.4967e-05\n",
      "Epoch 544/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7522e-04 - val_loss: 9.3685e-05\n",
      "Epoch 545/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 7.7273e-04 - val_loss: 9.2404e-05\n",
      "Epoch 546/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7026e-04 - val_loss: 9.1152e-05\n",
      "Epoch 547/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6781e-04 - val_loss: 8.9907e-05\n",
      "Epoch 548/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6535e-04 - val_loss: 8.8680e-05\n",
      "Epoch 549/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.6291e-04 - val_loss: 8.7475e-05\n",
      "Epoch 550/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6049e-04 - val_loss: 8.6278e-05\n",
      "Epoch 551/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5808e-04 - val_loss: 8.5095e-05\n",
      "Epoch 552/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5568e-04 - val_loss: 8.3931e-05\n",
      "Epoch 553/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5329e-04 - val_loss: 8.2778e-05\n",
      "Epoch 554/1000\n",
      "32/32 [==============================] - 0s 162us/step - loss: 7.5092e-04 - val_loss: 8.1643e-05\n",
      "Epoch 555/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.4855e-04 - val_loss: 8.0521e-05\n",
      "Epoch 556/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4618e-04 - val_loss: 7.9417e-05\n",
      "Epoch 557/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4385e-04 - val_loss: 7.8315e-05\n",
      "Epoch 558/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4151e-04 - val_loss: 7.7239e-05\n",
      "Epoch 559/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3918e-04 - val_loss: 7.6170e-05\n",
      "Epoch 560/1000\n",
      "32/32 [==============================] - 0s 163us/step - loss: 7.3687e-04 - val_loss: 7.5124e-05\n",
      "Epoch 561/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 7.3456e-04 - val_loss: 7.4086e-05\n",
      "Epoch 562/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3228e-04 - val_loss: 7.3065e-05\n",
      "Epoch 563/1000\n",
      "32/32 [==============================] - 0s 138us/step - loss: 7.3000e-04 - val_loss: 7.2053e-05\n",
      "Epoch 564/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 7.2773e-04 - val_loss: 7.1055e-05\n",
      "Epoch 565/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2546e-04 - val_loss: 7.0071e-05\n",
      "Epoch 566/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2322e-04 - val_loss: 6.9102e-05\n",
      "Epoch 567/1000\n",
      "32/32 [==============================] - 0s 166us/step - loss: 7.2097e-04 - val_loss: 6.8146e-05\n",
      "Epoch 568/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1874e-04 - val_loss: 6.7197e-05\n",
      "Epoch 569/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.1653e-04 - val_loss: 6.6261e-05\n",
      "Epoch 570/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1432e-04 - val_loss: 6.5337e-05\n",
      "Epoch 571/1000\n",
      "32/32 [==============================] - 0s 128us/step - loss: 7.1212e-04 - val_loss: 6.4431e-05\n",
      "Epoch 572/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 7.0993e-04 - val_loss: 6.3532e-05\n",
      "Epoch 573/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 7.0775e-04 - val_loss: 6.2650e-05\n",
      "Epoch 574/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 7.0558e-04 - val_loss: 6.1775e-05\n",
      "Epoch 575/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.0342e-04 - val_loss: 6.0914e-05\n",
      "Epoch 576/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0128e-04 - val_loss: 6.0062e-05\n",
      "Epoch 577/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.9913e-04 - val_loss: 5.9225e-05\n",
      "Epoch 578/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.9700e-04 - val_loss: 5.8398e-05\n",
      "Epoch 579/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.9488e-04 - val_loss: 5.7580e-05\n",
      "Epoch 580/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9277e-04 - val_loss: 5.6778e-05\n",
      "Epoch 581/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.9067e-04 - val_loss: 5.5981e-05\n",
      "Epoch 582/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8858e-04 - val_loss: 5.5201e-05\n",
      "Epoch 583/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8649e-04 - val_loss: 5.4430e-05\n",
      "Epoch 584/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.8441e-04 - val_loss: 5.3665e-05\n",
      "Epoch 585/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 6.8235e-04 - val_loss: 5.2917e-05\n",
      "Epoch 586/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 6.8030e-04 - val_loss: 5.2171e-05\n",
      "Epoch 587/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.7825e-04 - val_loss: 5.1447e-05\n",
      "Epoch 588/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7621e-04 - val_loss: 5.0726e-05\n",
      "Epoch 589/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 6.7418e-04 - val_loss: 5.0017e-05\n",
      "Epoch 590/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7216e-04 - val_loss: 4.9315e-05\n",
      "Epoch 591/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.7015e-04 - val_loss: 4.8624e-05\n",
      "Epoch 592/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.6815e-04 - val_loss: 4.7943e-05\n",
      "Epoch 593/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.6616e-04 - val_loss: 4.7273e-05\n",
      "Epoch 594/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6417e-04 - val_loss: 4.6615e-05\n",
      "Epoch 595/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6219e-04 - val_loss: 4.5959e-05\n",
      "Epoch 596/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.6022e-04 - val_loss: 4.5317e-05\n",
      "Epoch 597/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5826e-04 - val_loss: 4.4682e-05\n",
      "Epoch 598/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.5631e-04 - val_loss: 4.4056e-05\n",
      "Epoch 599/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 6.5437e-04 - val_loss: 4.3440e-05\n",
      "Epoch 600/1000\n",
      "32/32 [==============================] - 0s 130us/step - loss: 6.5243e-04 - val_loss: 4.2836e-05\n",
      "Epoch 601/1000\n",
      "32/32 [==============================] - 0s 171us/step - loss: 6.5051e-04 - val_loss: 4.2235e-05\n",
      "Epoch 602/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4859e-04 - val_loss: 4.1648e-05\n",
      "Epoch 603/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4668e-04 - val_loss: 4.1067e-05\n",
      "Epoch 604/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4477e-04 - val_loss: 4.0493e-05\n",
      "Epoch 605/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 6.4288e-04 - val_loss: 3.9928e-05\n",
      "Epoch 606/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 6.4100e-04 - val_loss: 3.9375e-05\n",
      "Epoch 607/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3912e-04 - val_loss: 3.8826e-05\n",
      "Epoch 608/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3725e-04 - val_loss: 3.8283e-05\n",
      "Epoch 609/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3538e-04 - val_loss: 3.7752e-05\n",
      "Epoch 610/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.3353e-04 - val_loss: 3.7227e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 611/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 6.3168e-04 - val_loss: 3.6716e-05\n",
      "Epoch 612/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2985e-04 - val_loss: 3.6208e-05\n",
      "Epoch 613/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.2801e-04 - val_loss: 3.5704e-05\n",
      "Epoch 614/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.2619e-04 - val_loss: 3.5211e-05\n",
      "Epoch 615/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.2437e-04 - val_loss: 3.4724e-05\n",
      "Epoch 616/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.2257e-04 - val_loss: 3.4245e-05\n",
      "Epoch 617/1000\n",
      "32/32 [==============================] - 0s 176us/step - loss: 6.2076e-04 - val_loss: 3.3771e-05\n",
      "Epoch 618/1000\n",
      "32/32 [==============================] - 0s 161us/step - loss: 6.1897e-04 - val_loss: 3.3307e-05\n",
      "Epoch 619/1000\n",
      "32/32 [==============================] - 0s 145us/step - loss: 6.1719e-04 - val_loss: 3.2848e-05\n",
      "Epoch 620/1000\n",
      "32/32 [==============================] - 0s 138us/step - loss: 6.1540e-04 - val_loss: 3.2401e-05\n",
      "Epoch 621/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 6.1363e-04 - val_loss: 3.1957e-05\n",
      "Epoch 622/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.1187e-04 - val_loss: 3.1520e-05\n",
      "Epoch 623/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1011e-04 - val_loss: 3.1094e-05\n",
      "Epoch 624/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.0836e-04 - val_loss: 3.0666e-05\n",
      "Epoch 625/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0662e-04 - val_loss: 3.0248e-05\n",
      "Epoch 626/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0488e-04 - val_loss: 2.9839e-05\n",
      "Epoch 627/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0315e-04 - val_loss: 2.9435e-05\n",
      "Epoch 628/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.0143e-04 - val_loss: 2.9036e-05\n",
      "Epoch 629/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9971e-04 - val_loss: 2.8648e-05\n",
      "Epoch 630/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 5.9800e-04 - val_loss: 2.8260e-05\n",
      "Epoch 631/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 5.9629e-04 - val_loss: 2.7879e-05\n",
      "Epoch 632/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9461e-04 - val_loss: 2.7509e-05\n",
      "Epoch 633/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.9292e-04 - val_loss: 2.7140e-05\n",
      "Epoch 634/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.9123e-04 - val_loss: 2.6779e-05\n",
      "Epoch 635/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.8955e-04 - val_loss: 2.6422e-05\n",
      "Epoch 636/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.8789e-04 - val_loss: 2.6071e-05\n",
      "Epoch 637/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.8623e-04 - val_loss: 2.5726e-05\n",
      "Epoch 638/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8458e-04 - val_loss: 2.5389e-05\n",
      "Epoch 639/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8293e-04 - val_loss: 2.5055e-05\n",
      "Epoch 640/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.8128e-04 - val_loss: 2.4728e-05\n",
      "Epoch 641/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.7965e-04 - val_loss: 2.4405e-05\n",
      "Epoch 642/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7802e-04 - val_loss: 2.4085e-05\n",
      "Epoch 643/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.7640e-04 - val_loss: 2.3771e-05\n",
      "Epoch 644/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7477e-04 - val_loss: 2.3465e-05\n",
      "Epoch 645/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 5.7317e-04 - val_loss: 2.3166e-05\n",
      "Epoch 646/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.7156e-04 - val_loss: 2.2866e-05\n",
      "Epoch 647/1000\n",
      "32/32 [==============================] - 0s 173us/step - loss: 5.6996e-04 - val_loss: 2.2571e-05\n",
      "Epoch 648/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.6837e-04 - val_loss: 2.2286e-05\n",
      "Epoch 649/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 5.6678e-04 - val_loss: 2.2005e-05\n",
      "Epoch 650/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6521e-04 - val_loss: 2.1726e-05\n",
      "Epoch 651/1000\n",
      "32/32 [==============================] - 0s 180us/step - loss: 5.6363e-04 - val_loss: 2.1454e-05\n",
      "Epoch 652/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 5.6207e-04 - val_loss: 2.1182e-05\n",
      "Epoch 653/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.6050e-04 - val_loss: 2.0918e-05\n",
      "Epoch 654/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.5894e-04 - val_loss: 2.0659e-05\n",
      "Epoch 655/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.5739e-04 - val_loss: 2.0403e-05\n",
      "Epoch 656/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 5.5585e-04 - val_loss: 2.0152e-05\n",
      "Epoch 657/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5431e-04 - val_loss: 1.9908e-05\n",
      "Epoch 658/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 5.5279e-04 - val_loss: 1.9662e-05\n",
      "Epoch 659/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5125e-04 - val_loss: 1.9422e-05\n",
      "Epoch 660/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.4974e-04 - val_loss: 1.9189e-05\n",
      "Epoch 661/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4821e-04 - val_loss: 1.8959e-05\n",
      "Epoch 662/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.4670e-04 - val_loss: 1.8731e-05\n",
      "Epoch 663/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4520e-04 - val_loss: 1.8510e-05\n",
      "Epoch 664/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.4370e-04 - val_loss: 1.8292e-05\n",
      "Epoch 665/1000\n",
      "32/32 [==============================] - 0s 192us/step - loss: 5.4221e-04 - val_loss: 1.8075e-05\n",
      "Epoch 666/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4072e-04 - val_loss: 1.7865e-05\n",
      "Epoch 667/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.3924e-04 - val_loss: 1.7660e-05\n",
      "Epoch 668/1000\n",
      "32/32 [==============================] - 0s 180us/step - loss: 5.3777e-04 - val_loss: 1.7459e-05\n",
      "Epoch 669/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.3629e-04 - val_loss: 1.7258e-05\n",
      "Epoch 670/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 5.3482e-04 - val_loss: 1.7062e-05\n",
      "Epoch 671/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.3337e-04 - val_loss: 1.6869e-05\n",
      "Epoch 672/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 5.3191e-04 - val_loss: 1.6679e-05\n",
      "Epoch 673/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 5.3046e-04 - val_loss: 1.6492e-05\n",
      "Epoch 674/1000\n",
      "32/32 [==============================] - 0s 164us/step - loss: 5.2902e-04 - val_loss: 1.6308e-05\n",
      "Epoch 675/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 5.2758e-04 - val_loss: 1.6130e-05\n",
      "Epoch 676/1000\n",
      "32/32 [==============================] - 0s 174us/step - loss: 5.2614e-04 - val_loss: 1.5954e-05\n",
      "Epoch 677/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2471e-04 - val_loss: 1.5781e-05\n",
      "Epoch 678/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2329e-04 - val_loss: 1.5612e-05\n",
      "Epoch 679/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2187e-04 - val_loss: 1.5443e-05\n",
      "Epoch 680/1000\n",
      "32/32 [==============================] - 0s 174us/step - loss: 5.2045e-04 - val_loss: 1.5280e-05\n",
      "Epoch 681/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1905e-04 - val_loss: 1.5120e-05\n",
      "Epoch 682/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.1764e-04 - val_loss: 1.4965e-05\n",
      "Epoch 683/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 5.1624e-04 - val_loss: 1.4810e-05\n",
      "Epoch 684/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1485e-04 - val_loss: 1.4658e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 685/1000\n",
      "32/32 [==============================] - 0s 201us/step - loss: 5.1347e-04 - val_loss: 1.4511e-05\n",
      "Epoch 686/1000\n",
      "32/32 [==============================] - 0s 160us/step - loss: 5.1207e-04 - val_loss: 1.4364e-05\n",
      "Epoch 687/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 5.1070e-04 - val_loss: 1.4221e-05\n",
      "Epoch 688/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.0932e-04 - val_loss: 1.4081e-05\n",
      "Epoch 689/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 5.0795e-04 - val_loss: 1.3942e-05\n",
      "Epoch 690/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0659e-04 - val_loss: 1.3808e-05\n",
      "Epoch 691/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0523e-04 - val_loss: 1.3677e-05\n",
      "Epoch 692/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0388e-04 - val_loss: 1.3548e-05\n",
      "Epoch 693/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0252e-04 - val_loss: 1.3419e-05\n",
      "Epoch 694/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0118e-04 - val_loss: 1.3295e-05\n",
      "Epoch 695/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.9984e-04 - val_loss: 1.3172e-05\n",
      "Epoch 696/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 4.9850e-04 - val_loss: 1.3053e-05\n",
      "Epoch 697/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.9717e-04 - val_loss: 1.2934e-05\n",
      "Epoch 698/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9584e-04 - val_loss: 1.2823e-05\n",
      "Epoch 699/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 4.9452e-04 - val_loss: 1.2710e-05\n",
      "Epoch 700/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.9320e-04 - val_loss: 1.2600e-05\n",
      "Epoch 701/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9188e-04 - val_loss: 1.2490e-05\n",
      "Epoch 702/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.9058e-04 - val_loss: 1.2382e-05\n",
      "Epoch 703/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.8927e-04 - val_loss: 1.2280e-05\n",
      "Epoch 704/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8797e-04 - val_loss: 1.2177e-05\n",
      "Epoch 705/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8668e-04 - val_loss: 1.2076e-05\n",
      "Epoch 706/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8539e-04 - val_loss: 1.1980e-05\n",
      "Epoch 707/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 4.8410e-04 - val_loss: 1.1885e-05\n",
      "Epoch 708/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.8282e-04 - val_loss: 1.1791e-05\n",
      "Epoch 709/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.8154e-04 - val_loss: 1.1701e-05\n",
      "Epoch 710/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.8026e-04 - val_loss: 1.1611e-05\n",
      "Epoch 711/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.7900e-04 - val_loss: 1.1524e-05\n",
      "Epoch 712/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.7773e-04 - val_loss: 1.1437e-05\n",
      "Epoch 713/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7647e-04 - val_loss: 1.1353e-05\n",
      "Epoch 714/1000\n",
      "32/32 [==============================] - 0s 181us/step - loss: 4.7521e-04 - val_loss: 1.1271e-05\n",
      "Epoch 715/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 4.7396e-04 - val_loss: 1.1191e-05\n",
      "Epoch 716/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 4.7270e-04 - val_loss: 1.1112e-05\n",
      "Epoch 717/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7146e-04 - val_loss: 1.1036e-05\n",
      "Epoch 718/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.7023e-04 - val_loss: 1.0960e-05\n",
      "Epoch 719/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6898e-04 - val_loss: 1.0886e-05\n",
      "Epoch 720/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.6775e-04 - val_loss: 1.0814e-05\n",
      "Epoch 721/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.6653e-04 - val_loss: 1.0744e-05\n",
      "Epoch 722/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 4.6530e-04 - val_loss: 1.0676e-05\n",
      "Epoch 723/1000\n",
      "32/32 [==============================] - 0s 189us/step - loss: 4.6409e-04 - val_loss: 1.0608e-05\n",
      "Epoch 724/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.6287e-04 - val_loss: 1.0544e-05\n",
      "Epoch 725/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.6166e-04 - val_loss: 1.0476e-05\n",
      "Epoch 726/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6045e-04 - val_loss: 1.0413e-05\n",
      "Epoch 727/1000\n",
      "32/32 [==============================] - 0s 133us/step - loss: 4.5924e-04 - val_loss: 1.0352e-05\n",
      "Epoch 728/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 4.5804e-04 - val_loss: 1.0291e-05\n",
      "Epoch 729/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 4.5684e-04 - val_loss: 1.0234e-05\n",
      "Epoch 730/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.5565e-04 - val_loss: 1.0176e-05\n",
      "Epoch 731/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 4.5447e-04 - val_loss: 1.0119e-05\n",
      "Epoch 732/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 4.5328e-04 - val_loss: 1.0066e-05\n",
      "Epoch 733/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5210e-04 - val_loss: 1.0014e-05\n",
      "Epoch 734/1000\n",
      "32/32 [==============================] - 0s 160us/step - loss: 4.5092e-04 - val_loss: 9.9624e-06\n",
      "Epoch 735/1000\n",
      "32/32 [==============================] - 0s 145us/step - loss: 4.4975e-04 - val_loss: 9.9130e-06\n",
      "Epoch 736/1000\n",
      "32/32 [==============================] - 0s 132us/step - loss: 4.4858e-04 - val_loss: 9.8635e-06\n",
      "Epoch 737/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.4741e-04 - val_loss: 9.8142e-06\n",
      "Epoch 738/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.4625e-04 - val_loss: 9.7673e-06\n",
      "Epoch 739/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 4.4509e-04 - val_loss: 9.7230e-06\n",
      "Epoch 740/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4394e-04 - val_loss: 9.6763e-06\n",
      "Epoch 741/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 4.4278e-04 - val_loss: 9.6324e-06\n",
      "Epoch 742/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 4.4164e-04 - val_loss: 9.5899e-06\n",
      "Epoch 743/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 4.4049e-04 - val_loss: 9.5482e-06\n",
      "Epoch 744/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3936e-04 - val_loss: 9.5073e-06\n",
      "Epoch 745/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.3822e-04 - val_loss: 9.4697e-06\n",
      "Epoch 746/1000\n",
      "32/32 [==============================] - 0s 174us/step - loss: 4.3709e-04 - val_loss: 9.4298e-06\n",
      "Epoch 747/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.3595e-04 - val_loss: 9.3931e-06\n",
      "Epoch 748/1000\n",
      "32/32 [==============================] - 0s 191us/step - loss: 4.3483e-04 - val_loss: 9.3570e-06\n",
      "Epoch 749/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3370e-04 - val_loss: 9.3222e-06\n",
      "Epoch 750/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 4.3258e-04 - val_loss: 9.2886e-06\n",
      "Epoch 751/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3147e-04 - val_loss: 9.2572e-06\n",
      "Epoch 752/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.3036e-04 - val_loss: 9.2235e-06\n",
      "Epoch 753/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.2925e-04 - val_loss: 9.1912e-06\n",
      "Epoch 754/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2815e-04 - val_loss: 9.1596e-06\n",
      "Epoch 755/1000\n",
      "32/32 [==============================] - 0s 158us/step - loss: 4.2704e-04 - val_loss: 9.1305e-06\n",
      "Epoch 756/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2594e-04 - val_loss: 9.1001e-06\n",
      "Epoch 757/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.2485e-04 - val_loss: 9.0726e-06\n",
      "Epoch 758/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2376e-04 - val_loss: 9.0441e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 759/1000\n",
      "32/32 [==============================] - 0s 165us/step - loss: 4.2267e-04 - val_loss: 9.0178e-06\n",
      "Epoch 760/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 4.2159e-04 - val_loss: 8.9940e-06\n",
      "Epoch 761/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.2050e-04 - val_loss: 8.9699e-06\n",
      "Epoch 762/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 4.1943e-04 - val_loss: 8.9473e-06\n",
      "Epoch 763/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.1835e-04 - val_loss: 8.9215e-06\n",
      "Epoch 764/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1728e-04 - val_loss: 8.8982e-06\n",
      "Epoch 765/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 4.1621e-04 - val_loss: 8.8754e-06\n",
      "Epoch 766/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.1515e-04 - val_loss: 8.8529e-06\n",
      "Epoch 767/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.1409e-04 - val_loss: 8.8325e-06\n",
      "Epoch 768/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.1302e-04 - val_loss: 8.8123e-06\n",
      "Epoch 769/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 4.1197e-04 - val_loss: 8.7917e-06\n",
      "Epoch 770/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 4.1092e-04 - val_loss: 8.7728e-06\n",
      "Epoch 771/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.0987e-04 - val_loss: 8.7534e-06\n",
      "Epoch 772/1000\n",
      "32/32 [==============================] - 0s 195us/step - loss: 4.0882e-04 - val_loss: 8.7379e-06\n",
      "Epoch 773/1000\n",
      "32/32 [==============================] - 0s 129us/step - loss: 4.0778e-04 - val_loss: 8.7208e-06\n",
      "Epoch 774/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0675e-04 - val_loss: 8.7040e-06\n",
      "Epoch 775/1000\n",
      "32/32 [==============================] - 0s 192us/step - loss: 4.0570e-04 - val_loss: 8.6882e-06\n",
      "Epoch 776/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 4.0467e-04 - val_loss: 8.6722e-06\n",
      "Epoch 777/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 4.0364e-04 - val_loss: 8.6582e-06\n",
      "Epoch 778/1000\n",
      "32/32 [==============================] - 0s 192us/step - loss: 4.0261e-04 - val_loss: 8.6462e-06\n",
      "Epoch 779/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0159e-04 - val_loss: 8.6306e-06\n",
      "Epoch 780/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0057e-04 - val_loss: 8.6169e-06\n",
      "Epoch 781/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.9955e-04 - val_loss: 8.6037e-06\n",
      "Epoch 782/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9854e-04 - val_loss: 8.5916e-06\n",
      "Epoch 783/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9752e-04 - val_loss: 8.5781e-06\n",
      "Epoch 784/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.9652e-04 - val_loss: 8.5677e-06\n",
      "Epoch 785/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9552e-04 - val_loss: 8.5558e-06\n",
      "Epoch 786/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 3.9451e-04 - val_loss: 8.5444e-06\n",
      "Epoch 787/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9351e-04 - val_loss: 8.5349e-06\n",
      "Epoch 788/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9251e-04 - val_loss: 8.5271e-06\n",
      "Epoch 789/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.9152e-04 - val_loss: 8.5175e-06\n",
      "Epoch 790/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.9053e-04 - val_loss: 8.5089e-06\n",
      "Epoch 791/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8954e-04 - val_loss: 8.4985e-06\n",
      "Epoch 792/1000\n",
      "32/32 [==============================] - 0s 164us/step - loss: 3.8856e-04 - val_loss: 8.4890e-06\n",
      "Epoch 793/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8757e-04 - val_loss: 8.4834e-06\n",
      "Epoch 794/1000\n",
      "32/32 [==============================] - 0s 160us/step - loss: 3.8660e-04 - val_loss: 8.4756e-06\n",
      "Epoch 795/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.8562e-04 - val_loss: 8.4683e-06\n",
      "Epoch 796/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8464e-04 - val_loss: 8.4609e-06\n",
      "Epoch 797/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 3.8367e-04 - val_loss: 8.4536e-06\n",
      "Epoch 798/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8271e-04 - val_loss: 8.4489e-06\n",
      "Epoch 799/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8174e-04 - val_loss: 8.4417e-06\n",
      "Epoch 800/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8078e-04 - val_loss: 8.4381e-06\n",
      "Epoch 801/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 3.7982e-04 - val_loss: 8.4312e-06\n",
      "Epoch 802/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7886e-04 - val_loss: 8.4271e-06\n",
      "Epoch 803/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.7791e-04 - val_loss: 8.4227e-06\n",
      "Epoch 804/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.7696e-04 - val_loss: 8.4200e-06\n",
      "Epoch 805/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7601e-04 - val_loss: 8.4158e-06\n",
      "Epoch 806/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.7506e-04 - val_loss: 8.4118e-06\n",
      "Epoch 807/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 3.7412e-04 - val_loss: 8.4076e-06\n",
      "Epoch 808/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.7318e-04 - val_loss: 8.4037e-06\n",
      "Epoch 809/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.7224e-04 - val_loss: 8.3995e-06\n",
      "Epoch 810/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.7131e-04 - val_loss: 8.3951e-06\n",
      "Epoch 811/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7037e-04 - val_loss: 8.3936e-06\n",
      "Epoch 812/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.6944e-04 - val_loss: 8.3904e-06\n",
      "Epoch 813/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6852e-04 - val_loss: 8.3883e-06\n",
      "Epoch 814/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.6759e-04 - val_loss: 8.3862e-06\n",
      "Epoch 815/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.6668e-04 - val_loss: 8.3834e-06\n",
      "Epoch 816/1000\n",
      "32/32 [==============================] - 0s 216us/step - loss: 3.6576e-04 - val_loss: 8.3822e-06\n",
      "Epoch 817/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 3.6484e-04 - val_loss: 8.3807e-06\n",
      "Epoch 818/1000\n",
      "32/32 [==============================] - 0s 177us/step - loss: 3.6392e-04 - val_loss: 8.3790e-06\n",
      "Epoch 819/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6302e-04 - val_loss: 8.3781e-06\n",
      "Epoch 820/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6211e-04 - val_loss: 8.3782e-06\n",
      "Epoch 821/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.6120e-04 - val_loss: 8.3773e-06\n",
      "Epoch 822/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6031e-04 - val_loss: 8.3766e-06\n",
      "Epoch 823/1000\n",
      "32/32 [==============================] - 0s 178us/step - loss: 3.5940e-04 - val_loss: 8.3756e-06\n",
      "Epoch 824/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5850e-04 - val_loss: 8.3763e-06\n",
      "Epoch 825/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5761e-04 - val_loss: 8.3746e-06\n",
      "Epoch 826/1000\n",
      "32/32 [==============================] - 0s 176us/step - loss: 3.5672e-04 - val_loss: 8.3736e-06\n",
      "Epoch 827/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 3.5583e-04 - val_loss: 8.3735e-06\n",
      "Epoch 828/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.5494e-04 - val_loss: 8.3725e-06\n",
      "Epoch 829/1000\n",
      "32/32 [==============================] - 0s 179us/step - loss: 3.5405e-04 - val_loss: 8.3717e-06\n",
      "Epoch 830/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 3.5317e-04 - val_loss: 8.3729e-06\n",
      "Epoch 831/1000\n",
      "32/32 [==============================] - 0s 164us/step - loss: 3.5229e-04 - val_loss: 8.3744e-06\n",
      "Epoch 832/1000\n",
      "32/32 [==============================] - 0s 120us/step - loss: 3.5141e-04 - val_loss: 8.3732e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 833/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5053e-04 - val_loss: 8.3749e-06\n",
      "Epoch 834/1000\n",
      "32/32 [==============================] - 0s 165us/step - loss: 3.4966e-04 - val_loss: 8.3753e-06\n",
      "Epoch 835/1000\n",
      "32/32 [==============================] - 0s 168us/step - loss: 3.4879e-04 - val_loss: 8.3753e-06\n",
      "Epoch 836/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4792e-04 - val_loss: 8.3766e-06\n",
      "Epoch 837/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.4706e-04 - val_loss: 8.3771e-06\n",
      "Epoch 838/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 3.4620e-04 - val_loss: 8.3784e-06\n",
      "Epoch 839/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4533e-04 - val_loss: 8.3791e-06\n",
      "Epoch 840/1000\n",
      "32/32 [==============================] - 0s 166us/step - loss: 3.4448e-04 - val_loss: 8.3790e-06\n",
      "Epoch 841/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.4362e-04 - val_loss: 8.3803e-06\n",
      "Epoch 842/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4277e-04 - val_loss: 8.3837e-06\n",
      "Epoch 843/1000\n",
      "32/32 [==============================] - 0s 158us/step - loss: 3.4192e-04 - val_loss: 8.3850e-06\n",
      "Epoch 844/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 3.4107e-04 - val_loss: 8.3860e-06\n",
      "Epoch 845/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 3.4022e-04 - val_loss: 8.3896e-06\n",
      "Epoch 846/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3938e-04 - val_loss: 8.3877e-06\n",
      "Epoch 847/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3854e-04 - val_loss: 8.3875e-06\n",
      "Epoch 848/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3770e-04 - val_loss: 8.3894e-06\n",
      "Epoch 849/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3686e-04 - val_loss: 8.3898e-06\n",
      "Epoch 850/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3603e-04 - val_loss: 8.3923e-06\n",
      "Epoch 851/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.3520e-04 - val_loss: 8.3942e-06\n",
      "Epoch 852/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 3.3437e-04 - val_loss: 8.3977e-06\n",
      "Epoch 853/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3354e-04 - val_loss: 8.3987e-06\n",
      "Epoch 854/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.3271e-04 - val_loss: 8.3996e-06\n",
      "Epoch 855/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3189e-04 - val_loss: 8.4005e-06\n",
      "Epoch 856/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 3.3106e-04 - val_loss: 8.4028e-06\n",
      "Epoch 857/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.3025e-04 - val_loss: 8.4026e-06\n",
      "Epoch 858/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2943e-04 - val_loss: 8.4043e-06\n",
      "Epoch 859/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2862e-04 - val_loss: 8.4070e-06\n",
      "Epoch 860/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.2781e-04 - val_loss: 8.4067e-06\n",
      "Epoch 861/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.2700e-04 - val_loss: 8.4087e-06\n",
      "Epoch 862/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 3.2619e-04 - val_loss: 8.4099e-06\n",
      "Epoch 863/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.2539e-04 - val_loss: 8.4121e-06\n",
      "Epoch 864/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2459e-04 - val_loss: 8.4118e-06\n",
      "Epoch 865/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 3.2379e-04 - val_loss: 8.4175e-06\n",
      "Epoch 866/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 3.2298e-04 - val_loss: 8.4162e-06\n",
      "Epoch 867/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 3.2220e-04 - val_loss: 8.4188e-06\n",
      "Epoch 868/1000\n",
      "32/32 [==============================] - 0s 160us/step - loss: 3.2140e-04 - val_loss: 8.4197e-06\n",
      "Epoch 869/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2060e-04 - val_loss: 8.4208e-06\n",
      "Epoch 870/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1982e-04 - val_loss: 8.4224e-06\n",
      "Epoch 871/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1903e-04 - val_loss: 8.4235e-06\n",
      "Epoch 872/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 3.1824e-04 - val_loss: 8.4260e-06\n",
      "Epoch 873/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.1746e-04 - val_loss: 8.4269e-06\n",
      "Epoch 874/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.1668e-04 - val_loss: 8.4294e-06\n",
      "Epoch 875/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1590e-04 - val_loss: 8.4288e-06\n",
      "Epoch 876/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 3.1512e-04 - val_loss: 8.4307e-06\n",
      "Epoch 877/1000\n",
      "32/32 [==============================] - 0s 175us/step - loss: 3.1435e-04 - val_loss: 8.4298e-06\n",
      "Epoch 878/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 3.1358e-04 - val_loss: 8.4323e-06\n",
      "Epoch 879/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 3.1281e-04 - val_loss: 8.4331e-06\n",
      "Epoch 880/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1204e-04 - val_loss: 8.4344e-06\n",
      "Epoch 881/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.1127e-04 - val_loss: 8.4364e-06\n",
      "Epoch 882/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1051e-04 - val_loss: 8.4351e-06\n",
      "Epoch 883/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.0975e-04 - val_loss: 8.4373e-06\n",
      "Epoch 884/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.0899e-04 - val_loss: 8.4396e-06\n",
      "Epoch 885/1000\n",
      "32/32 [==============================] - 0s 165us/step - loss: 3.0823e-04 - val_loss: 8.4389e-06\n",
      "Epoch 886/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 3.0748e-04 - val_loss: 8.4393e-06\n",
      "Epoch 887/1000\n",
      "32/32 [==============================] - 0s 163us/step - loss: 3.0672e-04 - val_loss: 8.4404e-06\n",
      "Epoch 888/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0597e-04 - val_loss: 8.4404e-06\n",
      "Epoch 889/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0523e-04 - val_loss: 8.4429e-06\n",
      "Epoch 890/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.0447e-04 - val_loss: 8.4436e-06\n",
      "Epoch 891/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0373e-04 - val_loss: 8.4431e-06\n",
      "Epoch 892/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.0299e-04 - val_loss: 8.4437e-06\n",
      "Epoch 893/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0225e-04 - val_loss: 8.4435e-06\n",
      "Epoch 894/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 3.0150e-04 - val_loss: 8.4453e-06\n",
      "Epoch 895/1000\n",
      "32/32 [==============================] - 0s 193us/step - loss: 3.0077e-04 - val_loss: 8.4451e-06\n",
      "Epoch 896/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0003e-04 - val_loss: 8.4457e-06\n",
      "Epoch 897/1000\n",
      "32/32 [==============================] - 0s 129us/step - loss: 2.9930e-04 - val_loss: 8.4480e-06\n",
      "Epoch 898/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.9857e-04 - val_loss: 8.4475e-06\n",
      "Epoch 899/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9784e-04 - val_loss: 8.4477e-06\n",
      "Epoch 900/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9711e-04 - val_loss: 8.4477e-06\n",
      "Epoch 901/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9639e-04 - val_loss: 8.4471e-06\n",
      "Epoch 902/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 2.9566e-04 - val_loss: 8.4471e-06\n",
      "Epoch 903/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9494e-04 - val_loss: 8.4450e-06\n",
      "Epoch 904/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9422e-04 - val_loss: 8.4439e-06\n",
      "Epoch 905/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.9350e-04 - val_loss: 8.4437e-06\n",
      "Epoch 906/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.9279e-04 - val_loss: 8.4449e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 907/1000\n",
      "32/32 [==============================] - 0s 163us/step - loss: 2.9208e-04 - val_loss: 8.4439e-06\n",
      "Epoch 908/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.9136e-04 - val_loss: 8.4449e-06\n",
      "Epoch 909/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 2.9065e-04 - val_loss: 8.4441e-06\n",
      "Epoch 910/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8994e-04 - val_loss: 8.4448e-06\n",
      "Epoch 911/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8924e-04 - val_loss: 8.4442e-06\n",
      "Epoch 912/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.8853e-04 - val_loss: 8.4426e-06\n",
      "Epoch 913/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8784e-04 - val_loss: 8.4427e-06\n",
      "Epoch 914/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8713e-04 - val_loss: 8.4396e-06\n",
      "Epoch 915/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.8643e-04 - val_loss: 8.4396e-06\n",
      "Epoch 916/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.8574e-04 - val_loss: 8.4366e-06\n",
      "Epoch 917/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 2.8504e-04 - val_loss: 8.4363e-06\n",
      "Epoch 918/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8435e-04 - val_loss: 8.4343e-06\n",
      "Epoch 919/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.8365e-04 - val_loss: 8.4327e-06\n",
      "Epoch 920/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.8297e-04 - val_loss: 8.4343e-06\n",
      "Epoch 921/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8229e-04 - val_loss: 8.4313e-06\n",
      "Epoch 922/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8160e-04 - val_loss: 8.4310e-06\n",
      "Epoch 923/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.8091e-04 - val_loss: 8.4307e-06\n",
      "Epoch 924/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.8023e-04 - val_loss: 8.4279e-06\n",
      "Epoch 925/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 2.7955e-04 - val_loss: 8.4273e-06\n",
      "Epoch 926/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.7887e-04 - val_loss: 8.4226e-06\n",
      "Epoch 927/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7820e-04 - val_loss: 8.4208e-06\n",
      "Epoch 928/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.7752e-04 - val_loss: 8.4204e-06\n",
      "Epoch 929/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.7685e-04 - val_loss: 8.4180e-06\n",
      "Epoch 930/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.7618e-04 - val_loss: 8.4152e-06\n",
      "Epoch 931/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.7551e-04 - val_loss: 8.4127e-06\n",
      "Epoch 932/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7484e-04 - val_loss: 8.4120e-06\n",
      "Epoch 933/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7418e-04 - val_loss: 8.4095e-06\n",
      "Epoch 934/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7351e-04 - val_loss: 8.4092e-06\n",
      "Epoch 935/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.7286e-04 - val_loss: 8.4082e-06\n",
      "Epoch 936/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7219e-04 - val_loss: 8.4040e-06\n",
      "Epoch 937/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7153e-04 - val_loss: 8.4028e-06\n",
      "Epoch 938/1000\n",
      "32/32 [==============================] - 0s 160us/step - loss: 2.7088e-04 - val_loss: 8.3999e-06\n",
      "Epoch 939/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 2.7023e-04 - val_loss: 8.3953e-06\n",
      "Epoch 940/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6957e-04 - val_loss: 8.3937e-06\n",
      "Epoch 941/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 2.6892e-04 - val_loss: 8.3886e-06\n",
      "Epoch 942/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.6827e-04 - val_loss: 8.3851e-06\n",
      "Epoch 943/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6762e-04 - val_loss: 8.3835e-06\n",
      "Epoch 944/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.6698e-04 - val_loss: 8.3799e-06\n",
      "Epoch 945/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 2.6633e-04 - val_loss: 8.3775e-06\n",
      "Epoch 946/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6569e-04 - val_loss: 8.3748e-06\n",
      "Epoch 947/1000\n",
      "32/32 [==============================] - 0s 129us/step - loss: 2.6505e-04 - val_loss: 8.3735e-06\n",
      "Epoch 948/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6441e-04 - val_loss: 8.3713e-06\n",
      "Epoch 949/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.6377e-04 - val_loss: 8.3681e-06\n",
      "Epoch 950/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6314e-04 - val_loss: 8.3638e-06\n",
      "Epoch 951/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6250e-04 - val_loss: 8.3578e-06\n",
      "Epoch 952/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.6187e-04 - val_loss: 8.3532e-06\n",
      "Epoch 953/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.6124e-04 - val_loss: 8.3489e-06\n",
      "Epoch 954/1000\n",
      "32/32 [==============================] - 0s 181us/step - loss: 2.6061e-04 - val_loss: 8.3451e-06\n",
      "Epoch 955/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 2.5998e-04 - val_loss: 8.3418e-06\n",
      "Epoch 956/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5936e-04 - val_loss: 8.3414e-06\n",
      "Epoch 957/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 2.5874e-04 - val_loss: 8.3382e-06\n",
      "Epoch 958/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.5811e-04 - val_loss: 8.3349e-06\n",
      "Epoch 959/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.5749e-04 - val_loss: 8.3318e-06\n",
      "Epoch 960/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5687e-04 - val_loss: 8.3267e-06\n",
      "Epoch 961/1000\n",
      "32/32 [==============================] - 0s 165us/step - loss: 2.5626e-04 - val_loss: 8.3220e-06\n",
      "Epoch 962/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.5564e-04 - val_loss: 8.3183e-06\n",
      "Epoch 963/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.5502e-04 - val_loss: 8.3138e-06\n",
      "Epoch 964/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5441e-04 - val_loss: 8.3082e-06\n",
      "Epoch 965/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.5380e-04 - val_loss: 8.3027e-06\n",
      "Epoch 966/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 2.5319e-04 - val_loss: 8.2993e-06\n",
      "Epoch 967/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5259e-04 - val_loss: 8.2952e-06\n",
      "Epoch 968/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5198e-04 - val_loss: 8.2904e-06\n",
      "Epoch 969/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5137e-04 - val_loss: 8.2871e-06\n",
      "Epoch 970/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5077e-04 - val_loss: 8.2827e-06\n",
      "Epoch 971/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.5017e-04 - val_loss: 8.2782e-06\n",
      "Epoch 972/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4957e-04 - val_loss: 8.2740e-06\n",
      "Epoch 973/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.4898e-04 - val_loss: 8.2688e-06\n",
      "Epoch 974/1000\n",
      "32/32 [==============================] - 0s 132us/step - loss: 2.4838e-04 - val_loss: 8.2624e-06\n",
      "Epoch 975/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4778e-04 - val_loss: 8.2585e-06\n",
      "Epoch 976/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4720e-04 - val_loss: 8.2524e-06\n",
      "Epoch 977/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4660e-04 - val_loss: 8.2468e-06\n",
      "Epoch 978/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 2.4601e-04 - val_loss: 8.2405e-06\n",
      "Epoch 979/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4542e-04 - val_loss: 8.2337e-06\n",
      "Epoch 980/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.4484e-04 - val_loss: 8.2307e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 981/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 2.4425e-04 - val_loss: 8.2262e-06\n",
      "Epoch 982/1000\n",
      "32/32 [==============================] - 0s 192us/step - loss: 2.4367e-04 - val_loss: 8.2231e-06\n",
      "Epoch 983/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.4309e-04 - val_loss: 8.2179e-06\n",
      "Epoch 984/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.4251e-04 - val_loss: 8.2120e-06\n",
      "Epoch 985/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.4192e-04 - val_loss: 8.2072e-06\n",
      "Epoch 986/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4135e-04 - val_loss: 8.2001e-06\n",
      "Epoch 987/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4077e-04 - val_loss: 8.1941e-06\n",
      "Epoch 988/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.4020e-04 - val_loss: 8.1890e-06\n",
      "Epoch 989/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.3962e-04 - val_loss: 8.1836e-06\n",
      "Epoch 990/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 2.3905e-04 - val_loss: 8.1783e-06\n",
      "Epoch 991/1000\n",
      "32/32 [==============================] - 0s 177us/step - loss: 2.3848e-04 - val_loss: 8.1696e-06\n",
      "Epoch 992/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3791e-04 - val_loss: 8.1641e-06\n",
      "Epoch 993/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.3735e-04 - val_loss: 8.1583e-06\n",
      "Epoch 994/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.3679e-04 - val_loss: 8.1531e-06\n",
      "Epoch 995/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3622e-04 - val_loss: 8.1446e-06\n",
      "Epoch 996/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.3566e-04 - val_loss: 8.1399e-06\n",
      "Epoch 997/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.3510e-04 - val_loss: 8.1365e-06\n",
      "Epoch 998/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.3454e-04 - val_loss: 8.1310e-06\n",
      "Epoch 999/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3398e-04 - val_loss: 8.1217e-06\n",
      "Epoch 1000/1000\n",
      "32/32 [==============================] - 0s 172us/step - loss: 2.3342e-04 - val_loss: 8.1171e-06\n",
      "0.00014758783800061792\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.39856923, -0.31191564, -0.5037411 , -0.60878336, -0.36186352,\n",
       "         -0.53622544, -0.71625394,  0.5010579 ,  0.2830679 ,  0.2544607 ],\n",
       "        [ 0.5505844 , -0.23389895,  0.5067956 , -0.44076166, -0.65445596,\n",
       "         -0.2462683 ,  0.57102466, -0.48279908, -0.6842674 , -0.03347318],\n",
       "        [ 0.89711744, -1.8881333 , -0.9163159 , -0.15211566,  0.7026993 ,\n",
       "         -1.0187443 , -0.6227963 ,  0.8958008 ,  0.6999281 ,  0.910984  ]],\n",
       "       dtype=float32),\n",
       " array([-0.62097865, -0.31833005,  0.46635935,  0.46035165, -0.31207067,\n",
       "        -0.42588407,  0.6433206 , -0.33717394,  0.1798445 ,  0.38315478],\n",
       "       dtype=float32),\n",
       " array([[-8.7912518e-01,  9.1336265e-02, -6.6903424e-01, -2.5425944e-01,\n",
       "          7.2408337e-03,  3.4046773e-02,  7.4167222e-01, -7.6350212e-01,\n",
       "          1.9926375e-02,  6.5992242e-01],\n",
       "        [-3.2849002e-01,  4.6211648e-01, -3.2892880e-01, -1.0348189e-01,\n",
       "         -2.0519510e-01,  2.8622195e-01,  1.5567784e-01, -1.9389203e-01,\n",
       "          3.2926512e-01,  6.6105419e-01],\n",
       "        [ 1.9136965e-01,  1.7413853e-01,  1.7226154e-01, -6.4414698e-01,\n",
       "          3.4360582e-01,  8.9620903e-02,  2.4404661e-01, -1.1544557e-03,\n",
       "         -4.8132029e-01,  2.5924543e-01],\n",
       "        [ 2.5025550e-01,  5.4725554e-02,  4.4300413e-01,  2.2641592e-01,\n",
       "          3.2211185e-01, -3.2012168e-01, -5.3979957e-01, -3.5156423e-01,\n",
       "          8.2537830e-02, -3.5264522e-01],\n",
       "        [-2.7545804e-01,  4.3392229e-01, -3.2824880e-01,  5.0783509e-01,\n",
       "          2.1326612e-01,  3.2598361e-01,  5.0728679e-01, -2.9788771e-01,\n",
       "         -4.0540585e-01,  3.4189945e-01],\n",
       "        [-6.2402815e-01, -3.0945566e-01, -2.7728352e-01, -2.3494020e-02,\n",
       "          3.2456130e-02, -3.9198611e-02,  2.6019478e-01, -3.2471511e-01,\n",
       "         -2.6646489e-01,  3.9191440e-01],\n",
       "        [ 1.1252959e-01, -9.4043121e-02,  7.4446522e-02, -9.0823621e-02,\n",
       "         -3.7530130e-01,  6.0677779e-01, -6.9261312e-01,  7.5361681e-01,\n",
       "         -8.0644464e-01, -6.8468994e-01],\n",
       "        [-4.0164851e-02, -3.1617203e-01,  2.1407384e-01,  4.6745858e-01,\n",
       "          1.7791927e-01,  7.2556385e-03, -1.3613874e-01,  3.9439166e-01,\n",
       "          2.8085107e-01,  2.0156191e-01],\n",
       "        [ 2.2899254e-01,  4.2094016e-01, -1.5142414e-01,  1.3385814e+00,\n",
       "         -3.7794545e-01, -2.7965540e-01,  9.5300116e-02, -9.8778471e-02,\n",
       "         -1.1402940e-01, -1.9263773e-01],\n",
       "        [ 1.1746866e-01,  8.8378139e-02,  4.1403109e-01, -6.0350454e-01,\n",
       "         -1.5730385e-01, -4.7967228e-01, -1.7171125e-01,  5.0525320e-01,\n",
       "          3.8077441e-01,  1.8601850e-02]], dtype=float32),\n",
       " array([ 0.6981028 ,  0.6404553 ,  0.6712739 , -0.3762607 , -0.59405696,\n",
       "         0.6405538 , -0.69511575,  0.68793505, -0.6620499 , -0.6972172 ],\n",
       "       dtype=float32),\n",
       " array([[ 0.71390057],\n",
       "        [ 0.20211373],\n",
       "        [ 0.5014978 ],\n",
       "        [-0.07287437],\n",
       "        [-0.13857341],\n",
       "        [ 0.17488746],\n",
       "        [-0.7018171 ],\n",
       "        [ 0.590109  ],\n",
       "        [-0.22787637],\n",
       "        [-0.6674623 ]], dtype=float32),\n",
       " array([0.7422324], dtype=float32)]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_challenger, history_challenger, evaluate_challenger=NN_model_structure_regression_5(X_train_challenger, X_val_challenger, Y_train_challenger, Y_val_challenger, adam2, 32, 1000, x_test_challenger, y_test_challenger)\n",
    "model_challenger.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_challenger.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_challenger_structure5.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_70 (Dense)             (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 15)                165       \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 221\n",
      "Trainable params: 221\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 32 samples, validate on 7 samples\n",
      "Epoch 1/1000\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 36.2059 - val_loss: 34.0603\n",
      "Epoch 2/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 33.0060 - val_loss: 28.6510\n",
      "Epoch 3/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.9431 - val_loss: 21.8393\n",
      "Epoch 4/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 22.7500 - val_loss: 13.3728\n",
      "Epoch 5/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 14.7242 - val_loss: 5.0848\n",
      "Epoch 6/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 6.2942 - val_loss: 1.7520\n",
      "Epoch 7/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.0496 - val_loss: 5.8764\n",
      "Epoch 8/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.8236 - val_loss: 7.8641\n",
      "Epoch 9/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.0966 - val_loss: 4.8280\n",
      "Epoch 10/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.4886 - val_loss: 1.8455\n",
      "Epoch 11/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.9110 - val_loss: 0.7804\n",
      "Epoch 12/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 0.7342 - val_loss: 1.0738\n",
      "Epoch 13/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.4449 - val_loss: 1.8046\n",
      "Epoch 14/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 1.1995 - val_loss: 2.3542\n",
      "Epoch 15/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.0775 - val_loss: 2.4994\n",
      "Epoch 16/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 2.5827 - val_loss: 2.2653\n",
      "Epoch 17/1000\n",
      "32/32 [==============================] - 0s 133us/step - loss: 2.6028 - val_loss: 1.7769\n",
      "Epoch 18/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 2.2235 - val_loss: 1.1859\n",
      "Epoch 19/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.6104 - val_loss: 0.6360\n",
      "Epoch 20/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.9492 - val_loss: 0.2402\n",
      "Epoch 21/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 0.4105 - val_loss: 0.0646\n",
      "Epoch 22/1000\n",
      "32/32 [==============================] - 0s 172us/step - loss: 0.1184 - val_loss: 0.1145\n",
      "Epoch 23/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1164 - val_loss: 0.3263\n",
      "Epoch 24/1000\n",
      "32/32 [==============================] - 0s 133us/step - loss: 0.3446 - val_loss: 0.5779\n",
      "Epoch 25/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.6509 - val_loss: 0.7385\n",
      "Epoch 26/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.8615 - val_loss: 0.7371\n",
      "Epoch 27/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 0.8744 - val_loss: 0.5914\n",
      "Epoch 28/1000\n",
      "32/32 [==============================] - 0s 176us/step - loss: 0.7043 - val_loss: 0.3788\n",
      "Epoch 29/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.4492 - val_loss: 0.1844\n",
      "Epoch 30/1000\n",
      "32/32 [==============================] - 0s 138us/step - loss: 0.2198 - val_loss: 0.0637\n",
      "Epoch 31/1000\n",
      "32/32 [==============================] - 0s 190us/step - loss: 0.0853 - val_loss: 0.0298\n",
      "Epoch 32/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0590 - val_loss: 0.0621\n",
      "Epoch 33/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.1128 - val_loss: 0.1252\n",
      "Epoch 34/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.2009 - val_loss: 0.1859\n",
      "Epoch 35/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.2806 - val_loss: 0.2219\n",
      "Epoch 36/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.3233 - val_loss: 0.2247\n",
      "Epoch 37/1000\n",
      "32/32 [==============================] - 0s 175us/step - loss: 0.3185 - val_loss: 0.1969\n",
      "Epoch 38/1000\n",
      "32/32 [==============================] - 0s 122us/step - loss: 0.2717 - val_loss: 0.1494\n",
      "Epoch 39/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1997 - val_loss: 0.0967\n",
      "Epoch 40/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1240 - val_loss: 0.0532\n",
      "Epoch 41/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0644 - val_loss: 0.0288\n",
      "Epoch 42/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0336 - val_loss: 0.0258\n",
      "Epoch 43/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0333 - val_loss: 0.0388\n",
      "Epoch 44/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0554 - val_loss: 0.0574\n",
      "Epoch 45/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0849 - val_loss: 0.0714\n",
      "Epoch 46/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1071 - val_loss: 0.0741\n",
      "Epoch 47/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1125 - val_loss: 0.0648\n",
      "Epoch 48/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1000 - val_loss: 0.0475\n",
      "Epoch 49/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0759 - val_loss: 0.0284\n",
      "Epoch 50/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0494 - val_loss: 0.0135\n",
      "Epoch 51/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0290 - val_loss: 0.0061\n",
      "Epoch 52/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0193 - val_loss: 0.0063\n",
      "Epoch 53/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0199 - val_loss: 0.0115\n",
      "Epoch 54/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0275 - val_loss: 0.0185\n",
      "Epoch 55/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0370 - val_loss: 0.0240\n",
      "Epoch 56/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0439 - val_loss: 0.0262\n",
      "Epoch 57/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0458 - val_loss: 0.0247\n",
      "Epoch 58/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0422 - val_loss: 0.0202\n",
      "Epoch 59/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0348 - val_loss: 0.0144\n",
      "Epoch 60/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0263 - val_loss: 0.0093\n",
      "Epoch 61/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0192 - val_loss: 0.0060\n",
      "Epoch 62/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0153 - val_loss: 0.0049\n",
      "Epoch 63/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0149 - val_loss: 0.0055\n",
      "Epoch 64/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0170 - val_loss: 0.0068\n",
      "Epoch 65/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0201 - val_loss: 0.0079\n",
      "Epoch 66/1000\n",
      "32/32 [==============================] - 0s 173us/step - loss: 0.0224 - val_loss: 0.0083\n",
      "Epoch 67/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 0.0230 - val_loss: 0.0078\n",
      "Epoch 68/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0216 - val_loss: 0.0066\n",
      "Epoch 69/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0188 - val_loss: 0.0053\n",
      "Epoch 70/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0157 - val_loss: 0.0045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0132 - val_loss: 0.0042\n",
      "Epoch 72/1000\n",
      "32/32 [==============================] - 0s 158us/step - loss: 0.0118 - val_loss: 0.0044\n",
      "Epoch 73/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0117 - val_loss: 0.0049\n",
      "Epoch 74/1000\n",
      "32/32 [==============================] - 0s 162us/step - loss: 0.0124 - val_loss: 0.0052\n",
      "Epoch 75/1000\n",
      "32/32 [==============================] - 0s 138us/step - loss: 0.0134 - val_loss: 0.0052\n",
      "Epoch 76/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0140 - val_loss: 0.0047\n",
      "Epoch 77/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0140 - val_loss: 0.0039\n",
      "Epoch 78/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0133 - val_loss: 0.0029\n",
      "Epoch 79/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0122 - val_loss: 0.0021\n",
      "Epoch 80/1000\n",
      "32/32 [==============================] - 0s 132us/step - loss: 0.0110 - val_loss: 0.0017\n",
      "Epoch 81/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 0.0100 - val_loss: 0.0017\n",
      "Epoch 82/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0095 - val_loss: 0.0020\n",
      "Epoch 83/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 0.0094 - val_loss: 0.0025\n",
      "Epoch 84/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0096 - val_loss: 0.0030\n",
      "Epoch 85/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0099 - val_loss: 0.0033\n",
      "Epoch 86/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 0.0101 - val_loss: 0.0033\n",
      "Epoch 87/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0100 - val_loss: 0.0030\n",
      "Epoch 88/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0097 - val_loss: 0.0026\n",
      "Epoch 89/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0092 - val_loss: 0.0021\n",
      "Epoch 90/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 0.0087 - val_loss: 0.0017\n",
      "Epoch 91/1000\n",
      "32/32 [==============================] - 0s 163us/step - loss: 0.0084 - val_loss: 0.0014\n",
      "Epoch 92/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0081 - val_loss: 0.0013\n",
      "Epoch 93/1000\n",
      "32/32 [==============================] - 0s 133us/step - loss: 0.0081 - val_loss: 0.0012\n",
      "Epoch 94/1000\n",
      "32/32 [==============================] - 0s 180us/step - loss: 0.0081 - val_loss: 0.0012\n",
      "Epoch 95/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0082 - val_loss: 0.0011\n",
      "Epoch 96/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0082 - val_loss: 0.0011\n",
      "Epoch 97/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0082 - val_loss: 0.0011\n",
      "Epoch 98/1000\n",
      "32/32 [==============================] - 0s 133us/step - loss: 0.0080 - val_loss: 0.0010\n",
      "Epoch 99/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0078 - val_loss: 0.0011\n",
      "Epoch 100/1000\n",
      "32/32 [==============================] - 0s 180us/step - loss: 0.0076 - val_loss: 0.0011\n",
      "Epoch 101/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0074 - val_loss: 0.0013\n",
      "Epoch 102/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0073 - val_loss: 0.0015\n",
      "Epoch 103/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0072 - val_loss: 0.0016\n",
      "Epoch 104/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0072 - val_loss: 0.0018\n",
      "Epoch 105/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0072 - val_loss: 0.0019\n",
      "Epoch 106/1000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0071 - val_loss: 0.0019\n",
      "Epoch 107/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0071 - val_loss: 0.0018\n",
      "Epoch 108/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0070 - val_loss: 0.0017\n",
      "Epoch 109/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0069 - val_loss: 0.0015\n",
      "Epoch 110/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0068 - val_loss: 0.0013\n",
      "Epoch 111/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0067 - val_loss: 0.0012\n",
      "Epoch 112/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0066 - val_loss: 0.0011\n",
      "Epoch 113/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 0.0065 - val_loss: 9.9028e-04\n",
      "Epoch 114/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0065 - val_loss: 9.2778e-04\n",
      "Epoch 115/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0065 - val_loss: 8.8580e-04\n",
      "Epoch 116/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0064 - val_loss: 8.6002e-04\n",
      "Epoch 117/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0064 - val_loss: 8.4828e-04\n",
      "Epoch 118/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0063 - val_loss: 8.4977e-04\n",
      "Epoch 119/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0062 - val_loss: 8.6348e-04\n",
      "Epoch 120/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 0.0062 - val_loss: 8.8712e-04\n",
      "Epoch 121/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0061 - val_loss: 9.1700e-04\n",
      "Epoch 122/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0060 - val_loss: 9.4852e-04\n",
      "Epoch 123/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0060 - val_loss: 9.7655e-04\n",
      "Epoch 124/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0059 - val_loss: 9.9604e-04\n",
      "Epoch 125/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0059 - val_loss: 0.0010\n",
      "Epoch 126/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0059 - val_loss: 9.9493e-04\n",
      "Epoch 127/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0058 - val_loss: 9.7245e-04\n",
      "Epoch 128/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 0.0058 - val_loss: 9.3830e-04\n",
      "Epoch 129/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0057 - val_loss: 8.9680e-04\n",
      "Epoch 130/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0057 - val_loss: 8.5269e-04\n",
      "Epoch 131/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0056 - val_loss: 8.0981e-04\n",
      "Epoch 132/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 0.0056 - val_loss: 7.7052e-04\n",
      "Epoch 133/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0055 - val_loss: 7.3620e-04\n",
      "Epoch 134/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0055 - val_loss: 7.0740e-04\n",
      "Epoch 135/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0055 - val_loss: 6.8441e-04\n",
      "Epoch 136/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0054 - val_loss: 6.6727e-04\n",
      "Epoch 137/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0054 - val_loss: 6.5560e-04\n",
      "Epoch 138/1000\n",
      "32/32 [==============================] - 0s 161us/step - loss: 0.0053 - val_loss: 6.4873e-04\n",
      "Epoch 139/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0053 - val_loss: 6.4555e-04\n",
      "Epoch 140/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0052 - val_loss: 6.4494e-04\n",
      "Epoch 141/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0052 - val_loss: 6.4577e-04\n",
      "Epoch 142/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0052 - val_loss: 6.4689e-04\n",
      "Epoch 143/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0051 - val_loss: 6.4718e-04\n",
      "Epoch 144/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0051 - val_loss: 6.4555e-04\n",
      "Epoch 145/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0051 - val_loss: 6.4130e-04\n",
      "Epoch 146/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0050 - val_loss: 6.3416e-04\n",
      "Epoch 147/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0050 - val_loss: 6.2447e-04\n",
      "Epoch 148/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0050 - val_loss: 6.1296e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0049 - val_loss: 6.0043e-04\n",
      "Epoch 150/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0049 - val_loss: 5.8758e-04\n",
      "Epoch 151/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0048 - val_loss: 5.7490e-04\n",
      "Epoch 152/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0048 - val_loss: 5.6273e-04\n",
      "Epoch 153/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0048 - val_loss: 5.5137e-04\n",
      "Epoch 154/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0047 - val_loss: 5.4108e-04\n",
      "Epoch 155/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0047 - val_loss: 5.3203e-04\n",
      "Epoch 156/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0047 - val_loss: 5.2419e-04\n",
      "Epoch 157/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0046 - val_loss: 5.1743e-04\n",
      "Epoch 158/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0046 - val_loss: 5.1151e-04\n",
      "Epoch 159/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0046 - val_loss: 5.0627e-04\n",
      "Epoch 160/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0046 - val_loss: 5.0152e-04\n",
      "Epoch 161/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0045 - val_loss: 4.9707e-04\n",
      "Epoch 162/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0045 - val_loss: 4.9272e-04\n",
      "Epoch 163/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0045 - val_loss: 4.8826e-04\n",
      "Epoch 164/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 0.0044 - val_loss: 4.8348e-04\n",
      "Epoch 165/1000\n",
      "32/32 [==============================] - 0s 166us/step - loss: 0.0044 - val_loss: 4.7837e-04\n",
      "Epoch 166/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0044 - val_loss: 4.7295e-04\n",
      "Epoch 167/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0043 - val_loss: 4.6740e-04\n",
      "Epoch 168/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0043 - val_loss: 4.6186e-04\n",
      "Epoch 169/1000\n",
      "32/32 [==============================] - 0s 184us/step - loss: 0.0043 - val_loss: 4.5643e-04\n",
      "Epoch 170/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 0.0043 - val_loss: 4.5109e-04\n",
      "Epoch 171/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0042 - val_loss: 4.4591e-04\n",
      "Epoch 172/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 0.0042 - val_loss: 4.4094e-04\n",
      "Epoch 173/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 0.0042 - val_loss: 4.3622e-04\n",
      "Epoch 174/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0042 - val_loss: 4.3175e-04\n",
      "Epoch 175/1000\n",
      "32/32 [==============================] - 0s 179us/step - loss: 0.0041 - val_loss: 4.2748e-04\n",
      "Epoch 176/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0041 - val_loss: 4.2334e-04\n",
      "Epoch 177/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0041 - val_loss: 4.1926e-04\n",
      "Epoch 178/1000\n",
      "32/32 [==============================] - 0s 158us/step - loss: 0.0040 - val_loss: 4.1525e-04\n",
      "Epoch 179/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0040 - val_loss: 4.1128e-04\n",
      "Epoch 180/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0040 - val_loss: 4.0738e-04\n",
      "Epoch 181/1000\n",
      "32/32 [==============================] - 0s 160us/step - loss: 0.0040 - val_loss: 4.0348e-04\n",
      "Epoch 182/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0039 - val_loss: 3.9956e-04\n",
      "Epoch 183/1000\n",
      "32/32 [==============================] - 0s 219us/step - loss: 0.0039 - val_loss: 3.9562e-04\n",
      "Epoch 184/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0039 - val_loss: 3.9169e-04\n",
      "Epoch 185/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0039 - val_loss: 3.8782e-04\n",
      "Epoch 186/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0038 - val_loss: 3.8402e-04\n",
      "Epoch 187/1000\n",
      "32/32 [==============================] - 0s 163us/step - loss: 0.0038 - val_loss: 3.8036e-04\n",
      "Epoch 188/1000\n",
      "32/32 [==============================] - 0s 167us/step - loss: 0.0038 - val_loss: 3.7683e-04\n",
      "Epoch 189/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0038 - val_loss: 3.7348e-04\n",
      "Epoch 190/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 0.0037 - val_loss: 3.7028e-04\n",
      "Epoch 191/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0037 - val_loss: 3.6725e-04\n",
      "Epoch 192/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0037 - val_loss: 3.6438e-04\n",
      "Epoch 193/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0037 - val_loss: 3.6169e-04\n",
      "Epoch 194/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0037 - val_loss: 3.5910e-04\n",
      "Epoch 195/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0036 - val_loss: 3.5656e-04\n",
      "Epoch 196/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 0.0036 - val_loss: 3.5407e-04\n",
      "Epoch 197/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0036 - val_loss: 3.5157e-04\n",
      "Epoch 198/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0036 - val_loss: 3.4907e-04\n",
      "Epoch 199/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0035 - val_loss: 3.4654e-04\n",
      "Epoch 200/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0035 - val_loss: 3.4398e-04\n",
      "Epoch 201/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0035 - val_loss: 3.4135e-04\n",
      "Epoch 202/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0035 - val_loss: 3.3868e-04\n",
      "Epoch 203/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0035 - val_loss: 3.3600e-04\n",
      "Epoch 204/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 0.0034 - val_loss: 3.3330e-04\n",
      "Epoch 205/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0034 - val_loss: 3.3064e-04\n",
      "Epoch 206/1000\n",
      "32/32 [==============================] - 0s 169us/step - loss: 0.0034 - val_loss: 3.2802e-04\n",
      "Epoch 207/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0034 - val_loss: 3.2548e-04\n",
      "Epoch 208/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 3.2302e-04\n",
      "Epoch 209/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 3.2065e-04\n",
      "Epoch 210/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0033 - val_loss: 3.1840e-04\n",
      "Epoch 211/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0033 - val_loss: 3.1624e-04\n",
      "Epoch 212/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 0.0033 - val_loss: 3.1420e-04\n",
      "Epoch 213/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0032 - val_loss: 3.1224e-04\n",
      "Epoch 214/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 3.1032e-04\n",
      "Epoch 215/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0032 - val_loss: 3.0844e-04\n",
      "Epoch 216/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 3.0657e-04\n",
      "Epoch 217/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0032 - val_loss: 3.0473e-04\n",
      "Epoch 218/1000\n",
      "32/32 [==============================] - 0s 137us/step - loss: 0.0031 - val_loss: 3.0289e-04\n",
      "Epoch 219/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0031 - val_loss: 3.0101e-04\n",
      "Epoch 220/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0031 - val_loss: 2.9910e-04\n",
      "Epoch 221/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0031 - val_loss: 2.9717e-04\n",
      "Epoch 222/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0031 - val_loss: 2.9520e-04\n",
      "Epoch 223/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0031 - val_loss: 2.9322e-04\n",
      "Epoch 224/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0030 - val_loss: 2.9129e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225/1000\n",
      "32/32 [==============================] - 0s 219us/step - loss: 0.0030 - val_loss: 2.8933e-04\n",
      "Epoch 226/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0030 - val_loss: 2.8740e-04\n",
      "Epoch 227/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0030 - val_loss: 2.8549e-04\n",
      "Epoch 228/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0030 - val_loss: 2.8361e-04\n",
      "Epoch 229/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0029 - val_loss: 2.8180e-04\n",
      "Epoch 230/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0029 - val_loss: 2.8004e-04\n",
      "Epoch 231/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0029 - val_loss: 2.7831e-04\n",
      "Epoch 232/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0029 - val_loss: 2.7664e-04\n",
      "Epoch 233/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0029 - val_loss: 2.7498e-04\n",
      "Epoch 234/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0029 - val_loss: 2.7335e-04\n",
      "Epoch 235/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 2.7176e-04\n",
      "Epoch 236/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0028 - val_loss: 2.7019e-04\n",
      "Epoch 237/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0028 - val_loss: 2.6863e-04\n",
      "Epoch 238/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 2.6708e-04\n",
      "Epoch 239/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 2.6552e-04\n",
      "Epoch 240/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 2.6398e-04\n",
      "Epoch 241/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 2.6241e-04\n",
      "Epoch 242/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0027 - val_loss: 2.6086e-04\n",
      "Epoch 243/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 2.5931e-04\n",
      "Epoch 244/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 2.5776e-04\n",
      "Epoch 245/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 2.5622e-04\n",
      "Epoch 246/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 2.5470e-04\n",
      "Epoch 247/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 2.5317e-04\n",
      "Epoch 248/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 2.5169e-04\n",
      "Epoch 249/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 2.5021e-04\n",
      "Epoch 250/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0026 - val_loss: 2.4875e-04\n",
      "Epoch 251/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0026 - val_loss: 2.4730e-04\n",
      "Epoch 252/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 2.4589e-04\n",
      "Epoch 253/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0025 - val_loss: 2.4447e-04\n",
      "Epoch 254/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 2.4311e-04\n",
      "Epoch 255/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0025 - val_loss: 2.4173e-04\n",
      "Epoch 256/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 2.4038e-04\n",
      "Epoch 257/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 2.3903e-04\n",
      "Epoch 258/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 2.3771e-04\n",
      "Epoch 259/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 2.3638e-04\n",
      "Epoch 260/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 2.3507e-04\n",
      "Epoch 261/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0024 - val_loss: 2.3378e-04\n",
      "Epoch 262/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 2.3247e-04\n",
      "Epoch 263/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0024 - val_loss: 2.3118e-04\n",
      "Epoch 264/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 2.2989e-04\n",
      "Epoch 265/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 2.2861e-04\n",
      "Epoch 266/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 2.2735e-04\n",
      "Epoch 267/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 2.2609e-04\n",
      "Epoch 268/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 2.2483e-04\n",
      "Epoch 269/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0023 - val_loss: 2.2358e-04\n",
      "Epoch 270/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 2.2234e-04\n",
      "Epoch 271/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0023 - val_loss: 2.2111e-04\n",
      "Epoch 272/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0023 - val_loss: 2.1991e-04\n",
      "Epoch 273/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 2.1871e-04\n",
      "Epoch 274/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0022 - val_loss: 2.1751e-04\n",
      "Epoch 275/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0022 - val_loss: 2.1633e-04\n",
      "Epoch 276/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 2.1516e-04\n",
      "Epoch 277/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 2.1400e-04\n",
      "Epoch 278/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0022 - val_loss: 2.1285e-04\n",
      "Epoch 279/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 0.0022 - val_loss: 2.1169e-04\n",
      "Epoch 280/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 2.1056e-04\n",
      "Epoch 281/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 2.0942e-04\n",
      "Epoch 282/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0021 - val_loss: 2.0832e-04\n",
      "Epoch 283/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0021 - val_loss: 2.0720e-04\n",
      "Epoch 284/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 2.0610e-04\n",
      "Epoch 285/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 2.0499e-04\n",
      "Epoch 286/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 2.0388e-04\n",
      "Epoch 287/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 2.0280e-04\n",
      "Epoch 288/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 2.0173e-04\n",
      "Epoch 289/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 2.0065e-04\n",
      "Epoch 290/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 1.9959e-04\n",
      "Epoch 291/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 1.9854e-04\n",
      "Epoch 292/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0020 - val_loss: 1.9747e-04\n",
      "Epoch 293/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0020 - val_loss: 1.9643e-04\n",
      "Epoch 294/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0020 - val_loss: 1.9540e-04\n",
      "Epoch 295/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 1.9437e-04\n",
      "Epoch 296/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0020 - val_loss: 1.9335e-04\n",
      "Epoch 297/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0020 - val_loss: 1.9234e-04\n",
      "Epoch 298/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 0.0019 - val_loss: 1.9134e-04\n",
      "Epoch 299/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0019 - val_loss: 1.9033e-04\n",
      "Epoch 300/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0019 - val_loss: 1.8936e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 301/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0019 - val_loss: 1.8835e-04\n",
      "Epoch 302/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 1.8739e-04\n",
      "Epoch 303/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0019 - val_loss: 1.8641e-04\n",
      "Epoch 304/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 1.8545e-04\n",
      "Epoch 305/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 1.8449e-04\n",
      "Epoch 306/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0019 - val_loss: 1.8353e-04\n",
      "Epoch 307/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 1.8259e-04\n",
      "Epoch 308/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 1.8163e-04\n",
      "Epoch 309/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 1.8071e-04\n",
      "Epoch 310/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 1.7978e-04\n",
      "Epoch 311/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0018 - val_loss: 1.7887e-04\n",
      "Epoch 312/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 1.7795e-04\n",
      "Epoch 313/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 1.7704e-04\n",
      "Epoch 314/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 1.7615e-04\n",
      "Epoch 315/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 1.7526e-04\n",
      "Epoch 316/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 1.7437e-04\n",
      "Epoch 317/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 1.7349e-04\n",
      "Epoch 318/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0017 - val_loss: 1.7262e-04\n",
      "Epoch 319/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 1.7174e-04\n",
      "Epoch 320/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 1.7086e-04\n",
      "Epoch 321/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 1.7000e-04\n",
      "Epoch 322/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 1.6915e-04\n",
      "Epoch 323/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 1.6829e-04\n",
      "Epoch 324/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 1.6746e-04\n",
      "Epoch 325/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 1.6663e-04\n",
      "Epoch 326/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 0.0016 - val_loss: 1.6578e-04\n",
      "Epoch 327/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 1.6495e-04\n",
      "Epoch 328/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 1.6415e-04\n",
      "Epoch 329/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0016 - val_loss: 1.6334e-04\n",
      "Epoch 330/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 1.6254e-04\n",
      "Epoch 331/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 1.6174e-04\n",
      "Epoch 332/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 1.6094e-04\n",
      "Epoch 333/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0016 - val_loss: 1.6013e-04\n",
      "Epoch 334/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 1.5935e-04\n",
      "Epoch 335/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0016 - val_loss: 1.5857e-04\n",
      "Epoch 336/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 1.5779e-04\n",
      "Epoch 337/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 1.5702e-04\n",
      "Epoch 338/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 0.0015 - val_loss: 1.5626e-04\n",
      "Epoch 339/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 1.5550e-04\n",
      "Epoch 340/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 1.5474e-04\n",
      "Epoch 341/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 1.5400e-04\n",
      "Epoch 342/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0015 - val_loss: 1.5325e-04\n",
      "Epoch 343/1000\n",
      "32/32 [==============================] - 0s 130us/step - loss: 0.0015 - val_loss: 1.5253e-04\n",
      "Epoch 344/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0015 - val_loss: 1.5178e-04\n",
      "Epoch 345/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0015 - val_loss: 1.5105e-04\n",
      "Epoch 346/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 1.5032e-04\n",
      "Epoch 347/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 1.4961e-04\n",
      "Epoch 348/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 1.4888e-04\n",
      "Epoch 349/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 1.4818e-04\n",
      "Epoch 350/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 1.4747e-04\n",
      "Epoch 351/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 1.4678e-04\n",
      "Epoch 352/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 1.4608e-04\n",
      "Epoch 353/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 1.4538e-04\n",
      "Epoch 354/1000\n",
      "32/32 [==============================] - 0s 166us/step - loss: 0.0014 - val_loss: 1.4470e-04\n",
      "Epoch 355/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0014 - val_loss: 1.4402e-04\n",
      "Epoch 356/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 1.4335e-04\n",
      "Epoch 357/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 1.4268e-04\n",
      "Epoch 358/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 1.4201e-04\n",
      "Epoch 359/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 1.4133e-04\n",
      "Epoch 360/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 1.4068e-04\n",
      "Epoch 361/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 1.4001e-04\n",
      "Epoch 362/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 0.0013 - val_loss: 1.3937e-04\n",
      "Epoch 363/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0013 - val_loss: 1.3873e-04\n",
      "Epoch 364/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0013 - val_loss: 1.3808e-04\n",
      "Epoch 365/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 1.3745e-04\n",
      "Epoch 366/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 0.0013 - val_loss: 1.3683e-04\n",
      "Epoch 367/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 0.0013 - val_loss: 1.3619e-04\n",
      "Epoch 368/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 1.3558e-04\n",
      "Epoch 369/1000\n",
      "32/32 [==============================] - 0s 161us/step - loss: 0.0013 - val_loss: 1.3495e-04\n",
      "Epoch 370/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0013 - val_loss: 1.3434e-04\n",
      "Epoch 371/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0013 - val_loss: 1.3372e-04\n",
      "Epoch 372/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 1.3311e-04\n",
      "Epoch 373/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0012 - val_loss: 1.3250e-04\n",
      "Epoch 374/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 0.0012 - val_loss: 1.3191e-04\n",
      "Epoch 375/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 1.3131e-04\n",
      "Epoch 376/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 1.3070e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 377/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 1.3013e-04\n",
      "Epoch 378/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 1.2955e-04\n",
      "Epoch 379/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 1.2897e-04\n",
      "Epoch 380/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 1.2838e-04\n",
      "Epoch 381/1000\n",
      "32/32 [==============================] - 0s 130us/step - loss: 0.0012 - val_loss: 1.2781e-04\n",
      "Epoch 382/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0012 - val_loss: 1.2725e-04\n",
      "Epoch 383/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 0.0012 - val_loss: 1.2667e-04\n",
      "Epoch 384/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0012 - val_loss: 1.2612e-04\n",
      "Epoch 385/1000\n",
      "32/32 [==============================] - 0s 178us/step - loss: 0.0012 - val_loss: 1.2555e-04\n",
      "Epoch 386/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 1.2500e-04\n",
      "Epoch 387/1000\n",
      "32/32 [==============================] - 0s 184us/step - loss: 0.0012 - val_loss: 1.2445e-04\n",
      "Epoch 388/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 1.2391e-04\n",
      "Epoch 389/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 1.2336e-04\n",
      "Epoch 390/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 1.2280e-04\n",
      "Epoch 391/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 1.2227e-04\n",
      "Epoch 392/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0011 - val_loss: 1.2173e-04\n",
      "Epoch 393/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 1.2121e-04\n",
      "Epoch 394/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 1.2068e-04\n",
      "Epoch 395/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 1.2015e-04\n",
      "Epoch 396/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 1.1962e-04\n",
      "Epoch 397/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 1.1911e-04\n",
      "Epoch 398/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 0.0011 - val_loss: 1.1860e-04\n",
      "Epoch 399/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 1.1809e-04\n",
      "Epoch 400/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 1.1759e-04\n",
      "Epoch 401/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 1.1709e-04\n",
      "Epoch 402/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 1.1658e-04\n",
      "Epoch 403/1000\n",
      "32/32 [==============================] - 0s 121us/step - loss: 0.0010 - val_loss: 1.1608e-04\n",
      "Epoch 404/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 1.1558e-04\n",
      "Epoch 405/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 1.1510e-04\n",
      "Epoch 406/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 1.1461e-04\n",
      "Epoch 407/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 1.1412e-04\n",
      "Epoch 408/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 1.1363e-04\n",
      "Epoch 409/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0010 - val_loss: 1.1316e-04\n",
      "Epoch 410/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0010 - val_loss: 1.1268e-04\n",
      "Epoch 411/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 0.0010 - val_loss: 1.1221e-04\n",
      "Epoch 412/1000\n",
      "32/32 [==============================] - 0s 191us/step - loss: 9.9717e-04 - val_loss: 1.1173e-04\n",
      "Epoch 413/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 9.9148e-04 - val_loss: 1.1126e-04\n",
      "Epoch 414/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.8581e-04 - val_loss: 1.1079e-04\n",
      "Epoch 415/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.8019e-04 - val_loss: 1.1033e-04\n",
      "Epoch 416/1000\n",
      "32/32 [==============================] - 0s 169us/step - loss: 9.7460e-04 - val_loss: 1.0988e-04\n",
      "Epoch 417/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 9.6905e-04 - val_loss: 1.0942e-04\n",
      "Epoch 418/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 9.6353e-04 - val_loss: 1.0896e-04\n",
      "Epoch 419/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.5804e-04 - val_loss: 1.0850e-04\n",
      "Epoch 420/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.5257e-04 - val_loss: 1.0805e-04\n",
      "Epoch 421/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4716e-04 - val_loss: 1.0762e-04\n",
      "Epoch 422/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.4179e-04 - val_loss: 1.0718e-04\n",
      "Epoch 423/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3644e-04 - val_loss: 1.0672e-04\n",
      "Epoch 424/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3111e-04 - val_loss: 1.0629e-04\n",
      "Epoch 425/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.2581e-04 - val_loss: 1.0585e-04\n",
      "Epoch 426/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.2055e-04 - val_loss: 1.0542e-04\n",
      "Epoch 427/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.1533e-04 - val_loss: 1.0498e-04\n",
      "Epoch 428/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.1013e-04 - val_loss: 1.0455e-04\n",
      "Epoch 429/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.0496e-04 - val_loss: 1.0414e-04\n",
      "Epoch 430/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.9983e-04 - val_loss: 1.0371e-04\n",
      "Epoch 431/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.9473e-04 - val_loss: 1.0329e-04\n",
      "Epoch 432/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.8967e-04 - val_loss: 1.0286e-04\n",
      "Epoch 433/1000\n",
      "32/32 [==============================] - 0s 206us/step - loss: 8.8461e-04 - val_loss: 1.0245e-04\n",
      "Epoch 434/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.7961e-04 - val_loss: 1.0203e-04\n",
      "Epoch 435/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.7463e-04 - val_loss: 1.0161e-04\n",
      "Epoch 436/1000\n",
      "32/32 [==============================] - 0s 160us/step - loss: 8.6968e-04 - val_loss: 1.0121e-04\n",
      "Epoch 437/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.6477e-04 - val_loss: 1.0081e-04\n",
      "Epoch 438/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5988e-04 - val_loss: 1.0040e-04\n",
      "Epoch 439/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5501e-04 - val_loss: 9.9996e-05\n",
      "Epoch 440/1000\n",
      "32/32 [==============================] - 0s 160us/step - loss: 8.5018e-04 - val_loss: 9.9597e-05\n",
      "Epoch 441/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 8.4537e-04 - val_loss: 9.9198e-05\n",
      "Epoch 442/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.4062e-04 - val_loss: 9.8804e-05\n",
      "Epoch 443/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3586e-04 - val_loss: 9.8417e-05\n",
      "Epoch 444/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 8.3114e-04 - val_loss: 9.8023e-05\n",
      "Epoch 445/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2646e-04 - val_loss: 9.7632e-05\n",
      "Epoch 446/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.2179e-04 - val_loss: 9.7235e-05\n",
      "Epoch 447/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 8.1717e-04 - val_loss: 9.6865e-05\n",
      "Epoch 448/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.1257e-04 - val_loss: 9.6476e-05\n",
      "Epoch 449/1000\n",
      "32/32 [==============================] - 0s 168us/step - loss: 8.0800e-04 - val_loss: 9.6102e-05\n",
      "Epoch 450/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.0343e-04 - val_loss: 9.5717e-05\n",
      "Epoch 451/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9891e-04 - val_loss: 9.5351e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 452/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9442e-04 - val_loss: 9.4972e-05\n",
      "Epoch 453/1000\n",
      "32/32 [==============================] - 0s 176us/step - loss: 7.8995e-04 - val_loss: 9.4609e-05\n",
      "Epoch 454/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8552e-04 - val_loss: 9.4230e-05\n",
      "Epoch 455/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.8111e-04 - val_loss: 9.3860e-05\n",
      "Epoch 456/1000\n",
      "32/32 [==============================] - 0s 170us/step - loss: 7.7670e-04 - val_loss: 9.3495e-05\n",
      "Epoch 457/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 7.7235e-04 - val_loss: 9.3129e-05\n",
      "Epoch 458/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 7.6801e-04 - val_loss: 9.2772e-05\n",
      "Epoch 459/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6371e-04 - val_loss: 9.2408e-05\n",
      "Epoch 460/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.5941e-04 - val_loss: 9.2061e-05\n",
      "Epoch 461/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5516e-04 - val_loss: 9.1694e-05\n",
      "Epoch 462/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 7.5092e-04 - val_loss: 9.1346e-05\n",
      "Epoch 463/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4671e-04 - val_loss: 9.0991e-05\n",
      "Epoch 464/1000\n",
      "32/32 [==============================] - 0s 120us/step - loss: 7.4254e-04 - val_loss: 9.0645e-05\n",
      "Epoch 465/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3838e-04 - val_loss: 9.0302e-05\n",
      "Epoch 466/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3425e-04 - val_loss: 8.9950e-05\n",
      "Epoch 467/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 7.3014e-04 - val_loss: 8.9610e-05\n",
      "Epoch 468/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2606e-04 - val_loss: 8.9270e-05\n",
      "Epoch 469/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.2199e-04 - val_loss: 8.8926e-05\n",
      "Epoch 470/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.1795e-04 - val_loss: 8.8592e-05\n",
      "Epoch 471/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1395e-04 - val_loss: 8.8255e-05\n",
      "Epoch 472/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.0994e-04 - val_loss: 8.7914e-05\n",
      "Epoch 473/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.0599e-04 - val_loss: 8.7583e-05\n",
      "Epoch 474/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 7.0205e-04 - val_loss: 8.7260e-05\n",
      "Epoch 475/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.9813e-04 - val_loss: 8.6929e-05\n",
      "Epoch 476/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.9424e-04 - val_loss: 8.6602e-05\n",
      "Epoch 477/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.9037e-04 - val_loss: 8.6281e-05\n",
      "Epoch 478/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 6.8652e-04 - val_loss: 8.5957e-05\n",
      "Epoch 479/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.8268e-04 - val_loss: 8.5634e-05\n",
      "Epoch 480/1000\n",
      "32/32 [==============================] - 0s 183us/step - loss: 6.7889e-04 - val_loss: 8.5321e-05\n",
      "Epoch 481/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.7511e-04 - val_loss: 8.4994e-05\n",
      "Epoch 482/1000\n",
      "32/32 [==============================] - 0s 168us/step - loss: 6.7135e-04 - val_loss: 8.4678e-05\n",
      "Epoch 483/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6762e-04 - val_loss: 8.4359e-05\n",
      "Epoch 484/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.6390e-04 - val_loss: 8.4045e-05\n",
      "Epoch 485/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.6020e-04 - val_loss: 8.3742e-05\n",
      "Epoch 486/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5654e-04 - val_loss: 8.3432e-05\n",
      "Epoch 487/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 6.5289e-04 - val_loss: 8.3126e-05\n",
      "Epoch 488/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.4926e-04 - val_loss: 8.2816e-05\n",
      "Epoch 489/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.4566e-04 - val_loss: 8.2513e-05\n",
      "Epoch 490/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4208e-04 - val_loss: 8.2216e-05\n",
      "Epoch 491/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.3851e-04 - val_loss: 8.1913e-05\n",
      "Epoch 492/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 6.3497e-04 - val_loss: 8.1612e-05\n",
      "Epoch 493/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.3145e-04 - val_loss: 8.1318e-05\n",
      "Epoch 494/1000\n",
      "32/32 [==============================] - 0s 129us/step - loss: 6.2796e-04 - val_loss: 8.1019e-05\n",
      "Epoch 495/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.2447e-04 - val_loss: 8.0733e-05\n",
      "Epoch 496/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2101e-04 - val_loss: 8.0430e-05\n",
      "Epoch 497/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1757e-04 - val_loss: 8.0145e-05\n",
      "Epoch 498/1000\n",
      "32/32 [==============================] - 0s 183us/step - loss: 6.1416e-04 - val_loss: 7.9866e-05\n",
      "Epoch 499/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1076e-04 - val_loss: 7.9569e-05\n",
      "Epoch 500/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0738e-04 - val_loss: 7.9281e-05\n",
      "Epoch 501/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.0403e-04 - val_loss: 7.8996e-05\n",
      "Epoch 502/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.0069e-04 - val_loss: 7.8715e-05\n",
      "Epoch 503/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.9736e-04 - val_loss: 7.8441e-05\n",
      "Epoch 504/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.9408e-04 - val_loss: 7.8160e-05\n",
      "Epoch 505/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9079e-04 - val_loss: 7.7880e-05\n",
      "Epoch 506/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8753e-04 - val_loss: 7.7603e-05\n",
      "Epoch 507/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8429e-04 - val_loss: 7.7324e-05\n",
      "Epoch 508/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8106e-04 - val_loss: 7.7057e-05\n",
      "Epoch 509/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7787e-04 - val_loss: 7.6779e-05\n",
      "Epoch 510/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.7468e-04 - val_loss: 7.6510e-05\n",
      "Epoch 511/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7152e-04 - val_loss: 7.6231e-05\n",
      "Epoch 512/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.6837e-04 - val_loss: 7.5966e-05\n",
      "Epoch 513/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 5.6524e-04 - val_loss: 7.5709e-05\n",
      "Epoch 514/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 5.6213e-04 - val_loss: 7.5444e-05\n",
      "Epoch 515/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 5.5904e-04 - val_loss: 7.5185e-05\n",
      "Epoch 516/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.5597e-04 - val_loss: 7.4922e-05\n",
      "Epoch 517/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.5291e-04 - val_loss: 7.4670e-05\n",
      "Epoch 518/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.4987e-04 - val_loss: 7.4405e-05\n",
      "Epoch 519/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4685e-04 - val_loss: 7.4151e-05\n",
      "Epoch 520/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.4385e-04 - val_loss: 7.3903e-05\n",
      "Epoch 521/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.4086e-04 - val_loss: 7.3646e-05\n",
      "Epoch 522/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3790e-04 - val_loss: 7.3391e-05\n",
      "Epoch 523/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.3495e-04 - val_loss: 7.3150e-05\n",
      "Epoch 524/1000\n",
      "32/32 [==============================] - 0s 165us/step - loss: 5.3202e-04 - val_loss: 7.2905e-05\n",
      "Epoch 525/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2910e-04 - val_loss: 7.2653e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 526/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2620e-04 - val_loss: 7.2403e-05\n",
      "Epoch 527/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.2331e-04 - val_loss: 7.2159e-05\n",
      "Epoch 528/1000\n",
      "32/32 [==============================] - 0s 194us/step - loss: 5.2045e-04 - val_loss: 7.1922e-05\n",
      "Epoch 529/1000\n",
      "32/32 [==============================] - 0s 167us/step - loss: 5.1762e-04 - val_loss: 7.1673e-05\n",
      "Epoch 530/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1478e-04 - val_loss: 7.1424e-05\n",
      "Epoch 531/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 5.1196e-04 - val_loss: 7.1190e-05\n",
      "Epoch 532/1000\n",
      "32/32 [==============================] - 0s 160us/step - loss: 5.0915e-04 - val_loss: 7.0955e-05\n",
      "Epoch 533/1000\n",
      "32/32 [==============================] - 0s 183us/step - loss: 5.0638e-04 - val_loss: 7.0710e-05\n",
      "Epoch 534/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0362e-04 - val_loss: 7.0480e-05\n",
      "Epoch 535/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.0086e-04 - val_loss: 7.0248e-05\n",
      "Epoch 536/1000\n",
      "32/32 [==============================] - 0s 168us/step - loss: 4.9815e-04 - val_loss: 7.0012e-05\n",
      "Epoch 537/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9542e-04 - val_loss: 6.9777e-05\n",
      "Epoch 538/1000\n",
      "32/32 [==============================] - 0s 172us/step - loss: 4.9272e-04 - val_loss: 6.9561e-05\n",
      "Epoch 539/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9003e-04 - val_loss: 6.9335e-05\n",
      "Epoch 540/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.8737e-04 - val_loss: 6.9121e-05\n",
      "Epoch 541/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.8471e-04 - val_loss: 6.8888e-05\n",
      "Epoch 542/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8208e-04 - val_loss: 6.8663e-05\n",
      "Epoch 543/1000\n",
      "32/32 [==============================] - 0s 166us/step - loss: 4.7946e-04 - val_loss: 6.8446e-05\n",
      "Epoch 544/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7684e-04 - val_loss: 6.8222e-05\n",
      "Epoch 545/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 4.7425e-04 - val_loss: 6.8005e-05\n",
      "Epoch 546/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7167e-04 - val_loss: 6.7777e-05\n",
      "Epoch 547/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6911e-04 - val_loss: 6.7571e-05\n",
      "Epoch 548/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6657e-04 - val_loss: 6.7352e-05\n",
      "Epoch 549/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6403e-04 - val_loss: 6.7139e-05\n",
      "Epoch 550/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6152e-04 - val_loss: 6.6925e-05\n",
      "Epoch 551/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5902e-04 - val_loss: 6.6710e-05\n",
      "Epoch 552/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.5652e-04 - val_loss: 6.6507e-05\n",
      "Epoch 553/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5405e-04 - val_loss: 6.6293e-05\n",
      "Epoch 554/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.5159e-04 - val_loss: 6.6090e-05\n",
      "Epoch 555/1000\n",
      "32/32 [==============================] - 0s 163us/step - loss: 4.4917e-04 - val_loss: 6.5887e-05\n",
      "Epoch 556/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4672e-04 - val_loss: 6.5675e-05\n",
      "Epoch 557/1000\n",
      "32/32 [==============================] - 0s 133us/step - loss: 4.4430e-04 - val_loss: 6.5473e-05\n",
      "Epoch 558/1000\n",
      "32/32 [==============================] - 0s 171us/step - loss: 4.4191e-04 - val_loss: 6.5278e-05\n",
      "Epoch 559/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 4.3952e-04 - val_loss: 6.5073e-05\n",
      "Epoch 560/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3715e-04 - val_loss: 6.4883e-05\n",
      "Epoch 561/1000\n",
      "32/32 [==============================] - 0s 190us/step - loss: 4.3478e-04 - val_loss: 6.4678e-05\n",
      "Epoch 562/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 4.3244e-04 - val_loss: 6.4481e-05\n",
      "Epoch 563/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.3011e-04 - val_loss: 6.4283e-05\n",
      "Epoch 564/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 4.2779e-04 - val_loss: 6.4091e-05\n",
      "Epoch 565/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 4.2548e-04 - val_loss: 6.3898e-05\n",
      "Epoch 566/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.2319e-04 - val_loss: 6.3708e-05\n",
      "Epoch 567/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.2091e-04 - val_loss: 6.3526e-05\n",
      "Epoch 568/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1865e-04 - val_loss: 6.3331e-05\n",
      "Epoch 569/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1639e-04 - val_loss: 6.3144e-05\n",
      "Epoch 570/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1417e-04 - val_loss: 6.2955e-05\n",
      "Epoch 571/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 4.1193e-04 - val_loss: 6.2773e-05\n",
      "Epoch 572/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0973e-04 - val_loss: 6.2590e-05\n",
      "Epoch 573/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.0753e-04 - val_loss: 6.2407e-05\n",
      "Epoch 574/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 4.0533e-04 - val_loss: 6.2223e-05\n",
      "Epoch 575/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.0317e-04 - val_loss: 6.2041e-05\n",
      "Epoch 576/1000\n",
      "32/32 [==============================] - 0s 169us/step - loss: 4.0100e-04 - val_loss: 6.1866e-05\n",
      "Epoch 577/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 3.9885e-04 - val_loss: 6.1678e-05\n",
      "Epoch 578/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 3.9672e-04 - val_loss: 6.1513e-05\n",
      "Epoch 579/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 3.9460e-04 - val_loss: 6.1335e-05\n",
      "Epoch 580/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9249e-04 - val_loss: 6.1169e-05\n",
      "Epoch 581/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 3.9040e-04 - val_loss: 6.0991e-05\n",
      "Epoch 582/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.8831e-04 - val_loss: 6.0817e-05\n",
      "Epoch 583/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8622e-04 - val_loss: 6.0655e-05\n",
      "Epoch 584/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.8417e-04 - val_loss: 6.0484e-05\n",
      "Epoch 585/1000\n",
      "32/32 [==============================] - 0s 131us/step - loss: 3.8212e-04 - val_loss: 6.0315e-05\n",
      "Epoch 586/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 3.8008e-04 - val_loss: 6.0148e-05\n",
      "Epoch 587/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7806e-04 - val_loss: 5.9981e-05\n",
      "Epoch 588/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 3.7604e-04 - val_loss: 5.9815e-05\n",
      "Epoch 589/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7404e-04 - val_loss: 5.9648e-05\n",
      "Epoch 590/1000\n",
      "32/32 [==============================] - 0s 178us/step - loss: 3.7204e-04 - val_loss: 5.9492e-05\n",
      "Epoch 591/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7006e-04 - val_loss: 5.9333e-05\n",
      "Epoch 592/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 3.6811e-04 - val_loss: 5.9174e-05\n",
      "Epoch 593/1000\n",
      "32/32 [==============================] - 0s 138us/step - loss: 3.6614e-04 - val_loss: 5.9016e-05\n",
      "Epoch 594/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.6420e-04 - val_loss: 5.8861e-05\n",
      "Epoch 595/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.6226e-04 - val_loss: 5.8710e-05\n",
      "Epoch 596/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6034e-04 - val_loss: 5.8551e-05\n",
      "Epoch 597/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5844e-04 - val_loss: 5.8396e-05\n",
      "Epoch 598/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.5654e-04 - val_loss: 5.8242e-05\n",
      "Epoch 599/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 3.5465e-04 - val_loss: 5.8093e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 600/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5277e-04 - val_loss: 5.7938e-05\n",
      "Epoch 601/1000\n",
      "32/32 [==============================] - 0s 199us/step - loss: 3.5090e-04 - val_loss: 5.7799e-05\n",
      "Epoch 602/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 3.4905e-04 - val_loss: 5.7650e-05\n",
      "Epoch 603/1000\n",
      "32/32 [==============================] - 0s 179us/step - loss: 3.4721e-04 - val_loss: 5.7499e-05\n",
      "Epoch 604/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4538e-04 - val_loss: 5.7353e-05\n",
      "Epoch 605/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4355e-04 - val_loss: 5.7211e-05\n",
      "Epoch 606/1000\n",
      "32/32 [==============================] - 0s 181us/step - loss: 3.4175e-04 - val_loss: 5.7067e-05\n",
      "Epoch 607/1000\n",
      "32/32 [==============================] - 0s 176us/step - loss: 3.3994e-04 - val_loss: 5.6936e-05\n",
      "Epoch 608/1000\n",
      "32/32 [==============================] - 0s 179us/step - loss: 3.3815e-04 - val_loss: 5.6793e-05\n",
      "Epoch 609/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.3637e-04 - val_loss: 5.6647e-05\n",
      "Epoch 610/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3460e-04 - val_loss: 5.6504e-05\n",
      "Epoch 611/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 3.3284e-04 - val_loss: 5.6373e-05\n",
      "Epoch 612/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.3109e-04 - val_loss: 5.6239e-05\n",
      "Epoch 613/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.2936e-04 - val_loss: 5.6104e-05\n",
      "Epoch 614/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2763e-04 - val_loss: 5.5969e-05\n",
      "Epoch 615/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.2591e-04 - val_loss: 5.5832e-05\n",
      "Epoch 616/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2420e-04 - val_loss: 5.5699e-05\n",
      "Epoch 617/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2250e-04 - val_loss: 5.5572e-05\n",
      "Epoch 618/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.2082e-04 - val_loss: 5.5445e-05\n",
      "Epoch 619/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 3.1914e-04 - val_loss: 5.5309e-05\n",
      "Epoch 620/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1747e-04 - val_loss: 5.5182e-05\n",
      "Epoch 621/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1581e-04 - val_loss: 5.5055e-05\n",
      "Epoch 622/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1416e-04 - val_loss: 5.4934e-05\n",
      "Epoch 623/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1252e-04 - val_loss: 5.4808e-05\n",
      "Epoch 624/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1090e-04 - val_loss: 5.4689e-05\n",
      "Epoch 625/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0927e-04 - val_loss: 5.4567e-05\n",
      "Epoch 626/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 3.0766e-04 - val_loss: 5.4448e-05\n",
      "Epoch 627/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 3.0607e-04 - val_loss: 5.4328e-05\n",
      "Epoch 628/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0447e-04 - val_loss: 5.4206e-05\n",
      "Epoch 629/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0289e-04 - val_loss: 5.4091e-05\n",
      "Epoch 630/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0131e-04 - val_loss: 5.3977e-05\n",
      "Epoch 631/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.9976e-04 - val_loss: 5.3855e-05\n",
      "Epoch 632/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 2.9820e-04 - val_loss: 5.3741e-05\n",
      "Epoch 633/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.9666e-04 - val_loss: 5.3621e-05\n",
      "Epoch 634/1000\n",
      "32/32 [==============================] - 0s 172us/step - loss: 2.9512e-04 - val_loss: 5.3509e-05\n",
      "Epoch 635/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 2.9359e-04 - val_loss: 5.3401e-05\n",
      "Epoch 636/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.9207e-04 - val_loss: 5.3295e-05\n",
      "Epoch 637/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.9056e-04 - val_loss: 5.3183e-05\n",
      "Epoch 638/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 2.8907e-04 - val_loss: 5.3077e-05\n",
      "Epoch 639/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.8757e-04 - val_loss: 5.2969e-05\n",
      "Epoch 640/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8609e-04 - val_loss: 5.2862e-05\n",
      "Epoch 641/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.8462e-04 - val_loss: 5.2757e-05\n",
      "Epoch 642/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 2.8316e-04 - val_loss: 5.2660e-05\n",
      "Epoch 643/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8170e-04 - val_loss: 5.2553e-05\n",
      "Epoch 644/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.8025e-04 - val_loss: 5.2450e-05\n",
      "Epoch 645/1000\n",
      "32/32 [==============================] - 0s 160us/step - loss: 2.7882e-04 - val_loss: 5.2351e-05\n",
      "Epoch 646/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7738e-04 - val_loss: 5.2250e-05\n",
      "Epoch 647/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7596e-04 - val_loss: 5.2143e-05\n",
      "Epoch 648/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 2.7454e-04 - val_loss: 5.2043e-05\n",
      "Epoch 649/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7314e-04 - val_loss: 5.1953e-05\n",
      "Epoch 650/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7174e-04 - val_loss: 5.1859e-05\n",
      "Epoch 651/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7036e-04 - val_loss: 5.1761e-05\n",
      "Epoch 652/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6897e-04 - val_loss: 5.1664e-05\n",
      "Epoch 653/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.6760e-04 - val_loss: 5.1567e-05\n",
      "Epoch 654/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6623e-04 - val_loss: 5.1479e-05\n",
      "Epoch 655/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6488e-04 - val_loss: 5.1390e-05\n",
      "Epoch 656/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.6353e-04 - val_loss: 5.1302e-05\n",
      "Epoch 657/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6219e-04 - val_loss: 5.1208e-05\n",
      "Epoch 658/1000\n",
      "32/32 [==============================] - 0s 132us/step - loss: 2.6086e-04 - val_loss: 5.1117e-05\n",
      "Epoch 659/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.5954e-04 - val_loss: 5.1028e-05\n",
      "Epoch 660/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5822e-04 - val_loss: 5.0950e-05\n",
      "Epoch 661/1000\n",
      "32/32 [==============================] - 0s 166us/step - loss: 2.5691e-04 - val_loss: 5.0868e-05\n",
      "Epoch 662/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5561e-04 - val_loss: 5.0783e-05\n",
      "Epoch 663/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 2.5432e-04 - val_loss: 5.0688e-05\n",
      "Epoch 664/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 2.5304e-04 - val_loss: 5.0607e-05\n",
      "Epoch 665/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.5175e-04 - val_loss: 5.0525e-05\n",
      "Epoch 666/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5048e-04 - val_loss: 5.0447e-05\n",
      "Epoch 667/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 2.4922e-04 - val_loss: 5.0370e-05\n",
      "Epoch 668/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4797e-04 - val_loss: 5.0288e-05\n",
      "Epoch 669/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 2.4672e-04 - val_loss: 5.0210e-05\n",
      "Epoch 670/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4548e-04 - val_loss: 5.0133e-05\n",
      "Epoch 671/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.4425e-04 - val_loss: 5.0056e-05\n",
      "Epoch 672/1000\n",
      "32/32 [==============================] - 0s 162us/step - loss: 2.4302e-04 - val_loss: 4.9987e-05\n",
      "Epoch 673/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.4180e-04 - val_loss: 4.9905e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 674/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.4059e-04 - val_loss: 4.9823e-05\n",
      "Epoch 675/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3939e-04 - val_loss: 4.9757e-05\n",
      "Epoch 676/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.3819e-04 - val_loss: 4.9691e-05\n",
      "Epoch 677/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3701e-04 - val_loss: 4.9617e-05\n",
      "Epoch 678/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3582e-04 - val_loss: 4.9545e-05\n",
      "Epoch 679/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.3465e-04 - val_loss: 4.9476e-05\n",
      "Epoch 680/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.3348e-04 - val_loss: 4.9412e-05\n",
      "Epoch 681/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.3232e-04 - val_loss: 4.9347e-05\n",
      "Epoch 682/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 2.3116e-04 - val_loss: 4.9277e-05\n",
      "Epoch 683/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 2.3001e-04 - val_loss: 4.9205e-05\n",
      "Epoch 684/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.2887e-04 - val_loss: 4.9140e-05\n",
      "Epoch 685/1000\n",
      "32/32 [==============================] - 0s 202us/step - loss: 2.2774e-04 - val_loss: 4.9073e-05\n",
      "Epoch 686/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2661e-04 - val_loss: 4.9015e-05\n",
      "Epoch 687/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.2549e-04 - val_loss: 4.8956e-05\n",
      "Epoch 688/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2438e-04 - val_loss: 4.8892e-05\n",
      "Epoch 689/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.2327e-04 - val_loss: 4.8827e-05\n",
      "Epoch 690/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2217e-04 - val_loss: 4.8770e-05\n",
      "Epoch 691/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2108e-04 - val_loss: 4.8709e-05\n",
      "Epoch 692/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1999e-04 - val_loss: 4.8659e-05\n",
      "Epoch 693/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.1891e-04 - val_loss: 4.8602e-05\n",
      "Epoch 694/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1784e-04 - val_loss: 4.8542e-05\n",
      "Epoch 695/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1677e-04 - val_loss: 4.8486e-05\n",
      "Epoch 696/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.1570e-04 - val_loss: 4.8430e-05\n",
      "Epoch 697/1000\n",
      "32/32 [==============================] - 0s 133us/step - loss: 2.1465e-04 - val_loss: 4.8381e-05\n",
      "Epoch 698/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 2.1360e-04 - val_loss: 4.8319e-05\n",
      "Epoch 699/1000\n",
      "32/32 [==============================] - 0s 162us/step - loss: 2.1256e-04 - val_loss: 4.8265e-05\n",
      "Epoch 700/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 2.1152e-04 - val_loss: 4.8215e-05\n",
      "Epoch 701/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.1050e-04 - val_loss: 4.8166e-05\n",
      "Epoch 702/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.0947e-04 - val_loss: 4.8122e-05\n",
      "Epoch 703/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0845e-04 - val_loss: 4.8067e-05\n",
      "Epoch 704/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0744e-04 - val_loss: 4.8015e-05\n",
      "Epoch 705/1000\n",
      "32/32 [==============================] - 0s 161us/step - loss: 2.0644e-04 - val_loss: 4.7967e-05\n",
      "Epoch 706/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0543e-04 - val_loss: 4.7920e-05\n",
      "Epoch 707/1000\n",
      "32/32 [==============================] - 0s 120us/step - loss: 2.0444e-04 - val_loss: 4.7873e-05\n",
      "Epoch 708/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0346e-04 - val_loss: 4.7831e-05\n",
      "Epoch 709/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 2.0247e-04 - val_loss: 4.7787e-05\n",
      "Epoch 710/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.0150e-04 - val_loss: 4.7739e-05\n",
      "Epoch 711/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0053e-04 - val_loss: 4.7701e-05\n",
      "Epoch 712/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9956e-04 - val_loss: 4.7657e-05\n",
      "Epoch 713/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9861e-04 - val_loss: 4.7619e-05\n",
      "Epoch 714/1000\n",
      "32/32 [==============================] - 0s 182us/step - loss: 1.9765e-04 - val_loss: 4.7576e-05\n",
      "Epoch 715/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.9670e-04 - val_loss: 4.7533e-05\n",
      "Epoch 716/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.9576e-04 - val_loss: 4.7494e-05\n",
      "Epoch 717/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9483e-04 - val_loss: 4.7459e-05\n",
      "Epoch 718/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9390e-04 - val_loss: 4.7420e-05\n",
      "Epoch 719/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9298e-04 - val_loss: 4.7385e-05\n",
      "Epoch 720/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9206e-04 - val_loss: 4.7345e-05\n",
      "Epoch 721/1000\n",
      "32/32 [==============================] - 0s 130us/step - loss: 1.9115e-04 - val_loss: 4.7308e-05\n",
      "Epoch 722/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9024e-04 - val_loss: 4.7271e-05\n",
      "Epoch 723/1000\n",
      "32/32 [==============================] - 0s 163us/step - loss: 1.8934e-04 - val_loss: 4.7239e-05\n",
      "Epoch 724/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8844e-04 - val_loss: 4.7211e-05\n",
      "Epoch 725/1000\n",
      "32/32 [==============================] - 0s 165us/step - loss: 1.8755e-04 - val_loss: 4.7173e-05\n",
      "Epoch 726/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.8667e-04 - val_loss: 4.7141e-05\n",
      "Epoch 727/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8579e-04 - val_loss: 4.7105e-05\n",
      "Epoch 728/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.8491e-04 - val_loss: 4.7076e-05\n",
      "Epoch 729/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8404e-04 - val_loss: 4.7052e-05\n",
      "Epoch 730/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8318e-04 - val_loss: 4.7021e-05\n",
      "Epoch 731/1000\n",
      "32/32 [==============================] - 0s 165us/step - loss: 1.8232e-04 - val_loss: 4.6985e-05\n",
      "Epoch 732/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 1.8146e-04 - val_loss: 4.6962e-05\n",
      "Epoch 733/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 1.8062e-04 - val_loss: 4.6935e-05\n",
      "Epoch 734/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7977e-04 - val_loss: 4.6905e-05\n",
      "Epoch 735/1000\n",
      "32/32 [==============================] - 0s 137us/step - loss: 1.7893e-04 - val_loss: 4.6879e-05\n",
      "Epoch 736/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7810e-04 - val_loss: 4.6850e-05\n",
      "Epoch 737/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.7727e-04 - val_loss: 4.6829e-05\n",
      "Epoch 738/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7645e-04 - val_loss: 4.6808e-05\n",
      "Epoch 739/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.7563e-04 - val_loss: 4.6784e-05\n",
      "Epoch 740/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.7481e-04 - val_loss: 4.6761e-05\n",
      "Epoch 741/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7401e-04 - val_loss: 4.6739e-05\n",
      "Epoch 742/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 1.7320e-04 - val_loss: 4.6713e-05\n",
      "Epoch 743/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.7241e-04 - val_loss: 4.6697e-05\n",
      "Epoch 744/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7161e-04 - val_loss: 4.6672e-05\n",
      "Epoch 745/1000\n",
      "32/32 [==============================] - 0s 189us/step - loss: 1.7082e-04 - val_loss: 4.6655e-05\n",
      "Epoch 746/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7004e-04 - val_loss: 4.6637e-05\n",
      "Epoch 747/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6926e-04 - val_loss: 4.6620e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 748/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.6848e-04 - val_loss: 4.6596e-05\n",
      "Epoch 749/1000\n",
      "32/32 [==============================] - 0s 138us/step - loss: 1.6772e-04 - val_loss: 4.6582e-05\n",
      "Epoch 750/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6695e-04 - val_loss: 4.6566e-05\n",
      "Epoch 751/1000\n",
      "32/32 [==============================] - 0s 171us/step - loss: 1.6619e-04 - val_loss: 4.6541e-05\n",
      "Epoch 752/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.6543e-04 - val_loss: 4.6532e-05\n",
      "Epoch 753/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 1.6468e-04 - val_loss: 4.6518e-05\n",
      "Epoch 754/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6394e-04 - val_loss: 4.6502e-05\n",
      "Epoch 755/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.6319e-04 - val_loss: 4.6492e-05\n",
      "Epoch 756/1000\n",
      "32/32 [==============================] - 0s 178us/step - loss: 1.6245e-04 - val_loss: 4.6477e-05\n",
      "Epoch 757/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.6172e-04 - val_loss: 4.6467e-05\n",
      "Epoch 758/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 1.6099e-04 - val_loss: 4.6449e-05\n",
      "Epoch 759/1000\n",
      "32/32 [==============================] - 0s 128us/step - loss: 1.6026e-04 - val_loss: 4.6443e-05\n",
      "Epoch 760/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 1.5955e-04 - val_loss: 4.6426e-05\n",
      "Epoch 761/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5884e-04 - val_loss: 4.6420e-05\n",
      "Epoch 762/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5812e-04 - val_loss: 4.6408e-05\n",
      "Epoch 763/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5742e-04 - val_loss: 4.6401e-05\n",
      "Epoch 764/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.5672e-04 - val_loss: 4.6385e-05\n",
      "Epoch 765/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 1.5602e-04 - val_loss: 4.6388e-05\n",
      "Epoch 766/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.5532e-04 - val_loss: 4.6375e-05\n",
      "Epoch 767/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5463e-04 - val_loss: 4.6368e-05\n",
      "Epoch 768/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.5395e-04 - val_loss: 4.6363e-05\n",
      "Epoch 769/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5327e-04 - val_loss: 4.6358e-05\n",
      "Epoch 770/1000\n",
      "32/32 [==============================] - 0s 164us/step - loss: 1.5259e-04 - val_loss: 4.6349e-05\n",
      "Epoch 771/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.5192e-04 - val_loss: 4.6347e-05\n",
      "Epoch 772/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.5125e-04 - val_loss: 4.6342e-05\n",
      "Epoch 773/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5058e-04 - val_loss: 4.6335e-05\n",
      "Epoch 774/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.4993e-04 - val_loss: 4.6334e-05\n",
      "Epoch 775/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 1.4926e-04 - val_loss: 4.6331e-05\n",
      "Epoch 776/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.4861e-04 - val_loss: 4.6334e-05\n",
      "Epoch 777/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.4797e-04 - val_loss: 4.6322e-05\n",
      "Epoch 778/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.4732e-04 - val_loss: 4.6318e-05\n",
      "Epoch 779/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 1.4668e-04 - val_loss: 4.6320e-05\n",
      "Epoch 780/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.4604e-04 - val_loss: 4.6323e-05\n",
      "Epoch 781/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4541e-04 - val_loss: 4.6329e-05\n",
      "Epoch 782/1000\n",
      "32/32 [==============================] - 0s 138us/step - loss: 1.4478e-04 - val_loss: 4.6326e-05\n",
      "Epoch 783/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4415e-04 - val_loss: 4.6320e-05\n",
      "Epoch 784/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.4353e-04 - val_loss: 4.6333e-05\n",
      "Epoch 785/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 1.4292e-04 - val_loss: 4.6328e-05\n",
      "Epoch 786/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.4230e-04 - val_loss: 4.6329e-05\n",
      "Epoch 787/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 1.4169e-04 - val_loss: 4.6334e-05\n",
      "Epoch 788/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4109e-04 - val_loss: 4.6344e-05\n",
      "Epoch 789/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4049e-04 - val_loss: 4.6344e-05\n",
      "Epoch 790/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3988e-04 - val_loss: 4.6344e-05\n",
      "Epoch 791/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.3929e-04 - val_loss: 4.6354e-05\n",
      "Epoch 792/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.3870e-04 - val_loss: 4.6358e-05\n",
      "Epoch 793/1000\n",
      "32/32 [==============================] - 0s 162us/step - loss: 1.3811e-04 - val_loss: 4.6367e-05\n",
      "Epoch 794/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3753e-04 - val_loss: 4.6370e-05\n",
      "Epoch 795/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3695e-04 - val_loss: 4.6378e-05\n",
      "Epoch 796/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3637e-04 - val_loss: 4.6380e-05\n",
      "Epoch 797/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3580e-04 - val_loss: 4.6386e-05\n",
      "Epoch 798/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 1.3523e-04 - val_loss: 4.6398e-05\n",
      "Epoch 799/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3466e-04 - val_loss: 4.6409e-05\n",
      "Epoch 800/1000\n",
      "32/32 [==============================] - 0s 161us/step - loss: 1.3410e-04 - val_loss: 4.6420e-05\n",
      "Epoch 801/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.3354e-04 - val_loss: 4.6424e-05\n",
      "Epoch 802/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3299e-04 - val_loss: 4.6439e-05\n",
      "Epoch 803/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3244e-04 - val_loss: 4.6443e-05\n",
      "Epoch 804/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.3189e-04 - val_loss: 4.6456e-05\n",
      "Epoch 805/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3134e-04 - val_loss: 4.6462e-05\n",
      "Epoch 806/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3079e-04 - val_loss: 4.6478e-05\n",
      "Epoch 807/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3026e-04 - val_loss: 4.6491e-05\n",
      "Epoch 808/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2972e-04 - val_loss: 4.6502e-05\n",
      "Epoch 809/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2919e-04 - val_loss: 4.6509e-05\n",
      "Epoch 810/1000\n",
      "32/32 [==============================] - 0s 182us/step - loss: 1.2866e-04 - val_loss: 4.6524e-05\n",
      "Epoch 811/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2813e-04 - val_loss: 4.6535e-05\n",
      "Epoch 812/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2761e-04 - val_loss: 4.6551e-05\n",
      "Epoch 813/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2709e-04 - val_loss: 4.6561e-05\n",
      "Epoch 814/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2657e-04 - val_loss: 4.6581e-05\n",
      "Epoch 815/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.2606e-04 - val_loss: 4.6592e-05\n",
      "Epoch 816/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.2555e-04 - val_loss: 4.6612e-05\n",
      "Epoch 817/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.2505e-04 - val_loss: 4.6625e-05\n",
      "Epoch 818/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.2454e-04 - val_loss: 4.6642e-05\n",
      "Epoch 819/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2404e-04 - val_loss: 4.6656e-05\n",
      "Epoch 820/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.2355e-04 - val_loss: 4.6673e-05\n",
      "Epoch 821/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 1.2305e-04 - val_loss: 4.6693e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 822/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2256e-04 - val_loss: 4.6708e-05\n",
      "Epoch 823/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2207e-04 - val_loss: 4.6724e-05\n",
      "Epoch 824/1000\n",
      "32/32 [==============================] - 0s 168us/step - loss: 1.2159e-04 - val_loss: 4.6741e-05\n",
      "Epoch 825/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2111e-04 - val_loss: 4.6761e-05\n",
      "Epoch 826/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.2063e-04 - val_loss: 4.6783e-05\n",
      "Epoch 827/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2015e-04 - val_loss: 4.6801e-05\n",
      "Epoch 828/1000\n",
      "32/32 [==============================] - 0s 183us/step - loss: 1.1968e-04 - val_loss: 4.6814e-05\n",
      "Epoch 829/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1921e-04 - val_loss: 4.6831e-05\n",
      "Epoch 830/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 1.1874e-04 - val_loss: 4.6855e-05\n",
      "Epoch 831/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 1.1828e-04 - val_loss: 4.6879e-05\n",
      "Epoch 832/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 1.1782e-04 - val_loss: 4.6899e-05\n",
      "Epoch 833/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 1.1736e-04 - val_loss: 4.6919e-05\n",
      "Epoch 834/1000\n",
      "32/32 [==============================] - 0s 181us/step - loss: 1.1690e-04 - val_loss: 4.6940e-05\n",
      "Epoch 835/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1645e-04 - val_loss: 4.6962e-05\n",
      "Epoch 836/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 1.1599e-04 - val_loss: 4.6988e-05\n",
      "Epoch 837/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 1.1555e-04 - val_loss: 4.7001e-05\n",
      "Epoch 838/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1511e-04 - val_loss: 4.7025e-05\n",
      "Epoch 839/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 1.1466e-04 - val_loss: 4.7046e-05\n",
      "Epoch 840/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1422e-04 - val_loss: 4.7078e-05\n",
      "Epoch 841/1000\n",
      "32/32 [==============================] - 0s 189us/step - loss: 1.1379e-04 - val_loss: 4.7104e-05\n",
      "Epoch 842/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1336e-04 - val_loss: 4.7122e-05\n",
      "Epoch 843/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.1292e-04 - val_loss: 4.7142e-05\n",
      "Epoch 844/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 1.1250e-04 - val_loss: 4.7168e-05\n",
      "Epoch 845/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1207e-04 - val_loss: 4.7191e-05\n",
      "Epoch 846/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1164e-04 - val_loss: 4.7215e-05\n",
      "Epoch 847/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1122e-04 - val_loss: 4.7241e-05\n",
      "Epoch 848/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 1.1081e-04 - val_loss: 4.7263e-05\n",
      "Epoch 849/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.1039e-04 - val_loss: 4.7293e-05\n",
      "Epoch 850/1000\n",
      "32/32 [==============================] - 0s 163us/step - loss: 1.0998e-04 - val_loss: 4.7322e-05\n",
      "Epoch 851/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0957e-04 - val_loss: 4.7343e-05\n",
      "Epoch 852/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.0916e-04 - val_loss: 4.7372e-05\n",
      "Epoch 853/1000\n",
      "32/32 [==============================] - 0s 133us/step - loss: 1.0876e-04 - val_loss: 4.7393e-05\n",
      "Epoch 854/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0835e-04 - val_loss: 4.7420e-05\n",
      "Epoch 855/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.0795e-04 - val_loss: 4.7449e-05\n",
      "Epoch 856/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0755e-04 - val_loss: 4.7474e-05\n",
      "Epoch 857/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 1.0716e-04 - val_loss: 4.7506e-05\n",
      "Epoch 858/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0676e-04 - val_loss: 4.7530e-05\n",
      "Epoch 859/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 1.0637e-04 - val_loss: 4.7556e-05\n",
      "Epoch 860/1000\n",
      "32/32 [==============================] - 0s 122us/step - loss: 1.0599e-04 - val_loss: 4.7589e-05\n",
      "Epoch 861/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0560e-04 - val_loss: 4.7624e-05\n",
      "Epoch 862/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 1.0522e-04 - val_loss: 4.7642e-05\n",
      "Epoch 863/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 1.0484e-04 - val_loss: 4.7664e-05\n",
      "Epoch 864/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.0446e-04 - val_loss: 4.7702e-05\n",
      "Epoch 865/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0409e-04 - val_loss: 4.7727e-05\n",
      "Epoch 866/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.0371e-04 - val_loss: 4.7760e-05\n",
      "Epoch 867/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.0334e-04 - val_loss: 4.7789e-05\n",
      "Epoch 868/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.0297e-04 - val_loss: 4.7815e-05\n",
      "Epoch 869/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0260e-04 - val_loss: 4.7851e-05\n",
      "Epoch 870/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.0224e-04 - val_loss: 4.7877e-05\n",
      "Epoch 871/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0187e-04 - val_loss: 4.7913e-05\n",
      "Epoch 872/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 1.0151e-04 - val_loss: 4.7936e-05\n",
      "Epoch 873/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.0115e-04 - val_loss: 4.7972e-05\n",
      "Epoch 874/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 1.0080e-04 - val_loss: 4.8002e-05\n",
      "Epoch 875/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.0045e-04 - val_loss: 4.8037e-05\n",
      "Epoch 876/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0010e-04 - val_loss: 4.8063e-05\n",
      "Epoch 877/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.9745e-05 - val_loss: 4.8094e-05\n",
      "Epoch 878/1000\n",
      "32/32 [==============================] - 0s 184us/step - loss: 9.9397e-05 - val_loss: 4.8118e-05\n",
      "Epoch 879/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.9057e-05 - val_loss: 4.8159e-05\n",
      "Epoch 880/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.8713e-05 - val_loss: 4.8194e-05\n",
      "Epoch 881/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.8369e-05 - val_loss: 4.8230e-05\n",
      "Epoch 882/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.8030e-05 - val_loss: 4.8260e-05\n",
      "Epoch 883/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 9.7694e-05 - val_loss: 4.8285e-05\n",
      "Epoch 884/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.7360e-05 - val_loss: 4.8321e-05\n",
      "Epoch 885/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.7031e-05 - val_loss: 4.8356e-05\n",
      "Epoch 886/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6697e-05 - val_loss: 4.8390e-05\n",
      "Epoch 887/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6372e-05 - val_loss: 4.8418e-05\n",
      "Epoch 888/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.6044e-05 - val_loss: 4.8443e-05\n",
      "Epoch 889/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.5717e-05 - val_loss: 4.8486e-05\n",
      "Epoch 890/1000\n",
      "32/32 [==============================] - 0s 179us/step - loss: 9.5401e-05 - val_loss: 4.8523e-05\n",
      "Epoch 891/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.5080e-05 - val_loss: 4.8558e-05\n",
      "Epoch 892/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.4759e-05 - val_loss: 4.8586e-05\n",
      "Epoch 893/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.4443e-05 - val_loss: 4.8620e-05\n",
      "Epoch 894/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.4133e-05 - val_loss: 4.8655e-05\n",
      "Epoch 895/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 9.3818e-05 - val_loss: 4.8699e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 896/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.3507e-05 - val_loss: 4.8726e-05\n",
      "Epoch 897/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.3199e-05 - val_loss: 4.8757e-05\n",
      "Epoch 898/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.2890e-05 - val_loss: 4.8791e-05\n",
      "Epoch 899/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.2587e-05 - val_loss: 4.8829e-05\n",
      "Epoch 900/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.2284e-05 - val_loss: 4.8866e-05\n",
      "Epoch 901/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.1979e-05 - val_loss: 4.8905e-05\n",
      "Epoch 902/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 9.1682e-05 - val_loss: 4.8932e-05\n",
      "Epoch 903/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1387e-05 - val_loss: 4.8973e-05\n",
      "Epoch 904/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 9.1089e-05 - val_loss: 4.9004e-05\n",
      "Epoch 905/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.0795e-05 - val_loss: 4.9043e-05\n",
      "Epoch 906/1000\n",
      "32/32 [==============================] - 0s 183us/step - loss: 9.0504e-05 - val_loss: 4.9083e-05\n",
      "Epoch 907/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 9.0214e-05 - val_loss: 4.9113e-05\n",
      "Epoch 908/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9929e-05 - val_loss: 4.9146e-05\n",
      "Epoch 909/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.9640e-05 - val_loss: 4.9187e-05\n",
      "Epoch 910/1000\n",
      "32/32 [==============================] - 0s 179us/step - loss: 8.9356e-05 - val_loss: 4.9223e-05\n",
      "Epoch 911/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9072e-05 - val_loss: 4.9261e-05\n",
      "Epoch 912/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.8789e-05 - val_loss: 4.9296e-05\n",
      "Epoch 913/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 8.8509e-05 - val_loss: 4.9332e-05\n",
      "Epoch 914/1000\n",
      "32/32 [==============================] - 0s 162us/step - loss: 8.8234e-05 - val_loss: 4.9367e-05\n",
      "Epoch 915/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.7954e-05 - val_loss: 4.9405e-05\n",
      "Epoch 916/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.7680e-05 - val_loss: 4.9439e-05\n",
      "Epoch 917/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7407e-05 - val_loss: 4.9479e-05\n",
      "Epoch 918/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 8.7139e-05 - val_loss: 4.9515e-05\n",
      "Epoch 919/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 8.6869e-05 - val_loss: 4.9553e-05\n",
      "Epoch 920/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.6596e-05 - val_loss: 4.9591e-05\n",
      "Epoch 921/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.6336e-05 - val_loss: 4.9622e-05\n",
      "Epoch 922/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.6067e-05 - val_loss: 4.9660e-05\n",
      "Epoch 923/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.5805e-05 - val_loss: 4.9699e-05\n",
      "Epoch 924/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 8.5542e-05 - val_loss: 4.9738e-05\n",
      "Epoch 925/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5285e-05 - val_loss: 4.9782e-05\n",
      "Epoch 926/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5024e-05 - val_loss: 4.9814e-05\n",
      "Epoch 927/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 8.4769e-05 - val_loss: 4.9852e-05\n",
      "Epoch 928/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.4516e-05 - val_loss: 4.9897e-05\n",
      "Epoch 929/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.4261e-05 - val_loss: 4.9927e-05\n",
      "Epoch 930/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.4008e-05 - val_loss: 4.9964e-05\n",
      "Epoch 931/1000\n",
      "32/32 [==============================] - 0s 138us/step - loss: 8.3756e-05 - val_loss: 5.0002e-05\n",
      "Epoch 932/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.3506e-05 - val_loss: 5.0043e-05\n",
      "Epoch 933/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.3259e-05 - val_loss: 5.0087e-05\n",
      "Epoch 934/1000\n",
      "32/32 [==============================] - 0s 137us/step - loss: 8.3018e-05 - val_loss: 5.0119e-05\n",
      "Epoch 935/1000\n",
      "32/32 [==============================] - 0s 173us/step - loss: 8.2771e-05 - val_loss: 5.0156e-05\n",
      "Epoch 936/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2528e-05 - val_loss: 5.0192e-05\n",
      "Epoch 937/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2286e-05 - val_loss: 5.0232e-05\n",
      "Epoch 938/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.2044e-05 - val_loss: 5.0271e-05\n",
      "Epoch 939/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.1809e-05 - val_loss: 5.0311e-05\n",
      "Epoch 940/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.1568e-05 - val_loss: 5.0351e-05\n",
      "Epoch 941/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.1336e-05 - val_loss: 5.0379e-05\n",
      "Epoch 942/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.1096e-05 - val_loss: 5.0426e-05\n",
      "Epoch 943/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0865e-05 - val_loss: 5.0466e-05\n",
      "Epoch 944/1000\n",
      "32/32 [==============================] - 0s 178us/step - loss: 8.0633e-05 - val_loss: 5.0508e-05\n",
      "Epoch 945/1000\n",
      "32/32 [==============================] - 0s 164us/step - loss: 8.0407e-05 - val_loss: 5.0542e-05\n",
      "Epoch 946/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.0177e-05 - val_loss: 5.0577e-05\n",
      "Epoch 947/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.9947e-05 - val_loss: 5.0616e-05\n",
      "Epoch 948/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 7.9722e-05 - val_loss: 5.0660e-05\n",
      "Epoch 949/1000\n",
      "32/32 [==============================] - 0s 165us/step - loss: 7.9497e-05 - val_loss: 5.0692e-05\n",
      "Epoch 950/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9273e-05 - val_loss: 5.0730e-05\n",
      "Epoch 951/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9052e-05 - val_loss: 5.0770e-05\n",
      "Epoch 952/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.8831e-05 - val_loss: 5.0814e-05\n",
      "Epoch 953/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.8611e-05 - val_loss: 5.0854e-05\n",
      "Epoch 954/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 7.8393e-05 - val_loss: 5.0884e-05\n",
      "Epoch 955/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 7.8177e-05 - val_loss: 5.0921e-05\n",
      "Epoch 956/1000\n",
      "32/32 [==============================] - 0s 176us/step - loss: 7.7961e-05 - val_loss: 5.0965e-05\n",
      "Epoch 957/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7747e-05 - val_loss: 5.1006e-05\n",
      "Epoch 958/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7533e-05 - val_loss: 5.1043e-05\n",
      "Epoch 959/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7321e-05 - val_loss: 5.1077e-05\n",
      "Epoch 960/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.7110e-05 - val_loss: 5.1119e-05\n",
      "Epoch 961/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 7.6900e-05 - val_loss: 5.1157e-05\n",
      "Epoch 962/1000\n",
      "32/32 [==============================] - 0s 165us/step - loss: 7.6692e-05 - val_loss: 5.1198e-05\n",
      "Epoch 963/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 7.6487e-05 - val_loss: 5.1238e-05\n",
      "Epoch 964/1000\n",
      "32/32 [==============================] - 0s 168us/step - loss: 7.6281e-05 - val_loss: 5.1275e-05\n",
      "Epoch 965/1000\n",
      "32/32 [==============================] - 0s 130us/step - loss: 7.6078e-05 - val_loss: 5.1316e-05\n",
      "Epoch 966/1000\n",
      "32/32 [==============================] - 0s 158us/step - loss: 7.5875e-05 - val_loss: 5.1356e-05\n",
      "Epoch 967/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5673e-05 - val_loss: 5.1394e-05\n",
      "Epoch 968/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5474e-05 - val_loss: 5.1430e-05\n",
      "Epoch 969/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5273e-05 - val_loss: 5.1469e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 970/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.5074e-05 - val_loss: 5.1512e-05\n",
      "Epoch 971/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4881e-05 - val_loss: 5.1553e-05\n",
      "Epoch 972/1000\n",
      "32/32 [==============================] - 0s 130us/step - loss: 7.4685e-05 - val_loss: 5.1587e-05\n",
      "Epoch 973/1000\n",
      "32/32 [==============================] - 0s 175us/step - loss: 7.4486e-05 - val_loss: 5.1621e-05\n",
      "Epoch 974/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4290e-05 - val_loss: 5.1661e-05\n",
      "Epoch 975/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 7.4100e-05 - val_loss: 5.1699e-05\n",
      "Epoch 976/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 7.3907e-05 - val_loss: 5.1748e-05\n",
      "Epoch 977/1000\n",
      "32/32 [==============================] - 0s 162us/step - loss: 7.3720e-05 - val_loss: 5.1791e-05\n",
      "Epoch 978/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3530e-05 - val_loss: 5.1820e-05\n",
      "Epoch 979/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3339e-05 - val_loss: 5.1858e-05\n",
      "Epoch 980/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3155e-05 - val_loss: 5.1897e-05\n",
      "Epoch 981/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2969e-05 - val_loss: 5.1935e-05\n",
      "Epoch 982/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.2784e-05 - val_loss: 5.1978e-05\n",
      "Epoch 983/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2601e-05 - val_loss: 5.2013e-05\n",
      "Epoch 984/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2419e-05 - val_loss: 5.2053e-05\n",
      "Epoch 985/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 7.2235e-05 - val_loss: 5.2092e-05\n",
      "Epoch 986/1000\n",
      "32/32 [==============================] - 0s 165us/step - loss: 7.2057e-05 - val_loss: 5.2129e-05\n",
      "Epoch 987/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1876e-05 - val_loss: 5.2172e-05\n",
      "Epoch 988/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1699e-05 - val_loss: 5.2207e-05\n",
      "Epoch 989/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.1523e-05 - val_loss: 5.2242e-05\n",
      "Epoch 990/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1346e-05 - val_loss: 5.2285e-05\n",
      "Epoch 991/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 7.1171e-05 - val_loss: 5.2328e-05\n",
      "Epoch 992/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0996e-05 - val_loss: 5.2361e-05\n",
      "Epoch 993/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 7.0825e-05 - val_loss: 5.2402e-05\n",
      "Epoch 994/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0649e-05 - val_loss: 5.2434e-05\n",
      "Epoch 995/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.0477e-05 - val_loss: 5.2476e-05\n",
      "Epoch 996/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.0307e-05 - val_loss: 5.2515e-05\n",
      "Epoch 997/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.0141e-05 - val_loss: 5.2555e-05\n",
      "Epoch 998/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.9971e-05 - val_loss: 5.2591e-05\n",
      "Epoch 999/1000\n",
      "32/32 [==============================] - 0s 168us/step - loss: 6.9802e-05 - val_loss: 5.2626e-05\n",
      "Epoch 1000/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9636e-05 - val_loss: 5.2670e-05\n",
      "0.0001340738672297448\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 0.28087384,  0.406483  ,  0.13724387,  0.95592755,  0.407868  ,\n",
       "         -0.60154533,  0.10206072, -0.20238079, -1.1041923 ,  0.24763638],\n",
       "        [-0.9669209 ,  0.03169855, -1.2415669 , -0.3425579 , -0.54937434,\n",
       "         -0.3668389 , -0.42208496,  1.972765  ,  0.49491808, -0.44845665],\n",
       "        [ 1.0381293 ,  0.43886545,  0.40161824,  0.26361358, -0.8454036 ,\n",
       "         -1.1648798 , -0.64350915, -0.76367366, -0.23929536, -0.24984089]],\n",
       "       dtype=float32),\n",
       " array([-0.18567239, -0.19960202, -0.4747588 , -0.39614034,  0.44003484,\n",
       "        -0.5078565 , -0.14193599,  0.3229062 ,  0.35802522,  0.36925665],\n",
       "       dtype=float32),\n",
       " array([[-0.19537196, -0.23077053, -0.05636588, -0.42498633,  0.5060052 ,\n",
       "          0.3231616 , -0.02683786,  0.46024093, -0.1698411 ,  0.00524977,\n",
       "         -0.2989134 , -0.51179147, -0.31882367,  0.8523579 , -0.57084537],\n",
       "        [-0.51346296, -0.58529073, -0.02220993, -0.05467043, -0.31122902,\n",
       "         -0.19538184, -0.2086527 , -0.09757219,  0.58176947, -0.01823435,\n",
       "          0.4098846 , -0.06436362, -0.04742014,  0.03835951, -0.5000402 ],\n",
       "        [-0.43921164, -0.3681185 , -0.2666925 ,  0.40465325, -0.39941758,\n",
       "          0.34656927, -0.2994952 , -0.3925528 ,  0.40540618,  0.08547107,\n",
       "          0.41319066,  0.5636793 ,  0.3619379 ,  0.02626503, -0.0152447 ],\n",
       "        [-0.09636358,  0.26144263,  0.42376527,  0.33920494,  0.42573926,\n",
       "         -0.02100564,  0.5249755 , -0.26222792, -0.04652944,  0.01138546,\n",
       "          0.27020335,  0.23353657, -0.33121747, -0.19680771, -0.26695836],\n",
       "        [ 0.6444319 ,  0.48605576,  0.3329639 , -0.10956048, -0.24822676,\n",
       "         -0.2432809 , -0.46710706, -0.33160397, -0.06920669, -0.00609629,\n",
       "         -0.6150961 , -0.02682306,  0.0206522 ,  0.6332188 , -0.11495157],\n",
       "        [-0.11253316, -0.16393217, -0.3965865 ,  0.74669635,  0.31753302,\n",
       "          0.47997072, -0.07104497,  0.23120542,  0.36222214,  0.5844162 ,\n",
       "          0.5159275 ,  0.09224833, -0.50661117, -0.19560418, -0.33688468],\n",
       "        [-0.560331  , -0.43610096,  0.01744487, -0.4190255 , -0.18438695,\n",
       "          0.1522491 , -0.28820834,  0.04923084,  0.07633739,  0.11661709,\n",
       "          0.5355309 ,  0.00828738,  0.17867789,  0.5779698 , -0.15759544],\n",
       "        [ 0.16568883,  0.2111184 ,  0.2800603 ,  0.3531651 ,  0.31272674,\n",
       "         -0.37004367,  0.12806463,  0.15938808, -0.14357384,  0.3626253 ,\n",
       "          0.39098588,  0.01568118, -0.5269154 ,  0.20521241, -0.5032645 ],\n",
       "        [-0.00920055, -0.29194713,  0.11178459, -0.18170513,  0.16535076,\n",
       "         -0.24463831, -0.15348285,  0.43635938, -0.21104504,  0.62231696,\n",
       "          0.2210935 , -0.21490175, -0.14582182,  0.3391615 , -0.03482896],\n",
       "        [-0.07863782,  0.42526978, -0.31706762, -0.29713634, -0.49770942,\n",
       "         -0.39235285, -0.28461435, -0.14192322,  0.14168485, -0.19087465,\n",
       "         -0.2885296 , -0.03319049, -0.063122  , -0.12303966, -0.21021166]],\n",
       "       dtype=float32),\n",
       " array([ 0.64235294,  0.6008658 ,  0.42775813, -0.6895246 , -0.67850417,\n",
       "        -0.677785  , -0.630058  ,  0.00099323, -0.6486663 , -0.49589586,\n",
       "        -0.63270766,  0.13985339,  0.4843318 , -0.31778306,  0.625485  ],\n",
       "       dtype=float32),\n",
       " array([[ 0.56346565],\n",
       "        [ 0.44756982],\n",
       "        [ 0.16653597],\n",
       "        [-0.7210768 ],\n",
       "        [-0.65047294],\n",
       "        [-0.6499058 ],\n",
       "        [-0.41116095],\n",
       "        [-0.0137547 ],\n",
       "        [-0.49379086],\n",
       "        [-0.21454443],\n",
       "        [-0.50186807],\n",
       "        [ 0.01662074],\n",
       "        [ 0.18066901],\n",
       "        [-0.03551944],\n",
       "        [ 0.35675946]], dtype=float32),\n",
       " array([0.74507636], dtype=float32)]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_challenger, history_challenger, evaluate_challenger=NN_model_structure_regression_6(X_train_challenger, X_val_challenger, Y_train_challenger, Y_val_challenger, adam2, 32, 1000, x_test_challenger, y_test_challenger)\n",
    "model_challenger.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_challenger.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_challenger_structure6.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
