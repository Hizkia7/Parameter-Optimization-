{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import seaborn as sns\n",
    "from random import seed\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import  MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, LSTM, BatchNormalization\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras import callbacks\n",
    "from keras import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate Dataset\n",
    "#Airfoil Self-Noise\n",
    "df_airfoil=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Airfoil_self_noise.csv')\n",
    "\n",
    "#Automobile\n",
    "df_automobile=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Automobile_data.txt')\n",
    "\n",
    "#Autompg\n",
    "df_autompg=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Auto-mpg.csv')\n",
    "\n",
    "#ChallengerUSA\n",
    "df_challenger=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Challenger USA Space Shuttle O-Ring.csv')\n",
    "\n",
    "#Combine Cycle Power\n",
    "df_combine=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Combine Cycle Power Plant.csv')\n",
    "\n",
    "#Computer Hardware\n",
    "df_computer=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Computer Hardware.csv')\n",
    "\n",
    "#Concrete Compressive Strength\n",
    "df_concrete_compressive_strength=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Concrete Compressive Strength.csv')\n",
    "\n",
    "#Concrete Slump Test\n",
    "df_concrete1=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Concrete Slump Test.csv')\n",
    "df_concrete2=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Concrete Slump Test.csv')\n",
    "df_concrete3=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Concrete Slump Test.csv')\n",
    "\n",
    "#Energy Efficiency\n",
    "df_energy1=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Energy Efficiency.csv')\n",
    "df_energy2=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Energy Efficiency.csv')\n",
    "\n",
    "#Fertility Diagnosis\n",
    "df_fertility=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\fertility_Diagnosis.csv')\n",
    "\n",
    "#Forest Fires\n",
    "df_forest=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\forestfires.csv')\n",
    "\n",
    "#Housing\n",
    "df_housing=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Housing.csv')\n",
    "\n",
    "#Istanbul Stock Exchange\n",
    "df_istanbul=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Istanbul Stock Exchange.csv')\n",
    "\n",
    "#WDBC\n",
    "df_wdbc=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\wdbc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:66: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#remove Nan columns of df_energy1\n",
    "df_energy1=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Energy Efficiency.csv')\n",
    "df_energy1.drop(df_energy1.columns[11],inplace=True, axis = 1)\n",
    "df_energy1.drop(df_energy1.columns[10],inplace=True, axis = 1)\n",
    "\n",
    "#remove Nan columns of df_energy2\n",
    "df_energy2=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Energy Efficiency.csv')\n",
    "df_energy2.drop(df_energy2.columns[11],inplace=True, axis = 1)\n",
    "df_energy2.drop(df_energy2.columns[10],inplace=True, axis = 1)\n",
    "\n",
    "#remove question marks\n",
    "#df_automobile\n",
    "imp= Imputer(missing_values=\"NaN\", strategy=\"mean\")\n",
    "df_automobile=df_automobile.replace(\"?\", np.NaN)\n",
    "df_automobile['num-of-doors'] = df_automobile['num-of-doors'].fillna(\"four\")\n",
    "for i in df_automobile.columns:\n",
    "    if df_automobile[i].isnull().sum()>0:\n",
    "        df_automobile[i]=imp.fit_transform(df_automobile[[i]])\n",
    "#df_automobile = df_automobile[(df_automobile.astype(str) != '?').all(axis=1)]\n",
    "#df_automobile.reset_index(drop=True, inplace=True)\n",
    "df_automobile = df_automobile.drop(['engine-location'], axis=1)\n",
    "#df_autompg\n",
    "df_autompg = df_autompg[(df_autompg.astype(str) != '?').all(axis=1)]\n",
    "df_autompg.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#convert string to number\n",
    "le=LabelEncoder()\n",
    "#df_automobile\n",
    "string_automobile=df_automobile[['make','fuel-type','aspiration','num-of-doors', 'body-style', 'drive-wheels', 'engine-type', 'num-of-cylinders', 'fuel-system']]\n",
    "df_automobile[['make','fuel-type','aspiration','num-of-doors', 'body-style', 'drive-wheels', 'engine-type', 'num-of-cylinders', 'fuel-system']]=string_automobile.apply(le.fit_transform)\n",
    "encoder=df_automobile[['make','fuel-type','aspiration','num-of-doors', 'body-style', 'drive-wheels', 'engine-type', 'num-of-cylinders', 'fuel-system']].astype(np.int64)\n",
    "df_automobile[['make','fuel-type','aspiration','num-of-doors', 'body-style', 'drive-wheels', 'engine-type', 'num-of-cylinders', 'fuel-system']]=encoder\n",
    "a=df_automobile[['normalized-losses','horsepower','price']].astype(np.int64)\n",
    "b=df_automobile[['bore','stroke','peak-rpm']].astype(float)\n",
    "df_automobile[['normalized-losses','horsepower','price']]=a\n",
    "df_automobile[['bore','stroke','peak-rpm']]=b\n",
    "#df_computer\n",
    "string_computer=df_computer[['Vendor','Model']]\n",
    "df_computer[['Vendor','Model']]=string_computer.apply(le.fit_transform)\n",
    "df_computer[['Vendor','Model']]=df_computer[['Vendor','Model']].astype(np.int64)\n",
    "\n",
    "#dropna spesific column & special preprocessing\n",
    "#df_forest\n",
    "df_forest=df_forest[(df_forest['area'].astype(int) != 0)] \n",
    "df_forest.reset_index(drop=True, inplace=True)\n",
    "num_features=10\n",
    "dimension=(num_features+1)*9+10\n",
    "population_size=(2*dimension+1)*2\n",
    "df_forest=df_forest[:population_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_data1(df,num_features):\n",
    "    dimension=(num_features+1)*9+10\n",
    "    population_size=(2*dimension+1)*2\n",
    "    df=df.dropna()\n",
    "    df=df[:population_size]\n",
    "    df\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection(df):\n",
    "    cor=df.corr()\n",
    "    plt.figure(figsize=(100,50))\n",
    "    sns.set(font_scale=3)\n",
    "    sns.heatmap(cor, annot=True, cmap=plt.cm.Blues)\n",
    "    plt.show()\n",
    "    return cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split1(x, y):\n",
    "    x_train, x_test, y_train, y_test= train_test_split(x, y, test_size=0.15, random_state=42)\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_data2(df):\n",
    "    train_size = 0.85*len(df)\n",
    "    train_size = int(train_size)\n",
    "    df_train = df[:train_size]\n",
    "    df_test = df[train_size:]\n",
    "    print(len(df_test))\n",
    "    print(len(df_train))\n",
    "    validation_size=len(df_test)/len(df_train)\n",
    "    print(validation_size)\n",
    "    return df_train, df_test, validation_size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#df_airfoil=preprocessing_data1(df_airfoil,5)\n",
    "#df_automobile=preprocessing_data1(df_automobile,22)\n",
    "#df_autompg=preprocessing_data1(df_autompg,7)\n",
    "#df_challenger=preprocessing_data1(df_challenger,3)\n",
    "#df_combine=preprocessing_data1(df_combine,4)\n",
    "#df_computer=preprocessing_data1(df_computer,9)\n",
    "#df_concrete_compressive_strength=preprocessing_data1(df_concrete_compressive_strength,8)\n",
    "#df_concrete1=preprocessing_data1(df_concrete1,7)\n",
    "#df_concrete2=preprocessing_data1(df_concrete2,7)\n",
    "#df_concrete3=preprocessing_data1(df_concrete3,7)\n",
    "#df_energy1=preprocessing_data1(df_energy1,8)\n",
    "#df_energy2=preprocessing_data1(df_energy2,8)\n",
    "\n",
    "#df_fertility=preprocessing_data1(df_fertility,9)\n",
    "for i in df_fertility:\n",
    "    df_fertility.Diagnosis[df_fertility.Diagnosis == 'N'] = 1\n",
    "    df_fertility.Diagnosis[df_fertility.Diagnosis == 'O'] = 2\n",
    "df_fertility['Diagnosis']=df_fertility['Diagnosis'].astype(np.int64)\n",
    "\n",
    "#df_forest=preprocessing_data1(df_forest,10)\n",
    "#df_housing=preprocessing_data1(df_housing,13)\n",
    "\n",
    "#df_istanbul=preprocessing_data1(df_istanbul,7)\n",
    "new_header = df_istanbul.iloc[0]\n",
    "df_istanbul = df_istanbul[1:]\n",
    "df_istanbul.columns = new_header\n",
    "df_istanbul[['ISE1','ISE2','SP','DAX','FTSE','NIKKEI','BOVESPA','EU','EM']]=df_istanbul[['ISE1','ISE2','SP','DAX','FTSE','NIKKEI','BOVESPA','EU','EM']].astype(np.float64)\n",
    "\n",
    "\n",
    "#df_wdbc=preprocessing_data1(df_wdbc,10)\n",
    "df_wdbc.drop(df_wdbc.columns[0], axis=1, inplace = True)\n",
    "df_wdbc.columns=['id','diagnosis','radius_mean','texture_mean','perimeter_mean','area_mean','smoothness_mean','compactness_mean','concavity_mean','concave points_mean','symmetry_mean','fractal_dimension_mean','radius_se','texture_se','perimeter_se','area_se','smoothness_se','compactness_se','concavity_se','concave points_se','symmetry_se','fractal_dimension_se','radius_worst','texture_worst','perimeter_worst','area_worst','smoothness_worst','compactness_worst','concavity_worst','concave points_worst','symmetry_worst','fractal_dimension_worst']\n",
    "for i in df_wdbc:\n",
    "    df_wdbc.diagnosis[df_wdbc.diagnosis == 'M'] = 1\n",
    "    df_wdbc.diagnosis[df_wdbc.diagnosis == 'B'] = 2\n",
    "df_wdbc['diagnosis']=df_wdbc['diagnosis'].astype(np.object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Frequency  Angle of Attack  Chord length  Free-stream velocity  \\\n",
      "0        800              0.0        0.3048                  71.3   \n",
      "1       1000              0.0        0.3048                  71.3   \n",
      "2       1250              0.0        0.3048                  71.3   \n",
      "3       1600              0.0        0.3048                  71.3   \n",
      "4       2000              0.0        0.3048                  71.3   \n",
      "\n",
      "   Suction side displacement thickness  Scaled sound pressure level  \n",
      "0                             0.002663                      126.201  \n",
      "1                             0.002663                      125.201  \n",
      "2                             0.002663                      125.951  \n",
      "3                             0.002663                      127.591  \n",
      "4                             0.002663                      127.461  \n",
      "    Mpg  Cylinders  Displacement Horsepower  Weight  Acceleration  Model Year  \\\n",
      "0  18.0          8         307.0        130    3504          12.0          70   \n",
      "1  15.0          8         350.0        165    3693          11.5          70   \n",
      "2  18.0          8         318.0        150    3436          11.0          70   \n",
      "3  16.0          8         304.0        150    3433          12.0          70   \n",
      "4  17.0          8         302.0        140    3449          10.5          70   \n",
      "\n",
      "   Origin                   Car Name  \n",
      "0       1  chevrolet chevelle malibu  \n",
      "1       1          buick skylark 320  \n",
      "2       1         plymouth satellite  \n",
      "3       1              amc rebel sst  \n",
      "4       1                ford torino  \n",
      "   symboling  normalized-losses  make  fuel-type  aspiration  num-of-doors  \\\n",
      "0          3                122     0          1           0             1   \n",
      "1          3                122     0          1           0             1   \n",
      "2          1                122     0          1           0             1   \n",
      "3          2                164     1          1           0             0   \n",
      "4          2                164     1          1           0             0   \n",
      "\n",
      "   body-style  drive-wheels  wheel-base  length  ...  engine-size  \\\n",
      "0           0             2        88.6   168.8  ...          130   \n",
      "1           0             2        88.6   168.8  ...          130   \n",
      "2           2             2        94.5   171.2  ...          152   \n",
      "3           3             1        99.8   176.6  ...          109   \n",
      "4           3             0        99.4   176.6  ...          136   \n",
      "\n",
      "   fuel-system  bore  stroke  compression-ratio  horsepower  peak-rpm  \\\n",
      "0            5  3.47    2.68                9.0         111    5000.0   \n",
      "1            5  3.47    2.68                9.0         111    5000.0   \n",
      "2            5  2.68    3.47                9.0         154    5000.0   \n",
      "3            5  3.19    3.40               10.0         102    5500.0   \n",
      "4            5  3.19    3.40                8.0         115    5500.0   \n",
      "\n",
      "   city-mpg  highway-mpg  price  \n",
      "0        21           27  13495  \n",
      "1        21           27  16500  \n",
      "2        19           26  16500  \n",
      "3        24           30  13950  \n",
      "4        18           22  17450  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "   Number of O-rings  Thermal Distress  Launch Temperature  \\\n",
      "0                  6                 0                  66   \n",
      "1                  6                 1                  70   \n",
      "2                  6                 0                  69   \n",
      "3                  6                 0                  68   \n",
      "4                  6                 0                  67   \n",
      "\n",
      "   Leak-Check Pressure  Temporal Order of Flight  \n",
      "0                   50                         1  \n",
      "1                   50                         2  \n",
      "2                   50                         3  \n",
      "3                   50                         4  \n",
      "4                   50                         5  \n"
     ]
    }
   ],
   "source": [
    "print(df_airfoil.head())\n",
    "print(df_autompg.head())\n",
    "print(df_automobile.head())\n",
    "print(df_challenger.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:62: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#Train and Test 17 datasets\n",
    "#Airfoil\n",
    "x_airfoil = df_airfoil.drop(['Scaled sound pressure level'], axis = 1)\n",
    "y_airfoil = df_airfoil['Scaled sound pressure level']\n",
    "#Wdbc\n",
    "x_wdbc = df_wdbc[['radius_mean','perimeter_mean','area_mean','concavity_mean','concave points_mean','radius_worst','perimeter_worst','area_worst','concave points_worst']]\n",
    "y_wdbc = df_wdbc['diagnosis']\n",
    "labelencoder_Y = LabelEncoder()\n",
    "y_wdbc = labelencoder_Y.fit_transform(y_wdbc)\n",
    "#Automobile\n",
    "x_automobile = df_automobile.drop(['price','make','body-style'], axis = 1)\n",
    "y_automobile = df_automobile['price']\n",
    "y_automobile = np.reshape(y_automobile.values, (-1,1))\n",
    "#Autompg\n",
    "x_autompg = df_autompg.drop(['Mpg','Car Name'], axis = 1)\n",
    "y_autompg = df_autompg['Mpg']\n",
    "#Challenger\n",
    "x_challenger = df_challenger.drop(['Number of O-rings','Temporal Order of Flight'], axis = 1)\n",
    "y_challenger = df_challenger['Number of O-rings']\n",
    "#Combine\n",
    "x_combine = df_combine.drop(['PE'], axis = 1)\n",
    "y_combine = df_combine['PE']\n",
    "y_combine = np.reshape(y_combine.values, (-1,1))\n",
    "#Computer\n",
    "x_computer = df_computer.drop(['ERP'], axis = 1)\n",
    "y_computer = df_computer['ERP']\n",
    "y_computer = np.reshape(y_computer.values, (-1,1))\n",
    "#Concrete_compressive_strength\n",
    "x_concrete_compressive_strength = df_concrete_compressive_strength.drop(['CCS'], axis = 1)\n",
    "y_concrete_compressive_strength = df_concrete_compressive_strength['CCS']\n",
    "y_concrete_compressive_strength = np.reshape(y_concrete_compressive_strength.values, (-1,1))\n",
    "#Concrete1\n",
    "x_concrete1 = df_concrete1.drop(['No','Compressive Strength (28-day)(Mpa)'], axis = 1)\n",
    "y_concrete1 = df_concrete1['Compressive Strength (28-day)(Mpa)']\n",
    "#Concrete2\n",
    "x_concrete2 = df_concrete2.drop(['No','SLUMP(cm)'], axis = 1)\n",
    "y_concrete2 = df_concrete2['SLUMP(cm)']\n",
    "y_concrete2 = np.reshape(y_concrete2.values, (-1,1))\n",
    "#Concrete3\n",
    "x_concrete3 = df_concrete3.drop(['No','FLOW(cm)'], axis = 1)\n",
    "y_concrete3 = df_concrete3['FLOW(cm)']\n",
    "y_concrete3 = np.reshape(y_concrete3.values, (-1,1))\n",
    "#Energy1\n",
    "x_energy1 = df_energy1.drop(['Y1'], axis = 1)\n",
    "y_energy1 = df_energy1['Y1']\n",
    "#Energy2\n",
    "x_energy2 = df_energy2.drop(['Y2'], axis = 1)\n",
    "y_energy2 = df_energy2['Y2']\n",
    "#Fertility\n",
    "x_fertility = df_fertility.drop(['Diagnosis'], axis = 1)\n",
    "y_fertility = df_fertility['Diagnosis']\n",
    "#Forest\n",
    "x_forest = df_forest.drop(['month','day','area'], axis = 1)\n",
    "y_forest = df_forest['area']\n",
    "y_forest = np.reshape(y_forest.values, (-1,1))\n",
    "#Housing\n",
    "x_housing = df_housing.drop(['MEDV'], axis = 1)\n",
    "y_housing = df_housing['MEDV']\n",
    "#Istanbul\n",
    "x_istanbul = df_istanbul.drop(['date','ISE1','ISE2'], axis = 1)\n",
    "y_istanbul = df_istanbul[['ISE1','ISE2']]\n",
    "y_istanbul['mean'] = y_istanbul.mean(axis=1)\n",
    "y_istanbul = y_istanbul['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_airfoil, x_test_airfoil, y_train_airfoil, y_test_airfoil = train_test_split1(x_airfoil, y_airfoil)\n",
    "x_train_automobile, x_test_automobile, y_train_automobile, y_test_automobile = train_test_split1(x_automobile, y_automobile)\n",
    "x_train_autompg, x_test_autompg, y_train_autompg, y_test_autompg = train_test_split1(x_autompg, y_autompg)\n",
    "x_train_challenger, x_test_challenger, y_train_challenger, y_test_challenger = train_test_split1(x_challenger, y_challenger)\n",
    "x_train_combine, x_test_combine, y_train_combine, y_test_combine = train_test_split1(x_combine, y_combine)\n",
    "x_train_computer, x_test_computer, y_train_computer, y_test_computer = train_test_split1(x_computer, y_computer)\n",
    "x_train_concrete_compressive_strength, x_test_concrete_compressive_strength, y_train_concrete_compressive_strength, y_test_concrete_compressive_strength = train_test_split1(x_concrete_compressive_strength, y_concrete_compressive_strength)\n",
    "x_train_concrete1, x_test_concrete1, y_train_concrete1, y_test_concrete1 = train_test_split1(x_concrete1, y_concrete1)\n",
    "x_train_concrete2, x_test_concrete2, y_train_concrete2, y_test_concrete2 = train_test_split1(x_concrete2, y_concrete2)\n",
    "x_train_concrete3, x_test_concrete3, y_train_concrete3, y_test_concrete3 = train_test_split1(x_concrete3, y_concrete3)\n",
    "x_train_energy1, x_test_energy1, y_train_energy1, y_test_energy1 = train_test_split1(x_energy1, y_energy1)\n",
    "x_train_energy2, x_test_energy2, y_train_energy2, y_test_energy2 = train_test_split1(x_energy2, y_energy2)\n",
    "x_train_fertility, x_test_fertility, y_train_fertility, y_test_fertility = train_test_split1(x_fertility, y_fertility)\n",
    "x_train_forest, x_test_forest, y_train_forest, y_test_forest = train_test_split1(x_forest, y_forest)\n",
    "x_train_housing, x_test_housing, y_train_housing, y_test_housing = train_test_split1(x_housing, y_housing)\n",
    "x_train_istanbul, x_test_istanbul, y_train_istanbul, y_test_istanbul = train_test_split1(x_istanbul, y_istanbul)\n",
    "x_train_wdbc, x_test_wdbc, y_train_wdbc, y_test_wdbc = train_test_split1(x_wdbc, y_wdbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_split(x_train, y_train):\n",
    "    X_train, X_val, Y_train, Y_val= train_test_split(x_train, y_train, test_size=0.176, random_state=42)\n",
    "    return X_train, X_val, Y_train, Y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_scaler(X_train, X_val, x_test):\n",
    "    sc=StandardScaler()\n",
    "    X_train=X_train.values\n",
    "    X_val=X_val.values\n",
    "    x_test=x_test.values\n",
    "    X_scale_train=sc.fit(X_train)\n",
    "    #X_scale_val=sc.fit(X_val)\n",
    "    #x_scale_test=sc.fit(x_test)\n",
    "    X_train=X_scale_train.transform(X_train)\n",
    "    X_val=X_scale_train.transform(X_val)\n",
    "    x_test=X_scale_train.transform(x_test)\n",
    "    return X_train, X_val, x_test, X_scale_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_scaler_automobile(X_train, X_val, x_test, Y_train, Y_val, y_test):\n",
    "    minmax_x=MinMaxScaler()\n",
    "    minmax_y=MinMaxScaler()\n",
    "    X_train=X_train.values\n",
    "    X_val=X_val.values\n",
    "    x_test=x_test.values\n",
    "    X_scale_train=minmax_x.fit(X_train)\n",
    "    #X_scale_val=min_max.fit(X_val)\n",
    "    #x_scale_test=min_max.fit(x_test)\n",
    "    Y_scale_train=minmax_y.fit(Y_train)\n",
    "    #Y_scale_val=min_max.fit(Y_val)\n",
    "    #y_scale_test=min_max.fit(y_test)\n",
    "    X_train=X_scale_train.transform(X_train)\n",
    "    X_val=X_scale_train.transform(X_val)\n",
    "    x_test=X_scale_train.transform(x_test)\n",
    "    Y_train=Y_scale_train.transform(Y_train)\n",
    "    Y_val=Y_scale_train.transform(Y_val)\n",
    "    y_test=Y_scale_train.transform(y_test)\n",
    "    return X_train, X_val, x_test, Y_train, Y_val, y_test, X_scale_train, Y_scale_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_scaler(X_train, X_val, x_test, Y_train, Y_val, y_test):\n",
    "    min_max=MinMaxScaler()\n",
    "    X_train=X_train.values\n",
    "    X_val=X_val.values\n",
    "    x_test=x_test.values\n",
    "    X_scale_train=min_max.fit(X_train)\n",
    "    X_scale_val=min_max.fit(X_val)\n",
    "    x_scale_test=min_max.fit(x_test)\n",
    "    Y_scale_train=min_max.fit(Y_train)\n",
    "    Y_scale_val=min_max.fit(Y_val)\n",
    "    y_scale_test=min_max.fit(y_test)\n",
    "    X_train=X_scale_train.transform(X_train)\n",
    "    X_val=X_scale_val.transform(X_val)\n",
    "    x_test=x_scale_test.transform(x_test)\n",
    "    Y_train=Y_scale_train.transform(Y_train)\n",
    "    Y_val=Y_scale_train.transform(Y_val)\n",
    "    y_test=y_scale_test.transform(y_test)\n",
    "    return X_train, X_val, x_test, Y_train, Y_val, y_test, min_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(X_train, X_val, x_test, Y_train, Y_val, y_test):\n",
    "    normalizer=Normalizer()\n",
    "    X_train=normalizer.fit_transform(X_train)\n",
    "    X_val=normalizer.fit_transform(X_val)\n",
    "    x_test=normalizer.fit_transform(x_test)\n",
    "    Y_train=normalizer.fit_transform(Y_train)\n",
    "    Y_val=normalizer.fit_transform(Y_val)\n",
    "    y_test=normalizer.fit_transform(y_test)\n",
    "    return X_train, X_val, x_test, Y_train, Y_val, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimizer list\n",
    "adam0 = optimizers.Adam(lr=0.1)\n",
    "adam1 = optimizers.Adam(lr=0.001)\n",
    "adam2 = optimizers.Adam(lr=0.01)\n",
    "adam3 = optimizers.Adam(lr=0.0001)\n",
    "adam4 = optimizers.Adam(lr=0.00001)\n",
    "sgd = optimizers.SGD(lr=0.00001, decay=1e-4, momentum=0.9, nesterov=True)\n",
    "RMSprop= optimizers.RMSprop(lr=0.01,rho=0.9)\n",
    "adagrad = optimizers.Adagrad(lr=0.01)\n",
    "adadelta = optimizers.Adadelta(lr=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_model_structure_regression_linear(X_train, X_val, Y_train, Y_val, adam, size, epochs, x_test, y_test):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units = 5, input_dim = (X_train.shape[1])))\n",
    "    model.add(Activation('tanh'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(units = 10))\n",
    "    model.add(Activation('linear'))\n",
    "    model.add(Dense(units = 1))\n",
    "    model.compile(optimizer = adam , loss = 'mse')\n",
    "    model.summary()\n",
    "    history=model.fit(X_train,Y_train, batch_size=size,epochs=epochs, validation_data=(X_val, Y_val), shuffle=True)\n",
    "    evaluate = model.evaluate(x_test, y_test, verbose=2, batch_size=size)\n",
    "    print(evaluate)\n",
    "    return model, history, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_model_structure_regression_relu(X_train, X_val, Y_train, Y_val, adam, size, epochs, x_test, y_test):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units = 5, input_dim = (X_train.shape[1])))\n",
    "    model.add(Activation('relu'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(units = 10))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(units = 1))\n",
    "    model.compile(optimizer = adam , loss = 'mse')\n",
    "    model.summary()\n",
    "    history=model.fit(X_train,Y_train, batch_size=size,epochs=epochs, validation_data=(X_val, Y_val), shuffle=True)\n",
    "    evaluate = model.evaluate(x_test, y_test, verbose=2, batch_size=size)\n",
    "    print(evaluate)\n",
    "    return model, history, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_model_structure_regression_sigmoid(X_train, X_val, Y_train, Y_val, adam, size, epochs, x_test, y_test):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units = 5, input_dim = (X_train.shape[1])))\n",
    "    model.add(Activation('relu'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(units = 10))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.add(Dense(units = 1))\n",
    "    model.compile(optimizer = adam , loss = 'mse')\n",
    "    model.summary()\n",
    "    history=model.fit(X_train,Y_train, batch_size=size,epochs=epochs, validation_data=(X_val, Y_val), shuffle=True)\n",
    "    evaluate = model.evaluate(x_test, y_test, verbose=2, batch_size=size)\n",
    "    print(evaluate)\n",
    "    return model, history, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_model_structure_regression_tanh(X_train, X_val, Y_train, Y_val, adam, size, epochs, x_test, y_test):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units = 5, input_dim = (X_train.shape[1])))\n",
    "    model.add(Activation('relu'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(units = 10))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(Dense(units = 1))\n",
    "    model.compile(optimizer = adam , loss = 'mse')\n",
    "    model.summary()\n",
    "    history=model.fit(X_train,Y_train, batch_size=size,epochs=epochs, validation_data=(X_val, Y_val), shuffle=True)\n",
    "    evaluate = model.evaluate(x_test, y_test, verbose=2, batch_size=size)\n",
    "    print(evaluate)\n",
    "    return model, history, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_airfoil, X_val_airfoil, Y_train_airfoil, Y_val_airfoil = train_val_split(x_train_airfoil, y_train_airfoil)\n",
    "X_train_automobile, X_val_automobile, Y_train_automobile, Y_val_automobile = train_val_split(x_train_automobile, y_train_automobile)\n",
    "X_train_autompg, X_val_autompg, Y_train_autompg, Y_val_autompg = train_val_split(x_train_autompg, y_train_autompg)\n",
    "X_train_challenger, X_val_challenger, Y_train_challenger, Y_val_challenger = train_val_split(x_train_challenger, y_train_challenger)\n",
    "X_train_combine, X_val_combine, Y_train_combine, Y_val_combine = train_val_split(x_train_combine, y_train_combine)\n",
    "X_train_computer, X_val_computer, Y_train_computer, Y_val_computer = train_val_split(x_train_computer, y_train_computer)\n",
    "X_train_concrete_compressive_strength, X_val_concrete_compressive_strength, Y_train_concrete_compressive_strength, Y_val_concrete_compressive_strength = train_val_split(x_train_concrete_compressive_strength, y_train_concrete_compressive_strength)\n",
    "X_train_concrete1, X_val_concrete1, Y_train_concrete1, Y_val_concrete1 = train_val_split(x_train_concrete1, y_train_concrete1)\n",
    "X_train_concrete2, X_val_concrete2, Y_train_concrete2, Y_val_concrete2 = train_val_split(x_train_concrete2, y_train_concrete2)\n",
    "X_train_concrete3, X_val_concrete3, Y_train_concrete3, Y_val_concrete3 = train_val_split(x_train_concrete3, y_train_concrete3)\n",
    "X_train_energy1, X_val_energy1, Y_train_energy1, Y_val_energy1 = train_val_split(x_train_energy1, y_train_energy1)\n",
    "X_train_energy2, X_val_energy2, Y_train_energy2, Y_val_energy2 = train_val_split(x_train_energy2, y_train_energy2)\n",
    "X_train_fertility, X_val_fertility, Y_train_fertility, Y_val_fertility = train_val_split(x_train_fertility, y_train_fertility)\n",
    "X_train_forest, X_val_forest, Y_train_forest, Y_val_forest = train_val_split(x_train_forest, y_train_forest)\n",
    "X_train_housing, X_val_housing, Y_train_housing, Y_val_housing = train_val_split(x_train_housing, y_train_housing)\n",
    "X_train_istanbul, X_val_istanbul, Y_train_istanbul, Y_val_istanbul = train_val_split(x_train_istanbul, y_train_istanbul)\n",
    "X_train_wdbc, X_val_wdbc, Y_train_wdbc, Y_val_wdbc = train_val_split(x_train_wdbc, y_train_wdbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_airfoil, X_val_airfoil, x_test_airfoil, X_scale_train_airfoil=standard_scaler(X_train_airfoil, X_val_airfoil, x_test_airfoil)\n",
    "#X_train_automobile, X_val_automobile, x_test_automobile=standard_scaler(X_train_automobile, X_val_automobile, x_test_automobile)\n",
    "#X_train_automobile, X_val_automobile, x_test_automobile, Y_train_automobile, Y_val_automobile, y_test_automobile = normalization(X_train_automobile, X_val_automobile, x_test_automobile, Y_train_automobile, Y_val_automobile, y_test_automobile)\n",
    "X_train_automobile, X_val_automobile, x_test_automobile, Y_train_automobile, Y_val_automobile, y_test_automobile, X_scale_train_automobile, Y_scale_train_automobile=min_max_scaler_automobile(X_train_automobile, X_val_automobile, x_test_automobile, Y_train_automobile, Y_val_automobile, y_test_automobile)\n",
    "X_train_autompg, X_val_autompg, x_test_autompg, X_scale_train_autompg=standard_scaler(X_train_autompg, X_val_autompg, x_test_autompg)\n",
    "X_train_challenger, X_val_challenger, x_test_challenger, X_scale_train_challenger=standard_scaler(X_train_challenger, X_val_challenger, x_test_challenger)\n",
    "X_train_combine, X_val_combine, x_test_combine, Y_train_combine, Y_val_combine, y_test_combine, min_max_combine=min_max_scaler(X_train_combine, X_val_combine, x_test_combine, Y_train_combine, Y_val_combine, y_test_combine)\n",
    "X_train_computer, X_val_computer, x_test_computer, Y_train_computer, Y_val_computer, y_test_computer, min_max_computer=min_max_scaler(X_train_computer, X_val_computer, x_test_computer, Y_train_computer, Y_val_computer, y_test_computer)\n",
    "X_train_concrete_compressive_strength, X_val_concrete_compressive_strength, x_test_concrete_compressive_strength, Y_train_concrete_compressive_strength, Y_val_concrete_compressive_strength, y_test_concrete_compressive_strength, min_max_concrete_compressive_strength=min_max_scaler(X_train_concrete_compressive_strength, X_val_concrete_compressive_strength, x_test_concrete_compressive_strength, Y_train_concrete_compressive_strength, Y_val_concrete_compressive_strength, y_test_concrete_compressive_strength)\n",
    "X_train_concrete1, X_val_concrete1, x_test_concrete1, X_scale_train_concrete1=standard_scaler(X_train_concrete1, X_val_concrete1, x_test_concrete1)\n",
    "X_train_concrete2, X_val_concrete2, x_test_concrete2, Y_train_concrete2, Y_val_concrete2, y_test_concrete2, min_max_concrete2=min_max_scaler(X_train_concrete2, X_val_concrete2, x_test_concrete2, Y_train_concrete2, Y_val_concrete2, y_test_concrete2)\n",
    "X_train_concrete3, X_val_concrete3, x_test_concrete3, Y_train_concrete3, Y_val_concrete3, y_test_concrete3, min_max_concrete3=min_max_scaler(X_train_concrete3, X_val_concrete3, x_test_concrete3, Y_train_concrete3, Y_val_concrete3, y_test_concrete3)\n",
    "X_train_energy1, X_val_energy1, x_test_energy1, X_scale_train_energy1=standard_scaler(X_train_energy1, X_val_energy1, x_test_energy1)\n",
    "X_train_energy2, X_val_energy2, x_test_energy2, X_scale_train_energy2=standard_scaler(X_train_energy2, X_val_energy2, x_test_energy2)\n",
    "X_train_fertility, X_val_fertility, x_test_fertility, X_scale_train_fertility=standard_scaler(X_train_fertility, X_val_fertility, x_test_fertility)\n",
    "X_train_forest, X_val_forest, x_test_forest, Y_train_forest, Y_val_forest, y_test_forest, min_max_forest=min_max_scaler(X_train_forest, X_val_forest, x_test_forest, Y_train_forest, Y_val_forest, y_test_forest)\n",
    "X_train_housing, X_val_housing, x_test_housing, X_scale_train_housing=standard_scaler(X_train_housing, X_val_housing, x_test_housing)\n",
    "X_train_istanbul, X_val_istanbul, x_test_istanbul, X_scale_train_istanbul=standard_scaler(X_train_istanbul, X_val_istanbul, x_test_istanbul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 101\n",
      "Trainable params: 101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 1052 samples, validate on 225 samples\n",
      "Epoch 1/1000\n",
      "1052/1052 [==============================] - 0s 418us/step - loss: 15335.8281 - val_loss: 14813.8082\n",
      "Epoch 2/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12745.5174 - val_loss: 9340.9521\n",
      "Epoch 3/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 4991.5128 - val_loss: 1071.3421\n",
      "Epoch 4/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 231.5984 - val_loss: 48.0513\n",
      "Epoch 5/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 33.5590 - val_loss: 26.2937\n",
      "Epoch 6/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 23.8334 - val_loss: 25.7704\n",
      "Epoch 7/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.9212 - val_loss: 26.0837\n",
      "Epoch 8/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 22.4475 - val_loss: 25.8088\n",
      "Epoch 9/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 22.1239 - val_loss: 26.1220\n",
      "Epoch 10/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.0189 - val_loss: 26.0504\n",
      "Epoch 11/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.1236 - val_loss: 26.2732\n",
      "Epoch 12/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 21.9091 - val_loss: 26.6561\n",
      "Epoch 13/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.0607 - val_loss: 26.2458\n",
      "Epoch 14/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.2124 - val_loss: 27.2494\n",
      "Epoch 15/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.8763 - val_loss: 26.0476\n",
      "Epoch 16/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.9897 - val_loss: 26.0085\n",
      "Epoch 17/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.7654 - val_loss: 26.2178\n",
      "Epoch 18/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 21.7873 - val_loss: 26.5811\n",
      "Epoch 19/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.8099 - val_loss: 26.5445\n",
      "Epoch 20/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.9283 - val_loss: 25.7763\n",
      "Epoch 21/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.8068 - val_loss: 26.0453\n",
      "Epoch 22/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.8311 - val_loss: 26.5196\n",
      "Epoch 23/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.8360 - val_loss: 25.7529\n",
      "Epoch 24/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 21.6532 - val_loss: 26.0914\n",
      "Epoch 25/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.7359 - val_loss: 27.6398\n",
      "Epoch 26/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 21.8432 - val_loss: 26.6036\n",
      "Epoch 27/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 21.8332 - val_loss: 26.6530\n",
      "Epoch 28/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 21.8720 - val_loss: 26.3301\n",
      "Epoch 29/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 21.6367 - val_loss: 25.7620\n",
      "Epoch 30/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 22.1479 - val_loss: 26.0468\n",
      "Epoch 31/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.4804 - val_loss: 26.5191\n",
      "Epoch 32/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.6774 - val_loss: 26.0916\n",
      "Epoch 33/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 21.7147 - val_loss: 25.7566\n",
      "Epoch 34/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.0778 - val_loss: 26.9811\n",
      "Epoch 35/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 22.0285 - val_loss: 25.4914\n",
      "Epoch 36/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.1181 - val_loss: 25.4891\n",
      "Epoch 37/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.9244 - val_loss: 26.2248\n",
      "Epoch 38/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 22.3150 - val_loss: 25.9573\n",
      "Epoch 39/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 21.6884 - val_loss: 25.6022\n",
      "Epoch 40/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.0805 - val_loss: 25.5233\n",
      "Epoch 41/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.0679 - val_loss: 25.4019\n",
      "Epoch 42/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 21.6631 - val_loss: 25.5147\n",
      "Epoch 43/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 21.8312 - val_loss: 25.7112\n",
      "Epoch 44/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.7584 - val_loss: 25.2604\n",
      "Epoch 45/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 21.7721 - val_loss: 26.6845\n",
      "Epoch 46/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.8777 - val_loss: 26.8738\n",
      "Epoch 47/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.0444 - val_loss: 25.6682\n",
      "Epoch 48/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.5197 - val_loss: 26.0608\n",
      "Epoch 49/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.9436 - val_loss: 26.4057\n",
      "Epoch 50/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.0346 - val_loss: 25.6260\n",
      "Epoch 51/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 21.7286 - val_loss: 26.7659\n",
      "Epoch 52/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 21.8236 - val_loss: 26.4247\n",
      "Epoch 53/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.8651 - val_loss: 26.2399\n",
      "Epoch 54/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.7589 - val_loss: 26.1954\n",
      "Epoch 55/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.7978 - val_loss: 26.3401\n",
      "Epoch 56/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.9729 - val_loss: 26.6045\n",
      "Epoch 57/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 22.4906 - val_loss: 26.0168\n",
      "Epoch 58/1000\n",
      "1052/1052 [==============================] - 0s 109us/step - loss: 22.7348 - val_loss: 26.3167\n",
      "Epoch 59/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 21.4623 - val_loss: 25.8539\n",
      "Epoch 60/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 21.8990 - val_loss: 26.4907\n",
      "Epoch 61/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 21.7369 - val_loss: 26.1561\n",
      "Epoch 62/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.7334 - val_loss: 25.6689\n",
      "Epoch 63/1000\n",
      "1052/1052 [==============================] - 0s 143us/step - loss: 21.7134 - val_loss: 25.7782\n",
      "Epoch 64/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 21.6646 - val_loss: 25.9241\n",
      "Epoch 65/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 99us/step - loss: 21.6102 - val_loss: 25.6163\n",
      "Epoch 66/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 21.6835 - val_loss: 26.8271\n",
      "Epoch 67/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.0123 - val_loss: 25.6005\n",
      "Epoch 68/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.2203 - val_loss: 25.6938\n",
      "Epoch 69/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 22.0446 - val_loss: 26.0751\n",
      "Epoch 70/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.8529 - val_loss: 28.4044\n",
      "Epoch 71/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.8004 - val_loss: 26.4922\n",
      "Epoch 72/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.2209 - val_loss: 26.3785\n",
      "Epoch 73/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 22.0070 - val_loss: 29.0429\n",
      "Epoch 74/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.5267 - val_loss: 25.8519\n",
      "Epoch 75/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.9887 - val_loss: 26.7100\n",
      "Epoch 76/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 22.0764 - val_loss: 26.7771\n",
      "Epoch 77/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.7211 - val_loss: 25.6645\n",
      "Epoch 78/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.9424 - val_loss: 26.1356\n",
      "Epoch 79/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.2047 - val_loss: 25.7177\n",
      "Epoch 80/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.5465 - val_loss: 26.5282\n",
      "Epoch 81/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.6764 - val_loss: 25.5652\n",
      "Epoch 82/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 22.1149 - val_loss: 25.4735\n",
      "Epoch 83/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 23.6257 - val_loss: 26.8147\n",
      "Epoch 84/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 22.7512 - val_loss: 26.3138\n",
      "Epoch 85/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.0638 - val_loss: 26.5396\n",
      "Epoch 86/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 21.7480 - val_loss: 25.6016\n",
      "Epoch 87/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 21.6800 - val_loss: 25.7704\n",
      "Epoch 88/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 22.3239 - val_loss: 26.4177\n",
      "Epoch 89/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 22.2978 - val_loss: 25.5615\n",
      "Epoch 90/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.9914 - val_loss: 26.3797\n",
      "Epoch 91/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.8905 - val_loss: 25.4971\n",
      "Epoch 92/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 21.7559 - val_loss: 27.0290\n",
      "Epoch 93/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.9015 - val_loss: 25.5386\n",
      "Epoch 94/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.2754 - val_loss: 25.8542\n",
      "Epoch 95/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.6595 - val_loss: 25.7886\n",
      "Epoch 96/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.2457 - val_loss: 26.4143\n",
      "Epoch 97/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 22.0712 - val_loss: 27.3863\n",
      "Epoch 98/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.8661 - val_loss: 27.4605\n",
      "Epoch 99/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 22.3412 - val_loss: 25.4074\n",
      "Epoch 100/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.9321 - val_loss: 26.2109\n",
      "Epoch 101/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.6910 - val_loss: 26.9563\n",
      "Epoch 102/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.3629 - val_loss: 27.8564\n",
      "Epoch 103/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 21.5057 - val_loss: 25.5717\n",
      "Epoch 104/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 22.0708 - val_loss: 25.4053\n",
      "Epoch 105/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.2955 - val_loss: 25.6985\n",
      "Epoch 106/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.9005 - val_loss: 26.4842\n",
      "Epoch 107/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.2481 - val_loss: 25.3953\n",
      "Epoch 108/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.8736 - val_loss: 27.5342\n",
      "Epoch 109/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.3671 - val_loss: 25.8212\n",
      "Epoch 110/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.4670 - val_loss: 25.4527\n",
      "Epoch 111/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.0287 - val_loss: 26.9785\n",
      "Epoch 112/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.2646 - val_loss: 25.7191\n",
      "Epoch 113/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.1485 - val_loss: 25.2801\n",
      "Epoch 114/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.9392 - val_loss: 26.3185\n",
      "Epoch 115/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 22.2873 - val_loss: 25.3403\n",
      "Epoch 116/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.5231 - val_loss: 25.9827\n",
      "Epoch 117/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 21.8246 - val_loss: 26.6308\n",
      "Epoch 118/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.3449 - val_loss: 25.7950\n",
      "Epoch 119/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 21.7515 - val_loss: 25.5852\n",
      "Epoch 120/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 21.9958 - val_loss: 26.1701\n",
      "Epoch 121/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.9427 - val_loss: 26.4608\n",
      "Epoch 122/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.9858 - val_loss: 29.2843\n",
      "Epoch 123/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 22.4416 - val_loss: 25.6840\n",
      "Epoch 124/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 22.1153 - val_loss: 25.6882\n",
      "Epoch 125/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.8422 - val_loss: 25.5406\n",
      "Epoch 126/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 22.8247 - val_loss: 25.8761\n",
      "Epoch 127/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.7817 - val_loss: 25.8468\n",
      "Epoch 128/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.3005 - val_loss: 27.3295\n",
      "Epoch 129/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 22.1489 - val_loss: 25.7970\n",
      "Epoch 130/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 22.4066 - val_loss: 26.7520\n",
      "Epoch 131/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.3282 - val_loss: 25.5408\n",
      "Epoch 132/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 22.2827 - val_loss: 25.8913\n",
      "Epoch 133/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.9453 - val_loss: 28.1673\n",
      "Epoch 134/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.5845 - val_loss: 25.3021\n",
      "Epoch 135/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.0818 - val_loss: 26.8138\n",
      "Epoch 136/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 22.0683 - val_loss: 26.8444\n",
      "Epoch 137/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.6505 - val_loss: 27.2118\n",
      "Epoch 138/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 23.7931 - val_loss: 25.8904\n",
      "Epoch 139/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.8005 - val_loss: 26.5758\n",
      "Epoch 140/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 98us/step - loss: 22.9685 - val_loss: 27.4244\n",
      "Epoch 141/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 23.6275 - val_loss: 27.1499\n",
      "Epoch 142/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 21.9534 - val_loss: 26.4189\n",
      "Epoch 143/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.7800 - val_loss: 25.8620\n",
      "Epoch 144/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 22.6024 - val_loss: 26.0463\n",
      "Epoch 145/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.3630 - val_loss: 26.8442\n",
      "Epoch 146/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.4092 - val_loss: 25.6580\n",
      "Epoch 147/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.5018 - val_loss: 26.6457\n",
      "Epoch 148/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.0331 - val_loss: 25.2813\n",
      "Epoch 149/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.8325 - val_loss: 25.1043\n",
      "Epoch 150/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 22.1293 - val_loss: 26.4234\n",
      "Epoch 151/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.2897 - val_loss: 25.7879\n",
      "Epoch 152/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.9213 - val_loss: 27.1975\n",
      "Epoch 153/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.8035 - val_loss: 27.6461\n",
      "Epoch 154/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.0147 - val_loss: 29.7239\n",
      "Epoch 155/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.7185 - val_loss: 27.0033\n",
      "Epoch 156/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.1687 - val_loss: 27.2611\n",
      "Epoch 157/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.2911 - val_loss: 26.3297\n",
      "Epoch 158/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 23.7598 - val_loss: 25.9045\n",
      "Epoch 159/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 23.4393 - val_loss: 26.2522\n",
      "Epoch 160/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.3212 - val_loss: 27.6107\n",
      "Epoch 161/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.1567 - val_loss: 26.8478\n",
      "Epoch 162/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.9076 - val_loss: 25.7455\n",
      "Epoch 163/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.8465 - val_loss: 27.4380\n",
      "Epoch 164/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.8594 - val_loss: 26.0296\n",
      "Epoch 165/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.3804 - val_loss: 26.2770\n",
      "Epoch 166/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.9830 - val_loss: 27.6632\n",
      "Epoch 167/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.0829 - val_loss: 27.4854\n",
      "Epoch 168/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 22.6290 - val_loss: 25.8976\n",
      "Epoch 169/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.0575 - val_loss: 25.8829\n",
      "Epoch 170/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.1881 - val_loss: 26.7748\n",
      "Epoch 171/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.4317 - val_loss: 25.5696\n",
      "Epoch 172/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.8332 - val_loss: 27.8359\n",
      "Epoch 173/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.7965 - val_loss: 25.4548\n",
      "Epoch 174/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.5181 - val_loss: 26.9563\n",
      "Epoch 175/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 22.3727 - val_loss: 25.8833\n",
      "Epoch 176/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.5122 - val_loss: 28.3514\n",
      "Epoch 177/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 23.2948 - val_loss: 25.8350\n",
      "Epoch 178/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.1845 - val_loss: 25.6649\n",
      "Epoch 179/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.4420 - val_loss: 26.1829\n",
      "Epoch 180/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 22.4215 - val_loss: 29.3197\n",
      "Epoch 181/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 23.1512 - val_loss: 26.2313\n",
      "Epoch 182/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.6719 - val_loss: 26.7820\n",
      "Epoch 183/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.5848 - val_loss: 27.4410\n",
      "Epoch 184/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.8489 - val_loss: 25.1926\n",
      "Epoch 185/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 21.4854 - val_loss: 26.0991\n",
      "Epoch 186/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.7283 - val_loss: 25.7191\n",
      "Epoch 187/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.7711 - val_loss: 25.1957\n",
      "Epoch 188/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.8940 - val_loss: 27.6561\n",
      "Epoch 189/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 22.8671 - val_loss: 25.6184\n",
      "Epoch 190/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 22.3429 - val_loss: 27.9788\n",
      "Epoch 191/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.1710 - val_loss: 25.5243\n",
      "Epoch 192/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.1512 - val_loss: 26.2655\n",
      "Epoch 193/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.0808 - val_loss: 26.1893\n",
      "Epoch 194/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 22.4573 - val_loss: 26.9156\n",
      "Epoch 195/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.4527 - val_loss: 25.3511\n",
      "Epoch 196/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.8117 - val_loss: 25.2616\n",
      "Epoch 197/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.3814 - val_loss: 26.0137\n",
      "Epoch 198/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.8580 - val_loss: 25.6276\n",
      "Epoch 199/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.9723 - val_loss: 26.9811\n",
      "Epoch 200/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.4827 - val_loss: 26.5876\n",
      "Epoch 201/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.6345 - val_loss: 26.1483\n",
      "Epoch 202/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.7952 - val_loss: 26.4945\n",
      "Epoch 203/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.7217 - val_loss: 25.4161\n",
      "Epoch 204/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.2808 - val_loss: 25.7146\n",
      "Epoch 205/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.2768 - val_loss: 24.5137\n",
      "Epoch 206/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.0871 - val_loss: 24.8912\n",
      "Epoch 207/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 22.0169 - val_loss: 25.0632\n",
      "Epoch 208/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.1164 - val_loss: 27.1294\n",
      "Epoch 209/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 20.5291 - val_loss: 24.7273\n",
      "Epoch 210/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 20.1743 - val_loss: 24.2775\n",
      "Epoch 211/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 20.7957 - val_loss: 25.1276\n",
      "Epoch 212/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 20.8645 - val_loss: 24.6236\n",
      "Epoch 213/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 20.0954 - val_loss: 24.5226\n",
      "Epoch 214/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 19.8719 - val_loss: 24.1730\n",
      "Epoch 215/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 85us/step - loss: 20.2159 - val_loss: 24.8436\n",
      "Epoch 216/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 19.2494 - val_loss: 24.0095\n",
      "Epoch 217/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 19.4951 - val_loss: 23.5365\n",
      "Epoch 218/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 20.0485 - val_loss: 23.7629\n",
      "Epoch 219/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.7663 - val_loss: 23.3365\n",
      "Epoch 220/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 19.9557 - val_loss: 24.1125\n",
      "Epoch 221/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.4550 - val_loss: 22.4133\n",
      "Epoch 222/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.2295 - val_loss: 23.5066\n",
      "Epoch 223/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.6564 - val_loss: 21.7443\n",
      "Epoch 224/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 18.2163 - val_loss: 21.7438\n",
      "Epoch 225/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 18.4190 - val_loss: 23.3673\n",
      "Epoch 226/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.9729 - val_loss: 22.4832\n",
      "Epoch 227/1000\n",
      "1052/1052 [==============================] - 0s 112us/step - loss: 18.0912 - val_loss: 23.1294\n",
      "Epoch 228/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 17.7823 - val_loss: 21.2779\n",
      "Epoch 229/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 17.5559 - val_loss: 20.8066\n",
      "Epoch 230/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 17.9313 - val_loss: 21.3593\n",
      "Epoch 231/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.4372 - val_loss: 21.3595\n",
      "Epoch 232/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 17.6745 - val_loss: 20.4038\n",
      "Epoch 233/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.4200 - val_loss: 21.4983\n",
      "Epoch 234/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.4552 - val_loss: 19.8358\n",
      "Epoch 235/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.4632 - val_loss: 20.0046\n",
      "Epoch 236/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.7710 - val_loss: 19.2241\n",
      "Epoch 237/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.5043 - val_loss: 20.7154\n",
      "Epoch 238/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.3365 - val_loss: 19.8008\n",
      "Epoch 239/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.4738 - val_loss: 19.4511\n",
      "Epoch 240/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 16.9745 - val_loss: 20.1152\n",
      "Epoch 241/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 16.4656 - val_loss: 19.1308\n",
      "Epoch 242/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.1653 - val_loss: 22.1556\n",
      "Epoch 243/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 16.5823 - val_loss: 19.2903\n",
      "Epoch 244/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 16.8695 - val_loss: 19.1167\n",
      "Epoch 245/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 16.1577 - val_loss: 18.6896\n",
      "Epoch 246/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 16.5677 - val_loss: 19.0767\n",
      "Epoch 247/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.1341 - val_loss: 19.5131\n",
      "Epoch 248/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 15.9974 - val_loss: 18.8062\n",
      "Epoch 249/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 16.7481 - val_loss: 17.7979\n",
      "Epoch 250/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 16.0444 - val_loss: 17.9334\n",
      "Epoch 251/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 16.2524 - val_loss: 19.0586\n",
      "Epoch 252/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 16.1328 - val_loss: 18.3587\n",
      "Epoch 253/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 15.5534 - val_loss: 17.9541\n",
      "Epoch 254/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 16.1527 - val_loss: 18.3928\n",
      "Epoch 255/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 15.5086 - val_loss: 17.7275\n",
      "Epoch 256/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 15.4238 - val_loss: 17.4542\n",
      "Epoch 257/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 15.6680 - val_loss: 18.0697\n",
      "Epoch 258/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 16.1641 - val_loss: 19.2407\n",
      "Epoch 259/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 16.1364 - val_loss: 17.8359\n",
      "Epoch 260/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 16.3314 - val_loss: 17.7297\n",
      "Epoch 261/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 15.1740 - val_loss: 18.1105\n",
      "Epoch 262/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 15.3641 - val_loss: 17.8109\n",
      "Epoch 263/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 16.7447 - val_loss: 20.5216\n",
      "Epoch 264/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 15.8555 - val_loss: 17.9035\n",
      "Epoch 265/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 15.3295 - val_loss: 17.8792\n",
      "Epoch 266/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 15.3376 - val_loss: 17.4304\n",
      "Epoch 267/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 14.8216 - val_loss: 17.5569\n",
      "Epoch 268/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.7210 - val_loss: 18.8304\n",
      "Epoch 269/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 15.1873 - val_loss: 17.8759\n",
      "Epoch 270/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 15.2254 - val_loss: 18.6349\n",
      "Epoch 271/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 14.8452 - val_loss: 17.9759\n",
      "Epoch 272/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.3806 - val_loss: 19.0097\n",
      "Epoch 273/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 15.0951 - val_loss: 16.8323\n",
      "Epoch 274/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.9119 - val_loss: 18.0336\n",
      "Epoch 275/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.1991 - val_loss: 16.7072\n",
      "Epoch 276/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 15.6058 - val_loss: 18.3010\n",
      "Epoch 277/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 14.1815 - val_loss: 17.0912\n",
      "Epoch 278/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.8668 - val_loss: 16.7269\n",
      "Epoch 279/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 14.1942 - val_loss: 17.4606\n",
      "Epoch 280/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.4554 - val_loss: 17.5710\n",
      "Epoch 281/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 15.2818 - val_loss: 16.3017\n",
      "Epoch 282/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.8977 - val_loss: 17.0280\n",
      "Epoch 283/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 14.5071 - val_loss: 18.1671\n",
      "Epoch 284/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 13.8166 - val_loss: 16.8730\n",
      "Epoch 285/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.1967 - val_loss: 17.0077\n",
      "Epoch 286/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.7400 - val_loss: 16.9930\n",
      "Epoch 287/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.2295 - val_loss: 17.9176\n",
      "Epoch 288/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.4124 - val_loss: 17.0299\n",
      "Epoch 289/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.4138 - val_loss: 16.3630\n",
      "Epoch 290/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.5423 - val_loss: 18.9510\n",
      "Epoch 291/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.0356 - val_loss: 16.8021\n",
      "Epoch 292/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.3412 - val_loss: 17.5294\n",
      "Epoch 293/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.4205 - val_loss: 16.7293\n",
      "Epoch 294/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 12.7356 - val_loss: 15.6536\n",
      "Epoch 295/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.8000 - val_loss: 18.1133\n",
      "Epoch 296/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.2034 - val_loss: 15.1849\n",
      "Epoch 297/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.5440 - val_loss: 15.8667\n",
      "Epoch 298/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.6506 - val_loss: 15.9025\n",
      "Epoch 299/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.3564 - val_loss: 15.4260\n",
      "Epoch 300/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.2118 - val_loss: 15.3916\n",
      "Epoch 301/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.3622 - val_loss: 16.5567\n",
      "Epoch 302/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.3354 - val_loss: 17.2233\n",
      "Epoch 303/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.3880 - val_loss: 14.6199\n",
      "Epoch 304/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.0334 - val_loss: 15.6792\n",
      "Epoch 305/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.7800 - val_loss: 15.5513\n",
      "Epoch 306/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.7315 - val_loss: 15.3424\n",
      "Epoch 307/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.1873 - val_loss: 16.4638\n",
      "Epoch 308/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 11.9848 - val_loss: 14.7708\n",
      "Epoch 309/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.4156 - val_loss: 16.2424\n",
      "Epoch 310/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.4648 - val_loss: 15.2481\n",
      "Epoch 311/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.5030 - val_loss: 14.4574\n",
      "Epoch 312/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.6896 - val_loss: 15.7856\n",
      "Epoch 313/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 11.5963 - val_loss: 16.5717\n",
      "Epoch 314/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 11.9304 - val_loss: 13.7434\n",
      "Epoch 315/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.1392 - val_loss: 13.8824\n",
      "Epoch 316/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.5151 - val_loss: 16.1885\n",
      "Epoch 317/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.4039 - val_loss: 14.0312\n",
      "Epoch 318/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.1526 - val_loss: 15.0483\n",
      "Epoch 319/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.0209 - val_loss: 14.6173\n",
      "Epoch 320/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.7274 - val_loss: 14.7839\n",
      "Epoch 321/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.9562 - val_loss: 14.2696\n",
      "Epoch 322/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.3060 - val_loss: 14.2265\n",
      "Epoch 323/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.9873 - val_loss: 13.3941\n",
      "Epoch 324/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.6783 - val_loss: 13.8145\n",
      "Epoch 325/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.7824 - val_loss: 13.7667\n",
      "Epoch 326/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.8600 - val_loss: 15.7606\n",
      "Epoch 327/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.8157 - val_loss: 12.8932\n",
      "Epoch 328/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.0900 - val_loss: 13.4654\n",
      "Epoch 329/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.9075 - val_loss: 14.0150\n",
      "Epoch 330/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 10.8056 - val_loss: 14.5322\n",
      "Epoch 331/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 10.5199 - val_loss: 15.2040\n",
      "Epoch 332/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 11.0012 - val_loss: 12.2205\n",
      "Epoch 333/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.5430 - val_loss: 14.2806\n",
      "Epoch 334/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 10.5753 - val_loss: 12.8925\n",
      "Epoch 335/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 10.7290 - val_loss: 13.0814\n",
      "Epoch 336/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.5678 - val_loss: 12.5214\n",
      "Epoch 337/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.2181 - val_loss: 11.9443\n",
      "Epoch 338/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.5692 - val_loss: 14.4714\n",
      "Epoch 339/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.6936 - val_loss: 13.0419\n",
      "Epoch 340/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.0417 - val_loss: 12.3930\n",
      "Epoch 341/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.9445 - val_loss: 12.3535\n",
      "Epoch 342/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.2828 - val_loss: 11.8314\n",
      "Epoch 343/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.2896 - val_loss: 12.0770\n",
      "Epoch 344/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.7248 - val_loss: 14.7342\n",
      "Epoch 345/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 10.6716 - val_loss: 12.4217\n",
      "Epoch 346/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.8015 - val_loss: 11.4862\n",
      "Epoch 347/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.6797 - val_loss: 11.9049\n",
      "Epoch 348/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.1066 - val_loss: 13.2248\n",
      "Epoch 349/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.9368 - val_loss: 12.7346\n",
      "Epoch 350/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.1275 - val_loss: 12.0314\n",
      "Epoch 351/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.0527 - val_loss: 11.5991\n",
      "Epoch 352/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.4549 - val_loss: 11.7403\n",
      "Epoch 353/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.7431 - val_loss: 12.4461\n",
      "Epoch 354/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.0867 - val_loss: 12.4595\n",
      "Epoch 355/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.4085 - val_loss: 11.2492\n",
      "Epoch 356/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 9.5077 - val_loss: 11.5859\n",
      "Epoch 357/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.6822 - val_loss: 12.3184\n",
      "Epoch 358/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 9.6682 - val_loss: 11.4317\n",
      "Epoch 359/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.4512 - val_loss: 11.8390\n",
      "Epoch 360/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.5875 - val_loss: 11.2702\n",
      "Epoch 361/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.4582 - val_loss: 12.5828\n",
      "Epoch 362/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 9.2688 - val_loss: 11.6382\n",
      "Epoch 363/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.5985 - val_loss: 11.3744\n",
      "Epoch 364/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 9.1357 - val_loss: 11.0792\n",
      "Epoch 365/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.1006 - val_loss: 11.9804\n",
      "Epoch 366/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.2948 - val_loss: 11.8927\n",
      "Epoch 367/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.7819 - val_loss: 12.4112\n",
      "Epoch 368/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2358 - val_loss: 11.6490\n",
      "Epoch 369/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2468 - val_loss: 12.3961\n",
      "Epoch 370/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.4354 - val_loss: 11.4846\n",
      "Epoch 371/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.8173 - val_loss: 12.5697\n",
      "Epoch 372/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.6868 - val_loss: 10.7954\n",
      "Epoch 373/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.1264 - val_loss: 11.0363\n",
      "Epoch 374/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.3112 - val_loss: 11.8821\n",
      "Epoch 375/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2830 - val_loss: 11.2891\n",
      "Epoch 376/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.0605 - val_loss: 11.1979\n",
      "Epoch 377/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.9007 - val_loss: 11.2115\n",
      "Epoch 378/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.8919 - val_loss: 12.9873\n",
      "Epoch 379/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.1790 - val_loss: 11.4894\n",
      "Epoch 380/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.4616 - val_loss: 11.8457\n",
      "Epoch 381/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8978 - val_loss: 10.7651\n",
      "Epoch 382/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1790 - val_loss: 11.2219\n",
      "Epoch 383/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.3639 - val_loss: 11.1764\n",
      "Epoch 384/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9544 - val_loss: 11.3498\n",
      "Epoch 385/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.3380 - val_loss: 11.2909\n",
      "Epoch 386/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.3175 - val_loss: 12.1869\n",
      "Epoch 387/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1213 - val_loss: 12.2919\n",
      "Epoch 388/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9156 - val_loss: 11.2875\n",
      "Epoch 389/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2076 - val_loss: 10.9421\n",
      "Epoch 390/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9534 - val_loss: 11.5267\n",
      "Epoch 391/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 9.1032 - val_loss: 12.3782\n",
      "Epoch 392/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 9.4605 - val_loss: 12.1919\n",
      "Epoch 393/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.1551 - val_loss: 11.9488\n",
      "Epoch 394/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.8969 - val_loss: 12.0075\n",
      "Epoch 395/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.0924 - val_loss: 11.0676\n",
      "Epoch 396/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 9.2852 - val_loss: 10.7730\n",
      "Epoch 397/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 9.1166 - val_loss: 11.4052\n",
      "Epoch 398/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.9620 - val_loss: 11.6439\n",
      "Epoch 399/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 9.1980 - val_loss: 10.8345\n",
      "Epoch 400/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.6920 - val_loss: 12.1709\n",
      "Epoch 401/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1617 - val_loss: 10.3512\n",
      "Epoch 402/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.2980 - val_loss: 10.6881\n",
      "Epoch 403/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.0652 - val_loss: 12.5850\n",
      "Epoch 404/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.1229 - val_loss: 11.2115\n",
      "Epoch 405/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9066 - val_loss: 11.2407\n",
      "Epoch 406/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.7972 - val_loss: 11.4674\n",
      "Epoch 407/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2545 - val_loss: 10.8275\n",
      "Epoch 408/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.5615 - val_loss: 13.5992\n",
      "Epoch 409/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.1723 - val_loss: 10.4143\n",
      "Epoch 410/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1377 - val_loss: 11.0902\n",
      "Epoch 411/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.6892 - val_loss: 10.7111\n",
      "Epoch 412/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.9876 - val_loss: 10.5439\n",
      "Epoch 413/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9482 - val_loss: 12.1209\n",
      "Epoch 414/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.1489 - val_loss: 12.4657\n",
      "Epoch 415/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2228 - val_loss: 10.7022\n",
      "Epoch 416/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9510 - val_loss: 10.6564\n",
      "Epoch 417/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.5021 - val_loss: 12.0711\n",
      "Epoch 418/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0961 - val_loss: 10.4595\n",
      "Epoch 419/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.6000 - val_loss: 11.5235\n",
      "Epoch 420/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.6582 - val_loss: 11.0969\n",
      "Epoch 421/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8686 - val_loss: 13.3962\n",
      "Epoch 422/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1825 - val_loss: 10.6244\n",
      "Epoch 423/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.1980 - val_loss: 10.5999\n",
      "Epoch 424/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7650 - val_loss: 11.0281\n",
      "Epoch 425/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6971 - val_loss: 11.3442\n",
      "Epoch 426/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.9910 - val_loss: 10.2269\n",
      "Epoch 427/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8255 - val_loss: 10.8966\n",
      "Epoch 428/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8535 - val_loss: 10.5845\n",
      "Epoch 429/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.6989 - val_loss: 11.8441\n",
      "Epoch 430/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2748 - val_loss: 10.7370\n",
      "Epoch 431/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7146 - val_loss: 10.8031\n",
      "Epoch 432/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.8722 - val_loss: 10.2564\n",
      "Epoch 433/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7270 - val_loss: 10.3861\n",
      "Epoch 434/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.1095 - val_loss: 11.4157\n",
      "Epoch 435/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7579 - val_loss: 10.3730\n",
      "Epoch 436/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4844 - val_loss: 10.3754\n",
      "Epoch 437/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.9474 - val_loss: 10.2164\n",
      "Epoch 438/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.6142 - val_loss: 10.5103\n",
      "Epoch 439/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.7340 - val_loss: 11.9118\n",
      "Epoch 440/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1197 - val_loss: 10.1782\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 441/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8333 - val_loss: 10.6158\n",
      "Epoch 442/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5943 - val_loss: 13.2924\n",
      "Epoch 443/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.0929 - val_loss: 10.4415\n",
      "Epoch 444/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.9190 - val_loss: 10.7437\n",
      "Epoch 445/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9863 - val_loss: 12.1734\n",
      "Epoch 446/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8537 - val_loss: 10.4844\n",
      "Epoch 447/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8075 - val_loss: 12.1447\n",
      "Epoch 448/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.9984 - val_loss: 10.5252\n",
      "Epoch 449/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9610 - val_loss: 13.8780\n",
      "Epoch 450/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.6081 - val_loss: 11.0037\n",
      "Epoch 451/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7990 - val_loss: 11.1462\n",
      "Epoch 452/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9362 - val_loss: 12.8580\n",
      "Epoch 453/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7290 - val_loss: 10.0941\n",
      "Epoch 454/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8474 - val_loss: 10.5930\n",
      "Epoch 455/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4860 - val_loss: 10.0670\n",
      "Epoch 456/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6797 - val_loss: 11.7747\n",
      "Epoch 457/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.6885 - val_loss: 9.8424\n",
      "Epoch 458/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9913 - val_loss: 11.3706\n",
      "Epoch 459/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.6205 - val_loss: 10.2264\n",
      "Epoch 460/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8476 - val_loss: 11.0420\n",
      "Epoch 461/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5327 - val_loss: 10.1998\n",
      "Epoch 462/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1324 - val_loss: 11.0617\n",
      "Epoch 463/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8352 - val_loss: 10.2463\n",
      "Epoch 464/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5685 - val_loss: 10.7611\n",
      "Epoch 465/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0416 - val_loss: 12.1937\n",
      "Epoch 466/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5508 - val_loss: 10.4516\n",
      "Epoch 467/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7348 - val_loss: 11.0110\n",
      "Epoch 468/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8073 - val_loss: 10.7020\n",
      "Epoch 469/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5971 - val_loss: 9.9999\n",
      "Epoch 470/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.4812 - val_loss: 10.1863\n",
      "Epoch 471/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8570 - val_loss: 11.6593\n",
      "Epoch 472/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9851 - val_loss: 10.3732\n",
      "Epoch 473/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7017 - val_loss: 12.2229\n",
      "Epoch 474/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0620 - val_loss: 10.6054\n",
      "Epoch 475/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.7731 - val_loss: 11.0280\n",
      "Epoch 476/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.4682 - val_loss: 10.3671\n",
      "Epoch 477/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9622 - val_loss: 10.1773\n",
      "Epoch 478/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5832 - val_loss: 10.1945\n",
      "Epoch 479/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.0352 - val_loss: 9.8206\n",
      "Epoch 480/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.7468 - val_loss: 9.9802\n",
      "Epoch 481/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.8631 - val_loss: 12.1729\n",
      "Epoch 482/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7091 - val_loss: 11.6943\n",
      "Epoch 483/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.8491 - val_loss: 9.9191\n",
      "Epoch 484/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7332 - val_loss: 10.9009\n",
      "Epoch 485/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8265 - val_loss: 10.1415\n",
      "Epoch 486/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.6432 - val_loss: 9.9649\n",
      "Epoch 487/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4142 - val_loss: 11.4402\n",
      "Epoch 488/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1570 - val_loss: 10.8498\n",
      "Epoch 489/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.5335 - val_loss: 10.9119\n",
      "Epoch 490/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.8886 - val_loss: 11.1713\n",
      "Epoch 491/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.3610 - val_loss: 10.5318\n",
      "Epoch 492/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7820 - val_loss: 10.9958\n",
      "Epoch 493/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5771 - val_loss: 10.3607\n",
      "Epoch 494/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.3447 - val_loss: 10.0093\n",
      "Epoch 495/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.4423 - val_loss: 10.3298\n",
      "Epoch 496/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7306 - val_loss: 9.9220\n",
      "Epoch 497/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3054 - val_loss: 12.1378\n",
      "Epoch 498/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5074 - val_loss: 10.4513\n",
      "Epoch 499/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.5302 - val_loss: 10.2793\n",
      "Epoch 500/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6371 - val_loss: 9.8197\n",
      "Epoch 501/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4012 - val_loss: 9.8700\n",
      "Epoch 502/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9578 - val_loss: 9.8060\n",
      "Epoch 503/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6785 - val_loss: 10.3242\n",
      "Epoch 504/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.7669 - val_loss: 10.8714\n",
      "Epoch 505/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.9680 - val_loss: 10.4052\n",
      "Epoch 506/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8828 - val_loss: 11.2259\n",
      "Epoch 507/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6045 - val_loss: 10.0112\n",
      "Epoch 508/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.2043 - val_loss: 10.6767\n",
      "Epoch 509/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.7283 - val_loss: 9.9554\n",
      "Epoch 510/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6856 - val_loss: 11.0195\n",
      "Epoch 511/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1015 - val_loss: 9.7065\n",
      "Epoch 512/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9856 - val_loss: 10.9284\n",
      "Epoch 513/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6986 - val_loss: 9.8752\n",
      "Epoch 514/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.5460 - val_loss: 10.3100\n",
      "Epoch 515/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5290 - val_loss: 9.9791\n",
      "Epoch 516/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.6764 - val_loss: 11.0927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 517/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.4861 - val_loss: 9.9951\n",
      "Epoch 518/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.5267 - val_loss: 10.6996\n",
      "Epoch 519/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.9231 - val_loss: 9.9808\n",
      "Epoch 520/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6855 - val_loss: 9.6069\n",
      "Epoch 521/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.8462 - val_loss: 10.3027\n",
      "Epoch 522/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.9344 - val_loss: 10.0582\n",
      "Epoch 523/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5104 - val_loss: 10.9985\n",
      "Epoch 524/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4420 - val_loss: 11.2029\n",
      "Epoch 525/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6539 - val_loss: 10.4260\n",
      "Epoch 526/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.5142 - val_loss: 10.3386\n",
      "Epoch 527/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6960 - val_loss: 11.1194\n",
      "Epoch 528/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4969 - val_loss: 10.9898\n",
      "Epoch 529/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6352 - val_loss: 12.4672\n",
      "Epoch 530/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7057 - val_loss: 10.9226\n",
      "Epoch 531/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2577 - val_loss: 10.3044\n",
      "Epoch 532/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4523 - val_loss: 9.6977\n",
      "Epoch 533/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1993 - val_loss: 10.8677\n",
      "Epoch 534/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.2826 - val_loss: 9.9646\n",
      "Epoch 535/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5856 - val_loss: 11.5947\n",
      "Epoch 536/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6867 - val_loss: 11.1694\n",
      "Epoch 537/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5448 - val_loss: 11.0570\n",
      "Epoch 538/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4560 - val_loss: 10.1326\n",
      "Epoch 539/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.6756 - val_loss: 10.5994\n",
      "Epoch 540/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2786 - val_loss: 9.9799\n",
      "Epoch 541/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7183 - val_loss: 9.8825\n",
      "Epoch 542/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9719 - val_loss: 10.0030\n",
      "Epoch 543/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.4910 - val_loss: 9.7986\n",
      "Epoch 544/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.6252 - val_loss: 10.3286\n",
      "Epoch 545/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.5599 - val_loss: 10.4311\n",
      "Epoch 546/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.7104 - val_loss: 9.5536\n",
      "Epoch 547/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7290 - val_loss: 9.9056\n",
      "Epoch 548/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2824 - val_loss: 10.1849\n",
      "Epoch 549/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5625 - val_loss: 10.4560\n",
      "Epoch 550/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7041 - val_loss: 9.9511\n",
      "Epoch 551/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6615 - val_loss: 11.9823\n",
      "Epoch 552/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.3787 - val_loss: 9.6830\n",
      "Epoch 553/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3936 - val_loss: 9.6468\n",
      "Epoch 554/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4866 - val_loss: 9.9051\n",
      "Epoch 555/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3669 - val_loss: 9.4904\n",
      "Epoch 556/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.3638 - val_loss: 9.8430\n",
      "Epoch 557/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.0048 - val_loss: 9.4756\n",
      "Epoch 558/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.5276 - val_loss: 10.1555\n",
      "Epoch 559/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 8.5476 - val_loss: 10.4100\n",
      "Epoch 560/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 8.4110 - val_loss: 11.4894\n",
      "Epoch 561/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.3224 - val_loss: 9.7490\n",
      "Epoch 562/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3834 - val_loss: 10.3955\n",
      "Epoch 563/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.4126 - val_loss: 9.7902\n",
      "Epoch 564/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.2987 - val_loss: 12.5255\n",
      "Epoch 565/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.7484 - val_loss: 11.0751\n",
      "Epoch 566/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 9.0762 - val_loss: 9.8976\n",
      "Epoch 567/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.4326 - val_loss: 9.7460\n",
      "Epoch 568/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.7334 - val_loss: 9.6233\n",
      "Epoch 569/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4892 - val_loss: 10.1264\n",
      "Epoch 570/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5706 - val_loss: 10.1998\n",
      "Epoch 571/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8572 - val_loss: 10.1593\n",
      "Epoch 572/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5496 - val_loss: 10.9647\n",
      "Epoch 573/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7034 - val_loss: 10.4492\n",
      "Epoch 574/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6472 - val_loss: 10.0459\n",
      "Epoch 575/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2294 - val_loss: 10.0112\n",
      "Epoch 576/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5213 - val_loss: 10.3024\n",
      "Epoch 577/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6048 - val_loss: 10.8950\n",
      "Epoch 578/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.5781 - val_loss: 10.5215\n",
      "Epoch 579/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4013 - val_loss: 10.5501\n",
      "Epoch 580/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.2125 - val_loss: 9.6651\n",
      "Epoch 581/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8585 - val_loss: 9.6210\n",
      "Epoch 582/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3627 - val_loss: 9.4843\n",
      "Epoch 583/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4023 - val_loss: 9.6513\n",
      "Epoch 584/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.5400 - val_loss: 9.9718\n",
      "Epoch 585/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.5381 - val_loss: 10.8771\n",
      "Epoch 586/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3830 - val_loss: 9.9605\n",
      "Epoch 587/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6951 - val_loss: 9.7590\n",
      "Epoch 588/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.6313 - val_loss: 10.8316\n",
      "Epoch 589/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.4761 - val_loss: 11.1190\n",
      "Epoch 590/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 8.6139 - val_loss: 9.4833\n",
      "Epoch 591/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5247 - val_loss: 9.4560\n",
      "Epoch 592/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2899 - val_loss: 9.7362\n",
      "Epoch 593/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4771 - val_loss: 9.7935\n",
      "Epoch 594/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.7330 - val_loss: 10.1713\n",
      "Epoch 595/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1849 - val_loss: 9.9207\n",
      "Epoch 596/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5086 - val_loss: 10.3475\n",
      "Epoch 597/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4919 - val_loss: 10.6867\n",
      "Epoch 598/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1709 - val_loss: 10.7691\n",
      "Epoch 599/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.8216 - val_loss: 9.9315\n",
      "Epoch 600/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4297 - val_loss: 9.9420\n",
      "Epoch 601/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7618 - val_loss: 10.0275\n",
      "Epoch 602/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7091 - val_loss: 9.9961\n",
      "Epoch 603/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1999 - val_loss: 9.8186\n",
      "Epoch 604/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.3472 - val_loss: 10.1710\n",
      "Epoch 605/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4332 - val_loss: 10.4370\n",
      "Epoch 606/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5157 - val_loss: 10.7923\n",
      "Epoch 607/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.0821 - val_loss: 9.3766\n",
      "Epoch 608/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9075 - val_loss: 10.0812\n",
      "Epoch 609/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.4928 - val_loss: 9.4708\n",
      "Epoch 610/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4530 - val_loss: 10.1477\n",
      "Epoch 611/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2002 - val_loss: 11.0919\n",
      "Epoch 612/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5374 - val_loss: 11.0828\n",
      "Epoch 613/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0399 - val_loss: 10.0618\n",
      "Epoch 614/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2957 - val_loss: 9.6313\n",
      "Epoch 615/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3017 - val_loss: 9.3157\n",
      "Epoch 616/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3731 - val_loss: 9.5799\n",
      "Epoch 617/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.5929 - val_loss: 10.5276\n",
      "Epoch 618/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.6526 - val_loss: 10.9215\n",
      "Epoch 619/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4083 - val_loss: 9.6171\n",
      "Epoch 620/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1297 - val_loss: 9.8086\n",
      "Epoch 621/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4149 - val_loss: 9.9976\n",
      "Epoch 622/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5132 - val_loss: 10.0159\n",
      "Epoch 623/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4576 - val_loss: 10.5433\n",
      "Epoch 624/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3488 - val_loss: 9.7038\n",
      "Epoch 625/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2319 - val_loss: 9.7443\n",
      "Epoch 626/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5783 - val_loss: 9.8130\n",
      "Epoch 627/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7010 - val_loss: 10.2155\n",
      "Epoch 628/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0561 - val_loss: 10.1352\n",
      "Epoch 629/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.5568 - val_loss: 11.0438\n",
      "Epoch 630/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4579 - val_loss: 9.9019\n",
      "Epoch 631/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.1930 - val_loss: 9.5888\n",
      "Epoch 632/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2305 - val_loss: 10.1969\n",
      "Epoch 633/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.8399 - val_loss: 9.6341\n",
      "Epoch 634/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.4089 - val_loss: 10.1682\n",
      "Epoch 635/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8395 - val_loss: 11.3185\n",
      "Epoch 636/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.0568 - val_loss: 10.0987\n",
      "Epoch 637/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.3577 - val_loss: 10.8777\n",
      "Epoch 638/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4118 - val_loss: 9.8364\n",
      "Epoch 639/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3476 - val_loss: 9.7485\n",
      "Epoch 640/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2668 - val_loss: 9.7764\n",
      "Epoch 641/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6843 - val_loss: 11.4314\n",
      "Epoch 642/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.5382 - val_loss: 10.0986\n",
      "Epoch 643/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3883 - val_loss: 10.4664\n",
      "Epoch 644/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3798 - val_loss: 9.5559\n",
      "Epoch 645/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.0951 - val_loss: 10.3957\n",
      "Epoch 646/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1553 - val_loss: 9.5650\n",
      "Epoch 647/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4737 - val_loss: 13.4625\n",
      "Epoch 648/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4260 - val_loss: 10.3369\n",
      "Epoch 649/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3663 - val_loss: 10.2421\n",
      "Epoch 650/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2896 - val_loss: 10.3883\n",
      "Epoch 651/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2257 - val_loss: 9.2190\n",
      "Epoch 652/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4769 - val_loss: 10.3384\n",
      "Epoch 653/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.4785 - val_loss: 9.6849\n",
      "Epoch 654/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3347 - val_loss: 10.6474\n",
      "Epoch 655/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.5432 - val_loss: 12.5600\n",
      "Epoch 656/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.0543 - val_loss: 10.2325\n",
      "Epoch 657/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2004 - val_loss: 9.3851\n",
      "Epoch 658/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4375 - val_loss: 9.9134\n",
      "Epoch 659/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3912 - val_loss: 10.9021\n",
      "Epoch 660/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4304 - val_loss: 9.8686\n",
      "Epoch 661/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4385 - val_loss: 9.9793\n",
      "Epoch 662/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.1990 - val_loss: 9.5057\n",
      "Epoch 663/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2153 - val_loss: 10.6797\n",
      "Epoch 664/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2903 - val_loss: 9.8916\n",
      "Epoch 665/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.6705 - val_loss: 9.6277\n",
      "Epoch 666/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8589 - val_loss: 11.0920\n",
      "Epoch 667/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1716 - val_loss: 10.4593\n",
      "Epoch 668/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.2713 - val_loss: 12.4596\n",
      "Epoch 669/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1039 - val_loss: 10.9779\n",
      "Epoch 670/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.3473 - val_loss: 10.0252\n",
      "Epoch 671/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8275 - val_loss: 16.8893\n",
      "Epoch 672/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 9.431 - 0s 89us/step - loss: 9.1764 - val_loss: 10.0448\n",
      "Epoch 673/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8722 - val_loss: 10.7202\n",
      "Epoch 674/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8575 - val_loss: 11.4492\n",
      "Epoch 675/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3735 - val_loss: 10.8398\n",
      "Epoch 676/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 8.2003 - val_loss: 9.4842\n",
      "Epoch 677/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4637 - val_loss: 10.2754\n",
      "Epoch 678/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8238 - val_loss: 9.3185\n",
      "Epoch 679/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0662 - val_loss: 10.1767\n",
      "Epoch 680/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3775 - val_loss: 10.3057\n",
      "Epoch 681/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.6783 - val_loss: 9.3682\n",
      "Epoch 682/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2462 - val_loss: 9.4794\n",
      "Epoch 683/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7760 - val_loss: 9.4390\n",
      "Epoch 684/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1470 - val_loss: 10.0272\n",
      "Epoch 685/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.1956 - val_loss: 9.7927\n",
      "Epoch 686/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.6305 - val_loss: 10.0555\n",
      "Epoch 687/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9581 - val_loss: 9.6836\n",
      "Epoch 688/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7772 - val_loss: 10.2290\n",
      "Epoch 689/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.5951 - val_loss: 9.4920\n",
      "Epoch 690/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1271 - val_loss: 9.6884\n",
      "Epoch 691/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3942 - val_loss: 9.3701\n",
      "Epoch 692/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.6436 - val_loss: 9.8673\n",
      "Epoch 693/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.4367 - val_loss: 10.3907\n",
      "Epoch 694/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1482 - val_loss: 9.4007\n",
      "Epoch 695/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5424 - val_loss: 9.7298\n",
      "Epoch 696/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.0629 - val_loss: 9.4801\n",
      "Epoch 697/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.1541 - val_loss: 10.3279\n",
      "Epoch 698/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6612 - val_loss: 10.3285\n",
      "Epoch 699/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.5938 - val_loss: 10.1774\n",
      "Epoch 700/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1369 - val_loss: 9.8352\n",
      "Epoch 701/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3361 - val_loss: 9.5555\n",
      "Epoch 702/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5351 - val_loss: 14.4750\n",
      "Epoch 703/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0804 - val_loss: 11.4343\n",
      "Epoch 704/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.3824 - val_loss: 12.1432\n",
      "Epoch 705/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6261 - val_loss: 9.9861\n",
      "Epoch 706/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1339 - val_loss: 9.5522\n",
      "Epoch 707/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4008 - val_loss: 9.3667\n",
      "Epoch 708/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3271 - val_loss: 10.7436\n",
      "Epoch 709/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4095 - val_loss: 9.7673\n",
      "Epoch 710/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3491 - val_loss: 10.6013\n",
      "Epoch 711/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.6097 - val_loss: 10.2372\n",
      "Epoch 712/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.2094 - val_loss: 9.2481\n",
      "Epoch 713/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.2904 - val_loss: 9.2826\n",
      "Epoch 714/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3737 - val_loss: 9.6684\n",
      "Epoch 715/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2222 - val_loss: 10.7071\n",
      "Epoch 716/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.0640 - val_loss: 9.9017\n",
      "Epoch 717/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.4497 - val_loss: 9.8708\n",
      "Epoch 718/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4074 - val_loss: 9.5418\n",
      "Epoch 719/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8620 - val_loss: 9.9058\n",
      "Epoch 720/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.2639 - val_loss: 9.6474\n",
      "Epoch 721/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.1549 - val_loss: 10.4312\n",
      "Epoch 722/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.0186 - val_loss: 10.3115\n",
      "Epoch 723/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6402 - val_loss: 9.7052\n",
      "Epoch 724/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1897 - val_loss: 9.2482\n",
      "Epoch 725/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2843 - val_loss: 9.6260\n",
      "Epoch 726/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1627 - val_loss: 10.1098\n",
      "Epoch 727/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 8.4413 - val_loss: 10.1602\n",
      "Epoch 728/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.3196 - val_loss: 9.5088\n",
      "Epoch 729/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.3748 - val_loss: 10.0991\n",
      "Epoch 730/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.4453 - val_loss: 9.6998\n",
      "Epoch 731/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.4375 - val_loss: 10.6443\n",
      "Epoch 732/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.4118 - val_loss: 9.1369\n",
      "Epoch 733/1000\n",
      "1052/1052 [==============================] - 0s 109us/step - loss: 8.0586 - val_loss: 10.3628\n",
      "Epoch 734/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.3642 - val_loss: 9.3289\n",
      "Epoch 735/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.1091 - val_loss: 9.8498\n",
      "Epoch 736/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3933 - val_loss: 9.5311\n",
      "Epoch 737/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1294 - val_loss: 9.1712\n",
      "Epoch 738/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.6037 - val_loss: 9.2519\n",
      "Epoch 739/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7617 - val_loss: 10.8684\n",
      "Epoch 740/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7618 - val_loss: 9.9720\n",
      "Epoch 741/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3777 - val_loss: 10.4936\n",
      "Epoch 742/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.6260 - val_loss: 9.2070\n",
      "Epoch 743/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4051 - val_loss: 13.1258\n",
      "Epoch 744/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4273 - val_loss: 9.7857\n",
      "Epoch 745/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3568 - val_loss: 10.4212\n",
      "Epoch 746/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6808 - val_loss: 9.0661\n",
      "Epoch 747/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.0205 - val_loss: 9.7801\n",
      "Epoch 748/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4747 - val_loss: 10.0842\n",
      "Epoch 749/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.4284 - val_loss: 11.9391\n",
      "Epoch 750/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6211 - val_loss: 10.2931\n",
      "Epoch 751/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3541 - val_loss: 9.5445\n",
      "Epoch 752/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3546 - val_loss: 9.2796\n",
      "Epoch 753/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.1659 - val_loss: 9.0317\n",
      "Epoch 754/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.0081 - val_loss: 10.1370\n",
      "Epoch 755/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7065 - val_loss: 9.7025\n",
      "Epoch 756/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3906 - val_loss: 9.4899\n",
      "Epoch 757/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8804 - val_loss: 10.4735\n",
      "Epoch 758/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2327 - val_loss: 9.4743\n",
      "Epoch 759/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2640 - val_loss: 9.8452\n",
      "Epoch 760/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9398 - val_loss: 13.9790\n",
      "Epoch 761/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.1855 - val_loss: 10.2996\n",
      "Epoch 762/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.3648 - val_loss: 9.7881\n",
      "Epoch 763/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.0591 - val_loss: 10.7754\n",
      "Epoch 764/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8207 - val_loss: 9.3586\n",
      "Epoch 765/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8432 - val_loss: 10.3132\n",
      "Epoch 766/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3230 - val_loss: 9.8394\n",
      "Epoch 767/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1814 - val_loss: 9.5272\n",
      "Epoch 768/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2799 - val_loss: 9.4100\n",
      "Epoch 769/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2861 - val_loss: 9.5354\n",
      "Epoch 770/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.7238 - val_loss: 10.1101\n",
      "Epoch 771/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2519 - val_loss: 9.8141\n",
      "Epoch 772/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5393 - val_loss: 9.1879\n",
      "Epoch 773/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5687 - val_loss: 9.7128\n",
      "Epoch 774/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3406 - val_loss: 10.1801\n",
      "Epoch 775/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4308 - val_loss: 10.4148\n",
      "Epoch 776/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7580 - val_loss: 9.5483\n",
      "Epoch 777/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0440 - val_loss: 9.8713\n",
      "Epoch 778/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.3256 - val_loss: 9.1902\n",
      "Epoch 779/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3260 - val_loss: 10.2268\n",
      "Epoch 780/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2117 - val_loss: 9.8850\n",
      "Epoch 781/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3653 - val_loss: 9.5835\n",
      "Epoch 782/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3620 - val_loss: 9.3841\n",
      "Epoch 783/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4252 - val_loss: 9.5849\n",
      "Epoch 784/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3421 - val_loss: 11.4493\n",
      "Epoch 785/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5459 - val_loss: 9.8587\n",
      "Epoch 786/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.7296 - val_loss: 9.7518\n",
      "Epoch 787/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3486 - val_loss: 9.8017\n",
      "Epoch 788/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3158 - val_loss: 9.6135\n",
      "Epoch 789/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4691 - val_loss: 9.4804\n",
      "Epoch 790/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2252 - val_loss: 9.4298\n",
      "Epoch 791/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2844 - val_loss: 15.0297\n",
      "Epoch 792/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5032 - val_loss: 9.6723\n",
      "Epoch 793/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3447 - val_loss: 9.5233\n",
      "Epoch 794/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1349 - val_loss: 9.9940\n",
      "Epoch 795/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1506 - val_loss: 9.6276\n",
      "Epoch 796/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4310 - val_loss: 9.2249\n",
      "Epoch 797/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6194 - val_loss: 10.4677\n",
      "Epoch 798/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.2407 - val_loss: 12.5117\n",
      "Epoch 799/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.0424 - val_loss: 9.6954\n",
      "Epoch 800/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.2678 - val_loss: 9.6316\n",
      "Epoch 801/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.2517 - val_loss: 9.3974\n",
      "Epoch 802/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1854 - val_loss: 9.1864\n",
      "Epoch 803/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3112 - val_loss: 9.9003\n",
      "Epoch 804/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3175 - val_loss: 9.0804\n",
      "Epoch 805/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3115 - val_loss: 9.6530\n",
      "Epoch 806/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3735 - val_loss: 9.5484\n",
      "Epoch 807/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1113 - val_loss: 10.1432\n",
      "Epoch 808/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.4879 - val_loss: 9.5171\n",
      "Epoch 809/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1025 - val_loss: 9.9452\n",
      "Epoch 810/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2065 - val_loss: 10.8613\n",
      "Epoch 811/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3378 - val_loss: 9.3585\n",
      "Epoch 812/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3282 - val_loss: 9.8482\n",
      "Epoch 813/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5134 - val_loss: 9.1506\n",
      "Epoch 814/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4990 - val_loss: 9.4423\n",
      "Epoch 815/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2042 - val_loss: 9.3561\n",
      "Epoch 816/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.2850 - val_loss: 9.9311\n",
      "Epoch 817/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5561 - val_loss: 9.8655\n",
      "Epoch 818/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2388 - val_loss: 10.0911\n",
      "Epoch 819/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3564 - val_loss: 9.1768\n",
      "Epoch 820/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3357 - val_loss: 9.5719\n",
      "Epoch 821/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1688 - val_loss: 9.4526\n",
      "Epoch 822/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.9840 - val_loss: 9.4178\n",
      "Epoch 823/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.1220 - val_loss: 9.3597\n",
      "Epoch 824/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4813 - val_loss: 9.5743\n",
      "Epoch 825/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3106 - val_loss: 9.2162\n",
      "Epoch 826/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1029 - val_loss: 9.2140\n",
      "Epoch 827/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4176 - val_loss: 9.7894\n",
      "Epoch 828/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4505 - val_loss: 9.5401\n",
      "Epoch 829/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3123 - val_loss: 9.1489\n",
      "Epoch 830/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3940 - val_loss: 10.3659\n",
      "Epoch 831/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4069 - val_loss: 10.6676\n",
      "Epoch 832/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2026 - val_loss: 9.3178\n",
      "Epoch 833/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0993 - val_loss: 9.1686\n",
      "Epoch 834/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3320 - val_loss: 9.8966\n",
      "Epoch 835/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.2791 - val_loss: 9.2365\n",
      "Epoch 836/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3091 - val_loss: 9.8572\n",
      "Epoch 837/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1747 - val_loss: 10.0655\n",
      "Epoch 838/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1823 - val_loss: 9.4263\n",
      "Epoch 839/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7752 - val_loss: 10.7028\n",
      "Epoch 840/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3596 - val_loss: 9.3081\n",
      "Epoch 841/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5575 - val_loss: 9.3234\n",
      "Epoch 842/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.3205 - val_loss: 11.0732\n",
      "Epoch 843/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5916 - val_loss: 8.9858\n",
      "Epoch 844/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5652 - val_loss: 9.2267\n",
      "Epoch 845/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0525 - val_loss: 10.3625\n",
      "Epoch 846/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2857 - val_loss: 10.3587\n",
      "Epoch 847/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1670 - val_loss: 10.2841\n",
      "Epoch 848/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9077 - val_loss: 9.6519\n",
      "Epoch 849/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.9090 - val_loss: 10.0801\n",
      "Epoch 850/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.4447 - val_loss: 9.1819\n",
      "Epoch 851/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.2513 - val_loss: 9.2960\n",
      "Epoch 852/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2072 - val_loss: 9.5609\n",
      "Epoch 853/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1098 - val_loss: 9.5392\n",
      "Epoch 854/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4559 - val_loss: 9.2762\n",
      "Epoch 855/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1493 - val_loss: 9.1079\n",
      "Epoch 856/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0487 - val_loss: 9.4684\n",
      "Epoch 857/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0593 - val_loss: 9.1665\n",
      "Epoch 858/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.0917 - val_loss: 10.3155\n",
      "Epoch 859/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 8.2052 - 0s 91us/step - loss: 8.7236 - val_loss: 11.1256\n",
      "Epoch 860/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2792 - val_loss: 10.3184\n",
      "Epoch 861/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5612 - val_loss: 10.0366\n",
      "Epoch 862/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2780 - val_loss: 9.6405\n",
      "Epoch 863/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3926 - val_loss: 9.3936\n",
      "Epoch 864/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6273 - val_loss: 9.8136\n",
      "Epoch 865/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.0191 - val_loss: 9.9089\n",
      "Epoch 866/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0802 - val_loss: 12.1251\n",
      "Epoch 867/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4250 - val_loss: 10.2775\n",
      "Epoch 868/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6636 - val_loss: 10.1782\n",
      "Epoch 869/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.2573 - val_loss: 12.7108\n",
      "Epoch 870/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5105 - val_loss: 9.5626\n",
      "Epoch 871/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.9961 - val_loss: 9.1448\n",
      "Epoch 872/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3828 - val_loss: 10.2397\n",
      "Epoch 873/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6442 - val_loss: 9.6419\n",
      "Epoch 874/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2246 - val_loss: 10.8391\n",
      "Epoch 875/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2233 - val_loss: 9.4537\n",
      "Epoch 876/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.3432 - val_loss: 9.3507\n",
      "Epoch 877/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5844 - val_loss: 11.0533\n",
      "Epoch 878/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3216 - val_loss: 9.1573\n",
      "Epoch 879/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6063 - val_loss: 9.2327\n",
      "Epoch 880/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.1805 - val_loss: 9.1084\n",
      "Epoch 881/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.3135 - val_loss: 9.9058\n",
      "Epoch 882/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.9415 - val_loss: 10.0250\n",
      "Epoch 883/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.0719 - val_loss: 9.6034\n",
      "Epoch 884/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1436 - val_loss: 9.2505\n",
      "Epoch 885/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0592 - val_loss: 9.0002\n",
      "Epoch 886/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7054 - val_loss: 10.9792\n",
      "Epoch 887/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3028 - val_loss: 9.6498\n",
      "Epoch 888/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4009 - val_loss: 9.7671\n",
      "Epoch 889/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2772 - val_loss: 10.3689\n",
      "Epoch 890/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3969 - val_loss: 9.0846\n",
      "Epoch 891/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.2467 - val_loss: 9.8931\n",
      "Epoch 892/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9523 - val_loss: 12.9418\n",
      "Epoch 893/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.4514 - val_loss: 9.5135\n",
      "Epoch 894/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2360 - val_loss: 10.6769\n",
      "Epoch 895/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.5594 - val_loss: 10.0397\n",
      "Epoch 896/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.3236 - val_loss: 9.5955\n",
      "Epoch 897/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.3766 - val_loss: 9.5189\n",
      "Epoch 898/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.7832 - val_loss: 10.5760\n",
      "Epoch 899/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.5605 - val_loss: 10.4051\n",
      "Epoch 900/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.4854 - val_loss: 9.9773\n",
      "Epoch 901/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.3411 - val_loss: 9.5852\n",
      "Epoch 902/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.0575 - val_loss: 9.0697\n",
      "Epoch 903/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.1482 - val_loss: 11.6769\n",
      "Epoch 904/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.3229 - val_loss: 10.2671\n",
      "Epoch 905/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3974 - val_loss: 9.2429\n",
      "Epoch 906/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1824 - val_loss: 10.0813\n",
      "Epoch 907/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3491 - val_loss: 9.4886\n",
      "Epoch 908/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.0746 - val_loss: 9.2467\n",
      "Epoch 909/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0629 - val_loss: 10.3150\n",
      "Epoch 910/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1272 - val_loss: 10.8350\n",
      "Epoch 911/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.3035 - val_loss: 10.1865\n",
      "Epoch 912/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1185 - val_loss: 9.3112\n",
      "Epoch 913/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9464 - val_loss: 10.0812\n",
      "Epoch 914/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1722 - val_loss: 9.3772\n",
      "Epoch 915/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5041 - val_loss: 9.9580\n",
      "Epoch 916/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0314 - val_loss: 10.8391\n",
      "Epoch 917/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2946 - val_loss: 9.4624\n",
      "Epoch 918/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3831 - val_loss: 9.8053\n",
      "Epoch 919/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4992 - val_loss: 9.3196\n",
      "Epoch 920/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5176 - val_loss: 9.7708\n",
      "Epoch 921/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3844 - val_loss: 9.1800\n",
      "Epoch 922/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4355 - val_loss: 10.4556\n",
      "Epoch 923/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.6787 - val_loss: 12.2395\n",
      "Epoch 924/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4287 - val_loss: 9.5676\n",
      "Epoch 925/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3109 - val_loss: 9.1974\n",
      "Epoch 926/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.7950 - val_loss: 11.0602\n",
      "Epoch 927/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.1273 - val_loss: 9.4110\n",
      "Epoch 928/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2054 - val_loss: 10.4259\n",
      "Epoch 929/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0157 - val_loss: 9.1422\n",
      "Epoch 930/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0781 - val_loss: 9.7021\n",
      "Epoch 931/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1031 - val_loss: 10.6129\n",
      "Epoch 932/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2548 - val_loss: 9.5363\n",
      "Epoch 933/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2882 - val_loss: 9.6188\n",
      "Epoch 934/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5101 - val_loss: 9.3598\n",
      "Epoch 935/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6694 - val_loss: 10.1490\n",
      "Epoch 936/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4666 - val_loss: 9.2939\n",
      "Epoch 937/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2448 - val_loss: 9.3652\n",
      "Epoch 938/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0013 - val_loss: 10.7331\n",
      "Epoch 939/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.1058 - val_loss: 9.4497\n",
      "Epoch 940/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0817 - val_loss: 9.1837\n",
      "Epoch 941/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.1862 - val_loss: 9.7076\n",
      "Epoch 942/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0978 - val_loss: 9.1116\n",
      "Epoch 943/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.5692 - val_loss: 9.3605\n",
      "Epoch 944/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.4152 - val_loss: 9.0338\n",
      "Epoch 945/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.1987 - val_loss: 9.6051\n",
      "Epoch 946/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.0421 - val_loss: 9.3509\n",
      "Epoch 947/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1482 - val_loss: 9.0396\n",
      "Epoch 948/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.3281 - val_loss: 10.8993\n",
      "Epoch 949/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3707 - val_loss: 9.0905\n",
      "Epoch 950/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8705 - val_loss: 10.5877\n",
      "Epoch 951/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0230 - val_loss: 9.0914\n",
      "Epoch 952/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8000 - val_loss: 10.1633\n",
      "Epoch 953/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.4579 - val_loss: 11.5746\n",
      "Epoch 954/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.0006 - val_loss: 9.3749\n",
      "Epoch 955/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.3130 - val_loss: 9.2160\n",
      "Epoch 956/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.7960 - val_loss: 10.9376\n",
      "Epoch 957/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0652 - val_loss: 9.5029\n",
      "Epoch 958/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1676 - val_loss: 9.1208\n",
      "Epoch 959/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1734 - val_loss: 9.3879\n",
      "Epoch 960/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8181 - val_loss: 9.5042\n",
      "Epoch 961/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1805 - val_loss: 10.0599\n",
      "Epoch 962/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1739 - val_loss: 9.4197\n",
      "Epoch 963/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1163 - val_loss: 10.0819\n",
      "Epoch 964/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.9159 - val_loss: 9.5625\n",
      "Epoch 965/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6653 - val_loss: 9.4057\n",
      "Epoch 966/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3391 - val_loss: 11.7182\n",
      "Epoch 967/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.6153 - val_loss: 9.2813\n",
      "Epoch 968/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5001 - val_loss: 10.8566\n",
      "Epoch 969/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0475 - val_loss: 9.5441\n",
      "Epoch 970/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0221 - val_loss: 10.4883\n",
      "Epoch 971/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6438 - val_loss: 10.0242\n",
      "Epoch 972/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.1700 - val_loss: 8.8254\n",
      "Epoch 973/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0918 - val_loss: 9.2804\n",
      "Epoch 974/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2160 - val_loss: 9.8550\n",
      "Epoch 975/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2673 - val_loss: 9.4276\n",
      "Epoch 976/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4609 - val_loss: 9.1479\n",
      "Epoch 977/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2409 - val_loss: 10.3247\n",
      "Epoch 978/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7467 - val_loss: 10.1517\n",
      "Epoch 979/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1482 - val_loss: 8.9801\n",
      "Epoch 980/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7771 - val_loss: 10.5575\n",
      "Epoch 981/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.2054 - val_loss: 9.8168\n",
      "Epoch 982/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2253 - val_loss: 9.4536\n",
      "Epoch 983/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3357 - val_loss: 10.8504\n",
      "Epoch 984/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3348 - val_loss: 9.1677\n",
      "Epoch 985/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.2257 - val_loss: 10.6848\n",
      "Epoch 986/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6433 - val_loss: 9.0042\n",
      "Epoch 987/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1171 - val_loss: 9.1886\n",
      "Epoch 988/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1625 - val_loss: 10.4589\n",
      "Epoch 989/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.0648 - val_loss: 9.6444\n",
      "Epoch 990/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.1225 - val_loss: 10.0073\n",
      "Epoch 991/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1245 - val_loss: 9.7496\n",
      "Epoch 992/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2729 - val_loss: 9.4698\n",
      "Epoch 993/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8890 - val_loss: 12.3283\n",
      "Epoch 994/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.4235 - val_loss: 10.3935\n",
      "Epoch 995/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1924 - val_loss: 8.9718\n",
      "Epoch 996/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.6967 - val_loss: 9.6822\n",
      "Epoch 997/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1483 - val_loss: 10.5121\n",
      "Epoch 998/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2738 - val_loss: 10.0786\n",
      "Epoch 999/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.8914 - val_loss: 8.8752\n",
      "Epoch 1000/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3189 - val_loss: 9.0938\n",
      "7.672016580547907\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 0.7087425 ,  0.1404251 , -3.193     , -1.9082919 , -3.7617931 ],\n",
       "        [ 1.4338864 ,  0.18494618,  0.07939274,  0.4951963 ,  0.19296935],\n",
       "        [ 1.6166356 ,  0.29391664, -0.00454639,  0.38734654, -0.71108216],\n",
       "        [-0.24788852, -0.12054072,  0.06733918,  0.01921353,  0.14085282],\n",
       "        [-0.31918317,  0.18439576, -2.3774862 , -0.31030443, -0.31814748]],\n",
       "       dtype=float32),\n",
       " array([ 0.739141 , -1.3315203, -4.6797523, -1.2957648, -4.72295  ],\n",
       "       dtype=float32),\n",
       " array([[ 0.09057587,  0.22450846, -0.24725057,  0.06204393,  0.6878021 ,\n",
       "         -0.6110786 , -0.06546178, -0.88051337, -0.7157743 ,  0.39152974],\n",
       "        [-1.1620767 ,  1.0693033 ,  2.1112447 ,  1.283406  ,  1.0418489 ,\n",
       "         -1.4466256 , -1.6035215 , -2.1358845 , -2.1962378 ,  1.3185877 ],\n",
       "        [-1.6225098 ,  2.082052  ,  1.8690599 ,  2.0784264 ,  1.1625152 ,\n",
       "         -1.5635835 , -1.3624095 , -1.7895293 , -1.8424351 ,  1.3716922 ],\n",
       "        [ 0.3014366 , -0.9622789 , -0.2595032 , -0.88682103, -0.23047163,\n",
       "          0.76061356,  0.3446585 ,  0.9733831 ,  0.5471412 , -0.38675418],\n",
       "        [-2.4063342 ,  2.5133066 ,  2.339018  ,  2.4303143 ,  2.3811474 ,\n",
       "         -1.7245318 , -1.7668929 , -2.5314522 , -2.3680797 ,  1.6702887 ]],\n",
       "       dtype=float32),\n",
       " array([ 2.0717475, -2.0547724, -1.941587 , -1.88155  , -2.0542798,\n",
       "         1.9313225,  1.9211035,  2.0331316,  1.8778844, -2.0189118],\n",
       "       dtype=float32),\n",
       " array([[ 1.5727423],\n",
       "        [-1.648034 ],\n",
       "        [-2.0571952],\n",
       "        [-2.2855206],\n",
       "        [-1.3367932],\n",
       "        [ 1.7930768],\n",
       "        [ 2.107048 ],\n",
       "        [ 1.625188 ],\n",
       "        [ 2.2765017],\n",
       "        [-1.7279805]], dtype=float32),\n",
       " array([1.9004133], dtype=float32)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_airfoil, history_airfoil, evaluate_airfoil=NN_model_structure_regression_linear(X_train_airfoil, X_val_airfoil, Y_train_airfoil, Y_val_airfoil, adam2, 32, 1000, x_test_airfoil, y_test_airfoil)\n",
    "model_airfoil.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_airfoil.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_airfoil_linear_4th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 101\n",
      "Trainable params: 101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1052 samples, validate on 225 samples\n",
      "Epoch 1/1000\n",
      "1052/1052 [==============================] - 0s 199us/step - loss: 7922.5692 - val_loss: 824.8005\n",
      "Epoch 2/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 482.9400 - val_loss: 219.7331\n",
      "Epoch 3/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 168.1777 - val_loss: 115.9316\n",
      "Epoch 4/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 97.5513 - val_loss: 78.8904\n",
      "Epoch 5/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 67.4053 - val_loss: 57.9112\n",
      "Epoch 6/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 51.9549 - val_loss: 46.3827\n",
      "Epoch 7/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 43.0066 - val_loss: 39.6107\n",
      "Epoch 8/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 34.7096 - val_loss: 34.4670\n",
      "Epoch 9/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 28.9208 - val_loss: 29.0218\n",
      "Epoch 10/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 24.5982 - val_loss: 28.0284\n",
      "Epoch 11/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 22.0853 - val_loss: 26.2737\n",
      "Epoch 12/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 21.4936 - val_loss: 28.0337\n",
      "Epoch 13/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 22.1538 - val_loss: 26.2620\n",
      "Epoch 14/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 21.3372 - val_loss: 24.3272\n",
      "Epoch 15/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 20.5756 - val_loss: 24.3702\n",
      "Epoch 16/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 19.9739 - val_loss: 24.8568\n",
      "Epoch 17/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 19.9660 - val_loss: 23.8659\n",
      "Epoch 18/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 19.9647 - val_loss: 25.1475\n",
      "Epoch 19/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 19.7946 - val_loss: 24.4866\n",
      "Epoch 20/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 19.9527 - val_loss: 24.9537\n",
      "Epoch 21/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 19.6895 - val_loss: 25.2982\n",
      "Epoch 22/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 19.7980 - val_loss: 24.4665\n",
      "Epoch 23/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 19.8629 - val_loss: 24.9521\n",
      "Epoch 24/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 19.8355 - val_loss: 24.7480\n",
      "Epoch 25/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 20.1901 - val_loss: 24.9246\n",
      "Epoch 26/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 19.7913 - val_loss: 24.6810\n",
      "Epoch 27/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 19.8711 - val_loss: 24.9261\n",
      "Epoch 28/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 19.9885 - val_loss: 23.9764\n",
      "Epoch 29/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 19.5546 - val_loss: 23.6754\n",
      "Epoch 30/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 19.6758 - val_loss: 23.4765\n",
      "Epoch 31/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 19.6908 - val_loss: 23.5715\n",
      "Epoch 32/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 19.6104 - val_loss: 23.6154\n",
      "Epoch 33/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 19.5959 - val_loss: 24.1217\n",
      "Epoch 34/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 19.5759 - val_loss: 25.2087\n",
      "Epoch 35/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 19.3895 - val_loss: 23.7387\n",
      "Epoch 36/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 19.7711 - val_loss: 23.5623\n",
      "Epoch 37/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 19.4405 - val_loss: 23.9705\n",
      "Epoch 38/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 19.5753 - val_loss: 24.3592\n",
      "Epoch 39/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 19.1914 - val_loss: 24.7996\n",
      "Epoch 40/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 19.6171 - val_loss: 24.2907\n",
      "Epoch 41/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 19.0650 - val_loss: 24.2924\n",
      "Epoch 42/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 19.4953 - val_loss: 23.7740\n",
      "Epoch 43/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 19.2958 - val_loss: 23.7279\n",
      "Epoch 44/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.7656 - val_loss: 24.0642\n",
      "Epoch 45/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 20.2575 - val_loss: 23.7989\n",
      "Epoch 46/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 19.6138 - val_loss: 24.2181\n",
      "Epoch 47/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 19.0849 - val_loss: 26.5746\n",
      "Epoch 48/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 19.6379 - val_loss: 23.2004\n",
      "Epoch 49/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.7043 - val_loss: 22.6234\n",
      "Epoch 50/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.4228 - val_loss: 22.7073\n",
      "Epoch 51/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.0265 - val_loss: 21.7797\n",
      "Epoch 52/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.9275 - val_loss: 23.4624\n",
      "Epoch 53/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.7958 - val_loss: 21.6443\n",
      "Epoch 54/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.9365 - val_loss: 23.4684\n",
      "Epoch 55/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 17.3601 - val_loss: 21.3141\n",
      "Epoch 56/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 17.6731 - val_loss: 21.1555\n",
      "Epoch 57/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 17.3074 - val_loss: 21.4172\n",
      "Epoch 58/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 17.4477 - val_loss: 22.1809\n",
      "Epoch 59/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 17.3911 - val_loss: 20.2478\n",
      "Epoch 60/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 16.7707 - val_loss: 19.3882\n",
      "Epoch 61/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 16.4093 - val_loss: 19.6857\n",
      "Epoch 62/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 15.7431 - val_loss: 18.4986\n",
      "Epoch 63/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 15.3149 - val_loss: 19.1004\n",
      "Epoch 64/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 15.7081 - val_loss: 17.7837\n",
      "Epoch 65/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 15.3351 - val_loss: 18.0797\n",
      "Epoch 66/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 15.1824 - val_loss: 19.0430\n",
      "Epoch 67/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 93us/step - loss: 14.9724 - val_loss: 17.1008\n",
      "Epoch 68/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.8595 - val_loss: 17.9312\n",
      "Epoch 69/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 15.1943 - val_loss: 17.3325\n",
      "Epoch 70/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.5259 - val_loss: 16.2603\n",
      "Epoch 71/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.0577 - val_loss: 16.7346\n",
      "Epoch 72/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.9345 - val_loss: 16.9591\n",
      "Epoch 73/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.9974 - val_loss: 15.6633\n",
      "Epoch 74/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.8160 - val_loss: 17.0072\n",
      "Epoch 75/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.1130 - val_loss: 19.9702\n",
      "Epoch 76/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.6406 - val_loss: 15.5450\n",
      "Epoch 77/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.3028 - val_loss: 15.4717\n",
      "Epoch 78/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 13.6695 - val_loss: 15.4946\n",
      "Epoch 79/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.7048 - val_loss: 15.4418\n",
      "Epoch 80/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.9450 - val_loss: 16.2907\n",
      "Epoch 81/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.3574 - val_loss: 15.0964\n",
      "Epoch 82/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 13.6667 - val_loss: 15.4585\n",
      "Epoch 83/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 13.8758 - val_loss: 15.0755\n",
      "Epoch 84/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.0211 - val_loss: 15.4258\n",
      "Epoch 85/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.8037 - val_loss: 15.9808\n",
      "Epoch 86/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.8495 - val_loss: 14.5677\n",
      "Epoch 87/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 13.0668 - val_loss: 15.7934\n",
      "Epoch 88/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 13.1389 - val_loss: 15.9986\n",
      "Epoch 89/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.8085 - val_loss: 15.4443\n",
      "Epoch 90/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.7190 - val_loss: 14.8639\n",
      "Epoch 91/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 12.8483 - val_loss: 14.6201\n",
      "Epoch 92/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.8685 - val_loss: 15.1068\n",
      "Epoch 93/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 13.1413 - val_loss: 14.4471\n",
      "Epoch 94/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 12.5521 - val_loss: 14.3690\n",
      "Epoch 95/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.8573 - val_loss: 14.5139\n",
      "Epoch 96/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 12.7461 - val_loss: 14.2758\n",
      "Epoch 97/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 13.3525 - val_loss: 14.2259\n",
      "Epoch 98/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 13.3879 - val_loss: 14.1727\n",
      "Epoch 99/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.4422 - val_loss: 14.2608\n",
      "Epoch 100/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 13.1364 - val_loss: 14.0333\n",
      "Epoch 101/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 12.4372 - val_loss: 14.8456\n",
      "Epoch 102/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 12.3257 - val_loss: 15.0304\n",
      "Epoch 103/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.2953 - val_loss: 14.7289\n",
      "Epoch 104/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 12.2594 - val_loss: 15.5897\n",
      "Epoch 105/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.5200 - val_loss: 14.2349\n",
      "Epoch 106/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 12.6820 - val_loss: 14.4380\n",
      "Epoch 107/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 12.9249 - val_loss: 14.3383\n",
      "Epoch 108/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.0777 - val_loss: 16.1223\n",
      "Epoch 109/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.5225 - val_loss: 17.2909\n",
      "Epoch 110/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.4231 - val_loss: 15.0605\n",
      "Epoch 111/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.6851 - val_loss: 14.4577\n",
      "Epoch 112/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.9231 - val_loss: 14.0230\n",
      "Epoch 113/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.0960 - val_loss: 16.1849\n",
      "Epoch 114/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.5876 - val_loss: 15.1513\n",
      "Epoch 115/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 12.3883 - val_loss: 14.3611\n",
      "Epoch 116/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.0377 - val_loss: 15.0454\n",
      "Epoch 117/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 12.5956 - val_loss: 14.6145\n",
      "Epoch 118/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.4384 - val_loss: 16.4133\n",
      "Epoch 119/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 12.5198 - val_loss: 13.9876\n",
      "Epoch 120/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.1924 - val_loss: 14.1228\n",
      "Epoch 121/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 12.4731 - val_loss: 14.0857\n",
      "Epoch 122/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 12.5212 - val_loss: 14.1856\n",
      "Epoch 123/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.1803 - val_loss: 14.4062\n",
      "Epoch 124/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.1930 - val_loss: 15.1330\n",
      "Epoch 125/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.3899 - val_loss: 16.0372\n",
      "Epoch 126/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.4428 - val_loss: 14.4291\n",
      "Epoch 127/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.2322 - val_loss: 14.5613\n",
      "Epoch 128/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.3837 - val_loss: 15.1931\n",
      "Epoch 129/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 12.1960 - val_loss: 13.7883\n",
      "Epoch 130/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.0489 - val_loss: 13.8406\n",
      "Epoch 131/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.4906 - val_loss: 14.2978\n",
      "Epoch 132/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.3016 - val_loss: 16.1228\n",
      "Epoch 133/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.9062 - val_loss: 14.4436\n",
      "Epoch 134/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.6096 - val_loss: 14.9174\n",
      "Epoch 135/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.5529 - val_loss: 14.4846\n",
      "Epoch 136/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.3178 - val_loss: 13.4890\n",
      "Epoch 137/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.9805 - val_loss: 14.8697\n",
      "Epoch 138/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.1884 - val_loss: 13.6840\n",
      "Epoch 139/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.6018 - val_loss: 14.3880\n",
      "Epoch 140/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 12.5733 - val_loss: 13.9289\n",
      "Epoch 141/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 12.0739 - val_loss: 13.9645\n",
      "Epoch 142/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.6208 - val_loss: 14.1552\n",
      "Epoch 143/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.0916 - val_loss: 13.9288\n",
      "Epoch 144/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 12.4290 - val_loss: 14.9225\n",
      "Epoch 145/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.0300 - val_loss: 13.8967\n",
      "Epoch 146/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 12.0066 - val_loss: 14.8923\n",
      "Epoch 147/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.1960 - val_loss: 15.5275\n",
      "Epoch 148/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.9258 - val_loss: 14.1855\n",
      "Epoch 149/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.8511 - val_loss: 14.2220\n",
      "Epoch 150/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.4805 - val_loss: 13.7983\n",
      "Epoch 151/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.0660 - val_loss: 16.3878\n",
      "Epoch 152/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.2774 - val_loss: 15.5960\n",
      "Epoch 153/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.8089 - val_loss: 14.9604\n",
      "Epoch 154/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 12.4893 - val_loss: 14.1376\n",
      "Epoch 155/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 12.7966 - val_loss: 14.1656\n",
      "Epoch 156/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.6287 - val_loss: 14.6821\n",
      "Epoch 157/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.9586 - val_loss: 14.1998\n",
      "Epoch 158/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.9865 - val_loss: 16.5230\n",
      "Epoch 159/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.2098 - val_loss: 15.0361\n",
      "Epoch 160/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.7415 - val_loss: 15.4280\n",
      "Epoch 161/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.2998 - val_loss: 13.8928\n",
      "Epoch 162/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.1460 - val_loss: 14.4168\n",
      "Epoch 163/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 12.6059 - val_loss: 14.2706\n",
      "Epoch 164/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 12.0669 - val_loss: 14.1785\n",
      "Epoch 165/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.9298 - val_loss: 14.9117\n",
      "Epoch 166/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 12.6292 - val_loss: 16.4884\n",
      "Epoch 167/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.8462 - val_loss: 14.6176\n",
      "Epoch 168/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.9062 - val_loss: 15.0668\n",
      "Epoch 169/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.8340 - val_loss: 16.0392\n",
      "Epoch 170/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 12.3285 - val_loss: 14.3632\n",
      "Epoch 171/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 12.1197 - val_loss: 14.9799\n",
      "Epoch 172/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 12.1550 - val_loss: 15.3224\n",
      "Epoch 173/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.6835 - val_loss: 14.9996\n",
      "Epoch 174/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.2486 - val_loss: 14.7962\n",
      "Epoch 175/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 13.6501 - val_loss: 14.6686\n",
      "Epoch 176/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.4155 - val_loss: 15.0416\n",
      "Epoch 177/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.5022 - val_loss: 16.4189\n",
      "Epoch 178/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.2982 - val_loss: 15.7193\n",
      "Epoch 179/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.9417 - val_loss: 14.0896\n",
      "Epoch 180/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.0600 - val_loss: 14.3133\n",
      "Epoch 181/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.5195 - val_loss: 14.5254\n",
      "Epoch 182/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.5565 - val_loss: 15.2388\n",
      "Epoch 183/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.6873 - val_loss: 15.2254\n",
      "Epoch 184/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.1264 - val_loss: 14.2018\n",
      "Epoch 185/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.8496 - val_loss: 15.0998\n",
      "Epoch 186/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 12.1434 - val_loss: 14.5821\n",
      "Epoch 187/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.0921 - val_loss: 15.1902\n",
      "Epoch 188/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.2988 - val_loss: 15.6272\n",
      "Epoch 189/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.3397 - val_loss: 14.7540\n",
      "Epoch 190/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.9999 - val_loss: 14.4411\n",
      "Epoch 191/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.6432 - val_loss: 15.7208\n",
      "Epoch 192/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.0700 - val_loss: 13.9122\n",
      "Epoch 193/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.7228 - val_loss: 14.2987\n",
      "Epoch 194/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.9058 - val_loss: 14.7599\n",
      "Epoch 195/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.8385 - val_loss: 14.4729\n",
      "Epoch 196/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.8522 - val_loss: 13.9394\n",
      "Epoch 197/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.1587 - val_loss: 14.1003\n",
      "Epoch 198/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 12.4785 - val_loss: 14.5471\n",
      "Epoch 199/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.4603 - val_loss: 16.7339\n",
      "Epoch 200/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 13.1721 - val_loss: 15.1307\n",
      "Epoch 201/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 12.8584 - val_loss: 14.4167\n",
      "Epoch 202/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.2574 - val_loss: 14.8892\n",
      "Epoch 203/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 12.5022 - val_loss: 14.8095\n",
      "Epoch 204/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 12.1210 - val_loss: 14.1305\n",
      "Epoch 205/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.6354 - val_loss: 13.8574\n",
      "Epoch 206/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.5897 - val_loss: 15.2096\n",
      "Epoch 207/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 12.1735 - val_loss: 14.4045\n",
      "Epoch 208/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.7928 - val_loss: 15.7048\n",
      "Epoch 209/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 12.7941 - val_loss: 14.4513\n",
      "Epoch 210/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.4304 - val_loss: 15.3501\n",
      "Epoch 211/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.3090 - val_loss: 14.6657\n",
      "Epoch 212/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.3351 - val_loss: 14.3636\n",
      "Epoch 213/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 12.1780 - val_loss: 14.4557\n",
      "Epoch 214/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.8538 - val_loss: 19.8309\n",
      "Epoch 215/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.9583 - val_loss: 13.8469\n",
      "Epoch 216/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.7834 - val_loss: 14.1347\n",
      "Epoch 217/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.7717 - val_loss: 15.3542\n",
      "Epoch 218/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.2094 - val_loss: 16.0923\n",
      "Epoch 219/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 12.2644 - val_loss: 14.6878\n",
      "Epoch 220/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 12.8987 - val_loss: 15.6299\n",
      "Epoch 221/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 12.3225 - val_loss: 15.5224\n",
      "Epoch 222/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 12.0139 - val_loss: 14.6748\n",
      "Epoch 223/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 12.0791 - val_loss: 14.9360\n",
      "Epoch 224/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 11.7011 - val_loss: 14.1710\n",
      "Epoch 225/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 12.0840 - val_loss: 14.7601\n",
      "Epoch 226/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 12.4395 - val_loss: 15.7258\n",
      "Epoch 227/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 12.1265 - val_loss: 14.4397\n",
      "Epoch 228/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 12.2092 - val_loss: 14.9756\n",
      "Epoch 229/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 12.2645 - val_loss: 14.6793\n",
      "Epoch 230/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 12.6204 - val_loss: 18.0989\n",
      "Epoch 231/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.0901 - val_loss: 14.8438\n",
      "Epoch 232/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 12.1088 - val_loss: 14.4971\n",
      "Epoch 233/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.8886 - val_loss: 13.9853\n",
      "Epoch 234/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.3617 - val_loss: 16.0306\n",
      "Epoch 235/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.3291 - val_loss: 14.8225\n",
      "Epoch 236/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 12.3373 - val_loss: 15.8400\n",
      "Epoch 237/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.0260 - val_loss: 14.1087\n",
      "Epoch 238/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.1764 - val_loss: 15.8799\n",
      "Epoch 239/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.8970 - val_loss: 14.3354\n",
      "Epoch 240/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.8542 - val_loss: 15.0086\n",
      "Epoch 241/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 11.9055 - val_loss: 15.2042\n",
      "Epoch 242/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.9321 - val_loss: 14.5640\n",
      "Epoch 243/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.9681 - val_loss: 15.6935\n",
      "Epoch 244/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.9170 - val_loss: 14.1734\n",
      "Epoch 245/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.7600 - val_loss: 18.6988\n",
      "Epoch 246/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.1415 - val_loss: 14.4044\n",
      "Epoch 247/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.9762 - val_loss: 15.5637\n",
      "Epoch 248/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.7636 - val_loss: 15.2424\n",
      "Epoch 249/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.6528 - val_loss: 14.4159\n",
      "Epoch 250/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.9272 - val_loss: 14.7012\n",
      "Epoch 251/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.9291 - val_loss: 15.3332\n",
      "Epoch 252/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.9851 - val_loss: 14.4217\n",
      "Epoch 253/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 12.1512 - val_loss: 14.8089\n",
      "Epoch 254/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 12.4117 - val_loss: 14.1934\n",
      "Epoch 255/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.4320 - val_loss: 15.4943\n",
      "Epoch 256/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 12.1848 - val_loss: 14.7860\n",
      "Epoch 257/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.9203 - val_loss: 14.8475\n",
      "Epoch 258/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 12.4498 - val_loss: 14.3887\n",
      "Epoch 259/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.5469 - val_loss: 14.3378\n",
      "Epoch 260/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 12.0954 - val_loss: 14.4815\n",
      "Epoch 261/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 11.9363 - val_loss: 15.4982\n",
      "Epoch 262/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 12.0825 - val_loss: 14.1849\n",
      "Epoch 263/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.9618 - val_loss: 14.6575\n",
      "Epoch 264/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.3741 - val_loss: 14.7536\n",
      "Epoch 265/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.9558 - val_loss: 15.0742\n",
      "Epoch 266/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.5799 - val_loss: 14.1826\n",
      "Epoch 267/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.6071 - val_loss: 15.0771\n",
      "Epoch 268/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 12.0154 - val_loss: 14.4259\n",
      "Epoch 269/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.0204 - val_loss: 15.7528\n",
      "Epoch 270/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 12.5671 - val_loss: 14.8584\n",
      "Epoch 271/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.4529 - val_loss: 15.6233\n",
      "Epoch 272/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 12.0297 - val_loss: 14.0936\n",
      "Epoch 273/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.3997 - val_loss: 13.9801\n",
      "Epoch 274/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.5024 - val_loss: 14.7879\n",
      "Epoch 275/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 12.8062 - val_loss: 15.4054\n",
      "Epoch 276/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.0990 - val_loss: 16.0195\n",
      "Epoch 277/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.7139 - val_loss: 14.6866\n",
      "Epoch 278/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.0755 - val_loss: 13.8174\n",
      "Epoch 279/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.4797 - val_loss: 15.3297\n",
      "Epoch 280/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.8288 - val_loss: 14.4549\n",
      "Epoch 281/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.6630 - val_loss: 14.6269\n",
      "Epoch 282/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.0004 - val_loss: 14.9140\n",
      "Epoch 283/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 12.4237 - val_loss: 17.2508\n",
      "Epoch 284/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.7982 - val_loss: 14.2862\n",
      "Epoch 285/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.8346 - val_loss: 15.1733\n",
      "Epoch 286/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.6512 - val_loss: 13.8880\n",
      "Epoch 287/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.2329 - val_loss: 15.4056\n",
      "Epoch 288/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.9079 - val_loss: 14.6209\n",
      "Epoch 289/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.3927 - val_loss: 16.5070\n",
      "Epoch 290/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.6131 - val_loss: 14.6292\n",
      "Epoch 291/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.4872 - val_loss: 15.0084\n",
      "Epoch 292/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.6632 - val_loss: 14.2834\n",
      "Epoch 293/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 12.0728 - val_loss: 15.1785\n",
      "Epoch 294/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.3737 - val_loss: 14.7496\n",
      "Epoch 295/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.1978 - val_loss: 17.8168\n",
      "Epoch 296/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 12.4388 - val_loss: 14.2765\n",
      "Epoch 297/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 12.2724 - val_loss: 14.6713\n",
      "Epoch 298/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.7118 - val_loss: 15.8262\n",
      "Epoch 299/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.6839 - val_loss: 14.0656\n",
      "Epoch 300/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.9050 - val_loss: 14.3071\n",
      "Epoch 301/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 13.9466 - val_loss: 14.1011\n",
      "Epoch 302/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.4198 - val_loss: 14.4870\n",
      "Epoch 303/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.7755 - val_loss: 13.6999\n",
      "Epoch 304/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.8530 - val_loss: 15.0860\n",
      "Epoch 305/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 12.1594 - val_loss: 14.5255\n",
      "Epoch 306/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.9545 - val_loss: 15.4171\n",
      "Epoch 307/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.8968 - val_loss: 14.7459\n",
      "Epoch 308/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.6146 - val_loss: 15.1028\n",
      "Epoch 309/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.7292 - val_loss: 14.3925\n",
      "Epoch 310/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.9423 - val_loss: 15.9759\n",
      "Epoch 311/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.6838 - val_loss: 14.2891\n",
      "Epoch 312/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.9413 - val_loss: 14.8405\n",
      "Epoch 313/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.0622 - val_loss: 13.7715\n",
      "Epoch 314/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.0846 - val_loss: 13.7114\n",
      "Epoch 315/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.4154 - val_loss: 15.0461\n",
      "Epoch 316/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.1231 - val_loss: 15.5171\n",
      "Epoch 317/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 12.0113 - val_loss: 15.5608\n",
      "Epoch 318/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.0580 - val_loss: 14.1473\n",
      "Epoch 319/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.0029 - val_loss: 14.4402\n",
      "Epoch 320/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.9349 - val_loss: 13.8976\n",
      "Epoch 321/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.9676 - val_loss: 13.9165\n",
      "Epoch 322/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.8195 - val_loss: 14.0246\n",
      "Epoch 323/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 12.1373 - val_loss: 14.7921\n",
      "Epoch 324/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.9716 - val_loss: 13.9755\n",
      "Epoch 325/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.0315 - val_loss: 15.0830\n",
      "Epoch 326/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.6947 - val_loss: 15.8440\n",
      "Epoch 327/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.7308 - val_loss: 14.6496\n",
      "Epoch 328/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.1003 - val_loss: 16.8669\n",
      "Epoch 329/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 13.3350 - val_loss: 14.9276\n",
      "Epoch 330/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.7471 - val_loss: 14.0932\n",
      "Epoch 331/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.9141 - val_loss: 14.3983\n",
      "Epoch 332/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.5164 - val_loss: 15.3346\n",
      "Epoch 333/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 12.1076 - val_loss: 15.1906\n",
      "Epoch 334/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.4743 - val_loss: 13.8285\n",
      "Epoch 335/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.0354 - val_loss: 15.6144\n",
      "Epoch 336/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.8807 - val_loss: 15.4352\n",
      "Epoch 337/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.9441 - val_loss: 15.5314\n",
      "Epoch 338/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 12.2368 - val_loss: 13.9901\n",
      "Epoch 339/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.4630 - val_loss: 15.1757\n",
      "Epoch 340/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.9755 - val_loss: 14.0148\n",
      "Epoch 341/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.7984 - val_loss: 14.3996\n",
      "Epoch 342/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.2776 - val_loss: 16.7556\n",
      "Epoch 343/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.1461 - val_loss: 14.8686\n",
      "Epoch 344/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.7969 - val_loss: 14.3234\n",
      "Epoch 345/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.6200 - val_loss: 16.6716\n",
      "Epoch 346/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 12.2135 - val_loss: 14.1058\n",
      "Epoch 347/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 12.1823 - val_loss: 14.7322\n",
      "Epoch 348/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.5588 - val_loss: 14.4543\n",
      "Epoch 349/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.7049 - val_loss: 13.9944\n",
      "Epoch 350/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 11.8037 - val_loss: 14.2645\n",
      "Epoch 351/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.8167 - val_loss: 15.6763\n",
      "Epoch 352/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 11.8203 - val_loss: 16.2379\n",
      "Epoch 353/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.8459 - val_loss: 14.2863\n",
      "Epoch 354/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.6686 - val_loss: 14.9560\n",
      "Epoch 355/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.9135 - val_loss: 15.1907\n",
      "Epoch 356/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.1050 - val_loss: 14.9129\n",
      "Epoch 357/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.0812 - val_loss: 15.0810\n",
      "Epoch 358/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.9592 - val_loss: 14.9405\n",
      "Epoch 359/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.2126 - val_loss: 14.9161\n",
      "Epoch 360/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.2810 - val_loss: 13.9176\n",
      "Epoch 361/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 12.2698 - val_loss: 14.6262\n",
      "Epoch 362/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.3265 - val_loss: 14.6249\n",
      "Epoch 363/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.6728 - val_loss: 14.6963\n",
      "Epoch 364/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.2259 - val_loss: 14.2822\n",
      "Epoch 365/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 12.2205 - val_loss: 13.9657\n",
      "Epoch 366/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.6217 - val_loss: 14.6766\n",
      "Epoch 367/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.7583 - val_loss: 14.9712\n",
      "Epoch 368/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.5059 - val_loss: 13.8555\n",
      "Epoch 369/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.4480 - val_loss: 16.3326\n",
      "Epoch 370/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.9573 - val_loss: 15.9162\n",
      "Epoch 371/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.4390 - val_loss: 15.7157\n",
      "Epoch 372/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.7171 - val_loss: 14.4693\n",
      "Epoch 373/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.0301 - val_loss: 14.9876\n",
      "Epoch 374/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.8629 - val_loss: 15.2250\n",
      "Epoch 375/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 12.5562 - val_loss: 15.6016\n",
      "Epoch 376/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.0017 - val_loss: 14.0042\n",
      "Epoch 377/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.9242 - val_loss: 14.6006\n",
      "Epoch 378/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.7526 - val_loss: 14.2106\n",
      "Epoch 379/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.5204 - val_loss: 14.2730\n",
      "Epoch 380/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.8093 - val_loss: 16.7804\n",
      "Epoch 381/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.5176 - val_loss: 13.8275\n",
      "Epoch 382/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 12.7968 - val_loss: 13.9290\n",
      "Epoch 383/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.9362 - val_loss: 13.9957\n",
      "Epoch 384/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.8709 - val_loss: 15.2248\n",
      "Epoch 385/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.1656 - val_loss: 15.3878\n",
      "Epoch 386/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.3030 - val_loss: 14.2230\n",
      "Epoch 387/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.5705 - val_loss: 14.3298\n",
      "Epoch 388/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 12.0806 - val_loss: 14.4095\n",
      "Epoch 389/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 11.8371 - val_loss: 17.1978\n",
      "Epoch 390/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 13.0035 - val_loss: 14.0207\n",
      "Epoch 391/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 11.8406 - val_loss: 13.6642\n",
      "Epoch 392/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 11.8645 - val_loss: 17.1040\n",
      "Epoch 393/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 11.8595 - val_loss: 15.7763\n",
      "Epoch 394/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.5989 - val_loss: 14.6634\n",
      "Epoch 395/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 12.1506 - val_loss: 14.5361\n",
      "Epoch 396/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.8041 - val_loss: 14.6877\n",
      "Epoch 397/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.7968 - val_loss: 15.3498\n",
      "Epoch 398/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.1152 - val_loss: 14.3756\n",
      "Epoch 399/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.9761 - val_loss: 13.9566\n",
      "Epoch 400/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.9399 - val_loss: 15.1404\n",
      "Epoch 401/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.1616 - val_loss: 13.7047\n",
      "Epoch 402/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.9145 - val_loss: 15.0896\n",
      "Epoch 403/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.7048 - val_loss: 17.2424\n",
      "Epoch 404/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.1886 - val_loss: 14.5245\n",
      "Epoch 405/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.7218 - val_loss: 14.4018\n",
      "Epoch 406/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 11.6933 - val_loss: 14.3470\n",
      "Epoch 407/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.6940 - val_loss: 15.0334\n",
      "Epoch 408/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.7855 - val_loss: 13.6209\n",
      "Epoch 409/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.9362 - val_loss: 15.4507\n",
      "Epoch 410/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 12.3807 - val_loss: 14.1755\n",
      "Epoch 411/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.9387 - val_loss: 14.4883\n",
      "Epoch 412/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.2352 - val_loss: 15.4365\n",
      "Epoch 413/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.3400 - val_loss: 14.2576\n",
      "Epoch 414/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.0375 - val_loss: 14.7266\n",
      "Epoch 415/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.7129 - val_loss: 14.4096\n",
      "Epoch 416/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.8126 - val_loss: 14.7829\n",
      "Epoch 417/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.1648 - val_loss: 15.1525\n",
      "Epoch 418/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 12.3487 - val_loss: 15.2541\n",
      "Epoch 419/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.6189 - val_loss: 15.0461\n",
      "Epoch 420/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.3174 - val_loss: 15.2211\n",
      "Epoch 421/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.7409 - val_loss: 15.0449\n",
      "Epoch 422/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.0478 - val_loss: 14.2508\n",
      "Epoch 423/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.2718 - val_loss: 13.4450\n",
      "Epoch 424/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.7909 - val_loss: 15.2740\n",
      "Epoch 425/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.7341 - val_loss: 14.0617\n",
      "Epoch 426/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.0458 - val_loss: 14.1909\n",
      "Epoch 427/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.4667 - val_loss: 14.4979\n",
      "Epoch 428/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.3248 - val_loss: 13.8013\n",
      "Epoch 429/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.2361 - val_loss: 13.7941\n",
      "Epoch 430/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.8271 - val_loss: 14.3755\n",
      "Epoch 431/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.5853 - val_loss: 13.9883\n",
      "Epoch 432/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.5398 - val_loss: 13.3112\n",
      "Epoch 433/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.3677 - val_loss: 15.8100\n",
      "Epoch 434/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.6409 - val_loss: 13.5803\n",
      "Epoch 435/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.1574 - val_loss: 13.8456\n",
      "Epoch 436/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.2781 - val_loss: 15.3276\n",
      "Epoch 437/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.1170 - val_loss: 13.5231\n",
      "Epoch 438/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.6293 - val_loss: 15.4727\n",
      "Epoch 439/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.0105 - val_loss: 14.5863\n",
      "Epoch 440/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.0651 - val_loss: 13.9213\n",
      "Epoch 441/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.5067 - val_loss: 14.6916\n",
      "Epoch 442/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.0013 - val_loss: 14.0987\n",
      "Epoch 443/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.5170 - val_loss: 13.7819\n",
      "Epoch 444/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.0877 - val_loss: 14.7954\n",
      "Epoch 445/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.5815 - val_loss: 15.6643\n",
      "Epoch 446/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.4931 - val_loss: 13.5888\n",
      "Epoch 447/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.0777 - val_loss: 13.2607\n",
      "Epoch 448/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.3154 - val_loss: 13.8978\n",
      "Epoch 449/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.9221 - val_loss: 14.6429\n",
      "Epoch 450/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.4069 - val_loss: 13.5412\n",
      "Epoch 451/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.2527 - val_loss: 13.3992\n",
      "Epoch 452/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.3471 - val_loss: 14.5468\n",
      "Epoch 453/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 11.9207 - val_loss: 14.6231\n",
      "Epoch 454/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.1140 - val_loss: 13.9677\n",
      "Epoch 455/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.5215 - val_loss: 13.4758\n",
      "Epoch 456/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.5516 - val_loss: 13.9283\n",
      "Epoch 457/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.2611 - val_loss: 13.6259\n",
      "Epoch 458/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.0199 - val_loss: 14.1850\n",
      "Epoch 459/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.6386 - val_loss: 13.4840\n",
      "Epoch 460/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 11.2003 - val_loss: 13.5368\n",
      "Epoch 461/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.7451 - val_loss: 13.6480\n",
      "Epoch 462/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.2689 - val_loss: 13.5494\n",
      "Epoch 463/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.5704 - val_loss: 13.3810\n",
      "Epoch 464/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.3638 - val_loss: 14.3860\n",
      "Epoch 465/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.4709 - val_loss: 13.7700\n",
      "Epoch 466/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.4915 - val_loss: 15.7633\n",
      "Epoch 467/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.6394 - val_loss: 13.7041\n",
      "Epoch 468/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.6732 - val_loss: 14.5534\n",
      "Epoch 469/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.9466 - val_loss: 13.8933\n",
      "Epoch 470/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 10.9796 - val_loss: 14.0594\n",
      "Epoch 471/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.4744 - val_loss: 13.9565\n",
      "Epoch 472/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.4284 - val_loss: 13.4747\n",
      "Epoch 473/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.5533 - val_loss: 13.6305\n",
      "Epoch 474/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.0638 - val_loss: 14.7829\n",
      "Epoch 475/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.2864 - val_loss: 13.5687\n",
      "Epoch 476/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 11.4754 - val_loss: 13.8415\n",
      "Epoch 477/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.7794 - val_loss: 14.0912\n",
      "Epoch 478/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.8546 - val_loss: 13.6660\n",
      "Epoch 479/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.2233 - val_loss: 13.3575\n",
      "Epoch 480/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.9685 - val_loss: 14.3440\n",
      "Epoch 481/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.9919 - val_loss: 15.2458\n",
      "Epoch 482/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.1702 - val_loss: 13.8077\n",
      "Epoch 483/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.5451 - val_loss: 14.3608\n",
      "Epoch 484/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.9181 - val_loss: 13.8715\n",
      "Epoch 485/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.5024 - val_loss: 13.6074\n",
      "Epoch 486/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.1543 - val_loss: 13.6857\n",
      "Epoch 487/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.1415 - val_loss: 14.0568\n",
      "Epoch 488/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.7478 - val_loss: 14.4380\n",
      "Epoch 489/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.0024 - val_loss: 13.6797\n",
      "Epoch 490/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.1698 - val_loss: 13.9831\n",
      "Epoch 491/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.5687 - val_loss: 13.9040\n",
      "Epoch 492/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.9500 - val_loss: 13.3568\n",
      "Epoch 493/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.1273 - val_loss: 13.4491\n",
      "Epoch 494/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.2989 - val_loss: 13.4271\n",
      "Epoch 495/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 12.3917 - val_loss: 14.4315\n",
      "Epoch 496/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.5314 - val_loss: 15.3722\n",
      "Epoch 497/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.5812 - val_loss: 13.3390\n",
      "Epoch 498/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.6491 - val_loss: 14.6775\n",
      "Epoch 499/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.3757 - val_loss: 13.4092\n",
      "Epoch 500/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.9326 - val_loss: 13.6148\n",
      "Epoch 501/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.4352 - val_loss: 13.3028\n",
      "Epoch 502/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 11.2337 - val_loss: 13.5034\n",
      "Epoch 503/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.3297 - val_loss: 14.3698\n",
      "Epoch 504/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.7591 - val_loss: 13.5139\n",
      "Epoch 505/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.7688 - val_loss: 14.0765\n",
      "Epoch 506/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.1604 - val_loss: 14.0274\n",
      "Epoch 507/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.1701 - val_loss: 14.5748\n",
      "Epoch 508/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.4708 - val_loss: 14.0803\n",
      "Epoch 509/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 11.8984 - val_loss: 14.6557\n",
      "Epoch 510/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.4671 - val_loss: 14.3015\n",
      "Epoch 511/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.5289 - val_loss: 13.2812\n",
      "Epoch 512/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.6909 - val_loss: 15.2540\n",
      "Epoch 513/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.3325 - val_loss: 13.3404\n",
      "Epoch 514/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.2318 - val_loss: 14.3299\n",
      "Epoch 515/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.5877 - val_loss: 14.0898\n",
      "Epoch 516/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.9143 - val_loss: 14.7148\n",
      "Epoch 517/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.5657 - val_loss: 14.5121\n",
      "Epoch 518/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.2602 - val_loss: 14.0156\n",
      "Epoch 519/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.5849 - val_loss: 15.5773\n",
      "Epoch 520/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.6335 - val_loss: 13.4482\n",
      "Epoch 521/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.3681 - val_loss: 14.6766\n",
      "Epoch 522/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.0247 - val_loss: 14.5352\n",
      "Epoch 523/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.5903 - val_loss: 14.5102\n",
      "Epoch 524/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.3522 - val_loss: 14.5500\n",
      "Epoch 525/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.7361 - val_loss: 14.6708\n",
      "Epoch 526/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.3254 - val_loss: 15.0356\n",
      "Epoch 527/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 11.6093 - val_loss: 14.1911\n",
      "Epoch 528/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.2900 - val_loss: 13.3068\n",
      "Epoch 529/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.4819 - val_loss: 13.6473\n",
      "Epoch 530/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.3240 - val_loss: 13.8787\n",
      "Epoch 531/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.1739 - val_loss: 13.6382\n",
      "Epoch 532/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.9258 - val_loss: 14.9959\n",
      "Epoch 533/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.7885 - val_loss: 15.2476\n",
      "Epoch 534/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.8272 - val_loss: 14.9352\n",
      "Epoch 535/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.5208 - val_loss: 14.4223\n",
      "Epoch 536/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.9976 - val_loss: 14.2237\n",
      "Epoch 537/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.0968 - val_loss: 13.3303\n",
      "Epoch 538/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.1962 - val_loss: 13.7747\n",
      "Epoch 539/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.5783 - val_loss: 13.7025\n",
      "Epoch 540/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.2557 - val_loss: 13.3853\n",
      "Epoch 541/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.2465 - val_loss: 14.0486\n",
      "Epoch 542/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.4075 - val_loss: 13.3289\n",
      "Epoch 543/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.1759 - val_loss: 13.6532\n",
      "Epoch 544/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.8554 - val_loss: 13.7973\n",
      "Epoch 545/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.5322 - val_loss: 14.4976\n",
      "Epoch 546/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.6120 - val_loss: 13.9723\n",
      "Epoch 547/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.6930 - val_loss: 13.4871\n",
      "Epoch 548/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.3139 - val_loss: 14.4636\n",
      "Epoch 549/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.1578 - val_loss: 13.8879\n",
      "Epoch 550/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.3425 - val_loss: 13.6549\n",
      "Epoch 551/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.3721 - val_loss: 14.1800\n",
      "Epoch 552/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.4706 - val_loss: 14.4782\n",
      "Epoch 553/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.6453 - val_loss: 14.0253\n",
      "Epoch 554/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.3132 - val_loss: 14.4691\n",
      "Epoch 555/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 12.3353 - val_loss: 14.5111\n",
      "Epoch 556/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.5868 - val_loss: 14.1260\n",
      "Epoch 557/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 11.0817 - val_loss: 14.1099\n",
      "Epoch 558/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 11.0263 - val_loss: 13.5969\n",
      "Epoch 559/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 11.3241 - val_loss: 13.9349\n",
      "Epoch 560/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 11.4054 - val_loss: 15.1135\n",
      "Epoch 561/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 11.5776 - val_loss: 13.7079\n",
      "Epoch 562/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 11.4302 - val_loss: 13.5568\n",
      "Epoch 563/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.2691 - val_loss: 13.9311\n",
      "Epoch 564/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.3014 - val_loss: 15.5650\n",
      "Epoch 565/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.5635 - val_loss: 14.1407\n",
      "Epoch 566/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.2143 - val_loss: 13.4428\n",
      "Epoch 567/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.5008 - val_loss: 14.1784\n",
      "Epoch 568/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.2811 - val_loss: 15.3289\n",
      "Epoch 569/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.3970 - val_loss: 15.5519\n",
      "Epoch 570/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.6027 - val_loss: 13.6827\n",
      "Epoch 571/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.9353 - val_loss: 14.5019\n",
      "Epoch 572/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.2480 - val_loss: 13.6437\n",
      "Epoch 573/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.4911 - val_loss: 15.4163\n",
      "Epoch 574/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.6558 - val_loss: 15.7314\n",
      "Epoch 575/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.6213 - val_loss: 14.0552\n",
      "Epoch 576/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.4085 - val_loss: 13.3644\n",
      "Epoch 577/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.5951 - val_loss: 14.1469\n",
      "Epoch 578/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.7363 - val_loss: 13.8672\n",
      "Epoch 579/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.5432 - val_loss: 13.5903\n",
      "Epoch 580/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.6788 - val_loss: 16.0691\n",
      "Epoch 581/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 12.1056 - val_loss: 14.7753\n",
      "Epoch 582/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.5486 - val_loss: 15.0304\n",
      "Epoch 583/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.1701 - val_loss: 14.7796\n",
      "Epoch 584/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.0217 - val_loss: 14.0340\n",
      "Epoch 585/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.7092 - val_loss: 14.1825\n",
      "Epoch 586/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.3108 - val_loss: 13.8081\n",
      "Epoch 587/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.2518 - val_loss: 17.0886\n",
      "Epoch 588/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.2725 - val_loss: 14.0279\n",
      "Epoch 589/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 11.4496 - val_loss: 15.4012\n",
      "Epoch 590/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.3822 - val_loss: 13.8316\n",
      "Epoch 591/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.8629 - val_loss: 14.0926\n",
      "Epoch 592/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 95us/step - loss: 12.9187 - val_loss: 13.3386\n",
      "Epoch 593/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 11.5994 - val_loss: 13.9949\n",
      "Epoch 594/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.4566 - val_loss: 13.7497\n",
      "Epoch 595/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.4974 - val_loss: 13.2047\n",
      "Epoch 596/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.5017 - val_loss: 13.6849\n",
      "Epoch 597/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.6983 - val_loss: 13.7248\n",
      "Epoch 598/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.3113 - val_loss: 14.4149\n",
      "Epoch 599/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.7298 - val_loss: 13.6115\n",
      "Epoch 600/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.3498 - val_loss: 17.6485\n",
      "Epoch 601/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 12.7143 - val_loss: 14.6152\n",
      "Epoch 602/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.5612 - val_loss: 14.3047\n",
      "Epoch 603/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.9018 - val_loss: 13.7000\n",
      "Epoch 604/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.2028 - val_loss: 14.8404\n",
      "Epoch 605/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.5194 - val_loss: 14.0709\n",
      "Epoch 606/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.2750 - val_loss: 13.2806\n",
      "Epoch 607/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.7039 - val_loss: 14.3203\n",
      "Epoch 608/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.3332 - val_loss: 13.1785\n",
      "Epoch 609/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 11.5277 - val_loss: 15.1334\n",
      "Epoch 610/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.7678 - val_loss: 13.9837\n",
      "Epoch 611/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.2034 - val_loss: 16.5124\n",
      "Epoch 612/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.6817 - val_loss: 14.0948\n",
      "Epoch 613/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 11.3361 - val_loss: 13.4603\n",
      "Epoch 614/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.0043 - val_loss: 16.6581\n",
      "Epoch 615/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.7330 - val_loss: 13.3323\n",
      "Epoch 616/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.1454 - val_loss: 14.2995\n",
      "Epoch 617/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.8556 - val_loss: 17.2619\n",
      "Epoch 618/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.3976 - val_loss: 14.7697\n",
      "Epoch 619/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.2787 - val_loss: 14.3904\n",
      "Epoch 620/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.3827 - val_loss: 13.9037\n",
      "Epoch 621/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.3637 - val_loss: 13.5578\n",
      "Epoch 622/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.1559 - val_loss: 14.4355\n",
      "Epoch 623/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 11.2972 - val_loss: 13.5250\n",
      "Epoch 624/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 11.6444 - val_loss: 13.2200\n",
      "Epoch 625/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.2426 - val_loss: 13.5194\n",
      "Epoch 626/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.4854 - val_loss: 13.2998\n",
      "Epoch 627/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.5524 - val_loss: 13.3113\n",
      "Epoch 628/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.9863 - val_loss: 13.4308\n",
      "Epoch 629/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.2805 - val_loss: 13.4935\n",
      "Epoch 630/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.4403 - val_loss: 14.5361\n",
      "Epoch 631/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.7051 - val_loss: 13.2084\n",
      "Epoch 632/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 11.2242 - val_loss: 14.3503\n",
      "Epoch 633/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.0964 - val_loss: 13.9425\n",
      "Epoch 634/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.8094 - val_loss: 13.6848\n",
      "Epoch 635/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.7098 - val_loss: 13.8825\n",
      "Epoch 636/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.2224 - val_loss: 13.4126\n",
      "Epoch 637/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.1761 - val_loss: 13.9518\n",
      "Epoch 638/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 12.0855 - val_loss: 13.8230\n",
      "Epoch 639/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.4610 - val_loss: 15.2994\n",
      "Epoch 640/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.5972 - val_loss: 15.0667\n",
      "Epoch 641/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.4563 - val_loss: 14.2378\n",
      "Epoch 642/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.9422 - val_loss: 13.2689\n",
      "Epoch 643/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.1696 - val_loss: 13.5474\n",
      "Epoch 644/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.6189 - val_loss: 14.5485\n",
      "Epoch 645/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.5858 - val_loss: 13.0944\n",
      "Epoch 646/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 12.1379 - val_loss: 14.4903\n",
      "Epoch 647/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 12.4957 - val_loss: 14.1333\n",
      "Epoch 648/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.5822 - val_loss: 13.5098\n",
      "Epoch 649/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.0789 - val_loss: 13.5867\n",
      "Epoch 650/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.2837 - val_loss: 13.9988\n",
      "Epoch 651/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.2720 - val_loss: 13.9430\n",
      "Epoch 652/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.8649 - val_loss: 14.5891\n",
      "Epoch 653/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 11.3512 - val_loss: 14.3880\n",
      "Epoch 654/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 11.6951 - val_loss: 13.9621\n",
      "Epoch 655/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.0356 - val_loss: 15.0663\n",
      "Epoch 656/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.4091 - val_loss: 13.4740\n",
      "Epoch 657/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 11.4691 - val_loss: 14.0716\n",
      "Epoch 658/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 11.4550 - val_loss: 13.5368\n",
      "Epoch 659/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.1031 - val_loss: 13.7841\n",
      "Epoch 660/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.3648 - val_loss: 13.3925\n",
      "Epoch 661/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 11.9276 - val_loss: 13.5098\n",
      "Epoch 662/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 11.2644 - val_loss: 13.5078\n",
      "Epoch 663/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.1047 - val_loss: 13.2702\n",
      "Epoch 664/1000\n",
      "1052/1052 [==============================] - 0s 123us/step - loss: 11.4213 - val_loss: 13.1635\n",
      "Epoch 665/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 11.4789 - val_loss: 13.4586\n",
      "Epoch 666/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 11.1487 - val_loss: 14.3802\n",
      "Epoch 667/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 98us/step - loss: 11.5568 - val_loss: 13.9772\n",
      "Epoch 668/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.4990 - val_loss: 13.6518\n",
      "Epoch 669/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.9190 - val_loss: 13.7697\n",
      "Epoch 670/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 12.0404 - val_loss: 13.7329\n",
      "Epoch 671/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.9364 - val_loss: 13.3476\n",
      "Epoch 672/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.8552 - val_loss: 13.1534\n",
      "Epoch 673/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.3479 - val_loss: 13.6513\n",
      "Epoch 674/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.4250 - val_loss: 14.6891\n",
      "Epoch 675/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 11.9660 - val_loss: 14.6236\n",
      "Epoch 676/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.2991 - val_loss: 13.2118\n",
      "Epoch 677/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.5950 - val_loss: 13.5871\n",
      "Epoch 678/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.3403 - val_loss: 14.1275\n",
      "Epoch 679/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.4336 - val_loss: 14.8564\n",
      "Epoch 680/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.4958 - val_loss: 14.3483\n",
      "Epoch 681/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.5525 - val_loss: 13.9322\n",
      "Epoch 682/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.5273 - val_loss: 13.7384\n",
      "Epoch 683/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 11.1358 - val_loss: 13.4130\n",
      "Epoch 684/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.6135 - val_loss: 13.6409\n",
      "Epoch 685/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 11.9550 - val_loss: 14.9676\n",
      "Epoch 686/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 12.4443 - val_loss: 13.3327\n",
      "Epoch 687/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.6198 - val_loss: 13.7913\n",
      "Epoch 688/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 11.5568 - val_loss: 13.0959\n",
      "Epoch 689/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 11.0251 - val_loss: 14.2507\n",
      "Epoch 690/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 11.2143 - val_loss: 15.1922\n",
      "Epoch 691/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.4069 - val_loss: 14.8984\n",
      "Epoch 692/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.2488 - val_loss: 13.3679\n",
      "Epoch 693/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 12.2604 - val_loss: 13.4610\n",
      "Epoch 694/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.1686 - val_loss: 13.4696\n",
      "Epoch 695/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.4095 - val_loss: 14.1948\n",
      "Epoch 696/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 11.6480 - val_loss: 14.0938\n",
      "Epoch 697/1000\n",
      "1052/1052 [==============================] - 0s 111us/step - loss: 11.6957 - val_loss: 14.9611\n",
      "Epoch 698/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.3114 - val_loss: 14.2101\n",
      "Epoch 699/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.6178 - val_loss: 13.4862\n",
      "Epoch 700/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 11.1801 - val_loss: 14.1593\n",
      "Epoch 701/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 11.3183 - val_loss: 13.7167\n",
      "Epoch 702/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 12.5908 - val_loss: 13.3922\n",
      "Epoch 703/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 12.6514 - val_loss: 17.8292\n",
      "Epoch 704/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.5395 - val_loss: 14.5651\n",
      "Epoch 705/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 11.3249 - val_loss: 14.2663\n",
      "Epoch 706/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.5606 - val_loss: 13.0743\n",
      "Epoch 707/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.2338 - val_loss: 14.2573\n",
      "Epoch 708/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.3144 - val_loss: 13.4467\n",
      "Epoch 709/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.1445 - val_loss: 14.3032\n",
      "Epoch 710/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.7209 - val_loss: 14.4459\n",
      "Epoch 711/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.6691 - val_loss: 13.9411\n",
      "Epoch 712/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.0796 - val_loss: 14.0449\n",
      "Epoch 713/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.8685 - val_loss: 14.0499\n",
      "Epoch 714/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.3085 - val_loss: 13.6386\n",
      "Epoch 715/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.0854 - val_loss: 13.5004\n",
      "Epoch 716/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 10.9663 - val_loss: 13.4396\n",
      "Epoch 717/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.2136 - val_loss: 14.0348\n",
      "Epoch 718/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.5828 - val_loss: 13.8363\n",
      "Epoch 719/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 11.4938 - val_loss: 14.2499\n",
      "Epoch 720/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 11.3795 - val_loss: 13.7302\n",
      "Epoch 721/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 11.4888 - val_loss: 14.9077\n",
      "Epoch 722/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 11.7079 - val_loss: 14.6044\n",
      "Epoch 723/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.2288 - val_loss: 14.7653\n",
      "Epoch 724/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 11.8676 - val_loss: 15.5756\n",
      "Epoch 725/1000\n",
      "1052/1052 [==============================] - 0s 113us/step - loss: 12.6762 - val_loss: 17.8527\n",
      "Epoch 726/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 12.5759 - val_loss: 13.5106\n",
      "Epoch 727/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 11.4058 - val_loss: 13.5117\n",
      "Epoch 728/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.9566 - val_loss: 14.7894\n",
      "Epoch 729/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 11.0217 - val_loss: 13.9577\n",
      "Epoch 730/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.0430 - val_loss: 13.6378\n",
      "Epoch 731/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.3436 - val_loss: 14.2447\n",
      "Epoch 732/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 12.1754 - val_loss: 13.3337\n",
      "Epoch 733/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 11.2396 - val_loss: 14.6307\n",
      "Epoch 734/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.7509 - val_loss: 14.7769\n",
      "Epoch 735/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 11.9845 - val_loss: 13.9938\n",
      "Epoch 736/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.9780 - val_loss: 14.1409\n",
      "Epoch 737/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.8461 - val_loss: 13.1707\n",
      "Epoch 738/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 11.1474 - val_loss: 15.1990\n",
      "Epoch 739/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 11.3345 - val_loss: 14.3472\n",
      "Epoch 740/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 11.0573 - val_loss: 13.4882\n",
      "Epoch 741/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.8348 - val_loss: 14.0989\n",
      "Epoch 742/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 84us/step - loss: 11.8050 - val_loss: 14.1631\n",
      "Epoch 743/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 12.1146 - val_loss: 14.2022\n",
      "Epoch 744/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 11.6969 - val_loss: 13.8061\n",
      "Epoch 745/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 11.6109 - val_loss: 15.4448\n",
      "Epoch 746/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.3434 - val_loss: 14.7322\n",
      "Epoch 747/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.8544 - val_loss: 14.4352\n",
      "Epoch 748/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.1207 - val_loss: 13.6761\n",
      "Epoch 749/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.2597 - val_loss: 13.3124\n",
      "Epoch 750/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 11.1852 - val_loss: 14.7308\n",
      "Epoch 751/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 11.2020 - val_loss: 13.4358\n",
      "Epoch 752/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.5222 - val_loss: 13.3625\n",
      "Epoch 753/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.2910 - val_loss: 13.6574\n",
      "Epoch 754/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 11.7216 - val_loss: 14.7911\n",
      "Epoch 755/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 11.9489 - val_loss: 13.3648\n",
      "Epoch 756/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 11.3997 - val_loss: 13.0938\n",
      "Epoch 757/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 11.6250 - val_loss: 14.2651\n",
      "Epoch 758/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.2180 - val_loss: 13.4561\n",
      "Epoch 759/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.5097 - val_loss: 13.4253\n",
      "Epoch 760/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.2704 - val_loss: 13.7103\n",
      "Epoch 761/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 11.2441 - val_loss: 13.4900\n",
      "Epoch 762/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 11.0274 - val_loss: 13.5467\n",
      "Epoch 763/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.0761 - val_loss: 15.7495\n",
      "Epoch 764/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.8473 - val_loss: 14.5128\n",
      "Epoch 765/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 11.1818 - val_loss: 13.8120\n",
      "Epoch 766/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 11.9413 - val_loss: 14.3073\n",
      "Epoch 767/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 11.9024 - val_loss: 14.8607\n",
      "Epoch 768/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.7263 - val_loss: 14.5865\n",
      "Epoch 769/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.5017 - val_loss: 13.7424\n",
      "Epoch 770/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.2613 - val_loss: 13.8636\n",
      "Epoch 771/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.6496 - val_loss: 14.6095\n",
      "Epoch 772/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 11.3304 - val_loss: 13.9167\n",
      "Epoch 773/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.2649 - val_loss: 14.0004\n",
      "Epoch 774/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.7569 - val_loss: 13.2229\n",
      "Epoch 775/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.8499 - val_loss: 13.8578\n",
      "Epoch 776/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 12.2773 - val_loss: 14.0604\n",
      "Epoch 777/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.1642 - val_loss: 13.6540\n",
      "Epoch 778/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.0511 - val_loss: 14.5476\n",
      "Epoch 779/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 11.4766 - val_loss: 14.2153\n",
      "Epoch 780/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 11.8770 - val_loss: 15.0735\n",
      "Epoch 781/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.6943 - val_loss: 14.2586\n",
      "Epoch 782/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.3119 - val_loss: 13.7560\n",
      "Epoch 783/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 11.2501 - val_loss: 13.7425\n",
      "Epoch 784/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 11.4920 - val_loss: 13.1442\n",
      "Epoch 785/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.3017 - val_loss: 13.7096\n",
      "Epoch 786/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 11.15 - 0s 86us/step - loss: 11.4603 - val_loss: 15.9070\n",
      "Epoch 787/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 11.7171 - val_loss: 14.0385\n",
      "Epoch 788/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.5423 - val_loss: 15.3598\n",
      "Epoch 789/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.9329 - val_loss: 14.1914\n",
      "Epoch 790/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.8477 - val_loss: 14.7345\n",
      "Epoch 791/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.1492 - val_loss: 14.2092\n",
      "Epoch 792/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.6900 - val_loss: 14.1879\n",
      "Epoch 793/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.9649 - val_loss: 13.1834\n",
      "Epoch 794/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.6702 - val_loss: 14.2682\n",
      "Epoch 795/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.9995 - val_loss: 14.7787\n",
      "Epoch 796/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.4892 - val_loss: 13.2359\n",
      "Epoch 797/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.4504 - val_loss: 13.5642\n",
      "Epoch 798/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 11.3873 - val_loss: 13.4225\n",
      "Epoch 799/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.1154 - val_loss: 13.5443\n",
      "Epoch 800/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.1165 - val_loss: 14.0383\n",
      "Epoch 801/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.3566 - val_loss: 13.3689\n",
      "Epoch 802/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.5946 - val_loss: 13.2756\n",
      "Epoch 803/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 11.2291 - val_loss: 13.2609\n",
      "Epoch 804/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.3860 - val_loss: 14.8714\n",
      "Epoch 805/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.2748 - val_loss: 13.6056\n",
      "Epoch 806/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 11.3386 - val_loss: 14.4272\n",
      "Epoch 807/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.2952 - val_loss: 13.7964\n",
      "Epoch 808/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.7750 - val_loss: 13.2818\n",
      "Epoch 809/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.2250 - val_loss: 14.2618\n",
      "Epoch 810/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 11.2023 - val_loss: 13.2387\n",
      "Epoch 811/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.1389 - val_loss: 13.5297\n",
      "Epoch 812/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.3118 - val_loss: 14.3910\n",
      "Epoch 813/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.0314 - val_loss: 13.9344\n",
      "Epoch 814/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.9277 - val_loss: 13.4972\n",
      "Epoch 815/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.6434 - val_loss: 14.1408\n",
      "Epoch 816/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.3315 - val_loss: 13.7234\n",
      "Epoch 817/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 84us/step - loss: 11.1065 - val_loss: 13.0433\n",
      "Epoch 818/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 11.2010 - val_loss: 13.6659\n",
      "Epoch 819/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.6026 - val_loss: 14.9567\n",
      "Epoch 820/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.0327 - val_loss: 14.6176\n",
      "Epoch 821/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.8462 - val_loss: 15.1965\n",
      "Epoch 822/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 11.4991 - val_loss: 14.3393\n",
      "Epoch 823/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.8734 - val_loss: 14.7174\n",
      "Epoch 824/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.5984 - val_loss: 16.8286\n",
      "Epoch 825/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.7320 - val_loss: 14.4154\n",
      "Epoch 826/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.8495 - val_loss: 15.1846\n",
      "Epoch 827/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 11.2784 - val_loss: 13.8704\n",
      "Epoch 828/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.7256 - val_loss: 14.1701\n",
      "Epoch 829/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.4088 - val_loss: 14.0675\n",
      "Epoch 830/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.4797 - val_loss: 14.2528\n",
      "Epoch 831/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.2721 - val_loss: 13.8809\n",
      "Epoch 832/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.3203 - val_loss: 14.2349\n",
      "Epoch 833/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.1594 - val_loss: 13.7468\n",
      "Epoch 834/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.2824 - val_loss: 13.2518\n",
      "Epoch 835/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 11.0843 - val_loss: 14.1167\n",
      "Epoch 836/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.7049 - val_loss: 13.7775\n",
      "Epoch 837/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 12.5747 - val_loss: 13.7004\n",
      "Epoch 838/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.5327 - val_loss: 14.0476\n",
      "Epoch 839/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 11.9198 - val_loss: 14.1606\n",
      "Epoch 840/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.6080 - val_loss: 14.2058\n",
      "Epoch 841/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.9490 - val_loss: 14.8791\n",
      "Epoch 842/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.5702 - val_loss: 14.5178\n",
      "Epoch 843/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.7444 - val_loss: 13.7671\n",
      "Epoch 844/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 11.2877 - val_loss: 13.5110\n",
      "Epoch 845/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.8381 - val_loss: 13.7671\n",
      "Epoch 846/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 11.3218 - val_loss: 14.2804\n",
      "Epoch 847/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.0889 - val_loss: 14.1326\n",
      "Epoch 848/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.2077 - val_loss: 14.2185\n",
      "Epoch 849/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.4650 - val_loss: 15.6246\n",
      "Epoch 850/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 11.3514 - val_loss: 14.8447\n",
      "Epoch 851/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 11.2642 - val_loss: 13.4268\n",
      "Epoch 852/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 11.2932 - val_loss: 14.8225\n",
      "Epoch 853/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 12.4108 - val_loss: 13.4493\n",
      "Epoch 854/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.5711 - val_loss: 14.1569\n",
      "Epoch 855/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 11.0916 - val_loss: 13.1449\n",
      "Epoch 856/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.2217 - val_loss: 14.3247\n",
      "Epoch 857/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.9480 - val_loss: 13.3774\n",
      "Epoch 858/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.3150 - val_loss: 13.5116\n",
      "Epoch 859/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 11.0956 - val_loss: 13.3440\n",
      "Epoch 860/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.9152 - val_loss: 13.9402\n",
      "Epoch 861/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.4726 - val_loss: 13.6919\n",
      "Epoch 862/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.6072 - val_loss: 16.7258\n",
      "Epoch 863/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 12.2044 - val_loss: 13.2571\n",
      "Epoch 864/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.1587 - val_loss: 13.5483\n",
      "Epoch 865/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 11.4190 - val_loss: 13.0859\n",
      "Epoch 866/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.3918 - val_loss: 14.5073\n",
      "Epoch 867/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.2930 - val_loss: 15.3887\n",
      "Epoch 868/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.4364 - val_loss: 13.9988\n",
      "Epoch 869/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.7145 - val_loss: 13.7735\n",
      "Epoch 870/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.8816 - val_loss: 14.0786\n",
      "Epoch 871/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.3955 - val_loss: 13.8992\n",
      "Epoch 872/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 11.5214 - val_loss: 15.4227\n",
      "Epoch 873/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 11.5044 - val_loss: 14.0645\n",
      "Epoch 874/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.2677 - val_loss: 13.9209\n",
      "Epoch 875/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.6076 - val_loss: 13.6048\n",
      "Epoch 876/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.2355 - val_loss: 13.8712\n",
      "Epoch 877/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.7876 - val_loss: 13.7783\n",
      "Epoch 878/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.4149 - val_loss: 14.2549\n",
      "Epoch 879/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.4615 - val_loss: 13.2716\n",
      "Epoch 880/1000\n",
      "1052/1052 [==============================] - 0s 110us/step - loss: 11.9704 - val_loss: 13.7101\n",
      "Epoch 881/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 11.4988 - val_loss: 14.4120\n",
      "Epoch 882/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 11.5440 - val_loss: 14.3377\n",
      "Epoch 883/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.4973 - val_loss: 13.5853\n",
      "Epoch 884/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 11.7086 - val_loss: 13.5082\n",
      "Epoch 885/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 11.1281 - val_loss: 14.3065\n",
      "Epoch 886/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.0878 - val_loss: 15.5909\n",
      "Epoch 887/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 13.3193 - val_loss: 14.3090\n",
      "Epoch 888/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.6315 - val_loss: 14.8552\n",
      "Epoch 889/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.5529 - val_loss: 13.3115\n",
      "Epoch 890/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.0072 - val_loss: 15.9691\n",
      "Epoch 891/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 12.3842 - val_loss: 15.0128\n",
      "Epoch 892/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 103us/step - loss: 11.8150 - val_loss: 13.9382\n",
      "Epoch 893/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 12.1843 - val_loss: 13.5576\n",
      "Epoch 894/1000\n",
      "1052/1052 [==============================] - 0s 112us/step - loss: 11.6417 - val_loss: 14.0283\n",
      "Epoch 895/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 11.6433 - val_loss: 13.9761\n",
      "Epoch 896/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 11.2276 - val_loss: 14.4472\n",
      "Epoch 897/1000\n",
      "1052/1052 [==============================] - 0s 113us/step - loss: 11.5458 - val_loss: 14.3717\n",
      "Epoch 898/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 11.6625 - val_loss: 15.4203\n",
      "Epoch 899/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.8134 - val_loss: 13.5183\n",
      "Epoch 900/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 11.3131 - val_loss: 14.6644\n",
      "Epoch 901/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 12.4272 - val_loss: 15.1129\n",
      "Epoch 902/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.5239 - val_loss: 15.0812\n",
      "Epoch 903/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.5574 - val_loss: 15.7764\n",
      "Epoch 904/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 13.3460 - val_loss: 14.5731\n",
      "Epoch 905/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.4092 - val_loss: 13.7130\n",
      "Epoch 906/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.4445 - val_loss: 14.5775\n",
      "Epoch 907/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.4709 - val_loss: 13.8038\n",
      "Epoch 908/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.7000 - val_loss: 13.3881\n",
      "Epoch 909/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.4193 - val_loss: 14.4391\n",
      "Epoch 910/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.3591 - val_loss: 13.4856\n",
      "Epoch 911/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.2664 - val_loss: 15.7304\n",
      "Epoch 912/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 11.14 - 0s 91us/step - loss: 11.3648 - val_loss: 16.0654\n",
      "Epoch 913/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 12.3443 - val_loss: 14.8068\n",
      "Epoch 914/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 11.8040 - val_loss: 13.6575\n",
      "Epoch 915/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.1338 - val_loss: 13.9909\n",
      "Epoch 916/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 11.1405 - val_loss: 13.5644\n",
      "Epoch 917/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 11.1411 - val_loss: 15.5968\n",
      "Epoch 918/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.3414 - val_loss: 13.2741\n",
      "Epoch 919/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 11.2247 - val_loss: 13.6185\n",
      "Epoch 920/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.1327 - val_loss: 13.3178\n",
      "Epoch 921/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.4769 - val_loss: 13.2927\n",
      "Epoch 922/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.1957 - val_loss: 14.0265\n",
      "Epoch 923/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.7835 - val_loss: 14.4443\n",
      "Epoch 924/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 12.3589 - val_loss: 14.1843\n",
      "Epoch 925/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.4132 - val_loss: 13.5430\n",
      "Epoch 926/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 11.1277 - val_loss: 13.1854\n",
      "Epoch 927/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 11.0326 - val_loss: 16.0397\n",
      "Epoch 928/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.4810 - val_loss: 13.4410\n",
      "Epoch 929/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.5852 - val_loss: 13.4970\n",
      "Epoch 930/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.7984 - val_loss: 15.3622\n",
      "Epoch 931/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.0080 - val_loss: 13.7961\n",
      "Epoch 932/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.6593 - val_loss: 15.4767\n",
      "Epoch 933/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.6668 - val_loss: 14.5172\n",
      "Epoch 934/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.6927 - val_loss: 15.0543\n",
      "Epoch 935/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 12.3599 - val_loss: 13.7752\n",
      "Epoch 936/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 11.3647 - val_loss: 14.1207\n",
      "Epoch 937/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.9907 - val_loss: 14.3328\n",
      "Epoch 938/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.1823 - val_loss: 14.2056\n",
      "Epoch 939/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.4359 - val_loss: 13.8230\n",
      "Epoch 940/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.2019 - val_loss: 13.5236\n",
      "Epoch 941/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.0830 - val_loss: 13.2200\n",
      "Epoch 942/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.0760 - val_loss: 13.8065\n",
      "Epoch 943/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.9939 - val_loss: 14.2151\n",
      "Epoch 944/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.4040 - val_loss: 13.8083\n",
      "Epoch 945/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.4705 - val_loss: 13.5788\n",
      "Epoch 946/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.2616 - val_loss: 13.3353\n",
      "Epoch 947/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.7378 - val_loss: 13.5934\n",
      "Epoch 948/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.7643 - val_loss: 13.7322\n",
      "Epoch 949/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.2516 - val_loss: 13.2945\n",
      "Epoch 950/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.1701 - val_loss: 13.5201\n",
      "Epoch 951/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.4082 - val_loss: 14.7794\n",
      "Epoch 952/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 11.7302 - val_loss: 13.1229\n",
      "Epoch 953/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.3491 - val_loss: 13.5053\n",
      "Epoch 954/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.7592 - val_loss: 17.0760\n",
      "Epoch 955/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.5087 - val_loss: 15.2375\n",
      "Epoch 956/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 12.0225 - val_loss: 13.4661\n",
      "Epoch 957/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 11.4745 - val_loss: 13.7849\n",
      "Epoch 958/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 11.0953 - val_loss: 13.7585\n",
      "Epoch 959/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.2442 - val_loss: 13.8559\n",
      "Epoch 960/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.9047 - val_loss: 13.4794\n",
      "Epoch 961/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.2993 - val_loss: 13.9506\n",
      "Epoch 962/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.3542 - val_loss: 14.4474\n",
      "Epoch 963/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.6495 - val_loss: 13.3511\n",
      "Epoch 964/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.7533 - val_loss: 13.8406\n",
      "Epoch 965/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.6025 - val_loss: 13.6185\n",
      "Epoch 966/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 11.2053 - val_loss: 13.3476\n",
      "Epoch 967/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.5590 - val_loss: 13.6896\n",
      "Epoch 968/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.4907 - val_loss: 14.2057\n",
      "Epoch 969/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.1396 - val_loss: 13.5587\n",
      "Epoch 970/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.7622 - val_loss: 14.3505\n",
      "Epoch 971/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.4928 - val_loss: 15.0824\n",
      "Epoch 972/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.4836 - val_loss: 13.6322\n",
      "Epoch 973/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 11.3970 - val_loss: 13.4072\n",
      "Epoch 974/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.5201 - val_loss: 13.4287\n",
      "Epoch 975/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.2490 - val_loss: 14.3376\n",
      "Epoch 976/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 11.9179 - val_loss: 14.8753\n",
      "Epoch 977/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 11.2146 - val_loss: 13.7575\n",
      "Epoch 978/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.4662 - val_loss: 14.2912\n",
      "Epoch 979/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.6236 - val_loss: 14.5281\n",
      "Epoch 980/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.8362 - val_loss: 13.8692\n",
      "Epoch 981/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.4367 - val_loss: 13.7243\n",
      "Epoch 982/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.1763 - val_loss: 16.0216\n",
      "Epoch 983/1000\n",
      "1052/1052 [==============================] - 0s 124us/step - loss: 12.2558 - val_loss: 17.8204\n",
      "Epoch 984/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 12.6444 - val_loss: 15.9785\n",
      "Epoch 985/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.1906 - val_loss: 13.2520\n",
      "Epoch 986/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 11.4172 - val_loss: 13.4862\n",
      "Epoch 987/1000\n",
      "1052/1052 [==============================] - 0s 144us/step - loss: 11.8391 - val_loss: 13.9860\n",
      "Epoch 988/1000\n",
      "1052/1052 [==============================] - 0s 118us/step - loss: 11.6301 - val_loss: 14.3700\n",
      "Epoch 989/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.4425 - val_loss: 14.0572\n",
      "Epoch 990/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 11.1395 - val_loss: 13.5152\n",
      "Epoch 991/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.4182 - val_loss: 13.2363\n",
      "Epoch 992/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.4456 - val_loss: 14.2305\n",
      "Epoch 993/1000\n",
      "1052/1052 [==============================] - 0s 117us/step - loss: 11.4508 - val_loss: 15.5166\n",
      "Epoch 994/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 11.6519 - val_loss: 13.9868\n",
      "Epoch 995/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.4669 - val_loss: 16.6021\n",
      "Epoch 996/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 12.0551 - val_loss: 13.0065\n",
      "Epoch 997/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 11.6775 - val_loss: 13.8083\n",
      "Epoch 998/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 11.5442 - val_loss: 13.1930\n",
      "Epoch 999/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.0396 - val_loss: 14.5623\n",
      "Epoch 1000/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 12.3761 - val_loss: 13.7738\n",
      "10.5850738371368\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.31571296, -0.38110504, -3.769983  ,  0.11913731, -1.7195567 ],\n",
       "        [-0.23514554,  0.02222654, -0.06436571, -0.25299507,  0.8710252 ],\n",
       "        [ 2.206672  ,  0.5852924 , -0.9175721 , -2.1951203 , -0.03383337],\n",
       "        [ 0.07774983,  0.03995496,  0.18881723,  0.05850926,  0.17726563],\n",
       "        [ 0.4514462 , -1.028287  , -0.50851274, -0.19075231,  0.96649754]],\n",
       "       dtype=float32),\n",
       " array([ 2.6104069,  3.5114892, -2.7942383,  3.6506455,  0.8097739],\n",
       "       dtype=float32),\n",
       " array([[-0.3438415 ,  1.1507928 , -0.5571401 ,  0.03497237,  0.8969057 ,\n",
       "         -1.0122128 ,  0.989814  , -0.23544563,  1.2580944 , -0.1907548 ],\n",
       "        [-0.7738095 ,  0.5596551 , -0.07651436,  1.0835688 , -0.01368968,\n",
       "         -0.39661095,  1.4969416 , -0.22487035,  1.5679551 , -0.11425459],\n",
       "        [-0.4324529 , -1.5551146 , -0.41895422, -1.6259886 , -1.133219  ,\n",
       "         -0.6088671 , -1.2403544 , -0.8458967 , -1.5708776 , -0.42115033],\n",
       "        [-0.26141056,  1.2381513 , -0.32299986,  0.6694634 ,  0.8852173 ,\n",
       "         -0.57208407,  1.7976264 , -0.3102568 ,  1.9989294 , -0.0458734 ],\n",
       "        [-0.55793107,  0.7170909 , -0.57856226,  0.2687582 ,  0.59519565,\n",
       "         -0.32667416,  0.5289783 , -0.50132203,  0.50638634, -0.57073915]],\n",
       "       dtype=float32),\n",
       " array([-0.52338475,  3.450629  ,  0.        ,  3.4247463 ,  3.3874977 ,\n",
       "        -0.61350787,  3.479929  , -0.38393778,  3.4957218 , -0.42293555],\n",
       "       dtype=float32),\n",
       " array([[-0.13043435],\n",
       "        [ 1.7145237 ],\n",
       "        [-0.01628882],\n",
       "        [ 1.5127237 ],\n",
       "        [ 1.2043146 ],\n",
       "        [-0.08603185],\n",
       "        [ 1.7069162 ],\n",
       "        [ 0.29628977],\n",
       "        [ 1.8807495 ],\n",
       "        [ 0.23099971]], dtype=float32),\n",
       " array([3.5178149], dtype=float32)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_airfoil, history_airfoil, evaluate_airfoil=NN_model_structure_regression_relu(X_train_airfoil, X_val_airfoil, Y_train_airfoil, Y_val_airfoil, adam2, 32, 1000, x_test_airfoil, y_test_airfoil)\n",
    "model_airfoil.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_airfoil.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_airfoil_relu_4th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 101\n",
      "Trainable params: 101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1052 samples, validate on 225 samples\n",
      "Epoch 1/1000\n",
      "1052/1052 [==============================] - 0s 246us/step - loss: 13474.7667 - val_loss: 11432.0780\n",
      "Epoch 2/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9847.5244 - val_loss: 8578.4742\n",
      "Epoch 3/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 7619.0728 - val_loss: 6834.7877\n",
      "Epoch 4/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 6155.1381 - val_loss: 5597.4088\n",
      "Epoch 5/1000\n",
      "1052/1052 [==============================] - 0s 109us/step - loss: 5078.4511 - val_loss: 4658.7124\n",
      "Epoch 6/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 4243.8331 - val_loss: 3915.4279\n",
      "Epoch 7/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 3575.2751 - val_loss: 3311.5417\n",
      "Epoch 8/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 3005.4807 - val_loss: 2721.2549\n",
      "Epoch 9/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 2391.0008 - val_loss: 2130.8391\n",
      "Epoch 10/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 1890.8255 - val_loss: 1711.1223\n",
      "Epoch 11/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 1525.5544 - val_loss: 1389.5324\n",
      "Epoch 12/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 1241.7440 - val_loss: 1136.2025\n",
      "Epoch 13/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 1016.1366 - val_loss: 933.0623\n",
      "Epoch 14/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 834.4419 - val_loss: 768.5757\n",
      "Epoch 15/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 687.2632 - val_loss: 634.1954\n",
      "Epoch 16/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 567.2174 - val_loss: 524.7775\n",
      "Epoch 17/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 469.2644 - val_loss: 435.3159\n",
      "Epoch 18/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 389.2379 - val_loss: 362.0852\n",
      "Epoch 19/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 323.9454 - val_loss: 301.8553\n",
      "Epoch 20/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 270.4367 - val_loss: 252.8938\n",
      "Epoch 21/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 227.0324 - val_loss: 212.4494\n",
      "Epoch 22/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 191.3719 - val_loss: 180.0626\n",
      "Epoch 23/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 162.6510 - val_loss: 153.4244\n",
      "Epoch 24/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 139.3305 - val_loss: 131.7154\n",
      "Epoch 25/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 120.4561 - val_loss: 114.1295\n",
      "Epoch 26/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 105.2060 - val_loss: 100.0943\n",
      "Epoch 27/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 93.0225 - val_loss: 88.6956\n",
      "Epoch 28/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 83.2643 - val_loss: 79.4724\n",
      "Epoch 29/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 75.4722 - val_loss: 72.0915\n",
      "Epoch 30/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 69.2845 - val_loss: 66.1821\n",
      "Epoch 31/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 64.3344 - val_loss: 61.6659\n",
      "Epoch 32/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 60.5534 - val_loss: 57.7277\n",
      "Epoch 33/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 57.5036 - val_loss: 54.7329\n",
      "Epoch 34/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 55.0909 - val_loss: 52.5142\n",
      "Epoch 35/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 53.2900 - val_loss: 50.6146\n",
      "Epoch 36/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 51.8522 - val_loss: 49.1728\n",
      "Epoch 37/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 50.7587 - val_loss: 48.0266\n",
      "Epoch 38/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 49.9165 - val_loss: 47.1336\n",
      "Epoch 39/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 49.2653 - val_loss: 46.4649\n",
      "Epoch 40/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 48.8003 - val_loss: 45.8718\n",
      "Epoch 41/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 48.4113 - val_loss: 45.4598\n",
      "Epoch 42/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 48.1399 - val_loss: 45.1225\n",
      "Epoch 43/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 47.9222 - val_loss: 44.8975\n",
      "Epoch 44/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 47.7673 - val_loss: 44.7074\n",
      "Epoch 45/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 47.6592 - val_loss: 44.4983\n",
      "Epoch 46/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 47.5606 - val_loss: 44.3550\n",
      "Epoch 47/1000\n",
      "1052/1052 [==============================] - 0s 108us/step - loss: 47.4843 - val_loss: 44.2579\n",
      "Epoch 48/1000\n",
      "1052/1052 [==============================] - 0s 108us/step - loss: 47.4300 - val_loss: 44.1682\n",
      "Epoch 49/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 47.3800 - val_loss: 44.0723\n",
      "Epoch 50/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 47.3242 - val_loss: 43.9535\n",
      "Epoch 51/1000\n",
      "1052/1052 [==============================] - 0s 108us/step - loss: 47.2187 - val_loss: 43.6529\n",
      "Epoch 52/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 46.8158 - val_loss: 43.0063\n",
      "Epoch 53/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 45.6680 - val_loss: 39.7165\n",
      "Epoch 54/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 41.3642 - val_loss: 37.9943\n",
      "Epoch 55/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 37.2041 - val_loss: 34.5649\n",
      "Epoch 56/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 35.5261 - val_loss: 33.2305\n",
      "Epoch 57/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 35.57 - 0s 89us/step - loss: 34.1631 - val_loss: 30.6749\n",
      "Epoch 58/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 28.2135 - val_loss: 28.6892\n",
      "Epoch 59/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 24.7089 - val_loss: 26.8710\n",
      "Epoch 60/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 23.4456 - val_loss: 26.0294\n",
      "Epoch 61/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.8329 - val_loss: 24.6801\n",
      "Epoch 62/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 20.6654 - val_loss: 23.8938\n",
      "Epoch 63/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 19.7812 - val_loss: 22.9244\n",
      "Epoch 64/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 19.0912 - val_loss: 22.2623\n",
      "Epoch 65/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.4019 - val_loss: 21.7236\n",
      "Epoch 66/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.7908 - val_loss: 21.1798\n",
      "Epoch 67/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.2314 - val_loss: 20.9720\n",
      "Epoch 68/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 16.8298 - val_loss: 20.8723\n",
      "Epoch 69/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 16.5506 - val_loss: 20.4488\n",
      "Epoch 70/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 16.1849 - val_loss: 20.4130\n",
      "Epoch 71/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 16.0672 - val_loss: 20.2290\n",
      "Epoch 72/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 15.6768 - val_loss: 19.9998\n",
      "Epoch 73/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 15.5176 - val_loss: 19.7937\n",
      "Epoch 74/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 15.3073 - val_loss: 19.6714\n",
      "Epoch 75/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 15.1910 - val_loss: 19.5039\n",
      "Epoch 76/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 15.1461 - val_loss: 19.4675\n",
      "Epoch 77/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 15.0880 - val_loss: 19.4114\n",
      "Epoch 78/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 14.9206 - val_loss: 19.3976\n",
      "Epoch 79/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 15.0408 - val_loss: 19.5015\n",
      "Epoch 80/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 14.7636 - val_loss: 19.3562\n",
      "Epoch 81/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 14.7238 - val_loss: 19.3073\n",
      "Epoch 82/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.6126 - val_loss: 19.2030\n",
      "Epoch 83/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 14.5637 - val_loss: 19.2333\n",
      "Epoch 84/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.6705 - val_loss: 18.9528\n",
      "Epoch 85/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 14.5186 - val_loss: 19.2861\n",
      "Epoch 86/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.5128 - val_loss: 19.0277\n",
      "Epoch 87/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 14.4118 - val_loss: 19.0157\n",
      "Epoch 88/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.4332 - val_loss: 18.9850\n",
      "Epoch 89/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.3098 - val_loss: 19.2034\n",
      "Epoch 90/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 14.3107 - val_loss: 18.8271\n",
      "Epoch 91/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.0843 - val_loss: 18.7139\n",
      "Epoch 92/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 14.1186 - val_loss: 18.7676\n",
      "Epoch 93/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 14.1076 - val_loss: 18.9349\n",
      "Epoch 94/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 13.9289 - val_loss: 19.0360\n",
      "Epoch 95/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 14.1654 - val_loss: 18.8344\n",
      "Epoch 96/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 13.9974 - val_loss: 18.8158\n",
      "Epoch 97/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 14.0055 - val_loss: 18.6653\n",
      "Epoch 98/1000\n",
      "1052/1052 [==============================] - 0s 109us/step - loss: 13.8812 - val_loss: 18.8693\n",
      "Epoch 99/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 13.8632 - val_loss: 18.8680\n",
      "Epoch 100/1000\n",
      "1052/1052 [==============================] - 0s 110us/step - loss: 13.8635 - val_loss: 18.6693\n",
      "Epoch 101/1000\n",
      "1052/1052 [==============================] - 0s 112us/step - loss: 13.8840 - val_loss: 18.7323\n",
      "Epoch 102/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 13.7480 - val_loss: 18.9495\n",
      "Epoch 103/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 13.9134 - val_loss: 18.8906\n",
      "Epoch 104/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 13.6708 - val_loss: 18.6490\n",
      "Epoch 105/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.6880 - val_loss: 18.6427\n",
      "Epoch 106/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.6493 - val_loss: 18.5068\n",
      "Epoch 107/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 13.6536 - val_loss: 18.5274\n",
      "Epoch 108/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 13.6999 - val_loss: 18.8667\n",
      "Epoch 109/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.7882 - val_loss: 18.9859\n",
      "Epoch 110/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.6466 - val_loss: 18.9806\n",
      "Epoch 111/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.7508 - val_loss: 18.5475\n",
      "Epoch 112/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 13.5728 - val_loss: 18.5167\n",
      "Epoch 113/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 13.7320 - val_loss: 18.5111\n",
      "Epoch 114/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.5631 - val_loss: 18.4217\n",
      "Epoch 115/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.4380 - val_loss: 18.5414\n",
      "Epoch 116/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.5286 - val_loss: 18.6315\n",
      "Epoch 117/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 13.4849 - val_loss: 18.4661\n",
      "Epoch 118/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 13.4392 - val_loss: 18.5160\n",
      "Epoch 119/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.5216 - val_loss: 18.4750\n",
      "Epoch 120/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 13.6190 - val_loss: 18.3817\n",
      "Epoch 121/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 13.4103 - val_loss: 18.5160\n",
      "Epoch 122/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 13.7055 - val_loss: 18.3222\n",
      "Epoch 123/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 13.5370 - val_loss: 18.3555\n",
      "Epoch 124/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.5254 - val_loss: 18.2869\n",
      "Epoch 125/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 13.4928 - val_loss: 18.4054\n",
      "Epoch 126/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 13.5971 - val_loss: 18.2536\n",
      "Epoch 127/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 13.4887 - val_loss: 18.4018\n",
      "Epoch 128/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 13.4857 - val_loss: 18.3198\n",
      "Epoch 129/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 13.3708 - val_loss: 18.3244\n",
      "Epoch 130/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.3721 - val_loss: 18.0688\n",
      "Epoch 131/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 13.3357 - val_loss: 18.4699\n",
      "Epoch 132/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 13.3743 - val_loss: 18.2388\n",
      "Epoch 133/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 13.4409 - val_loss: 18.0476\n",
      "Epoch 134/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.2859 - val_loss: 18.0094\n",
      "Epoch 135/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.3310 - val_loss: 17.9533\n",
      "Epoch 136/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.1720 - val_loss: 18.0070\n",
      "Epoch 137/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.2512 - val_loss: 18.0142\n",
      "Epoch 138/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.1585 - val_loss: 18.2291\n",
      "Epoch 139/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.2707 - val_loss: 18.1104\n",
      "Epoch 140/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.2412 - val_loss: 17.8218\n",
      "Epoch 141/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.1853 - val_loss: 17.8115\n",
      "Epoch 142/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.0716 - val_loss: 17.7737\n",
      "Epoch 143/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.1890 - val_loss: 17.7326\n",
      "Epoch 144/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.2173 - val_loss: 17.8727\n",
      "Epoch 145/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 13.1556 - val_loss: 18.1151\n",
      "Epoch 146/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.0798 - val_loss: 17.6284\n",
      "Epoch 147/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.0067 - val_loss: 18.0156\n",
      "Epoch 148/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.1078 - val_loss: 17.6632\n",
      "Epoch 149/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 13.0298 - val_loss: 17.5938\n",
      "Epoch 150/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 13.0612 - val_loss: 18.1994\n",
      "Epoch 151/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.1404 - val_loss: 17.7624\n",
      "Epoch 152/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.0064 - val_loss: 18.0913\n",
      "Epoch 153/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.0441 - val_loss: 17.5928\n",
      "Epoch 154/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.0804 - val_loss: 17.5597\n",
      "Epoch 155/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.9944 - val_loss: 17.6467\n",
      "Epoch 156/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 12.9368 - val_loss: 17.6011\n",
      "Epoch 157/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.0977 - val_loss: 17.4796\n",
      "Epoch 158/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.1137 - val_loss: 17.5779\n",
      "Epoch 159/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 13.0955 - val_loss: 17.6658\n",
      "Epoch 160/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 12.9358 - val_loss: 17.9032\n",
      "Epoch 161/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 13.0814 - val_loss: 17.6998\n",
      "Epoch 162/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.9439 - val_loss: 17.5115\n",
      "Epoch 163/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.9030 - val_loss: 17.3725\n",
      "Epoch 164/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 12.01 - 0s 84us/step - loss: 12.9236 - val_loss: 17.4549\n",
      "Epoch 165/1000\n",
      "1052/1052 [==============================] - 0s 124us/step - loss: 12.8392 - val_loss: 17.3362\n",
      "Epoch 166/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.9212 - val_loss: 17.4136\n",
      "Epoch 167/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.8885 - val_loss: 17.5291\n",
      "Epoch 168/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.0880 - val_loss: 17.6982\n",
      "Epoch 169/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 12.9134 - val_loss: 17.3652\n",
      "Epoch 170/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 12.8459 - val_loss: 17.2968\n",
      "Epoch 171/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.9181 - val_loss: 17.3816\n",
      "Epoch 172/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.9461 - val_loss: 17.4277\n",
      "Epoch 173/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.9169 - val_loss: 17.2796\n",
      "Epoch 174/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.8987 - val_loss: 17.3438\n",
      "Epoch 175/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.8026 - val_loss: 17.4099\n",
      "Epoch 176/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.7984 - val_loss: 17.3222\n",
      "Epoch 177/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 12.9211 - val_loss: 17.2738\n",
      "Epoch 178/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.7747 - val_loss: 17.3688\n",
      "Epoch 179/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.8827 - val_loss: 17.2288\n",
      "Epoch 180/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 12.7492 - val_loss: 17.4708\n",
      "Epoch 181/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 12.7847 - val_loss: 17.5084\n",
      "Epoch 182/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 12.6730 - val_loss: 17.4971\n",
      "Epoch 183/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.6932 - val_loss: 17.3679\n",
      "Epoch 184/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.6880 - val_loss: 17.1955\n",
      "Epoch 185/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.7758 - val_loss: 17.4570\n",
      "Epoch 186/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.8511 - val_loss: 17.2056\n",
      "Epoch 187/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.7272 - val_loss: 17.3974\n",
      "Epoch 188/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 12.7133 - val_loss: 17.1805\n",
      "Epoch 189/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.7885 - val_loss: 17.5177\n",
      "Epoch 190/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.7378 - val_loss: 17.4914\n",
      "Epoch 191/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.7037 - val_loss: 18.2153\n",
      "Epoch 192/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 12.6965 - val_loss: 17.6401\n",
      "Epoch 193/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.8544 - val_loss: 18.1294\n",
      "Epoch 194/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.7918 - val_loss: 17.5431\n",
      "Epoch 195/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.5367 - val_loss: 17.6646\n",
      "Epoch 196/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.5950 - val_loss: 17.3762\n",
      "Epoch 197/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.6329 - val_loss: 17.4584\n",
      "Epoch 198/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.6309 - val_loss: 17.5585\n",
      "Epoch 199/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 12.5625 - val_loss: 17.7663\n",
      "Epoch 200/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.7240 - val_loss: 18.1547\n",
      "Epoch 201/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.5636 - val_loss: 17.5267\n",
      "Epoch 202/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.5505 - val_loss: 17.6156\n",
      "Epoch 203/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 12.6667 - val_loss: 17.8659\n",
      "Epoch 204/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.6351 - val_loss: 17.9368\n",
      "Epoch 205/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 12.6740 - val_loss: 17.6715\n",
      "Epoch 206/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.7466 - val_loss: 17.6437\n",
      "Epoch 207/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.6284 - val_loss: 17.6127\n",
      "Epoch 208/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.5731 - val_loss: 17.8509\n",
      "Epoch 209/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 12.6100 - val_loss: 18.0315\n",
      "Epoch 210/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 12.5186 - val_loss: 17.5932\n",
      "Epoch 211/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 12.5219 - val_loss: 17.5057\n",
      "Epoch 212/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 12.5022 - val_loss: 17.8734\n",
      "Epoch 213/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 12.6184 - val_loss: 18.1640\n",
      "Epoch 214/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 12.5914 - val_loss: 17.3836\n",
      "Epoch 215/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 12.5320 - val_loss: 17.3844\n",
      "Epoch 216/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.5801 - val_loss: 17.3778\n",
      "Epoch 217/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 12.4965 - val_loss: 17.5076\n",
      "Epoch 218/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.4226 - val_loss: 17.5552\n",
      "Epoch 219/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.4586 - val_loss: 17.5308\n",
      "Epoch 220/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 12.4575 - val_loss: 17.5970\n",
      "Epoch 221/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.3955 - val_loss: 17.4683\n",
      "Epoch 222/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.4855 - val_loss: 17.5269\n",
      "Epoch 223/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.4177 - val_loss: 17.7350\n",
      "Epoch 224/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 12.4589 - val_loss: 17.8467\n",
      "Epoch 225/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.4376 - val_loss: 17.9633\n",
      "Epoch 226/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.3604 - val_loss: 17.4844\n",
      "Epoch 227/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.5192 - val_loss: 17.7801\n",
      "Epoch 228/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.4243 - val_loss: 18.3143\n",
      "Epoch 229/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 12.4306 - val_loss: 17.6750\n",
      "Epoch 230/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.4129 - val_loss: 17.3348\n",
      "Epoch 231/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.5588 - val_loss: 17.8696\n",
      "Epoch 232/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 12.3853 - val_loss: 17.6461\n",
      "Epoch 233/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.3964 - val_loss: 17.5224\n",
      "Epoch 234/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.3985 - val_loss: 17.4517\n",
      "Epoch 235/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.5100 - val_loss: 17.5553\n",
      "Epoch 236/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.4637 - val_loss: 17.6242\n",
      "Epoch 237/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.3690 - val_loss: 17.5859\n",
      "Epoch 238/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.4737 - val_loss: 17.4101\n",
      "Epoch 239/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.4692 - val_loss: 17.4331\n",
      "Epoch 240/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.4559 - val_loss: 17.4131\n",
      "Epoch 241/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 12.5235 - val_loss: 17.4453\n",
      "Epoch 242/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 12.3796 - val_loss: 17.5223\n",
      "Epoch 243/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 12.5519 - val_loss: 17.7420\n",
      "Epoch 244/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.6256 - val_loss: 17.5365\n",
      "Epoch 245/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.3157 - val_loss: 17.4737\n",
      "Epoch 246/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.3426 - val_loss: 17.6998\n",
      "Epoch 247/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 12.4216 - val_loss: 17.7338\n",
      "Epoch 248/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.3316 - val_loss: 17.7920\n",
      "Epoch 249/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.3829 - val_loss: 18.1463\n",
      "Epoch 250/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.3888 - val_loss: 17.4099\n",
      "Epoch 251/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.3343 - val_loss: 17.5055\n",
      "Epoch 252/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.4611 - val_loss: 17.4191\n",
      "Epoch 253/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.3126 - val_loss: 17.4624\n",
      "Epoch 254/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.2386 - val_loss: 17.5558\n",
      "Epoch 255/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.3079 - val_loss: 17.4740\n",
      "Epoch 256/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.2785 - val_loss: 17.3895\n",
      "Epoch 257/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.2460 - val_loss: 17.5010\n",
      "Epoch 258/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 12.1778 - val_loss: 17.3274\n",
      "Epoch 259/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 12.2272 - val_loss: 17.6527\n",
      "Epoch 260/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.3419 - val_loss: 17.7531\n",
      "Epoch 261/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 12.2089 - val_loss: 17.5987\n",
      "Epoch 262/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 12.3588 - val_loss: 17.6200\n",
      "Epoch 263/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 12.2203 - val_loss: 17.5354\n",
      "Epoch 264/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 12.1687 - val_loss: 17.4202\n",
      "Epoch 265/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.3173 - val_loss: 17.4299\n",
      "Epoch 266/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.2989 - val_loss: 17.5863\n",
      "Epoch 267/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.2427 - val_loss: 17.4238\n",
      "Epoch 268/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 12.1671 - val_loss: 17.5241\n",
      "Epoch 269/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 12.1647 - val_loss: 17.5077\n",
      "Epoch 270/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.1842 - val_loss: 17.7417\n",
      "Epoch 271/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.2674 - val_loss: 17.6708\n",
      "Epoch 272/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.1230 - val_loss: 17.6100\n",
      "Epoch 273/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 12.2130 - val_loss: 17.4975\n",
      "Epoch 274/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.5443 - val_loss: 17.6576\n",
      "Epoch 275/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.1722 - val_loss: 17.7015\n",
      "Epoch 276/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 12.2760 - val_loss: 17.7927\n",
      "Epoch 277/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 12.1174 - val_loss: 17.7075\n",
      "Epoch 278/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 12.1275 - val_loss: 17.5269\n",
      "Epoch 279/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.1477 - val_loss: 17.5971\n",
      "Epoch 280/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.0574 - val_loss: 17.6896\n",
      "Epoch 281/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 12.0903 - val_loss: 17.4546\n",
      "Epoch 282/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.0423 - val_loss: 17.6526\n",
      "Epoch 283/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.1471 - val_loss: 17.6363\n",
      "Epoch 284/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 12.1414 - val_loss: 17.5294\n",
      "Epoch 285/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.2408 - val_loss: 17.4982\n",
      "Epoch 286/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.1539 - val_loss: 17.5082\n",
      "Epoch 287/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.0832 - val_loss: 18.0461\n",
      "Epoch 288/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 12.2910 - val_loss: 17.4730\n",
      "Epoch 289/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 12.1702 - val_loss: 17.5661\n",
      "Epoch 290/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.1210 - val_loss: 17.5423\n",
      "Epoch 291/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.0968 - val_loss: 17.6767\n",
      "Epoch 292/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 12.2351 - val_loss: 17.5918\n",
      "Epoch 293/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.0757 - val_loss: 17.5527\n",
      "Epoch 294/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.1420 - val_loss: 17.7139\n",
      "Epoch 295/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.9874 - val_loss: 17.4523\n",
      "Epoch 296/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 12.1152 - val_loss: 17.5758\n",
      "Epoch 297/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.1831 - val_loss: 17.4688\n",
      "Epoch 298/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 12.0018 - val_loss: 17.3204\n",
      "Epoch 299/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.9857 - val_loss: 17.4127\n",
      "Epoch 300/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 12.0555 - val_loss: 17.2670\n",
      "Epoch 301/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 11.9678 - val_loss: 18.1932\n",
      "Epoch 302/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.1131 - val_loss: 17.4266\n",
      "Epoch 303/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.9600 - val_loss: 17.4754\n",
      "Epoch 304/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.2271 - val_loss: 17.3436\n",
      "Epoch 305/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.0174 - val_loss: 17.7460\n",
      "Epoch 306/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 12.1099 - val_loss: 17.6653\n",
      "Epoch 307/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 11.9766 - val_loss: 17.5970\n",
      "Epoch 308/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.1083 - val_loss: 17.3827\n",
      "Epoch 309/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.9644 - val_loss: 17.6275\n",
      "Epoch 310/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.9934 - val_loss: 17.7720\n",
      "Epoch 311/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.9368 - val_loss: 17.3645\n",
      "Epoch 312/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.0572 - val_loss: 17.5033\n",
      "Epoch 313/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.0347 - val_loss: 17.3296\n",
      "Epoch 314/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.0308 - val_loss: 17.3928\n",
      "Epoch 315/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.9892 - val_loss: 17.3897\n",
      "Epoch 316/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.9719 - val_loss: 17.2434\n",
      "Epoch 317/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.1976 - val_loss: 17.2522\n",
      "Epoch 318/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.0030 - val_loss: 17.2000\n",
      "Epoch 319/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.9609 - val_loss: 17.5253\n",
      "Epoch 320/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.9742 - val_loss: 17.4002\n",
      "Epoch 321/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 12.0471 - val_loss: 17.2585\n",
      "Epoch 322/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 11.9730 - val_loss: 17.1584\n",
      "Epoch 323/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.9735 - val_loss: 17.2221\n",
      "Epoch 324/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.9930 - val_loss: 17.4443\n",
      "Epoch 325/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.9476 - val_loss: 17.2730\n",
      "Epoch 326/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.9317 - val_loss: 17.3528\n",
      "Epoch 327/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.9360 - val_loss: 17.3642\n",
      "Epoch 328/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 12.0981 - val_loss: 17.3012\n",
      "Epoch 329/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 12.1337 - val_loss: 17.1850\n",
      "Epoch 330/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 11.9684 - val_loss: 17.1696\n",
      "Epoch 331/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 11.8797 - val_loss: 17.3049\n",
      "Epoch 332/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.9514 - val_loss: 17.2373\n",
      "Epoch 333/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.9923 - val_loss: 17.3240\n",
      "Epoch 334/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.9499 - val_loss: 17.2034\n",
      "Epoch 335/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.9612 - val_loss: 17.1427\n",
      "Epoch 336/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.8914 - val_loss: 17.1402\n",
      "Epoch 337/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.9202 - val_loss: 17.1177\n",
      "Epoch 338/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.9449 - val_loss: 17.2636\n",
      "Epoch 339/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.9783 - val_loss: 17.3524\n",
      "Epoch 340/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 11.9613 - val_loss: 17.3138\n",
      "Epoch 341/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.9773 - val_loss: 17.2261\n",
      "Epoch 342/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.1093 - val_loss: 17.3188\n",
      "Epoch 343/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 12.0077 - val_loss: 16.9920\n",
      "Epoch 344/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.0053 - val_loss: 17.0350\n",
      "Epoch 345/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.9457 - val_loss: 16.9589\n",
      "Epoch 346/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.9159 - val_loss: 17.1511\n",
      "Epoch 347/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.9620 - val_loss: 17.0468\n",
      "Epoch 348/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.9162 - val_loss: 17.0937\n",
      "Epoch 349/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.9060 - val_loss: 17.1084\n",
      "Epoch 350/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.9504 - val_loss: 17.2385\n",
      "Epoch 351/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.9368 - val_loss: 17.0583\n",
      "Epoch 352/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 12.0026 - val_loss: 17.0326\n",
      "Epoch 353/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.8953 - val_loss: 17.2768\n",
      "Epoch 354/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 11.9411 - val_loss: 17.1294\n",
      "Epoch 355/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.8439 - val_loss: 17.1076\n",
      "Epoch 356/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.9171 - val_loss: 17.0367\n",
      "Epoch 357/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 11.9612 - val_loss: 17.1513\n",
      "Epoch 358/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.8755 - val_loss: 17.1777\n",
      "Epoch 359/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 11.9133 - val_loss: 16.9962\n",
      "Epoch 360/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.9584 - val_loss: 17.0046\n",
      "Epoch 361/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.8851 - val_loss: 17.0309\n",
      "Epoch 362/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.9104 - val_loss: 17.1515\n",
      "Epoch 363/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.9813 - val_loss: 17.2605\n",
      "Epoch 364/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.8706 - val_loss: 16.9446\n",
      "Epoch 365/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.0062 - val_loss: 16.9276\n",
      "Epoch 366/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.9795 - val_loss: 17.1651\n",
      "Epoch 367/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.9511 - val_loss: 17.4298\n",
      "Epoch 368/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.0887 - val_loss: 17.1004\n",
      "Epoch 369/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.0204 - val_loss: 17.1033\n",
      "Epoch 370/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.9104 - val_loss: 16.9956\n",
      "Epoch 371/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.9466 - val_loss: 16.9756\n",
      "Epoch 372/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.8959 - val_loss: 16.9860\n",
      "Epoch 373/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.8631 - val_loss: 17.1159\n",
      "Epoch 374/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.8543 - val_loss: 17.2026\n",
      "Epoch 375/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.8886 - val_loss: 17.1550\n",
      "Epoch 376/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.9644 - val_loss: 16.9560\n",
      "Epoch 377/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.9493 - val_loss: 17.1530\n",
      "Epoch 378/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.8536 - val_loss: 17.0585\n",
      "Epoch 379/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.8647 - val_loss: 16.9979\n",
      "Epoch 380/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.8175 - val_loss: 17.0782\n",
      "Epoch 381/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 11.8621 - val_loss: 17.0813\n",
      "Epoch 382/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 11.8704 - val_loss: 17.1717\n",
      "Epoch 383/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 11.9396 - val_loss: 17.0629\n",
      "Epoch 384/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 12.0390 - val_loss: 16.9726\n",
      "Epoch 385/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 11.9566 - val_loss: 17.2396\n",
      "Epoch 386/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 11.9948 - val_loss: 17.1453\n",
      "Epoch 387/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 11.8490 - val_loss: 17.0950\n",
      "Epoch 388/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.8822 - val_loss: 16.9807\n",
      "Epoch 389/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 11.9068 - val_loss: 17.0553\n",
      "Epoch 390/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.9153 - val_loss: 17.5012\n",
      "Epoch 391/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.8892 - val_loss: 16.9286\n",
      "Epoch 392/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.8915 - val_loss: 16.9315\n",
      "Epoch 393/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.9761 - val_loss: 17.1702\n",
      "Epoch 394/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.8793 - val_loss: 16.9927\n",
      "Epoch 395/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.9327 - val_loss: 16.9015\n",
      "Epoch 396/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.7744 - val_loss: 16.8779\n",
      "Epoch 397/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.8064 - val_loss: 17.1636\n",
      "Epoch 398/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.0218 - val_loss: 17.1054\n",
      "Epoch 399/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.9853 - val_loss: 17.1810\n",
      "Epoch 400/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.9634 - val_loss: 17.3153\n",
      "Epoch 401/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.7865 - val_loss: 17.0355\n",
      "Epoch 402/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.8287 - val_loss: 17.2081\n",
      "Epoch 403/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.8829 - val_loss: 16.9800\n",
      "Epoch 404/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.7908 - val_loss: 17.1496\n",
      "Epoch 405/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.7809 - val_loss: 17.2319\n",
      "Epoch 406/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 12.1798 - val_loss: 16.9007\n",
      "Epoch 407/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.8530 - val_loss: 16.8337\n",
      "Epoch 408/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.8777 - val_loss: 16.9396\n",
      "Epoch 409/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.8559 - val_loss: 16.8888\n",
      "Epoch 410/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.8446 - val_loss: 17.2508\n",
      "Epoch 411/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.8618 - val_loss: 17.1754\n",
      "Epoch 412/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.9665 - val_loss: 17.3404\n",
      "Epoch 413/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.8455 - val_loss: 16.8134\n",
      "Epoch 414/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.8322 - val_loss: 16.9198\n",
      "Epoch 415/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.9302 - val_loss: 17.0272\n",
      "Epoch 416/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.8724 - val_loss: 16.9178\n",
      "Epoch 417/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.9126 - val_loss: 17.1196\n",
      "Epoch 418/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.8836 - val_loss: 16.8326\n",
      "Epoch 419/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.7839 - val_loss: 16.9967\n",
      "Epoch 420/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.8957 - val_loss: 16.9818\n",
      "Epoch 421/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.8722 - val_loss: 16.8801\n",
      "Epoch 422/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.8146 - val_loss: 16.7609\n",
      "Epoch 423/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.8059 - val_loss: 16.9115\n",
      "Epoch 424/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.8870 - val_loss: 16.9390\n",
      "Epoch 425/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.9374 - val_loss: 16.7826\n",
      "Epoch 426/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.7957 - val_loss: 16.8870\n",
      "Epoch 427/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.8447 - val_loss: 17.4117\n",
      "Epoch 428/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 11.9046 - val_loss: 16.7013\n",
      "Epoch 429/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.7681 - val_loss: 16.9869\n",
      "Epoch 430/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.7108 - val_loss: 17.0184\n",
      "Epoch 431/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.7246 - val_loss: 17.0064\n",
      "Epoch 432/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 11.5269 - val_loss: 16.8278\n",
      "Epoch 433/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.5796 - val_loss: 16.7053\n",
      "Epoch 434/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.4616 - val_loss: 16.6359\n",
      "Epoch 435/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.3385 - val_loss: 16.8708\n",
      "Epoch 436/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.2958 - val_loss: 16.6437\n",
      "Epoch 437/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.3753 - val_loss: 16.6628\n",
      "Epoch 438/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.3749 - val_loss: 16.6761\n",
      "Epoch 439/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.3809 - val_loss: 16.5787\n",
      "Epoch 440/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.2443 - val_loss: 16.8881\n",
      "Epoch 441/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.2496 - val_loss: 16.5235\n",
      "Epoch 442/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.4055 - val_loss: 16.8857\n",
      "Epoch 443/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.2578 - val_loss: 16.6954\n",
      "Epoch 444/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.2016 - val_loss: 16.4739\n",
      "Epoch 445/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.0671 - val_loss: 16.3988\n",
      "Epoch 446/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.1247 - val_loss: 16.3057\n",
      "Epoch 447/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.0906 - val_loss: 16.8401\n",
      "Epoch 448/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.1435 - val_loss: 16.6313\n",
      "Epoch 449/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.0363 - val_loss: 16.3415\n",
      "Epoch 450/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.9159 - val_loss: 16.3068\n",
      "Epoch 451/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.0233 - val_loss: 16.5146\n",
      "Epoch 452/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.9661 - val_loss: 16.4438\n",
      "Epoch 453/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.9612 - val_loss: 16.3775\n",
      "Epoch 454/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.9609 - val_loss: 16.2741\n",
      "Epoch 455/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.0590 - val_loss: 16.0627\n",
      "Epoch 456/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.9793 - val_loss: 16.5473\n",
      "Epoch 457/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.8186 - val_loss: 16.3616\n",
      "Epoch 458/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.9258 - val_loss: 16.1632\n",
      "Epoch 459/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.8484 - val_loss: 15.9744\n",
      "Epoch 460/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.8279 - val_loss: 15.6017\n",
      "Epoch 461/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 10.6801 - val_loss: 15.3267\n",
      "Epoch 462/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.7591 - val_loss: 15.3881\n",
      "Epoch 463/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.6544 - val_loss: 15.3887\n",
      "Epoch 464/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.5903 - val_loss: 15.1098\n",
      "Epoch 465/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.8353 - val_loss: 14.9419\n",
      "Epoch 466/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.6070 - val_loss: 14.9425\n",
      "Epoch 467/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 10.5363 - val_loss: 14.7553\n",
      "Epoch 468/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.4546 - val_loss: 14.6233\n",
      "Epoch 469/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.5065 - val_loss: 14.7822\n",
      "Epoch 470/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.3945 - val_loss: 14.7529\n",
      "Epoch 471/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.4639 - val_loss: 14.4561\n",
      "Epoch 472/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.3896 - val_loss: 14.3253\n",
      "Epoch 473/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 10.5283 - val_loss: 14.4986\n",
      "Epoch 474/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.3057 - val_loss: 14.2842\n",
      "Epoch 475/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.3564 - val_loss: 14.1112\n",
      "Epoch 476/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.2465 - val_loss: 14.2619\n",
      "Epoch 477/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.3429 - val_loss: 14.0789\n",
      "Epoch 478/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 10.3039 - val_loss: 13.8705\n",
      "Epoch 479/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.1937 - val_loss: 13.8111\n",
      "Epoch 480/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.1616 - val_loss: 14.0374\n",
      "Epoch 481/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.2751 - val_loss: 13.2341\n",
      "Epoch 482/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.9211 - val_loss: 13.1521\n",
      "Epoch 483/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.2264 - val_loss: 13.2595\n",
      "Epoch 484/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.1042 - val_loss: 12.7353\n",
      "Epoch 485/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.8132 - val_loss: 12.7395\n",
      "Epoch 486/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.6063 - val_loss: 12.5316\n",
      "Epoch 487/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.6258 - val_loss: 12.3632\n",
      "Epoch 488/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.6672 - val_loss: 12.7682\n",
      "Epoch 489/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.5895 - val_loss: 12.0160\n",
      "Epoch 490/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.3819 - val_loss: 12.1099\n",
      "Epoch 491/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.3573 - val_loss: 11.8864\n",
      "Epoch 492/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.3821 - val_loss: 12.1206\n",
      "Epoch 493/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.4633 - val_loss: 13.0347\n",
      "Epoch 494/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.3693 - val_loss: 11.8013\n",
      "Epoch 495/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0714 - val_loss: 11.9694\n",
      "Epoch 496/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1788 - val_loss: 11.6220\n",
      "Epoch 497/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.0970 - val_loss: 11.6101\n",
      "Epoch 498/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9833 - val_loss: 11.5203\n",
      "Epoch 499/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.3281 - val_loss: 12.2624\n",
      "Epoch 500/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1618 - val_loss: 11.9375\n",
      "Epoch 501/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9341 - val_loss: 11.4901\n",
      "Epoch 502/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8731 - val_loss: 11.6297\n",
      "Epoch 503/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8133 - val_loss: 11.5870\n",
      "Epoch 504/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.8444 - val_loss: 11.5842\n",
      "Epoch 505/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8559 - val_loss: 11.2880\n",
      "Epoch 506/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.0774 - val_loss: 11.8847\n",
      "Epoch 507/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9647 - val_loss: 11.4061\n",
      "Epoch 508/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.7652 - val_loss: 11.4242\n",
      "Epoch 509/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8664 - val_loss: 11.8484\n",
      "Epoch 510/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6360 - val_loss: 11.2902\n",
      "Epoch 511/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6629 - val_loss: 11.4398\n",
      "Epoch 512/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6822 - val_loss: 11.3638\n",
      "Epoch 513/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.6927 - val_loss: 11.2761\n",
      "Epoch 514/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.7936 - val_loss: 11.7222\n",
      "Epoch 515/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8845 - val_loss: 11.4705\n",
      "Epoch 516/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7721 - val_loss: 12.0967\n",
      "Epoch 517/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7019 - val_loss: 11.2011\n",
      "Epoch 518/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5965 - val_loss: 11.2596\n",
      "Epoch 519/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5430 - val_loss: 11.0098\n",
      "Epoch 520/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4047 - val_loss: 11.3115\n",
      "Epoch 521/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3438 - val_loss: 11.1120\n",
      "Epoch 522/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4188 - val_loss: 11.0187\n",
      "Epoch 523/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5714 - val_loss: 10.9264\n",
      "Epoch 524/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4001 - val_loss: 11.1268\n",
      "Epoch 525/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.5744 - val_loss: 11.0757\n",
      "Epoch 526/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4114 - val_loss: 10.9971\n",
      "Epoch 527/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3852 - val_loss: 11.2017\n",
      "Epoch 528/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3481 - val_loss: 10.8294\n",
      "Epoch 529/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3061 - val_loss: 10.9506\n",
      "Epoch 530/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2948 - val_loss: 11.0142\n",
      "Epoch 531/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3021 - val_loss: 10.9380\n",
      "Epoch 532/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3855 - val_loss: 10.9016\n",
      "Epoch 533/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2626 - val_loss: 10.8715\n",
      "Epoch 534/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3459 - val_loss: 11.1861\n",
      "Epoch 535/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2367 - val_loss: 10.8193\n",
      "Epoch 536/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2191 - val_loss: 10.7165\n",
      "Epoch 537/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2394 - val_loss: 11.3399\n",
      "Epoch 538/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2798 - val_loss: 10.8064\n",
      "Epoch 539/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2183 - val_loss: 10.8598\n",
      "Epoch 540/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2906 - val_loss: 10.7526\n",
      "Epoch 541/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1860 - val_loss: 10.8119\n",
      "Epoch 542/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3153 - val_loss: 10.7602\n",
      "Epoch 543/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2798 - val_loss: 10.7042\n",
      "Epoch 544/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2338 - val_loss: 11.1450\n",
      "Epoch 545/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.1416 - val_loss: 10.8644\n",
      "Epoch 546/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1919 - val_loss: 11.4554\n",
      "Epoch 547/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2098 - val_loss: 10.8320\n",
      "Epoch 548/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.9948 - val_loss: 10.8803\n",
      "Epoch 549/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 7.9808 - val_loss: 10.6698\n",
      "Epoch 550/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 8.0837 - val_loss: 10.9252\n",
      "Epoch 551/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.1197 - val_loss: 10.8030\n",
      "Epoch 552/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.2454 - val_loss: 10.6604\n",
      "Epoch 553/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.9695 - val_loss: 10.8451\n",
      "Epoch 554/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1078 - val_loss: 11.2116\n",
      "Epoch 555/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.2193 - val_loss: 10.8138\n",
      "Epoch 556/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.9530 - val_loss: 10.9136\n",
      "Epoch 557/1000\n",
      "1052/1052 [==============================] - 0s 109us/step - loss: 8.0471 - val_loss: 10.9402\n",
      "Epoch 558/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.1143 - val_loss: 11.2267\n",
      "Epoch 559/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0487 - val_loss: 10.5875\n",
      "Epoch 560/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0394 - val_loss: 10.6673\n",
      "Epoch 561/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0156 - val_loss: 10.5635\n",
      "Epoch 562/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.8292 - val_loss: 10.8422\n",
      "Epoch 563/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.9651 - val_loss: 10.5737\n",
      "Epoch 564/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9788 - val_loss: 10.6600\n",
      "Epoch 565/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9167 - val_loss: 11.0333\n",
      "Epoch 566/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.0343 - val_loss: 10.5716\n",
      "Epoch 567/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1076 - val_loss: 10.7102\n",
      "Epoch 568/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1350 - val_loss: 10.7314\n",
      "Epoch 569/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.8600 - val_loss: 10.6617\n",
      "Epoch 570/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9945 - val_loss: 10.4801\n",
      "Epoch 571/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0032 - val_loss: 10.5721\n",
      "Epoch 572/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.8721 - val_loss: 10.3845\n",
      "Epoch 573/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0624 - val_loss: 10.8381\n",
      "Epoch 574/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9325 - val_loss: 10.8965\n",
      "Epoch 575/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.9617 - val_loss: 10.3300\n",
      "Epoch 576/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.8571 - val_loss: 10.5814\n",
      "Epoch 577/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.7691 - val_loss: 10.4732\n",
      "Epoch 578/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.8602 - val_loss: 10.3432\n",
      "Epoch 579/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0787 - val_loss: 10.5622\n",
      "Epoch 580/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.9054 - val_loss: 10.4133\n",
      "Epoch 581/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.8632 - val_loss: 10.6964\n",
      "Epoch 582/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8340 - val_loss: 10.4382\n",
      "Epoch 583/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8092 - val_loss: 10.5872\n",
      "Epoch 584/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9262 - val_loss: 10.5116\n",
      "Epoch 585/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8301 - val_loss: 10.2924\n",
      "Epoch 586/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.7325 - val_loss: 10.5004\n",
      "Epoch 587/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.6322 - val_loss: 10.5308\n",
      "Epoch 588/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.7448 - val_loss: 10.3410\n",
      "Epoch 589/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9287 - val_loss: 11.1563\n",
      "Epoch 590/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.8158 - val_loss: 10.2058\n",
      "Epoch 591/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.7516 - val_loss: 10.7891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 592/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.1260 - val_loss: 10.2641\n",
      "Epoch 593/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.9818 - val_loss: 10.1219\n",
      "Epoch 594/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.6088 - val_loss: 10.4192\n",
      "Epoch 595/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0117 - val_loss: 10.0907\n",
      "Epoch 596/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.8090 - val_loss: 10.2235\n",
      "Epoch 597/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.7513 - val_loss: 10.2567\n",
      "Epoch 598/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9077 - val_loss: 10.3124\n",
      "Epoch 599/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.6607 - val_loss: 10.0990\n",
      "Epoch 600/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.5990 - val_loss: 10.1971\n",
      "Epoch 601/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.7533 - val_loss: 10.2480\n",
      "Epoch 602/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.8622 - val_loss: 10.0105\n",
      "Epoch 603/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.7093 - val_loss: 9.6698\n",
      "Epoch 604/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.6725 - val_loss: 10.0476\n",
      "Epoch 605/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.5927 - val_loss: 9.7740\n",
      "Epoch 606/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.7827 - val_loss: 9.8344\n",
      "Epoch 607/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.6825 - val_loss: 9.9515\n",
      "Epoch 608/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.5526 - val_loss: 9.8165\n",
      "Epoch 609/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.4752 - val_loss: 9.7079\n",
      "Epoch 610/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.5234 - val_loss: 9.4274\n",
      "Epoch 611/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.5420 - val_loss: 9.7552\n",
      "Epoch 612/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.4228 - val_loss: 9.3435\n",
      "Epoch 613/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.3354 - val_loss: 9.9323\n",
      "Epoch 614/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.3940 - val_loss: 9.3800\n",
      "Epoch 615/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.2664 - val_loss: 9.5828\n",
      "Epoch 616/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.2934 - val_loss: 9.9817\n",
      "Epoch 617/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.1865 - val_loss: 9.4668\n",
      "Epoch 618/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.2327 - val_loss: 9.3546\n",
      "Epoch 619/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.2474 - val_loss: 9.4761\n",
      "Epoch 620/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.2128 - val_loss: 8.9941\n",
      "Epoch 621/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.2668 - val_loss: 9.3392\n",
      "Epoch 622/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.1582 - val_loss: 9.2298\n",
      "Epoch 623/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.0026 - val_loss: 9.3613\n",
      "Epoch 624/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.0049 - val_loss: 9.2308\n",
      "Epoch 625/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.2883 - val_loss: 9.2856\n",
      "Epoch 626/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.9816 - val_loss: 9.0597\n",
      "Epoch 627/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.9151 - val_loss: 9.0037\n",
      "Epoch 628/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.9562 - val_loss: 8.8003\n",
      "Epoch 629/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.9280 - val_loss: 8.7481\n",
      "Epoch 630/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.8305 - val_loss: 8.7932\n",
      "Epoch 631/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.0626 - val_loss: 8.9101\n",
      "Epoch 632/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.0214 - val_loss: 8.8513\n",
      "Epoch 633/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.9492 - val_loss: 8.6258\n",
      "Epoch 634/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.9536 - val_loss: 8.7020\n",
      "Epoch 635/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.8169 - val_loss: 8.6155\n",
      "Epoch 636/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.8996 - val_loss: 8.9523\n",
      "Epoch 637/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.8765 - val_loss: 8.6827\n",
      "Epoch 638/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.8791 - val_loss: 8.7586\n",
      "Epoch 639/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.8313 - val_loss: 9.3633\n",
      "Epoch 640/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.9294 - val_loss: 8.4933\n",
      "Epoch 641/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.0343 - val_loss: 8.6431\n",
      "Epoch 642/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.8444 - val_loss: 8.5378\n",
      "Epoch 643/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.8407 - val_loss: 8.8695\n",
      "Epoch 644/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.7678 - val_loss: 8.4377\n",
      "Epoch 645/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.5906 - val_loss: 8.4065\n",
      "Epoch 646/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.5342 - val_loss: 8.6723\n",
      "Epoch 647/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.7343 - val_loss: 8.6065\n",
      "Epoch 648/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.6675 - val_loss: 8.4120\n",
      "Epoch 649/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.6045 - val_loss: 8.4465\n",
      "Epoch 650/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.6653 - val_loss: 8.4718\n",
      "Epoch 651/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.6496 - val_loss: 8.2425\n",
      "Epoch 652/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.5650 - val_loss: 8.2388\n",
      "Epoch 653/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.6973 - val_loss: 8.6377\n",
      "Epoch 654/1000\n",
      "1052/1052 [==============================] - 0s 127us/step - loss: 6.6985 - val_loss: 9.0783\n",
      "Epoch 655/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 6.9175 - val_loss: 8.6355\n",
      "Epoch 656/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.8658 - val_loss: 8.7791\n",
      "Epoch 657/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.5403 - val_loss: 8.2747\n",
      "Epoch 658/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.4064 - val_loss: 8.3842\n",
      "Epoch 659/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.5545 - val_loss: 8.2039\n",
      "Epoch 660/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.6418 - val_loss: 8.3817\n",
      "Epoch 661/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.5759 - val_loss: 8.4857\n",
      "Epoch 662/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.6432 - val_loss: 8.3421\n",
      "Epoch 663/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.5176 - val_loss: 8.1316\n",
      "Epoch 664/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.4321 - val_loss: 8.1489\n",
      "Epoch 665/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.4798 - val_loss: 8.1171\n",
      "Epoch 666/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.5531 - val_loss: 8.2588\n",
      "Epoch 667/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.4048 - val_loss: 8.1851\n",
      "Epoch 668/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.3804 - val_loss: 8.2437\n",
      "Epoch 669/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.4975 - val_loss: 7.9691\n",
      "Epoch 670/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.3702 - val_loss: 8.2739\n",
      "Epoch 671/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.3830 - val_loss: 8.2807\n",
      "Epoch 672/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.4692 - val_loss: 8.1512\n",
      "Epoch 673/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.4315 - val_loss: 8.0936\n",
      "Epoch 674/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.3174 - val_loss: 7.9820\n",
      "Epoch 675/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.3289 - val_loss: 7.9329\n",
      "Epoch 676/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.4413 - val_loss: 8.1724\n",
      "Epoch 677/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.2805 - val_loss: 8.0050\n",
      "Epoch 678/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.4338 - val_loss: 8.1104\n",
      "Epoch 679/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.3278 - val_loss: 7.9543\n",
      "Epoch 680/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.3308 - val_loss: 8.6522\n",
      "Epoch 681/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 6.6146 - val_loss: 8.2411\n",
      "Epoch 682/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.5015 - val_loss: 7.8793\n",
      "Epoch 683/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.3138 - val_loss: 8.0016\n",
      "Epoch 684/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.5887 - val_loss: 8.0268\n",
      "Epoch 685/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.4178 - val_loss: 7.9979\n",
      "Epoch 686/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.3277 - val_loss: 8.1153\n",
      "Epoch 687/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 6.3445 - val_loss: 8.1256\n",
      "Epoch 688/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.3461 - val_loss: 8.2149\n",
      "Epoch 689/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.3279 - val_loss: 7.8370\n",
      "Epoch 690/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.4955 - val_loss: 8.1178\n",
      "Epoch 691/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.4377 - val_loss: 7.8622\n",
      "Epoch 692/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.3085 - val_loss: 7.8763\n",
      "Epoch 693/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.2660 - val_loss: 7.6944\n",
      "Epoch 694/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.2377 - val_loss: 8.1774\n",
      "Epoch 695/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.4210 - val_loss: 7.7282\n",
      "Epoch 696/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.3715 - val_loss: 7.9861\n",
      "Epoch 697/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.2971 - val_loss: 8.1291\n",
      "Epoch 698/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.3711 - val_loss: 7.8099\n",
      "Epoch 699/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.2791 - val_loss: 7.8233\n",
      "Epoch 700/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.2779 - val_loss: 8.2105\n",
      "Epoch 701/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.3703 - val_loss: 8.6155\n",
      "Epoch 702/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.2216 - val_loss: 8.2737\n",
      "Epoch 703/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.3105 - val_loss: 7.6445\n",
      "Epoch 704/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.4340 - val_loss: 7.7173\n",
      "Epoch 705/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.4516 - val_loss: 7.9187\n",
      "Epoch 706/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.3363 - val_loss: 7.9132\n",
      "Epoch 707/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.2704 - val_loss: 7.7137\n",
      "Epoch 708/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.2248 - val_loss: 7.7427\n",
      "Epoch 709/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.3196 - val_loss: 7.7900\n",
      "Epoch 710/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.1604 - val_loss: 8.0872\n",
      "Epoch 711/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.1611 - val_loss: 7.7406\n",
      "Epoch 712/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.3649 - val_loss: 7.8911\n",
      "Epoch 713/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.2938 - val_loss: 8.2591\n",
      "Epoch 714/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.1374 - val_loss: 7.7286\n",
      "Epoch 715/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.2011 - val_loss: 7.8166\n",
      "Epoch 716/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.1788 - val_loss: 7.9914\n",
      "Epoch 717/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 6.2027 - val_loss: 7.5519\n",
      "Epoch 718/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 6.1876 - val_loss: 7.8724\n",
      "Epoch 719/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 6.3488 - val_loss: 7.6619\n",
      "Epoch 720/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 6.1477 - val_loss: 7.9188\n",
      "Epoch 721/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 6.2196 - val_loss: 7.6784\n",
      "Epoch 722/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 6.1141 - val_loss: 7.6252\n",
      "Epoch 723/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 6.2410 - val_loss: 7.8134\n",
      "Epoch 724/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.2848 - val_loss: 7.6798\n",
      "Epoch 725/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 6.4839 - val_loss: 7.6111\n",
      "Epoch 726/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.3219 - val_loss: 7.6011\n",
      "Epoch 727/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.1511 - val_loss: 7.7622\n",
      "Epoch 728/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.1454 - val_loss: 7.5474\n",
      "Epoch 729/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.1772 - val_loss: 7.5586\n",
      "Epoch 730/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.1560 - val_loss: 7.9097\n",
      "Epoch 731/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.1156 - val_loss: 7.7294\n",
      "Epoch 732/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.1820 - val_loss: 7.8549\n",
      "Epoch 733/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.2827 - val_loss: 8.0405\n",
      "Epoch 734/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.1438 - val_loss: 7.6537\n",
      "Epoch 735/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.2720 - val_loss: 7.7175\n",
      "Epoch 736/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.2795 - val_loss: 8.5765\n",
      "Epoch 737/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.2420 - val_loss: 7.4146\n",
      "Epoch 738/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 6.0726 - val_loss: 7.7058\n",
      "Epoch 739/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.2849 - val_loss: 7.5031\n",
      "Epoch 740/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.0838 - val_loss: 7.6715\n",
      "Epoch 741/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.2180 - val_loss: 7.7082\n",
      "Epoch 742/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.2497 - val_loss: 7.7655\n",
      "Epoch 743/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.1132 - val_loss: 7.5873\n",
      "Epoch 744/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.1056 - val_loss: 7.5184\n",
      "Epoch 745/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.1034 - val_loss: 7.8089\n",
      "Epoch 746/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.2356 - val_loss: 7.4426\n",
      "Epoch 747/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.0912 - val_loss: 7.6336\n",
      "Epoch 748/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.1722 - val_loss: 7.8355\n",
      "Epoch 749/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.0228 - val_loss: 7.5741\n",
      "Epoch 750/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.1379 - val_loss: 7.3352\n",
      "Epoch 751/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.1346 - val_loss: 7.2654\n",
      "Epoch 752/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.0567 - val_loss: 7.2609\n",
      "Epoch 753/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.0374 - val_loss: 7.6152\n",
      "Epoch 754/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.2463 - val_loss: 7.8166\n",
      "Epoch 755/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.2723 - val_loss: 7.2458\n",
      "Epoch 756/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.0718 - val_loss: 7.2553\n",
      "Epoch 757/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.9306 - val_loss: 7.4497\n",
      "Epoch 758/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.0015 - val_loss: 7.1539\n",
      "Epoch 759/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.1648 - val_loss: 7.1706\n",
      "Epoch 760/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.0210 - val_loss: 7.1785\n",
      "Epoch 761/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 6.0081 - val_loss: 7.1462\n",
      "Epoch 762/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.1008 - val_loss: 7.6462\n",
      "Epoch 763/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.2800 - val_loss: 7.6870\n",
      "Epoch 764/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 6.1630 - val_loss: 7.3268\n",
      "Epoch 765/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.0522 - val_loss: 7.3207\n",
      "Epoch 766/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.0698 - val_loss: 7.3712\n",
      "Epoch 767/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.9534 - val_loss: 8.0984\n",
      "Epoch 768/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.0955 - val_loss: 7.0102\n",
      "Epoch 769/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.9198 - val_loss: 7.1847\n",
      "Epoch 770/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.0170 - val_loss: 7.1506\n",
      "Epoch 771/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.9667 - val_loss: 7.3962\n",
      "Epoch 772/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.9776 - val_loss: 7.3571\n",
      "Epoch 773/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.0739 - val_loss: 7.0286\n",
      "Epoch 774/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.8976 - val_loss: 7.2859\n",
      "Epoch 775/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 5.8743 - val_loss: 7.5671\n",
      "Epoch 776/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.0809 - val_loss: 6.9590\n",
      "Epoch 777/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.9270 - val_loss: 7.0325\n",
      "Epoch 778/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.9056 - val_loss: 6.9325\n",
      "Epoch 779/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.8604 - val_loss: 7.1020\n",
      "Epoch 780/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.8756 - val_loss: 7.2943\n",
      "Epoch 781/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.8821 - val_loss: 7.1755\n",
      "Epoch 782/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.8893 - val_loss: 7.0318\n",
      "Epoch 783/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.8511 - val_loss: 6.9793\n",
      "Epoch 784/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.1219 - val_loss: 7.0564\n",
      "Epoch 785/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.8886 - val_loss: 7.4415\n",
      "Epoch 786/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.0774 - val_loss: 6.9971\n",
      "Epoch 787/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.9523 - val_loss: 7.4893\n",
      "Epoch 788/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.0142 - val_loss: 7.2958\n",
      "Epoch 789/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.1862 - val_loss: 7.8932\n",
      "Epoch 790/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.9792 - val_loss: 7.0492\n",
      "Epoch 791/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.8237 - val_loss: 7.0154\n",
      "Epoch 792/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.9234 - val_loss: 6.7925\n",
      "Epoch 793/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.0008 - val_loss: 7.8739\n",
      "Epoch 794/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.2944 - val_loss: 7.2529\n",
      "Epoch 795/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.9303 - val_loss: 7.0005\n",
      "Epoch 796/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.9230 - val_loss: 6.9489\n",
      "Epoch 797/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.8942 - val_loss: 7.2000\n",
      "Epoch 798/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.8683 - val_loss: 6.9496\n",
      "Epoch 799/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.9363 - val_loss: 7.0209\n",
      "Epoch 800/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.8829 - val_loss: 6.8940\n",
      "Epoch 801/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.9986 - val_loss: 7.1456\n",
      "Epoch 802/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.0659 - val_loss: 7.6361\n",
      "Epoch 803/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.9691 - val_loss: 7.1284\n",
      "Epoch 804/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.9265 - val_loss: 6.9285\n",
      "Epoch 805/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.0582 - val_loss: 7.8875\n",
      "Epoch 806/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.0393 - val_loss: 6.8455\n",
      "Epoch 807/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.9388 - val_loss: 6.9861\n",
      "Epoch 808/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.8426 - val_loss: 7.0015\n",
      "Epoch 809/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.8837 - val_loss: 7.1520\n",
      "Epoch 810/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.0507 - val_loss: 6.8545\n",
      "Epoch 811/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.9917 - val_loss: 6.8623\n",
      "Epoch 812/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.8451 - val_loss: 6.8873\n",
      "Epoch 813/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.9023 - val_loss: 6.9222\n",
      "Epoch 814/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.9620 - val_loss: 7.1791\n",
      "Epoch 815/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.8901 - val_loss: 6.8437\n",
      "Epoch 816/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.0384 - val_loss: 6.9305\n",
      "Epoch 817/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.9228 - val_loss: 6.8311\n",
      "Epoch 818/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.8401 - val_loss: 6.8932\n",
      "Epoch 819/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.8887 - val_loss: 6.8081\n",
      "Epoch 820/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.9852 - val_loss: 6.8195\n",
      "Epoch 821/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.9261 - val_loss: 7.0333\n",
      "Epoch 822/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.8985 - val_loss: 7.1127\n",
      "Epoch 823/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.8746 - val_loss: 7.3572\n",
      "Epoch 824/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.0234 - val_loss: 7.0143\n",
      "Epoch 825/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.9851 - val_loss: 6.9856\n",
      "Epoch 826/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.8521 - val_loss: 6.7850\n",
      "Epoch 827/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.7815 - val_loss: 6.7968\n",
      "Epoch 828/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.9119 - val_loss: 6.8642\n",
      "Epoch 829/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.9326 - val_loss: 6.9921\n",
      "Epoch 830/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.0230 - val_loss: 6.9339\n",
      "Epoch 831/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.8376 - val_loss: 7.3201\n",
      "Epoch 832/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.8396 - val_loss: 6.6806\n",
      "Epoch 833/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.8644 - val_loss: 7.1115\n",
      "Epoch 834/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.8251 - val_loss: 7.7051\n",
      "Epoch 835/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.0135 - val_loss: 6.8473\n",
      "Epoch 836/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.9211 - val_loss: 6.8127\n",
      "Epoch 837/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.9003 - val_loss: 6.7648\n",
      "Epoch 838/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.8110 - val_loss: 6.7416\n",
      "Epoch 839/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.9513 - val_loss: 6.9718\n",
      "Epoch 840/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.8011 - val_loss: 6.8439\n",
      "Epoch 841/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.7993 - val_loss: 7.0315\n",
      "Epoch 842/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.7956 - val_loss: 6.6511\n",
      "Epoch 843/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.8107 - val_loss: 6.8791\n",
      "Epoch 844/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.8580 - val_loss: 6.7169\n",
      "Epoch 845/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.7885 - val_loss: 6.7485\n",
      "Epoch 846/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.9060 - val_loss: 6.9390\n",
      "Epoch 847/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.8845 - val_loss: 6.7113\n",
      "Epoch 848/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.8848 - val_loss: 6.7400\n",
      "Epoch 849/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.7807 - val_loss: 6.6644\n",
      "Epoch 850/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.7558 - val_loss: 6.7553\n",
      "Epoch 851/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.7761 - val_loss: 6.7050\n",
      "Epoch 852/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.6995 - val_loss: 6.6675\n",
      "Epoch 853/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.7762 - val_loss: 6.8150\n",
      "Epoch 854/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.8734 - val_loss: 6.7897\n",
      "Epoch 855/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.8603 - val_loss: 6.9811\n",
      "Epoch 856/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.8298 - val_loss: 6.7426\n",
      "Epoch 857/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.7801 - val_loss: 6.9098\n",
      "Epoch 858/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.8683 - val_loss: 7.0519\n",
      "Epoch 859/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.8738 - val_loss: 7.0460\n",
      "Epoch 860/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.8122 - val_loss: 6.8041\n",
      "Epoch 861/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.7836 - val_loss: 7.3974\n",
      "Epoch 862/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.8775 - val_loss: 7.3024\n",
      "Epoch 863/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.8790 - val_loss: 6.8760\n",
      "Epoch 864/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.7564 - val_loss: 7.0244\n",
      "Epoch 865/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.8599 - val_loss: 6.7637\n",
      "Epoch 866/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.8035 - val_loss: 6.9369\n",
      "Epoch 867/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.7934 - val_loss: 6.8579\n",
      "Epoch 868/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.7342 - val_loss: 6.5514\n",
      "Epoch 869/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.0102 - val_loss: 6.7810\n",
      "Epoch 870/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.8612 - val_loss: 6.9714\n",
      "Epoch 871/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.8917 - val_loss: 6.7598\n",
      "Epoch 872/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.8231 - val_loss: 6.6035\n",
      "Epoch 873/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.8180 - val_loss: 6.9524\n",
      "Epoch 874/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.9599 - val_loss: 6.5833\n",
      "Epoch 875/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.7485 - val_loss: 6.6035\n",
      "Epoch 876/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.7141 - val_loss: 6.8276\n",
      "Epoch 877/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.7895 - val_loss: 6.9365\n",
      "Epoch 878/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.8036 - val_loss: 6.7341\n",
      "Epoch 879/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.7928 - val_loss: 6.8283\n",
      "Epoch 880/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.7215 - val_loss: 7.1221\n",
      "Epoch 881/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.9666 - val_loss: 6.6462\n",
      "Epoch 882/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.7003 - val_loss: 6.7606\n",
      "Epoch 883/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.9668 - val_loss: 6.9323\n",
      "Epoch 884/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.7811 - val_loss: 6.6001\n",
      "Epoch 885/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.7596 - val_loss: 7.1971\n",
      "Epoch 886/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 5.8571 - val_loss: 6.6512\n",
      "Epoch 887/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 5.7367 - val_loss: 6.7301\n",
      "Epoch 888/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 5.7695 - val_loss: 7.0423\n",
      "Epoch 889/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 5.7363 - val_loss: 6.8580\n",
      "Epoch 890/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 5.8205 - val_loss: 6.7337\n",
      "Epoch 891/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 5.8507 - val_loss: 6.8475\n",
      "Epoch 892/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 5.9068 - val_loss: 7.0338\n",
      "Epoch 893/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 5.6654 - val_loss: 6.5616\n",
      "Epoch 894/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.7166 - val_loss: 7.0095\n",
      "Epoch 895/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.0905 - val_loss: 6.5808\n",
      "Epoch 896/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.7703 - val_loss: 6.8950\n",
      "Epoch 897/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6827 - val_loss: 6.8405\n",
      "Epoch 898/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.7579 - val_loss: 7.2287\n",
      "Epoch 899/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.7678 - val_loss: 7.1311\n",
      "Epoch 900/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.7230 - val_loss: 6.7967\n",
      "Epoch 901/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.5495 - val_loss: 6.7376\n",
      "Epoch 902/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.8495 - val_loss: 7.4873\n",
      "Epoch 903/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.7096 - val_loss: 6.7642\n",
      "Epoch 904/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.7310 - val_loss: 6.7619\n",
      "Epoch 905/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.7356 - val_loss: 6.8576\n",
      "Epoch 906/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.7663 - val_loss: 6.6752\n",
      "Epoch 907/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.7217 - val_loss: 6.8336\n",
      "Epoch 908/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.7297 - val_loss: 6.9427\n",
      "Epoch 909/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.6185 - val_loss: 6.8155\n",
      "Epoch 910/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.8237 - val_loss: 6.8192\n",
      "Epoch 911/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.7860 - val_loss: 6.6330\n",
      "Epoch 912/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.8857 - val_loss: 6.8681\n",
      "Epoch 913/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.7750 - val_loss: 6.7429\n",
      "Epoch 914/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.8727 - val_loss: 7.0076\n",
      "Epoch 915/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.6284 - val_loss: 6.9107\n",
      "Epoch 916/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.8028 - val_loss: 7.3093\n",
      "Epoch 917/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.6794 - val_loss: 7.3241\n",
      "Epoch 918/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.7684 - val_loss: 6.7782\n",
      "Epoch 919/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.7075 - val_loss: 6.6281\n",
      "Epoch 920/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.6651 - val_loss: 7.1790\n",
      "Epoch 921/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.8536 - val_loss: 7.0318\n",
      "Epoch 922/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6246 - val_loss: 6.8990\n",
      "Epoch 923/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.6500 - val_loss: 6.7466\n",
      "Epoch 924/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6782 - val_loss: 6.7957\n",
      "Epoch 925/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.6553 - val_loss: 7.0050\n",
      "Epoch 926/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.7371 - val_loss: 6.8922\n",
      "Epoch 927/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.7011 - val_loss: 7.3639\n",
      "Epoch 928/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.9340 - val_loss: 7.1474\n",
      "Epoch 929/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.6884 - val_loss: 6.6701\n",
      "Epoch 930/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6651 - val_loss: 6.7031\n",
      "Epoch 931/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.7701 - val_loss: 7.2283\n",
      "Epoch 932/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6735 - val_loss: 6.9836\n",
      "Epoch 933/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.7805 - val_loss: 7.2027\n",
      "Epoch 934/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.8691 - val_loss: 6.9379\n",
      "Epoch 935/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.7846 - val_loss: 6.7985\n",
      "Epoch 936/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.6483 - val_loss: 6.8144\n",
      "Epoch 937/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.6620 - val_loss: 6.7995\n",
      "Epoch 938/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.5701 - val_loss: 7.1866\n",
      "Epoch 939/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.6651 - val_loss: 6.9903\n",
      "Epoch 940/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.8199 - val_loss: 6.8961\n",
      "Epoch 941/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.6435 - val_loss: 6.9526\n",
      "Epoch 942/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6358 - val_loss: 6.8330\n",
      "Epoch 943/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.6082 - val_loss: 6.6193\n",
      "Epoch 944/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.6383 - val_loss: 7.2595\n",
      "Epoch 945/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.6212 - val_loss: 6.7618\n",
      "Epoch 946/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.6400 - val_loss: 6.8330\n",
      "Epoch 947/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.6086 - val_loss: 6.9503\n",
      "Epoch 948/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.6684 - val_loss: 6.9232\n",
      "Epoch 949/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.6466 - val_loss: 6.5895\n",
      "Epoch 950/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.5753 - val_loss: 6.7135\n",
      "Epoch 951/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6126 - val_loss: 6.7532\n",
      "Epoch 952/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.5353 - val_loss: 6.9137\n",
      "Epoch 953/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.7063 - val_loss: 6.8889\n",
      "Epoch 954/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.7519 - val_loss: 6.6156\n",
      "Epoch 955/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.8021 - val_loss: 7.1219\n",
      "Epoch 956/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.7342 - val_loss: 7.0765\n",
      "Epoch 957/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.5635 - val_loss: 7.1227\n",
      "Epoch 958/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.5906 - val_loss: 6.9944\n",
      "Epoch 959/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.4888 - val_loss: 6.9671\n",
      "Epoch 960/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.8490 - val_loss: 6.7668\n",
      "Epoch 961/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6349 - val_loss: 6.8977\n",
      "Epoch 962/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.5483 - val_loss: 7.0009\n",
      "Epoch 963/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.6776 - val_loss: 6.7974\n",
      "Epoch 964/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.6176 - val_loss: 7.0146\n",
      "Epoch 965/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.5774 - val_loss: 6.9802\n",
      "Epoch 966/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.6135 - val_loss: 7.2313\n",
      "Epoch 967/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.6827 - val_loss: 6.8099\n",
      "Epoch 968/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.5736 - val_loss: 6.9163\n",
      "Epoch 969/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.5413 - val_loss: 6.8712\n",
      "Epoch 970/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.6144 - val_loss: 6.9705\n",
      "Epoch 971/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.5219 - val_loss: 6.7899\n",
      "Epoch 972/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.6001 - val_loss: 7.2896\n",
      "Epoch 973/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.5447 - val_loss: 7.4415\n",
      "Epoch 974/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.6993 - val_loss: 7.2082\n",
      "Epoch 975/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.7216 - val_loss: 6.9210\n",
      "Epoch 976/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.6761 - val_loss: 6.8493\n",
      "Epoch 977/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.5207 - val_loss: 6.8754\n",
      "Epoch 978/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.5691 - val_loss: 7.6228\n",
      "Epoch 979/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.9078 - val_loss: 6.8670\n",
      "Epoch 980/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.5105 - val_loss: 7.1545\n",
      "Epoch 981/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.6102 - val_loss: 6.9197\n",
      "Epoch 982/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6458 - val_loss: 7.3798\n",
      "Epoch 983/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.6762 - val_loss: 7.2391\n",
      "Epoch 984/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.6467 - val_loss: 6.8906\n",
      "Epoch 985/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.5993 - val_loss: 7.5169\n",
      "Epoch 986/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.0329 - val_loss: 6.6741\n",
      "Epoch 987/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.5558 - val_loss: 6.9512\n",
      "Epoch 988/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.5087 - val_loss: 7.0457\n",
      "Epoch 989/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.6363 - val_loss: 6.9622\n",
      "Epoch 990/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.6113 - val_loss: 7.2031\n",
      "Epoch 991/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.7560 - val_loss: 7.1895\n",
      "Epoch 992/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6059 - val_loss: 6.7530\n",
      "Epoch 993/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.5778 - val_loss: 7.1650\n",
      "Epoch 994/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6108 - val_loss: 6.8722\n",
      "Epoch 995/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.5282 - val_loss: 6.8124\n",
      "Epoch 996/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.6726 - val_loss: 6.5748\n",
      "Epoch 997/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6012 - val_loss: 6.8521\n",
      "Epoch 998/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.5814 - val_loss: 6.9833\n",
      "Epoch 999/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.5561 - val_loss: 6.7498\n",
      "Epoch 1000/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.6060 - val_loss: 6.8280\n",
      "5.680907883475312\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 0.09842891, -5.9014864 , -3.633644  , -0.13739903,  2.5892413 ],\n",
       "        [-1.7494925 , -0.84082913, -1.1324776 , -3.5437012 , -0.96982396],\n",
       "        [-0.15670197, -1.8609674 ,  2.2376769 , -4.8273067 ,  1.7579633 ],\n",
       "        [ 0.65256923,  0.48146918,  0.12185725,  0.7327178 , -0.14215545],\n",
       "        [-1.1810416 , -0.94193864, -3.087126  ,  1.1811019 ,  0.18019107]],\n",
       "       dtype=float32),\n",
       " array([ 4.898565  , -0.7032437 ,  0.58674103, -1.2950473 ,  2.437206  ],\n",
       "       dtype=float32),\n",
       " array([[ -0.9338975 ,   6.3288255 ,   0.34630173,   0.14828701,\n",
       "           0.33993703,   0.39467466,   1.9059079 ,  -1.3629316 ,\n",
       "          18.742342  ,   0.66618794],\n",
       "        [  1.110268  ,   1.4438086 ,   5.7119894 ,  -6.303383  ,\n",
       "           5.876701  ,   8.677212  ,  -2.588627  ,   0.05822279,\n",
       "          -0.9374768 ,   2.3301573 ],\n",
       "        [  1.2054665 ,   2.0089025 ,   0.23766361, -16.303696  ,\n",
       "           0.24573158,   0.25445515,  -1.0777525 ,   2.7943509 ,\n",
       "           1.1265295 ,   0.20810513],\n",
       "        [  1.1250999 ,   2.1798642 ,   5.7471714 ,  -2.851752  ,\n",
       "           5.6540985 ,   4.68852   ,  -0.07340586,   5.828982  ,\n",
       "           6.2538576 ,   0.5505585 ],\n",
       "        [  1.2111678 ,   0.4182452 ,  -0.14465901,  -1.7820729 ,\n",
       "          -0.13961639,  -0.18933861,  -1.0593699 ,  -4.1029673 ,\n",
       "           0.20753786,  -0.48021024]], dtype=float32),\n",
       " array([ 2.435494 ,  0.027584 ,  2.7198453,  2.961158 ,  3.0435207,\n",
       "         1.5121644,  7.774095 ,  2.2183774,  3.923744 , -2.2682474],\n",
       "       dtype=float32),\n",
       " array([[13.72175  ],\n",
       "        [14.040215 ],\n",
       "        [13.813882 ],\n",
       "        [ 9.5374775],\n",
       "        [13.864059 ],\n",
       "        [13.939551 ],\n",
       "        [17.769598 ],\n",
       "        [ 5.888504 ],\n",
       "        [13.239505 ],\n",
       "        [13.864063 ]], dtype=float32),\n",
       " array([12.853505], dtype=float32)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_airfoil, history_airfoil, evaluate_airfoil=NN_model_structure_regression_sigmoid(X_train_airfoil, X_val_airfoil, Y_train_airfoil, Y_val_airfoil, adam2, 32, 1000, x_test_airfoil, y_test_airfoil)\n",
    "model_airfoil.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_airfoil.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_airfoil_sigmoid_4th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 101\n",
      "Trainable params: 101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1052 samples, validate on 225 samples\n",
      "Epoch 1/1000\n",
      "1052/1052 [==============================] - 0s 225us/step - loss: 12887.8743 - val_loss: 10376.4927\n",
      "Epoch 2/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8708.0909 - val_loss: 7363.8360\n",
      "Epoch 3/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 6370.7822 - val_loss: 5548.9860\n",
      "Epoch 4/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 4869.7653 - val_loss: 4305.3023\n",
      "Epoch 5/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 3805.3149 - val_loss: 3397.8065\n",
      "Epoch 6/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 3013.9477 - val_loss: 2706.9553\n",
      "Epoch 7/1000\n",
      "1052/1052 [==============================] - 0s 108us/step - loss: 2406.9529 - val_loss: 2170.3525\n",
      "Epoch 8/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 1931.9222 - val_loss: 1749.7224\n",
      "Epoch 9/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 1557.4234 - val_loss: 1413.7083\n",
      "Epoch 10/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 1258.3373 - val_loss: 1145.5337\n",
      "Epoch 11/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 1018.9545 - val_loss: 929.3547\n",
      "Epoch 12/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 826.2793 - val_loss: 755.5187\n",
      "Epoch 13/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 671.0852 - val_loss: 615.1509\n",
      "Epoch 14/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 546.2010 - val_loss: 501.2908\n",
      "Epoch 15/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 445.1179 - val_loss: 410.1412\n",
      "Epoch 16/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 363.9746 - val_loss: 336.2730\n",
      "Epoch 17/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 298.5992 - val_loss: 276.8127\n",
      "Epoch 18/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 246.1928 - val_loss: 228.7392\n",
      "Epoch 19/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 204.1137 - val_loss: 190.3449\n",
      "Epoch 20/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 170.6003 - val_loss: 159.5402\n",
      "Epoch 21/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 143.8217 - val_loss: 135.1520\n",
      "Epoch 22/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 122.6309 - val_loss: 115.6975\n",
      "Epoch 23/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 105.8896 - val_loss: 100.1206\n",
      "Epoch 24/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 92.6777 - val_loss: 87.7332\n",
      "Epoch 25/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 82.2527 - val_loss: 78.1754\n",
      "Epoch 26/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 74.1688 - val_loss: 70.5763\n",
      "Epoch 27/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 67.8652 - val_loss: 64.5752\n",
      "Epoch 28/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 62.9565 - val_loss: 59.9151\n",
      "Epoch 29/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 59.1590 - val_loss: 56.3789\n",
      "Epoch 30/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 56.2720 - val_loss: 53.5124\n",
      "Epoch 31/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 54.0240 - val_loss: 51.3435\n",
      "Epoch 32/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 52.3232 - val_loss: 49.6541\n",
      "Epoch 33/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 51.0853 - val_loss: 48.2536\n",
      "Epoch 34/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 50.0809 - val_loss: 47.2915\n",
      "Epoch 35/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 49.3749 - val_loss: 46.5243\n",
      "Epoch 36/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 48.8577 - val_loss: 45.8964\n",
      "Epoch 37/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 48.4307 - val_loss: 45.4921\n",
      "Epoch 38/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 48.1452 - val_loss: 45.1348\n",
      "Epoch 39/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 47.9274 - val_loss: 44.8634\n",
      "Epoch 40/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 47.7817 - val_loss: 44.6289\n",
      "Epoch 41/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 47.6531 - val_loss: 44.5032\n",
      "Epoch 42/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 47.5780 - val_loss: 44.3598\n",
      "Epoch 43/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 47.5213 - val_loss: 44.2698\n",
      "Epoch 44/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 47.4722 - val_loss: 44.2120\n",
      "Epoch 45/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 47.4415 - val_loss: 44.1548\n",
      "Epoch 46/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 47.4297 - val_loss: 44.0811\n",
      "Epoch 47/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 47.4138 - val_loss: 44.0433\n",
      "Epoch 48/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 47.3989 - val_loss: 44.0424\n",
      "Epoch 49/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 47.3901 - val_loss: 44.0233\n",
      "Epoch 50/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 47.3830 - val_loss: 44.0021\n",
      "Epoch 51/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 47.3806 - val_loss: 43.9865\n",
      "Epoch 52/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 47.3832 - val_loss: 43.9484\n",
      "Epoch 53/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 47.3747 - val_loss: 43.9401\n",
      "Epoch 54/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 47.3745 - val_loss: 43.9564\n",
      "Epoch 55/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 47.3723 - val_loss: 43.9501\n",
      "Epoch 56/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 47.3780 - val_loss: 43.9264\n",
      "Epoch 57/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 47.3730 - val_loss: 43.9267\n",
      "Epoch 58/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 47.3728 - val_loss: 43.9394\n",
      "Epoch 59/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 47.3719 - val_loss: 43.9267\n",
      "Epoch 60/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 47.3738 - val_loss: 43.9303\n",
      "Epoch 61/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 47.3738 - val_loss: 43.9193\n",
      "Epoch 62/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 47.3813 - val_loss: 43.9218\n",
      "Epoch 63/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 47.3720 - val_loss: 43.9261\n",
      "Epoch 64/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 47.3728 - val_loss: 43.9178\n",
      "Epoch 65/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 47.3710 - val_loss: 43.9080\n",
      "Epoch 66/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 91us/step - loss: 47.3711 - val_loss: 43.9291\n",
      "Epoch 67/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 47.3689 - val_loss: 43.9140\n",
      "Epoch 68/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 47.3717 - val_loss: 43.9311\n",
      "Epoch 69/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 47.3672 - val_loss: 43.9194\n",
      "Epoch 70/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 47.3752 - val_loss: 43.9155\n",
      "Epoch 71/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 47.3687 - val_loss: 43.9201\n",
      "Epoch 72/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 47.3675 - val_loss: 43.9132\n",
      "Epoch 73/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 47.3747 - val_loss: 43.9246\n",
      "Epoch 74/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 47.3670 - val_loss: 43.9075\n",
      "Epoch 75/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 47.3699 - val_loss: 43.8977\n",
      "Epoch 76/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 47.3595 - val_loss: 43.9184\n",
      "Epoch 77/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 47.3579 - val_loss: 43.9333\n",
      "Epoch 78/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 47.3457 - val_loss: 43.9241\n",
      "Epoch 79/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 47.3333 - val_loss: 43.9024\n",
      "Epoch 80/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 47.2891 - val_loss: 43.9211\n",
      "Epoch 81/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 47.0625 - val_loss: 44.0520\n",
      "Epoch 82/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 45.9016 - val_loss: 40.0627\n",
      "Epoch 83/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 41.4928 - val_loss: 38.3391\n",
      "Epoch 84/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 38.2237 - val_loss: 37.3883\n",
      "Epoch 85/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 37.1430 - val_loss: 37.0655\n",
      "Epoch 86/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 36.9256 - val_loss: 36.6937\n",
      "Epoch 87/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 36.6784 - val_loss: 36.4547\n",
      "Epoch 88/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 36.4325 - val_loss: 36.3969\n",
      "Epoch 89/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 36.3204 - val_loss: 36.4706\n",
      "Epoch 90/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 36.1879 - val_loss: 36.3931\n",
      "Epoch 91/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 36.0446 - val_loss: 36.1711\n",
      "Epoch 92/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 35.6198 - val_loss: 36.1657\n",
      "Epoch 93/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 28.3031 - val_loss: 27.0786\n",
      "Epoch 94/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 22.5327 - val_loss: 25.1016\n",
      "Epoch 95/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 20.1375 - val_loss: 22.9879\n",
      "Epoch 96/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.4182 - val_loss: 21.1746\n",
      "Epoch 97/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.2199 - val_loss: 20.6230\n",
      "Epoch 98/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 16.6634 - val_loss: 19.9979\n",
      "Epoch 99/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 16.3396 - val_loss: 19.7112\n",
      "Epoch 100/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 15.9242 - val_loss: 19.4906\n",
      "Epoch 101/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 15.7515 - val_loss: 19.1750\n",
      "Epoch 102/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 15.6136 - val_loss: 19.5345\n",
      "Epoch 103/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 15.4978 - val_loss: 19.0606\n",
      "Epoch 104/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 15.3342 - val_loss: 19.1875\n",
      "Epoch 105/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 15.2716 - val_loss: 19.2745\n",
      "Epoch 106/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 15.1225 - val_loss: 19.9893\n",
      "Epoch 107/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 15.2911 - val_loss: 19.0908\n",
      "Epoch 108/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 15.1322 - val_loss: 19.5005\n",
      "Epoch 109/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 15.1681 - val_loss: 18.9284\n",
      "Epoch 110/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 15.0881 - val_loss: 19.2523\n",
      "Epoch 111/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.9184 - val_loss: 18.7736\n",
      "Epoch 112/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.9015 - val_loss: 18.7277\n",
      "Epoch 113/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.9058 - val_loss: 18.6555\n",
      "Epoch 114/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.8811 - val_loss: 18.6858\n",
      "Epoch 115/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.8005 - val_loss: 18.5165\n",
      "Epoch 116/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.9160 - val_loss: 18.6452\n",
      "Epoch 117/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.8830 - val_loss: 18.5606\n",
      "Epoch 118/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.8244 - val_loss: 18.4888\n",
      "Epoch 119/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 14.7390 - val_loss: 18.4433\n",
      "Epoch 120/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.7204 - val_loss: 18.5004\n",
      "Epoch 121/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.6860 - val_loss: 18.3426\n",
      "Epoch 122/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.7237 - val_loss: 18.5242\n",
      "Epoch 123/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.8860 - val_loss: 18.5805\n",
      "Epoch 124/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.7364 - val_loss: 18.5416\n",
      "Epoch 125/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.7645 - val_loss: 18.3041\n",
      "Epoch 126/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.6915 - val_loss: 18.3809\n",
      "Epoch 127/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.7791 - val_loss: 18.2629\n",
      "Epoch 128/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.6028 - val_loss: 18.3235\n",
      "Epoch 129/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.6243 - val_loss: 18.2312\n",
      "Epoch 130/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 14.7264 - val_loss: 18.2834\n",
      "Epoch 131/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.7255 - val_loss: 18.2468\n",
      "Epoch 132/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 14.7146 - val_loss: 18.3937\n",
      "Epoch 133/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.7087 - val_loss: 18.2603\n",
      "Epoch 134/1000\n",
      "1052/1052 [==============================] - 0s 127us/step - loss: 14.6909 - val_loss: 18.4140\n",
      "Epoch 135/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.7043 - val_loss: 18.2411\n",
      "Epoch 136/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.7497 - val_loss: 18.3237\n",
      "Epoch 137/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.7009 - val_loss: 18.5862\n",
      "Epoch 138/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 14.7680 - val_loss: 18.7045\n",
      "Epoch 139/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.7198 - val_loss: 18.1969\n",
      "Epoch 140/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.6290 - val_loss: 18.3447\n",
      "Epoch 141/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.6152 - val_loss: 18.4518\n",
      "Epoch 142/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.6720 - val_loss: 18.2697\n",
      "Epoch 143/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 14.6270 - val_loss: 18.6040\n",
      "Epoch 144/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 14.6644 - val_loss: 18.5033\n",
      "Epoch 145/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.6084 - val_loss: 18.1928\n",
      "Epoch 146/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.6753 - val_loss: 18.2094\n",
      "Epoch 147/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.6060 - val_loss: 18.4859\n",
      "Epoch 148/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.6192 - val_loss: 18.2668\n",
      "Epoch 149/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.6027 - val_loss: 18.1877\n",
      "Epoch 150/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.6299 - val_loss: 18.2625\n",
      "Epoch 151/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 14.6612 - val_loss: 18.3540\n",
      "Epoch 152/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 14.6787 - val_loss: 18.4911\n",
      "Epoch 153/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.5904 - val_loss: 18.4566\n",
      "Epoch 154/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.7491 - val_loss: 18.3124\n",
      "Epoch 155/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.6901 - val_loss: 18.5789\n",
      "Epoch 156/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.5945 - val_loss: 18.4020\n",
      "Epoch 157/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.6024 - val_loss: 18.1739\n",
      "Epoch 158/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.6471 - val_loss: 18.4363\n",
      "Epoch 159/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.6351 - val_loss: 18.3041\n",
      "Epoch 160/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 14.7005 - val_loss: 18.9762\n",
      "Epoch 161/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.6918 - val_loss: 18.2449\n",
      "Epoch 162/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.6097 - val_loss: 18.9201\n",
      "Epoch 163/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 14.7208 - val_loss: 18.4789\n",
      "Epoch 164/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.6284 - val_loss: 18.2485\n",
      "Epoch 165/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.5847 - val_loss: 18.3863\n",
      "Epoch 166/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.7970 - val_loss: 18.5210\n",
      "Epoch 167/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.7046 - val_loss: 18.2349\n",
      "Epoch 168/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.5406 - val_loss: 18.2447\n",
      "Epoch 169/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.5041 - val_loss: 18.4747\n",
      "Epoch 170/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.6376 - val_loss: 18.6549\n",
      "Epoch 171/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.6573 - val_loss: 18.4780\n",
      "Epoch 172/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.7833 - val_loss: 18.3379\n",
      "Epoch 173/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.5832 - val_loss: 18.6900\n",
      "Epoch 174/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.6449 - val_loss: 18.2597\n",
      "Epoch 175/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 14.5280 - val_loss: 18.2822\n",
      "Epoch 176/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.6214 - val_loss: 18.2983\n",
      "Epoch 177/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.6071 - val_loss: 18.2186\n",
      "Epoch 178/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 14.6128 - val_loss: 18.4920\n",
      "Epoch 179/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.5877 - val_loss: 18.3748\n",
      "Epoch 180/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.6751 - val_loss: 18.1605\n",
      "Epoch 181/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.6244 - val_loss: 18.4310\n",
      "Epoch 182/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 14.6296 - val_loss: 18.2555\n",
      "Epoch 183/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 14.5464 - val_loss: 18.7142\n",
      "Epoch 184/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.6320 - val_loss: 18.1494\n",
      "Epoch 185/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.6038 - val_loss: 18.2205\n",
      "Epoch 186/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.6376 - val_loss: 18.2841\n",
      "Epoch 187/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.6464 - val_loss: 18.6077\n",
      "Epoch 188/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.6905 - val_loss: 18.2301\n",
      "Epoch 189/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.6642 - val_loss: 18.5394\n",
      "Epoch 190/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.6185 - val_loss: 18.2380\n",
      "Epoch 191/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.5313 - val_loss: 18.3659\n",
      "Epoch 192/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.5560 - val_loss: 18.2835\n",
      "Epoch 193/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.5744 - val_loss: 18.2046\n",
      "Epoch 194/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.6279 - val_loss: 18.1854\n",
      "Epoch 195/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.5260 - val_loss: 18.3428\n",
      "Epoch 196/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.5656 - val_loss: 18.3734\n",
      "Epoch 197/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 14.5323 - val_loss: 18.3228\n",
      "Epoch 198/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 14.5578 - val_loss: 18.2756\n",
      "Epoch 199/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.5497 - val_loss: 18.2831\n",
      "Epoch 200/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.6464 - val_loss: 18.2883\n",
      "Epoch 201/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 14.5838 - val_loss: 18.4220\n",
      "Epoch 202/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.5686 - val_loss: 18.3426\n",
      "Epoch 203/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 14.5176 - val_loss: 18.4737\n",
      "Epoch 204/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 14.5182 - val_loss: 18.4320\n",
      "Epoch 205/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.5521 - val_loss: 18.3244\n",
      "Epoch 206/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.6081 - val_loss: 18.4343\n",
      "Epoch 207/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.6385 - val_loss: 18.4383\n",
      "Epoch 208/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 14.6365 - val_loss: 18.4339\n",
      "Epoch 209/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.5698 - val_loss: 18.1940\n",
      "Epoch 210/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 14.6115 - val_loss: 18.2002\n",
      "Epoch 211/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 14.6609 - val_loss: 18.7838\n",
      "Epoch 212/1000\n",
      "1052/1052 [==============================] - 0s 109us/step - loss: 14.6333 - val_loss: 18.5184\n",
      "Epoch 213/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 14.6234 - val_loss: 18.2491\n",
      "Epoch 214/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 14.6067 - val_loss: 18.4918\n",
      "Epoch 215/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 14.5983 - val_loss: 18.3251\n",
      "Epoch 216/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 100us/step - loss: 14.5559 - val_loss: 18.4799\n",
      "Epoch 217/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 14.6203 - val_loss: 18.1685\n",
      "Epoch 218/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.6512 - val_loss: 18.3578\n",
      "Epoch 219/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.6188 - val_loss: 18.1438\n",
      "Epoch 220/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.5448 - val_loss: 18.4844\n",
      "Epoch 221/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.5411 - val_loss: 18.5450\n",
      "Epoch 222/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.7012 - val_loss: 18.4345\n",
      "Epoch 223/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 14.5587 - val_loss: 18.4325\n",
      "Epoch 224/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.6210 - val_loss: 18.3532\n",
      "Epoch 225/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.4798 - val_loss: 18.0459\n",
      "Epoch 226/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 14.5436 - val_loss: 18.2316\n",
      "Epoch 227/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.5803 - val_loss: 18.2985\n",
      "Epoch 228/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.6290 - val_loss: 18.4490\n",
      "Epoch 229/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 14.5775 - val_loss: 18.3261\n",
      "Epoch 230/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.6261 - val_loss: 18.2242\n",
      "Epoch 231/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.6462 - val_loss: 18.2758\n",
      "Epoch 232/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.5741 - val_loss: 18.1699\n",
      "Epoch 233/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 14.5383 - val_loss: 18.1604\n",
      "Epoch 234/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 14.5672 - val_loss: 18.3805\n",
      "Epoch 235/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.6049 - val_loss: 18.1416\n",
      "Epoch 236/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.5368 - val_loss: 18.6576\n",
      "Epoch 237/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.6558 - val_loss: 18.3953\n",
      "Epoch 238/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.6098 - val_loss: 18.1820\n",
      "Epoch 239/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.6158 - val_loss: 18.2000\n",
      "Epoch 240/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.6112 - val_loss: 18.2922\n",
      "Epoch 241/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.5562 - val_loss: 18.3657\n",
      "Epoch 242/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.6904 - val_loss: 18.1617\n",
      "Epoch 243/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.5658 - val_loss: 18.0714\n",
      "Epoch 244/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.6631 - val_loss: 18.1473\n",
      "Epoch 245/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 14.6388 - val_loss: 18.2179\n",
      "Epoch 246/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 14.6647 - val_loss: 18.2405\n",
      "Epoch 247/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.7034 - val_loss: 18.0983\n",
      "Epoch 248/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.5675 - val_loss: 18.2548\n",
      "Epoch 249/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.5724 - val_loss: 18.1803\n",
      "Epoch 250/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.5902 - val_loss: 18.1378\n",
      "Epoch 251/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.5610 - val_loss: 18.1340\n",
      "Epoch 252/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.5662 - val_loss: 18.2392\n",
      "Epoch 253/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.6068 - val_loss: 18.1589\n",
      "Epoch 254/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 14.6202 - val_loss: 18.4643\n",
      "Epoch 255/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.6376 - val_loss: 18.1619\n",
      "Epoch 256/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.8194 - val_loss: 18.0916\n",
      "Epoch 257/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.6369 - val_loss: 18.1683\n",
      "Epoch 258/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.6361 - val_loss: 18.1313\n",
      "Epoch 259/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 14.7085 - val_loss: 18.1792\n",
      "Epoch 260/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.5761 - val_loss: 18.3033\n",
      "Epoch 261/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.5627 - val_loss: 18.0887\n",
      "Epoch 262/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.5320 - val_loss: 18.1552\n",
      "Epoch 263/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.5752 - val_loss: 18.3683\n",
      "Epoch 264/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.6302 - val_loss: 18.1669\n",
      "Epoch 265/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.5776 - val_loss: 18.1493\n",
      "Epoch 266/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.6887 - val_loss: 18.1325\n",
      "Epoch 267/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 14.5552 - val_loss: 18.1128\n",
      "Epoch 268/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.6185 - val_loss: 18.1508\n",
      "Epoch 269/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.6945 - val_loss: 18.2330\n",
      "Epoch 270/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.6133 - val_loss: 18.4447\n",
      "Epoch 271/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 14.5766 - val_loss: 18.3724\n",
      "Epoch 272/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.5404 - val_loss: 18.3301\n",
      "Epoch 273/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.6253 - val_loss: 18.4420\n",
      "Epoch 274/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 14.6560 - val_loss: 18.1836\n",
      "Epoch 275/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 14.4824 - val_loss: 18.0498\n",
      "Epoch 276/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 14.6938 - val_loss: 18.1946\n",
      "Epoch 277/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 14.6428 - val_loss: 18.2038\n",
      "Epoch 278/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 14.6029 - val_loss: 18.0522\n",
      "Epoch 279/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.5473 - val_loss: 18.1273\n",
      "Epoch 280/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.5832 - val_loss: 18.3086\n",
      "Epoch 281/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.6805 - val_loss: 18.0611\n",
      "Epoch 282/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.5603 - val_loss: 18.1697\n",
      "Epoch 283/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.6102 - val_loss: 18.5035\n",
      "Epoch 284/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 14.5938 - val_loss: 18.1437\n",
      "Epoch 285/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 14.5951 - val_loss: 18.0658\n",
      "Epoch 286/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.5733 - val_loss: 18.5909\n",
      "Epoch 287/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 14.5441 - val_loss: 18.0940\n",
      "Epoch 288/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.5274 - val_loss: 18.2049\n",
      "Epoch 289/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 14.5953 - val_loss: 18.3473\n",
      "Epoch 290/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.4812 - val_loss: 18.3439\n",
      "Epoch 291/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 93us/step - loss: 14.5402 - val_loss: 18.5393\n",
      "Epoch 292/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 14.5934 - val_loss: 18.4130\n",
      "Epoch 293/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.4542 - val_loss: 18.2923\n",
      "Epoch 294/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 14.6337 - val_loss: 18.1090\n",
      "Epoch 295/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 14.5806 - val_loss: 18.2006\n",
      "Epoch 296/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.5242 - val_loss: 18.2265\n",
      "Epoch 297/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.4487 - val_loss: 18.4007\n",
      "Epoch 298/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.5429 - val_loss: 18.2429\n",
      "Epoch 299/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 14.5970 - val_loss: 18.2467\n",
      "Epoch 300/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.4784 - val_loss: 18.0810\n",
      "Epoch 301/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.5090 - val_loss: 18.4939\n",
      "Epoch 302/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.7319 - val_loss: 18.4954\n",
      "Epoch 303/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.6004 - val_loss: 18.1094\n",
      "Epoch 304/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.5119 - val_loss: 18.1847\n",
      "Epoch 305/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.5587 - val_loss: 18.2545\n",
      "Epoch 306/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.6832 - val_loss: 18.5181\n",
      "Epoch 307/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.5872 - val_loss: 18.6228\n",
      "Epoch 308/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.5537 - val_loss: 18.2304\n",
      "Epoch 309/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 14.4953 - val_loss: 18.0460\n",
      "Epoch 310/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.4609 - val_loss: 18.0916\n",
      "Epoch 311/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 14.5646 - val_loss: 18.4230\n",
      "Epoch 312/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 14.5007 - val_loss: 18.3145\n",
      "Epoch 313/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.5983 - val_loss: 18.2065\n",
      "Epoch 314/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.5123 - val_loss: 18.5728\n",
      "Epoch 315/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.5975 - val_loss: 18.2047\n",
      "Epoch 316/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.5213 - val_loss: 18.1069\n",
      "Epoch 317/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.4845 - val_loss: 18.2885\n",
      "Epoch 318/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.5872 - val_loss: 18.3143\n",
      "Epoch 319/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.5315 - val_loss: 18.2544\n",
      "Epoch 320/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.6990 - val_loss: 18.5170\n",
      "Epoch 321/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 14.5326 - val_loss: 18.1626\n",
      "Epoch 322/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.5771 - val_loss: 18.2954\n",
      "Epoch 323/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.5658 - val_loss: 18.9234\n",
      "Epoch 324/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.6455 - val_loss: 18.1067\n",
      "Epoch 325/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.5324 - val_loss: 18.2325\n",
      "Epoch 326/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.6301 - val_loss: 18.1817\n",
      "Epoch 327/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.5670 - val_loss: 18.1800\n",
      "Epoch 328/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.5313 - val_loss: 18.3424\n",
      "Epoch 329/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.4832 - val_loss: 18.1238\n",
      "Epoch 330/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.5540 - val_loss: 18.6645\n",
      "Epoch 331/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.7258 - val_loss: 18.5974\n",
      "Epoch 332/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 14.6212 - val_loss: 18.1235\n",
      "Epoch 333/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.5620 - val_loss: 18.1484\n",
      "Epoch 334/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.5056 - val_loss: 18.3438\n",
      "Epoch 335/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.5140 - val_loss: 18.3447\n",
      "Epoch 336/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 14.4862 - val_loss: 18.1533\n",
      "Epoch 337/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 14.5060 - val_loss: 18.1696\n",
      "Epoch 338/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 14.5411 - val_loss: 18.3087\n",
      "Epoch 339/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 14.5734 - val_loss: 18.0399\n",
      "Epoch 340/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.6279 - val_loss: 18.1387\n",
      "Epoch 341/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.4804 - val_loss: 18.1603\n",
      "Epoch 342/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.5179 - val_loss: 18.2781\n",
      "Epoch 343/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.4816 - val_loss: 18.1270\n",
      "Epoch 344/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.4451 - val_loss: 18.2865\n",
      "Epoch 345/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 14.5555 - val_loss: 18.1347\n",
      "Epoch 346/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 14.5244 - val_loss: 18.2492\n",
      "Epoch 347/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.4713 - val_loss: 18.7856\n",
      "Epoch 348/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.5733 - val_loss: 18.6664\n",
      "Epoch 349/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.6121 - val_loss: 18.2237\n",
      "Epoch 350/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.4925 - val_loss: 18.1855\n",
      "Epoch 351/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.4650 - val_loss: 18.1972\n",
      "Epoch 352/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.5012 - val_loss: 18.3431\n",
      "Epoch 353/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.4491 - val_loss: 18.3750\n",
      "Epoch 354/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.6022 - val_loss: 18.1251\n",
      "Epoch 355/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 14.6326 - val_loss: 18.2076\n",
      "Epoch 356/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 14.5433 - val_loss: 18.2186\n",
      "Epoch 357/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.5674 - val_loss: 18.2148\n",
      "Epoch 358/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 14.5402 - val_loss: 18.2637\n",
      "Epoch 359/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 14.5344 - val_loss: 18.0685\n",
      "Epoch 360/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 14.4856 - val_loss: 18.4183\n",
      "Epoch 361/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 14.4782 - val_loss: 18.2233\n",
      "Epoch 362/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.4745 - val_loss: 18.2815\n",
      "Epoch 363/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 14.6104 - val_loss: 18.3119\n",
      "Epoch 364/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 14.6216 - val_loss: 18.2762\n",
      "Epoch 365/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.4335 - val_loss: 18.4017\n",
      "Epoch 366/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.5632 - val_loss: 18.1773\n",
      "Epoch 367/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.5847 - val_loss: 18.1636\n",
      "Epoch 368/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 14.5931 - val_loss: 18.4762\n",
      "Epoch 369/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.5483 - val_loss: 18.2084\n",
      "Epoch 370/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.6245 - val_loss: 18.0696\n",
      "Epoch 371/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.4963 - val_loss: 18.1068\n",
      "Epoch 372/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.5307 - val_loss: 18.0975\n",
      "Epoch 373/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.5154 - val_loss: 18.1286\n",
      "Epoch 374/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.4262 - val_loss: 18.5126\n",
      "Epoch 375/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 14.4810 - val_loss: 18.5428\n",
      "Epoch 376/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 14.6819 - val_loss: 18.1663\n",
      "Epoch 377/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 14.5912 - val_loss: 18.0795\n",
      "Epoch 378/1000\n",
      "1052/1052 [==============================] - 0s 110us/step - loss: 14.5762 - val_loss: 18.3906\n",
      "Epoch 379/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 14.6333 - val_loss: 18.6362\n",
      "Epoch 380/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 14.5564 - val_loss: 18.3558\n",
      "Epoch 381/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 14.5479 - val_loss: 18.1413\n",
      "Epoch 382/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 14.5919 - val_loss: 18.1468\n",
      "Epoch 383/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 14.4997 - val_loss: 18.0812\n",
      "Epoch 384/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 14.5574 - val_loss: 18.1834\n",
      "Epoch 385/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.5766 - val_loss: 18.0635\n",
      "Epoch 386/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.4379 - val_loss: 18.0828\n",
      "Epoch 387/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 14.5234 - val_loss: 18.0564\n",
      "Epoch 388/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 14.5687 - val_loss: 18.0607\n",
      "Epoch 389/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 14.4475 - val_loss: 18.0616\n",
      "Epoch 390/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.4889 - val_loss: 18.1355\n",
      "Epoch 391/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 14.5631 - val_loss: 18.1251\n",
      "Epoch 392/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.4758 - val_loss: 18.1929\n",
      "Epoch 393/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 14.5484 - val_loss: 18.1168\n",
      "Epoch 394/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 14.5229 - val_loss: 18.0038\n",
      "Epoch 395/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.5860 - val_loss: 17.9339\n",
      "Epoch 396/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.4605 - val_loss: 18.0904\n",
      "Epoch 397/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.4714 - val_loss: 18.1607\n",
      "Epoch 398/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 14.6943 - val_loss: 18.1044\n",
      "Epoch 399/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.5019 - val_loss: 18.1380\n",
      "Epoch 400/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.5114 - val_loss: 18.1306\n",
      "Epoch 401/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.5326 - val_loss: 18.1121\n",
      "Epoch 402/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 14.4204 - val_loss: 18.2675\n",
      "Epoch 403/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.4631 - val_loss: 18.1669\n",
      "Epoch 404/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 14.4935 - val_loss: 18.1239\n",
      "Epoch 405/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.5011 - val_loss: 17.9710\n",
      "Epoch 406/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.4550 - val_loss: 18.0172\n",
      "Epoch 407/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.4160 - val_loss: 17.9585\n",
      "Epoch 408/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.4327 - val_loss: 18.0243\n",
      "Epoch 409/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.4460 - val_loss: 18.0091\n",
      "Epoch 410/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.4736 - val_loss: 19.0356\n",
      "Epoch 411/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.7939 - val_loss: 18.5971\n",
      "Epoch 412/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.7137 - val_loss: 18.6095\n",
      "Epoch 413/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.5847 - val_loss: 17.9183\n",
      "Epoch 414/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.5286 - val_loss: 18.0773\n",
      "Epoch 415/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.5275 - val_loss: 18.0629\n",
      "Epoch 416/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.4999 - val_loss: 18.0709\n",
      "Epoch 417/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.4977 - val_loss: 17.9975\n",
      "Epoch 418/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.5192 - val_loss: 18.0716\n",
      "Epoch 419/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.4611 - val_loss: 18.0904\n",
      "Epoch 420/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.5428 - val_loss: 18.0247\n",
      "Epoch 421/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 14.5509 - val_loss: 18.2762\n",
      "Epoch 422/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.5025 - val_loss: 18.0975\n",
      "Epoch 423/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.5083 - val_loss: 17.9674\n",
      "Epoch 424/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.5007 - val_loss: 18.2746\n",
      "Epoch 425/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.5056 - val_loss: 18.1135\n",
      "Epoch 426/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.5187 - val_loss: 18.2808\n",
      "Epoch 427/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.6870 - val_loss: 17.9083\n",
      "Epoch 428/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.4092 - val_loss: 18.1343\n",
      "Epoch 429/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.4348 - val_loss: 18.0263\n",
      "Epoch 430/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.5627 - val_loss: 17.9271\n",
      "Epoch 431/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.4484 - val_loss: 18.0032\n",
      "Epoch 432/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.4391 - val_loss: 17.9737\n",
      "Epoch 433/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.4789 - val_loss: 18.1357\n",
      "Epoch 434/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.5680 - val_loss: 18.0831\n",
      "Epoch 435/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.4926 - val_loss: 17.9056\n",
      "Epoch 436/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.4331 - val_loss: 17.9111\n",
      "Epoch 437/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.4937 - val_loss: 17.9131\n",
      "Epoch 438/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.4429 - val_loss: 18.0432\n",
      "Epoch 439/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.4604 - val_loss: 17.9400\n",
      "Epoch 440/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.4118 - val_loss: 17.8641\n",
      "Epoch 441/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.4754 - val_loss: 18.0901\n",
      "Epoch 442/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.5767 - val_loss: 17.8214\n",
      "Epoch 443/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.4363 - val_loss: 18.0801\n",
      "Epoch 444/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.3991 - val_loss: 18.0565\n",
      "Epoch 445/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.5132 - val_loss: 18.2084\n",
      "Epoch 446/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.6875 - val_loss: 18.1401\n",
      "Epoch 447/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.3991 - val_loss: 17.8967\n",
      "Epoch 448/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.5055 - val_loss: 18.2159\n",
      "Epoch 449/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.4724 - val_loss: 17.9198\n",
      "Epoch 450/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.4414 - val_loss: 17.8976\n",
      "Epoch 451/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.3942 - val_loss: 17.8609\n",
      "Epoch 452/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.5600 - val_loss: 17.8304\n",
      "Epoch 453/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.5359 - val_loss: 18.2359\n",
      "Epoch 454/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.4790 - val_loss: 18.1925\n",
      "Epoch 455/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.3729 - val_loss: 17.8943\n",
      "Epoch 456/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.4878 - val_loss: 17.8901\n",
      "Epoch 457/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.5232 - val_loss: 18.1150\n",
      "Epoch 458/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.5481 - val_loss: 18.1816\n",
      "Epoch 459/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 14.5248 - val_loss: 18.1172\n",
      "Epoch 460/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.4631 - val_loss: 17.8703\n",
      "Epoch 461/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.4898 - val_loss: 18.1356\n",
      "Epoch 462/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.4701 - val_loss: 17.9403\n",
      "Epoch 463/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 14.4884 - val_loss: 18.0013\n",
      "Epoch 464/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.4180 - val_loss: 17.9188\n",
      "Epoch 465/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.4641 - val_loss: 18.1151\n",
      "Epoch 466/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.4460 - val_loss: 18.0818\n",
      "Epoch 467/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.5548 - val_loss: 18.3735\n",
      "Epoch 468/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 14.5702 - val_loss: 18.0244\n",
      "Epoch 469/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.4623 - val_loss: 18.7172\n",
      "Epoch 470/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.5177 - val_loss: 18.2926\n",
      "Epoch 471/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 14.4550 - val_loss: 17.9337\n",
      "Epoch 472/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.3704 - val_loss: 17.9354\n",
      "Epoch 473/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.5511 - val_loss: 17.9587\n",
      "Epoch 474/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 14.4663 - val_loss: 17.8453\n",
      "Epoch 475/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.6222 - val_loss: 18.2747\n",
      "Epoch 476/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.4816 - val_loss: 17.8439\n",
      "Epoch 477/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.4315 - val_loss: 18.0135\n",
      "Epoch 478/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.3977 - val_loss: 18.0232\n",
      "Epoch 479/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.3820 - val_loss: 17.8258\n",
      "Epoch 480/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.4033 - val_loss: 18.1670\n",
      "Epoch 481/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.4250 - val_loss: 17.9171\n",
      "Epoch 482/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.3550 - val_loss: 18.3844\n",
      "Epoch 483/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.5297 - val_loss: 17.9193\n",
      "Epoch 484/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.3979 - val_loss: 18.1357\n",
      "Epoch 485/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.3854 - val_loss: 17.9973\n",
      "Epoch 486/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 14.3493 - val_loss: 17.9635\n",
      "Epoch 487/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 14.3595 - val_loss: 17.9037\n",
      "Epoch 488/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.3911 - val_loss: 18.1036\n",
      "Epoch 489/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.6257 - val_loss: 17.9303\n",
      "Epoch 490/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.4576 - val_loss: 18.0724\n",
      "Epoch 491/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.5171 - val_loss: 18.0713\n",
      "Epoch 492/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.4614 - val_loss: 17.8166\n",
      "Epoch 493/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.5880 - val_loss: 17.9599\n",
      "Epoch 494/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 14.4917 - val_loss: 18.1487\n",
      "Epoch 495/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.4954 - val_loss: 18.1215\n",
      "Epoch 496/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.4629 - val_loss: 18.3044\n",
      "Epoch 497/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.4276 - val_loss: 18.0683\n",
      "Epoch 498/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.3484 - val_loss: 17.9724\n",
      "Epoch 499/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.4138 - val_loss: 17.9814\n",
      "Epoch 500/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 14.4337 - val_loss: 17.9236\n",
      "Epoch 501/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.3800 - val_loss: 17.9603\n",
      "Epoch 502/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.4818 - val_loss: 18.1260\n",
      "Epoch 503/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.4222 - val_loss: 18.2699\n",
      "Epoch 504/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.4099 - val_loss: 17.9373\n",
      "Epoch 505/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 14.3293 - val_loss: 17.8845\n",
      "Epoch 506/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.4034 - val_loss: 17.8148\n",
      "Epoch 507/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.4861 - val_loss: 18.0561\n",
      "Epoch 508/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.5696 - val_loss: 18.0553\n",
      "Epoch 509/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.3710 - val_loss: 17.9396\n",
      "Epoch 510/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.4166 - val_loss: 17.7183\n",
      "Epoch 511/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.4628 - val_loss: 17.9801\n",
      "Epoch 512/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 14.3706 - val_loss: 18.2249\n",
      "Epoch 513/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 14.4130 - val_loss: 17.9017\n",
      "Epoch 514/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.4816 - val_loss: 18.1699\n",
      "Epoch 515/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.4391 - val_loss: 17.7956\n",
      "Epoch 516/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.3433 - val_loss: 17.9070\n",
      "Epoch 517/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 14.4442 - val_loss: 18.1152\n",
      "Epoch 518/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.4094 - val_loss: 17.7621\n",
      "Epoch 519/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.4636 - val_loss: 17.9792\n",
      "Epoch 520/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.4242 - val_loss: 17.9051\n",
      "Epoch 521/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.4369 - val_loss: 17.8524\n",
      "Epoch 522/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.4429 - val_loss: 17.8391\n",
      "Epoch 523/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.4472 - val_loss: 18.2289\n",
      "Epoch 524/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.3366 - val_loss: 17.8403\n",
      "Epoch 525/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.3544 - val_loss: 17.8621\n",
      "Epoch 526/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.2986 - val_loss: 17.9019\n",
      "Epoch 527/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.3920 - val_loss: 18.1358\n",
      "Epoch 528/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.4071 - val_loss: 17.9380\n",
      "Epoch 529/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.3926 - val_loss: 17.8242\n",
      "Epoch 530/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.3600 - val_loss: 17.8851\n",
      "Epoch 531/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.7324 - val_loss: 17.8781\n",
      "Epoch 532/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.3627 - val_loss: 17.8486\n",
      "Epoch 533/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.3660 - val_loss: 17.8612\n",
      "Epoch 534/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.3261 - val_loss: 17.8020\n",
      "Epoch 535/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.3098 - val_loss: 17.9290\n",
      "Epoch 536/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.4178 - val_loss: 17.7038\n",
      "Epoch 537/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.3187 - val_loss: 17.9870\n",
      "Epoch 538/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 14.3765 - val_loss: 17.7937\n",
      "Epoch 539/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.4880 - val_loss: 17.8744\n",
      "Epoch 540/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.3765 - val_loss: 17.8112\n",
      "Epoch 541/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 14.3671 - val_loss: 17.6625\n",
      "Epoch 542/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 14.3697 - val_loss: 17.9768\n",
      "Epoch 543/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 14.4930 - val_loss: 18.2748\n",
      "Epoch 544/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 14.5968 - val_loss: 17.8403\n",
      "Epoch 545/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 14.4041 - val_loss: 18.3171\n",
      "Epoch 546/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 14.5719 - val_loss: 18.1097\n",
      "Epoch 547/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 14.5784 - val_loss: 17.8135\n",
      "Epoch 548/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 14.5005 - val_loss: 17.8741\n",
      "Epoch 549/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 14.4536 - val_loss: 17.8966\n",
      "Epoch 550/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.4224 - val_loss: 17.8985\n",
      "Epoch 551/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.3755 - val_loss: 17.9473\n",
      "Epoch 552/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.4024 - val_loss: 18.1014\n",
      "Epoch 553/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.5257 - val_loss: 17.9122\n",
      "Epoch 554/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.4046 - val_loss: 18.5463\n",
      "Epoch 555/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.3640 - val_loss: 18.0415\n",
      "Epoch 556/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.4799 - val_loss: 17.8824\n",
      "Epoch 557/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.3973 - val_loss: 17.9111\n",
      "Epoch 558/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.3519 - val_loss: 17.7669\n",
      "Epoch 559/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.4166 - val_loss: 18.0395\n",
      "Epoch 560/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.3785 - val_loss: 17.7575\n",
      "Epoch 561/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.3056 - val_loss: 18.2229\n",
      "Epoch 562/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.3955 - val_loss: 18.0249\n",
      "Epoch 563/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.3380 - val_loss: 17.8146\n",
      "Epoch 564/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.3295 - val_loss: 17.8610\n",
      "Epoch 565/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.4926 - val_loss: 17.7222\n",
      "Epoch 566/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.5039 - val_loss: 17.9187\n",
      "Epoch 567/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.3647 - val_loss: 17.8536\n",
      "Epoch 568/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 14.4018 - val_loss: 17.7933\n",
      "Epoch 569/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.5316 - val_loss: 17.8082\n",
      "Epoch 570/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.4277 - val_loss: 18.0389\n",
      "Epoch 571/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.3956 - val_loss: 17.8887\n",
      "Epoch 572/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.5308 - val_loss: 17.9252\n",
      "Epoch 573/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.3804 - val_loss: 17.9536\n",
      "Epoch 574/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 14.4367 - val_loss: 17.8105\n",
      "Epoch 575/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.3379 - val_loss: 18.2238\n",
      "Epoch 576/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.5521 - val_loss: 18.1529\n",
      "Epoch 577/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 14.3772 - val_loss: 18.1942\n",
      "Epoch 578/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.3843 - val_loss: 17.7714\n",
      "Epoch 579/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.2983 - val_loss: 17.7090\n",
      "Epoch 580/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.3111 - val_loss: 17.7630\n",
      "Epoch 581/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.3329 - val_loss: 17.9932\n",
      "Epoch 582/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.4808 - val_loss: 17.7823\n",
      "Epoch 583/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.5261 - val_loss: 17.9119\n",
      "Epoch 584/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.4172 - val_loss: 17.9497\n",
      "Epoch 585/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.4923 - val_loss: 17.7567\n",
      "Epoch 586/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.3522 - val_loss: 17.8813\n",
      "Epoch 587/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.3502 - val_loss: 17.8074\n",
      "Epoch 588/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 14.4203 - val_loss: 17.8436\n",
      "Epoch 589/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 14.3027 - val_loss: 17.8227\n",
      "Epoch 590/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.3426 - val_loss: 17.9475\n",
      "Epoch 591/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.3157 - val_loss: 17.8077\n",
      "Epoch 592/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.2907 - val_loss: 17.9313\n",
      "Epoch 593/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.4248 - val_loss: 17.7211\n",
      "Epoch 594/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.2561 - val_loss: 17.7173\n",
      "Epoch 595/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.3020 - val_loss: 17.8030\n",
      "Epoch 596/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.2689 - val_loss: 18.2842\n",
      "Epoch 597/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.4711 - val_loss: 18.2375\n",
      "Epoch 598/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.4252 - val_loss: 17.8102\n",
      "Epoch 599/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.3641 - val_loss: 17.7968\n",
      "Epoch 600/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.3174 - val_loss: 18.0867\n",
      "Epoch 601/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.5147 - val_loss: 17.9159\n",
      "Epoch 602/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.3648 - val_loss: 17.9691\n",
      "Epoch 603/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 14.3865 - val_loss: 18.0423\n",
      "Epoch 604/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.4703 - val_loss: 17.7721\n",
      "Epoch 605/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.4128 - val_loss: 17.7503\n",
      "Epoch 606/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.5284 - val_loss: 17.9439\n",
      "Epoch 607/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.4057 - val_loss: 18.0279\n",
      "Epoch 608/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.3454 - val_loss: 18.0974\n",
      "Epoch 609/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 14.3130 - val_loss: 17.7875\n",
      "Epoch 610/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.2758 - val_loss: 17.8246\n",
      "Epoch 611/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 14.2740 - val_loss: 17.8479\n",
      "Epoch 612/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.3872 - val_loss: 18.3581\n",
      "Epoch 613/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.3874 - val_loss: 17.7896\n",
      "Epoch 614/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.3632 - val_loss: 18.0326\n",
      "Epoch 615/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.2994 - val_loss: 18.0778\n",
      "Epoch 616/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 14.3397 - val_loss: 17.7481\n",
      "Epoch 617/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.4462 - val_loss: 18.3366\n",
      "Epoch 618/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.5791 - val_loss: 18.0282\n",
      "Epoch 619/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.4622 - val_loss: 17.8614\n",
      "Epoch 620/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.3561 - val_loss: 17.7347\n",
      "Epoch 621/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.2567 - val_loss: 17.9023\n",
      "Epoch 622/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 14.3097 - val_loss: 17.9327\n",
      "Epoch 623/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.3819 - val_loss: 17.8816\n",
      "Epoch 624/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.3003 - val_loss: 17.8752\n",
      "Epoch 625/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.3767 - val_loss: 17.8983\n",
      "Epoch 626/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.2539 - val_loss: 17.8946\n",
      "Epoch 627/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.3392 - val_loss: 17.8288\n",
      "Epoch 628/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.2233 - val_loss: 17.8904\n",
      "Epoch 629/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.3619 - val_loss: 17.8192\n",
      "Epoch 630/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.3787 - val_loss: 17.9368\n",
      "Epoch 631/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 14.3588 - val_loss: 17.7441\n",
      "Epoch 632/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.4295 - val_loss: 17.9400\n",
      "Epoch 633/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.3029 - val_loss: 18.0288\n",
      "Epoch 634/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.3080 - val_loss: 17.9875\n",
      "Epoch 635/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.3595 - val_loss: 17.8674\n",
      "Epoch 636/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.3459 - val_loss: 17.9935\n",
      "Epoch 637/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 14.3369 - val_loss: 17.7929\n",
      "Epoch 638/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.3821 - val_loss: 17.9056\n",
      "Epoch 639/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.3128 - val_loss: 17.7458\n",
      "Epoch 640/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.2289 - val_loss: 18.2134\n",
      "Epoch 641/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.3148 - val_loss: 17.8576\n",
      "Epoch 642/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 14.2617 - val_loss: 18.0584\n",
      "Epoch 643/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.2379 - val_loss: 18.0292\n",
      "Epoch 644/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.3263 - val_loss: 18.0215\n",
      "Epoch 645/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.2354 - val_loss: 18.0286\n",
      "Epoch 646/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.4654 - val_loss: 17.9212\n",
      "Epoch 647/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.2959 - val_loss: 18.3528\n",
      "Epoch 648/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.2795 - val_loss: 18.0482\n",
      "Epoch 649/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.3014 - val_loss: 17.8664\n",
      "Epoch 650/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 14.3678 - val_loss: 18.2611\n",
      "Epoch 651/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 14.2387 - val_loss: 17.8236\n",
      "Epoch 652/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.2576 - val_loss: 17.9677\n",
      "Epoch 653/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.3389 - val_loss: 17.8702\n",
      "Epoch 654/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.3553 - val_loss: 17.9116\n",
      "Epoch 655/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.2305 - val_loss: 17.7942\n",
      "Epoch 656/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.2621 - val_loss: 17.7804\n",
      "Epoch 657/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.3037 - val_loss: 17.8093\n",
      "Epoch 658/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.2609 - val_loss: 17.7724\n",
      "Epoch 659/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.2824 - val_loss: 17.8171\n",
      "Epoch 660/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.3037 - val_loss: 17.8309\n",
      "Epoch 661/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.2613 - val_loss: 17.8109\n",
      "Epoch 662/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.3194 - val_loss: 17.9517\n",
      "Epoch 663/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.3296 - val_loss: 17.8252\n",
      "Epoch 664/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 14.2900 - val_loss: 17.9944\n",
      "Epoch 665/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 14.3402 - val_loss: 18.2282\n",
      "Epoch 666/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.2687 - val_loss: 17.9649\n",
      "Epoch 667/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.2923 - val_loss: 17.8863\n",
      "Epoch 668/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.3229 - val_loss: 17.8919\n",
      "Epoch 669/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.4960 - val_loss: 17.7897\n",
      "Epoch 670/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.3124 - val_loss: 18.1188\n",
      "Epoch 671/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.2987 - val_loss: 17.8238\n",
      "Epoch 672/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.2801 - val_loss: 17.9292\n",
      "Epoch 673/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.3104 - val_loss: 18.1450\n",
      "Epoch 674/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.3035 - val_loss: 18.0976\n",
      "Epoch 675/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.2502 - val_loss: 17.7994\n",
      "Epoch 676/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.5119 - val_loss: 18.2132\n",
      "Epoch 677/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.2776 - val_loss: 17.9587\n",
      "Epoch 678/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.3159 - val_loss: 17.8402\n",
      "Epoch 679/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.2201 - val_loss: 17.8244\n",
      "Epoch 680/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.2201 - val_loss: 17.9591\n",
      "Epoch 681/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.3244 - val_loss: 17.7892\n",
      "Epoch 682/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.3023 - val_loss: 18.0265\n",
      "Epoch 683/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.2884 - val_loss: 18.1229\n",
      "Epoch 684/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.2860 - val_loss: 17.9250\n",
      "Epoch 685/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.2643 - val_loss: 17.8154\n",
      "Epoch 686/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.3085 - val_loss: 17.7449\n",
      "Epoch 687/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.3193 - val_loss: 17.9204\n",
      "Epoch 688/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.2819 - val_loss: 17.9401\n",
      "Epoch 689/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.3284 - val_loss: 17.8655\n",
      "Epoch 690/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.2234 - val_loss: 17.8865\n",
      "Epoch 691/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.3139 - val_loss: 18.3109\n",
      "Epoch 692/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.2929 - val_loss: 18.0126\n",
      "Epoch 693/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.2152 - val_loss: 17.7640\n",
      "Epoch 694/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 14.2679 - val_loss: 17.9259\n",
      "Epoch 695/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.2910 - val_loss: 17.9793\n",
      "Epoch 696/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.3141 - val_loss: 18.1043\n",
      "Epoch 697/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 14.4073 - val_loss: 17.8799\n",
      "Epoch 698/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.2645 - val_loss: 18.6173\n",
      "Epoch 699/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.3734 - val_loss: 17.8802\n",
      "Epoch 700/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.2792 - val_loss: 18.0033\n",
      "Epoch 701/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.2529 - val_loss: 18.1947\n",
      "Epoch 702/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.2254 - val_loss: 17.9287\n",
      "Epoch 703/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.2592 - val_loss: 17.8937\n",
      "Epoch 704/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.2745 - val_loss: 17.8747\n",
      "Epoch 705/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.2165 - val_loss: 17.9396\n",
      "Epoch 706/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.3459 - val_loss: 17.7900\n",
      "Epoch 707/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.3904 - val_loss: 18.1985\n",
      "Epoch 708/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 14.2808 - val_loss: 17.9273\n",
      "Epoch 709/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 14.2523 - val_loss: 17.8491\n",
      "Epoch 710/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 14.3425 - val_loss: 17.9628\n",
      "Epoch 711/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 14.2953 - val_loss: 17.8091\n",
      "Epoch 712/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 14.1938 - val_loss: 17.9137\n",
      "Epoch 713/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 14.3044 - val_loss: 18.0693\n",
      "Epoch 714/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 14.3871 - val_loss: 18.1869\n",
      "Epoch 715/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 14.1694 - val_loss: 17.8031\n",
      "Epoch 716/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 14.3523 - val_loss: 17.8826\n",
      "Epoch 717/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.2506 - val_loss: 17.8645\n",
      "Epoch 718/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.4294 - val_loss: 17.9941\n",
      "Epoch 719/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.4803 - val_loss: 17.9292\n",
      "Epoch 720/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.4357 - val_loss: 18.0509\n",
      "Epoch 721/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.4158 - val_loss: 17.8490\n",
      "Epoch 722/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.3748 - val_loss: 17.8098\n",
      "Epoch 723/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.2277 - val_loss: 17.8841\n",
      "Epoch 724/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.3399 - val_loss: 17.9674\n",
      "Epoch 725/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.2238 - val_loss: 17.8537\n",
      "Epoch 726/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.3050 - val_loss: 18.2205\n",
      "Epoch 727/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.3444 - val_loss: 17.8109\n",
      "Epoch 728/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.3354 - val_loss: 18.0123\n",
      "Epoch 729/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 14.3088 - val_loss: 18.0077\n",
      "Epoch 730/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.3073 - val_loss: 17.8940\n",
      "Epoch 731/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.3201 - val_loss: 17.9649\n",
      "Epoch 732/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 14.2707 - val_loss: 17.9582\n",
      "Epoch 733/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.1713 - val_loss: 18.0601\n",
      "Epoch 734/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.3165 - val_loss: 18.3175\n",
      "Epoch 735/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 14.2574 - val_loss: 17.9454\n",
      "Epoch 736/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.4305 - val_loss: 18.1032\n",
      "Epoch 737/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.3267 - val_loss: 17.8947\n",
      "Epoch 738/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 14.2447 - val_loss: 17.9678\n",
      "Epoch 739/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.2115 - val_loss: 18.0537\n",
      "Epoch 740/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 14.1792 - val_loss: 18.0805\n",
      "Epoch 741/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.2134 - val_loss: 17.9295\n",
      "Epoch 742/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.2563 - val_loss: 17.9089\n",
      "Epoch 743/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.5724 - val_loss: 18.1773\n",
      "Epoch 744/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.3243 - val_loss: 17.9344\n",
      "Epoch 745/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.1385 - val_loss: 18.0763\n",
      "Epoch 746/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.1126 - val_loss: 17.8860\n",
      "Epoch 747/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.0654 - val_loss: 17.9250\n",
      "Epoch 748/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.2189 - val_loss: 18.0263\n",
      "Epoch 749/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.2683 - val_loss: 17.9445\n",
      "Epoch 750/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.1793 - val_loss: 17.5945\n",
      "Epoch 751/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.1730 - val_loss: 17.7234\n",
      "Epoch 752/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.1548 - val_loss: 17.8074\n",
      "Epoch 753/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.1368 - val_loss: 17.8211\n",
      "Epoch 754/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 14.0831 - val_loss: 17.5375\n",
      "Epoch 755/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.0823 - val_loss: 17.7897\n",
      "Epoch 756/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.0799 - val_loss: 17.7361\n",
      "Epoch 757/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.0610 - val_loss: 17.5140\n",
      "Epoch 758/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.2197 - val_loss: 17.5798\n",
      "Epoch 759/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.1400 - val_loss: 17.7162\n",
      "Epoch 760/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.0994 - val_loss: 17.8403\n",
      "Epoch 761/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.1434 - val_loss: 18.0094\n",
      "Epoch 762/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.1105 - val_loss: 17.9672\n",
      "Epoch 763/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.0014 - val_loss: 17.6617\n",
      "Epoch 764/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.0533 - val_loss: 17.9485\n",
      "Epoch 765/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.1069 - val_loss: 17.9007\n",
      "Epoch 766/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.3070 - val_loss: 17.6452\n",
      "Epoch 767/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.1322 - val_loss: 17.6959\n",
      "Epoch 768/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.0531 - val_loss: 17.5602\n",
      "Epoch 769/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.9355 - val_loss: 18.2838\n",
      "Epoch 770/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 14.1080 - val_loss: 17.7512\n",
      "Epoch 771/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.1028 - val_loss: 17.9464\n",
      "Epoch 772/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.9937 - val_loss: 18.1687\n",
      "Epoch 773/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 13.9448 - val_loss: 17.6409\n",
      "Epoch 774/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.1353 - val_loss: 17.7658\n",
      "Epoch 775/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.9316 - val_loss: 17.7889\n",
      "Epoch 776/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.9330 - val_loss: 17.8483\n",
      "Epoch 777/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.0848 - val_loss: 17.9017\n",
      "Epoch 778/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.2322 - val_loss: 17.8216\n",
      "Epoch 779/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.0888 - val_loss: 18.1331\n",
      "Epoch 780/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.1411 - val_loss: 18.1959\n",
      "Epoch 781/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.9950 - val_loss: 18.1988\n",
      "Epoch 782/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.0539 - val_loss: 18.0418\n",
      "Epoch 783/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.9920 - val_loss: 17.6355\n",
      "Epoch 784/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 13.9891 - val_loss: 17.7461\n",
      "Epoch 785/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 13.9544 - val_loss: 18.0854\n",
      "Epoch 786/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 14.0531 - val_loss: 17.7401\n",
      "Epoch 787/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.3013 - val_loss: 17.4627\n",
      "Epoch 788/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 14.0720 - val_loss: 18.0507\n",
      "Epoch 789/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.2343 - val_loss: 17.7645\n",
      "Epoch 790/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.0847 - val_loss: 17.6523\n",
      "Epoch 791/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.0746 - val_loss: 17.4642\n",
      "Epoch 792/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 14.0582 - val_loss: 17.5413\n",
      "Epoch 793/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.1590 - val_loss: 17.6066\n",
      "Epoch 794/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.0569 - val_loss: 17.5946\n",
      "Epoch 795/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.9808 - val_loss: 17.5410\n",
      "Epoch 796/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 14.0467 - val_loss: 17.6472\n",
      "Epoch 797/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.0165 - val_loss: 17.6887\n",
      "Epoch 798/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.0481 - val_loss: 17.6439\n",
      "Epoch 799/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 14.0173 - val_loss: 17.6347\n",
      "Epoch 800/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 14.1668 - val_loss: 17.6133\n",
      "Epoch 801/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.9754 - val_loss: 17.7091\n",
      "Epoch 802/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.9705 - val_loss: 17.5965\n",
      "Epoch 803/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.0466 - val_loss: 17.7616\n",
      "Epoch 804/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 14.0367 - val_loss: 18.0896\n",
      "Epoch 805/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 15.34 - 0s 92us/step - loss: 14.0300 - val_loss: 17.9712\n",
      "Epoch 806/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.0354 - val_loss: 18.1474\n",
      "Epoch 807/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.1957 - val_loss: 17.9656\n",
      "Epoch 808/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.0315 - val_loss: 17.6422\n",
      "Epoch 809/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.2293 - val_loss: 18.3456\n",
      "Epoch 810/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.2647 - val_loss: 17.9048\n",
      "Epoch 811/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.1057 - val_loss: 18.3559\n",
      "Epoch 812/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 14.0217 - val_loss: 17.7484\n",
      "Epoch 813/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.0571 - val_loss: 18.0854\n",
      "Epoch 814/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.3220 - val_loss: 18.0936\n",
      "Epoch 815/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.2246 - val_loss: 17.6525\n",
      "Epoch 816/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.0522 - val_loss: 18.1839\n",
      "Epoch 817/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.0627 - val_loss: 17.7587\n",
      "Epoch 818/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.0846 - val_loss: 17.6462\n",
      "Epoch 819/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.9520 - val_loss: 17.8040\n",
      "Epoch 820/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.9228 - val_loss: 18.1169\n",
      "Epoch 821/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.0912 - val_loss: 18.1274\n",
      "Epoch 822/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.9115 - val_loss: 17.7277\n",
      "Epoch 823/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.9853 - val_loss: 18.0188\n",
      "Epoch 824/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.9795 - val_loss: 17.8223\n",
      "Epoch 825/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.9695 - val_loss: 18.0706\n",
      "Epoch 826/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.9961 - val_loss: 17.6690\n",
      "Epoch 827/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.2514 - val_loss: 17.6482\n",
      "Epoch 828/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.0394 - val_loss: 17.6777\n",
      "Epoch 829/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 14.0085 - val_loss: 18.1193\n",
      "Epoch 830/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.0590 - val_loss: 17.5865\n",
      "Epoch 831/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.0379 - val_loss: 17.6857\n",
      "Epoch 832/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.0153 - val_loss: 17.9156\n",
      "Epoch 833/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.2163 - val_loss: 17.7515\n",
      "Epoch 834/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 14.0399 - val_loss: 18.1036\n",
      "Epoch 835/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.8958 - val_loss: 17.8877\n",
      "Epoch 836/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.1202 - val_loss: 17.6328\n",
      "Epoch 837/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.9959 - val_loss: 17.6386\n",
      "Epoch 838/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 14.0199 - val_loss: 17.5912\n",
      "Epoch 839/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.1226 - val_loss: 17.7445\n",
      "Epoch 840/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.0870 - val_loss: 17.8651\n",
      "Epoch 841/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 14.0887 - val_loss: 17.6133\n",
      "Epoch 842/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.9203 - val_loss: 17.7707\n",
      "Epoch 843/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 13.9669 - val_loss: 17.7231\n",
      "Epoch 844/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 14.1101 - val_loss: 17.6869\n",
      "Epoch 845/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.9665 - val_loss: 17.9199\n",
      "Epoch 846/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.9288 - val_loss: 17.6755\n",
      "Epoch 847/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.9778 - val_loss: 17.7276\n",
      "Epoch 848/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.9897 - val_loss: 17.9491\n",
      "Epoch 849/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.9600 - val_loss: 17.8016\n",
      "Epoch 850/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 13.8889 - val_loss: 17.7659\n",
      "Epoch 851/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 14.1372 - val_loss: 17.7174\n",
      "Epoch 852/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.9814 - val_loss: 18.2179\n",
      "Epoch 853/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.9955 - val_loss: 17.6877\n",
      "Epoch 854/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 13.9307 - val_loss: 17.9193\n",
      "Epoch 855/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.9228 - val_loss: 17.9453\n",
      "Epoch 856/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.9580 - val_loss: 17.8138\n",
      "Epoch 857/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.9812 - val_loss: 18.1798\n",
      "Epoch 858/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 13.8863 - val_loss: 17.6827\n",
      "Epoch 859/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 13.9208 - val_loss: 17.6282\n",
      "Epoch 860/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.9352 - val_loss: 17.7920\n",
      "Epoch 861/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 13.9592 - val_loss: 17.8572\n",
      "Epoch 862/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.0652 - val_loss: 17.8729\n",
      "Epoch 863/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.9460 - val_loss: 17.7886\n",
      "Epoch 864/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.9964 - val_loss: 17.9997\n",
      "Epoch 865/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.9788 - val_loss: 17.7275\n",
      "Epoch 866/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.9220 - val_loss: 17.6626\n",
      "Epoch 867/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 13.9104 - val_loss: 17.7225\n",
      "Epoch 868/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.9449 - val_loss: 17.5925\n",
      "Epoch 869/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.9265 - val_loss: 17.7862\n",
      "Epoch 870/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 13.9521 - val_loss: 17.6308\n",
      "Epoch 871/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 13.9150 - val_loss: 17.9543\n",
      "Epoch 872/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.9473 - val_loss: 17.6586\n",
      "Epoch 873/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.9298 - val_loss: 18.3738\n",
      "Epoch 874/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 14.1933 - val_loss: 17.7672\n",
      "Epoch 875/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 14.0718 - val_loss: 17.8746\n",
      "Epoch 876/1000\n",
      "1052/1052 [==============================] - 0s 115us/step - loss: 14.0823 - val_loss: 17.8464\n",
      "Epoch 877/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 13.9544 - val_loss: 17.6492\n",
      "Epoch 878/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 13.9046 - val_loss: 17.6118\n",
      "Epoch 879/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 13.8991 - val_loss: 17.7149\n",
      "Epoch 880/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 13.9393 - val_loss: 17.6621\n",
      "Epoch 881/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 13.9189 - val_loss: 17.6096\n",
      "Epoch 882/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 13.9388 - val_loss: 17.7951\n",
      "Epoch 883/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 14.0018 - val_loss: 17.6954\n",
      "Epoch 884/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 13.9054 - val_loss: 17.8179\n",
      "Epoch 885/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.0074 - val_loss: 18.5116\n",
      "Epoch 886/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.2050 - val_loss: 18.1706\n",
      "Epoch 887/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.1308 - val_loss: 17.7992\n",
      "Epoch 888/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.0656 - val_loss: 17.7587\n",
      "Epoch 889/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.1876 - val_loss: 18.1849\n",
      "Epoch 890/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 14.1329 - val_loss: 17.8820\n",
      "Epoch 891/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 93us/step - loss: 13.9607 - val_loss: 17.6913\n",
      "Epoch 892/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.0513 - val_loss: 18.1075\n",
      "Epoch 893/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 13.21 - 0s 84us/step - loss: 13.9066 - val_loss: 17.6713\n",
      "Epoch 894/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.2318 - val_loss: 17.7872\n",
      "Epoch 895/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.0645 - val_loss: 17.8295\n",
      "Epoch 896/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.0102 - val_loss: 17.7555\n",
      "Epoch 897/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.9002 - val_loss: 17.6605\n",
      "Epoch 898/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.0552 - val_loss: 17.8348\n",
      "Epoch 899/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.8586 - val_loss: 17.6126\n",
      "Epoch 900/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.8909 - val_loss: 17.6236\n",
      "Epoch 901/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.9698 - val_loss: 17.4786\n",
      "Epoch 902/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.8804 - val_loss: 17.6976\n",
      "Epoch 903/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 13.8735 - val_loss: 17.6120\n",
      "Epoch 904/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.8737 - val_loss: 17.6303\n",
      "Epoch 905/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.9368 - val_loss: 17.5784\n",
      "Epoch 906/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.9809 - val_loss: 18.0421\n",
      "Epoch 907/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.0976 - val_loss: 17.7703\n",
      "Epoch 908/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.0943 - val_loss: 17.7276\n",
      "Epoch 909/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.9636 - val_loss: 17.8758\n",
      "Epoch 910/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.9088 - val_loss: 17.7186\n",
      "Epoch 911/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.9529 - val_loss: 17.6311\n",
      "Epoch 912/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.0272 - val_loss: 17.4878\n",
      "Epoch 913/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.0374 - val_loss: 17.9875\n",
      "Epoch 914/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.0453 - val_loss: 17.5884\n",
      "Epoch 915/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.9109 - val_loss: 17.5657\n",
      "Epoch 916/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.9678 - val_loss: 17.6964\n",
      "Epoch 917/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 13.8974 - val_loss: 17.5746\n",
      "Epoch 918/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 13.9545 - val_loss: 17.7987\n",
      "Epoch 919/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.9487 - val_loss: 18.2074\n",
      "Epoch 920/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.8981 - val_loss: 18.1481\n",
      "Epoch 921/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.0020 - val_loss: 17.7452\n",
      "Epoch 922/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.2579 - val_loss: 17.6472\n",
      "Epoch 923/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.0648 - val_loss: 17.5733\n",
      "Epoch 924/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 14.0434 - val_loss: 17.6016\n",
      "Epoch 925/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.0350 - val_loss: 17.7726\n",
      "Epoch 926/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 13.9916 - val_loss: 17.7494\n",
      "Epoch 927/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.9147 - val_loss: 17.6182\n",
      "Epoch 928/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.8824 - val_loss: 17.5854\n",
      "Epoch 929/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.8964 - val_loss: 17.6672\n",
      "Epoch 930/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 13.8696 - val_loss: 17.8756\n",
      "Epoch 931/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 13.8888 - val_loss: 17.8021\n",
      "Epoch 932/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 13.8462 - val_loss: 17.5519\n",
      "Epoch 933/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.8243 - val_loss: 17.6547\n",
      "Epoch 934/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 13.9162 - val_loss: 17.8392\n",
      "Epoch 935/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.1059 - val_loss: 17.7228\n",
      "Epoch 936/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.9583 - val_loss: 17.7110\n",
      "Epoch 937/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 13.9292 - val_loss: 17.5294\n",
      "Epoch 938/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 13.8303 - val_loss: 17.7339\n",
      "Epoch 939/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.9187 - val_loss: 18.0636\n",
      "Epoch 940/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 13.8448 - val_loss: 17.5412\n",
      "Epoch 941/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.8911 - val_loss: 17.6561\n",
      "Epoch 942/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.8642 - val_loss: 17.5824\n",
      "Epoch 943/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.7980 - val_loss: 17.7826\n",
      "Epoch 944/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 13.9549 - val_loss: 17.8062\n",
      "Epoch 945/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 13.9251 - val_loss: 17.6174\n",
      "Epoch 946/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 13.7873 - val_loss: 17.8142\n",
      "Epoch 947/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 13.8383 - val_loss: 17.6709\n",
      "Epoch 948/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 13.9699 - val_loss: 18.2215\n",
      "Epoch 949/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.0246 - val_loss: 18.0696\n",
      "Epoch 950/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.3128 - val_loss: 17.7067\n",
      "Epoch 951/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.4760 - val_loss: 17.5616\n",
      "Epoch 952/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.0648 - val_loss: 17.5206\n",
      "Epoch 953/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.8882 - val_loss: 17.6894\n",
      "Epoch 954/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.8546 - val_loss: 17.5004\n",
      "Epoch 955/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 13.8936 - val_loss: 17.5316\n",
      "Epoch 956/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 13.9285 - val_loss: 17.5686\n",
      "Epoch 957/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.0927 - val_loss: 17.8183\n",
      "Epoch 958/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 13.9268 - val_loss: 17.7604\n",
      "Epoch 959/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.0068 - val_loss: 17.7570\n",
      "Epoch 960/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.8540 - val_loss: 17.4893\n",
      "Epoch 961/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 13.9901 - val_loss: 17.7992\n",
      "Epoch 962/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 13.9376 - val_loss: 17.7348\n",
      "Epoch 963/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 13.8713 - val_loss: 17.5495\n",
      "Epoch 964/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.8550 - val_loss: 17.8819\n",
      "Epoch 965/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 13.8105 - val_loss: 17.5516\n",
      "Epoch 966/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.8348 - val_loss: 17.6061\n",
      "Epoch 967/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.8209 - val_loss: 17.6672\n",
      "Epoch 968/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.9314 - val_loss: 17.5682\n",
      "Epoch 969/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 13.8536 - val_loss: 17.6277\n",
      "Epoch 970/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.9689 - val_loss: 17.6030\n",
      "Epoch 971/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.8419 - val_loss: 17.7268\n",
      "Epoch 972/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 14.0495 - val_loss: 17.7716\n",
      "Epoch 973/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.0606 - val_loss: 17.6107\n",
      "Epoch 974/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.9713 - val_loss: 18.0651\n",
      "Epoch 975/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.8594 - val_loss: 17.5029\n",
      "Epoch 976/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 13.8811 - val_loss: 17.7003\n",
      "Epoch 977/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 13.9527 - val_loss: 18.3388\n",
      "Epoch 978/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.8138 - val_loss: 17.9299\n",
      "Epoch 979/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.7657 - val_loss: 17.7612\n",
      "Epoch 980/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.9006 - val_loss: 17.7171\n",
      "Epoch 981/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.8729 - val_loss: 17.7776\n",
      "Epoch 982/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.8404 - val_loss: 18.1712\n",
      "Epoch 983/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.8762 - val_loss: 17.8086\n",
      "Epoch 984/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 13.8715 - val_loss: 17.5907\n",
      "Epoch 985/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 13.8825 - val_loss: 17.6375\n",
      "Epoch 986/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.8698 - val_loss: 17.8516\n",
      "Epoch 987/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.9135 - val_loss: 18.1651\n",
      "Epoch 988/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.1821 - val_loss: 17.7471\n",
      "Epoch 989/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.9365 - val_loss: 18.3850\n",
      "Epoch 990/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.9295 - val_loss: 17.5359\n",
      "Epoch 991/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.8985 - val_loss: 17.7513\n",
      "Epoch 992/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 13.8289 - val_loss: 17.8085\n",
      "Epoch 993/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 13.8969 - val_loss: 17.6641\n",
      "Epoch 994/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.8463 - val_loss: 17.7828\n",
      "Epoch 995/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.9923 - val_loss: 17.9216\n",
      "Epoch 996/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.9473 - val_loss: 17.7439\n",
      "Epoch 997/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.9673 - val_loss: 17.8841\n",
      "Epoch 998/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.0048 - val_loss: 17.9873\n",
      "Epoch 999/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.9350 - val_loss: 17.4752\n",
      "Epoch 1000/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.8877 - val_loss: 17.7733\n",
      "15.333703783761084\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.2129882 , -1.3916765 , -2.498589  , -4.306378  , -0.28662115],\n",
       "        [-0.25465715, -2.1115909 , -0.76168764, -0.14669733, -1.6031045 ],\n",
       "        [ 1.2049081 ,  0.11068133, -3.6935475 , -0.05172126, -3.457383  ],\n",
       "        [-0.52491426,  0.09669611, -0.11740874,  0.5195677 ,  0.76185924],\n",
       "        [-1.0396574 , -0.33236754, -0.8500821 , -0.23586908,  0.74254096]],\n",
       "       dtype=float32),\n",
       " array([ 0.599656 ,  1.8336166,  0.454187 , -0.6513071, -0.8254293],\n",
       "       dtype=float32),\n",
       " array([[ 17.965073  ,  -1.4654329 ,   0.4134388 ,   1.4050494 ,\n",
       "           2.1075644 ,   0.3005464 ,  -1.0886469 ,  15.2600765 ,\n",
       "           1.3145143 ,   3.3079073 ],\n",
       "        [  6.8659935 ,  -1.0694307 ,  -1.5926831 ,   9.92844   ,\n",
       "           0.7976873 ,  -0.41765836,  -0.7821657 ,   6.295135  ,\n",
       "           0.9926483 ,  -1.0106857 ],\n",
       "        [  7.802627  , -12.214326  ,  -4.57506   ,   1.6078452 ,\n",
       "          13.531264  ,  -0.20133321,  -8.968804  ,   5.4872236 ,\n",
       "          11.441814  ,  10.95442   ],\n",
       "        [  0.04703061,   0.8224721 ,  -0.6403113 ,  25.477377  ,\n",
       "          -0.6928611 ,  -0.45618334,   0.4877272 ,   1.194553  ,\n",
       "          -0.7261391 ,   0.04395696],\n",
       "        [ -0.06412428, -15.696207  ,  -0.24908897,  13.446137  ,\n",
       "          15.595139  ,  -0.38260373, -10.516255  ,  -0.0422694 ,\n",
       "          14.473506  ,   0.13909651]], dtype=float32),\n",
       " array([ 1.3725438, -2.4157085, -2.0180988,  0.8548336,  2.2084692,\n",
       "         0.5034975, -3.586273 ,  2.728173 ,  3.0624251,  2.1253557],\n",
       "       dtype=float32),\n",
       " array([[ 11.875983],\n",
       "        [-12.443515],\n",
       "        [-11.736508],\n",
       "        [ 11.972754],\n",
       "        [ 12.165944],\n",
       "        [ -9.872052],\n",
       "        [-12.184381],\n",
       "        [ 12.007314],\n",
       "        [ 12.178444],\n",
       "        [ 11.820725]], dtype=float32),\n",
       " array([11.391776], dtype=float32)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_airfoil, history_airfoil, evaluate_airfoil=NN_model_structure_regression_tanh(X_train_airfoil, X_val_airfoil, Y_train_airfoil, Y_val_airfoil, adam2, 32, 1000, x_test_airfoil, y_test_airfoil)\n",
    "model_airfoil.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_airfoil.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_airfoil_tanh_4th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 5)                 40        \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 111\n",
      "Trainable params: 111\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 274 samples, validate on 59 samples\n",
      "Epoch 1/1000\n",
      "274/274 [==============================] - 0s 684us/step - loss: 527.7655 - val_loss: 323.8174\n",
      "Epoch 2/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 205.3354 - val_loss: 55.0332\n",
      "Epoch 3/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 66.0818 - val_loss: 41.6964\n",
      "Epoch 4/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 32.4761 - val_loss: 29.6001\n",
      "Epoch 5/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 26.9797 - val_loss: 23.7414\n",
      "Epoch 6/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 23.9372 - val_loss: 20.1111\n",
      "Epoch 7/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 21.7482 - val_loss: 17.8597\n",
      "Epoch 8/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 19.5785 - val_loss: 17.1237\n",
      "Epoch 9/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 18.4506 - val_loss: 16.0184\n",
      "Epoch 10/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 17.7566 - val_loss: 14.7416\n",
      "Epoch 11/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 16.3598 - val_loss: 13.7965\n",
      "Epoch 12/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 15.0443 - val_loss: 12.6098\n",
      "Epoch 13/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 13.9057 - val_loss: 12.2525\n",
      "Epoch 14/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 12.5173 - val_loss: 12.6628\n",
      "Epoch 15/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 11.2527 - val_loss: 12.2344\n",
      "Epoch 16/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 10.2496 - val_loss: 12.2332\n",
      "Epoch 17/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 9.5205 - val_loss: 11.4947\n",
      "Epoch 18/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 9.0770 - val_loss: 11.7356\n",
      "Epoch 19/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 8.8531 - val_loss: 11.4720\n",
      "Epoch 20/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 8.5576 - val_loss: 10.3699\n",
      "Epoch 21/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 8.1987 - val_loss: 10.3598\n",
      "Epoch 22/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 8.3857 - val_loss: 10.5104\n",
      "Epoch 23/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 8.2688 - val_loss: 11.0494\n",
      "Epoch 24/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 7.9731 - val_loss: 10.3215\n",
      "Epoch 25/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.9071 - val_loss: 9.7685\n",
      "Epoch 26/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.5753 - val_loss: 10.3472\n",
      "Epoch 27/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.3921 - val_loss: 10.3140\n",
      "Epoch 28/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.5364 - val_loss: 10.4890\n",
      "Epoch 29/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.4073 - val_loss: 9.9288\n",
      "Epoch 30/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.3766 - val_loss: 10.4935\n",
      "Epoch 31/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 7.8869 - val_loss: 10.2343\n",
      "Epoch 32/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.6371 - val_loss: 10.4421\n",
      "Epoch 33/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.2794 - val_loss: 10.2909\n",
      "Epoch 34/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.1914 - val_loss: 10.3135\n",
      "Epoch 35/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.1798 - val_loss: 10.8418\n",
      "Epoch 36/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.2372 - val_loss: 10.1950\n",
      "Epoch 37/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.2971 - val_loss: 10.8445\n",
      "Epoch 38/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0714 - val_loss: 10.4867\n",
      "Epoch 39/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.2790 - val_loss: 10.7446\n",
      "Epoch 40/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 7.2266 - val_loss: 10.3232\n",
      "Epoch 41/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0755 - val_loss: 10.0930\n",
      "Epoch 42/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.0490 - val_loss: 10.3847\n",
      "Epoch 43/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 7.0389 - val_loss: 10.0833\n",
      "Epoch 44/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 7.0093 - val_loss: 10.0806\n",
      "Epoch 45/1000\n",
      "274/274 [==============================] - 0s 135us/step - loss: 7.3565 - val_loss: 10.1039\n",
      "Epoch 46/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 7.2972 - val_loss: 10.5373\n",
      "Epoch 47/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1540 - val_loss: 10.1107\n",
      "Epoch 48/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.7920 - val_loss: 10.3852\n",
      "Epoch 49/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.2684 - val_loss: 9.9122\n",
      "Epoch 50/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1989 - val_loss: 10.2310\n",
      "Epoch 51/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.0355 - val_loss: 9.9947\n",
      "Epoch 52/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.9510 - val_loss: 10.2747\n",
      "Epoch 53/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 7.0339 - val_loss: 10.1933\n",
      "Epoch 54/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0389 - val_loss: 9.8123\n",
      "Epoch 55/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.1959 - val_loss: 9.8404\n",
      "Epoch 56/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.9473 - val_loss: 10.0585\n",
      "Epoch 57/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9219 - val_loss: 10.0730\n",
      "Epoch 58/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.0297 - val_loss: 10.2384\n",
      "Epoch 59/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1590 - val_loss: 9.7998\n",
      "Epoch 60/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9003 - val_loss: 9.8327\n",
      "Epoch 61/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.1392 - val_loss: 9.9827\n",
      "Epoch 62/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1416 - val_loss: 9.6569\n",
      "Epoch 63/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9624 - val_loss: 9.8061\n",
      "Epoch 64/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.9064 - val_loss: 9.9338\n",
      "Epoch 65/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8620 - val_loss: 9.8573\n",
      "Epoch 66/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.0485 - val_loss: 9.7122\n",
      "Epoch 67/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9501 - val_loss: 9.7103\n",
      "Epoch 68/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 6.8844 - val_loss: 9.7785\n",
      "Epoch 69/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8792 - val_loss: 9.7659\n",
      "Epoch 70/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7891 - val_loss: 10.0221\n",
      "Epoch 71/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9409 - val_loss: 9.7190\n",
      "Epoch 72/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.8094 - val_loss: 9.8870\n",
      "Epoch 73/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.0282 - val_loss: 9.9163\n",
      "Epoch 74/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9788 - val_loss: 9.6680\n",
      "Epoch 75/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8553 - val_loss: 9.5919\n",
      "Epoch 76/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0528 - val_loss: 9.6825\n",
      "Epoch 77/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.9669 - val_loss: 9.8169\n",
      "Epoch 78/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9917 - val_loss: 9.6834\n",
      "Epoch 79/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8581 - val_loss: 9.6790\n",
      "Epoch 80/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7912 - val_loss: 9.9559\n",
      "Epoch 81/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0581 - val_loss: 9.9176\n",
      "Epoch 82/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9113 - val_loss: 10.3058\n",
      "Epoch 83/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0463 - val_loss: 9.9573\n",
      "Epoch 84/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.8511 - val_loss: 9.7662\n",
      "Epoch 85/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8140 - val_loss: 9.5677\n",
      "Epoch 86/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9245 - val_loss: 9.5007\n",
      "Epoch 87/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8714 - val_loss: 9.8495\n",
      "Epoch 88/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8672 - val_loss: 9.7467\n",
      "Epoch 89/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7353 - val_loss: 9.7747\n",
      "Epoch 90/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7235 - val_loss: 9.7088\n",
      "Epoch 91/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0698 - val_loss: 9.8882\n",
      "Epoch 92/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0636 - val_loss: 9.4578\n",
      "Epoch 93/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.2719 - val_loss: 9.5274\n",
      "Epoch 94/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7622 - val_loss: 9.4502\n",
      "Epoch 95/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.7346 - val_loss: 9.5844\n",
      "Epoch 96/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9074 - val_loss: 9.6235\n",
      "Epoch 97/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.8351 - val_loss: 9.6321\n",
      "Epoch 98/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7482 - val_loss: 9.6145\n",
      "Epoch 99/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 6.7504 - val_loss: 9.5137\n",
      "Epoch 100/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.8308 - val_loss: 9.5670\n",
      "Epoch 101/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7990 - val_loss: 9.5190\n",
      "Epoch 102/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7113 - val_loss: 9.6671\n",
      "Epoch 103/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7537 - val_loss: 9.6217\n",
      "Epoch 104/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7677 - val_loss: 9.7213\n",
      "Epoch 105/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7297 - val_loss: 9.4359\n",
      "Epoch 106/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7583 - val_loss: 9.4299\n",
      "Epoch 107/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.8446 - val_loss: 9.5950\n",
      "Epoch 108/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.9565 - val_loss: 9.5154\n",
      "Epoch 109/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.9251 - val_loss: 9.4579\n",
      "Epoch 110/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.7965 - val_loss: 9.4659\n",
      "Epoch 111/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7402 - val_loss: 9.4462\n",
      "Epoch 112/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.7606 - val_loss: 9.5428\n",
      "Epoch 113/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 7.0734 - val_loss: 9.5299\n",
      "Epoch 114/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.7724 - val_loss: 9.6124\n",
      "Epoch 115/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.8843 - val_loss: 9.5635\n",
      "Epoch 116/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 6.5925 - val_loss: 9.8657\n",
      "Epoch 117/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.7255 - val_loss: 9.5589\n",
      "Epoch 118/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 6.8394 - val_loss: 9.7312\n",
      "Epoch 119/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.6558 - val_loss: 9.5484\n",
      "Epoch 120/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6627 - val_loss: 9.6194\n",
      "Epoch 121/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.7689 - val_loss: 9.5789\n",
      "Epoch 122/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7069 - val_loss: 9.5518\n",
      "Epoch 123/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.8039 - val_loss: 9.4449\n",
      "Epoch 124/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.9725 - val_loss: 9.5072\n",
      "Epoch 125/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.8224 - val_loss: 9.3875\n",
      "Epoch 126/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7227 - val_loss: 9.3873\n",
      "Epoch 127/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6992 - val_loss: 9.4561\n",
      "Epoch 128/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6043 - val_loss: 9.5538\n",
      "Epoch 129/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.8463 - val_loss: 9.4703\n",
      "Epoch 130/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6743 - val_loss: 9.4567\n",
      "Epoch 131/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.7047 - val_loss: 9.4466\n",
      "Epoch 132/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.7889 - val_loss: 9.5078\n",
      "Epoch 133/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.8790 - val_loss: 9.4917\n",
      "Epoch 134/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.7246 - val_loss: 9.5338\n",
      "Epoch 135/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6930 - val_loss: 9.4507\n",
      "Epoch 136/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.6238 - val_loss: 9.6970\n",
      "Epoch 137/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6386 - val_loss: 9.3829\n",
      "Epoch 138/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6943 - val_loss: 9.5450\n",
      "Epoch 139/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1441 - val_loss: 9.5314\n",
      "Epoch 140/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8075 - val_loss: 9.4270\n",
      "Epoch 141/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0544 - val_loss: 9.6524\n",
      "Epoch 142/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6836 - val_loss: 9.4596\n",
      "Epoch 143/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.9173 - val_loss: 9.5876\n",
      "Epoch 144/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8041 - val_loss: 9.4335\n",
      "Epoch 145/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.6401 - val_loss: 9.6131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 146/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.6007 - val_loss: 9.4913\n",
      "Epoch 147/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.7114 - val_loss: 9.5248\n",
      "Epoch 148/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.6659 - val_loss: 9.3778\n",
      "Epoch 149/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.6050 - val_loss: 9.6321\n",
      "Epoch 150/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.5404 - val_loss: 9.2799\n",
      "Epoch 151/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5958 - val_loss: 9.5428\n",
      "Epoch 152/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6216 - val_loss: 9.2847\n",
      "Epoch 153/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5767 - val_loss: 9.5678\n",
      "Epoch 154/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.9115 - val_loss: 9.4598\n",
      "Epoch 155/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.6695 - val_loss: 9.5600\n",
      "Epoch 156/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6352 - val_loss: 9.3907\n",
      "Epoch 157/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6022 - val_loss: 9.4899\n",
      "Epoch 158/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 6.6839 - val_loss: 9.4318\n",
      "Epoch 159/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.5647 - val_loss: 9.5066\n",
      "Epoch 160/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.6178 - val_loss: 9.4007\n",
      "Epoch 161/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5636 - val_loss: 9.3714\n",
      "Epoch 162/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5352 - val_loss: 9.2900\n",
      "Epoch 163/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.5836 - val_loss: 9.4474\n",
      "Epoch 164/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 6.5463 - val_loss: 9.3854\n",
      "Epoch 165/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 6.8559 - val_loss: 9.6367\n",
      "Epoch 166/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.8260 - val_loss: 9.5856\n",
      "Epoch 167/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6512 - val_loss: 9.4869\n",
      "Epoch 168/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5824 - val_loss: 9.6761\n",
      "Epoch 169/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6261 - val_loss: 9.4311\n",
      "Epoch 170/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.7485 - val_loss: 9.5667\n",
      "Epoch 171/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.8230 - val_loss: 9.4632\n",
      "Epoch 172/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 6.9429 - val_loss: 9.5644\n",
      "Epoch 173/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7230 - val_loss: 9.7389\n",
      "Epoch 174/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 6.5692 - val_loss: 9.5434\n",
      "Epoch 175/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.4559 - val_loss: 9.6657\n",
      "Epoch 176/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 6.6707 - val_loss: 9.5344\n",
      "Epoch 177/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.5365 - val_loss: 9.5424\n",
      "Epoch 178/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.4920 - val_loss: 9.5464\n",
      "Epoch 179/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6574 - val_loss: 9.5998\n",
      "Epoch 180/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 6.4526 - val_loss: 9.4188\n",
      "Epoch 181/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5849 - val_loss: 9.5008\n",
      "Epoch 182/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5883 - val_loss: 9.4499\n",
      "Epoch 183/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6687 - val_loss: 9.4271\n",
      "Epoch 184/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 6.5288 - val_loss: 9.3927\n",
      "Epoch 185/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4980 - val_loss: 9.6508\n",
      "Epoch 186/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7659 - val_loss: 9.4891\n",
      "Epoch 187/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6374 - val_loss: 9.5506\n",
      "Epoch 188/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.4899 - val_loss: 9.4808\n",
      "Epoch 189/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.5561 - val_loss: 9.5243\n",
      "Epoch 190/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5010 - val_loss: 9.3234\n",
      "Epoch 191/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5693 - val_loss: 9.3866\n",
      "Epoch 192/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.5971 - val_loss: 9.4993\n",
      "Epoch 193/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7154 - val_loss: 9.5486\n",
      "Epoch 194/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.5261 - val_loss: 9.5033\n",
      "Epoch 195/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.5750 - val_loss: 9.6801\n",
      "Epoch 196/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.6354 - val_loss: 9.4536\n",
      "Epoch 197/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 6.5559 - val_loss: 9.3757\n",
      "Epoch 198/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 6.5300 - val_loss: 9.2800\n",
      "Epoch 199/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5201 - val_loss: 9.4751\n",
      "Epoch 200/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.4690 - val_loss: 9.5316\n",
      "Epoch 201/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6262 - val_loss: 9.5843\n",
      "Epoch 202/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5922 - val_loss: 9.3274\n",
      "Epoch 203/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.6187 - val_loss: 9.6027\n",
      "Epoch 204/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.4966 - val_loss: 9.3645\n",
      "Epoch 205/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.5507 - val_loss: 9.3409\n",
      "Epoch 206/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5528 - val_loss: 9.3777\n",
      "Epoch 207/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4344 - val_loss: 9.3445\n",
      "Epoch 208/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4215 - val_loss: 9.3099\n",
      "Epoch 209/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5803 - val_loss: 9.2826\n",
      "Epoch 210/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.4613 - val_loss: 9.3816\n",
      "Epoch 211/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6937 - val_loss: 9.4161\n",
      "Epoch 212/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5515 - val_loss: 9.5913\n",
      "Epoch 213/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.3977 - val_loss: 9.3492\n",
      "Epoch 214/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.4384 - val_loss: 9.4603\n",
      "Epoch 215/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 6.4921 - val_loss: 9.3973\n",
      "Epoch 216/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4123 - val_loss: 9.4221\n",
      "Epoch 217/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4665 - val_loss: 9.2892\n",
      "Epoch 218/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4420 - val_loss: 9.3813\n",
      "Epoch 219/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5991 - val_loss: 9.2433\n",
      "Epoch 220/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7861 - val_loss: 9.4463\n",
      "Epoch 221/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.6800 - val_loss: 9.2679\n",
      "Epoch 222/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4133 - val_loss: 9.5441\n",
      "Epoch 223/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 109us/step - loss: 6.5600 - val_loss: 9.3782\n",
      "Epoch 224/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.4565 - val_loss: 9.1962\n",
      "Epoch 225/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.5015 - val_loss: 9.3819\n",
      "Epoch 226/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5610 - val_loss: 9.4138\n",
      "Epoch 227/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6556 - val_loss: 9.5747\n",
      "Epoch 228/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7379 - val_loss: 9.4089\n",
      "Epoch 229/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.8377 - val_loss: 9.4459\n",
      "Epoch 230/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3987 - val_loss: 9.5345\n",
      "Epoch 231/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4428 - val_loss: 9.3245\n",
      "Epoch 232/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3774 - val_loss: 9.2665\n",
      "Epoch 233/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4210 - val_loss: 9.2482\n",
      "Epoch 234/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.3730 - val_loss: 9.4620\n",
      "Epoch 235/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.4018 - val_loss: 9.4031\n",
      "Epoch 236/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4069 - val_loss: 9.4129\n",
      "Epoch 237/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4284 - val_loss: 9.3066\n",
      "Epoch 238/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4005 - val_loss: 9.2815\n",
      "Epoch 239/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.3758 - val_loss: 9.2218\n",
      "Epoch 240/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.4010 - val_loss: 9.2484\n",
      "Epoch 241/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3749 - val_loss: 9.3433\n",
      "Epoch 242/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.3756 - val_loss: 9.2523\n",
      "Epoch 243/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.4220 - val_loss: 9.3810\n",
      "Epoch 244/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4320 - val_loss: 9.2404\n",
      "Epoch 245/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3930 - val_loss: 9.3078\n",
      "Epoch 246/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4210 - val_loss: 9.3245\n",
      "Epoch 247/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3495 - val_loss: 9.2778\n",
      "Epoch 248/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5608 - val_loss: 9.4874\n",
      "Epoch 249/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.4364 - val_loss: 9.3601\n",
      "Epoch 250/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4627 - val_loss: 9.3015\n",
      "Epoch 251/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.6065 - val_loss: 9.1563\n",
      "Epoch 252/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 6.6812 - val_loss: 9.1804\n",
      "Epoch 253/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4536 - val_loss: 9.2919\n",
      "Epoch 254/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.2784 - val_loss: 9.0398\n",
      "Epoch 255/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 6.3819 - val_loss: 9.1648\n",
      "Epoch 256/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.6783 - val_loss: 9.3847\n",
      "Epoch 257/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3932 - val_loss: 9.2148\n",
      "Epoch 258/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3226 - val_loss: 9.3197\n",
      "Epoch 259/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.4323 - val_loss: 9.1934\n",
      "Epoch 260/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.3611 - val_loss: 9.3636\n",
      "Epoch 261/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2964 - val_loss: 9.1968\n",
      "Epoch 262/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3632 - val_loss: 9.4087\n",
      "Epoch 263/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3761 - val_loss: 9.1590\n",
      "Epoch 264/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.3852 - val_loss: 9.1586\n",
      "Epoch 265/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.6039 - val_loss: 9.0854\n",
      "Epoch 266/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3045 - val_loss: 9.1203\n",
      "Epoch 267/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3380 - val_loss: 9.1111\n",
      "Epoch 268/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.2631 - val_loss: 9.0959\n",
      "Epoch 269/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.3579 - val_loss: 9.1183\n",
      "Epoch 270/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4691 - val_loss: 9.0396\n",
      "Epoch 271/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3445 - val_loss: 9.0340\n",
      "Epoch 272/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2891 - val_loss: 9.1375\n",
      "Epoch 273/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3808 - val_loss: 9.0893\n",
      "Epoch 274/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4882 - val_loss: 9.2743\n",
      "Epoch 275/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.4878 - val_loss: 9.1411\n",
      "Epoch 276/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4257 - val_loss: 9.1946\n",
      "Epoch 277/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3290 - val_loss: 9.2858\n",
      "Epoch 278/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3408 - val_loss: 9.2734\n",
      "Epoch 279/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1918 - val_loss: 9.3627\n",
      "Epoch 280/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3650 - val_loss: 9.1533\n",
      "Epoch 281/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3823 - val_loss: 9.2574\n",
      "Epoch 282/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.6005 - val_loss: 9.1894\n",
      "Epoch 283/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6104 - val_loss: 9.2029\n",
      "Epoch 284/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5582 - val_loss: 9.1677\n",
      "Epoch 285/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4217 - val_loss: 9.0915\n",
      "Epoch 286/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6668 - val_loss: 9.1522\n",
      "Epoch 287/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4765 - val_loss: 9.2875\n",
      "Epoch 288/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2941 - val_loss: 9.3769\n",
      "Epoch 289/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.2961 - val_loss: 9.0485\n",
      "Epoch 290/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.3544 - val_loss: 9.0392\n",
      "Epoch 291/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 6.1940 - val_loss: 9.1080\n",
      "Epoch 292/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.3451 - val_loss: 9.1776\n",
      "Epoch 293/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2064 - val_loss: 9.1163\n",
      "Epoch 294/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.2786 - val_loss: 9.1016\n",
      "Epoch 295/1000\n",
      "274/274 [==============================] - 0s 117us/step - loss: 6.3174 - val_loss: 9.0990\n",
      "Epoch 296/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.2545 - val_loss: 9.1724\n",
      "Epoch 297/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 6.2410 - val_loss: 9.1015\n",
      "Epoch 298/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.1852 - val_loss: 9.2144\n",
      "Epoch 299/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3152 - val_loss: 9.0770\n",
      "Epoch 300/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 106us/step - loss: 6.1907 - val_loss: 8.9672\n",
      "Epoch 301/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2234 - val_loss: 9.0985\n",
      "Epoch 302/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3004 - val_loss: 9.0596\n",
      "Epoch 303/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.2166 - val_loss: 9.0944\n",
      "Epoch 304/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3150 - val_loss: 9.0598\n",
      "Epoch 305/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2047 - val_loss: 9.2104\n",
      "Epoch 306/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1886 - val_loss: 8.9974\n",
      "Epoch 307/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2177 - val_loss: 9.0859\n",
      "Epoch 308/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1354 - val_loss: 9.0773\n",
      "Epoch 309/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1898 - val_loss: 9.0984\n",
      "Epoch 310/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2277 - val_loss: 9.1064\n",
      "Epoch 311/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2168 - val_loss: 9.0048\n",
      "Epoch 312/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1884 - val_loss: 9.0009\n",
      "Epoch 313/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.1659 - val_loss: 8.9593\n",
      "Epoch 314/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2500 - val_loss: 8.9181\n",
      "Epoch 315/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2519 - val_loss: 9.2087\n",
      "Epoch 316/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1301 - val_loss: 9.1029\n",
      "Epoch 317/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2579 - val_loss: 9.2751\n",
      "Epoch 318/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3389 - val_loss: 9.0970\n",
      "Epoch 319/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1843 - val_loss: 9.1700\n",
      "Epoch 320/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2041 - val_loss: 9.0902\n",
      "Epoch 321/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1835 - val_loss: 9.2019\n",
      "Epoch 322/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3236 - val_loss: 9.0211\n",
      "Epoch 323/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1736 - val_loss: 9.0939\n",
      "Epoch 324/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.2478 - val_loss: 9.0653\n",
      "Epoch 325/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.1283 - val_loss: 9.0034\n",
      "Epoch 326/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1756 - val_loss: 9.0909\n",
      "Epoch 327/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1431 - val_loss: 9.0765\n",
      "Epoch 328/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1455 - val_loss: 8.9049\n",
      "Epoch 329/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1652 - val_loss: 8.8933\n",
      "Epoch 330/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1762 - val_loss: 8.9542\n",
      "Epoch 331/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2354 - val_loss: 8.8884\n",
      "Epoch 332/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3895 - val_loss: 9.0858\n",
      "Epoch 333/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2625 - val_loss: 9.0381\n",
      "Epoch 334/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3403 - val_loss: 9.0483\n",
      "Epoch 335/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.1242 - val_loss: 9.0883\n",
      "Epoch 336/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2007 - val_loss: 9.0502\n",
      "Epoch 337/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2516 - val_loss: 9.0994\n",
      "Epoch 338/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1994 - val_loss: 9.0248\n",
      "Epoch 339/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2167 - val_loss: 9.0527\n",
      "Epoch 340/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4852 - val_loss: 8.9550\n",
      "Epoch 341/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1337 - val_loss: 9.0641\n",
      "Epoch 342/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1978 - val_loss: 8.9793\n",
      "Epoch 343/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1942 - val_loss: 8.9727\n",
      "Epoch 344/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1248 - val_loss: 8.9107\n",
      "Epoch 345/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1718 - val_loss: 8.9375\n",
      "Epoch 346/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.0884 - val_loss: 9.0033\n",
      "Epoch 347/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1816 - val_loss: 8.9836\n",
      "Epoch 348/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2053 - val_loss: 8.8379\n",
      "Epoch 349/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0912 - val_loss: 8.9697\n",
      "Epoch 350/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3110 - val_loss: 8.7877\n",
      "Epoch 351/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.2082 - val_loss: 9.0336\n",
      "Epoch 352/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1803 - val_loss: 8.8938\n",
      "Epoch 353/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.1564 - val_loss: 8.8604\n",
      "Epoch 354/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1352 - val_loss: 8.9220\n",
      "Epoch 355/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1388 - val_loss: 8.8608\n",
      "Epoch 356/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1169 - val_loss: 8.9214\n",
      "Epoch 357/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0895 - val_loss: 8.9342\n",
      "Epoch 358/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1171 - val_loss: 8.8531\n",
      "Epoch 359/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1960 - val_loss: 8.9357\n",
      "Epoch 360/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1405 - val_loss: 8.8990\n",
      "Epoch 361/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0843 - val_loss: 8.9519\n",
      "Epoch 362/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.3503 - val_loss: 9.0095\n",
      "Epoch 363/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1222 - val_loss: 9.0584\n",
      "Epoch 364/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.1982 - val_loss: 9.0704\n",
      "Epoch 365/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4019 - val_loss: 9.1150\n",
      "Epoch 366/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.0794 - val_loss: 8.9558\n",
      "Epoch 367/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.1294 - val_loss: 9.0078\n",
      "Epoch 368/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2995 - val_loss: 8.9667\n",
      "Epoch 369/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.1002 - val_loss: 8.9173\n",
      "Epoch 370/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 6.0824 - val_loss: 9.0904\n",
      "Epoch 371/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0520 - val_loss: 8.9375\n",
      "Epoch 372/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0946 - val_loss: 8.9491\n",
      "Epoch 373/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0859 - val_loss: 8.9955\n",
      "Epoch 374/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2132 - val_loss: 8.9098\n",
      "Epoch 375/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5228 - val_loss: 9.0170\n",
      "Epoch 376/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2786 - val_loss: 9.0009\n",
      "Epoch 377/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 106us/step - loss: 6.1997 - val_loss: 8.8075\n",
      "Epoch 378/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1350 - val_loss: 8.9102\n",
      "Epoch 379/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0270 - val_loss: 8.9634\n",
      "Epoch 380/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0412 - val_loss: 8.9154\n",
      "Epoch 381/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1194 - val_loss: 8.8317\n",
      "Epoch 382/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2757 - val_loss: 9.0345\n",
      "Epoch 383/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.0545 - val_loss: 8.9748\n",
      "Epoch 384/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0577 - val_loss: 9.0227\n",
      "Epoch 385/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1729 - val_loss: 9.0296\n",
      "Epoch 386/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1825 - val_loss: 9.0067\n",
      "Epoch 387/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.5243 - val_loss: 8.9694\n",
      "Epoch 388/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0968 - val_loss: 9.0932\n",
      "Epoch 389/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 6.0142 - val_loss: 8.9154\n",
      "Epoch 390/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.9743 - val_loss: 8.9130\n",
      "Epoch 391/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0392 - val_loss: 8.8435\n",
      "Epoch 392/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1250 - val_loss: 8.9038\n",
      "Epoch 393/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0423 - val_loss: 8.8626\n",
      "Epoch 394/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0181 - val_loss: 8.8795\n",
      "Epoch 395/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 6.0822 - val_loss: 8.8190\n",
      "Epoch 396/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0703 - val_loss: 8.8860\n",
      "Epoch 397/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.0360 - val_loss: 8.8816\n",
      "Epoch 398/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9460 - val_loss: 8.8271\n",
      "Epoch 399/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1002 - val_loss: 8.9717\n",
      "Epoch 400/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.1260 - val_loss: 8.9829\n",
      "Epoch 401/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9426 - val_loss: 8.8685\n",
      "Epoch 402/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0978 - val_loss: 9.0361\n",
      "Epoch 403/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.0966 - val_loss: 8.9218\n",
      "Epoch 404/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.0098 - val_loss: 8.9682\n",
      "Epoch 405/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.9739 - val_loss: 8.9231\n",
      "Epoch 406/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.9767 - val_loss: 8.9940\n",
      "Epoch 407/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9772 - val_loss: 8.9561\n",
      "Epoch 408/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0017 - val_loss: 9.0064\n",
      "Epoch 409/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3243 - val_loss: 8.8874\n",
      "Epoch 410/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1395 - val_loss: 8.8208\n",
      "Epoch 411/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8916 - val_loss: 9.1002\n",
      "Epoch 412/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.0511 - val_loss: 8.8075\n",
      "Epoch 413/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.3049 - val_loss: 8.8593\n",
      "Epoch 414/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9969 - val_loss: 8.7785\n",
      "Epoch 415/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.9577 - val_loss: 9.0025\n",
      "Epoch 416/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.0612 - val_loss: 8.8163\n",
      "Epoch 417/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.0444 - val_loss: 8.8251\n",
      "Epoch 418/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.0326 - val_loss: 8.7716\n",
      "Epoch 419/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 6.0793 - val_loss: 8.7574\n",
      "Epoch 420/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.0623 - val_loss: 9.1138\n",
      "Epoch 421/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.0975 - val_loss: 8.8158\n",
      "Epoch 422/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0997 - val_loss: 9.0207\n",
      "Epoch 423/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.1389 - val_loss: 8.8617\n",
      "Epoch 424/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.0544 - val_loss: 8.8890\n",
      "Epoch 425/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.0768 - val_loss: 8.8088\n",
      "Epoch 426/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.9480 - val_loss: 8.8811\n",
      "Epoch 427/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.0246 - val_loss: 8.9176\n",
      "Epoch 428/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9800 - val_loss: 8.8226\n",
      "Epoch 429/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.2031 - val_loss: 8.9275\n",
      "Epoch 430/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.0317 - val_loss: 8.8400\n",
      "Epoch 431/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 6.0555 - val_loss: 8.8234\n",
      "Epoch 432/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.0450 - val_loss: 8.9750\n",
      "Epoch 433/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9445 - val_loss: 8.8172\n",
      "Epoch 434/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2618 - val_loss: 8.8341\n",
      "Epoch 435/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1627 - val_loss: 8.9032\n",
      "Epoch 436/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1106 - val_loss: 9.0101\n",
      "Epoch 437/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1127 - val_loss: 8.9726\n",
      "Epoch 438/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.9699 - val_loss: 9.0913\n",
      "Epoch 439/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.0386 - val_loss: 8.8299\n",
      "Epoch 440/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9668 - val_loss: 9.0013\n",
      "Epoch 441/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.1389 - val_loss: 8.8258\n",
      "Epoch 442/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8815 - val_loss: 9.0936\n",
      "Epoch 443/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9077 - val_loss: 8.9143\n",
      "Epoch 444/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0066 - val_loss: 8.9168\n",
      "Epoch 445/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0723 - val_loss: 8.8537\n",
      "Epoch 446/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9994 - val_loss: 8.9716\n",
      "Epoch 447/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9476 - val_loss: 8.9183\n",
      "Epoch 448/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8956 - val_loss: 9.0556\n",
      "Epoch 449/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9328 - val_loss: 8.9030\n",
      "Epoch 450/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0144 - val_loss: 8.8609\n",
      "Epoch 451/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.9404 - val_loss: 8.8014\n",
      "Epoch 452/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.9494 - val_loss: 8.8204\n",
      "Epoch 453/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9563 - val_loss: 8.8782\n",
      "Epoch 454/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 106us/step - loss: 5.9476 - val_loss: 8.8977\n",
      "Epoch 455/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9560 - val_loss: 8.8185\n",
      "Epoch 456/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.9520 - val_loss: 8.8983\n",
      "Epoch 457/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9199 - val_loss: 8.8650\n",
      "Epoch 458/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9271 - val_loss: 8.9846\n",
      "Epoch 459/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.8077 - val_loss: 8.8118\n",
      "Epoch 460/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0334 - val_loss: 8.9668\n",
      "Epoch 461/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9670 - val_loss: 8.7290\n",
      "Epoch 462/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8794 - val_loss: 8.8894\n",
      "Epoch 463/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.9028 - val_loss: 8.8777\n",
      "Epoch 464/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9332 - val_loss: 8.7596\n",
      "Epoch 465/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1023 - val_loss: 8.9453\n",
      "Epoch 466/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5042 - val_loss: 8.7036\n",
      "Epoch 467/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9529 - val_loss: 8.8032\n",
      "Epoch 468/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0962 - val_loss: 8.8067\n",
      "Epoch 469/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9201 - val_loss: 8.8387\n",
      "Epoch 470/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8599 - val_loss: 8.8774\n",
      "Epoch 471/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9317 - val_loss: 8.9046\n",
      "Epoch 472/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8750 - val_loss: 8.8284\n",
      "Epoch 473/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9283 - val_loss: 8.8836\n",
      "Epoch 474/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8713 - val_loss: 8.7949\n",
      "Epoch 475/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8552 - val_loss: 8.8371\n",
      "Epoch 476/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8613 - val_loss: 8.9898\n",
      "Epoch 477/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9037 - val_loss: 8.8114\n",
      "Epoch 478/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8763 - val_loss: 8.7948\n",
      "Epoch 479/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8591 - val_loss: 8.9255\n",
      "Epoch 480/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9222 - val_loss: 8.8475\n",
      "Epoch 481/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9496 - val_loss: 8.8779\n",
      "Epoch 482/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8701 - val_loss: 8.9002\n",
      "Epoch 483/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0043 - val_loss: 8.9176\n",
      "Epoch 484/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9314 - val_loss: 8.8592\n",
      "Epoch 485/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8684 - val_loss: 8.7697\n",
      "Epoch 486/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8945 - val_loss: 8.8344\n",
      "Epoch 487/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9678 - val_loss: 8.8025\n",
      "Epoch 488/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.1706 - val_loss: 8.8962\n",
      "Epoch 489/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9935 - val_loss: 8.6483\n",
      "Epoch 490/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9650 - val_loss: 8.9486\n",
      "Epoch 491/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9422 - val_loss: 8.9734\n",
      "Epoch 492/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.9040 - val_loss: 8.9694\n",
      "Epoch 493/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0142 - val_loss: 8.8560\n",
      "Epoch 494/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.0012 - val_loss: 8.8525\n",
      "Epoch 495/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8471 - val_loss: 8.9781\n",
      "Epoch 496/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9420 - val_loss: 8.7331\n",
      "Epoch 497/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8307 - val_loss: 8.8742\n",
      "Epoch 498/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.9137 - val_loss: 8.6994\n",
      "Epoch 499/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0153 - val_loss: 8.8476\n",
      "Epoch 500/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9332 - val_loss: 8.7525\n",
      "Epoch 501/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9139 - val_loss: 8.8872\n",
      "Epoch 502/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8560 - val_loss: 9.0294\n",
      "Epoch 503/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8520 - val_loss: 8.8860\n",
      "Epoch 504/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9739 - val_loss: 8.8193\n",
      "Epoch 505/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9127 - val_loss: 8.8576\n",
      "Epoch 506/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9229 - val_loss: 8.7644\n",
      "Epoch 507/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7607 - val_loss: 8.9035\n",
      "Epoch 508/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8637 - val_loss: 8.7974\n",
      "Epoch 509/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9990 - val_loss: 8.7780\n",
      "Epoch 510/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9010 - val_loss: 8.8390\n",
      "Epoch 511/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9996 - val_loss: 8.6935\n",
      "Epoch 512/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.8832 - val_loss: 8.7851\n",
      "Epoch 513/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8025 - val_loss: 8.7559\n",
      "Epoch 514/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.0150 - val_loss: 8.7134\n",
      "Epoch 515/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8266 - val_loss: 8.8094\n",
      "Epoch 516/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8263 - val_loss: 8.9000\n",
      "Epoch 517/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9272 - val_loss: 8.7897\n",
      "Epoch 518/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9270 - val_loss: 8.8702\n",
      "Epoch 519/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.9401 - val_loss: 8.7344\n",
      "Epoch 520/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8511 - val_loss: 8.6664\n",
      "Epoch 521/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0318 - val_loss: 8.7171\n",
      "Epoch 522/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1858 - val_loss: 8.8048\n",
      "Epoch 523/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8256 - val_loss: 8.9195\n",
      "Epoch 524/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8754 - val_loss: 8.7465\n",
      "Epoch 525/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8201 - val_loss: 8.7573\n",
      "Epoch 526/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 5.9851 - val_loss: 8.7133\n",
      "Epoch 527/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8264 - val_loss: 8.7113\n",
      "Epoch 528/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0409 - val_loss: 8.6910\n",
      "Epoch 529/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.9304 - val_loss: 8.6001\n",
      "Epoch 530/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8882 - val_loss: 8.8491\n",
      "Epoch 531/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 98us/step - loss: 5.8581 - val_loss: 8.7701\n",
      "Epoch 532/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.9676 - val_loss: 8.7328\n",
      "Epoch 533/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9417 - val_loss: 8.8798\n",
      "Epoch 534/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.9545 - val_loss: 8.8194\n",
      "Epoch 535/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9918 - val_loss: 8.7952\n",
      "Epoch 536/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9110 - val_loss: 8.9070\n",
      "Epoch 537/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8778 - val_loss: 8.7748\n",
      "Epoch 538/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.8469 - val_loss: 8.8621\n",
      "Epoch 539/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8500 - val_loss: 8.8603\n",
      "Epoch 540/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.9841 - val_loss: 8.7950\n",
      "Epoch 541/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.8479 - val_loss: 8.9528\n",
      "Epoch 542/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7343 - val_loss: 8.7649\n",
      "Epoch 543/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9909 - val_loss: 8.7272\n",
      "Epoch 544/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8474 - val_loss: 8.8535\n",
      "Epoch 545/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8635 - val_loss: 8.9037\n",
      "Epoch 546/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0192 - val_loss: 8.7043\n",
      "Epoch 547/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0372 - val_loss: 8.8072\n",
      "Epoch 548/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9428 - val_loss: 8.7855\n",
      "Epoch 549/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8666 - val_loss: 8.8220\n",
      "Epoch 550/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8124 - val_loss: 8.6980\n",
      "Epoch 551/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8119 - val_loss: 8.7733\n",
      "Epoch 552/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7912 - val_loss: 8.7030\n",
      "Epoch 553/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7920 - val_loss: 8.7098\n",
      "Epoch 554/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8327 - val_loss: 8.8130\n",
      "Epoch 555/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7802 - val_loss: 8.7635\n",
      "Epoch 556/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7957 - val_loss: 8.8813\n",
      "Epoch 557/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7758 - val_loss: 8.7319\n",
      "Epoch 558/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.7755 - val_loss: 8.8363\n",
      "Epoch 559/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0274 - val_loss: 8.5980\n",
      "Epoch 560/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1018 - val_loss: 8.7712\n",
      "Epoch 561/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.9642 - val_loss: 8.6793\n",
      "Epoch 562/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8123 - val_loss: 8.7050\n",
      "Epoch 563/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8061 - val_loss: 8.7815\n",
      "Epoch 564/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7321 - val_loss: 8.6241\n",
      "Epoch 565/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8269 - val_loss: 8.7829\n",
      "Epoch 566/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8381 - val_loss: 8.7943\n",
      "Epoch 567/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7448 - val_loss: 8.8034\n",
      "Epoch 568/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.8591 - val_loss: 8.7525\n",
      "Epoch 569/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.8434 - val_loss: 8.8097\n",
      "Epoch 570/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8652 - val_loss: 8.7047\n",
      "Epoch 571/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.8487 - val_loss: 8.8982\n",
      "Epoch 572/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8196 - val_loss: 8.7197\n",
      "Epoch 573/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7826 - val_loss: 8.6841\n",
      "Epoch 574/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7853 - val_loss: 8.5948\n",
      "Epoch 575/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8687 - val_loss: 8.5603\n",
      "Epoch 576/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8075 - val_loss: 8.5805\n",
      "Epoch 577/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8040 - val_loss: 8.6272\n",
      "Epoch 578/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9368 - val_loss: 8.7652\n",
      "Epoch 579/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7520 - val_loss: 8.5762\n",
      "Epoch 580/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8798 - val_loss: 8.8793\n",
      "Epoch 581/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8185 - val_loss: 8.6497\n",
      "Epoch 582/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 5.7871 - val_loss: 8.8154\n",
      "Epoch 583/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8870 - val_loss: 8.6271\n",
      "Epoch 584/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7983 - val_loss: 8.7252\n",
      "Epoch 585/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.8010 - val_loss: 8.7924\n",
      "Epoch 586/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7951 - val_loss: 8.6078\n",
      "Epoch 587/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8072 - val_loss: 8.7756\n",
      "Epoch 588/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7757 - val_loss: 8.5608\n",
      "Epoch 589/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7637 - val_loss: 8.7738\n",
      "Epoch 590/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7933 - val_loss: 8.6874\n",
      "Epoch 591/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7901 - val_loss: 8.6213\n",
      "Epoch 592/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.8566 - val_loss: 8.6753\n",
      "Epoch 593/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7796 - val_loss: 8.6291\n",
      "Epoch 594/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.0638 - val_loss: 8.9171\n",
      "Epoch 595/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1023 - val_loss: 8.7401\n",
      "Epoch 596/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0141 - val_loss: 8.7261\n",
      "Epoch 597/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1028 - val_loss: 8.7524\n",
      "Epoch 598/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9327 - val_loss: 8.6889\n",
      "Epoch 599/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.7814 - val_loss: 8.6715\n",
      "Epoch 600/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7003 - val_loss: 8.5010\n",
      "Epoch 601/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8118 - val_loss: 8.6184\n",
      "Epoch 602/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8947 - val_loss: 8.8411\n",
      "Epoch 603/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7879 - val_loss: 8.5586\n",
      "Epoch 604/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9007 - val_loss: 8.6558\n",
      "Epoch 605/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7853 - val_loss: 8.7847\n",
      "Epoch 606/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7690 - val_loss: 8.6751\n",
      "Epoch 607/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7144 - val_loss: 8.7499\n",
      "Epoch 608/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 98us/step - loss: 5.9562 - val_loss: 8.6088\n",
      "Epoch 609/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.7734 - val_loss: 8.7258\n",
      "Epoch 610/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7870 - val_loss: 8.7619\n",
      "Epoch 611/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8360 - val_loss: 8.6958\n",
      "Epoch 612/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7317 - val_loss: 8.5725\n",
      "Epoch 613/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7968 - val_loss: 8.6950\n",
      "Epoch 614/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7468 - val_loss: 8.4530\n",
      "Epoch 615/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.8913 - val_loss: 8.6653\n",
      "Epoch 616/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7528 - val_loss: 8.6018\n",
      "Epoch 617/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7719 - val_loss: 8.5689\n",
      "Epoch 618/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9090 - val_loss: 8.6646\n",
      "Epoch 619/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8498 - val_loss: 8.6301\n",
      "Epoch 620/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8830 - val_loss: 8.7335\n",
      "Epoch 621/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7903 - val_loss: 8.6223\n",
      "Epoch 622/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7219 - val_loss: 8.5790\n",
      "Epoch 623/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7962 - val_loss: 8.7006\n",
      "Epoch 624/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7251 - val_loss: 8.7127\n",
      "Epoch 625/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7147 - val_loss: 8.5962\n",
      "Epoch 626/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7414 - val_loss: 8.6525\n",
      "Epoch 627/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.6930 - val_loss: 8.7681\n",
      "Epoch 628/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8233 - val_loss: 8.4974\n",
      "Epoch 629/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7362 - val_loss: 8.5422\n",
      "Epoch 630/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7592 - val_loss: 8.6683\n",
      "Epoch 631/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8569 - val_loss: 8.5722\n",
      "Epoch 632/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8025 - val_loss: 8.5915\n",
      "Epoch 633/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8118 - val_loss: 8.8320\n",
      "Epoch 634/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0999 - val_loss: 8.6007\n",
      "Epoch 635/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8140 - val_loss: 8.6833\n",
      "Epoch 636/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7383 - val_loss: 8.6846\n",
      "Epoch 637/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 5.6940 - val_loss: 8.8277\n",
      "Epoch 638/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8290 - val_loss: 8.6548\n",
      "Epoch 639/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.7379 - val_loss: 8.5748\n",
      "Epoch 640/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7786 - val_loss: 8.6956\n",
      "Epoch 641/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7539 - val_loss: 8.7055\n",
      "Epoch 642/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7242 - val_loss: 8.5992\n",
      "Epoch 643/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.9033 - val_loss: 8.6927\n",
      "Epoch 644/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8674 - val_loss: 8.6004\n",
      "Epoch 645/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7173 - val_loss: 8.6592\n",
      "Epoch 646/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6949 - val_loss: 8.8082\n",
      "Epoch 647/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8438 - val_loss: 8.6166\n",
      "Epoch 648/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.0337 - val_loss: 8.6683\n",
      "Epoch 649/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1968 - val_loss: 8.5982\n",
      "Epoch 650/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6714 - val_loss: 8.5776\n",
      "Epoch 651/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8432 - val_loss: 8.7822\n",
      "Epoch 652/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8973 - val_loss: 8.4991\n",
      "Epoch 653/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.7632 - val_loss: 8.7419\n",
      "Epoch 654/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8636 - val_loss: 8.5480\n",
      "Epoch 655/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8615 - val_loss: 8.6984\n",
      "Epoch 656/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6489 - val_loss: 8.5796\n",
      "Epoch 657/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7720 - val_loss: 8.7621\n",
      "Epoch 658/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 5.7048 - val_loss: 8.6755\n",
      "Epoch 659/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.7980 - val_loss: 8.5242\n",
      "Epoch 660/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7646 - val_loss: 8.6816\n",
      "Epoch 661/1000\n",
      "274/274 [==============================] - 0s 125us/step - loss: 5.6582 - val_loss: 8.5931\n",
      "Epoch 662/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7374 - val_loss: 8.5956\n",
      "Epoch 663/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8268 - val_loss: 8.4597\n",
      "Epoch 664/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7027 - val_loss: 8.5776\n",
      "Epoch 665/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7386 - val_loss: 8.3653\n",
      "Epoch 666/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7018 - val_loss: 8.4832\n",
      "Epoch 667/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7492 - val_loss: 8.4518\n",
      "Epoch 668/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8564 - val_loss: 8.5731\n",
      "Epoch 669/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6542 - val_loss: 8.5335\n",
      "Epoch 670/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7462 - val_loss: 8.7069\n",
      "Epoch 671/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.8375 - val_loss: 8.5176\n",
      "Epoch 672/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6763 - val_loss: 8.6450\n",
      "Epoch 673/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7509 - val_loss: 8.6086\n",
      "Epoch 674/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8231 - val_loss: 8.6334\n",
      "Epoch 675/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.9721 - val_loss: 8.5675\n",
      "Epoch 676/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.9374 - val_loss: 8.4825\n",
      "Epoch 677/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.6946 - val_loss: 8.7039\n",
      "Epoch 678/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6197 - val_loss: 8.4130\n",
      "Epoch 679/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.8044 - val_loss: 8.6345\n",
      "Epoch 680/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8971 - val_loss: 8.2946\n",
      "Epoch 681/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.6808 - val_loss: 8.5335\n",
      "Epoch 682/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6642 - val_loss: 8.4760\n",
      "Epoch 683/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7126 - val_loss: 8.6149\n",
      "Epoch 684/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.6873 - val_loss: 8.6896\n",
      "Epoch 685/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 120us/step - loss: 6.0016 - val_loss: 8.5234\n",
      "Epoch 686/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8001 - val_loss: 8.6722\n",
      "Epoch 687/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7588 - val_loss: 8.5734\n",
      "Epoch 688/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6385 - val_loss: 8.5382\n",
      "Epoch 689/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7052 - val_loss: 8.5964\n",
      "Epoch 690/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7590 - val_loss: 8.4358\n",
      "Epoch 691/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7672 - val_loss: 8.4930\n",
      "Epoch 692/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0854 - val_loss: 8.5103\n",
      "Epoch 693/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8330 - val_loss: 8.4906\n",
      "Epoch 694/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6637 - val_loss: 8.6143\n",
      "Epoch 695/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6859 - val_loss: 8.3460\n",
      "Epoch 696/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7880 - val_loss: 8.4532\n",
      "Epoch 697/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7399 - val_loss: 8.4609\n",
      "Epoch 698/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7479 - val_loss: 8.6187\n",
      "Epoch 699/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6615 - val_loss: 8.4123\n",
      "Epoch 700/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7431 - val_loss: 8.5277\n",
      "Epoch 701/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6536 - val_loss: 8.6040\n",
      "Epoch 702/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8203 - val_loss: 8.3665\n",
      "Epoch 703/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0496 - val_loss: 8.5472\n",
      "Epoch 704/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7823 - val_loss: 8.5179\n",
      "Epoch 705/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.7766 - val_loss: 8.5088\n",
      "Epoch 706/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6731 - val_loss: 8.5885\n",
      "Epoch 707/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7476 - val_loss: 8.4849\n",
      "Epoch 708/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9286 - val_loss: 8.6500\n",
      "Epoch 709/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.6740 - val_loss: 8.6439\n",
      "Epoch 710/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6590 - val_loss: 8.5434\n",
      "Epoch 711/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6315 - val_loss: 8.4422\n",
      "Epoch 712/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6981 - val_loss: 8.4827\n",
      "Epoch 713/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6085 - val_loss: 8.3212\n",
      "Epoch 714/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 5.7399 - val_loss: 8.5486\n",
      "Epoch 715/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.6570 - val_loss: 8.4156\n",
      "Epoch 716/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6754 - val_loss: 8.6225\n",
      "Epoch 717/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6663 - val_loss: 8.5260\n",
      "Epoch 718/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7144 - val_loss: 8.5959\n",
      "Epoch 719/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.6011 - val_loss: 8.5811\n",
      "Epoch 720/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7393 - val_loss: 8.5539\n",
      "Epoch 721/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7291 - val_loss: 8.5674\n",
      "Epoch 722/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7115 - val_loss: 8.6971\n",
      "Epoch 723/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6982 - val_loss: 8.5535\n",
      "Epoch 724/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7581 - val_loss: 8.5178\n",
      "Epoch 725/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8025 - val_loss: 8.4655\n",
      "Epoch 726/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.9810 - val_loss: 8.7649\n",
      "Epoch 727/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0727 - val_loss: 8.4065\n",
      "Epoch 728/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8076 - val_loss: 8.5549\n",
      "Epoch 729/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8265 - val_loss: 8.5461\n",
      "Epoch 730/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.9091 - val_loss: 8.5694\n",
      "Epoch 731/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6691 - val_loss: 8.6460\n",
      "Epoch 732/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7548 - val_loss: 8.5389\n",
      "Epoch 733/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.6636 - val_loss: 8.7787\n",
      "Epoch 734/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7346 - val_loss: 8.3882\n",
      "Epoch 735/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6866 - val_loss: 8.5051\n",
      "Epoch 736/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7095 - val_loss: 8.5771\n",
      "Epoch 737/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6543 - val_loss: 8.5433\n",
      "Epoch 738/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8231 - val_loss: 8.3223\n",
      "Epoch 739/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6543 - val_loss: 8.5593\n",
      "Epoch 740/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.6255 - val_loss: 8.4553\n",
      "Epoch 741/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7127 - val_loss: 8.4687\n",
      "Epoch 742/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6687 - val_loss: 8.3947\n",
      "Epoch 743/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7398 - val_loss: 8.5259\n",
      "Epoch 744/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5907 - val_loss: 8.5007\n",
      "Epoch 745/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7112 - val_loss: 8.5888\n",
      "Epoch 746/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7149 - val_loss: 8.3648\n",
      "Epoch 747/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.8692 - val_loss: 8.6023\n",
      "Epoch 748/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.7775 - val_loss: 8.6554\n",
      "Epoch 749/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6529 - val_loss: 8.4120\n",
      "Epoch 750/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.6589 - val_loss: 8.6211\n",
      "Epoch 751/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6951 - val_loss: 8.6235\n",
      "Epoch 752/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6470 - val_loss: 8.5122\n",
      "Epoch 753/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6447 - val_loss: 8.7533\n",
      "Epoch 754/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6962 - val_loss: 8.6734\n",
      "Epoch 755/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.6771 - val_loss: 8.4078\n",
      "Epoch 756/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6258 - val_loss: 8.7210\n",
      "Epoch 757/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7175 - val_loss: 8.5303\n",
      "Epoch 758/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5603 - val_loss: 8.7884\n",
      "Epoch 759/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7661 - val_loss: 8.3738\n",
      "Epoch 760/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7919 - val_loss: 8.7854\n",
      "Epoch 761/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.7225 - val_loss: 8.5515\n",
      "Epoch 762/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 105us/step - loss: 5.6333 - val_loss: 8.5824\n",
      "Epoch 763/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6321 - val_loss: 8.4042\n",
      "Epoch 764/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.8029 - val_loss: 8.5447\n",
      "Epoch 765/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.7227 - val_loss: 8.4707\n",
      "Epoch 766/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.6746 - val_loss: 8.3822\n",
      "Epoch 767/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.6878 - val_loss: 8.6291\n",
      "Epoch 768/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7413 - val_loss: 8.4009\n",
      "Epoch 769/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.5980 - val_loss: 8.5405\n",
      "Epoch 770/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5809 - val_loss: 8.5866\n",
      "Epoch 771/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6576 - val_loss: 8.5807\n",
      "Epoch 772/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6809 - val_loss: 8.5728\n",
      "Epoch 773/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6463 - val_loss: 8.5998\n",
      "Epoch 774/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6523 - val_loss: 8.5790\n",
      "Epoch 775/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7456 - val_loss: 8.3908\n",
      "Epoch 776/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5897 - val_loss: 8.6507\n",
      "Epoch 777/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6900 - val_loss: 8.6184\n",
      "Epoch 778/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.7381 - val_loss: 8.4741\n",
      "Epoch 779/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.7344 - val_loss: 8.5824\n",
      "Epoch 780/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.0032 - val_loss: 8.6395\n",
      "Epoch 781/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 5.8819 - val_loss: 8.6261\n",
      "Epoch 782/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5941 - val_loss: 8.6695\n",
      "Epoch 783/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.7209 - val_loss: 8.4000\n",
      "Epoch 784/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6682 - val_loss: 8.6650\n",
      "Epoch 785/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.6607 - val_loss: 8.4579\n",
      "Epoch 786/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6204 - val_loss: 8.4067\n",
      "Epoch 787/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6902 - val_loss: 8.6650\n",
      "Epoch 788/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.7984 - val_loss: 8.2945\n",
      "Epoch 789/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7739 - val_loss: 8.5765\n",
      "Epoch 790/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6374 - val_loss: 8.5101\n",
      "Epoch 791/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6021 - val_loss: 8.3450\n",
      "Epoch 792/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7387 - val_loss: 8.5870\n",
      "Epoch 793/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7503 - val_loss: 8.4471\n",
      "Epoch 794/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6218 - val_loss: 8.6208\n",
      "Epoch 795/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.7350 - val_loss: 8.5103\n",
      "Epoch 796/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7068 - val_loss: 8.3713\n",
      "Epoch 797/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6093 - val_loss: 8.6280\n",
      "Epoch 798/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.6723 - val_loss: 8.3259\n",
      "Epoch 799/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.6351 - val_loss: 8.4349\n",
      "Epoch 800/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6638 - val_loss: 8.5409\n",
      "Epoch 801/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5976 - val_loss: 8.4841\n",
      "Epoch 802/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6330 - val_loss: 8.4706\n",
      "Epoch 803/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.7582 - val_loss: 8.5107\n",
      "Epoch 804/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6480 - val_loss: 8.4268\n",
      "Epoch 805/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6604 - val_loss: 8.5132\n",
      "Epoch 806/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7344 - val_loss: 8.3862\n",
      "Epoch 807/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5685 - val_loss: 8.5824\n",
      "Epoch 808/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6481 - val_loss: 8.3960\n",
      "Epoch 809/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6103 - val_loss: 8.5104\n",
      "Epoch 810/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5720 - val_loss: 8.3188\n",
      "Epoch 811/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6374 - val_loss: 8.5287\n",
      "Epoch 812/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6462 - val_loss: 8.3697\n",
      "Epoch 813/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.6993 - val_loss: 8.6249\n",
      "Epoch 814/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5913 - val_loss: 8.6273\n",
      "Epoch 815/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8579 - val_loss: 8.4276\n",
      "Epoch 816/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.8866 - val_loss: 8.6672\n",
      "Epoch 817/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6795 - val_loss: 8.5390\n",
      "Epoch 818/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6598 - val_loss: 8.4703\n",
      "Epoch 819/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6347 - val_loss: 8.4120\n",
      "Epoch 820/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.5949 - val_loss: 8.5194\n",
      "Epoch 821/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7470 - val_loss: 8.4936\n",
      "Epoch 822/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6122 - val_loss: 8.8157\n",
      "Epoch 823/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6611 - val_loss: 8.3573\n",
      "Epoch 824/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6652 - val_loss: 8.5624\n",
      "Epoch 825/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6611 - val_loss: 8.5198\n",
      "Epoch 826/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.5931 - val_loss: 8.5733\n",
      "Epoch 827/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7097 - val_loss: 8.6346\n",
      "Epoch 828/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8122 - val_loss: 8.4285\n",
      "Epoch 829/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.6543 - val_loss: 8.5437\n",
      "Epoch 830/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7208 - val_loss: 8.4648\n",
      "Epoch 831/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6889 - val_loss: 8.6326\n",
      "Epoch 832/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6415 - val_loss: 8.5085\n",
      "Epoch 833/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6852 - val_loss: 8.7362\n",
      "Epoch 834/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7435 - val_loss: 8.4324\n",
      "Epoch 835/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7645 - val_loss: 8.4979\n",
      "Epoch 836/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8589 - val_loss: 8.4365\n",
      "Epoch 837/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.7207 - val_loss: 8.5432\n",
      "Epoch 838/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6298 - val_loss: 8.5117\n",
      "Epoch 839/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 95us/step - loss: 5.6905 - val_loss: 8.4437\n",
      "Epoch 840/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7098 - val_loss: 8.5157\n",
      "Epoch 841/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6237 - val_loss: 8.5288\n",
      "Epoch 842/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2042 - val_loss: 8.6430\n",
      "Epoch 843/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6573 - val_loss: 8.5377\n",
      "Epoch 844/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.5958 - val_loss: 8.5906\n",
      "Epoch 845/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6019 - val_loss: 8.6228\n",
      "Epoch 846/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6049 - val_loss: 8.4807\n",
      "Epoch 847/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6009 - val_loss: 8.5217\n",
      "Epoch 848/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5776 - val_loss: 8.4621\n",
      "Epoch 849/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6111 - val_loss: 8.3769\n",
      "Epoch 850/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.6198 - val_loss: 8.5078\n",
      "Epoch 851/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6916 - val_loss: 8.4543\n",
      "Epoch 852/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5737 - val_loss: 8.4737\n",
      "Epoch 853/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5733 - val_loss: 8.5061\n",
      "Epoch 854/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.7287 - val_loss: 8.5034\n",
      "Epoch 855/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8511 - val_loss: 8.5325\n",
      "Epoch 856/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7289 - val_loss: 8.6721\n",
      "Epoch 857/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.6561 - val_loss: 8.3998\n",
      "Epoch 858/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5590 - val_loss: 8.7332\n",
      "Epoch 859/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8192 - val_loss: 8.4549\n",
      "Epoch 860/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8629 - val_loss: 8.7125\n",
      "Epoch 861/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.6218 - val_loss: 8.6732\n",
      "Epoch 862/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.5972 - val_loss: 8.4961\n",
      "Epoch 863/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7822 - val_loss: 8.6951\n",
      "Epoch 864/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6929 - val_loss: 8.2847\n",
      "Epoch 865/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.6588 - val_loss: 8.6115\n",
      "Epoch 866/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6041 - val_loss: 8.3794\n",
      "Epoch 867/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.5926 - val_loss: 8.5777\n",
      "Epoch 868/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.6593 - val_loss: 8.4368\n",
      "Epoch 869/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6234 - val_loss: 8.5139\n",
      "Epoch 870/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.5746 - val_loss: 8.4285\n",
      "Epoch 871/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.5579 - val_loss: 8.5468\n",
      "Epoch 872/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6271 - val_loss: 8.6068\n",
      "Epoch 873/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.6633 - val_loss: 8.5098\n",
      "Epoch 874/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6121 - val_loss: 8.6062\n",
      "Epoch 875/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5371 - val_loss: 8.4631\n",
      "Epoch 876/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.6783 - val_loss: 8.4868\n",
      "Epoch 877/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5804 - val_loss: 8.4966\n",
      "Epoch 878/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6367 - val_loss: 8.6246\n",
      "Epoch 879/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.6361 - val_loss: 8.3804\n",
      "Epoch 880/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.7604 - val_loss: 8.5771\n",
      "Epoch 881/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.7314 - val_loss: 8.3863\n",
      "Epoch 882/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6297 - val_loss: 8.4716\n",
      "Epoch 883/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7856 - val_loss: 8.6177\n",
      "Epoch 884/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5750 - val_loss: 8.5884\n",
      "Epoch 885/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6175 - val_loss: 8.6719\n",
      "Epoch 886/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.6379 - val_loss: 8.4501\n",
      "Epoch 887/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6605 - val_loss: 8.5796\n",
      "Epoch 888/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7406 - val_loss: 8.6164\n",
      "Epoch 889/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7247 - val_loss: 8.6403\n",
      "Epoch 890/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6002 - val_loss: 8.4651\n",
      "Epoch 891/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7745 - val_loss: 8.5315\n",
      "Epoch 892/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5667 - val_loss: 8.4751\n",
      "Epoch 893/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5659 - val_loss: 8.8071\n",
      "Epoch 894/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9091 - val_loss: 8.4686\n",
      "Epoch 895/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6044 - val_loss: 8.6228\n",
      "Epoch 896/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5583 - val_loss: 8.3282\n",
      "Epoch 897/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6500 - val_loss: 8.7230\n",
      "Epoch 898/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6569 - val_loss: 8.3080\n",
      "Epoch 899/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6412 - val_loss: 8.5913\n",
      "Epoch 900/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5609 - val_loss: 8.5249\n",
      "Epoch 901/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7288 - val_loss: 8.5748\n",
      "Epoch 902/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5396 - val_loss: 8.5663\n",
      "Epoch 903/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.6285 - val_loss: 8.4802\n",
      "Epoch 904/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6285 - val_loss: 8.5446\n",
      "Epoch 905/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5944 - val_loss: 8.4821\n",
      "Epoch 906/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6310 - val_loss: 8.3742\n",
      "Epoch 907/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6569 - val_loss: 8.5485\n",
      "Epoch 908/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5557 - val_loss: 8.5405\n",
      "Epoch 909/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.5669 - val_loss: 8.4439\n",
      "Epoch 910/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6233 - val_loss: 8.5385\n",
      "Epoch 911/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5898 - val_loss: 8.3329\n",
      "Epoch 912/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5859 - val_loss: 8.3437\n",
      "Epoch 913/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.6315 - val_loss: 8.6344\n",
      "Epoch 914/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8021 - val_loss: 8.3473\n",
      "Epoch 915/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7372 - val_loss: 8.5856\n",
      "Epoch 916/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 113us/step - loss: 5.6135 - val_loss: 8.6146\n",
      "Epoch 917/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5576 - val_loss: 8.4491\n",
      "Epoch 918/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6180 - val_loss: 8.7432\n",
      "Epoch 919/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5470 - val_loss: 8.4470\n",
      "Epoch 920/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.6248 - val_loss: 8.3671\n",
      "Epoch 921/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.5806 - val_loss: 8.3640\n",
      "Epoch 922/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5631 - val_loss: 8.3697\n",
      "Epoch 923/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5840 - val_loss: 8.6445\n",
      "Epoch 924/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5386 - val_loss: 8.4535\n",
      "Epoch 925/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5775 - val_loss: 8.3077\n",
      "Epoch 926/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.5526 - val_loss: 8.4932\n",
      "Epoch 927/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.5329 - val_loss: 8.4726\n",
      "Epoch 928/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5505 - val_loss: 8.6109\n",
      "Epoch 929/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5446 - val_loss: 8.5122\n",
      "Epoch 930/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.6055 - val_loss: 8.4383\n",
      "Epoch 931/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6051 - val_loss: 8.6795\n",
      "Epoch 932/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6145 - val_loss: 8.4078\n",
      "Epoch 933/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5745 - val_loss: 8.4936\n",
      "Epoch 934/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.5753 - val_loss: 8.6357\n",
      "Epoch 935/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5252 - val_loss: 8.4276\n",
      "Epoch 936/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5739 - val_loss: 8.5983\n",
      "Epoch 937/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6529 - val_loss: 8.5258\n",
      "Epoch 938/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5269 - val_loss: 8.6812\n",
      "Epoch 939/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5725 - val_loss: 8.3250\n",
      "Epoch 940/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.5632 - val_loss: 8.5030\n",
      "Epoch 941/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.5767 - val_loss: 8.3875\n",
      "Epoch 942/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6027 - val_loss: 8.4809\n",
      "Epoch 943/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6200 - val_loss: 8.5757\n",
      "Epoch 944/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7007 - val_loss: 8.5420\n",
      "Epoch 945/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5937 - val_loss: 8.5379\n",
      "Epoch 946/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6119 - val_loss: 8.5170\n",
      "Epoch 947/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.5955 - val_loss: 8.3819\n",
      "Epoch 948/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.5862 - val_loss: 8.3688\n",
      "Epoch 949/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7877 - val_loss: 8.4839\n",
      "Epoch 950/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6861 - val_loss: 8.7988\n",
      "Epoch 951/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.6032 - val_loss: 8.4104\n",
      "Epoch 952/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4985 - val_loss: 8.6859\n",
      "Epoch 953/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6920 - val_loss: 8.4018\n",
      "Epoch 954/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6541 - val_loss: 8.6643\n",
      "Epoch 955/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6580 - val_loss: 8.7724\n",
      "Epoch 956/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6145 - val_loss: 8.4685\n",
      "Epoch 957/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6767 - val_loss: 8.5391\n",
      "Epoch 958/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7935 - val_loss: 8.4778\n",
      "Epoch 959/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6702 - val_loss: 8.4790\n",
      "Epoch 960/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7606 - val_loss: 8.5442\n",
      "Epoch 961/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6091 - val_loss: 8.5829\n",
      "Epoch 962/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6509 - val_loss: 8.4341\n",
      "Epoch 963/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7062 - val_loss: 8.4379\n",
      "Epoch 964/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5577 - val_loss: 8.6356\n",
      "Epoch 965/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5409 - val_loss: 8.4978\n",
      "Epoch 966/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6733 - val_loss: 8.7293\n",
      "Epoch 967/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6074 - val_loss: 8.4842\n",
      "Epoch 968/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6176 - val_loss: 8.6951\n",
      "Epoch 969/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.5474 - val_loss: 8.4095\n",
      "Epoch 970/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5804 - val_loss: 8.4753\n",
      "Epoch 971/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5729 - val_loss: 8.5093\n",
      "Epoch 972/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5467 - val_loss: 8.5055\n",
      "Epoch 973/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5932 - val_loss: 8.5803\n",
      "Epoch 974/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5761 - val_loss: 8.4650\n",
      "Epoch 975/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5829 - val_loss: 8.5443\n",
      "Epoch 976/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5356 - val_loss: 8.5120\n",
      "Epoch 977/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6163 - val_loss: 8.5589\n",
      "Epoch 978/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4950 - val_loss: 8.3779\n",
      "Epoch 979/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.5205 - val_loss: 8.6735\n",
      "Epoch 980/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.6262 - val_loss: 8.5601\n",
      "Epoch 981/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6987 - val_loss: 8.3404\n",
      "Epoch 982/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6138 - val_loss: 8.6117\n",
      "Epoch 983/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7091 - val_loss: 8.5213\n",
      "Epoch 984/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6105 - val_loss: 8.4225\n",
      "Epoch 985/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6202 - val_loss: 8.5988\n",
      "Epoch 986/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.5851 - val_loss: 8.3707\n",
      "Epoch 987/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5509 - val_loss: 8.5858\n",
      "Epoch 988/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5695 - val_loss: 8.4327\n",
      "Epoch 989/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5820 - val_loss: 8.5526\n",
      "Epoch 990/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7506 - val_loss: 8.3873\n",
      "Epoch 991/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6164 - val_loss: 8.5091\n",
      "Epoch 992/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0357 - val_loss: 8.4405\n",
      "Epoch 993/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 6.0525 - val_loss: 8.5214\n",
      "Epoch 994/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1849 - val_loss: 8.9953\n",
      "Epoch 995/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5521 - val_loss: 8.7284\n",
      "Epoch 996/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0522 - val_loss: 8.9772\n",
      "Epoch 997/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.6153 - val_loss: 8.4773\n",
      "Epoch 998/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5334 - val_loss: 9.0170\n",
      "Epoch 999/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6589 - val_loss: 8.4599\n",
      "Epoch 1000/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.5623 - val_loss: 8.5517\n",
      "7.207257876961918\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 1.3227559 ,  0.6106956 , -0.8675589 , -3.5244222 , -1.1287844 ],\n",
       "        [-5.041491  , -2.3730898 ,  0.63648856,  4.074997  , -0.42533156],\n",
       "        [-1.8531946 ,  1.14759   ,  0.22032951, -2.424565  ,  0.40579486],\n",
       "        [ 2.3968732 ,  2.6486132 ,  0.53338337, -2.9351628 ,  2.2392395 ],\n",
       "        [-1.6769222 , -1.1783738 ,  1.1914943 , -0.44460407, -0.42974356],\n",
       "        [-1.2211828 , -0.99476206, -1.2144927 ,  1.0303143 , -1.4027028 ],\n",
       "        [ 2.7640762 ,  0.82176155, -1.4117393 ,  2.5781817 , -0.21668957]],\n",
       "       dtype=float32),\n",
       " array([ 1.7787924 , -0.74598217, -2.680197  , -1.210682  ,  2.4426036 ],\n",
       "       dtype=float32),\n",
       " array([[-0.38798124, -0.33427227, -0.10083748,  0.40901184, -0.44767374,\n",
       "         -0.59402424,  0.12195282,  0.149138  ,  0.5278687 ,  0.06234827],\n",
       "        [-0.1023507 ,  0.41467944,  0.6408592 , -0.0948898 ,  0.56022304,\n",
       "          0.43878043, -0.15697199, -0.52051103,  0.14196037,  0.04117951],\n",
       "        [-0.13972719,  0.19807121,  0.3224786 ,  0.42278388,  0.23423249,\n",
       "          0.42468283,  0.11245709, -0.23098649,  0.031858  ,  0.16066839],\n",
       "        [-0.5802515 , -0.49156946,  0.33833647, -0.39481863,  0.13172646,\n",
       "         -0.43070176,  0.09701331,  0.6348798 ,  0.06207775, -0.11619066],\n",
       "        [-0.14999709,  0.600353  ,  0.7702311 ,  0.88965666,  0.03341315,\n",
       "          0.49780846,  0.3361956 , -0.00173593,  0.47554702,  0.24350253]],\n",
       "       dtype=float32),\n",
       " array([-1.9570115, -1.9621617, -1.9723155, -2.0135775, -1.8368669,\n",
       "        -1.9322976, -1.8019863,  1.8664855, -1.8608044, -1.9104966],\n",
       "       dtype=float32),\n",
       " array([[-1.1792505 ],\n",
       "        [-1.4542323 ],\n",
       "        [-1.0050015 ],\n",
       "        [-1.3031656 ],\n",
       "        [-0.7446528 ],\n",
       "        [-1.5537766 ],\n",
       "        [-0.9607792 ],\n",
       "        [ 1.3009865 ],\n",
       "        [-0.86545736],\n",
       "        [-0.87815887]], dtype=float32),\n",
       " array([1.8599626], dtype=float32)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_autompg, history_autompg, evaluate_autompg=NN_model_structure_regression_linear(X_train_autompg, X_val_autompg, Y_train_autompg, Y_val_autompg, adam2, 32, 1000, x_test_autompg, y_test_autompg)\n",
    "model_autompg.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_autompg.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_autompg_linear_4th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 5)                 40        \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 111\n",
      "Trainable params: 111\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 274 samples, validate on 59 samples\n",
      "Epoch 1/1000\n",
      "274/274 [==============================] - 0s 707us/step - loss: 375.3231 - val_loss: 90.5134\n",
      "Epoch 2/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 81.0192 - val_loss: 60.1416\n",
      "Epoch 3/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 44.3811 - val_loss: 23.8303\n",
      "Epoch 4/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 21.4425 - val_loss: 14.6125\n",
      "Epoch 5/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 15.8663 - val_loss: 11.6410\n",
      "Epoch 6/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 14.5403 - val_loss: 11.3344\n",
      "Epoch 7/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 12.7138 - val_loss: 10.9965\n",
      "Epoch 8/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 11.6268 - val_loss: 10.2097\n",
      "Epoch 9/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 10.7304 - val_loss: 9.9416\n",
      "Epoch 10/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 10.3913 - val_loss: 9.5060\n",
      "Epoch 11/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 10.3176 - val_loss: 9.1359\n",
      "Epoch 12/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 9.8961 - val_loss: 8.9411\n",
      "Epoch 13/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 9.9624 - val_loss: 8.7147\n",
      "Epoch 14/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 9.6866 - val_loss: 8.6516\n",
      "Epoch 15/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 9.6187 - val_loss: 8.2888\n",
      "Epoch 16/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 9.2103 - val_loss: 8.0880\n",
      "Epoch 17/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 8.8967 - val_loss: 8.6354\n",
      "Epoch 18/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 8.6440 - val_loss: 8.0921\n",
      "Epoch 19/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.8157 - val_loss: 8.0475\n",
      "Epoch 20/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 8.5335 - val_loss: 8.1657\n",
      "Epoch 21/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 8.6415 - val_loss: 8.1758\n",
      "Epoch 22/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.5546 - val_loss: 7.8468\n",
      "Epoch 23/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 8.4060 - val_loss: 8.3293\n",
      "Epoch 24/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 8.5677 - val_loss: 8.0542\n",
      "Epoch 25/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 8.2670 - val_loss: 7.8695\n",
      "Epoch 26/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.1909 - val_loss: 8.0808\n",
      "Epoch 27/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 8.1146 - val_loss: 8.0626\n",
      "Epoch 28/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 8.0871 - val_loss: 8.2739\n",
      "Epoch 29/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 8.0936 - val_loss: 7.8927\n",
      "Epoch 30/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.1560 - val_loss: 7.7912\n",
      "Epoch 31/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 8.2153 - val_loss: 7.9665\n",
      "Epoch 32/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.0203 - val_loss: 8.0795\n",
      "Epoch 33/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 8.2454 - val_loss: 8.1139\n",
      "Epoch 34/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 8.5726 - val_loss: 7.7292\n",
      "Epoch 35/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.4344 - val_loss: 8.0394\n",
      "Epoch 36/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 8.1692 - val_loss: 8.0393\n",
      "Epoch 37/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.9000 - val_loss: 7.8584\n",
      "Epoch 38/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.8207 - val_loss: 8.0529\n",
      "Epoch 39/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.9376 - val_loss: 7.8942\n",
      "Epoch 40/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 7.8138 - val_loss: 8.0367\n",
      "Epoch 41/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 7.9305 - val_loss: 7.8426\n",
      "Epoch 42/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 8.1122 - val_loss: 8.2702\n",
      "Epoch 43/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.7219 - val_loss: 8.2712\n",
      "Epoch 44/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.5994 - val_loss: 7.9342\n",
      "Epoch 45/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 7.5988 - val_loss: 8.0259\n",
      "Epoch 46/1000\n",
      "274/274 [==============================] - 0s 138us/step - loss: 7.5870 - val_loss: 7.6326\n",
      "Epoch 47/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 7.9089 - val_loss: 7.5188\n",
      "Epoch 48/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 7.4414 - val_loss: 7.6926\n",
      "Epoch 49/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 7.5202 - val_loss: 7.6904\n",
      "Epoch 50/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3474 - val_loss: 7.5049\n",
      "Epoch 51/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.5161 - val_loss: 7.8149\n",
      "Epoch 52/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.4868 - val_loss: 7.2903\n",
      "Epoch 53/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.4556 - val_loss: 7.5944\n",
      "Epoch 54/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.3837 - val_loss: 7.2646\n",
      "Epoch 55/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.3183 - val_loss: 7.5927\n",
      "Epoch 56/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 7.2674 - val_loss: 7.5583\n",
      "Epoch 57/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3358 - val_loss: 7.2174\n",
      "Epoch 58/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3612 - val_loss: 7.6296\n",
      "Epoch 59/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3227 - val_loss: 7.2777\n",
      "Epoch 60/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.2614 - val_loss: 7.1932\n",
      "Epoch 61/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.2514 - val_loss: 7.3144\n",
      "Epoch 62/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.4147 - val_loss: 7.2635\n",
      "Epoch 63/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.6722 - val_loss: 7.5749\n",
      "Epoch 64/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.6929 - val_loss: 6.9873\n",
      "Epoch 65/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1833 - val_loss: 7.2542\n",
      "Epoch 66/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.2449 - val_loss: 7.1207\n",
      "Epoch 67/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.1658 - val_loss: 7.2421\n",
      "Epoch 68/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1201 - val_loss: 6.9943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1683 - val_loss: 7.2298\n",
      "Epoch 70/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.2456 - val_loss: 7.0825\n",
      "Epoch 71/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.2901 - val_loss: 7.4210\n",
      "Epoch 72/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9856 - val_loss: 7.2983\n",
      "Epoch 73/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3164 - val_loss: 7.3068\n",
      "Epoch 74/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1279 - val_loss: 6.9523\n",
      "Epoch 75/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.2750 - val_loss: 6.9835\n",
      "Epoch 76/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.2021 - val_loss: 7.3953\n",
      "Epoch 77/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 8.0349 - val_loss: 7.3187\n",
      "Epoch 78/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.4534 - val_loss: 7.0596\n",
      "Epoch 79/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1236 - val_loss: 7.1458\n",
      "Epoch 80/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9325 - val_loss: 7.3227\n",
      "Epoch 81/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.1165 - val_loss: 7.0422\n",
      "Epoch 82/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9725 - val_loss: 6.7495\n",
      "Epoch 83/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8950 - val_loss: 7.3972\n",
      "Epoch 84/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.3100 - val_loss: 6.9816\n",
      "Epoch 85/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9444 - val_loss: 6.9933\n",
      "Epoch 86/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1676 - val_loss: 6.8967\n",
      "Epoch 87/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.0136 - val_loss: 7.0239\n",
      "Epoch 88/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.2577 - val_loss: 6.9640\n",
      "Epoch 89/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0215 - val_loss: 7.2419\n",
      "Epoch 90/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 7.0234 - val_loss: 6.6965\n",
      "Epoch 91/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.8986 - val_loss: 6.6978\n",
      "Epoch 92/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8514 - val_loss: 6.9648\n",
      "Epoch 93/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8343 - val_loss: 6.8435\n",
      "Epoch 94/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.8838 - val_loss: 6.7175\n",
      "Epoch 95/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 7.0338 - val_loss: 7.1380\n",
      "Epoch 96/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.9021 - val_loss: 6.6964\n",
      "Epoch 97/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7946 - val_loss: 6.7041\n",
      "Epoch 98/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8714 - val_loss: 7.1641\n",
      "Epoch 99/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.9945 - val_loss: 6.9093\n",
      "Epoch 100/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 7.3544 - val_loss: 7.1404\n",
      "Epoch 101/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0153 - val_loss: 6.7981\n",
      "Epoch 102/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8605 - val_loss: 6.6503\n",
      "Epoch 103/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.8344 - val_loss: 6.8450\n",
      "Epoch 104/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 6.8035 - val_loss: 6.7639\n",
      "Epoch 105/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7949 - val_loss: 6.9403\n",
      "Epoch 106/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7732 - val_loss: 7.0528\n",
      "Epoch 107/1000\n",
      "274/274 [==============================] - 0s 115us/step - loss: 6.8016 - val_loss: 6.7341\n",
      "Epoch 108/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 7.4049 - val_loss: 7.6912\n",
      "Epoch 109/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.3214 - val_loss: 6.7407\n",
      "Epoch 110/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 7.2310 - val_loss: 7.2322\n",
      "Epoch 111/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 7.2841 - val_loss: 7.2413\n",
      "Epoch 112/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.9724 - val_loss: 6.7602\n",
      "Epoch 113/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.1138 - val_loss: 7.1566\n",
      "Epoch 114/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 7.3071 - val_loss: 6.7603\n",
      "Epoch 115/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.1747 - val_loss: 7.2185\n",
      "Epoch 116/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.0054 - val_loss: 7.1325\n",
      "Epoch 117/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.7897 - val_loss: 6.9415\n",
      "Epoch 118/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.7290 - val_loss: 6.7921\n",
      "Epoch 119/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.6297 - val_loss: 6.8068\n",
      "Epoch 120/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.9134 - val_loss: 7.3866\n",
      "Epoch 121/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.8701 - val_loss: 6.8343\n",
      "Epoch 122/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.8115 - val_loss: 6.9013\n",
      "Epoch 123/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.8351 - val_loss: 7.1252\n",
      "Epoch 124/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6194 - val_loss: 6.9991\n",
      "Epoch 125/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7642 - val_loss: 6.9470\n",
      "Epoch 126/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.6666 - val_loss: 6.9347\n",
      "Epoch 127/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.7138 - val_loss: 7.2320\n",
      "Epoch 128/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.8682 - val_loss: 6.7296\n",
      "Epoch 129/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.7177 - val_loss: 7.2987\n",
      "Epoch 130/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6218 - val_loss: 7.0733\n",
      "Epoch 131/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6225 - val_loss: 6.7964\n",
      "Epoch 132/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6544 - val_loss: 6.8104\n",
      "Epoch 133/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 6.8974 - val_loss: 7.3076\n",
      "Epoch 134/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8340 - val_loss: 6.7110\n",
      "Epoch 135/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6436 - val_loss: 7.0116\n",
      "Epoch 136/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5561 - val_loss: 7.0154\n",
      "Epoch 137/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7791 - val_loss: 7.0417\n",
      "Epoch 138/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7248 - val_loss: 7.1006\n",
      "Epoch 139/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5931 - val_loss: 7.0107\n",
      "Epoch 140/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.5500 - val_loss: 6.9858\n",
      "Epoch 141/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 6.6209 - val_loss: 7.1731\n",
      "Epoch 142/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6184 - val_loss: 7.1870\n",
      "Epoch 143/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.8729 - val_loss: 6.9809\n",
      "Epoch 144/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5608 - val_loss: 6.9702\n",
      "Epoch 145/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7602 - val_loss: 7.1128\n",
      "Epoch 146/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 98us/step - loss: 6.8571 - val_loss: 7.0344\n",
      "Epoch 147/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6038 - val_loss: 7.0058\n",
      "Epoch 148/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.4912 - val_loss: 6.7746\n",
      "Epoch 149/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5768 - val_loss: 7.0195\n",
      "Epoch 150/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.4723 - val_loss: 7.1312\n",
      "Epoch 151/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5118 - val_loss: 6.8704\n",
      "Epoch 152/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6385 - val_loss: 6.8876\n",
      "Epoch 153/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6589 - val_loss: 7.2477\n",
      "Epoch 154/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.6301 - val_loss: 7.1422\n",
      "Epoch 155/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7208 - val_loss: 7.1923\n",
      "Epoch 156/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.6693 - val_loss: 6.9513\n",
      "Epoch 157/1000\n",
      "274/274 [==============================] - 0s 115us/step - loss: 6.9423 - val_loss: 7.1129\n",
      "Epoch 158/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0705 - val_loss: 7.1966\n",
      "Epoch 159/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5606 - val_loss: 7.0739\n",
      "Epoch 160/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.6069 - val_loss: 6.8480\n",
      "Epoch 161/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5202 - val_loss: 7.2019\n",
      "Epoch 162/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.4862 - val_loss: 6.9373\n",
      "Epoch 163/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6103 - val_loss: 7.0718\n",
      "Epoch 164/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.8998 - val_loss: 7.5768\n",
      "Epoch 165/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7661 - val_loss: 6.9360\n",
      "Epoch 166/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7378 - val_loss: 7.0785\n",
      "Epoch 167/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5840 - val_loss: 7.2572\n",
      "Epoch 168/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5781 - val_loss: 6.8865\n",
      "Epoch 169/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.6626 - val_loss: 7.2481\n",
      "Epoch 170/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.7922 - val_loss: 6.9454\n",
      "Epoch 171/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7388 - val_loss: 7.3553\n",
      "Epoch 172/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.8063 - val_loss: 7.5527\n",
      "Epoch 173/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.6978 - val_loss: 7.7460\n",
      "Epoch 174/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0569 - val_loss: 6.9797\n",
      "Epoch 175/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4768 - val_loss: 7.0360\n",
      "Epoch 176/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.5401 - val_loss: 7.1926\n",
      "Epoch 177/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3507 - val_loss: 7.0058\n",
      "Epoch 178/1000\n",
      "274/274 [==============================] - 0s 135us/step - loss: 6.4741 - val_loss: 6.9638\n",
      "Epoch 179/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 6.5531 - val_loss: 7.6196\n",
      "Epoch 180/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.5305 - val_loss: 7.0895\n",
      "Epoch 181/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.4288 - val_loss: 7.2883\n",
      "Epoch 182/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.1491 - val_loss: 7.6455\n",
      "Epoch 183/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.9950 - val_loss: 7.8720\n",
      "Epoch 184/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.8226 - val_loss: 7.0779\n",
      "Epoch 185/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 7.0414 - val_loss: 6.8191\n",
      "Epoch 186/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.9331 - val_loss: 7.0682\n",
      "Epoch 187/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.1184 - val_loss: 7.2591\n",
      "Epoch 188/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.7539 - val_loss: 7.2377\n",
      "Epoch 189/1000\n",
      "274/274 [==============================] - 0s 117us/step - loss: 6.4139 - val_loss: 7.0494\n",
      "Epoch 190/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.6064 - val_loss: 7.1617\n",
      "Epoch 191/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5858 - val_loss: 7.4358\n",
      "Epoch 192/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.8286 - val_loss: 7.1674\n",
      "Epoch 193/1000\n",
      "274/274 [==============================] - 0s 135us/step - loss: 6.5938 - val_loss: 6.9256\n",
      "Epoch 194/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 6.5804 - val_loss: 7.2418\n",
      "Epoch 195/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5153 - val_loss: 7.1408\n",
      "Epoch 196/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3574 - val_loss: 6.7781\n",
      "Epoch 197/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.4591 - val_loss: 7.0675\n",
      "Epoch 198/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.3454 - val_loss: 7.1353\n",
      "Epoch 199/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.4424 - val_loss: 7.1956\n",
      "Epoch 200/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.5917 - val_loss: 6.9051\n",
      "Epoch 201/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.3562 - val_loss: 7.3229\n",
      "Epoch 202/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3609 - val_loss: 7.1294\n",
      "Epoch 203/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.4110 - val_loss: 6.8478\n",
      "Epoch 204/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 6.6161 - val_loss: 6.9731\n",
      "Epoch 205/1000\n",
      "274/274 [==============================] - 0s 153us/step - loss: 6.8062 - val_loss: 7.1500\n",
      "Epoch 206/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3819 - val_loss: 7.2072\n",
      "Epoch 207/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2916 - val_loss: 7.1763\n",
      "Epoch 208/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.4483 - val_loss: 7.2077\n",
      "Epoch 209/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3271 - val_loss: 6.9150\n",
      "Epoch 210/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.4052 - val_loss: 7.2519\n",
      "Epoch 211/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7012 - val_loss: 6.9641\n",
      "Epoch 212/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7127 - val_loss: 7.6682\n",
      "Epoch 213/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7746 - val_loss: 7.2199\n",
      "Epoch 214/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.5902 - val_loss: 6.8361\n",
      "Epoch 215/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7671 - val_loss: 6.8617\n",
      "Epoch 216/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3586 - val_loss: 7.4363\n",
      "Epoch 217/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3579 - val_loss: 6.9316\n",
      "Epoch 218/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.3837 - val_loss: 6.8810\n",
      "Epoch 219/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4591 - val_loss: 7.1620\n",
      "Epoch 220/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.3398 - val_loss: 6.9211\n",
      "Epoch 221/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5589 - val_loss: 7.1315\n",
      "Epoch 222/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5522 - val_loss: 7.0468\n",
      "Epoch 223/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 6.4729 - val_loss: 7.1665\n",
      "Epoch 224/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3860 - val_loss: 7.0623\n",
      "Epoch 225/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.3582 - val_loss: 7.1402\n",
      "Epoch 226/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3082 - val_loss: 7.0736\n",
      "Epoch 227/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.3099 - val_loss: 6.7786\n",
      "Epoch 228/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3860 - val_loss: 7.3330\n",
      "Epoch 229/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3882 - val_loss: 7.0319\n",
      "Epoch 230/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4742 - val_loss: 6.7373\n",
      "Epoch 231/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.2726 - val_loss: 7.1913\n",
      "Epoch 232/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.2484 - val_loss: 7.0772\n",
      "Epoch 233/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4409 - val_loss: 7.0283\n",
      "Epoch 234/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3021 - val_loss: 6.9959\n",
      "Epoch 235/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5023 - val_loss: 7.2007\n",
      "Epoch 236/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4556 - val_loss: 7.1671\n",
      "Epoch 237/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.3712 - val_loss: 6.8332\n",
      "Epoch 238/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4112 - val_loss: 7.0648\n",
      "Epoch 239/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1933 - val_loss: 7.2500\n",
      "Epoch 240/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2579 - val_loss: 7.0118\n",
      "Epoch 241/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.2508 - val_loss: 6.9729\n",
      "Epoch 242/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3764 - val_loss: 6.8753\n",
      "Epoch 243/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3242 - val_loss: 7.4572\n",
      "Epoch 244/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.2941 - val_loss: 6.8224\n",
      "Epoch 245/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 6.5724 - val_loss: 7.2928\n",
      "Epoch 246/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3385 - val_loss: 7.7451\n",
      "Epoch 247/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.7730 - val_loss: 7.9412\n",
      "Epoch 248/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.1399 - val_loss: 8.9485\n",
      "Epoch 249/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3834 - val_loss: 7.6152\n",
      "Epoch 250/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8270 - val_loss: 7.6429\n",
      "Epoch 251/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2420 - val_loss: 7.2854\n",
      "Epoch 252/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5938 - val_loss: 7.3169\n",
      "Epoch 253/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2434 - val_loss: 6.9457\n",
      "Epoch 254/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 6.1523 - val_loss: 7.2929\n",
      "Epoch 255/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1912 - val_loss: 7.0428\n",
      "Epoch 256/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.1345 - val_loss: 7.1807\n",
      "Epoch 257/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.1531 - val_loss: 6.8145\n",
      "Epoch 258/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2078 - val_loss: 6.8688\n",
      "Epoch 259/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1686 - val_loss: 7.0848\n",
      "Epoch 260/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3544 - val_loss: 6.8328\n",
      "Epoch 261/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2117 - val_loss: 6.6110\n",
      "Epoch 262/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.2530 - val_loss: 7.2681\n",
      "Epoch 263/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.2956 - val_loss: 7.1934\n",
      "Epoch 264/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.1071 - val_loss: 7.0501\n",
      "Epoch 265/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1178 - val_loss: 7.0422\n",
      "Epoch 266/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0416 - val_loss: 7.1965\n",
      "Epoch 267/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.3046 - val_loss: 7.4308\n",
      "Epoch 268/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2103 - val_loss: 7.4882\n",
      "Epoch 269/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.2936 - val_loss: 7.3466\n",
      "Epoch 270/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 6.0691 - val_loss: 7.3328\n",
      "Epoch 271/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.1782 - val_loss: 7.0277\n",
      "Epoch 272/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.3322 - val_loss: 7.0106\n",
      "Epoch 273/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6398 - val_loss: 7.0876\n",
      "Epoch 274/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.2849 - val_loss: 7.3492\n",
      "Epoch 275/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.3337 - val_loss: 7.6328\n",
      "Epoch 276/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2442 - val_loss: 7.3979\n",
      "Epoch 277/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.6792 - val_loss: 7.0619\n",
      "Epoch 278/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.6874 - val_loss: 7.4008\n",
      "Epoch 279/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6098 - val_loss: 7.4288\n",
      "Epoch 280/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.3882 - val_loss: 6.8631\n",
      "Epoch 281/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2933 - val_loss: 6.7638\n",
      "Epoch 282/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.2872 - val_loss: 7.0860\n",
      "Epoch 283/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1620 - val_loss: 6.7944\n",
      "Epoch 284/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 6.3073 - val_loss: 7.0927\n",
      "Epoch 285/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1712 - val_loss: 7.0899\n",
      "Epoch 286/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3337 - val_loss: 6.8977\n",
      "Epoch 287/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4032 - val_loss: 7.3519\n",
      "Epoch 288/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5512 - val_loss: 7.8490\n",
      "Epoch 289/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5091 - val_loss: 7.3631\n",
      "Epoch 290/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.1874 - val_loss: 6.8735\n",
      "Epoch 291/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1283 - val_loss: 6.9136\n",
      "Epoch 292/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 6.1775 - val_loss: 7.1201\n",
      "Epoch 293/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.0632 - val_loss: 7.4512\n",
      "Epoch 294/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3426 - val_loss: 6.9706\n",
      "Epoch 295/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2134 - val_loss: 7.0596\n",
      "Epoch 296/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.2817 - val_loss: 7.0062\n",
      "Epoch 297/1000\n",
      "274/274 [==============================] - 0s 119us/step - loss: 6.0631 - val_loss: 7.2469\n",
      "Epoch 298/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.0228 - val_loss: 6.9019\n",
      "Epoch 299/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.0355 - val_loss: 6.8842\n",
      "Epoch 300/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 113us/step - loss: 6.4246 - val_loss: 7.8721\n",
      "Epoch 301/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5701 - val_loss: 7.0586\n",
      "Epoch 302/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0744 - val_loss: 7.1040\n",
      "Epoch 303/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2884 - val_loss: 7.4393\n",
      "Epoch 304/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 6.0583 - val_loss: 7.0468\n",
      "Epoch 305/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1643 - val_loss: 7.1143\n",
      "Epoch 306/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 6.1445 - val_loss: 7.2287\n",
      "Epoch 307/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.0421 - val_loss: 6.9613\n",
      "Epoch 308/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.0253 - val_loss: 7.0061\n",
      "Epoch 309/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0051 - val_loss: 7.0317\n",
      "Epoch 310/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.0758 - val_loss: 6.9859\n",
      "Epoch 311/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3155 - val_loss: 7.1178\n",
      "Epoch 312/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0246 - val_loss: 6.7836\n",
      "Epoch 313/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.0850 - val_loss: 7.0617\n",
      "Epoch 314/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.0585 - val_loss: 6.9424\n",
      "Epoch 315/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3700 - val_loss: 7.6759\n",
      "Epoch 316/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.3245 - val_loss: 6.9930\n",
      "Epoch 317/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0897 - val_loss: 7.2475\n",
      "Epoch 318/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.2678 - val_loss: 6.7842\n",
      "Epoch 319/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6498 - val_loss: 6.9654\n",
      "Epoch 320/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.4227 - val_loss: 7.8456\n",
      "Epoch 321/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4872 - val_loss: 7.3769\n",
      "Epoch 322/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1215 - val_loss: 6.8595\n",
      "Epoch 323/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2541 - val_loss: 6.9591\n",
      "Epoch 324/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.0758 - val_loss: 6.9110\n",
      "Epoch 325/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9802 - val_loss: 7.0484\n",
      "Epoch 326/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9570 - val_loss: 6.8741\n",
      "Epoch 327/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8741 - val_loss: 7.2215\n",
      "Epoch 328/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4712 - val_loss: 7.3022\n",
      "Epoch 329/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9384 - val_loss: 7.1745\n",
      "Epoch 330/1000\n",
      "274/274 [==============================] - 0s 167us/step - loss: 6.0139 - val_loss: 7.0148\n",
      "Epoch 331/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.9887 - val_loss: 7.0280\n",
      "Epoch 332/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9734 - val_loss: 6.8529\n",
      "Epoch 333/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9122 - val_loss: 7.2100\n",
      "Epoch 334/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.0457 - val_loss: 7.2174\n",
      "Epoch 335/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1874 - val_loss: 7.2657\n",
      "Epoch 336/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4291 - val_loss: 6.7221\n",
      "Epoch 337/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9767 - val_loss: 7.1362\n",
      "Epoch 338/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9970 - val_loss: 7.2345\n",
      "Epoch 339/1000\n",
      "274/274 [==============================] - 0s 117us/step - loss: 6.0785 - val_loss: 7.1572\n",
      "Epoch 340/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 5.9719 - val_loss: 6.9607\n",
      "Epoch 341/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.9747 - val_loss: 7.0686\n",
      "Epoch 342/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.1364 - val_loss: 6.7062\n",
      "Epoch 343/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.3780 - val_loss: 7.4132\n",
      "Epoch 344/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9372 - val_loss: 7.9721\n",
      "Epoch 345/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.3061 - val_loss: 7.4749\n",
      "Epoch 346/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.0710 - val_loss: 7.6684\n",
      "Epoch 347/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3052 - val_loss: 8.0275\n",
      "Epoch 348/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.4119 - val_loss: 8.0843\n",
      "Epoch 349/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 6.5035 - val_loss: 7.1084\n",
      "Epoch 350/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.9704 - val_loss: 7.3336\n",
      "Epoch 351/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.9517 - val_loss: 7.1646\n",
      "Epoch 352/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 6.0703 - val_loss: 6.7988\n",
      "Epoch 353/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 6.0231 - val_loss: 7.2897\n",
      "Epoch 354/1000\n",
      "274/274 [==============================] - 0s 119us/step - loss: 6.0263 - val_loss: 7.4133\n",
      "Epoch 355/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9549 - val_loss: 7.2543\n",
      "Epoch 356/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9609 - val_loss: 6.7988\n",
      "Epoch 357/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3103 - val_loss: 6.9094\n",
      "Epoch 358/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0415 - val_loss: 7.1666\n",
      "Epoch 359/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1343 - val_loss: 7.4998\n",
      "Epoch 360/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0605 - val_loss: 7.1154\n",
      "Epoch 361/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.0062 - val_loss: 7.1976\n",
      "Epoch 362/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2516 - val_loss: 6.8825\n",
      "Epoch 363/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.0275 - val_loss: 7.2785\n",
      "Epoch 364/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.9973 - val_loss: 6.8393\n",
      "Epoch 365/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9913 - val_loss: 7.0166\n",
      "Epoch 366/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0842 - val_loss: 6.7506\n",
      "Epoch 367/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4263 - val_loss: 7.5033\n",
      "Epoch 368/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.2672 - val_loss: 7.7133\n",
      "Epoch 369/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.3933 - val_loss: 7.1092\n",
      "Epoch 370/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 6.1485 - val_loss: 7.3060\n",
      "Epoch 371/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 5.9594 - val_loss: 6.9740\n",
      "Epoch 372/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.0772 - val_loss: 6.8057\n",
      "Epoch 373/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.9409 - val_loss: 7.2463\n",
      "Epoch 374/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.8674 - val_loss: 6.8747\n",
      "Epoch 375/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9570 - val_loss: 7.2923\n",
      "Epoch 376/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0623 - val_loss: 6.9887\n",
      "Epoch 377/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 106us/step - loss: 5.9165 - val_loss: 7.0289\n",
      "Epoch 378/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8180 - val_loss: 7.0015\n",
      "Epoch 379/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.9155 - val_loss: 7.1116\n",
      "Epoch 380/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1141 - val_loss: 7.0088\n",
      "Epoch 381/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4077 - val_loss: 7.8512\n",
      "Epoch 382/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.0160 - val_loss: 7.5488\n",
      "Epoch 383/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 6.4118 - val_loss: 7.7990\n",
      "Epoch 384/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.5296 - val_loss: 7.7128\n",
      "Epoch 385/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.0478 - val_loss: 6.5956\n",
      "Epoch 386/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8818 - val_loss: 6.9441\n",
      "Epoch 387/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0176 - val_loss: 7.2372\n",
      "Epoch 388/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1020 - val_loss: 7.0824\n",
      "Epoch 389/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9342 - val_loss: 7.1925\n",
      "Epoch 390/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9510 - val_loss: 6.9856\n",
      "Epoch 391/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.0395 - val_loss: 7.0489\n",
      "Epoch 392/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.8108 - val_loss: 7.3183\n",
      "Epoch 393/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8062 - val_loss: 7.1591\n",
      "Epoch 394/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.0900 - val_loss: 6.8319\n",
      "Epoch 395/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.9819 - val_loss: 7.2102\n",
      "Epoch 396/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9277 - val_loss: 7.1063\n",
      "Epoch 397/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.2245 - val_loss: 7.5827\n",
      "Epoch 398/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1855 - val_loss: 6.6167\n",
      "Epoch 399/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.1206 - val_loss: 7.3965\n",
      "Epoch 400/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 6.1423 - val_loss: 7.3592\n",
      "Epoch 401/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0052 - val_loss: 7.2850\n",
      "Epoch 402/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8195 - val_loss: 6.9198\n",
      "Epoch 403/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9510 - val_loss: 7.0288\n",
      "Epoch 404/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9132 - val_loss: 6.8003\n",
      "Epoch 405/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.0337 - val_loss: 7.2389\n",
      "Epoch 406/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.0901 - val_loss: 6.8454\n",
      "Epoch 407/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1426 - val_loss: 7.5387\n",
      "Epoch 408/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1270 - val_loss: 7.6301\n",
      "Epoch 409/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9380 - val_loss: 7.1516\n",
      "Epoch 410/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8322 - val_loss: 7.0484\n",
      "Epoch 411/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9205 - val_loss: 7.2287\n",
      "Epoch 412/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1414 - val_loss: 7.5160\n",
      "Epoch 413/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.2182 - val_loss: 7.0597\n",
      "Epoch 414/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.9410 - val_loss: 6.9311\n",
      "Epoch 415/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.8832 - val_loss: 6.9906\n",
      "Epoch 416/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1128 - val_loss: 6.8451\n",
      "Epoch 417/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 7.1298 - val_loss: 8.5679\n",
      "Epoch 418/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.8963 - val_loss: 7.6460\n",
      "Epoch 419/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 6.0391 - val_loss: 7.8822\n",
      "Epoch 420/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.7447 - val_loss: 8.0433\n",
      "Epoch 421/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0512 - val_loss: 7.2733\n",
      "Epoch 422/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2619 - val_loss: 7.3871\n",
      "Epoch 423/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.8939 - val_loss: 7.1180\n",
      "Epoch 424/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.0139 - val_loss: 6.7424\n",
      "Epoch 425/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.3604 - val_loss: 7.5338\n",
      "Epoch 426/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8890 - val_loss: 7.5311\n",
      "Epoch 427/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.0429 - val_loss: 7.5138\n",
      "Epoch 428/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 6.3939 - val_loss: 7.4503\n",
      "Epoch 429/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0673 - val_loss: 7.0266\n",
      "Epoch 430/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.3429 - val_loss: 7.3139\n",
      "Epoch 431/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9404 - val_loss: 7.2034\n",
      "Epoch 432/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.0290 - val_loss: 7.6651\n",
      "Epoch 433/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1428 - val_loss: 7.2095\n",
      "Epoch 434/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9198 - val_loss: 7.2823\n",
      "Epoch 435/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.9021 - val_loss: 7.2490\n",
      "Epoch 436/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7500 - val_loss: 7.0249\n",
      "Epoch 437/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7728 - val_loss: 7.0501\n",
      "Epoch 438/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8478 - val_loss: 7.6119\n",
      "Epoch 439/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0616 - val_loss: 7.5088\n",
      "Epoch 440/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.9303 - val_loss: 7.4615\n",
      "Epoch 441/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8444 - val_loss: 7.1484\n",
      "Epoch 442/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.1523 - val_loss: 7.5265\n",
      "Epoch 443/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9202 - val_loss: 7.3617\n",
      "Epoch 444/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9940 - val_loss: 7.5647\n",
      "Epoch 445/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.4811 - val_loss: 7.5760\n",
      "Epoch 446/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4658 - val_loss: 7.2862\n",
      "Epoch 447/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.0141 - val_loss: 7.2170\n",
      "Epoch 448/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8918 - val_loss: 7.3554\n",
      "Epoch 449/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8365 - val_loss: 7.5449\n",
      "Epoch 450/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.8252 - val_loss: 7.3902\n",
      "Epoch 451/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9798 - val_loss: 7.1818\n",
      "Epoch 452/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8712 - val_loss: 7.5666\n",
      "Epoch 453/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8842 - val_loss: 7.4431\n",
      "Epoch 454/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 104us/step - loss: 6.0118 - val_loss: 7.3089\n",
      "Epoch 455/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.9427 - val_loss: 7.2805\n",
      "Epoch 456/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8981 - val_loss: 7.3003\n",
      "Epoch 457/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9643 - val_loss: 7.5007\n",
      "Epoch 458/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2377 - val_loss: 7.5313\n",
      "Epoch 459/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1308 - val_loss: 7.7522\n",
      "Epoch 460/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0820 - val_loss: 7.6384\n",
      "Epoch 461/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1255 - val_loss: 7.5973\n",
      "Epoch 462/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2409 - val_loss: 7.1199\n",
      "Epoch 463/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8054 - val_loss: 7.5006\n",
      "Epoch 464/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7914 - val_loss: 7.3114\n",
      "Epoch 465/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.9888 - val_loss: 7.3063\n",
      "Epoch 466/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1656 - val_loss: 7.3662\n",
      "Epoch 467/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1411 - val_loss: 7.7195\n",
      "Epoch 468/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9244 - val_loss: 7.1934\n",
      "Epoch 469/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7715 - val_loss: 7.5398\n",
      "Epoch 470/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6862 - val_loss: 7.2792\n",
      "Epoch 471/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7765 - val_loss: 6.9984\n",
      "Epoch 472/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.7924 - val_loss: 7.4441\n",
      "Epoch 473/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.2006 - val_loss: 7.6117\n",
      "Epoch 474/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.9468 - val_loss: 7.4578\n",
      "Epoch 475/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9656 - val_loss: 8.2118\n",
      "Epoch 476/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9941 - val_loss: 7.8865\n",
      "Epoch 477/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7970 - val_loss: 8.0599\n",
      "Epoch 478/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5171 - val_loss: 7.5803\n",
      "Epoch 479/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3481 - val_loss: 7.1159\n",
      "Epoch 480/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8853 - val_loss: 7.3359\n",
      "Epoch 481/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8896 - val_loss: 7.4033\n",
      "Epoch 482/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7881 - val_loss: 7.6278\n",
      "Epoch 483/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3294 - val_loss: 7.6123\n",
      "Epoch 484/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8407 - val_loss: 7.1656\n",
      "Epoch 485/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1868 - val_loss: 7.4693\n",
      "Epoch 486/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.5339 - val_loss: 8.1795\n",
      "Epoch 487/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4106 - val_loss: 7.3703\n",
      "Epoch 488/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.8870 - val_loss: 7.5752\n",
      "Epoch 489/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7044 - val_loss: 7.3801\n",
      "Epoch 490/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.7893 - val_loss: 7.1409\n",
      "Epoch 491/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.1117 - val_loss: 7.5318\n",
      "Epoch 492/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.7487 - val_loss: 7.6095\n",
      "Epoch 493/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.9701 - val_loss: 7.2326\n",
      "Epoch 494/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8697 - val_loss: 7.4957\n",
      "Epoch 495/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7768 - val_loss: 7.2658\n",
      "Epoch 496/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7083 - val_loss: 7.4915\n",
      "Epoch 497/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7393 - val_loss: 7.4016\n",
      "Epoch 498/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.6894 - val_loss: 7.3382\n",
      "Epoch 499/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.9794 - val_loss: 7.5058\n",
      "Epoch 500/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7761 - val_loss: 7.4325\n",
      "Epoch 501/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.2679 - val_loss: 7.6087\n",
      "Epoch 502/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0532 - val_loss: 7.7146\n",
      "Epoch 503/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7131 - val_loss: 7.7002\n",
      "Epoch 504/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3103 - val_loss: 7.1272\n",
      "Epoch 505/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8715 - val_loss: 7.7617\n",
      "Epoch 506/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3589 - val_loss: 7.8316\n",
      "Epoch 507/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.9956 - val_loss: 7.9565\n",
      "Epoch 508/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.9273 - val_loss: 7.5951\n",
      "Epoch 509/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.0207 - val_loss: 7.7199\n",
      "Epoch 510/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7751 - val_loss: 7.8184\n",
      "Epoch 511/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.8843 - val_loss: 7.2625\n",
      "Epoch 512/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7393 - val_loss: 7.4931\n",
      "Epoch 513/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8124 - val_loss: 7.5007\n",
      "Epoch 514/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.0321 - val_loss: 7.5112\n",
      "Epoch 515/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8865 - val_loss: 7.3864\n",
      "Epoch 516/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.7530 - val_loss: 7.3247\n",
      "Epoch 517/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8057 - val_loss: 7.4101\n",
      "Epoch 518/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7315 - val_loss: 7.2163\n",
      "Epoch 519/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.9809 - val_loss: 7.3437\n",
      "Epoch 520/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8272 - val_loss: 7.6096\n",
      "Epoch 521/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.8402 - val_loss: 7.1721\n",
      "Epoch 522/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7820 - val_loss: 7.4685\n",
      "Epoch 523/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6865 - val_loss: 7.2032\n",
      "Epoch 524/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8214 - val_loss: 7.2276\n",
      "Epoch 525/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7993 - val_loss: 7.7578\n",
      "Epoch 526/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9654 - val_loss: 7.1646\n",
      "Epoch 527/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.7344 - val_loss: 7.4198\n",
      "Epoch 528/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2496 - val_loss: 8.0901\n",
      "Epoch 529/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5583 - val_loss: 7.9211\n",
      "Epoch 530/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9918 - val_loss: 7.6871\n",
      "Epoch 531/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 105us/step - loss: 5.7746 - val_loss: 7.1636\n",
      "Epoch 532/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1237 - val_loss: 7.4433\n",
      "Epoch 533/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9292 - val_loss: 7.7683\n",
      "Epoch 534/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9586 - val_loss: 7.1913\n",
      "Epoch 535/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2830 - val_loss: 8.4123\n",
      "Epoch 536/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.1547 - val_loss: 7.1438\n",
      "Epoch 537/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 5.9017 - val_loss: 7.2862\n",
      "Epoch 538/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.7037 - val_loss: 7.7382\n",
      "Epoch 539/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.1372 - val_loss: 7.6262\n",
      "Epoch 540/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8441 - val_loss: 7.1695\n",
      "Epoch 541/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2135 - val_loss: 7.6906\n",
      "Epoch 542/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3424 - val_loss: 7.9691\n",
      "Epoch 543/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0283 - val_loss: 7.5252\n",
      "Epoch 544/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8647 - val_loss: 7.4138\n",
      "Epoch 545/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0174 - val_loss: 8.6275\n",
      "Epoch 546/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 6.1997 - val_loss: 8.1785\n",
      "Epoch 547/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6561 - val_loss: 8.2268\n",
      "Epoch 548/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9876 - val_loss: 8.0666\n",
      "Epoch 549/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6660 - val_loss: 8.0278\n",
      "Epoch 550/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.0252 - val_loss: 8.2038\n",
      "Epoch 551/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.9641 - val_loss: 8.7782\n",
      "Epoch 552/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2955 - val_loss: 7.9165\n",
      "Epoch 553/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.0792 - val_loss: 7.5605\n",
      "Epoch 554/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.7380 - val_loss: 7.2205\n",
      "Epoch 555/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.6792 - val_loss: 7.4314\n",
      "Epoch 556/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7584 - val_loss: 7.7028\n",
      "Epoch 557/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7255 - val_loss: 7.3501\n",
      "Epoch 558/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8064 - val_loss: 7.3677\n",
      "Epoch 559/1000\n",
      "274/274 [==============================] - 0s 115us/step - loss: 5.7188 - val_loss: 7.5281\n",
      "Epoch 560/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.6722 - val_loss: 7.1867\n",
      "Epoch 561/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8332 - val_loss: 7.7623\n",
      "Epoch 562/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.7095 - val_loss: 7.8812\n",
      "Epoch 563/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.7822 - val_loss: 7.5232\n",
      "Epoch 564/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9961 - val_loss: 7.4636\n",
      "Epoch 565/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8206 - val_loss: 8.0464\n",
      "Epoch 566/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3660 - val_loss: 7.8304\n",
      "Epoch 567/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6416 - val_loss: 7.4488\n",
      "Epoch 568/1000\n",
      "274/274 [==============================] - 0s 135us/step - loss: 5.7846 - val_loss: 7.4813\n",
      "Epoch 569/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.8207 - val_loss: 7.9553\n",
      "Epoch 570/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.8193 - val_loss: 7.3665\n",
      "Epoch 571/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7884 - val_loss: 7.8202\n",
      "Epoch 572/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.8431 - val_loss: 7.5495\n",
      "Epoch 573/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7022 - val_loss: 7.0415\n",
      "Epoch 574/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8005 - val_loss: 7.4659\n",
      "Epoch 575/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.7754 - val_loss: 7.3658\n",
      "Epoch 576/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8732 - val_loss: 7.5873\n",
      "Epoch 577/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.5860 - val_loss: 8.2302\n",
      "Epoch 578/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0192 - val_loss: 7.6322\n",
      "Epoch 579/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0364 - val_loss: 7.7450\n",
      "Epoch 580/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.7443 - val_loss: 7.2365\n",
      "Epoch 581/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7020 - val_loss: 7.3359\n",
      "Epoch 582/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7044 - val_loss: 7.4145\n",
      "Epoch 583/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7021 - val_loss: 7.3330\n",
      "Epoch 584/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1915 - val_loss: 8.0406\n",
      "Epoch 585/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7641 - val_loss: 8.8074\n",
      "Epoch 586/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4519 - val_loss: 7.9826\n",
      "Epoch 587/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 6.0049 - val_loss: 7.6527\n",
      "Epoch 588/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8884 - val_loss: 8.9244\n",
      "Epoch 589/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7120 - val_loss: 8.3023\n",
      "Epoch 590/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6412 - val_loss: 8.0642\n",
      "Epoch 591/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 6.2711 - val_loss: 7.2735\n",
      "Epoch 592/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8328 - val_loss: 7.3041\n",
      "Epoch 593/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6454 - val_loss: 7.1593\n",
      "Epoch 594/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9879 - val_loss: 7.8851\n",
      "Epoch 595/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5629 - val_loss: 7.6872\n",
      "Epoch 596/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.7780 - val_loss: 7.5915\n",
      "Epoch 597/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7257 - val_loss: 7.1971\n",
      "Epoch 598/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6490 - val_loss: 7.6018\n",
      "Epoch 599/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.9041 - val_loss: 7.7010\n",
      "Epoch 600/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1644 - val_loss: 7.7526\n",
      "Epoch 601/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5398 - val_loss: 7.8300\n",
      "Epoch 602/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9957 - val_loss: 7.6609\n",
      "Epoch 603/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8942 - val_loss: 7.3654\n",
      "Epoch 604/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.6968 - val_loss: 7.4324\n",
      "Epoch 605/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6674 - val_loss: 7.3965\n",
      "Epoch 606/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.8767 - val_loss: 7.5333\n",
      "Epoch 607/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8001 - val_loss: 7.4263\n",
      "Epoch 608/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 106us/step - loss: 5.7215 - val_loss: 7.3117\n",
      "Epoch 609/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8171 - val_loss: 7.8452\n",
      "Epoch 610/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.0398 - val_loss: 7.3390\n",
      "Epoch 611/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7612 - val_loss: 7.5519\n",
      "Epoch 612/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9006 - val_loss: 7.4627\n",
      "Epoch 613/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6698 - val_loss: 7.3053\n",
      "Epoch 614/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6900 - val_loss: 7.4680\n",
      "Epoch 615/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6702 - val_loss: 7.2670\n",
      "Epoch 616/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6563 - val_loss: 7.5391\n",
      "Epoch 617/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8787 - val_loss: 7.6118\n",
      "Epoch 618/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.2578 - val_loss: 7.5726\n",
      "Epoch 619/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.3286 - val_loss: 7.9976\n",
      "Epoch 620/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.9356 - val_loss: 7.3443\n",
      "Epoch 621/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9012 - val_loss: 7.6312\n",
      "Epoch 622/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9323 - val_loss: 7.9886\n",
      "Epoch 623/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.8280 - val_loss: 7.3714\n",
      "Epoch 624/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.8246 - val_loss: 7.9955\n",
      "Epoch 625/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 6.7340 - val_loss: 8.5106\n",
      "Epoch 626/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9162 - val_loss: 8.1009\n",
      "Epoch 627/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6947 - val_loss: 7.1139\n",
      "Epoch 628/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6253 - val_loss: 7.3370\n",
      "Epoch 629/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8223 - val_loss: 7.5038\n",
      "Epoch 630/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1477 - val_loss: 7.3806\n",
      "Epoch 631/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6896 - val_loss: 7.2523\n",
      "Epoch 632/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8415 - val_loss: 7.6178\n",
      "Epoch 633/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9062 - val_loss: 7.8034\n",
      "Epoch 634/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7900 - val_loss: 7.3026\n",
      "Epoch 635/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.6460 - val_loss: 7.4487\n",
      "Epoch 636/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.8528 - val_loss: 7.7503\n",
      "Epoch 637/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.7217 - val_loss: 7.3323\n",
      "Epoch 638/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2129 - val_loss: 8.1343\n",
      "Epoch 639/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0669 - val_loss: 7.3800\n",
      "Epoch 640/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7961 - val_loss: 7.2281\n",
      "Epoch 641/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6474 - val_loss: 7.8026\n",
      "Epoch 642/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6386 - val_loss: 7.4165\n",
      "Epoch 643/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7979 - val_loss: 7.8694\n",
      "Epoch 644/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.8937 - val_loss: 7.6151\n",
      "Epoch 645/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.7041 - val_loss: 7.5530\n",
      "Epoch 646/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.0945 - val_loss: 7.5992\n",
      "Epoch 647/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2434 - val_loss: 8.2523\n",
      "Epoch 648/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4499 - val_loss: 7.6295\n",
      "Epoch 649/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7573 - val_loss: 7.6957\n",
      "Epoch 650/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9616 - val_loss: 7.9877\n",
      "Epoch 651/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7035 - val_loss: 7.4620\n",
      "Epoch 652/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6838 - val_loss: 7.4216\n",
      "Epoch 653/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6885 - val_loss: 7.5180\n",
      "Epoch 654/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9081 - val_loss: 7.3750\n",
      "Epoch 655/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.0266 - val_loss: 7.5101\n",
      "Epoch 656/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7726 - val_loss: 8.0851\n",
      "Epoch 657/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4092 - val_loss: 7.4327\n",
      "Epoch 658/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7002 - val_loss: 7.3234\n",
      "Epoch 659/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0102 - val_loss: 7.6177\n",
      "Epoch 660/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7747 - val_loss: 7.5836\n",
      "Epoch 661/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.9491 - val_loss: 8.2051\n",
      "Epoch 662/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8126 - val_loss: 7.6098\n",
      "Epoch 663/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1054 - val_loss: 7.7702\n",
      "Epoch 664/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1015 - val_loss: 7.2733\n",
      "Epoch 665/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8590 - val_loss: 7.4223\n",
      "Epoch 666/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2544 - val_loss: 7.8825\n",
      "Epoch 667/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.6000 - val_loss: 7.6558\n",
      "Epoch 668/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8322 - val_loss: 7.2190\n",
      "Epoch 669/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9799 - val_loss: 7.9422\n",
      "Epoch 670/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7701 - val_loss: 7.6603\n",
      "Epoch 671/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7253 - val_loss: 7.3330\n",
      "Epoch 672/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6798 - val_loss: 7.2412\n",
      "Epoch 673/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8622 - val_loss: 7.3329\n",
      "Epoch 674/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6873 - val_loss: 7.5973\n",
      "Epoch 675/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8329 - val_loss: 7.3179\n",
      "Epoch 676/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6249 - val_loss: 7.4612\n",
      "Epoch 677/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5924 - val_loss: 7.3902\n",
      "Epoch 678/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1851 - val_loss: 7.8783\n",
      "Epoch 679/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0388 - val_loss: 7.8759\n",
      "Epoch 680/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8232 - val_loss: 7.2355\n",
      "Epoch 681/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6141 - val_loss: 7.3798\n",
      "Epoch 682/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.6589 - val_loss: 7.2769\n",
      "Epoch 683/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7467 - val_loss: 7.8392\n",
      "Epoch 684/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6103 - val_loss: 7.3623\n",
      "Epoch 685/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 99us/step - loss: 5.8023 - val_loss: 7.3341\n",
      "Epoch 686/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7416 - val_loss: 7.7584\n",
      "Epoch 687/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6281 - val_loss: 7.2019\n",
      "Epoch 688/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6343 - val_loss: 7.2686\n",
      "Epoch 689/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6019 - val_loss: 7.6707\n",
      "Epoch 690/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7131 - val_loss: 7.8294\n",
      "Epoch 691/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.7815 - val_loss: 7.5575\n",
      "Epoch 692/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0338 - val_loss: 7.8344\n",
      "Epoch 693/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9423 - val_loss: 7.4959\n",
      "Epoch 694/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9011 - val_loss: 7.5120\n",
      "Epoch 695/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7530 - val_loss: 7.2549\n",
      "Epoch 696/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7520 - val_loss: 7.4597\n",
      "Epoch 697/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.8234 - val_loss: 7.9945\n",
      "Epoch 698/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7577 - val_loss: 7.3888\n",
      "Epoch 699/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6473 - val_loss: 7.6814\n",
      "Epoch 700/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5653 - val_loss: 7.6921\n",
      "Epoch 701/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0170 - val_loss: 7.3495\n",
      "Epoch 702/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5671 - val_loss: 7.4057\n",
      "Epoch 703/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6016 - val_loss: 7.8358\n",
      "Epoch 704/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.7690 - val_loss: 8.0096\n",
      "Epoch 705/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8784 - val_loss: 7.7717\n",
      "Epoch 706/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7540 - val_loss: 7.6965\n",
      "Epoch 707/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8774 - val_loss: 7.3998\n",
      "Epoch 708/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7212 - val_loss: 7.6904\n",
      "Epoch 709/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.6380 - val_loss: 7.5693\n",
      "Epoch 710/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4742 - val_loss: 7.8262\n",
      "Epoch 711/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7980 - val_loss: 7.4124\n",
      "Epoch 712/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6937 - val_loss: 7.8534\n",
      "Epoch 713/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.8717 - val_loss: 7.3293\n",
      "Epoch 714/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6301 - val_loss: 7.4876\n",
      "Epoch 715/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8415 - val_loss: 7.5431\n",
      "Epoch 716/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7559 - val_loss: 7.1969\n",
      "Epoch 717/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.0673 - val_loss: 7.9108\n",
      "Epoch 718/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2474 - val_loss: 8.0493\n",
      "Epoch 719/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.6712 - val_loss: 8.2384\n",
      "Epoch 720/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.8212 - val_loss: 8.1590\n",
      "Epoch 721/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 6.0845 - val_loss: 7.9801\n",
      "Epoch 722/1000\n",
      "274/274 [==============================] - 0s 117us/step - loss: 5.7248 - val_loss: 8.2398\n",
      "Epoch 723/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.6760 - val_loss: 7.7307\n",
      "Epoch 724/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.7088 - val_loss: 7.1488\n",
      "Epoch 725/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.8508 - val_loss: 7.5130\n",
      "Epoch 726/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.5411 - val_loss: 7.8414\n",
      "Epoch 727/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.5298 - val_loss: 8.6837\n",
      "Epoch 728/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0178 - val_loss: 7.7476\n",
      "Epoch 729/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5414 - val_loss: 7.5236\n",
      "Epoch 730/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 6.2744 - val_loss: 7.9605\n",
      "Epoch 731/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7919 - val_loss: 7.7966\n",
      "Epoch 732/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.0168 - val_loss: 7.7379\n",
      "Epoch 733/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.7850 - val_loss: 7.5510\n",
      "Epoch 734/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8743 - val_loss: 7.4379\n",
      "Epoch 735/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8102 - val_loss: 7.1660\n",
      "Epoch 736/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9802 - val_loss: 7.8235\n",
      "Epoch 737/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8253 - val_loss: 7.4307\n",
      "Epoch 738/1000\n",
      "274/274 [==============================] - 0s 138us/step - loss: 5.6815 - val_loss: 7.4695\n",
      "Epoch 739/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 5.6650 - val_loss: 7.5686\n",
      "Epoch 740/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7734 - val_loss: 7.4033\n",
      "Epoch 741/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.6854 - val_loss: 7.4341\n",
      "Epoch 742/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5678 - val_loss: 7.8877\n",
      "Epoch 743/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.8273 - val_loss: 7.6104\n",
      "Epoch 744/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7352 - val_loss: 6.9787\n",
      "Epoch 745/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5685 - val_loss: 7.5024\n",
      "Epoch 746/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.7382 - val_loss: 7.5832\n",
      "Epoch 747/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6442 - val_loss: 7.3837\n",
      "Epoch 748/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7242 - val_loss: 7.3873\n",
      "Epoch 749/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6588 - val_loss: 7.4927\n",
      "Epoch 750/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6496 - val_loss: 7.2368\n",
      "Epoch 751/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6858 - val_loss: 7.1651\n",
      "Epoch 752/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6995 - val_loss: 7.5104\n",
      "Epoch 753/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8777 - val_loss: 7.4056\n",
      "Epoch 754/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.9378 - val_loss: 8.1714\n",
      "Epoch 755/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8317 - val_loss: 7.8455\n",
      "Epoch 756/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7503 - val_loss: 7.3085\n",
      "Epoch 757/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5958 - val_loss: 7.4846\n",
      "Epoch 758/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.6018 - val_loss: 7.3594\n",
      "Epoch 759/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6182 - val_loss: 7.2506\n",
      "Epoch 760/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7491 - val_loss: 7.6432\n",
      "Epoch 761/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8941 - val_loss: 7.9857\n",
      "Epoch 762/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 98us/step - loss: 5.9282 - val_loss: 7.9652\n",
      "Epoch 763/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5994 - val_loss: 8.1570\n",
      "Epoch 764/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5801 - val_loss: 8.9797\n",
      "Epoch 765/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.4459 - val_loss: 8.5097\n",
      "Epoch 766/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0981 - val_loss: 7.6356\n",
      "Epoch 767/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.7959 - val_loss: 7.0928\n",
      "Epoch 768/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7059 - val_loss: 7.5299\n",
      "Epoch 769/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7178 - val_loss: 7.6705\n",
      "Epoch 770/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 5.855 - 0s 106us/step - loss: 5.7615 - val_loss: 7.1977\n",
      "Epoch 771/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6773 - val_loss: 7.2191\n",
      "Epoch 772/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6399 - val_loss: 7.9367\n",
      "Epoch 773/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.5820 - val_loss: 7.3596\n",
      "Epoch 774/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7874 - val_loss: 7.3080\n",
      "Epoch 775/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4700 - val_loss: 7.7797\n",
      "Epoch 776/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1715 - val_loss: 7.9881\n",
      "Epoch 777/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7195 - val_loss: 7.5233\n",
      "Epoch 778/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5057 - val_loss: 7.5432\n",
      "Epoch 779/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5797 - val_loss: 7.5227\n",
      "Epoch 780/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5997 - val_loss: 7.7446\n",
      "Epoch 781/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9005 - val_loss: 7.2013\n",
      "Epoch 782/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.1226 - val_loss: 7.5486\n",
      "Epoch 783/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8708 - val_loss: 7.4730\n",
      "Epoch 784/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7661 - val_loss: 7.2681\n",
      "Epoch 785/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6899 - val_loss: 7.1840\n",
      "Epoch 786/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6616 - val_loss: 7.3590\n",
      "Epoch 787/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5522 - val_loss: 7.3414\n",
      "Epoch 788/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8676 - val_loss: 7.7527\n",
      "Epoch 789/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7582 - val_loss: 7.6107\n",
      "Epoch 790/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.1431 - val_loss: 7.0806\n",
      "Epoch 791/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.9145 - val_loss: 7.3186\n",
      "Epoch 792/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7453 - val_loss: 7.2007\n",
      "Epoch 793/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7686 - val_loss: 7.4969\n",
      "Epoch 794/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8525 - val_loss: 7.5477\n",
      "Epoch 795/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7650 - val_loss: 7.5298\n",
      "Epoch 796/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5997 - val_loss: 7.2713\n",
      "Epoch 797/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7533 - val_loss: 7.4049\n",
      "Epoch 798/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6769 - val_loss: 7.5459\n",
      "Epoch 799/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0232 - val_loss: 7.8037\n",
      "Epoch 800/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.8803 - val_loss: 7.3492\n",
      "Epoch 801/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8147 - val_loss: 7.2883\n",
      "Epoch 802/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.0471 - val_loss: 7.6416\n",
      "Epoch 803/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.9091 - val_loss: 7.2148\n",
      "Epoch 804/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6975 - val_loss: 7.6007\n",
      "Epoch 805/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5724 - val_loss: 7.7117\n",
      "Epoch 806/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6288 - val_loss: 7.3874\n",
      "Epoch 807/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.6712 - val_loss: 7.6875\n",
      "Epoch 808/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0181 - val_loss: 7.7653\n",
      "Epoch 809/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.8434 - val_loss: 7.8092\n",
      "Epoch 810/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7180 - val_loss: 7.1367\n",
      "Epoch 811/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.7505 - val_loss: 7.6130\n",
      "Epoch 812/1000\n",
      "274/274 [==============================] - 0s 157us/step - loss: 5.8649 - val_loss: 7.3687\n",
      "Epoch 813/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.8531 - val_loss: 7.5309\n",
      "Epoch 814/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 5.6078 - val_loss: 7.4738\n",
      "Epoch 815/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7103 - val_loss: 7.1241\n",
      "Epoch 816/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5910 - val_loss: 7.4883\n",
      "Epoch 817/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 5.6761 - val_loss: 7.4878\n",
      "Epoch 818/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7488 - val_loss: 7.5552\n",
      "Epoch 819/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1343 - val_loss: 7.6224\n",
      "Epoch 820/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.6333 - val_loss: 7.1479\n",
      "Epoch 821/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7960 - val_loss: 7.2191\n",
      "Epoch 822/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8884 - val_loss: 7.5724\n",
      "Epoch 823/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.8448 - val_loss: 7.3244\n",
      "Epoch 824/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 5.6863 - val_loss: 7.4966\n",
      "Epoch 825/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6906 - val_loss: 7.7592\n",
      "Epoch 826/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5968 - val_loss: 7.3613\n",
      "Epoch 827/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8170 - val_loss: 7.4183\n",
      "Epoch 828/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7092 - val_loss: 7.2852\n",
      "Epoch 829/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5717 - val_loss: 7.3902\n",
      "Epoch 830/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7970 - val_loss: 7.3525\n",
      "Epoch 831/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7662 - val_loss: 7.1535\n",
      "Epoch 832/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.6891 - val_loss: 7.6289\n",
      "Epoch 833/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.7900 - val_loss: 7.7102\n",
      "Epoch 834/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.7222 - val_loss: 7.1786\n",
      "Epoch 835/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5308 - val_loss: 7.7361\n",
      "Epoch 836/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8852 - val_loss: 7.4030\n",
      "Epoch 837/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.0205 - val_loss: 7.1188\n",
      "Epoch 838/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.8453 - val_loss: 7.3809\n",
      "Epoch 839/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 91us/step - loss: 5.6823 - val_loss: 7.3143\n",
      "Epoch 840/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6182 - val_loss: 7.5809\n",
      "Epoch 841/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7165 - val_loss: 7.4624\n",
      "Epoch 842/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8640 - val_loss: 7.2658\n",
      "Epoch 843/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6548 - val_loss: 7.2102\n",
      "Epoch 844/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0101 - val_loss: 7.7746\n",
      "Epoch 845/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.8248 - val_loss: 7.8914\n",
      "Epoch 846/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.1002 - val_loss: 8.4682\n",
      "Epoch 847/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.2346 - val_loss: 9.3638\n",
      "Epoch 848/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3660 - val_loss: 8.5991\n",
      "Epoch 849/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.2850 - val_loss: 8.5146\n",
      "Epoch 850/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8283 - val_loss: 7.5610\n",
      "Epoch 851/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8081 - val_loss: 7.7662\n",
      "Epoch 852/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5356 - val_loss: 7.5121\n",
      "Epoch 853/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.7408 - val_loss: 7.3954\n",
      "Epoch 854/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9992 - val_loss: 7.8285\n",
      "Epoch 855/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.5782 - val_loss: 7.2316\n",
      "Epoch 856/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.7232 - val_loss: 7.3094\n",
      "Epoch 857/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5292 - val_loss: 7.6995\n",
      "Epoch 858/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.7035 - val_loss: 7.5307\n",
      "Epoch 859/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.7494 - val_loss: 7.1984\n",
      "Epoch 860/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1051 - val_loss: 7.3400\n",
      "Epoch 861/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.0650 - val_loss: 8.0246\n",
      "Epoch 862/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9642 - val_loss: 7.7280\n",
      "Epoch 863/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4714 - val_loss: 7.3894\n",
      "Epoch 864/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2107 - val_loss: 7.9947\n",
      "Epoch 865/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9056 - val_loss: 8.1103\n",
      "Epoch 866/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6814 - val_loss: 7.7694\n",
      "Epoch 867/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0056 - val_loss: 7.6754\n",
      "Epoch 868/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.8083 - val_loss: 7.8403\n",
      "Epoch 869/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.3461 - val_loss: 7.5407\n",
      "Epoch 870/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5604 - val_loss: 7.1785\n",
      "Epoch 871/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 6.1554 - val_loss: 7.4881\n",
      "Epoch 872/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.6322 - val_loss: 7.3817\n",
      "Epoch 873/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7340 - val_loss: 7.6145\n",
      "Epoch 874/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8190 - val_loss: 7.3659\n",
      "Epoch 875/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8903 - val_loss: 7.2349\n",
      "Epoch 876/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.8678 - val_loss: 7.4514\n",
      "Epoch 877/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5531 - val_loss: 7.3085\n",
      "Epoch 878/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.5381 - val_loss: 7.2747\n",
      "Epoch 879/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4746 - val_loss: 7.3828\n",
      "Epoch 880/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0405 - val_loss: 8.2470\n",
      "Epoch 881/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.4315 - val_loss: 7.8748\n",
      "Epoch 882/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7701 - val_loss: 8.0622\n",
      "Epoch 883/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8790 - val_loss: 7.4652\n",
      "Epoch 884/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6073 - val_loss: 7.2697\n",
      "Epoch 885/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6974 - val_loss: 7.4688\n",
      "Epoch 886/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6905 - val_loss: 7.6346\n",
      "Epoch 887/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7438 - val_loss: 7.5307\n",
      "Epoch 888/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.6667 - val_loss: 7.7270\n",
      "Epoch 889/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.8734 - val_loss: 7.4674\n",
      "Epoch 890/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.8920 - val_loss: 7.7568\n",
      "Epoch 891/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.0126 - val_loss: 7.1480\n",
      "Epoch 892/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7333 - val_loss: 7.7452\n",
      "Epoch 893/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.6731 - val_loss: 7.2934\n",
      "Epoch 894/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7052 - val_loss: 7.5484\n",
      "Epoch 895/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.8057 - val_loss: 7.2985\n",
      "Epoch 896/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9117 - val_loss: 8.0420\n",
      "Epoch 897/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8065 - val_loss: 7.2139\n",
      "Epoch 898/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2289 - val_loss: 7.8189\n",
      "Epoch 899/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8463 - val_loss: 8.1833\n",
      "Epoch 900/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9770 - val_loss: 7.8649\n",
      "Epoch 901/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7389 - val_loss: 7.2394\n",
      "Epoch 902/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5654 - val_loss: 7.5642\n",
      "Epoch 903/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.7886 - val_loss: 7.3612\n",
      "Epoch 904/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0720 - val_loss: 7.8870\n",
      "Epoch 905/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.5817 - val_loss: 7.5738\n",
      "Epoch 906/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1906 - val_loss: 7.6391\n",
      "Epoch 907/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4278 - val_loss: 7.5216\n",
      "Epoch 908/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.8129 - val_loss: 7.2523\n",
      "Epoch 909/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5672 - val_loss: 7.4079\n",
      "Epoch 910/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6853 - val_loss: 7.4923\n",
      "Epoch 911/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5543 - val_loss: 7.3346\n",
      "Epoch 912/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6364 - val_loss: 7.2458\n",
      "Epoch 913/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.6587 - val_loss: 7.4488\n",
      "Epoch 914/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6352 - val_loss: 7.0894\n",
      "Epoch 915/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.7687 - val_loss: 7.7688\n",
      "Epoch 916/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.7550 - val_loss: 7.3756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 917/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.7809 - val_loss: 7.7305\n",
      "Epoch 918/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8527 - val_loss: 7.7282\n",
      "Epoch 919/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1183 - val_loss: 7.6050\n",
      "Epoch 920/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6579 - val_loss: 7.4417\n",
      "Epoch 921/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6278 - val_loss: 7.3350\n",
      "Epoch 922/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9560 - val_loss: 7.8867\n",
      "Epoch 923/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.6084 - val_loss: 8.4024\n",
      "Epoch 924/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0070 - val_loss: 8.0480\n",
      "Epoch 925/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.8392 - val_loss: 7.4843\n",
      "Epoch 926/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6560 - val_loss: 7.1492\n",
      "Epoch 927/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1803 - val_loss: 7.4592\n",
      "Epoch 928/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.7963 - val_loss: 8.2450\n",
      "Epoch 929/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3830 - val_loss: 7.7206\n",
      "Epoch 930/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.9904 - val_loss: 7.2617\n",
      "Epoch 931/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8175 - val_loss: 7.9724\n",
      "Epoch 932/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.9340 - val_loss: 7.3238\n",
      "Epoch 933/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9339 - val_loss: 7.4332\n",
      "Epoch 934/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5211 - val_loss: 7.4755\n",
      "Epoch 935/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5858 - val_loss: 7.4666\n",
      "Epoch 936/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4869 - val_loss: 7.4210\n",
      "Epoch 937/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.7740 - val_loss: 7.5397\n",
      "Epoch 938/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.5013 - val_loss: 7.6423\n",
      "Epoch 939/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7545 - val_loss: 7.3199\n",
      "Epoch 940/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7063 - val_loss: 7.5577\n",
      "Epoch 941/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8128 - val_loss: 7.6129\n",
      "Epoch 942/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.6895 - val_loss: 7.1682\n",
      "Epoch 943/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6742 - val_loss: 7.3870\n",
      "Epoch 944/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.8445 - val_loss: 7.5952\n",
      "Epoch 945/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.6884 - val_loss: 7.5682\n",
      "Epoch 946/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.5808 - val_loss: 7.3482\n",
      "Epoch 947/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.7908 - val_loss: 7.6263\n",
      "Epoch 948/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6999 - val_loss: 7.3233\n",
      "Epoch 949/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7700 - val_loss: 7.5182\n",
      "Epoch 950/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8459 - val_loss: 7.4596\n",
      "Epoch 951/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.0102 - val_loss: 7.2545\n",
      "Epoch 952/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2456 - val_loss: 7.5021\n",
      "Epoch 953/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.9402 - val_loss: 7.9267\n",
      "Epoch 954/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.7436 - val_loss: 7.2086\n",
      "Epoch 955/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6239 - val_loss: 7.4682\n",
      "Epoch 956/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5255 - val_loss: 7.4949\n",
      "Epoch 957/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5115 - val_loss: 7.4282\n",
      "Epoch 958/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5457 - val_loss: 7.3122\n",
      "Epoch 959/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7949 - val_loss: 7.8331\n",
      "Epoch 960/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7041 - val_loss: 7.3140\n",
      "Epoch 961/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4901 - val_loss: 7.3958\n",
      "Epoch 962/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6260 - val_loss: 7.5139\n",
      "Epoch 963/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.4940 - val_loss: 7.3758\n",
      "Epoch 964/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.8560 - val_loss: 7.9337\n",
      "Epoch 965/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0159 - val_loss: 7.8702\n",
      "Epoch 966/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.7146 - val_loss: 7.8637\n",
      "Epoch 967/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5500 - val_loss: 7.5615\n",
      "Epoch 968/1000\n",
      "274/274 [==============================] - 0s 138us/step - loss: 5.7318 - val_loss: 7.7658\n",
      "Epoch 969/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 5.5821 - val_loss: 7.7034\n",
      "Epoch 970/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6592 - val_loss: 7.8937\n",
      "Epoch 971/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6030 - val_loss: 7.3259\n",
      "Epoch 972/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5159 - val_loss: 7.1544\n",
      "Epoch 973/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6656 - val_loss: 7.6416\n",
      "Epoch 974/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.5754 - val_loss: 7.1182\n",
      "Epoch 975/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6303 - val_loss: 7.3881\n",
      "Epoch 976/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.1359 - val_loss: 8.4000\n",
      "Epoch 977/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5760 - val_loss: 7.3287\n",
      "Epoch 978/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6379 - val_loss: 7.3657\n",
      "Epoch 979/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6546 - val_loss: 7.3375\n",
      "Epoch 980/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1290 - val_loss: 7.7444\n",
      "Epoch 981/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6914 - val_loss: 7.3324\n",
      "Epoch 982/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5050 - val_loss: 7.3161\n",
      "Epoch 983/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.6580 - val_loss: 7.3980\n",
      "Epoch 984/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5977 - val_loss: 7.4229\n",
      "Epoch 985/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7191 - val_loss: 7.7340\n",
      "Epoch 986/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9485 - val_loss: 7.9914\n",
      "Epoch 987/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2798 - val_loss: 7.2011\n",
      "Epoch 988/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5312 - val_loss: 7.1599\n",
      "Epoch 989/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6173 - val_loss: 7.6312\n",
      "Epoch 990/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4866 - val_loss: 7.4289\n",
      "Epoch 991/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.5903 - val_loss: 7.7647\n",
      "Epoch 992/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.4681 - val_loss: 7.4236\n",
      "Epoch 993/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5423 - val_loss: 7.6582\n",
      "Epoch 994/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 98us/step - loss: 5.7270 - val_loss: 7.7912\n",
      "Epoch 995/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6321 - val_loss: 7.7907\n",
      "Epoch 996/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5250 - val_loss: 7.8104\n",
      "Epoch 997/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6012 - val_loss: 8.5363\n",
      "Epoch 998/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7247 - val_loss: 7.2651\n",
      "Epoch 999/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6051 - val_loss: 7.0903\n",
      "Epoch 1000/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6366 - val_loss: 7.7862\n",
      "6.990270040803036\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.40470234, -0.34036833, -0.21301723, -2.316638  ,  0.44856235],\n",
       "        [-0.537564  ,  0.83137596, -1.4813678 ,  1.2403859 ,  1.3589271 ],\n",
       "        [ 0.09280413, -1.688394  , -0.05514244, -0.45548353, -0.32898977],\n",
       "        [-0.14545976, -0.9405773 ,  0.7701559 , -0.46130422, -0.88907075],\n",
       "        [ 0.11598106, -0.05062935, -0.8791152 , -0.10582069,  0.34689492],\n",
       "        [ 0.4911989 ,  0.40812534, -0.93944454, -0.01865491,  0.9012109 ],\n",
       "        [ 0.28417295,  1.4655538 , -1.1644257 ,  0.46175352, -1.2777091 ]],\n",
       "       dtype=float32),\n",
       " array([ 2.0805876 , -0.09349127,  0.7071946 , -2.014894  ,  1.0451025 ],\n",
       "       dtype=float32),\n",
       " array([[ 0.7071228 ,  1.236339  ,  0.51266813,  0.7351515 ,  0.5657641 ,\n",
       "         -0.7828475 , -0.6345413 , -0.2411179 ,  0.61309546, -0.3517006 ],\n",
       "        [ 1.2454439 ,  0.96782553,  1.2109356 ,  0.7396092 ,  0.13301918,\n",
       "         -0.65142345, -0.3792337 , -0.8569448 ,  0.5029983 ,  0.8623957 ],\n",
       "        [ 0.9147484 ,  0.63412374, -0.0052255 , -0.07606117,  1.0225037 ,\n",
       "         -0.44816062,  0.13768145, -0.5343685 ,  0.5458169 , -0.17301694],\n",
       "        [-1.3513743 , -2.1499436 , -2.52393   , -1.764599  , -2.107455  ,\n",
       "         -0.32944787, -0.05948553, -0.26789704, -1.6924682 , -4.6754847 ],\n",
       "        [ 0.75430024,  0.19348201,  0.2918455 ,  0.00917732,  1.1220422 ,\n",
       "         -0.9144657 , -1.0275133 , -0.4425455 ,  0.7876163 ,  0.39121437]],\n",
       "       dtype=float32),\n",
       " array([ 0.47164088,  0.5192805 ,  0.52572113,  0.34593138,  0.7407599 ,\n",
       "        -0.8207713 , -0.6569776 , -0.49050033,  0.3359326 , -0.6361074 ],\n",
       "       dtype=float32),\n",
       " array([[0.95334774],\n",
       "        [1.1905102 ],\n",
       "        [1.016302  ],\n",
       "        [0.4577664 ],\n",
       "        [1.0605526 ],\n",
       "        [0.35186923],\n",
       "        [0.00842438],\n",
       "        [0.25280356],\n",
       "        [0.5563079 ],\n",
       "        [0.9506064 ]], dtype=float32),\n",
       " array([0.678181], dtype=float32)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_autompg, history_autompg, evaluate_autompg=NN_model_structure_regression_relu(X_train_autompg, X_val_autompg, Y_train_autompg, Y_val_autompg, adam2, 32, 1000, x_test_autompg, y_test_autompg)\n",
    "model_autompg.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_autompg.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_autompg_relu_4th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_19 (Dense)             (None, 5)                 40        \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 111\n",
      "Trainable params: 111\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 274 samples, validate on 59 samples\n",
      "Epoch 1/1000\n",
      "274/274 [==============================] - 0s 868us/step - loss: 510.7027 - val_loss: 420.0942\n",
      "Epoch 2/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 312.8247 - val_loss: 251.2009\n",
      "Epoch 3/1000\n",
      "274/274 [==============================] - 0s 117us/step - loss: 187.2360 - val_loss: 154.2138\n",
      "Epoch 4/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 118.2871 - val_loss: 104.1507\n",
      "Epoch 5/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 84.8585 - val_loss: 79.4434\n",
      "Epoch 6/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 70.1468 - val_loss: 68.4508\n",
      "Epoch 7/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 63.9920 - val_loss: 63.6667\n",
      "Epoch 8/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 62.2929 - val_loss: 61.4513\n",
      "Epoch 9/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 61.5958 - val_loss: 60.6260\n",
      "Epoch 10/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.4211 - val_loss: 60.3488\n",
      "Epoch 11/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.4391 - val_loss: 60.1999\n",
      "Epoch 12/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 61.4056 - val_loss: 60.1490\n",
      "Epoch 13/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 61.4012 - val_loss: 60.1535\n",
      "Epoch 14/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 61.4006 - val_loss: 60.2380\n",
      "Epoch 15/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 61.3982 - val_loss: 60.2728\n",
      "Epoch 16/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 61.4028 - val_loss: 60.2262\n",
      "Epoch 17/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 61.4232 - val_loss: 60.3292\n",
      "Epoch 18/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.4010 - val_loss: 60.2470\n",
      "Epoch 19/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 61.4168 - val_loss: 60.1824\n",
      "Epoch 20/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 61.4179 - val_loss: 60.2456\n",
      "Epoch 21/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.3859 - val_loss: 60.2478\n",
      "Epoch 22/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 61.4036 - val_loss: 60.1807\n",
      "Epoch 23/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 61.3987 - val_loss: 60.2158\n",
      "Epoch 24/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 61.4325 - val_loss: 60.0621\n",
      "Epoch 25/1000\n",
      "274/274 [==============================] - 0s 142us/step - loss: 61.3840 - val_loss: 60.0743\n",
      "Epoch 26/1000\n",
      "274/274 [==============================] - 0s 171us/step - loss: 61.4101 - val_loss: 60.0128\n",
      "Epoch 27/1000\n",
      "274/274 [==============================] - 0s 128us/step - loss: 61.3798 - val_loss: 60.0380\n",
      "Epoch 28/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 61.3716 - val_loss: 60.1327\n",
      "Epoch 29/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.3568 - val_loss: 60.2057\n",
      "Epoch 30/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 61.3602 - val_loss: 60.1775\n",
      "Epoch 31/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 61.3502 - val_loss: 60.2693\n",
      "Epoch 32/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 61.3298 - val_loss: 60.3339\n",
      "Epoch 33/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 61.3284 - val_loss: 60.3727\n",
      "Epoch 34/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 61.3132 - val_loss: 60.3807\n",
      "Epoch 35/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 61.3142 - val_loss: 60.4138\n",
      "Epoch 36/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 61.3026 - val_loss: 60.4452\n",
      "Epoch 37/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 61.2989 - val_loss: 60.4684\n",
      "Epoch 38/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 61.2929 - val_loss: 60.4653\n",
      "Epoch 39/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.3167 - val_loss: 60.4508\n",
      "Epoch 40/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 61.2747 - val_loss: 60.5723\n",
      "Epoch 41/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 61.2859 - val_loss: 60.6355\n",
      "Epoch 42/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.3060 - val_loss: 60.7417\n",
      "Epoch 43/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 61.2800 - val_loss: 60.6943\n",
      "Epoch 44/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 61.2730 - val_loss: 60.6612\n",
      "Epoch 45/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 61.2659 - val_loss: 60.7009\n",
      "Epoch 46/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 61.2785 - val_loss: 60.6894\n",
      "Epoch 47/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 61.2899 - val_loss: 60.6919\n",
      "Epoch 48/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 61.2674 - val_loss: 60.9086\n",
      "Epoch 49/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 61.2752 - val_loss: 61.1464\n",
      "Epoch 50/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 61.2621 - val_loss: 61.2384\n",
      "Epoch 51/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 61.2583 - val_loss: 61.3030\n",
      "Epoch 52/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 61.2597 - val_loss: 61.2363\n",
      "Epoch 53/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 61.2599 - val_loss: 61.1520\n",
      "Epoch 54/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 61.2505 - val_loss: 61.1841\n",
      "Epoch 55/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 61.2422 - val_loss: 61.2902\n",
      "Epoch 56/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 61.2516 - val_loss: 61.3515\n",
      "Epoch 57/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 61.2485 - val_loss: 61.4723\n",
      "Epoch 58/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.2349 - val_loss: 61.4846\n",
      "Epoch 59/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 61.2471 - val_loss: 61.5183\n",
      "Epoch 60/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 61.2472 - val_loss: 61.4507\n",
      "Epoch 61/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 61.2374 - val_loss: 61.4599\n",
      "Epoch 62/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 61.2460 - val_loss: 61.4186\n",
      "Epoch 63/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 61.2384 - val_loss: 61.4073\n",
      "Epoch 64/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 61.2396 - val_loss: 61.4068\n",
      "Epoch 65/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 61.2581 - val_loss: 61.4617\n",
      "Epoch 66/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 61.2349 - val_loss: 61.4939\n",
      "Epoch 67/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 61.2462 - val_loss: 61.6100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 61.2761 - val_loss: 61.6543\n",
      "Epoch 69/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.2753 - val_loss: 61.4300\n",
      "Epoch 70/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.2311 - val_loss: 61.4460\n",
      "Epoch 71/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.2604 - val_loss: 61.5225\n",
      "Epoch 72/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 61.2470 - val_loss: 61.4423\n",
      "Epoch 73/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 61.2583 - val_loss: 61.3479\n",
      "Epoch 74/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 61.2404 - val_loss: 61.4454\n",
      "Epoch 75/1000\n",
      "274/274 [==============================] - 0s 117us/step - loss: 61.2320 - val_loss: 61.4560\n",
      "Epoch 76/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.2743 - val_loss: 61.5758\n",
      "Epoch 77/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 61.2483 - val_loss: 61.4483\n",
      "Epoch 78/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.2486 - val_loss: 61.4993\n",
      "Epoch 79/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.2322 - val_loss: 61.4508\n",
      "Epoch 80/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 61.2373 - val_loss: 61.4239\n",
      "Epoch 81/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 61.2447 - val_loss: 61.5246\n",
      "Epoch 82/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 61.2392 - val_loss: 61.4908\n",
      "Epoch 83/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 61.2288 - val_loss: 61.4328\n",
      "Epoch 84/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 61.2402 - val_loss: 61.3847\n",
      "Epoch 85/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 61.2288 - val_loss: 61.3225\n",
      "Epoch 86/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 61.2308 - val_loss: 61.3695\n",
      "Epoch 87/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 61.2636 - val_loss: 61.2582\n",
      "Epoch 88/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 61.2569 - val_loss: 61.1876\n",
      "Epoch 89/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 61.2630 - val_loss: 61.3332\n",
      "Epoch 90/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 61.2289 - val_loss: 61.3322\n",
      "Epoch 91/1000\n",
      "274/274 [==============================] - 0s 182us/step - loss: 61.2369 - val_loss: 61.3913\n",
      "Epoch 92/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 61.2357 - val_loss: 61.3861\n",
      "Epoch 93/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 61.2649 - val_loss: 61.3335\n",
      "Epoch 94/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 61.2233 - val_loss: 61.3823\n",
      "Epoch 95/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 61.2329 - val_loss: 61.5263\n",
      "Epoch 96/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.2401 - val_loss: 61.5130\n",
      "Epoch 97/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 61.2328 - val_loss: 61.4865\n",
      "Epoch 98/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 61.2168 - val_loss: 61.3593\n",
      "Epoch 99/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 61.2341 - val_loss: 61.3448\n",
      "Epoch 100/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.2881 - val_loss: 61.2128\n",
      "Epoch 101/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 61.2315 - val_loss: 61.3733\n",
      "Epoch 102/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 61.2393 - val_loss: 61.3877\n",
      "Epoch 103/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 61.2455 - val_loss: 61.2827\n",
      "Epoch 104/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 61.2289 - val_loss: 61.2772\n",
      "Epoch 105/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.2187 - val_loss: 61.3769\n",
      "Epoch 106/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.2472 - val_loss: 61.4674\n",
      "Epoch 107/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 61.2371 - val_loss: 61.4433\n",
      "Epoch 108/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 61.2268 - val_loss: 61.4800\n",
      "Epoch 109/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 61.2286 - val_loss: 61.4418\n",
      "Epoch 110/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 61.2493 - val_loss: 61.4847\n",
      "Epoch 111/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 61.2523 - val_loss: 61.3930\n",
      "Epoch 112/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.2201 - val_loss: 61.4263\n",
      "Epoch 113/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 61.2187 - val_loss: 61.4287\n",
      "Epoch 114/1000\n",
      "274/274 [==============================] - 0s 115us/step - loss: 61.2178 - val_loss: 61.3691\n",
      "Epoch 115/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 61.2338 - val_loss: 61.3983\n",
      "Epoch 116/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.2335 - val_loss: 61.3031\n",
      "Epoch 117/1000\n",
      "274/274 [==============================] - 0s 119us/step - loss: 61.2194 - val_loss: 61.3541\n",
      "Epoch 118/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.2543 - val_loss: 61.3920\n",
      "Epoch 119/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.2087 - val_loss: 61.3233\n",
      "Epoch 120/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 61.2211 - val_loss: 61.3033\n",
      "Epoch 121/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 61.2282 - val_loss: 61.2116\n",
      "Epoch 122/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 61.1842 - val_loss: 61.2820\n",
      "Epoch 123/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.1887 - val_loss: 61.3145\n",
      "Epoch 124/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 61.2707 - val_loss: 61.4509\n",
      "Epoch 125/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 61.2035 - val_loss: 61.2403\n",
      "Epoch 126/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 61.1800 - val_loss: 61.2923\n",
      "Epoch 127/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 61.1580 - val_loss: 61.2309\n",
      "Epoch 128/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 61.1392 - val_loss: 61.2548\n",
      "Epoch 129/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 61.1164 - val_loss: 61.1312\n",
      "Epoch 130/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 60.9725 - val_loss: 59.6314\n",
      "Epoch 131/1000\n",
      "274/274 [==============================] - 0s 138us/step - loss: 50.1791 - val_loss: 48.1376\n",
      "Epoch 132/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 45.8620 - val_loss: 46.0792\n",
      "Epoch 133/1000\n",
      "274/274 [==============================] - 0s 153us/step - loss: 44.5626 - val_loss: 44.0612\n",
      "Epoch 134/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 43.2016 - val_loss: 42.9222\n",
      "Epoch 135/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 42.4881 - val_loss: 42.0739\n",
      "Epoch 136/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 41.8488 - val_loss: 40.9848\n",
      "Epoch 137/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 36.1223 - val_loss: 33.0807\n",
      "Epoch 138/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 31.3992 - val_loss: 31.7221\n",
      "Epoch 139/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 30.5044 - val_loss: 30.3247\n",
      "Epoch 140/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 29.7334 - val_loss: 29.1923\n",
      "Epoch 141/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 28.9327 - val_loss: 28.5709\n",
      "Epoch 142/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 28.3311 - val_loss: 27.5868\n",
      "Epoch 143/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 24.9848 - val_loss: 23.3002\n",
      "Epoch 144/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 22.2782 - val_loss: 22.3461\n",
      "Epoch 145/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 20.9328 - val_loss: 21.1962\n",
      "Epoch 146/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 19.6731 - val_loss: 20.0090\n",
      "Epoch 147/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 18.7517 - val_loss: 19.0944\n",
      "Epoch 148/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 18.0109 - val_loss: 18.3440\n",
      "Epoch 149/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 17.2605 - val_loss: 17.7648\n",
      "Epoch 150/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 16.6277 - val_loss: 17.5008\n",
      "Epoch 151/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 16.1498 - val_loss: 17.1556\n",
      "Epoch 152/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 15.5652 - val_loss: 16.7529\n",
      "Epoch 153/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 15.1764 - val_loss: 16.5872\n",
      "Epoch 154/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 14.8850 - val_loss: 16.1679\n",
      "Epoch 155/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 14.2841 - val_loss: 14.6178\n",
      "Epoch 156/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 12.2326 - val_loss: 14.2140\n",
      "Epoch 157/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 11.7640 - val_loss: 13.6888\n",
      "Epoch 158/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 11.2651 - val_loss: 13.1036\n",
      "Epoch 159/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 10.7134 - val_loss: 12.7980\n",
      "Epoch 160/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 10.4582 - val_loss: 12.8056\n",
      "Epoch 161/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 9.9167 - val_loss: 12.4965\n",
      "Epoch 162/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 9.7744 - val_loss: 12.4489\n",
      "Epoch 163/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 9.3980 - val_loss: 12.4474\n",
      "Epoch 164/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 9.3168 - val_loss: 12.4061\n",
      "Epoch 165/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 9.0962 - val_loss: 12.1192\n",
      "Epoch 166/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.9208 - val_loss: 12.2182\n",
      "Epoch 167/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.7374 - val_loss: 12.2844\n",
      "Epoch 168/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.5698 - val_loss: 12.0666\n",
      "Epoch 169/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.4910 - val_loss: 11.9877\n",
      "Epoch 170/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 8.3926 - val_loss: 11.9815\n",
      "Epoch 171/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 8.3265 - val_loss: 11.9259\n",
      "Epoch 172/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 8.2369 - val_loss: 11.9043\n",
      "Epoch 173/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 8.1298 - val_loss: 12.0100\n",
      "Epoch 174/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.0290 - val_loss: 12.0615\n",
      "Epoch 175/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.8772 - val_loss: 11.7865\n",
      "Epoch 176/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 10.48 - 0s 106us/step - loss: 7.7727 - val_loss: 11.7236\n",
      "Epoch 177/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.7868 - val_loss: 11.9416\n",
      "Epoch 178/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.6172 - val_loss: 11.6739\n",
      "Epoch 179/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 7.5034 - val_loss: 11.5219\n",
      "Epoch 180/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.5881 - val_loss: 11.4715\n",
      "Epoch 181/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.5169 - val_loss: 11.6051\n",
      "Epoch 182/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.3676 - val_loss: 11.5003\n",
      "Epoch 183/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3001 - val_loss: 11.2637\n",
      "Epoch 184/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2174 - val_loss: 11.5489\n",
      "Epoch 185/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.2235 - val_loss: 11.3929\n",
      "Epoch 186/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.2573 - val_loss: 11.3180\n",
      "Epoch 187/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0894 - val_loss: 11.5539\n",
      "Epoch 188/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0338 - val_loss: 11.0961\n",
      "Epoch 189/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.8868 - val_loss: 10.9777\n",
      "Epoch 190/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.8908 - val_loss: 10.8723\n",
      "Epoch 191/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7504 - val_loss: 10.8671\n",
      "Epoch 192/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6467 - val_loss: 10.8362\n",
      "Epoch 193/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.5668 - val_loss: 10.8239\n",
      "Epoch 194/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 6.5041 - val_loss: 10.8090\n",
      "Epoch 195/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 6.4853 - val_loss: 10.5967\n",
      "Epoch 196/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.4108 - val_loss: 10.6142\n",
      "Epoch 197/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3405 - val_loss: 10.7631\n",
      "Epoch 198/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3176 - val_loss: 10.5987\n",
      "Epoch 199/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2371 - val_loss: 10.5233\n",
      "Epoch 200/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1902 - val_loss: 10.1931\n",
      "Epoch 201/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3019 - val_loss: 10.2010\n",
      "Epoch 202/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1826 - val_loss: 10.1011\n",
      "Epoch 203/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1650 - val_loss: 10.2358\n",
      "Epoch 204/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0883 - val_loss: 10.2378\n",
      "Epoch 205/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.0344 - val_loss: 9.9041\n",
      "Epoch 206/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0216 - val_loss: 9.7662\n",
      "Epoch 207/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0829 - val_loss: 10.1309\n",
      "Epoch 208/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9752 - val_loss: 10.0186\n",
      "Epoch 209/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9606 - val_loss: 9.9046\n",
      "Epoch 210/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0053 - val_loss: 10.0104\n",
      "Epoch 211/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9173 - val_loss: 9.8639\n",
      "Epoch 212/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8644 - val_loss: 9.7635\n",
      "Epoch 213/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9099 - val_loss: 9.6332\n",
      "Epoch 214/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9251 - val_loss: 9.9091\n",
      "Epoch 215/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8113 - val_loss: 9.8894\n",
      "Epoch 216/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8088 - val_loss: 9.7128\n",
      "Epoch 217/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7705 - val_loss: 9.7113\n",
      "Epoch 218/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7976 - val_loss: 9.7400\n",
      "Epoch 219/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7948 - val_loss: 9.7796\n",
      "Epoch 220/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7536 - val_loss: 9.8107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 221/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.7446 - val_loss: 9.6955\n",
      "Epoch 222/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.6852 - val_loss: 9.5850\n",
      "Epoch 223/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.7603 - val_loss: 9.4095\n",
      "Epoch 224/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7416 - val_loss: 9.5279\n",
      "Epoch 225/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7487 - val_loss: 9.6823\n",
      "Epoch 226/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7042 - val_loss: 9.6631\n",
      "Epoch 227/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7216 - val_loss: 9.7982\n",
      "Epoch 228/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.6326 - val_loss: 9.5747\n",
      "Epoch 229/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6302 - val_loss: 9.4487\n",
      "Epoch 230/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.6705 - val_loss: 9.5844\n",
      "Epoch 231/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7259 - val_loss: 9.5901\n",
      "Epoch 232/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.6540 - val_loss: 9.5547\n",
      "Epoch 233/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 5.5868 - val_loss: 9.5301\n",
      "Epoch 234/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.5854 - val_loss: 9.5278\n",
      "Epoch 235/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6388 - val_loss: 9.5199\n",
      "Epoch 236/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.7810 - val_loss: 9.5436\n",
      "Epoch 237/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.7814 - val_loss: 9.3739\n",
      "Epoch 238/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.5029 - val_loss: 9.4317\n",
      "Epoch 239/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6574 - val_loss: 9.3347\n",
      "Epoch 240/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4942 - val_loss: 9.4800\n",
      "Epoch 241/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5484 - val_loss: 9.5781\n",
      "Epoch 242/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.5892 - val_loss: 9.5943\n",
      "Epoch 243/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 5.344 - 0s 106us/step - loss: 5.5975 - val_loss: 9.5048\n",
      "Epoch 244/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6089 - val_loss: 9.3310\n",
      "Epoch 245/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5167 - val_loss: 9.4056\n",
      "Epoch 246/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4713 - val_loss: 9.4210\n",
      "Epoch 247/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4789 - val_loss: 9.2869\n",
      "Epoch 248/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4928 - val_loss: 9.4266\n",
      "Epoch 249/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.4563 - val_loss: 9.4183\n",
      "Epoch 250/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.4776 - val_loss: 9.3922\n",
      "Epoch 251/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 5.4491 - val_loss: 9.2984\n",
      "Epoch 252/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 5.4872 - val_loss: 9.4226\n",
      "Epoch 253/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.4468 - val_loss: 9.3328\n",
      "Epoch 254/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.4240 - val_loss: 9.2694\n",
      "Epoch 255/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 5.4534 - val_loss: 9.3006\n",
      "Epoch 256/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 5.4219 - val_loss: 9.2986\n",
      "Epoch 257/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 5.4481 - val_loss: 9.1146\n",
      "Epoch 258/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 5.4001 - val_loss: 9.2071\n",
      "Epoch 259/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 5.3966 - val_loss: 9.2230\n",
      "Epoch 260/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 5.5122 - val_loss: 9.1908\n",
      "Epoch 261/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.6778 - val_loss: 9.4736\n",
      "Epoch 262/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4236 - val_loss: 9.4771\n",
      "Epoch 263/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.4192 - val_loss: 9.2992\n",
      "Epoch 264/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3949 - val_loss: 9.3426\n",
      "Epoch 265/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3599 - val_loss: 9.3375\n",
      "Epoch 266/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3971 - val_loss: 9.3191\n",
      "Epoch 267/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3620 - val_loss: 9.3089\n",
      "Epoch 268/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2966 - val_loss: 9.2339\n",
      "Epoch 269/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.3254 - val_loss: 9.2697\n",
      "Epoch 270/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3231 - val_loss: 9.3813\n",
      "Epoch 271/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3050 - val_loss: 9.3063\n",
      "Epoch 272/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4567 - val_loss: 9.2493\n",
      "Epoch 273/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 5.2341 - val_loss: 9.3176\n",
      "Epoch 274/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3216 - val_loss: 9.1065\n",
      "Epoch 275/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2743 - val_loss: 9.2179\n",
      "Epoch 276/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2772 - val_loss: 9.3234\n",
      "Epoch 277/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.3060 - val_loss: 9.2777\n",
      "Epoch 278/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.2506 - val_loss: 9.2487\n",
      "Epoch 279/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2601 - val_loss: 9.3302\n",
      "Epoch 280/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2718 - val_loss: 9.3226\n",
      "Epoch 281/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.2554 - val_loss: 9.2125\n",
      "Epoch 282/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3549 - val_loss: 9.1622\n",
      "Epoch 283/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2395 - val_loss: 9.3557\n",
      "Epoch 284/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2485 - val_loss: 9.2385\n",
      "Epoch 285/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2359 - val_loss: 9.1046\n",
      "Epoch 286/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.2376 - val_loss: 9.1641\n",
      "Epoch 287/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2533 - val_loss: 9.3440\n",
      "Epoch 288/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.2356 - val_loss: 9.2402\n",
      "Epoch 289/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2286 - val_loss: 9.1594\n",
      "Epoch 290/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.2368 - val_loss: 9.2715\n",
      "Epoch 291/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2269 - val_loss: 9.1930\n",
      "Epoch 292/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2275 - val_loss: 9.2355\n",
      "Epoch 293/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.2029 - val_loss: 9.2285\n",
      "Epoch 294/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1957 - val_loss: 9.3896\n",
      "Epoch 295/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2556 - val_loss: 9.1771\n",
      "Epoch 296/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1863 - val_loss: 9.2915\n",
      "Epoch 297/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.2534 - val_loss: 9.3300\n",
      "Epoch 298/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 97us/step - loss: 5.2558 - val_loss: 9.2916\n",
      "Epoch 299/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1840 - val_loss: 9.2943\n",
      "Epoch 300/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.2179 - val_loss: 9.2747\n",
      "Epoch 301/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1706 - val_loss: 9.3169\n",
      "Epoch 302/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1560 - val_loss: 9.1921\n",
      "Epoch 303/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.1830 - val_loss: 9.1532\n",
      "Epoch 304/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3406 - val_loss: 9.3444\n",
      "Epoch 305/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2297 - val_loss: 9.3014\n",
      "Epoch 306/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1667 - val_loss: 9.1487\n",
      "Epoch 307/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1313 - val_loss: 9.1962\n",
      "Epoch 308/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.1431 - val_loss: 9.2147\n",
      "Epoch 309/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.1562 - val_loss: 9.2562\n",
      "Epoch 310/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.1496 - val_loss: 9.2009\n",
      "Epoch 311/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1385 - val_loss: 9.1249\n",
      "Epoch 312/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1272 - val_loss: 9.2377\n",
      "Epoch 313/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.1191 - val_loss: 9.3187\n",
      "Epoch 314/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1175 - val_loss: 9.2378\n",
      "Epoch 315/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1186 - val_loss: 9.1237\n",
      "Epoch 316/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.1131 - val_loss: 9.2009\n",
      "Epoch 317/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.2317 - val_loss: 9.2440\n",
      "Epoch 318/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1224 - val_loss: 9.2308\n",
      "Epoch 319/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.1384 - val_loss: 9.2878\n",
      "Epoch 320/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.1456 - val_loss: 9.2115\n",
      "Epoch 321/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.1150 - val_loss: 9.1084\n",
      "Epoch 322/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.1098 - val_loss: 9.2411\n",
      "Epoch 323/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1124 - val_loss: 9.2405\n",
      "Epoch 324/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0907 - val_loss: 9.0912\n",
      "Epoch 325/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0996 - val_loss: 9.1692\n",
      "Epoch 326/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0955 - val_loss: 9.1822\n",
      "Epoch 327/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.1226 - val_loss: 9.3019\n",
      "Epoch 328/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.0978 - val_loss: 9.1548\n",
      "Epoch 329/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1338 - val_loss: 9.1720\n",
      "Epoch 330/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0710 - val_loss: 9.2881\n",
      "Epoch 331/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 5.0983 - val_loss: 9.1818\n",
      "Epoch 332/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.0989 - val_loss: 9.1168\n",
      "Epoch 333/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0620 - val_loss: 9.1761\n",
      "Epoch 334/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0769 - val_loss: 9.2664\n",
      "Epoch 335/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1010 - val_loss: 9.2009\n",
      "Epoch 336/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0624 - val_loss: 9.2200\n",
      "Epoch 337/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.1164 - val_loss: 9.0938\n",
      "Epoch 338/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0462 - val_loss: 9.1698\n",
      "Epoch 339/1000\n",
      "274/274 [==============================] - 0s 324us/step - loss: 5.0897 - val_loss: 9.3221\n",
      "Epoch 340/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 5.0843 - val_loss: 9.1116\n",
      "Epoch 341/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0524 - val_loss: 9.2231\n",
      "Epoch 342/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0346 - val_loss: 9.2749\n",
      "Epoch 343/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0635 - val_loss: 9.2332\n",
      "Epoch 344/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0831 - val_loss: 9.3027\n",
      "Epoch 345/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1753 - val_loss: 9.2263\n",
      "Epoch 346/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0588 - val_loss: 9.3879\n",
      "Epoch 347/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0926 - val_loss: 9.1453\n",
      "Epoch 348/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0193 - val_loss: 9.3023\n",
      "Epoch 349/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.0444 - val_loss: 9.3556\n",
      "Epoch 350/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0415 - val_loss: 9.2813\n",
      "Epoch 351/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0828 - val_loss: 9.1651\n",
      "Epoch 352/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0646 - val_loss: 9.3513\n",
      "Epoch 353/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0323 - val_loss: 9.2501\n",
      "Epoch 354/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0579 - val_loss: 9.1869\n",
      "Epoch 355/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.0617 - val_loss: 9.1668\n",
      "Epoch 356/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.0244 - val_loss: 9.2727\n",
      "Epoch 357/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0183 - val_loss: 9.3092\n",
      "Epoch 358/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9937 - val_loss: 9.1951\n",
      "Epoch 359/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0242 - val_loss: 9.1754\n",
      "Epoch 360/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0011 - val_loss: 9.2729\n",
      "Epoch 361/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0105 - val_loss: 9.2748\n",
      "Epoch 362/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0938 - val_loss: 9.2036\n",
      "Epoch 363/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0719 - val_loss: 9.2416\n",
      "Epoch 364/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9937 - val_loss: 9.1901\n",
      "Epoch 365/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0754 - val_loss: 9.2777\n",
      "Epoch 366/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0371 - val_loss: 9.2019\n",
      "Epoch 367/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.9952 - val_loss: 9.2258\n",
      "Epoch 368/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0111 - val_loss: 9.2867\n",
      "Epoch 369/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.0089 - val_loss: 9.3019\n",
      "Epoch 370/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.9776 - val_loss: 9.2494\n",
      "Epoch 371/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.9968 - val_loss: 9.3440\n",
      "Epoch 372/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.0104 - val_loss: 9.2927\n",
      "Epoch 373/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9721 - val_loss: 9.2329\n",
      "Epoch 374/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0112 - val_loss: 9.2646\n",
      "Epoch 375/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0320 - val_loss: 9.4780\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 376/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9884 - val_loss: 9.2512\n",
      "Epoch 377/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9897 - val_loss: 9.1953\n",
      "Epoch 378/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9701 - val_loss: 9.2526\n",
      "Epoch 379/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9721 - val_loss: 9.1754\n",
      "Epoch 380/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.9555 - val_loss: 9.2430\n",
      "Epoch 381/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9680 - val_loss: 9.3299\n",
      "Epoch 382/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9744 - val_loss: 9.3192\n",
      "Epoch 383/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9832 - val_loss: 9.4330\n",
      "Epoch 384/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9834 - val_loss: 9.3086\n",
      "Epoch 385/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9530 - val_loss: 9.2120\n",
      "Epoch 386/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9760 - val_loss: 9.4531\n",
      "Epoch 387/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.9701 - val_loss: 9.3131\n",
      "Epoch 388/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9577 - val_loss: 9.4412\n",
      "Epoch 389/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9515 - val_loss: 9.3446\n",
      "Epoch 390/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.0091 - val_loss: 9.3978\n",
      "Epoch 391/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0352 - val_loss: 9.5309\n",
      "Epoch 392/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9540 - val_loss: 9.4031\n",
      "Epoch 393/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9705 - val_loss: 9.2043\n",
      "Epoch 394/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.9379 - val_loss: 9.3144\n",
      "Epoch 395/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.9890 - val_loss: 9.5233\n",
      "Epoch 396/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.9557 - val_loss: 9.3586\n",
      "Epoch 397/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.9464 - val_loss: 9.3169\n",
      "Epoch 398/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9959 - val_loss: 9.4132\n",
      "Epoch 399/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.9522 - val_loss: 9.4344\n",
      "Epoch 400/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9401 - val_loss: 9.2870\n",
      "Epoch 401/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.9412 - val_loss: 9.3596\n",
      "Epoch 402/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9409 - val_loss: 9.3905\n",
      "Epoch 403/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.9541 - val_loss: 9.4701\n",
      "Epoch 404/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9372 - val_loss: 9.3695\n",
      "Epoch 405/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0029 - val_loss: 9.3035\n",
      "Epoch 406/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.9525 - val_loss: 9.3903\n",
      "Epoch 407/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9279 - val_loss: 9.3820\n",
      "Epoch 408/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.9216 - val_loss: 9.4553\n",
      "Epoch 409/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.9741 - val_loss: 9.5562\n",
      "Epoch 410/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9547 - val_loss: 9.3802\n",
      "Epoch 411/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9063 - val_loss: 9.2691\n",
      "Epoch 412/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.9306 - val_loss: 9.4898\n",
      "Epoch 413/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.9471 - val_loss: 9.4276\n",
      "Epoch 414/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9190 - val_loss: 9.4903\n",
      "Epoch 415/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.9167 - val_loss: 9.4413\n",
      "Epoch 416/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9611 - val_loss: 9.4628\n",
      "Epoch 417/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9119 - val_loss: 9.5212\n",
      "Epoch 418/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9291 - val_loss: 9.5564\n",
      "Epoch 419/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.9047 - val_loss: 9.3897\n",
      "Epoch 420/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9045 - val_loss: 9.3383\n",
      "Epoch 421/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8863 - val_loss: 9.3696\n",
      "Epoch 422/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9362 - val_loss: 9.4329\n",
      "Epoch 423/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.9728 - val_loss: 9.6013\n",
      "Epoch 424/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9198 - val_loss: 9.4137\n",
      "Epoch 425/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.9396 - val_loss: 9.4511\n",
      "Epoch 426/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9391 - val_loss: 9.4815\n",
      "Epoch 427/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.9529 - val_loss: 9.4157\n",
      "Epoch 428/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9048 - val_loss: 9.4141\n",
      "Epoch 429/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8887 - val_loss: 9.5206\n",
      "Epoch 430/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.8830 - val_loss: 9.5128\n",
      "Epoch 431/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9179 - val_loss: 9.4930\n",
      "Epoch 432/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9167 - val_loss: 9.4561\n",
      "Epoch 433/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8874 - val_loss: 9.4164\n",
      "Epoch 434/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.8935 - val_loss: 9.5139\n",
      "Epoch 435/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9285 - val_loss: 9.5604\n",
      "Epoch 436/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8921 - val_loss: 9.4683\n",
      "Epoch 437/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9321 - val_loss: 9.5895\n",
      "Epoch 438/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8916 - val_loss: 9.5129\n",
      "Epoch 439/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8828 - val_loss: 9.4765\n",
      "Epoch 440/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8924 - val_loss: 9.4721\n",
      "Epoch 441/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8981 - val_loss: 9.5217\n",
      "Epoch 442/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8675 - val_loss: 9.5257\n",
      "Epoch 443/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8735 - val_loss: 9.5188\n",
      "Epoch 444/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8716 - val_loss: 9.5682\n",
      "Epoch 445/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8710 - val_loss: 9.5736\n",
      "Epoch 446/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8786 - val_loss: 9.5991\n",
      "Epoch 447/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8577 - val_loss: 9.5617\n",
      "Epoch 448/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8653 - val_loss: 9.4802\n",
      "Epoch 449/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.8928 - val_loss: 9.5361\n",
      "Epoch 450/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.8582 - val_loss: 9.4467\n",
      "Epoch 451/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.8891 - val_loss: 9.6045\n",
      "Epoch 452/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.8497 - val_loss: 9.4790\n",
      "Epoch 453/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 105us/step - loss: 4.8596 - val_loss: 9.4585\n",
      "Epoch 454/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.8889 - val_loss: 9.5354\n",
      "Epoch 455/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8445 - val_loss: 9.5533\n",
      "Epoch 456/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8713 - val_loss: 9.8098\n",
      "Epoch 457/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.8578 - val_loss: 9.5771\n",
      "Epoch 458/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9206 - val_loss: 9.4705\n",
      "Epoch 459/1000\n",
      "274/274 [==============================] - 0s 115us/step - loss: 4.8606 - val_loss: 9.6314\n",
      "Epoch 460/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8655 - val_loss: 9.6647\n",
      "Epoch 461/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.8316 - val_loss: 9.6358\n",
      "Epoch 462/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8615 - val_loss: 9.5532\n",
      "Epoch 463/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.9092 - val_loss: 9.4771\n",
      "Epoch 464/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.9524 - val_loss: 9.7542\n",
      "Epoch 465/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8559 - val_loss: 9.7262\n",
      "Epoch 466/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8660 - val_loss: 9.5406\n",
      "Epoch 467/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8210 - val_loss: 9.4990\n",
      "Epoch 468/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.8203 - val_loss: 9.5697\n",
      "Epoch 469/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.8950 - val_loss: 9.5903\n",
      "Epoch 470/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8109 - val_loss: 9.5922\n",
      "Epoch 471/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.8184 - val_loss: 9.6452\n",
      "Epoch 472/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8334 - val_loss: 9.6582\n",
      "Epoch 473/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.8104 - val_loss: 9.6449\n",
      "Epoch 474/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8335 - val_loss: 9.5435\n",
      "Epoch 475/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.8313 - val_loss: 9.6495\n",
      "Epoch 476/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.8215 - val_loss: 9.6306\n",
      "Epoch 477/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.8344 - val_loss: 9.4364\n",
      "Epoch 478/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8046 - val_loss: 9.6609\n",
      "Epoch 479/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.8317 - val_loss: 9.6302\n",
      "Epoch 480/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.8237 - val_loss: 9.6086\n",
      "Epoch 481/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8354 - val_loss: 9.5587\n",
      "Epoch 482/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8352 - val_loss: 9.8039\n",
      "Epoch 483/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8510 - val_loss: 9.6587\n",
      "Epoch 484/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 4.8848 - val_loss: 9.7336\n",
      "Epoch 485/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8048 - val_loss: 9.7557\n",
      "Epoch 486/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8175 - val_loss: 9.6305\n",
      "Epoch 487/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8070 - val_loss: 9.6641\n",
      "Epoch 488/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8118 - val_loss: 9.6742\n",
      "Epoch 489/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8318 - val_loss: 9.7810\n",
      "Epoch 490/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8323 - val_loss: 9.6392\n",
      "Epoch 491/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8318 - val_loss: 9.6208\n",
      "Epoch 492/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7700 - val_loss: 9.7755\n",
      "Epoch 493/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8642 - val_loss: 9.5775\n",
      "Epoch 494/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8097 - val_loss: 9.5950\n",
      "Epoch 495/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7778 - val_loss: 9.7575\n",
      "Epoch 496/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8384 - val_loss: 9.6605\n",
      "Epoch 497/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7956 - val_loss: 9.5256\n",
      "Epoch 498/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7727 - val_loss: 9.5933\n",
      "Epoch 499/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8131 - val_loss: 9.6302\n",
      "Epoch 500/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.7788 - val_loss: 9.6915\n",
      "Epoch 501/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7596 - val_loss: 9.5879\n",
      "Epoch 502/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7332 - val_loss: 9.6080\n",
      "Epoch 503/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7691 - val_loss: 9.7188\n",
      "Epoch 504/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7772 - val_loss: 9.7096\n",
      "Epoch 505/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.8070 - val_loss: 9.6171\n",
      "Epoch 506/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.7562 - val_loss: 9.5500\n",
      "Epoch 507/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.7481 - val_loss: 9.6076\n",
      "Epoch 508/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.7968 - val_loss: 9.6959\n",
      "Epoch 509/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.8753 - val_loss: 9.6310\n",
      "Epoch 510/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7765 - val_loss: 9.5479\n",
      "Epoch 511/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.8141 - val_loss: 9.5608\n",
      "Epoch 512/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.7510 - val_loss: 9.5460\n",
      "Epoch 513/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7610 - val_loss: 9.6411\n",
      "Epoch 514/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7301 - val_loss: 9.6876\n",
      "Epoch 515/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.7564 - val_loss: 9.7442\n",
      "Epoch 516/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7318 - val_loss: 9.5954\n",
      "Epoch 517/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7527 - val_loss: 9.5622\n",
      "Epoch 518/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.7272 - val_loss: 9.6452\n",
      "Epoch 519/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7335 - val_loss: 9.6109\n",
      "Epoch 520/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7624 - val_loss: 9.5638\n",
      "Epoch 521/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7371 - val_loss: 9.5490\n",
      "Epoch 522/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7257 - val_loss: 9.6466\n",
      "Epoch 523/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7123 - val_loss: 9.6984\n",
      "Epoch 524/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7300 - val_loss: 9.6527\n",
      "Epoch 525/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.7578 - val_loss: 9.6265\n",
      "Epoch 526/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.7112 - val_loss: 9.7340\n",
      "Epoch 527/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7254 - val_loss: 9.7088\n",
      "Epoch 528/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6945 - val_loss: 9.5948\n",
      "Epoch 529/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7192 - val_loss: 9.5626\n",
      "Epoch 530/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 91us/step - loss: 4.7389 - val_loss: 9.6794\n",
      "Epoch 531/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7108 - val_loss: 9.6410\n",
      "Epoch 532/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6841 - val_loss: 9.7070\n",
      "Epoch 533/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.7263 - val_loss: 9.5310\n",
      "Epoch 534/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.7186 - val_loss: 9.5864\n",
      "Epoch 535/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.7196 - val_loss: 9.6575\n",
      "Epoch 536/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6754 - val_loss: 9.6380\n",
      "Epoch 537/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6817 - val_loss: 9.6662\n",
      "Epoch 538/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6969 - val_loss: 9.5362\n",
      "Epoch 539/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6802 - val_loss: 9.6545\n",
      "Epoch 540/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7443 - val_loss: 9.5942\n",
      "Epoch 541/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6750 - val_loss: 9.5832\n",
      "Epoch 542/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7156 - val_loss: 9.7547\n",
      "Epoch 543/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.7258 - val_loss: 9.6932\n",
      "Epoch 544/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.7188 - val_loss: 9.7376\n",
      "Epoch 545/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.6693 - val_loss: 9.6592\n",
      "Epoch 546/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7143 - val_loss: 9.5354\n",
      "Epoch 547/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6750 - val_loss: 9.6699\n",
      "Epoch 548/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.6898 - val_loss: 9.6106\n",
      "Epoch 549/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.6870 - val_loss: 9.6427\n",
      "Epoch 550/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.6801 - val_loss: 9.6397\n",
      "Epoch 551/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6716 - val_loss: 9.6532\n",
      "Epoch 552/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.6829 - val_loss: 9.5028\n",
      "Epoch 553/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.6561 - val_loss: 9.6058\n",
      "Epoch 554/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.6873 - val_loss: 9.5926\n",
      "Epoch 555/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6692 - val_loss: 9.6971\n",
      "Epoch 556/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6127 - val_loss: 9.7095\n",
      "Epoch 557/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6610 - val_loss: 9.4936\n",
      "Epoch 558/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6645 - val_loss: 9.5630\n",
      "Epoch 559/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6363 - val_loss: 9.7263\n",
      "Epoch 560/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.6241 - val_loss: 9.5627\n",
      "Epoch 561/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7010 - val_loss: 9.6414\n",
      "Epoch 562/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6601 - val_loss: 9.7048\n",
      "Epoch 563/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6560 - val_loss: 9.5350\n",
      "Epoch 564/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6386 - val_loss: 9.4325\n",
      "Epoch 565/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.6624 - val_loss: 9.5894\n",
      "Epoch 566/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6318 - val_loss: 9.5898\n",
      "Epoch 567/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.6738 - val_loss: 9.6568\n",
      "Epoch 568/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5976 - val_loss: 9.6566\n",
      "Epoch 569/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6369 - val_loss: 9.6195\n",
      "Epoch 570/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.6662 - val_loss: 9.6194\n",
      "Epoch 571/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6125 - val_loss: 9.5456\n",
      "Epoch 572/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.6226 - val_loss: 9.6783\n",
      "Epoch 573/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6102 - val_loss: 9.6313\n",
      "Epoch 574/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6003 - val_loss: 9.4612\n",
      "Epoch 575/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.6159 - val_loss: 9.5517\n",
      "Epoch 576/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5906 - val_loss: 9.4746\n",
      "Epoch 577/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6163 - val_loss: 9.6247\n",
      "Epoch 578/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.6062 - val_loss: 9.6435\n",
      "Epoch 579/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6316 - val_loss: 9.5139\n",
      "Epoch 580/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6084 - val_loss: 9.4796\n",
      "Epoch 581/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.6111 - val_loss: 9.6201\n",
      "Epoch 582/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.5937 - val_loss: 9.5603\n",
      "Epoch 583/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5776 - val_loss: 9.5735\n",
      "Epoch 584/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5992 - val_loss: 9.5691\n",
      "Epoch 585/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5945 - val_loss: 9.5394\n",
      "Epoch 586/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.5996 - val_loss: 9.4111\n",
      "Epoch 587/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5561 - val_loss: 9.5688\n",
      "Epoch 588/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5894 - val_loss: 9.5844\n",
      "Epoch 589/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.5786 - val_loss: 9.5150\n",
      "Epoch 590/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5942 - val_loss: 9.5823\n",
      "Epoch 591/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.6087 - val_loss: 9.7117\n",
      "Epoch 592/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5724 - val_loss: 9.4786\n",
      "Epoch 593/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5963 - val_loss: 9.4764\n",
      "Epoch 594/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5844 - val_loss: 9.4933\n",
      "Epoch 595/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.6132 - val_loss: 9.4781\n",
      "Epoch 596/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.5778 - val_loss: 9.6408\n",
      "Epoch 597/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.5914 - val_loss: 9.6086\n",
      "Epoch 598/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.5916 - val_loss: 9.4301\n",
      "Epoch 599/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6120 - val_loss: 9.4563\n",
      "Epoch 600/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5695 - val_loss: 9.5214\n",
      "Epoch 601/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.6081 - val_loss: 9.5562\n",
      "Epoch 602/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.5893 - val_loss: 9.5674\n",
      "Epoch 603/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.5736 - val_loss: 9.4067\n",
      "Epoch 604/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.5434 - val_loss: 9.2831\n",
      "Epoch 605/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5596 - val_loss: 9.5055\n",
      "Epoch 606/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5633 - val_loss: 9.6907\n",
      "Epoch 607/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 106us/step - loss: 4.5633 - val_loss: 9.3542\n",
      "Epoch 608/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.5659 - val_loss: 9.3899\n",
      "Epoch 609/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6206 - val_loss: 9.4336\n",
      "Epoch 610/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6299 - val_loss: 9.4829\n",
      "Epoch 611/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.5186 - val_loss: 9.3453\n",
      "Epoch 612/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5309 - val_loss: 9.4418\n",
      "Epoch 613/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5166 - val_loss: 9.3221\n",
      "Epoch 614/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5227 - val_loss: 9.5281\n",
      "Epoch 615/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5310 - val_loss: 9.4043\n",
      "Epoch 616/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5185 - val_loss: 9.3420\n",
      "Epoch 617/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5501 - val_loss: 9.3981\n",
      "Epoch 618/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5513 - val_loss: 9.3649\n",
      "Epoch 619/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5396 - val_loss: 9.3848\n",
      "Epoch 620/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5303 - val_loss: 9.3498\n",
      "Epoch 621/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.4941 - val_loss: 9.3804\n",
      "Epoch 622/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5408 - val_loss: 9.4083\n",
      "Epoch 623/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5026 - val_loss: 9.3232\n",
      "Epoch 624/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5376 - val_loss: 9.3488\n",
      "Epoch 625/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.4914 - val_loss: 9.4586\n",
      "Epoch 626/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5011 - val_loss: 9.3031\n",
      "Epoch 627/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5120 - val_loss: 9.1714\n",
      "Epoch 628/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5324 - val_loss: 9.3927\n",
      "Epoch 629/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5233 - val_loss: 9.4482\n",
      "Epoch 630/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5167 - val_loss: 9.2712\n",
      "Epoch 631/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4852 - val_loss: 9.3309\n",
      "Epoch 632/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5135 - val_loss: 9.3775\n",
      "Epoch 633/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4744 - val_loss: 9.1647\n",
      "Epoch 634/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5028 - val_loss: 9.2029\n",
      "Epoch 635/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4796 - val_loss: 9.2833\n",
      "Epoch 636/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4780 - val_loss: 9.3546\n",
      "Epoch 637/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4770 - val_loss: 9.2413\n",
      "Epoch 638/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4588 - val_loss: 9.1405\n",
      "Epoch 639/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4478 - val_loss: 9.2866\n",
      "Epoch 640/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4639 - val_loss: 9.2701\n",
      "Epoch 641/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4980 - val_loss: 9.2200\n",
      "Epoch 642/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.4500 - val_loss: 9.2430\n",
      "Epoch 643/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.4587 - val_loss: 9.0924\n",
      "Epoch 644/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4645 - val_loss: 9.2352\n",
      "Epoch 645/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.4661 - val_loss: 9.2184\n",
      "Epoch 646/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4590 - val_loss: 9.1658\n",
      "Epoch 647/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4604 - val_loss: 9.2363\n",
      "Epoch 648/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4459 - val_loss: 9.2380\n",
      "Epoch 649/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4377 - val_loss: 9.1634\n",
      "Epoch 650/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.4810 - val_loss: 9.1599\n",
      "Epoch 651/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4396 - val_loss: 9.2531\n",
      "Epoch 652/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4548 - val_loss: 9.0959\n",
      "Epoch 653/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4422 - val_loss: 9.0430\n",
      "Epoch 654/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.4634 - val_loss: 9.0398\n",
      "Epoch 655/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4448 - val_loss: 9.2662\n",
      "Epoch 656/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.4482 - val_loss: 9.2141\n",
      "Epoch 657/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.4374 - val_loss: 9.0881\n",
      "Epoch 658/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4386 - val_loss: 9.1336\n",
      "Epoch 659/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4603 - val_loss: 9.1618\n",
      "Epoch 660/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4614 - val_loss: 9.0050\n",
      "Epoch 661/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4432 - val_loss: 9.2313\n",
      "Epoch 662/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4508 - val_loss: 8.9964\n",
      "Epoch 663/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4397 - val_loss: 8.9451\n",
      "Epoch 664/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 4.4131 - val_loss: 9.0878\n",
      "Epoch 665/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.4274 - val_loss: 9.0153\n",
      "Epoch 666/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4187 - val_loss: 8.9912\n",
      "Epoch 667/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4591 - val_loss: 9.0183\n",
      "Epoch 668/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4295 - val_loss: 9.0794\n",
      "Epoch 669/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.4092 - val_loss: 9.0426\n",
      "Epoch 670/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4161 - val_loss: 9.1261\n",
      "Epoch 671/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.4183 - val_loss: 8.9451\n",
      "Epoch 672/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4144 - val_loss: 9.0229\n",
      "Epoch 673/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4041 - val_loss: 8.9486\n",
      "Epoch 674/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4291 - val_loss: 8.9130\n",
      "Epoch 675/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.4415 - val_loss: 9.0476\n",
      "Epoch 676/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3970 - val_loss: 9.0273\n",
      "Epoch 677/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.4137 - val_loss: 9.0116\n",
      "Epoch 678/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3958 - val_loss: 8.8589\n",
      "Epoch 679/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.3788 - val_loss: 8.9807\n",
      "Epoch 680/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3831 - val_loss: 9.0278\n",
      "Epoch 681/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.4101 - val_loss: 8.9315\n",
      "Epoch 682/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3774 - val_loss: 8.9879\n",
      "Epoch 683/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3665 - val_loss: 8.9067\n",
      "Epoch 684/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 4.3867 - val_loss: 8.9969\n",
      "Epoch 685/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3879 - val_loss: 8.8722\n",
      "Epoch 686/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3720 - val_loss: 9.0624\n",
      "Epoch 687/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3878 - val_loss: 8.9023\n",
      "Epoch 688/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3602 - val_loss: 8.8858\n",
      "Epoch 689/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.3745 - val_loss: 9.0096\n",
      "Epoch 690/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3555 - val_loss: 8.9353\n",
      "Epoch 691/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3611 - val_loss: 8.7707\n",
      "Epoch 692/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.3691 - val_loss: 8.9434\n",
      "Epoch 693/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3578 - val_loss: 8.8462\n",
      "Epoch 694/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3667 - val_loss: 8.8391\n",
      "Epoch 695/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3507 - val_loss: 8.8939\n",
      "Epoch 696/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3879 - val_loss: 9.0989\n",
      "Epoch 697/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.3549 - val_loss: 8.9149\n",
      "Epoch 698/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3849 - val_loss: 8.8358\n",
      "Epoch 699/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3487 - val_loss: 8.8887\n",
      "Epoch 700/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4162 - val_loss: 9.0529\n",
      "Epoch 701/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3822 - val_loss: 8.8183\n",
      "Epoch 702/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3433 - val_loss: 8.9238\n",
      "Epoch 703/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.3499 - val_loss: 8.9785\n",
      "Epoch 704/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.3618 - val_loss: 8.7789\n",
      "Epoch 705/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3488 - val_loss: 8.8674\n",
      "Epoch 706/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.3558 - val_loss: 8.9087\n",
      "Epoch 707/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3485 - val_loss: 8.8572\n",
      "Epoch 708/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3338 - val_loss: 8.7451\n",
      "Epoch 709/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3497 - val_loss: 8.9465\n",
      "Epoch 710/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3288 - val_loss: 8.9057\n",
      "Epoch 711/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3619 - val_loss: 8.8719\n",
      "Epoch 712/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3145 - val_loss: 8.9105\n",
      "Epoch 713/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3209 - val_loss: 8.8185\n",
      "Epoch 714/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3094 - val_loss: 8.8654\n",
      "Epoch 715/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2945 - val_loss: 8.8471\n",
      "Epoch 716/1000\n",
      "274/274 [==============================] - 0s 135us/step - loss: 4.3068 - val_loss: 8.8439\n",
      "Epoch 717/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 4.3032 - val_loss: 8.8829\n",
      "Epoch 718/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3509 - val_loss: 8.7478\n",
      "Epoch 719/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.3618 - val_loss: 8.8465\n",
      "Epoch 720/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.3860 - val_loss: 8.9124\n",
      "Epoch 721/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.4239 - val_loss: 8.6912\n",
      "Epoch 722/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2954 - val_loss: 9.0197\n",
      "Epoch 723/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3286 - val_loss: 8.9690\n",
      "Epoch 724/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 4.2900 - val_loss: 8.7898\n",
      "Epoch 725/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3691 - val_loss: 8.8495\n",
      "Epoch 726/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.3668 - val_loss: 8.7241\n",
      "Epoch 727/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3373 - val_loss: 8.9453\n",
      "Epoch 728/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3217 - val_loss: 8.8984\n",
      "Epoch 729/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2983 - val_loss: 8.9974\n",
      "Epoch 730/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 4.2846 - val_loss: 8.8258\n",
      "Epoch 731/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2881 - val_loss: 8.8210\n",
      "Epoch 732/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2659 - val_loss: 8.9148\n",
      "Epoch 733/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.2703 - val_loss: 8.8220\n",
      "Epoch 734/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.3103 - val_loss: 8.8362\n",
      "Epoch 735/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3347 - val_loss: 8.8369\n",
      "Epoch 736/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3411 - val_loss: 8.9167\n",
      "Epoch 737/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.2867 - val_loss: 8.6864\n",
      "Epoch 738/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2972 - val_loss: 8.8010\n",
      "Epoch 739/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3004 - val_loss: 8.9389\n",
      "Epoch 740/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2920 - val_loss: 8.5421\n",
      "Epoch 741/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.3050 - val_loss: 8.7689\n",
      "Epoch 742/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3419 - val_loss: 9.1254\n",
      "Epoch 743/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3673 - val_loss: 8.7388\n",
      "Epoch 744/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.2844 - val_loss: 8.8916\n",
      "Epoch 745/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2680 - val_loss: 8.8917\n",
      "Epoch 746/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.2837 - val_loss: 8.9423\n",
      "Epoch 747/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2818 - val_loss: 8.7807\n",
      "Epoch 748/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2995 - val_loss: 8.7817\n",
      "Epoch 749/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2762 - val_loss: 8.9265\n",
      "Epoch 750/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2723 - val_loss: 8.8891\n",
      "Epoch 751/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2751 - val_loss: 8.9680\n",
      "Epoch 752/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2819 - val_loss: 8.8642\n",
      "Epoch 753/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3334 - val_loss: 8.9526\n",
      "Epoch 754/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2509 - val_loss: 8.9771\n",
      "Epoch 755/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2766 - val_loss: 8.9525\n",
      "Epoch 756/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2749 - val_loss: 8.9583\n",
      "Epoch 757/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.2510 - val_loss: 8.7486\n",
      "Epoch 758/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.2664 - val_loss: 8.8544\n",
      "Epoch 759/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2395 - val_loss: 8.8681\n",
      "Epoch 760/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2511 - val_loss: 9.0174\n",
      "Epoch 761/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 4.2521 - val_loss: 8.9274\n",
      "Epoch 762/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2563 - val_loss: 8.9177\n",
      "Epoch 763/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2537 - val_loss: 8.9012\n",
      "Epoch 764/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2550 - val_loss: 8.8706\n",
      "Epoch 765/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.3072 - val_loss: 8.8512\n",
      "Epoch 766/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2687 - val_loss: 8.7916\n",
      "Epoch 767/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2347 - val_loss: 8.9297\n",
      "Epoch 768/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2536 - val_loss: 8.9665\n",
      "Epoch 769/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2534 - val_loss: 8.9675\n",
      "Epoch 770/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2229 - val_loss: 8.8593\n",
      "Epoch 771/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2340 - val_loss: 8.8503\n",
      "Epoch 772/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.2266 - val_loss: 8.9422\n",
      "Epoch 773/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.2553 - val_loss: 8.9034\n",
      "Epoch 774/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.2865 - val_loss: 8.9047\n",
      "Epoch 775/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.2262 - val_loss: 8.9037\n",
      "Epoch 776/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2209 - val_loss: 8.9128\n",
      "Epoch 777/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2419 - val_loss: 8.8842\n",
      "Epoch 778/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2147 - val_loss: 8.6775\n",
      "Epoch 779/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.2293 - val_loss: 8.7665\n",
      "Epoch 780/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2185 - val_loss: 9.0468\n",
      "Epoch 781/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2309 - val_loss: 8.8794\n",
      "Epoch 782/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 4.2415 - val_loss: 8.8241\n",
      "Epoch 783/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.2506 - val_loss: 8.9447\n",
      "Epoch 784/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.2190 - val_loss: 8.9758\n",
      "Epoch 785/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2442 - val_loss: 8.8695\n",
      "Epoch 786/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2113 - val_loss: 9.0139\n",
      "Epoch 787/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2763 - val_loss: 8.9010\n",
      "Epoch 788/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.2526 - val_loss: 8.9716\n",
      "Epoch 789/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2185 - val_loss: 8.9272\n",
      "Epoch 790/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.2145 - val_loss: 8.7831\n",
      "Epoch 791/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.2157 - val_loss: 8.7615\n",
      "Epoch 792/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2575 - val_loss: 8.8741\n",
      "Epoch 793/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2444 - val_loss: 9.0494\n",
      "Epoch 794/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2222 - val_loss: 8.8663\n",
      "Epoch 795/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.2411 - val_loss: 8.7439\n",
      "Epoch 796/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.2304 - val_loss: 8.9315\n",
      "Epoch 797/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2322 - val_loss: 9.0648\n",
      "Epoch 798/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 4.2379 - val_loss: 8.8795\n",
      "Epoch 799/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.2286 - val_loss: 8.8788\n",
      "Epoch 800/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2077 - val_loss: 8.9552\n",
      "Epoch 801/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.2198 - val_loss: 8.9629\n",
      "Epoch 802/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2296 - val_loss: 8.9505\n",
      "Epoch 803/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2325 - val_loss: 8.8567\n",
      "Epoch 804/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1990 - val_loss: 8.7646\n",
      "Epoch 805/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2121 - val_loss: 8.9454\n",
      "Epoch 806/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2332 - val_loss: 9.0075\n",
      "Epoch 807/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1996 - val_loss: 8.9157\n",
      "Epoch 808/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.2158 - val_loss: 9.0557\n",
      "Epoch 809/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 4.2533 - val_loss: 9.0317\n",
      "Epoch 810/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1981 - val_loss: 8.8352\n",
      "Epoch 811/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2125 - val_loss: 8.7872\n",
      "Epoch 812/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2010 - val_loss: 8.9890\n",
      "Epoch 813/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1913 - val_loss: 8.9610\n",
      "Epoch 814/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2238 - val_loss: 8.9129\n",
      "Epoch 815/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.2429 - val_loss: 8.9555\n",
      "Epoch 816/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2417 - val_loss: 8.9283\n",
      "Epoch 817/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2419 - val_loss: 9.0072\n",
      "Epoch 818/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2268 - val_loss: 8.8885\n",
      "Epoch 819/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2148 - val_loss: 9.0585\n",
      "Epoch 820/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2172 - val_loss: 8.9123\n",
      "Epoch 821/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2052 - val_loss: 8.8390\n",
      "Epoch 822/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2059 - val_loss: 9.0497\n",
      "Epoch 823/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2099 - val_loss: 9.0545\n",
      "Epoch 824/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1689 - val_loss: 8.9131\n",
      "Epoch 825/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2264 - val_loss: 8.8647\n",
      "Epoch 826/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2106 - val_loss: 8.8478\n",
      "Epoch 827/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2939 - val_loss: 9.0361\n",
      "Epoch 828/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2757 - val_loss: 9.1995\n",
      "Epoch 829/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.2676 - val_loss: 9.0075\n",
      "Epoch 830/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.1974 - val_loss: 9.0808\n",
      "Epoch 831/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1862 - val_loss: 9.0067\n",
      "Epoch 832/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1695 - val_loss: 9.0314\n",
      "Epoch 833/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.1637 - val_loss: 8.9275\n",
      "Epoch 834/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1936 - val_loss: 9.0069\n",
      "Epoch 835/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1860 - val_loss: 8.8970\n",
      "Epoch 836/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1816 - val_loss: 8.9814\n",
      "Epoch 837/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1928 - val_loss: 9.0023\n",
      "Epoch 838/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 99us/step - loss: 4.2123 - val_loss: 9.0263\n",
      "Epoch 839/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1618 - val_loss: 9.0074\n",
      "Epoch 840/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.1966 - val_loss: 9.0488\n",
      "Epoch 841/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.2111 - val_loss: 9.0043\n",
      "Epoch 842/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1666 - val_loss: 8.9503\n",
      "Epoch 843/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2036 - val_loss: 9.0387\n",
      "Epoch 844/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1931 - val_loss: 9.0966\n",
      "Epoch 845/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2023 - val_loss: 8.9087\n",
      "Epoch 846/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1836 - val_loss: 9.0700\n",
      "Epoch 847/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.2208 - val_loss: 8.9487\n",
      "Epoch 848/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1973 - val_loss: 8.8122\n",
      "Epoch 849/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1838 - val_loss: 8.8884\n",
      "Epoch 850/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.1960 - val_loss: 9.1012\n",
      "Epoch 851/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.1638 - val_loss: 9.0738\n",
      "Epoch 852/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2056 - val_loss: 9.0336\n",
      "Epoch 853/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2161 - val_loss: 8.8675\n",
      "Epoch 854/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1664 - val_loss: 9.0344\n",
      "Epoch 855/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2423 - val_loss: 9.1073\n",
      "Epoch 856/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.1612 - val_loss: 9.0016\n",
      "Epoch 857/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2069 - val_loss: 8.9315\n",
      "Epoch 858/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2288 - val_loss: 9.0411\n",
      "Epoch 859/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.2202 - val_loss: 9.0036\n",
      "Epoch 860/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1870 - val_loss: 9.0808\n",
      "Epoch 861/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1704 - val_loss: 9.1087\n",
      "Epoch 862/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.2093 - val_loss: 8.9507\n",
      "Epoch 863/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2021 - val_loss: 9.0573\n",
      "Epoch 864/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1290 - val_loss: 9.1541\n",
      "Epoch 865/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2284 - val_loss: 9.1208\n",
      "Epoch 866/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1817 - val_loss: 9.1199\n",
      "Epoch 867/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.1454 - val_loss: 8.9695\n",
      "Epoch 868/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1607 - val_loss: 9.0845\n",
      "Epoch 869/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1802 - val_loss: 9.1168\n",
      "Epoch 870/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.1918 - val_loss: 9.1649\n",
      "Epoch 871/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1841 - val_loss: 9.0074\n",
      "Epoch 872/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1685 - val_loss: 9.0394\n",
      "Epoch 873/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1693 - val_loss: 9.0936\n",
      "Epoch 874/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1494 - val_loss: 9.0257\n",
      "Epoch 875/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1663 - val_loss: 9.1371\n",
      "Epoch 876/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2245 - val_loss: 9.0478\n",
      "Epoch 877/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1303 - val_loss: 9.1573\n",
      "Epoch 878/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1743 - val_loss: 8.9108\n",
      "Epoch 879/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.1463 - val_loss: 9.0736\n",
      "Epoch 880/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1780 - val_loss: 9.1843\n",
      "Epoch 881/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1612 - val_loss: 9.0985\n",
      "Epoch 882/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1496 - val_loss: 9.0707\n",
      "Epoch 883/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1642 - val_loss: 9.2085\n",
      "Epoch 884/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2271 - val_loss: 9.0621\n",
      "Epoch 885/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2609 - val_loss: 9.1678\n",
      "Epoch 886/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1610 - val_loss: 9.1884\n",
      "Epoch 887/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2264 - val_loss: 9.1840\n",
      "Epoch 888/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1734 - val_loss: 8.9998\n",
      "Epoch 889/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 4.2224 - val_loss: 9.0112\n",
      "Epoch 890/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2270 - val_loss: 9.1490\n",
      "Epoch 891/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.1660 - val_loss: 9.1093\n",
      "Epoch 892/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2006 - val_loss: 9.0751\n",
      "Epoch 893/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1536 - val_loss: 9.1587\n",
      "Epoch 894/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1769 - val_loss: 8.9585\n",
      "Epoch 895/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1509 - val_loss: 9.2296\n",
      "Epoch 896/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1287 - val_loss: 9.1504\n",
      "Epoch 897/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1497 - val_loss: 9.0926\n",
      "Epoch 898/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1455 - val_loss: 9.1722\n",
      "Epoch 899/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.1385 - val_loss: 9.2063\n",
      "Epoch 900/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1143 - val_loss: 9.1236\n",
      "Epoch 901/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1276 - val_loss: 9.1198\n",
      "Epoch 902/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1492 - val_loss: 9.1172\n",
      "Epoch 903/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1153 - val_loss: 9.1583\n",
      "Epoch 904/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1175 - val_loss: 9.0609\n",
      "Epoch 905/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1933 - val_loss: 9.1996\n",
      "Epoch 906/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1246 - val_loss: 9.0974\n",
      "Epoch 907/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.1272 - val_loss: 9.1107\n",
      "Epoch 908/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1551 - val_loss: 9.1492\n",
      "Epoch 909/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.1717 - val_loss: 9.2344\n",
      "Epoch 910/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1092 - val_loss: 9.0529\n",
      "Epoch 911/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1583 - val_loss: 9.1014\n",
      "Epoch 912/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.1411 - val_loss: 9.0969\n",
      "Epoch 913/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 4.1525 - val_loss: 9.1438\n",
      "Epoch 914/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1399 - val_loss: 9.1380\n",
      "Epoch 915/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 109us/step - loss: 4.1351 - val_loss: 9.1727\n",
      "Epoch 916/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1458 - val_loss: 8.9472\n",
      "Epoch 917/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.2551 - val_loss: 9.2095\n",
      "Epoch 918/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1468 - val_loss: 9.2616\n",
      "Epoch 919/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1377 - val_loss: 9.0856\n",
      "Epoch 920/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1349 - val_loss: 9.0782\n",
      "Epoch 921/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.0884 - val_loss: 9.1831\n",
      "Epoch 922/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.1473 - val_loss: 9.1481\n",
      "Epoch 923/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1221 - val_loss: 9.0983\n",
      "Epoch 924/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1053 - val_loss: 8.9533\n",
      "Epoch 925/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1697 - val_loss: 9.1051\n",
      "Epoch 926/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1410 - val_loss: 9.1364\n",
      "Epoch 927/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0939 - val_loss: 9.2228\n",
      "Epoch 928/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1320 - val_loss: 9.0436\n",
      "Epoch 929/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1600 - val_loss: 9.0671\n",
      "Epoch 930/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2040 - val_loss: 9.0427\n",
      "Epoch 931/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1457 - val_loss: 9.2162\n",
      "Epoch 932/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1372 - val_loss: 9.1104\n",
      "Epoch 933/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1201 - val_loss: 9.1163\n",
      "Epoch 934/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1334 - val_loss: 9.0774\n",
      "Epoch 935/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.1123 - val_loss: 9.0391\n",
      "Epoch 936/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1470 - val_loss: 8.9567\n",
      "Epoch 937/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1440 - val_loss: 9.0936\n",
      "Epoch 938/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0999 - val_loss: 9.1301\n",
      "Epoch 939/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1114 - val_loss: 9.2020\n",
      "Epoch 940/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0932 - val_loss: 9.0811\n",
      "Epoch 941/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1454 - val_loss: 9.0676\n",
      "Epoch 942/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.1082 - val_loss: 9.0890\n",
      "Epoch 943/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1408 - val_loss: 9.3063\n",
      "Epoch 944/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1020 - val_loss: 8.9956\n",
      "Epoch 945/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1254 - val_loss: 9.1272\n",
      "Epoch 946/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1022 - val_loss: 9.1452\n",
      "Epoch 947/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1105 - val_loss: 9.2176\n",
      "Epoch 948/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1008 - val_loss: 9.2235\n",
      "Epoch 949/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1141 - val_loss: 8.9593\n",
      "Epoch 950/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1250 - val_loss: 9.1946\n",
      "Epoch 951/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1212 - val_loss: 9.1859\n",
      "Epoch 952/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1690 - val_loss: 9.1813\n",
      "Epoch 953/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1923 - val_loss: 9.0804\n",
      "Epoch 954/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1053 - val_loss: 9.2994\n",
      "Epoch 955/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1265 - val_loss: 9.0519\n",
      "Epoch 956/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1148 - val_loss: 9.1322\n",
      "Epoch 957/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0896 - val_loss: 9.1651\n",
      "Epoch 958/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1246 - val_loss: 9.1332\n",
      "Epoch 959/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0970 - val_loss: 9.0561\n",
      "Epoch 960/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1002 - val_loss: 9.3483\n",
      "Epoch 961/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.1525 - val_loss: 9.2091\n",
      "Epoch 962/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1390 - val_loss: 9.0926\n",
      "Epoch 963/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1536 - val_loss: 9.1623\n",
      "Epoch 964/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.1310 - val_loss: 9.2272\n",
      "Epoch 965/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0990 - val_loss: 9.1418\n",
      "Epoch 966/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1104 - val_loss: 9.2272\n",
      "Epoch 967/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0938 - val_loss: 9.1322\n",
      "Epoch 968/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1184 - val_loss: 9.3239\n",
      "Epoch 969/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0936 - val_loss: 9.2436\n",
      "Epoch 970/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0767 - val_loss: 9.1095\n",
      "Epoch 971/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0923 - val_loss: 9.1344\n",
      "Epoch 972/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0989 - val_loss: 9.0698\n",
      "Epoch 973/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.1744 - val_loss: 9.3015\n",
      "Epoch 974/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1201 - val_loss: 9.3483\n",
      "Epoch 975/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0897 - val_loss: 9.1852\n",
      "Epoch 976/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.1188 - val_loss: 9.1542\n",
      "Epoch 977/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0998 - val_loss: 9.0988\n",
      "Epoch 978/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0748 - val_loss: 9.1827\n",
      "Epoch 979/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1329 - val_loss: 9.1419\n",
      "Epoch 980/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.2018 - val_loss: 9.2082\n",
      "Epoch 981/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1310 - val_loss: 9.3225\n",
      "Epoch 982/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1677 - val_loss: 9.1581\n",
      "Epoch 983/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0678 - val_loss: 9.3296\n",
      "Epoch 984/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0869 - val_loss: 9.2077\n",
      "Epoch 985/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1017 - val_loss: 9.2624\n",
      "Epoch 986/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1068 - val_loss: 9.3414\n",
      "Epoch 987/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0801 - val_loss: 9.1143\n",
      "Epoch 988/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1243 - val_loss: 9.1841\n",
      "Epoch 989/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.1364 - val_loss: 9.1554\n",
      "Epoch 990/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.1653 - val_loss: 9.3337\n",
      "Epoch 991/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.0835 - val_loss: 9.3586\n",
      "Epoch 992/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 97us/step - loss: 4.1163 - val_loss: 9.2249\n",
      "Epoch 993/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1230 - val_loss: 9.2155\n",
      "Epoch 994/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0913 - val_loss: 9.1540\n",
      "Epoch 995/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0935 - val_loss: 9.2332\n",
      "Epoch 996/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.0804 - val_loss: 9.2690\n",
      "Epoch 997/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.0813 - val_loss: 9.2256\n",
      "Epoch 998/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1153 - val_loss: 9.0943\n",
      "Epoch 999/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0768 - val_loss: 9.2134\n",
      "Epoch 1000/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0687 - val_loss: 9.1049\n",
      "4.816794686398263\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 1.9426727 , -3.154216  ,  1.2947216 , -0.25928482, -3.776607  ],\n",
       "        [-1.2941108 , -1.8742912 , -2.4135976 ,  0.8706868 ,  2.3275826 ],\n",
       "        [-0.7898564 , -0.63225806,  3.9876556 , -0.7132185 , -3.685873  ],\n",
       "        [-3.4944487 ,  0.06518537,  2.3506112 , -1.3158121 , -0.19374251],\n",
       "        [-0.09480063, -0.89522725,  1.5488071 ,  0.53425384, -0.9364944 ],\n",
       "        [ 0.40939808, -0.72733086,  0.10736895,  3.66135   ,  0.4963284 ],\n",
       "        [-0.59899616, -2.4831371 , -3.8611042 , -1.5163778 ,  0.52634037]],\n",
       "       dtype=float32),\n",
       " array([-0.7506606 ,  0.64207524,  2.5996542 ,  0.41672248, -1.3979558 ],\n",
       "       dtype=float32),\n",
       " array([[ 0.99948496,  2.688472  ,  1.2906566 ,  3.5223038 , -3.1821342 ,\n",
       "         -2.501884  ,  1.7030418 ,  0.70416105,  2.4237258 ,  1.0781857 ],\n",
       "        [ 0.83689904,  6.774279  ,  0.427616  , -1.4888628 ,  1.3295146 ,\n",
       "          0.3013371 , -1.4857911 ,  0.6392784 , -2.1652515 ,  0.78460735],\n",
       "        [-7.826157  , -0.22110789, -2.2029898 ,  2.5571434 , -1.2095275 ,\n",
       "         -2.6646378 , -0.29335088, -5.6258802 , -3.0949855 ,  1.0271248 ],\n",
       "        [-6.5462685 ,  1.3430617 ,  1.4854434 ,  2.3829877 , -3.6039326 ,\n",
       "          1.6857805 ,  5.2047677 , -5.267786  ,  1.5029078 , -0.402514  ],\n",
       "        [-3.0997617 ,  1.4145672 , -1.0247791 , -0.17792971, -5.992969  ,\n",
       "          2.3900537 ,  6.2434607 , -2.6688561 , -0.65785867,  9.4295635 ]],\n",
       "       dtype=float32),\n",
       " array([ 0.3939707 , -3.3069975 , -2.5719812 ,  3.49577   , -1.4508746 ,\n",
       "        -0.77895665,  2.7638462 ,  0.4115579 , -0.54787594, -4.144469  ],\n",
       "       dtype=float32),\n",
       " array([[2.2248154],\n",
       "        [5.70611  ],\n",
       "        [4.2668285],\n",
       "        [5.090144 ],\n",
       "        [4.8215804],\n",
       "        [2.282337 ],\n",
       "        [5.5066495],\n",
       "        [1.7364285],\n",
       "        [7.293068 ],\n",
       "        [4.120754 ]], dtype=float32),\n",
       " array([2.7315295], dtype=float32)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_autompg, history_autompg, evaluate_autompg=NN_model_structure_regression_sigmoid(X_train_autompg, X_val_autompg, Y_train_autompg, Y_val_autompg, adam2, 32, 1000, x_test_autompg, y_test_autompg)\n",
    "model_autompg.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_autompg.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_autompg_sigmoid_4th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_22 (Dense)             (None, 5)                 40        \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 111\n",
      "Trainable params: 111\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 274 samples, validate on 59 samples\n",
      "Epoch 1/1000\n",
      "274/274 [==============================] - 0s 821us/step - loss: 471.8195 - val_loss: 343.1162\n",
      "Epoch 2/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 238.7313 - val_loss: 167.4537\n",
      "Epoch 3/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 114.7210 - val_loss: 87.0340\n",
      "Epoch 4/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 70.5667 - val_loss: 62.9043\n",
      "Epoch 5/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 62.0683 - val_loss: 59.4528\n",
      "Epoch 6/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 62.3018 - val_loss: 59.3895\n",
      "Epoch 7/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 62.2909 - val_loss: 59.3867\n",
      "Epoch 8/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.9415 - val_loss: 59.6171\n",
      "Epoch 9/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 61.4916 - val_loss: 59.9223\n",
      "Epoch 10/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.3738 - val_loss: 60.2024\n",
      "Epoch 11/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.3992 - val_loss: 60.3935\n",
      "Epoch 12/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 61.4553 - val_loss: 60.5293\n",
      "Epoch 13/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.4367 - val_loss: 60.3887\n",
      "Epoch 14/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.3987 - val_loss: 60.1501\n",
      "Epoch 15/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 61.4130 - val_loss: 60.0138\n",
      "Epoch 16/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 61.4160 - val_loss: 59.9913\n",
      "Epoch 17/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.4056 - val_loss: 60.0566\n",
      "Epoch 18/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 61.3965 - val_loss: 60.1689\n",
      "Epoch 19/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 61.4106 - val_loss: 60.2112\n",
      "Epoch 20/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.4136 - val_loss: 60.2871\n",
      "Epoch 21/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.4267 - val_loss: 60.1321\n",
      "Epoch 22/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.4156 - val_loss: 60.2046\n",
      "Epoch 23/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.3879 - val_loss: 60.1556\n",
      "Epoch 24/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.3994 - val_loss: 60.0727\n",
      "Epoch 25/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.4178 - val_loss: 60.1742\n",
      "Epoch 26/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 61.3951 - val_loss: 60.2244\n",
      "Epoch 27/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.3822 - val_loss: 60.1077\n",
      "Epoch 28/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.4452 - val_loss: 60.0603\n",
      "Epoch 29/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.3828 - val_loss: 60.1335\n",
      "Epoch 30/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.4050 - val_loss: 60.3061\n",
      "Epoch 31/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 61.3569 - val_loss: 60.3137\n",
      "Epoch 32/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.3381 - val_loss: 60.1842\n",
      "Epoch 33/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 61.4646 - val_loss: 60.3782\n",
      "Epoch 34/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 61.3230 - val_loss: 60.3229\n",
      "Epoch 35/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.3134 - val_loss: 60.3379\n",
      "Epoch 36/1000\n",
      "274/274 [==============================] - 0s 115us/step - loss: 61.3481 - val_loss: 60.2591\n",
      "Epoch 37/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 61.3091 - val_loss: 60.2939\n",
      "Epoch 38/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 61.3339 - val_loss: 60.5523\n",
      "Epoch 39/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 61.2948 - val_loss: 60.5684\n",
      "Epoch 40/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.2899 - val_loss: 60.5996\n",
      "Epoch 41/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 61.3000 - val_loss: 60.5804\n",
      "Epoch 42/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 61.2755 - val_loss: 60.7758\n",
      "Epoch 43/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 61.2707 - val_loss: 60.7897\n",
      "Epoch 44/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.2817 - val_loss: 60.8638\n",
      "Epoch 45/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 61.2424 - val_loss: 60.9049\n",
      "Epoch 46/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 61.2381 - val_loss: 60.9066\n",
      "Epoch 47/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.3183 - val_loss: 60.7955\n",
      "Epoch 48/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.2140 - val_loss: 61.0926\n",
      "Epoch 49/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 61.2299 - val_loss: 61.3267\n",
      "Epoch 50/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 61.1906 - val_loss: 61.3019\n",
      "Epoch 51/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 61.1487 - val_loss: 61.2365\n",
      "Epoch 52/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.1350 - val_loss: 61.0935\n",
      "Epoch 53/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 61.0992 - val_loss: 61.1029\n",
      "Epoch 54/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 61.1029 - val_loss: 61.0833\n",
      "Epoch 55/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 61.1104 - val_loss: 61.2843\n",
      "Epoch 56/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 61.0755 - val_loss: 61.2430\n",
      "Epoch 57/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.0694 - val_loss: 61.1899\n",
      "Epoch 58/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 61.1713 - val_loss: 60.9515\n",
      "Epoch 59/1000\n",
      "274/274 [==============================] - 0s 117us/step - loss: 61.1099 - val_loss: 61.0027\n",
      "Epoch 60/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 61.0731 - val_loss: 60.9637\n",
      "Epoch 61/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.0735 - val_loss: 61.0215\n",
      "Epoch 62/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 61.1491 - val_loss: 61.2478\n",
      "Epoch 63/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.0705 - val_loss: 61.2209\n",
      "Epoch 64/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 61.0531 - val_loss: 61.1034\n",
      "Epoch 65/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.1162 - val_loss: 60.9391\n",
      "Epoch 66/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 61.0716 - val_loss: 60.9973\n",
      "Epoch 67/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.0756 - val_loss: 60.9534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 61.0646 - val_loss: 61.0550\n",
      "Epoch 69/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 61.0680 - val_loss: 61.0739\n",
      "Epoch 70/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.0526 - val_loss: 61.1262\n",
      "Epoch 71/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 61.0614 - val_loss: 61.0885\n",
      "Epoch 72/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 61.0620 - val_loss: 61.0463\n",
      "Epoch 73/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 61.0638 - val_loss: 61.0382\n",
      "Epoch 74/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 61.0770 - val_loss: 61.0033\n",
      "Epoch 75/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 61.0570 - val_loss: 60.9768\n",
      "Epoch 76/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.0846 - val_loss: 60.9154\n",
      "Epoch 77/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.0552 - val_loss: 60.9810\n",
      "Epoch 78/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.0621 - val_loss: 61.0048\n",
      "Epoch 79/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.0618 - val_loss: 60.9725\n",
      "Epoch 80/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.0856 - val_loss: 60.9518\n",
      "Epoch 81/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 61.0744 - val_loss: 61.0019\n",
      "Epoch 82/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 61.0502 - val_loss: 60.9761\n",
      "Epoch 83/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 61.1226 - val_loss: 61.0520\n",
      "Epoch 84/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 61.1247 - val_loss: 60.8717\n",
      "Epoch 85/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 61.1058 - val_loss: 61.1021\n",
      "Epoch 86/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 61.0809 - val_loss: 61.0534\n",
      "Epoch 87/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.0653 - val_loss: 60.9545\n",
      "Epoch 88/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 61.0756 - val_loss: 60.8647\n",
      "Epoch 89/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 61.0657 - val_loss: 60.8779\n",
      "Epoch 90/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 61.1210 - val_loss: 61.1597\n",
      "Epoch 91/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.1024 - val_loss: 60.9993\n",
      "Epoch 92/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.0722 - val_loss: 61.0639\n",
      "Epoch 93/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 61.0459 - val_loss: 60.9478\n",
      "Epoch 94/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 61.0714 - val_loss: 60.9426\n",
      "Epoch 95/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.0602 - val_loss: 60.8930\n",
      "Epoch 96/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 61.0940 - val_loss: 60.9581\n",
      "Epoch 97/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 61.0748 - val_loss: 61.0102\n",
      "Epoch 98/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 61.1181 - val_loss: 60.8732\n",
      "Epoch 99/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.0515 - val_loss: 60.8610\n",
      "Epoch 100/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 61.0991 - val_loss: 60.7697\n",
      "Epoch 101/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 61.0791 - val_loss: 60.7649\n",
      "Epoch 102/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 61.1094 - val_loss: 60.8080\n",
      "Epoch 103/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 61.0577 - val_loss: 60.9469\n",
      "Epoch 104/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.0649 - val_loss: 60.9607\n",
      "Epoch 105/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.0647 - val_loss: 61.0154\n",
      "Epoch 106/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 61.2019 - val_loss: 61.1346\n",
      "Epoch 107/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 61.0513 - val_loss: 60.9831\n",
      "Epoch 108/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 61.0997 - val_loss: 60.7494\n",
      "Epoch 109/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 61.0900 - val_loss: 60.8696\n",
      "Epoch 110/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 61.0644 - val_loss: 60.8715\n",
      "Epoch 111/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.0556 - val_loss: 60.8509\n",
      "Epoch 112/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.0597 - val_loss: 60.9802\n",
      "Epoch 113/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.1189 - val_loss: 61.0573\n",
      "Epoch 114/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.0599 - val_loss: 60.7487\n",
      "Epoch 115/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 61.1017 - val_loss: 60.5658\n",
      "Epoch 116/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.0655 - val_loss: 60.7309\n",
      "Epoch 117/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.1242 - val_loss: 60.9934\n",
      "Epoch 118/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.0147 - val_loss: 60.8865\n",
      "Epoch 119/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 60.9220 - val_loss: 60.3537\n",
      "Epoch 120/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 56.7520 - val_loss: 48.6696\n",
      "Epoch 121/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 45.7832 - val_loss: 46.3032\n",
      "Epoch 122/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 43.2735 - val_loss: 43.1948\n",
      "Epoch 123/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 40.8734 - val_loss: 40.7055\n",
      "Epoch 124/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 38.4801 - val_loss: 37.2694\n",
      "Epoch 125/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 28.3135 - val_loss: 30.8306\n",
      "Epoch 126/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 24.8954 - val_loss: 27.5007\n",
      "Epoch 127/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 22.4205 - val_loss: 24.7638\n",
      "Epoch 128/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 20.7770 - val_loss: 22.7096\n",
      "Epoch 129/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 19.3989 - val_loss: 21.0922\n",
      "Epoch 130/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 18.4950 - val_loss: 20.3086\n",
      "Epoch 131/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 17.9436 - val_loss: 19.9605\n",
      "Epoch 132/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 16.8284 - val_loss: 18.5497\n",
      "Epoch 133/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 15.9701 - val_loss: 17.7272\n",
      "Epoch 134/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 14.8433 - val_loss: 16.8333\n",
      "Epoch 135/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 13.6014 - val_loss: 16.1365\n",
      "Epoch 136/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 12.6856 - val_loss: 16.0260\n",
      "Epoch 137/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 11.9581 - val_loss: 15.7270\n",
      "Epoch 138/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 11.3649 - val_loss: 14.8242\n",
      "Epoch 139/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 11.0452 - val_loss: 13.6226\n",
      "Epoch 140/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 10.6751 - val_loss: 12.9034\n",
      "Epoch 141/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 9.8595 - val_loss: 13.5147\n",
      "Epoch 142/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 9.7702 - val_loss: 12.1532\n",
      "Epoch 143/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 9.2006 - val_loss: 11.8255\n",
      "Epoch 144/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 8.7929 - val_loss: 11.1905\n",
      "Epoch 145/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 8.2126 - val_loss: 11.6331\n",
      "Epoch 146/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.7892 - val_loss: 11.1442\n",
      "Epoch 147/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.5104 - val_loss: 11.2881\n",
      "Epoch 148/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.4573 - val_loss: 11.0387\n",
      "Epoch 149/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3541 - val_loss: 11.0288\n",
      "Epoch 150/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1710 - val_loss: 11.0435\n",
      "Epoch 151/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.1035 - val_loss: 10.9901\n",
      "Epoch 152/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0017 - val_loss: 10.9228\n",
      "Epoch 153/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8438 - val_loss: 10.9305\n",
      "Epoch 154/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7615 - val_loss: 11.1442\n",
      "Epoch 155/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7310 - val_loss: 10.8751\n",
      "Epoch 156/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6366 - val_loss: 11.3408\n",
      "Epoch 157/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6853 - val_loss: 11.0539\n",
      "Epoch 158/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7711 - val_loss: 11.0584\n",
      "Epoch 159/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5953 - val_loss: 11.2693\n",
      "Epoch 160/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.5507 - val_loss: 11.0733\n",
      "Epoch 161/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3657 - val_loss: 10.9291\n",
      "Epoch 162/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.5651 - val_loss: 11.5209\n",
      "Epoch 163/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3988 - val_loss: 11.1457\n",
      "Epoch 164/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3875 - val_loss: 11.1755\n",
      "Epoch 165/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.5093 - val_loss: 10.7651\n",
      "Epoch 166/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2296 - val_loss: 11.1471\n",
      "Epoch 167/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2683 - val_loss: 11.3900\n",
      "Epoch 168/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2938 - val_loss: 11.3068\n",
      "Epoch 169/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1759 - val_loss: 11.4870\n",
      "Epoch 170/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2412 - val_loss: 10.9037\n",
      "Epoch 171/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1295 - val_loss: 11.1272\n",
      "Epoch 172/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2794 - val_loss: 11.2422\n",
      "Epoch 173/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1448 - val_loss: 11.0886\n",
      "Epoch 174/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1920 - val_loss: 11.1873\n",
      "Epoch 175/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1135 - val_loss: 11.2035\n",
      "Epoch 176/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.2846 - val_loss: 11.0670\n",
      "Epoch 177/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 6.1316 - val_loss: 11.1780\n",
      "Epoch 178/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2068 - val_loss: 11.0087\n",
      "Epoch 179/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1004 - val_loss: 11.4504\n",
      "Epoch 180/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0987 - val_loss: 11.1705\n",
      "Epoch 181/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9846 - val_loss: 11.1913\n",
      "Epoch 182/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0125 - val_loss: 10.9599\n",
      "Epoch 183/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.0036 - val_loss: 11.0357\n",
      "Epoch 184/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.1285 - val_loss: 10.9619\n",
      "Epoch 185/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0177 - val_loss: 11.5263\n",
      "Epoch 186/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9329 - val_loss: 11.1381\n",
      "Epoch 187/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9174 - val_loss: 11.0828\n",
      "Epoch 188/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.9581 - val_loss: 11.1799\n",
      "Epoch 189/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9494 - val_loss: 10.9335\n",
      "Epoch 190/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9989 - val_loss: 10.9440\n",
      "Epoch 191/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.9538 - val_loss: 11.2166\n",
      "Epoch 192/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.9284 - val_loss: 10.9791\n",
      "Epoch 193/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9313 - val_loss: 11.0566\n",
      "Epoch 194/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9291 - val_loss: 10.8621\n",
      "Epoch 195/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9887 - val_loss: 10.9017\n",
      "Epoch 196/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8613 - val_loss: 10.9045\n",
      "Epoch 197/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9314 - val_loss: 10.6082\n",
      "Epoch 198/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8496 - val_loss: 10.9862\n",
      "Epoch 199/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9198 - val_loss: 10.8478\n",
      "Epoch 200/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8763 - val_loss: 11.1014\n",
      "Epoch 201/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.9881 - val_loss: 10.7536\n",
      "Epoch 202/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8174 - val_loss: 11.1039\n",
      "Epoch 203/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9151 - val_loss: 10.7250\n",
      "Epoch 204/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9961 - val_loss: 10.8546\n",
      "Epoch 205/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8382 - val_loss: 11.1076\n",
      "Epoch 206/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.9023 - val_loss: 10.7494\n",
      "Epoch 207/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9461 - val_loss: 11.0490\n",
      "Epoch 208/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8674 - val_loss: 11.0227\n",
      "Epoch 209/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8209 - val_loss: 10.8420\n",
      "Epoch 210/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7902 - val_loss: 10.8703\n",
      "Epoch 211/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8212 - val_loss: 10.4841\n",
      "Epoch 212/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7695 - val_loss: 10.8219\n",
      "Epoch 213/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.9164 - val_loss: 10.7460\n",
      "Epoch 214/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8252 - val_loss: 10.5384\n",
      "Epoch 215/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7864 - val_loss: 10.4535\n",
      "Epoch 216/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.8303 - val_loss: 10.7894\n",
      "Epoch 217/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.9378 - val_loss: 10.5023\n",
      "Epoch 218/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9045 - val_loss: 10.4416\n",
      "Epoch 219/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8160 - val_loss: 10.8701\n",
      "Epoch 220/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9080 - val_loss: 10.3495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 221/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6742 - val_loss: 10.7059\n",
      "Epoch 222/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8825 - val_loss: 10.4405\n",
      "Epoch 223/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1004 - val_loss: 10.3137\n",
      "Epoch 224/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.8670 - val_loss: 10.5076\n",
      "Epoch 225/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8367 - val_loss: 10.4253\n",
      "Epoch 226/1000\n",
      "274/274 [==============================] - 0s 138us/step - loss: 5.7724 - val_loss: 10.4563\n",
      "Epoch 227/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7341 - val_loss: 10.1489\n",
      "Epoch 228/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6997 - val_loss: 10.2607\n",
      "Epoch 229/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7247 - val_loss: 10.2212\n",
      "Epoch 230/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6599 - val_loss: 10.3887\n",
      "Epoch 231/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.9203 - val_loss: 10.2509\n",
      "Epoch 232/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8875 - val_loss: 10.2288\n",
      "Epoch 233/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7465 - val_loss: 10.7377\n",
      "Epoch 234/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6576 - val_loss: 10.1544\n",
      "Epoch 235/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7025 - val_loss: 10.1312\n",
      "Epoch 236/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6968 - val_loss: 10.1459\n",
      "Epoch 237/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6931 - val_loss: 10.3077\n",
      "Epoch 238/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7186 - val_loss: 10.1009\n",
      "Epoch 239/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7212 - val_loss: 10.4542\n",
      "Epoch 240/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7678 - val_loss: 9.9561\n",
      "Epoch 241/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6449 - val_loss: 9.9394\n",
      "Epoch 242/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.6713 - val_loss: 9.8126\n",
      "Epoch 243/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6951 - val_loss: 9.7010\n",
      "Epoch 244/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7199 - val_loss: 9.3813\n",
      "Epoch 245/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7706 - val_loss: 9.4428\n",
      "Epoch 246/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.6608 - val_loss: 9.6256\n",
      "Epoch 247/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.6578 - val_loss: 9.6566\n",
      "Epoch 248/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6506 - val_loss: 9.9630\n",
      "Epoch 249/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6992 - val_loss: 9.5991\n",
      "Epoch 250/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6436 - val_loss: 9.5691\n",
      "Epoch 251/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6913 - val_loss: 9.4612\n",
      "Epoch 252/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.6348 - val_loss: 9.2419\n",
      "Epoch 253/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6493 - val_loss: 9.4343\n",
      "Epoch 254/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5621 - val_loss: 9.8328\n",
      "Epoch 255/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6920 - val_loss: 9.4665\n",
      "Epoch 256/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6210 - val_loss: 9.3858\n",
      "Epoch 257/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6316 - val_loss: 9.3910\n",
      "Epoch 258/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.6948 - val_loss: 9.3507\n",
      "Epoch 259/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5277 - val_loss: 9.2171\n",
      "Epoch 260/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5957 - val_loss: 9.3889\n",
      "Epoch 261/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.6161 - val_loss: 9.6057\n",
      "Epoch 262/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5346 - val_loss: 9.5522\n",
      "Epoch 263/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5848 - val_loss: 9.2023\n",
      "Epoch 264/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6054 - val_loss: 9.3091\n",
      "Epoch 265/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5839 - val_loss: 9.4948\n",
      "Epoch 266/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5781 - val_loss: 9.1940\n",
      "Epoch 267/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.5582 - val_loss: 9.0214\n",
      "Epoch 268/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5799 - val_loss: 9.2743\n",
      "Epoch 269/1000\n",
      "274/274 [==============================] - 0s 115us/step - loss: 5.6154 - val_loss: 9.0514\n",
      "Epoch 270/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6067 - val_loss: 9.4073\n",
      "Epoch 271/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5787 - val_loss: 9.5319\n",
      "Epoch 272/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5810 - val_loss: 9.0915\n",
      "Epoch 273/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6214 - val_loss: 8.7900\n",
      "Epoch 274/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7989 - val_loss: 8.8871\n",
      "Epoch 275/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4715 - val_loss: 8.7701\n",
      "Epoch 276/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5470 - val_loss: 8.5961\n",
      "Epoch 277/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5172 - val_loss: 8.6330\n",
      "Epoch 278/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5214 - val_loss: 8.3063\n",
      "Epoch 279/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5269 - val_loss: 8.4810\n",
      "Epoch 280/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5383 - val_loss: 8.3697\n",
      "Epoch 281/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.5310 - val_loss: 8.2114\n",
      "Epoch 282/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6861 - val_loss: 8.5376\n",
      "Epoch 283/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5664 - val_loss: 7.9961\n",
      "Epoch 284/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5573 - val_loss: 8.2511\n",
      "Epoch 285/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.5325 - val_loss: 7.8030\n",
      "Epoch 286/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5382 - val_loss: 8.0641\n",
      "Epoch 287/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5215 - val_loss: 7.9856\n",
      "Epoch 288/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4283 - val_loss: 8.0737\n",
      "Epoch 289/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3424 - val_loss: 8.0470\n",
      "Epoch 290/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3455 - val_loss: 8.1628\n",
      "Epoch 291/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2856 - val_loss: 8.0834\n",
      "Epoch 292/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3170 - val_loss: 8.1624\n",
      "Epoch 293/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2548 - val_loss: 7.9654\n",
      "Epoch 294/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2447 - val_loss: 8.0014\n",
      "Epoch 295/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2858 - val_loss: 7.9347\n",
      "Epoch 296/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3838 - val_loss: 8.1852\n",
      "Epoch 297/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.1934 - val_loss: 7.8484\n",
      "Epoch 298/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 116us/step - loss: 5.2581 - val_loss: 8.2507\n",
      "Epoch 299/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.0886 - val_loss: 8.4315\n",
      "Epoch 300/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 5.2003 - val_loss: 8.3357\n",
      "Epoch 301/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.1819 - val_loss: 8.4352\n",
      "Epoch 302/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.4509 - val_loss: 8.5213\n",
      "Epoch 303/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0986 - val_loss: 8.3697\n",
      "Epoch 304/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1663 - val_loss: 8.4479\n",
      "Epoch 305/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1817 - val_loss: 8.4381\n",
      "Epoch 306/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0873 - val_loss: 7.8257\n",
      "Epoch 307/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.0828 - val_loss: 8.1832\n",
      "Epoch 308/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.1073 - val_loss: 8.1332\n",
      "Epoch 309/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1222 - val_loss: 7.8793\n",
      "Epoch 310/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.0452 - val_loss: 7.8860\n",
      "Epoch 311/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.0952 - val_loss: 7.8107\n",
      "Epoch 312/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.1025 - val_loss: 7.4674\n",
      "Epoch 313/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1138 - val_loss: 7.5048\n",
      "Epoch 314/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.0272 - val_loss: 7.2295\n",
      "Epoch 315/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.2219 - val_loss: 7.5683\n",
      "Epoch 316/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.0691 - val_loss: 8.0628\n",
      "Epoch 317/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.1390 - val_loss: 8.1267\n",
      "Epoch 318/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.0315 - val_loss: 7.9785\n",
      "Epoch 319/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0326 - val_loss: 7.9927\n",
      "Epoch 320/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.0552 - val_loss: 7.6827\n",
      "Epoch 321/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9956 - val_loss: 7.5483\n",
      "Epoch 322/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0448 - val_loss: 7.6773\n",
      "Epoch 323/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1375 - val_loss: 7.9536\n",
      "Epoch 324/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.0261 - val_loss: 7.5972\n",
      "Epoch 325/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 5.0113 - val_loss: 7.5744\n",
      "Epoch 326/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.9926 - val_loss: 7.2775\n",
      "Epoch 327/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.0050 - val_loss: 7.4520\n",
      "Epoch 328/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0456 - val_loss: 7.3521\n",
      "Epoch 329/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9537 - val_loss: 7.3813\n",
      "Epoch 330/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0624 - val_loss: 7.4440\n",
      "Epoch 331/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9943 - val_loss: 7.4603\n",
      "Epoch 332/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0134 - val_loss: 7.1941\n",
      "Epoch 333/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0151 - val_loss: 7.4791\n",
      "Epoch 334/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9662 - val_loss: 7.4953\n",
      "Epoch 335/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9029 - val_loss: 7.5489\n",
      "Epoch 336/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8716 - val_loss: 7.4176\n",
      "Epoch 337/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0443 - val_loss: 7.2170\n",
      "Epoch 338/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9030 - val_loss: 7.6536\n",
      "Epoch 339/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8178 - val_loss: 7.5897\n",
      "Epoch 340/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9010 - val_loss: 7.2563\n",
      "Epoch 341/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8759 - val_loss: 7.5382\n",
      "Epoch 342/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8515 - val_loss: 7.1893\n",
      "Epoch 343/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.7887 - val_loss: 7.4392\n",
      "Epoch 344/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.8117 - val_loss: 7.5619\n",
      "Epoch 345/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8581 - val_loss: 7.4934\n",
      "Epoch 346/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8369 - val_loss: 7.2489\n",
      "Epoch 347/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8474 - val_loss: 7.7482\n",
      "Epoch 348/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9296 - val_loss: 7.6678\n",
      "Epoch 349/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7651 - val_loss: 7.6187\n",
      "Epoch 350/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8484 - val_loss: 7.7048\n",
      "Epoch 351/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7826 - val_loss: 7.4588\n",
      "Epoch 352/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.8345 - val_loss: 7.5526\n",
      "Epoch 353/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7840 - val_loss: 7.8157\n",
      "Epoch 354/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7248 - val_loss: 7.5862\n",
      "Epoch 355/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8732 - val_loss: 7.6440\n",
      "Epoch 356/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.8082 - val_loss: 7.7842\n",
      "Epoch 357/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 4.8072 - val_loss: 7.7732\n",
      "Epoch 358/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8718 - val_loss: 7.3316\n",
      "Epoch 359/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.8347 - val_loss: 7.4745\n",
      "Epoch 360/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.0111 - val_loss: 7.6144\n",
      "Epoch 361/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.9039 - val_loss: 7.6119\n",
      "Epoch 362/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8751 - val_loss: 7.7602\n",
      "Epoch 363/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8922 - val_loss: 7.8227\n",
      "Epoch 364/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.8517 - val_loss: 7.3190\n",
      "Epoch 365/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8045 - val_loss: 7.6212\n",
      "Epoch 366/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7044 - val_loss: 7.5184\n",
      "Epoch 367/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.7755 - val_loss: 7.6542\n",
      "Epoch 368/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8858 - val_loss: 7.4977\n",
      "Epoch 369/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7072 - val_loss: 7.5340\n",
      "Epoch 370/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7422 - val_loss: 7.5231\n",
      "Epoch 371/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.8102 - val_loss: 7.8275\n",
      "Epoch 372/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7557 - val_loss: 7.9125\n",
      "Epoch 373/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.7695 - val_loss: 7.7546\n",
      "Epoch 374/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 4.8454 - val_loss: 7.6832\n",
      "Epoch 375/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 109us/step - loss: 4.7826 - val_loss: 7.6053\n",
      "Epoch 376/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8264 - val_loss: 7.4448\n",
      "Epoch 377/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7122 - val_loss: 7.8769\n",
      "Epoch 378/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8282 - val_loss: 7.6218\n",
      "Epoch 379/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.6651 - val_loss: 7.1964\n",
      "Epoch 380/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7273 - val_loss: 7.9245\n",
      "Epoch 381/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.7831 - val_loss: 7.6090\n",
      "Epoch 382/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7627 - val_loss: 7.6149\n",
      "Epoch 383/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7582 - val_loss: 7.4162\n",
      "Epoch 384/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6820 - val_loss: 7.4921\n",
      "Epoch 385/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7126 - val_loss: 7.5972\n",
      "Epoch 386/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6951 - val_loss: 7.6063\n",
      "Epoch 387/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8308 - val_loss: 7.2243\n",
      "Epoch 388/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7512 - val_loss: 7.5716\n",
      "Epoch 389/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.6807 - val_loss: 7.6425\n",
      "Epoch 390/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6989 - val_loss: 7.5174\n",
      "Epoch 391/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6495 - val_loss: 7.4554\n",
      "Epoch 392/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6910 - val_loss: 7.4447\n",
      "Epoch 393/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7699 - val_loss: 7.4166\n",
      "Epoch 394/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6783 - val_loss: 7.7818\n",
      "Epoch 395/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8324 - val_loss: 7.4537\n",
      "Epoch 396/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6781 - val_loss: 7.8884\n",
      "Epoch 397/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6536 - val_loss: 7.7766\n",
      "Epoch 398/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6240 - val_loss: 7.6836\n",
      "Epoch 399/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6808 - val_loss: 7.3170\n",
      "Epoch 400/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6085 - val_loss: 7.6294\n",
      "Epoch 401/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6255 - val_loss: 8.0837\n",
      "Epoch 402/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6086 - val_loss: 7.4363\n",
      "Epoch 403/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.5766 - val_loss: 7.7359\n",
      "Epoch 404/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6603 - val_loss: 7.6456\n",
      "Epoch 405/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6296 - val_loss: 7.5180\n",
      "Epoch 406/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6303 - val_loss: 7.4124\n",
      "Epoch 407/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.6748 - val_loss: 7.9430\n",
      "Epoch 408/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.8270 - val_loss: 7.3007\n",
      "Epoch 409/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7885 - val_loss: 7.1426\n",
      "Epoch 410/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.7732 - val_loss: 7.7341\n",
      "Epoch 411/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6563 - val_loss: 7.4528\n",
      "Epoch 412/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5956 - val_loss: 7.7764\n",
      "Epoch 413/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6380 - val_loss: 7.5754\n",
      "Epoch 414/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.6175 - val_loss: 7.3171\n",
      "Epoch 415/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.5686 - val_loss: 7.2690\n",
      "Epoch 416/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.5329 - val_loss: 7.7126\n",
      "Epoch 417/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6310 - val_loss: 7.5125\n",
      "Epoch 418/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 4.6300 - val_loss: 7.0721\n",
      "Epoch 419/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.7153 - val_loss: 7.0589\n",
      "Epoch 420/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.6385 - val_loss: 7.7152\n",
      "Epoch 421/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.6601 - val_loss: 7.7283\n",
      "Epoch 422/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6353 - val_loss: 7.3125\n",
      "Epoch 423/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.6061 - val_loss: 7.3157\n",
      "Epoch 424/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8266 - val_loss: 7.4645\n",
      "Epoch 425/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5333 - val_loss: 7.1724\n",
      "Epoch 426/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.5313 - val_loss: 7.3440\n",
      "Epoch 427/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.6930 - val_loss: 7.5830\n",
      "Epoch 428/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6735 - val_loss: 7.0784\n",
      "Epoch 429/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.7573 - val_loss: 7.2035\n",
      "Epoch 430/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8169 - val_loss: 7.2862\n",
      "Epoch 431/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.6395 - val_loss: 7.5215\n",
      "Epoch 432/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6372 - val_loss: 7.4404\n",
      "Epoch 433/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5932 - val_loss: 7.6701\n",
      "Epoch 434/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.5985 - val_loss: 7.1708\n",
      "Epoch 435/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6335 - val_loss: 7.2512\n",
      "Epoch 436/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.5238 - val_loss: 7.1054\n",
      "Epoch 437/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5973 - val_loss: 7.0333\n",
      "Epoch 438/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5458 - val_loss: 7.1133\n",
      "Epoch 439/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4813 - val_loss: 7.3139\n",
      "Epoch 440/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.5484 - val_loss: 7.0763\n",
      "Epoch 441/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4887 - val_loss: 7.0406\n",
      "Epoch 442/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5199 - val_loss: 7.0257\n",
      "Epoch 443/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5448 - val_loss: 7.1671\n",
      "Epoch 444/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.5436 - val_loss: 7.1456\n",
      "Epoch 445/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4392 - val_loss: 6.7992\n",
      "Epoch 446/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 4.5366 - val_loss: 6.8094\n",
      "Epoch 447/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4804 - val_loss: 6.8042\n",
      "Epoch 448/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4603 - val_loss: 6.9348\n",
      "Epoch 449/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4506 - val_loss: 6.7685\n",
      "Epoch 450/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4809 - val_loss: 6.6075\n",
      "Epoch 451/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.6953 - val_loss: 6.8970\n",
      "Epoch 452/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 105us/step - loss: 4.4653 - val_loss: 6.9937\n",
      "Epoch 453/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4917 - val_loss: 6.5458\n",
      "Epoch 454/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5349 - val_loss: 6.8738\n",
      "Epoch 455/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.5750 - val_loss: 6.9620\n",
      "Epoch 456/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5282 - val_loss: 6.9699\n",
      "Epoch 457/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4897 - val_loss: 6.7220\n",
      "Epoch 458/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.4724 - val_loss: 6.8573\n",
      "Epoch 459/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5293 - val_loss: 6.8636\n",
      "Epoch 460/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.4231 - val_loss: 6.7649\n",
      "Epoch 461/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4259 - val_loss: 6.8330\n",
      "Epoch 462/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.4333 - val_loss: 6.7723\n",
      "Epoch 463/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4162 - val_loss: 6.8106\n",
      "Epoch 464/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4657 - val_loss: 6.6326\n",
      "Epoch 465/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3630 - val_loss: 6.6376\n",
      "Epoch 466/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5053 - val_loss: 6.5719\n",
      "Epoch 467/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.4902 - val_loss: 6.7719\n",
      "Epoch 468/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.4285 - val_loss: 6.6455\n",
      "Epoch 469/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5372 - val_loss: 6.5797\n",
      "Epoch 470/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4697 - val_loss: 6.6379\n",
      "Epoch 471/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4031 - val_loss: 6.7005\n",
      "Epoch 472/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3592 - val_loss: 6.7548\n",
      "Epoch 473/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.3962 - val_loss: 6.7384\n",
      "Epoch 474/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.4164 - val_loss: 6.6550\n",
      "Epoch 475/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3683 - val_loss: 6.6600\n",
      "Epoch 476/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.3905 - val_loss: 6.5664\n",
      "Epoch 477/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5748 - val_loss: 6.6144\n",
      "Epoch 478/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.4774 - val_loss: 6.4518\n",
      "Epoch 479/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4521 - val_loss: 6.4806\n",
      "Epoch 480/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3921 - val_loss: 6.5704\n",
      "Epoch 481/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3453 - val_loss: 6.4786\n",
      "Epoch 482/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3540 - val_loss: 6.2786\n",
      "Epoch 483/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3455 - val_loss: 6.4810\n",
      "Epoch 484/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3696 - val_loss: 6.6185\n",
      "Epoch 485/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5585 - val_loss: 6.6538\n",
      "Epoch 486/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4048 - val_loss: 6.5931\n",
      "Epoch 487/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3319 - val_loss: 6.3725\n",
      "Epoch 488/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.3781 - val_loss: 6.4204\n",
      "Epoch 489/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4228 - val_loss: 6.5252\n",
      "Epoch 490/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5897 - val_loss: 6.4268\n",
      "Epoch 491/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5646 - val_loss: 6.6071\n",
      "Epoch 492/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5055 - val_loss: 6.4718\n",
      "Epoch 493/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3953 - val_loss: 6.6243\n",
      "Epoch 494/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3368 - val_loss: 6.1890\n",
      "Epoch 495/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3449 - val_loss: 6.3915\n",
      "Epoch 496/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.3755 - val_loss: 6.4340\n",
      "Epoch 497/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.4604 - val_loss: 6.3562\n",
      "Epoch 498/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.4466 - val_loss: 6.3020\n",
      "Epoch 499/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.3407 - val_loss: 6.2988\n",
      "Epoch 500/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4498 - val_loss: 6.4761\n",
      "Epoch 501/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3335 - val_loss: 6.2114\n",
      "Epoch 502/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.3457 - val_loss: 6.3701\n",
      "Epoch 503/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3963 - val_loss: 6.4275\n",
      "Epoch 504/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.3887 - val_loss: 6.4804\n",
      "Epoch 505/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3123 - val_loss: 6.2935\n",
      "Epoch 506/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.3990 - val_loss: 6.3434\n",
      "Epoch 507/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3054 - val_loss: 6.5107\n",
      "Epoch 508/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.3754 - val_loss: 6.4405\n",
      "Epoch 509/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3172 - val_loss: 6.1740\n",
      "Epoch 510/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.3768 - val_loss: 6.2587\n",
      "Epoch 511/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.4346 - val_loss: 6.5621\n",
      "Epoch 512/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.3532 - val_loss: 6.1791\n",
      "Epoch 513/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.3822 - val_loss: 6.2792\n",
      "Epoch 514/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2675 - val_loss: 6.2479\n",
      "Epoch 515/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3817 - val_loss: 6.4277\n",
      "Epoch 516/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4432 - val_loss: 6.2501\n",
      "Epoch 517/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2979 - val_loss: 6.1596\n",
      "Epoch 518/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3328 - val_loss: 6.2506\n",
      "Epoch 519/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3103 - val_loss: 6.1876\n",
      "Epoch 520/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4418 - val_loss: 6.2445\n",
      "Epoch 521/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3977 - val_loss: 6.3374\n",
      "Epoch 522/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.3844 - val_loss: 6.1528\n",
      "Epoch 523/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2709 - val_loss: 6.4909\n",
      "Epoch 524/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4043 - val_loss: 6.2708\n",
      "Epoch 525/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4056 - val_loss: 6.3348\n",
      "Epoch 526/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.3154 - val_loss: 6.2734\n",
      "Epoch 527/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3366 - val_loss: 6.1787\n",
      "Epoch 528/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3709 - val_loss: 6.1756\n",
      "Epoch 529/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 113us/step - loss: 4.3081 - val_loss: 6.5783\n",
      "Epoch 530/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3990 - val_loss: 6.1293\n",
      "Epoch 531/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2879 - val_loss: 6.1541\n",
      "Epoch 532/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2851 - val_loss: 6.3611\n",
      "Epoch 533/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3194 - val_loss: 6.2874\n",
      "Epoch 534/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2885 - val_loss: 6.1124\n",
      "Epoch 535/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.4278 - val_loss: 6.2318\n",
      "Epoch 536/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.5180 - val_loss: 6.2644\n",
      "Epoch 537/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3431 - val_loss: 6.4471\n",
      "Epoch 538/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2950 - val_loss: 6.1021\n",
      "Epoch 539/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3483 - val_loss: 6.0702\n",
      "Epoch 540/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.2741 - val_loss: 6.2768\n",
      "Epoch 541/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2836 - val_loss: 6.1696\n",
      "Epoch 542/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.3832 - val_loss: 6.1995\n",
      "Epoch 543/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.3642 - val_loss: 6.1694\n",
      "Epoch 544/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.4339 - val_loss: 6.2683\n",
      "Epoch 545/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3146 - val_loss: 6.3223\n",
      "Epoch 546/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2744 - val_loss: 6.0869\n",
      "Epoch 547/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.3350 - val_loss: 6.1917\n",
      "Epoch 548/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2749 - val_loss: 6.0518\n",
      "Epoch 549/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.2718 - val_loss: 6.2150\n",
      "Epoch 550/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3818 - val_loss: 6.2142\n",
      "Epoch 551/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3819 - val_loss: 6.1788\n",
      "Epoch 552/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3405 - val_loss: 6.1166\n",
      "Epoch 553/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.3202 - val_loss: 6.3394\n",
      "Epoch 554/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2922 - val_loss: 6.4211\n",
      "Epoch 555/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3037 - val_loss: 6.0581\n",
      "Epoch 556/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2492 - val_loss: 6.2857\n",
      "Epoch 557/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3085 - val_loss: 6.2226\n",
      "Epoch 558/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3708 - val_loss: 6.3199\n",
      "Epoch 559/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.4658 - val_loss: 6.0404\n",
      "Epoch 560/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4654 - val_loss: 6.0599\n",
      "Epoch 561/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2806 - val_loss: 6.5701\n",
      "Epoch 562/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3244 - val_loss: 5.9581\n",
      "Epoch 563/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3490 - val_loss: 6.2814\n",
      "Epoch 564/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3201 - val_loss: 6.1464\n",
      "Epoch 565/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.3346 - val_loss: 6.2871\n",
      "Epoch 566/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2886 - val_loss: 6.0953\n",
      "Epoch 567/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3595 - val_loss: 6.1954\n",
      "Epoch 568/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4175 - val_loss: 6.0866\n",
      "Epoch 569/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5263 - val_loss: 6.2002\n",
      "Epoch 570/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3286 - val_loss: 6.1760\n",
      "Epoch 571/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.3024 - val_loss: 6.6173\n",
      "Epoch 572/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5058 - val_loss: 6.1838\n",
      "Epoch 573/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4945 - val_loss: 6.1527\n",
      "Epoch 574/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4160 - val_loss: 6.2251\n",
      "Epoch 575/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.5762 - val_loss: 6.2652\n",
      "Epoch 576/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.3324 - val_loss: 6.2834\n",
      "Epoch 577/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4153 - val_loss: 6.6548\n",
      "Epoch 578/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5327 - val_loss: 6.1022\n",
      "Epoch 579/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3523 - val_loss: 6.0937\n",
      "Epoch 580/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2966 - val_loss: 6.3296\n",
      "Epoch 581/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3175 - val_loss: 6.3025\n",
      "Epoch 582/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3555 - val_loss: 6.2139\n",
      "Epoch 583/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5487 - val_loss: 6.2774\n",
      "Epoch 584/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2571 - val_loss: 6.0844\n",
      "Epoch 585/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.3361 - val_loss: 6.5324\n",
      "Epoch 586/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2963 - val_loss: 6.0503\n",
      "Epoch 587/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3750 - val_loss: 6.2456\n",
      "Epoch 588/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3063 - val_loss: 6.1931\n",
      "Epoch 589/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3190 - val_loss: 6.0755\n",
      "Epoch 590/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3571 - val_loss: 6.2836\n",
      "Epoch 591/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3715 - val_loss: 6.1926\n",
      "Epoch 592/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2610 - val_loss: 6.3842\n",
      "Epoch 593/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3160 - val_loss: 6.0659\n",
      "Epoch 594/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3336 - val_loss: 6.0554\n",
      "Epoch 595/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2981 - val_loss: 6.2068\n",
      "Epoch 596/1000\n",
      "274/274 [==============================] - 0s 115us/step - loss: 4.2714 - val_loss: 6.1129\n",
      "Epoch 597/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3116 - val_loss: 6.0877\n",
      "Epoch 598/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3320 - val_loss: 6.1578\n",
      "Epoch 599/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.3477 - val_loss: 6.2398\n",
      "Epoch 600/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.4394 - val_loss: 6.1372\n",
      "Epoch 601/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.4098 - val_loss: 6.3075\n",
      "Epoch 602/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3491 - val_loss: 6.1839\n",
      "Epoch 603/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.3087 - val_loss: 6.1408\n",
      "Epoch 604/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.2791 - val_loss: 6.0467\n",
      "Epoch 605/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2362 - val_loss: 6.2741\n",
      "Epoch 606/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 4.2323 - val_loss: 6.0028\n",
      "Epoch 607/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3065 - val_loss: 6.2291\n",
      "Epoch 608/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2784 - val_loss: 6.0863\n",
      "Epoch 609/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2844 - val_loss: 6.3739\n",
      "Epoch 610/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3305 - val_loss: 5.9265\n",
      "Epoch 611/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.3571 - val_loss: 6.1022\n",
      "Epoch 612/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3242 - val_loss: 6.1569\n",
      "Epoch 613/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3537 - val_loss: 6.1975\n",
      "Epoch 614/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2910 - val_loss: 6.0757\n",
      "Epoch 615/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2594 - val_loss: 6.0411\n",
      "Epoch 616/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.2982 - val_loss: 6.1198\n",
      "Epoch 617/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2475 - val_loss: 6.1170\n",
      "Epoch 618/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.2548 - val_loss: 6.2955\n",
      "Epoch 619/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2740 - val_loss: 6.1606\n",
      "Epoch 620/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2749 - val_loss: 6.1682\n",
      "Epoch 621/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2897 - val_loss: 6.0892\n",
      "Epoch 622/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3884 - val_loss: 6.1177\n",
      "Epoch 623/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.3804 - val_loss: 6.4687\n",
      "Epoch 624/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3950 - val_loss: 6.1155\n",
      "Epoch 625/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.3147 - val_loss: 6.5243\n",
      "Epoch 626/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3485 - val_loss: 6.0072\n",
      "Epoch 627/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3157 - val_loss: 6.3930\n",
      "Epoch 628/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.2610 - val_loss: 6.2636\n",
      "Epoch 629/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.2402 - val_loss: 5.9614\n",
      "Epoch 630/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3323 - val_loss: 6.2184\n",
      "Epoch 631/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3081 - val_loss: 6.2863\n",
      "Epoch 632/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4175 - val_loss: 6.0345\n",
      "Epoch 633/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.4908 - val_loss: 6.3921\n",
      "Epoch 634/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2545 - val_loss: 5.9976\n",
      "Epoch 635/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.3528 - val_loss: 6.5717\n",
      "Epoch 636/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.2965 - val_loss: 6.1189\n",
      "Epoch 637/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2845 - val_loss: 6.1790\n",
      "Epoch 638/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.4103 - val_loss: 6.1121\n",
      "Epoch 639/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3418 - val_loss: 6.1335\n",
      "Epoch 640/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2494 - val_loss: 6.3067\n",
      "Epoch 641/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.2659 - val_loss: 5.9901\n",
      "Epoch 642/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3735 - val_loss: 6.1819\n",
      "Epoch 643/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2070 - val_loss: 6.1554\n",
      "Epoch 644/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2560 - val_loss: 6.2454\n",
      "Epoch 645/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2255 - val_loss: 6.0629\n",
      "Epoch 646/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2459 - val_loss: 6.0276\n",
      "Epoch 647/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.2757 - val_loss: 6.1410\n",
      "Epoch 648/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2005 - val_loss: 6.0142\n",
      "Epoch 649/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2436 - val_loss: 6.3600\n",
      "Epoch 650/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.4370 - val_loss: 6.0774\n",
      "Epoch 651/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2817 - val_loss: 6.2231\n",
      "Epoch 652/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3005 - val_loss: 5.9512\n",
      "Epoch 653/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2664 - val_loss: 6.1320\n",
      "Epoch 654/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2762 - val_loss: 6.1683\n",
      "Epoch 655/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2344 - val_loss: 6.3769\n",
      "Epoch 656/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2391 - val_loss: 5.9925\n",
      "Epoch 657/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.2456 - val_loss: 6.1203\n",
      "Epoch 658/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2805 - val_loss: 6.0918\n",
      "Epoch 659/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.3223 - val_loss: 6.3038\n",
      "Epoch 660/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2930 - val_loss: 6.2440\n",
      "Epoch 661/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.3784 - val_loss: 6.0549\n",
      "Epoch 662/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2424 - val_loss: 5.9677\n",
      "Epoch 663/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2889 - val_loss: 6.2393\n",
      "Epoch 664/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3255 - val_loss: 6.1661\n",
      "Epoch 665/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3999 - val_loss: 6.4647\n",
      "Epoch 666/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3184 - val_loss: 6.1017\n",
      "Epoch 667/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.3690 - val_loss: 6.1677\n",
      "Epoch 668/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2351 - val_loss: 6.1360\n",
      "Epoch 669/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2756 - val_loss: 5.9661\n",
      "Epoch 670/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3479 - val_loss: 6.0174\n",
      "Epoch 671/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2816 - val_loss: 6.5133\n",
      "Epoch 672/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.3045 - val_loss: 6.1314\n",
      "Epoch 673/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.2820 - val_loss: 6.1220\n",
      "Epoch 674/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.2555 - val_loss: 6.2780\n",
      "Epoch 675/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2094 - val_loss: 6.1732\n",
      "Epoch 676/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2184 - val_loss: 6.0568\n",
      "Epoch 677/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.2134 - val_loss: 5.9571\n",
      "Epoch 678/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2580 - val_loss: 6.2937\n",
      "Epoch 679/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3968 - val_loss: 5.9271\n",
      "Epoch 680/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1349 - val_loss: 6.5947\n",
      "Epoch 681/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3906 - val_loss: 5.9357\n",
      "Epoch 682/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2901 - val_loss: 6.1197\n",
      "Epoch 683/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 109us/step - loss: 4.1990 - val_loss: 6.1558\n",
      "Epoch 684/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2449 - val_loss: 6.2138\n",
      "Epoch 685/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3182 - val_loss: 6.2846\n",
      "Epoch 686/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4352 - val_loss: 5.9274\n",
      "Epoch 687/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2844 - val_loss: 6.3411\n",
      "Epoch 688/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.3850 - val_loss: 6.0086\n",
      "Epoch 689/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2861 - val_loss: 6.2756\n",
      "Epoch 690/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.4350 - val_loss: 6.0852\n",
      "Epoch 691/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.2406 - val_loss: 6.2849\n",
      "Epoch 692/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3237 - val_loss: 6.0352\n",
      "Epoch 693/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2516 - val_loss: 6.1145\n",
      "Epoch 694/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2209 - val_loss: 6.0501\n",
      "Epoch 695/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1973 - val_loss: 5.9943\n",
      "Epoch 696/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.2981 - val_loss: 6.1478\n",
      "Epoch 697/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.2322 - val_loss: 6.1625\n",
      "Epoch 698/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.2476 - val_loss: 5.9946\n",
      "Epoch 699/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3705 - val_loss: 6.1355\n",
      "Epoch 700/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.1649 - val_loss: 6.4373\n",
      "Epoch 701/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2610 - val_loss: 6.0419\n",
      "Epoch 702/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1959 - val_loss: 6.3934\n",
      "Epoch 703/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2178 - val_loss: 6.0592\n",
      "Epoch 704/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1757 - val_loss: 6.3049\n",
      "Epoch 705/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.2150 - val_loss: 5.9936\n",
      "Epoch 706/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2803 - val_loss: 6.1666\n",
      "Epoch 707/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.2535 - val_loss: 6.2890\n",
      "Epoch 708/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2260 - val_loss: 6.1557\n",
      "Epoch 709/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.2146 - val_loss: 6.0277\n",
      "Epoch 710/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1804 - val_loss: 6.2915\n",
      "Epoch 711/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2054 - val_loss: 6.0375\n",
      "Epoch 712/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2291 - val_loss: 6.1340\n",
      "Epoch 713/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1971 - val_loss: 6.0387\n",
      "Epoch 714/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1812 - val_loss: 6.1441\n",
      "Epoch 715/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2576 - val_loss: 6.1591\n",
      "Epoch 716/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.2549 - val_loss: 6.0978\n",
      "Epoch 717/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2199 - val_loss: 6.0738\n",
      "Epoch 718/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3031 - val_loss: 6.4236\n",
      "Epoch 719/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.3841 - val_loss: 5.9746\n",
      "Epoch 720/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3121 - val_loss: 6.4505\n",
      "Epoch 721/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2435 - val_loss: 5.9941\n",
      "Epoch 722/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2301 - val_loss: 6.0569\n",
      "Epoch 723/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2810 - val_loss: 6.0140\n",
      "Epoch 724/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1951 - val_loss: 6.1331\n",
      "Epoch 725/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1409 - val_loss: 6.1516\n",
      "Epoch 726/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2564 - val_loss: 6.3238\n",
      "Epoch 727/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.2788 - val_loss: 6.1829\n",
      "Epoch 728/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.2049 - val_loss: 6.1776\n",
      "Epoch 729/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.2612 - val_loss: 6.3106\n",
      "Epoch 730/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1371 - val_loss: 6.3038\n",
      "Epoch 731/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3153 - val_loss: 5.9997\n",
      "Epoch 732/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2680 - val_loss: 6.3198\n",
      "Epoch 733/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2108 - val_loss: 6.0329\n",
      "Epoch 734/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2503 - val_loss: 6.3330\n",
      "Epoch 735/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2075 - val_loss: 6.0858\n",
      "Epoch 736/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.3416 - val_loss: 6.3766\n",
      "Epoch 737/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2804 - val_loss: 5.9180\n",
      "Epoch 738/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4024 - val_loss: 6.1989\n",
      "Epoch 739/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1857 - val_loss: 5.8954\n",
      "Epoch 740/1000\n",
      "274/274 [==============================] - 0s 135us/step - loss: 4.2014 - val_loss: 6.4307\n",
      "Epoch 741/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.1653 - val_loss: 6.0058\n",
      "Epoch 742/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.2470 - val_loss: 6.3745\n",
      "Epoch 743/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2442 - val_loss: 6.1122\n",
      "Epoch 744/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2048 - val_loss: 6.0843\n",
      "Epoch 745/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1970 - val_loss: 6.0280\n",
      "Epoch 746/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2121 - val_loss: 6.0203\n",
      "Epoch 747/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2055 - val_loss: 6.1869\n",
      "Epoch 748/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1438 - val_loss: 5.9656\n",
      "Epoch 749/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1472 - val_loss: 6.2348\n",
      "Epoch 750/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1880 - val_loss: 6.1213\n",
      "Epoch 751/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.1691 - val_loss: 5.9456\n",
      "Epoch 752/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.1940 - val_loss: 6.2931\n",
      "Epoch 753/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 4.2044 - val_loss: 6.2137\n",
      "Epoch 754/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.2054 - val_loss: 5.9345\n",
      "Epoch 755/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.2153 - val_loss: 6.0881\n",
      "Epoch 756/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1547 - val_loss: 6.0830\n",
      "Epoch 757/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1829 - val_loss: 6.0550\n",
      "Epoch 758/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 4.1913 - val_loss: 6.2378\n",
      "Epoch 759/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1624 - val_loss: 6.1558\n",
      "Epoch 760/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 4.2255 - val_loss: 6.0421\n",
      "Epoch 761/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1556 - val_loss: 6.3018\n",
      "Epoch 762/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2392 - val_loss: 6.2029\n",
      "Epoch 763/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1573 - val_loss: 6.2993\n",
      "Epoch 764/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1970 - val_loss: 6.0495\n",
      "Epoch 765/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2400 - val_loss: 6.1204\n",
      "Epoch 766/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2345 - val_loss: 6.0784\n",
      "Epoch 767/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2922 - val_loss: 6.4509\n",
      "Epoch 768/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2984 - val_loss: 5.8712\n",
      "Epoch 769/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3310 - val_loss: 6.2165\n",
      "Epoch 770/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2413 - val_loss: 5.9255\n",
      "Epoch 771/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2270 - val_loss: 6.3080\n",
      "Epoch 772/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1595 - val_loss: 6.0573\n",
      "Epoch 773/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1874 - val_loss: 6.1416\n",
      "Epoch 774/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.1426 - val_loss: 6.0941\n",
      "Epoch 775/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1541 - val_loss: 6.0292\n",
      "Epoch 776/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2521 - val_loss: 6.3165\n",
      "Epoch 777/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2124 - val_loss: 6.0304\n",
      "Epoch 778/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.2676 - val_loss: 6.3572\n",
      "Epoch 779/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2729 - val_loss: 6.0586\n",
      "Epoch 780/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1650 - val_loss: 6.1474\n",
      "Epoch 781/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2108 - val_loss: 6.2400\n",
      "Epoch 782/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.2293 - val_loss: 5.8043\n",
      "Epoch 783/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1312 - val_loss: 6.1725\n",
      "Epoch 784/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2099 - val_loss: 6.3939\n",
      "Epoch 785/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2078 - val_loss: 6.2778\n",
      "Epoch 786/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2653 - val_loss: 6.2444\n",
      "Epoch 787/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1505 - val_loss: 6.1066\n",
      "Epoch 788/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.1712 - val_loss: 5.9593\n",
      "Epoch 789/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.1339 - val_loss: 6.1528\n",
      "Epoch 790/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1251 - val_loss: 6.2329\n",
      "Epoch 791/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.2230 - val_loss: 6.4440\n",
      "Epoch 792/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1457 - val_loss: 5.9543\n",
      "Epoch 793/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1457 - val_loss: 6.2231\n",
      "Epoch 794/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1600 - val_loss: 6.4955\n",
      "Epoch 795/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2071 - val_loss: 6.2145\n",
      "Epoch 796/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1349 - val_loss: 5.9087\n",
      "Epoch 797/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.1506 - val_loss: 6.2578\n",
      "Epoch 798/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1406 - val_loss: 6.4379\n",
      "Epoch 799/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.1776 - val_loss: 6.2828\n",
      "Epoch 800/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.1527 - val_loss: 6.2543\n",
      "Epoch 801/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1693 - val_loss: 6.4822\n",
      "Epoch 802/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2471 - val_loss: 6.4870\n",
      "Epoch 803/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2191 - val_loss: 6.5216\n",
      "Epoch 804/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3004 - val_loss: 6.3515\n",
      "Epoch 805/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0919 - val_loss: 6.4550\n",
      "Epoch 806/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1953 - val_loss: 6.2706\n",
      "Epoch 807/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0982 - val_loss: 6.5084\n",
      "Epoch 808/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.1293 - val_loss: 6.4310\n",
      "Epoch 809/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0369 - val_loss: 6.5863\n",
      "Epoch 810/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1831 - val_loss: 6.4928\n",
      "Epoch 811/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0606 - val_loss: 6.6291\n",
      "Epoch 812/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1865 - val_loss: 6.4163\n",
      "Epoch 813/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0238 - val_loss: 6.6994\n",
      "Epoch 814/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1230 - val_loss: 6.6753\n",
      "Epoch 815/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0853 - val_loss: 6.2244\n",
      "Epoch 816/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0300 - val_loss: 6.7222\n",
      "Epoch 817/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.1287 - val_loss: 6.4514\n",
      "Epoch 818/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.1208 - val_loss: 6.3120\n",
      "Epoch 819/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0956 - val_loss: 6.7866\n",
      "Epoch 820/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0826 - val_loss: 6.6169\n",
      "Epoch 821/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.0887 - val_loss: 6.6428\n",
      "Epoch 822/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0688 - val_loss: 6.9779\n",
      "Epoch 823/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1205 - val_loss: 6.8714\n",
      "Epoch 824/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.1932 - val_loss: 6.5123\n",
      "Epoch 825/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1062 - val_loss: 6.4064\n",
      "Epoch 826/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0656 - val_loss: 6.5987\n",
      "Epoch 827/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1241 - val_loss: 6.6828\n",
      "Epoch 828/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2220 - val_loss: 6.3542\n",
      "Epoch 829/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1268 - val_loss: 6.9197\n",
      "Epoch 830/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1147 - val_loss: 6.7224\n",
      "Epoch 831/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1289 - val_loss: 6.6173\n",
      "Epoch 832/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0725 - val_loss: 6.8035\n",
      "Epoch 833/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0858 - val_loss: 6.7209\n",
      "Epoch 834/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0717 - val_loss: 6.6148\n",
      "Epoch 835/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1449 - val_loss: 6.7359\n",
      "Epoch 836/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.9867 - val_loss: 6.7370\n",
      "Epoch 837/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 109us/step - loss: 4.1223 - val_loss: 6.8451\n",
      "Epoch 838/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0460 - val_loss: 6.6800\n",
      "Epoch 839/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0431 - val_loss: 6.9638\n",
      "Epoch 840/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0983 - val_loss: 6.7447\n",
      "Epoch 841/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1838 - val_loss: 7.1137\n",
      "Epoch 842/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1632 - val_loss: 6.6038\n",
      "Epoch 843/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1395 - val_loss: 7.0039\n",
      "Epoch 844/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0554 - val_loss: 6.5791\n",
      "Epoch 845/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1103 - val_loss: 6.5358\n",
      "Epoch 846/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0678 - val_loss: 7.0063\n",
      "Epoch 847/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0240 - val_loss: 6.7469\n",
      "Epoch 848/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.1069 - val_loss: 6.8759\n",
      "Epoch 849/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0080 - val_loss: 7.4190\n",
      "Epoch 850/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1045 - val_loss: 6.8411\n",
      "Epoch 851/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 4.2034 - val_loss: 7.2525\n",
      "Epoch 852/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1345 - val_loss: 6.5987\n",
      "Epoch 853/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0498 - val_loss: 7.0165\n",
      "Epoch 854/1000\n",
      "274/274 [==============================] - 0s 115us/step - loss: 4.0394 - val_loss: 6.7318\n",
      "Epoch 855/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0391 - val_loss: 6.7918\n",
      "Epoch 856/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.9989 - val_loss: 6.9762\n",
      "Epoch 857/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 4.0792 - val_loss: 7.0208\n",
      "Epoch 858/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0136 - val_loss: 6.7283\n",
      "Epoch 859/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.0263 - val_loss: 6.7686\n",
      "Epoch 860/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.0963 - val_loss: 6.9057\n",
      "Epoch 861/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0943 - val_loss: 6.9836\n",
      "Epoch 862/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.0209 - val_loss: 6.6260\n",
      "Epoch 863/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2011 - val_loss: 7.4929\n",
      "Epoch 864/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.3622 - val_loss: 6.9418\n",
      "Epoch 865/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1426 - val_loss: 6.7038\n",
      "Epoch 866/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.1214 - val_loss: 6.8380\n",
      "Epoch 867/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.1591 - val_loss: 7.0876\n",
      "Epoch 868/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.1129 - val_loss: 6.4143\n",
      "Epoch 869/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.2652 - val_loss: 7.2200\n",
      "Epoch 870/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1017 - val_loss: 6.9163\n",
      "Epoch 871/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.0418 - val_loss: 6.6591\n",
      "Epoch 872/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0470 - val_loss: 6.8145\n",
      "Epoch 873/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.0624 - val_loss: 7.0250\n",
      "Epoch 874/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.2154 - val_loss: 7.1066\n",
      "Epoch 875/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.1862 - val_loss: 7.0361\n",
      "Epoch 876/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9570 - val_loss: 6.4124\n",
      "Epoch 877/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0853 - val_loss: 7.1394\n",
      "Epoch 878/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0650 - val_loss: 6.9443\n",
      "Epoch 879/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1306 - val_loss: 6.6603\n",
      "Epoch 880/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1660 - val_loss: 7.3028\n",
      "Epoch 881/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.9985 - val_loss: 6.3816\n",
      "Epoch 882/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9345 - val_loss: 6.9509\n",
      "Epoch 883/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0810 - val_loss: 6.9825\n",
      "Epoch 884/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9922 - val_loss: 6.7415\n",
      "Epoch 885/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0768 - val_loss: 7.2388\n",
      "Epoch 886/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1708 - val_loss: 6.8890\n",
      "Epoch 887/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 3.9052 - val_loss: 7.4025\n",
      "Epoch 888/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3709 - val_loss: 6.8793\n",
      "Epoch 889/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9928 - val_loss: 7.3956\n",
      "Epoch 890/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.1412 - val_loss: 6.9129\n",
      "Epoch 891/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9855 - val_loss: 7.5527\n",
      "Epoch 892/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9591 - val_loss: 6.8268\n",
      "Epoch 893/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0876 - val_loss: 6.9785\n",
      "Epoch 894/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.1256 - val_loss: 7.4645\n",
      "Epoch 895/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.9787 - val_loss: 6.7928\n",
      "Epoch 896/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9688 - val_loss: 7.2752\n",
      "Epoch 897/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 3.9851 - val_loss: 7.1164\n",
      "Epoch 898/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9395 - val_loss: 7.2661\n",
      "Epoch 899/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9436 - val_loss: 7.2713\n",
      "Epoch 900/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9244 - val_loss: 7.0032\n",
      "Epoch 901/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9156 - val_loss: 7.3725\n",
      "Epoch 902/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9873 - val_loss: 7.0752\n",
      "Epoch 903/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.0268 - val_loss: 7.5129\n",
      "Epoch 904/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.9037 - val_loss: 7.1462\n",
      "Epoch 905/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9209 - val_loss: 7.2797\n",
      "Epoch 906/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0009 - val_loss: 7.5102\n",
      "Epoch 907/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0517 - val_loss: 7.3962\n",
      "Epoch 908/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.8746 - val_loss: 7.1928\n",
      "Epoch 909/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9824 - val_loss: 7.4440\n",
      "Epoch 910/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0212 - val_loss: 7.2417\n",
      "Epoch 911/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9795 - val_loss: 7.5927\n",
      "Epoch 912/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9598 - val_loss: 7.0574\n",
      "Epoch 913/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.9710 - val_loss: 7.3908\n",
      "Epoch 914/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 95us/step - loss: 3.9185 - val_loss: 7.4363\n",
      "Epoch 915/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8968 - val_loss: 7.5187\n",
      "Epoch 916/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.9601 - val_loss: 7.2008\n",
      "Epoch 917/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8598 - val_loss: 7.1457\n",
      "Epoch 918/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8715 - val_loss: 7.2058\n",
      "Epoch 919/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9044 - val_loss: 7.2906\n",
      "Epoch 920/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9027 - val_loss: 7.2434\n",
      "Epoch 921/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.8712 - val_loss: 7.2574\n",
      "Epoch 922/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.8925 - val_loss: 7.1338\n",
      "Epoch 923/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.9014 - val_loss: 7.2208\n",
      "Epoch 924/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0723 - val_loss: 7.2871\n",
      "Epoch 925/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9230 - val_loss: 7.2390\n",
      "Epoch 926/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9795 - val_loss: 7.1412\n",
      "Epoch 927/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1433 - val_loss: 7.1765\n",
      "Epoch 928/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8718 - val_loss: 6.8463\n",
      "Epoch 929/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0164 - val_loss: 7.0167\n",
      "Epoch 930/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8882 - val_loss: 7.0543\n",
      "Epoch 931/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8295 - val_loss: 7.0827\n",
      "Epoch 932/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9231 - val_loss: 7.4150\n",
      "Epoch 933/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 3.8996 - val_loss: 7.1415\n",
      "Epoch 934/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8759 - val_loss: 7.0792\n",
      "Epoch 935/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9151 - val_loss: 7.3848\n",
      "Epoch 936/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8657 - val_loss: 6.7853\n",
      "Epoch 937/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1056 - val_loss: 6.9315\n",
      "Epoch 938/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1888 - val_loss: 6.6250\n",
      "Epoch 939/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 3.9105 - val_loss: 7.0763\n",
      "Epoch 940/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9210 - val_loss: 6.9403\n",
      "Epoch 941/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9298 - val_loss: 7.0569\n",
      "Epoch 942/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9257 - val_loss: 7.5322\n",
      "Epoch 943/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9050 - val_loss: 7.1259\n",
      "Epoch 944/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 3.8864 - val_loss: 6.9148\n",
      "Epoch 945/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8179 - val_loss: 7.3101\n",
      "Epoch 946/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8945 - val_loss: 6.9787\n",
      "Epoch 947/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9536 - val_loss: 6.9918\n",
      "Epoch 948/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9380 - val_loss: 7.6434\n",
      "Epoch 949/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8987 - val_loss: 6.7297\n",
      "Epoch 950/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0563 - val_loss: 6.8263\n",
      "Epoch 951/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8872 - val_loss: 7.1580\n",
      "Epoch 952/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0355 - val_loss: 7.2958\n",
      "Epoch 953/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9695 - val_loss: 7.1714\n",
      "Epoch 954/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.1555 - val_loss: 7.6132\n",
      "Epoch 955/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2380 - val_loss: 7.0549\n",
      "Epoch 956/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1403 - val_loss: 7.2719\n",
      "Epoch 957/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.2162 - val_loss: 6.8807\n",
      "Epoch 958/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 3.9506 - val_loss: 7.2410\n",
      "Epoch 959/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.9449 - val_loss: 7.6113\n",
      "Epoch 960/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8368 - val_loss: 6.9622\n",
      "Epoch 961/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8934 - val_loss: 7.2815\n",
      "Epoch 962/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9792 - val_loss: 7.2153\n",
      "Epoch 963/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0286 - val_loss: 7.5644\n",
      "Epoch 964/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0367 - val_loss: 6.8281\n",
      "Epoch 965/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8908 - val_loss: 7.0016\n",
      "Epoch 966/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9229 - val_loss: 7.0567\n",
      "Epoch 967/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8970 - val_loss: 7.0999\n",
      "Epoch 968/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 3.8262 - val_loss: 6.9967\n",
      "Epoch 969/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 3.8442 - val_loss: 7.2083\n",
      "Epoch 970/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8157 - val_loss: 7.2202\n",
      "Epoch 971/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8682 - val_loss: 7.2449\n",
      "Epoch 972/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8167 - val_loss: 7.1648\n",
      "Epoch 973/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8980 - val_loss: 7.3083\n",
      "Epoch 974/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8051 - val_loss: 6.9805\n",
      "Epoch 975/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8358 - val_loss: 7.3360\n",
      "Epoch 976/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8934 - val_loss: 7.2216\n",
      "Epoch 977/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.8943 - val_loss: 7.1509\n",
      "Epoch 978/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9018 - val_loss: 7.4879\n",
      "Epoch 979/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.8802 - val_loss: 7.2810\n",
      "Epoch 980/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9598 - val_loss: 7.2682\n",
      "Epoch 981/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.8520 - val_loss: 7.1676\n",
      "Epoch 982/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8919 - val_loss: 7.1758\n",
      "Epoch 983/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 3.9450 - val_loss: 6.8913\n",
      "Epoch 984/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 3.9726 - val_loss: 7.4132\n",
      "Epoch 985/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.8460 - val_loss: 7.4508\n",
      "Epoch 986/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0594 - val_loss: 7.1967\n",
      "Epoch 987/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3520 - val_loss: 7.0423\n",
      "Epoch 988/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0605 - val_loss: 6.9960\n",
      "Epoch 989/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9701 - val_loss: 7.1225\n",
      "Epoch 990/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9347 - val_loss: 6.8488\n",
      "Epoch 991/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 91us/step - loss: 3.8769 - val_loss: 7.2134\n",
      "Epoch 992/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8627 - val_loss: 7.4632\n",
      "Epoch 993/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.7761 - val_loss: 6.8155\n",
      "Epoch 994/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.8235 - val_loss: 7.3052\n",
      "Epoch 995/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8693 - val_loss: 7.2435\n",
      "Epoch 996/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0226 - val_loss: 6.8686\n",
      "Epoch 997/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8932 - val_loss: 7.7644\n",
      "Epoch 998/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0472 - val_loss: 7.2254\n",
      "Epoch 999/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8667 - val_loss: 6.7731\n",
      "Epoch 1000/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8152 - val_loss: 7.4006\n",
      "7.165790848812814\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-2.602393  ,  0.02829075, -0.05768069,  0.18894286,  0.0348461 ],\n",
       "        [ 0.36711708,  0.16390473,  1.7725432 , -1.6706893 , -0.09129847],\n",
       "        [-1.2150987 ,  0.6919538 ,  0.4303669 ,  0.04038908, -1.3941375 ],\n",
       "        [ 0.80949277,  0.41154438, -0.6549829 , -0.14798775, -2.2688634 ],\n",
       "        [-0.12744196,  0.906149  ,  0.6035765 , -0.08853006,  0.6902179 ],\n",
       "        [-1.1379122 , -0.36782324,  2.4535136 ,  1.0528342 , -0.46240628],\n",
       "        [ 0.12341176, -2.4882882 ,  1.2593265 , -2.3518713 ,  0.0658196 ]],\n",
       "       dtype=float32),\n",
       " array([ 0.4970944 ,  0.70481455, -2.4729645 , -0.31301773, -0.16426153],\n",
       "       dtype=float32),\n",
       " array([[-2.7211897 ,  1.1551969 ,  0.83814   ,  0.45088214, -1.261206  ,\n",
       "          0.57161826,  0.81634265,  2.6362574 , -0.22535393,  3.8579538 ],\n",
       "        [-0.3434773 ,  0.12222189,  0.80744827,  0.37591806, -1.1984783 ,\n",
       "         -0.4075547 , -1.0825627 ,  0.36921167, -1.3944631 ,  0.6929098 ],\n",
       "        [-0.02752915,  0.67814803, -3.3144116 , -1.8415656 ,  1.7454609 ,\n",
       "          1.6150593 ,  0.77617764, -0.22563094,  8.135576  , -1.1169109 ],\n",
       "        [-0.7849908 , -0.42314777,  3.7202995 , -1.615981  ,  0.1922016 ,\n",
       "          1.2486197 , -1.6258186 ,  0.77668935,  0.9744877 ,  1.0970037 ],\n",
       "        [-1.792238  ,  0.5096316 ,  1.2167866 , -0.18728782,  0.67932117,\n",
       "         -0.11075225, -6.4540815 ,  1.2052416 ,  0.39027196,  0.26080045]],\n",
       "       dtype=float32),\n",
       " array([-1.2900468 ,  0.2638373 , -1.3478428 , -1.8656446 , -0.37406787,\n",
       "         0.9352587 , -2.6066518 ,  1.9759208 , -0.18609628,  0.52009267],\n",
       "       dtype=float32),\n",
       " array([[-3.6765714],\n",
       "        [ 3.4057798],\n",
       "        [ 3.0101402],\n",
       "        [-4.3426833],\n",
       "        [ 5.024019 ],\n",
       "        [ 3.3452828],\n",
       "        [-3.5443635],\n",
       "        [ 3.5901897],\n",
       "        [ 3.5305192],\n",
       "        [ 3.928789 ]], dtype=float32),\n",
       " array([2.8805492], dtype=float32)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_autompg, history_autompg, evaluate_autompg=NN_model_structure_regression_tanh(X_train_autompg, X_val_autompg, Y_train_autompg, Y_val_autompg, adam2, 32, 1000, x_test_autompg, y_test_autompg)\n",
    "model_autompg.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_autompg.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_autompg_tanh_4th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_25 (Dense)             (None, 5)                 115       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 186\n",
      "Trainable params: 186\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 143 samples, validate on 31 samples\n",
      "Epoch 1/1000\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1529 - val_loss: 0.0320\n",
      "Epoch 2/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0564 - val_loss: 0.0324\n",
      "Epoch 3/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0381 - val_loss: 0.0504\n",
      "Epoch 4/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0332 - val_loss: 0.0130\n",
      "Epoch 5/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0196 - val_loss: 0.0082\n",
      "Epoch 6/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0174 - val_loss: 0.0067\n",
      "Epoch 7/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0153 - val_loss: 0.0072\n",
      "Epoch 8/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0147 - val_loss: 0.0062\n",
      "Epoch 9/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0128 - val_loss: 0.0060\n",
      "Epoch 10/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0122 - val_loss: 0.0056\n",
      "Epoch 11/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0107 - val_loss: 0.0057\n",
      "Epoch 12/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0102 - val_loss: 0.0056\n",
      "Epoch 13/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0092 - val_loss: 0.0048\n",
      "Epoch 14/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0090 - val_loss: 0.0073\n",
      "Epoch 15/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0091 - val_loss: 0.0056\n",
      "Epoch 16/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0089 - val_loss: 0.0049\n",
      "Epoch 17/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0086 - val_loss: 0.0071\n",
      "Epoch 18/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0085 - val_loss: 0.0045\n",
      "Epoch 19/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0092 - val_loss: 0.0060\n",
      "Epoch 20/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0091 - val_loss: 0.0093\n",
      "Epoch 21/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0093 - val_loss: 0.0048\n",
      "Epoch 22/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0087 - val_loss: 0.0048\n",
      "Epoch 23/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0084 - val_loss: 0.0064\n",
      "Epoch 24/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0073 - val_loss: 0.0045\n",
      "Epoch 25/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0076 - val_loss: 0.0055\n",
      "Epoch 26/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0069 - val_loss: 0.0044\n",
      "Epoch 27/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0065 - val_loss: 0.0047\n",
      "Epoch 28/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0072 - val_loss: 0.0051\n",
      "Epoch 29/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0069 - val_loss: 0.0043\n",
      "Epoch 30/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0062 - val_loss: 0.0058\n",
      "Epoch 31/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0066 - val_loss: 0.0047\n",
      "Epoch 32/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0063 - val_loss: 0.0059\n",
      "Epoch 33/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0063 - val_loss: 0.0043\n",
      "Epoch 34/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0072 - val_loss: 0.0035\n",
      "Epoch 35/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0070 - val_loss: 0.0050\n",
      "Epoch 36/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0072 - val_loss: 0.0061\n",
      "Epoch 37/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0081 - val_loss: 0.0041\n",
      "Epoch 38/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0075 - val_loss: 0.0052\n",
      "Epoch 39/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0066 - val_loss: 0.0068\n",
      "Epoch 40/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0069 - val_loss: 0.0050\n",
      "Epoch 41/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0071 - val_loss: 0.0043\n",
      "Epoch 42/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0060 - val_loss: 0.0044\n",
      "Epoch 43/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0063 - val_loss: 0.0046\n",
      "Epoch 44/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0064 - val_loss: 0.0058\n",
      "Epoch 45/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0068 - val_loss: 0.0046\n",
      "Epoch 46/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0065 - val_loss: 0.0049\n",
      "Epoch 47/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0060 - val_loss: 0.0042\n",
      "Epoch 48/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0058 - val_loss: 0.0040\n",
      "Epoch 49/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0059 - val_loss: 0.0054\n",
      "Epoch 50/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0069 - val_loss: 0.0051\n",
      "Epoch 51/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0073 - val_loss: 0.0067\n",
      "Epoch 52/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0079 - val_loss: 0.0071\n",
      "Epoch 53/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0073 - val_loss: 0.0040\n",
      "Epoch 54/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0071 - val_loss: 0.0043\n",
      "Epoch 55/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0057 - val_loss: 0.0051\n",
      "Epoch 56/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0056 - val_loss: 0.0045\n",
      "Epoch 57/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0057 - val_loss: 0.0040\n",
      "Epoch 58/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0057 - val_loss: 0.0061\n",
      "Epoch 59/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0066 - val_loss: 0.0046\n",
      "Epoch 60/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0059 - val_loss: 0.0043\n",
      "Epoch 61/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0060 - val_loss: 0.0059\n",
      "Epoch 62/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0065 - val_loss: 0.0049\n",
      "Epoch 63/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0064 - val_loss: 0.0048\n",
      "Epoch 64/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0040\n",
      "Epoch 65/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0040\n",
      "Epoch 66/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0056 - val_loss: 0.0055\n",
      "Epoch 67/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0060 - val_loss: 0.0054\n",
      "Epoch 68/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 69/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 105us/step - loss: 0.0057 - val_loss: 0.0050\n",
      "Epoch 70/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0062 - val_loss: 0.0051\n",
      "Epoch 71/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0052 - val_loss: 0.0039\n",
      "Epoch 72/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0053 - val_loss: 0.0037\n",
      "Epoch 73/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0052 - val_loss: 0.0043\n",
      "Epoch 74/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0050 - val_loss: 0.0040\n",
      "Epoch 75/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0042\n",
      "Epoch 76/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0048 - val_loss: 0.0040\n",
      "Epoch 77/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0052 - val_loss: 0.0039\n",
      "Epoch 78/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0049\n",
      "Epoch 79/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0043\n",
      "Epoch 80/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0054 - val_loss: 0.0051\n",
      "Epoch 81/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0048 - val_loss: 0.0040\n",
      "Epoch 82/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0041\n",
      "Epoch 83/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0042\n",
      "Epoch 84/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0049 - val_loss: 0.0037\n",
      "Epoch 85/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 86/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0042\n",
      "Epoch 87/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0047 - val_loss: 0.0039\n",
      "Epoch 88/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0042\n",
      "Epoch 89/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0043\n",
      "Epoch 90/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0039\n",
      "Epoch 91/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0060\n",
      "Epoch 92/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0052 - val_loss: 0.0043\n",
      "Epoch 93/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0048 - val_loss: 0.0044\n",
      "Epoch 94/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0041\n",
      "Epoch 95/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0038\n",
      "Epoch 96/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0046 - val_loss: 0.0041\n",
      "Epoch 97/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 98/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0045 - val_loss: 0.0042\n",
      "Epoch 99/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0044\n",
      "Epoch 100/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0044\n",
      "Epoch 101/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0040\n",
      "Epoch 102/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0043\n",
      "Epoch 103/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0045 - val_loss: 0.0039\n",
      "Epoch 104/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0053 - val_loss: 0.0047\n",
      "Epoch 105/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0042\n",
      "Epoch 106/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0040\n",
      "Epoch 107/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0044\n",
      "Epoch 108/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.002 - 0s 119us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 109/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0036\n",
      "Epoch 110/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0055 - val_loss: 0.0042\n",
      "Epoch 111/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0041\n",
      "Epoch 112/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0042 - val_loss: 0.0034\n",
      "Epoch 113/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 114/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0070\n",
      "Epoch 115/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0039\n",
      "Epoch 116/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0044\n",
      "Epoch 117/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0043 - val_loss: 0.0036\n",
      "Epoch 118/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0042 - val_loss: 0.0034\n",
      "Epoch 119/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 120/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0035\n",
      "Epoch 121/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0034\n",
      "Epoch 122/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 123/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0056\n",
      "Epoch 124/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0034\n",
      "Epoch 125/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0041\n",
      "Epoch 126/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0040 - val_loss: 0.0037\n",
      "Epoch 127/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0040 - val_loss: 0.0034\n",
      "Epoch 128/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0074\n",
      "Epoch 129/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0048 - val_loss: 0.0057\n",
      "Epoch 130/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0070\n",
      "Epoch 131/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0035\n",
      "Epoch 132/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0051 - val_loss: 0.0041\n",
      "Epoch 133/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0074\n",
      "Epoch 134/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0051 - val_loss: 0.0052\n",
      "Epoch 135/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0058 - val_loss: 0.0044\n",
      "Epoch 136/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0055\n",
      "Epoch 137/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0058 - val_loss: 0.0047\n",
      "Epoch 138/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0053\n",
      "Epoch 139/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0036\n",
      "Epoch 140/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0059\n",
      "Epoch 141/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0050 - val_loss: 0.0032\n",
      "Epoch 142/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0032\n",
      "Epoch 143/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 144/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0032\n",
      "Epoch 145/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0039 - val_loss: 0.0047\n",
      "Epoch 146/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 147/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 148/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0030\n",
      "Epoch 149/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0031\n",
      "Epoch 150/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0031\n",
      "Epoch 151/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0035 - val_loss: 0.0032\n",
      "Epoch 152/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 153/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0037 - val_loss: 0.0034\n",
      "Epoch 154/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0031\n",
      "Epoch 155/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0033\n",
      "Epoch 156/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0033\n",
      "Epoch 157/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0032\n",
      "Epoch 158/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 159/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0032\n",
      "Epoch 160/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 161/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0033\n",
      "Epoch 162/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0040 - val_loss: 0.0053\n",
      "Epoch 163/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0033\n",
      "Epoch 164/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0030\n",
      "Epoch 165/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0040 - val_loss: 0.0035\n",
      "Epoch 166/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0045\n",
      "Epoch 167/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0033\n",
      "Epoch 168/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0034\n",
      "Epoch 169/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0037 - val_loss: 0.0044\n",
      "Epoch 170/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0027\n",
      "Epoch 171/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0034 - val_loss: 0.0029\n",
      "Epoch 172/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0038 - val_loss: 0.0044\n",
      "Epoch 173/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0029\n",
      "Epoch 174/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 175/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0033 - val_loss: 0.0029\n",
      "Epoch 176/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0031 - val_loss: 0.0029\n",
      "Epoch 177/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0033 - val_loss: 0.0051\n",
      "Epoch 178/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0042 - val_loss: 0.0032\n",
      "Epoch 179/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 180/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0037\n",
      "Epoch 181/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0034 - val_loss: 0.0027\n",
      "Epoch 182/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0033 - val_loss: 0.0028\n",
      "Epoch 183/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0035 - val_loss: 0.0054\n",
      "Epoch 184/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0041 - val_loss: 0.0035\n",
      "Epoch 185/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 186/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0032 - val_loss: 0.0028\n",
      "Epoch 187/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0035\n",
      "Epoch 188/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 189/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 190/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0077\n",
      "Epoch 191/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0052\n",
      "Epoch 192/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0050 - val_loss: 0.0038\n",
      "Epoch 193/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0044 - val_loss: 0.0035\n",
      "Epoch 194/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 195/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0050\n",
      "Epoch 196/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0027\n",
      "Epoch 197/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0032 - val_loss: 0.0027\n",
      "Epoch 198/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 199/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0031 - val_loss: 0.0026\n",
      "Epoch 200/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0032\n",
      "Epoch 201/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0026\n",
      "Epoch 202/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0028\n",
      "Epoch 203/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 204/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 205/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0026\n",
      "Epoch 206/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0037\n",
      "Epoch 207/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0032 - val_loss: 0.0039\n",
      "Epoch 208/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0053\n",
      "Epoch 209/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0040 - val_loss: 0.0029\n",
      "Epoch 210/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0028\n",
      "Epoch 211/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0030\n",
      "Epoch 212/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0026\n",
      "Epoch 213/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 214/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 215/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0036 - val_loss: 0.0030\n",
      "Epoch 216/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0039\n",
      "Epoch 217/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0026\n",
      "Epoch 218/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0026\n",
      "Epoch 219/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0029 - val_loss: 0.0025\n",
      "Epoch 220/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0024\n",
      "Epoch 221/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 222/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 223/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 109us/step - loss: 0.0028 - val_loss: 0.0038\n",
      "Epoch 224/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0031 - val_loss: 0.0025\n",
      "Epoch 225/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0032 - val_loss: 0.0031\n",
      "Epoch 226/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0032 - val_loss: 0.0030\n",
      "Epoch 227/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0026\n",
      "Epoch 228/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 229/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0033\n",
      "Epoch 230/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 231/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 232/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0042 - val_loss: 0.0038\n",
      "Epoch 233/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0045 - val_loss: 0.0058\n",
      "Epoch 234/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0043\n",
      "Epoch 235/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0040 - val_loss: 0.0050\n",
      "Epoch 236/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0038 - val_loss: 0.0025\n",
      "Epoch 237/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0026\n",
      "Epoch 238/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 239/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0030\n",
      "Epoch 240/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 241/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0031 - val_loss: 0.0027\n",
      "Epoch 242/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 243/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0024\n",
      "Epoch 244/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0030 - val_loss: 0.0034\n",
      "Epoch 245/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0035 - val_loss: 0.0027\n",
      "Epoch 246/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0024\n",
      "Epoch 247/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0032 - val_loss: 0.0035\n",
      "Epoch 248/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 249/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0038\n",
      "Epoch 250/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0025\n",
      "Epoch 251/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0033\n",
      "Epoch 252/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0025\n",
      "Epoch 253/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 254/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 255/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 256/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0027\n",
      "Epoch 257/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0031\n",
      "Epoch 258/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 259/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0029\n",
      "Epoch 260/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 261/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Epoch 262/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0027\n",
      "Epoch 263/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0026\n",
      "Epoch 264/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0048\n",
      "Epoch 265/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0031 - val_loss: 0.0026\n",
      "Epoch 266/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 267/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 268/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 269/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0027\n",
      "Epoch 270/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 271/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 272/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0024\n",
      "Epoch 273/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0028 - val_loss: 0.0038\n",
      "Epoch 274/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0029 - val_loss: 0.0025\n",
      "Epoch 275/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0024\n",
      "Epoch 276/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 277/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0028 - val_loss: 0.0023\n",
      "Epoch 278/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Epoch 279/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0024\n",
      "Epoch 280/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0029 - val_loss: 0.0024\n",
      "Epoch 281/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0032\n",
      "Epoch 282/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 283/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 284/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 285/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0039\n",
      "Epoch 286/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0031\n",
      "Epoch 287/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0037 - val_loss: 0.0029\n",
      "Epoch 288/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 289/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 290/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0024\n",
      "Epoch 291/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 292/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 293/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 294/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0026 - val_loss: 0.0034\n",
      "Epoch 295/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0026\n",
      "Epoch 296/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 297/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 298/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 299/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 300/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 126us/step - loss: 0.0028 - val_loss: 0.0031\n",
      "Epoch 301/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 302/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 303/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 304/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 305/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0029 - val_loss: 0.0023\n",
      "Epoch 306/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 307/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 308/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 309/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 310/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 311/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 312/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0043\n",
      "Epoch 313/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0023\n",
      "Epoch 314/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0029 - val_loss: 0.0026\n",
      "Epoch 315/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0036\n",
      "Epoch 316/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 317/1000\n",
      "143/143 [==============================] - 0s 377us/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 318/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0028 - val_loss: 0.0024\n",
      "Epoch 319/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 320/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0035\n",
      "Epoch 321/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 322/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 323/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0029 - val_loss: 0.0033\n",
      "Epoch 324/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 325/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0023 - val_loss: 0.0057\n",
      "Epoch 326/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 327/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 328/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0024\n",
      "Epoch 329/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 330/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0025 - val_loss: 0.0032\n",
      "Epoch 331/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0023\n",
      "Epoch 332/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 333/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 334/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 335/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0039\n",
      "Epoch 336/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0026\n",
      "Epoch 337/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0023\n",
      "Epoch 338/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0028\n",
      "Epoch 339/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 340/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 341/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 342/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 343/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 344/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 345/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0044\n",
      "Epoch 346/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 347/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0024\n",
      "Epoch 348/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 349/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 350/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0041\n",
      "Epoch 351/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 352/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0024\n",
      "Epoch 353/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 354/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 355/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 356/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 357/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 358/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0025 - val_loss: 0.0037\n",
      "Epoch 359/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0029 - val_loss: 0.0023\n",
      "Epoch 360/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 361/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 362/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 363/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 364/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 365/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 366/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0026 - val_loss: 0.0047\n",
      "Epoch 367/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0027\n",
      "Epoch 368/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0035\n",
      "Epoch 369/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 370/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0022\n",
      "Epoch 371/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 372/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 373/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0035\n",
      "Epoch 374/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0028\n",
      "Epoch 375/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 376/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 377/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 378/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0034\n",
      "Epoch 379/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 380/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 381/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 382/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0034\n",
      "Epoch 383/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 384/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 385/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 386/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 387/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 388/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 389/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 390/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 391/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 392/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0022 - val_loss: 0.0029\n",
      "Epoch 393/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 394/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 395/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 396/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0033\n",
      "Epoch 397/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 398/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 399/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 400/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 401/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 402/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 403/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 404/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 405/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 406/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 407/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0033\n",
      "Epoch 408/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 409/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 410/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0049\n",
      "Epoch 411/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0025\n",
      "Epoch 412/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0023\n",
      "Epoch 413/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 414/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 415/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 416/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0036\n",
      "Epoch 417/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0023\n",
      "Epoch 418/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 419/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 420/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 421/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 422/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0024\n",
      "Epoch 423/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 424/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0039\n",
      "Epoch 425/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 426/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0027 - val_loss: 0.0024\n",
      "Epoch 427/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 428/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 429/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 430/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 431/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 432/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 433/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 434/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0034\n",
      "Epoch 435/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 436/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0033\n",
      "Epoch 437/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 438/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 439/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 440/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 441/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 442/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0020 - val_loss: 0.0025\n",
      "Epoch 443/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 444/1000\n",
      "143/143 [==============================] - 0s 131us/step - loss: 0.0027 - val_loss: 0.0042\n",
      "Epoch 445/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0031 - val_loss: 0.0048\n",
      "Epoch 446/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0045 - val_loss: 0.0062\n",
      "Epoch 447/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0040 - val_loss: 0.0022\n",
      "Epoch 448/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0025\n",
      "Epoch 449/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 450/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 451/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0028 - val_loss: 0.0050\n",
      "Epoch 452/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0032 - val_loss: 0.0023\n",
      "Epoch 453/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 454/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 118us/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 455/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 456/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0027 - val_loss: 0.0022\n",
      "Epoch 457/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 458/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 459/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 460/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 461/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 462/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 463/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 464/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 465/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 466/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0020 - val_loss: 0.0028\n",
      "Epoch 467/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 468/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0028\n",
      "Epoch 469/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 470/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 471/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0032\n",
      "Epoch 472/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 473/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 474/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 475/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 476/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0035\n",
      "Epoch 477/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 478/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0021 - val_loss: 0.0031\n",
      "Epoch 479/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 480/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 481/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 482/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 483/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0045\n",
      "Epoch 484/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 485/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 486/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 487/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 488/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 489/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 490/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 491/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 492/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0020 - val_loss: 0.0028\n",
      "Epoch 493/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 494/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0030\n",
      "Epoch 495/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 496/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0020 - val_loss: 0.0025\n",
      "Epoch 497/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 498/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 499/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 500/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0025 - val_loss: 0.0036\n",
      "Epoch 501/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 502/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 503/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0032\n",
      "Epoch 504/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 505/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 506/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 507/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 508/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 509/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 510/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0025\n",
      "Epoch 511/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 512/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 513/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0020 - val_loss: 0.0034\n",
      "Epoch 514/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 515/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0032\n",
      "Epoch 516/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 517/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 518/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0028\n",
      "Epoch 519/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 520/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0020 - val_loss: 0.0038\n",
      "Epoch 521/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 522/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 523/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0031\n",
      "Epoch 524/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 525/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0027\n",
      "Epoch 526/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 527/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 528/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 529/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 530/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 531/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0027\n",
      "Epoch 532/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 533/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 534/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 535/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 536/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0033\n",
      "Epoch 537/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 538/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 539/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 540/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0029\n",
      "Epoch 541/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0028\n",
      "Epoch 542/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 543/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 544/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 545/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0032\n",
      "Epoch 546/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0018 - val_loss: 0.0032\n",
      "Epoch 547/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 548/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 549/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 550/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0035\n",
      "Epoch 551/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 552/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 553/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0032\n",
      "Epoch 554/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 555/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0027\n",
      "Epoch 556/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 557/1000\n",
      "143/143 [==============================] - 0s 223us/step - loss: 0.0018 - val_loss: 0.0032\n",
      "Epoch 558/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 559/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 560/1000\n",
      "143/143 [==============================] - 0s 167us/step - loss: 0.0018 - val_loss: 0.0028\n",
      "Epoch 561/1000\n",
      "143/143 [==============================] - 0s 188us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 562/1000\n",
      "143/143 [==============================] - 0s 174us/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 563/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0017 - val_loss: 0.0026\n",
      "Epoch 564/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0027\n",
      "Epoch 565/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0026\n",
      "Epoch 566/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0047\n",
      "Epoch 567/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 568/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 569/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0037\n",
      "Epoch 570/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 571/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0026 - val_loss: 0.0039\n",
      "Epoch 572/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 573/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 574/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 575/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 576/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 577/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0036\n",
      "Epoch 578/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 579/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 580/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 581/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 582/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0025\n",
      "Epoch 583/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0032\n",
      "Epoch 584/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0028\n",
      "Epoch 585/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0032\n",
      "Epoch 586/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 587/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 588/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0037\n",
      "Epoch 589/1000\n",
      "143/143 [==============================] - 0s 100us/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 590/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0025\n",
      "Epoch 591/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0034\n",
      "Epoch 592/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 593/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 594/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0017 - val_loss: 0.0031\n",
      "Epoch 595/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0028\n",
      "Epoch 596/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0033\n",
      "Epoch 597/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 598/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 599/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 600/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 601/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0027\n",
      "Epoch 602/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 603/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 604/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0017 - val_loss: 0.0028\n",
      "Epoch 605/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0022 - val_loss: 0.0034\n",
      "Epoch 606/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 607/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0031\n",
      "Epoch 608/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0030\n",
      "Epoch 609/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 610/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0029\n",
      "Epoch 611/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0027\n",
      "Epoch 612/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 613/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0032\n",
      "Epoch 614/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 615/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0018 - val_loss: 0.0026\n",
      "Epoch 616/1000\n",
      "143/143 [==============================] - 0s 140us/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 617/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0017 - val_loss: 0.0028\n",
      "Epoch 618/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0030\n",
      "Epoch 619/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0027\n",
      "Epoch 620/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0017 - val_loss: 0.0031\n",
      "Epoch 621/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 622/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 623/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0028\n",
      "Epoch 624/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0021 - val_loss: 0.0043\n",
      "Epoch 625/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 626/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0024 - val_loss: 0.0034\n",
      "Epoch 627/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0024 - val_loss: 0.0032\n",
      "Epoch 628/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 629/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0031\n",
      "Epoch 630/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0027\n",
      "Epoch 631/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0026\n",
      "Epoch 632/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0030\n",
      "Epoch 633/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0027\n",
      "Epoch 634/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 635/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 636/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0027\n",
      "Epoch 637/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0027\n",
      "Epoch 638/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0027\n",
      "Epoch 639/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0028\n",
      "Epoch 640/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0027\n",
      "Epoch 641/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0034\n",
      "Epoch 642/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0031\n",
      "Epoch 643/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 644/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 645/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0023 - val_loss: 0.0044\n",
      "Epoch 646/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 647/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0031\n",
      "Epoch 648/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 649/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0027\n",
      "Epoch 650/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0019 - val_loss: 0.0034\n",
      "Epoch 651/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 652/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0027\n",
      "Epoch 653/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0036\n",
      "Epoch 654/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0020 - val_loss: 0.0030\n",
      "Epoch 655/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0031\n",
      "Epoch 656/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 657/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0027\n",
      "Epoch 658/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0031\n",
      "Epoch 659/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0018 - val_loss: 0.0026\n",
      "Epoch 660/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0027\n",
      "Epoch 661/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0035\n",
      "Epoch 662/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 663/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 664/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0041\n",
      "Epoch 665/1000\n",
      "143/143 [==============================] - 0s 127us/step - loss: 0.0020 - val_loss: 0.0035\n",
      "Epoch 666/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0038\n",
      "Epoch 667/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 668/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 669/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0020 - val_loss: 0.0037\n",
      "Epoch 670/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0029\n",
      "Epoch 671/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0028\n",
      "Epoch 672/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0033\n",
      "Epoch 673/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0026\n",
      "Epoch 674/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0028\n",
      "Epoch 675/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0027\n",
      "Epoch 676/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0032\n",
      "Epoch 677/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0015 - val_loss: 0.0027\n",
      "Epoch 678/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0033\n",
      "Epoch 679/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0028\n",
      "Epoch 680/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0027\n",
      "Epoch 681/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0033\n",
      "Epoch 682/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0028\n",
      "Epoch 683/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0020 - val_loss: 0.0028\n",
      "Epoch 684/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0018 - val_loss: 0.0031\n",
      "Epoch 685/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0027\n",
      "Epoch 686/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0029\n",
      "Epoch 687/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 688/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0028\n",
      "Epoch 689/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0015 - val_loss: 0.0028\n",
      "Epoch 690/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0015 - val_loss: 0.0028\n",
      "Epoch 691/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0015 - val_loss: 0.0033\n",
      "Epoch 692/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0019 - val_loss: 0.0031\n",
      "Epoch 693/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0028\n",
      "Epoch 694/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 695/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0019 - val_loss: 0.0027\n",
      "Epoch 696/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0029\n",
      "Epoch 697/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0036\n",
      "Epoch 698/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0027\n",
      "Epoch 699/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 700/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0031\n",
      "Epoch 701/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0028\n",
      "Epoch 702/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0015 - val_loss: 0.0029\n",
      "Epoch 703/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0028\n",
      "Epoch 704/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0030\n",
      "Epoch 705/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0030\n",
      "Epoch 706/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0029\n",
      "Epoch 707/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0015 - val_loss: 0.0030\n",
      "Epoch 708/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0026\n",
      "Epoch 709/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0029\n",
      "Epoch 710/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0027\n",
      "Epoch 711/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0034\n",
      "Epoch 712/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0026\n",
      "Epoch 713/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0027\n",
      "Epoch 714/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0015 - val_loss: 0.0031\n",
      "Epoch 715/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0027\n",
      "Epoch 716/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0030\n",
      "Epoch 717/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0016 - val_loss: 0.0030\n",
      "Epoch 718/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0031\n",
      "Epoch 719/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 720/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0026\n",
      "Epoch 721/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0015 - val_loss: 0.0027\n",
      "Epoch 722/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0017 - val_loss: 0.0033\n",
      "Epoch 723/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0028\n",
      "Epoch 724/1000\n",
      "143/143 [==============================] - 0s 174us/step - loss: 0.0015 - val_loss: 0.0034\n",
      "Epoch 725/1000\n",
      "143/143 [==============================] - 0s 167us/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 726/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 727/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0014 - val_loss: 0.0029\n",
      "Epoch 728/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0028\n",
      "Epoch 729/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0029\n",
      "Epoch 730/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0030\n",
      "Epoch 731/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0033\n",
      "Epoch 732/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0028\n",
      "Epoch 733/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0014 - val_loss: 0.0030\n",
      "Epoch 734/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0031\n",
      "Epoch 735/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0030\n",
      "Epoch 736/1000\n",
      "143/143 [==============================] - 0s 174us/step - loss: 0.0014 - val_loss: 0.0029\n",
      "Epoch 737/1000\n",
      "143/143 [==============================] - 0s 188us/step - loss: 0.0015 - val_loss: 0.0033\n",
      "Epoch 738/1000\n",
      "143/143 [==============================] - 0s 167us/step - loss: 0.0015 - val_loss: 0.0028\n",
      "Epoch 739/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0015 - val_loss: 0.0030\n",
      "Epoch 740/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0015 - val_loss: 0.0027\n",
      "Epoch 741/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0016 - val_loss: 0.0030\n",
      "Epoch 742/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0014 - val_loss: 0.0030\n",
      "Epoch 743/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0014 - val_loss: 0.0030\n",
      "Epoch 744/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 745/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 746/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0018 - val_loss: 0.0030\n",
      "Epoch 747/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0017 - val_loss: 0.0037\n",
      "Epoch 748/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0015 - val_loss: 0.0028\n",
      "Epoch 749/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 750/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0015 - val_loss: 0.0029\n",
      "Epoch 751/1000\n",
      "143/143 [==============================] - 0s 167us/step - loss: 0.0016 - val_loss: 0.0040\n",
      "Epoch 752/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0016 - val_loss: 0.0033\n",
      "Epoch 753/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 754/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0045\n",
      "Epoch 755/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0033\n",
      "Epoch 756/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 757/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0018 - val_loss: 0.0031\n",
      "Epoch 758/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0027\n",
      "Epoch 759/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0032\n",
      "Epoch 760/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0027\n",
      "Epoch 761/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0014 - val_loss: 0.0033\n",
      "Epoch 762/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0027\n",
      "Epoch 763/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0029\n",
      "Epoch 764/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0040\n",
      "Epoch 765/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 766/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0029\n",
      "Epoch 767/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0036\n",
      "Epoch 768/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0016 - val_loss: 0.0029\n",
      "Epoch 769/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0018 - val_loss: 0.0028\n",
      "Epoch 770/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0029\n",
      "Epoch 771/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0016 - val_loss: 0.0037\n",
      "Epoch 772/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0018 - val_loss: 0.0032\n",
      "Epoch 773/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 774/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0045\n",
      "Epoch 775/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 776/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0028\n",
      "Epoch 777/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0017 - val_loss: 0.0037\n",
      "Epoch 778/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0015 - val_loss: 0.0028\n",
      "Epoch 779/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0028\n",
      "Epoch 780/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0015 - val_loss: 0.0036\n",
      "Epoch 781/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0028\n",
      "Epoch 782/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0030\n",
      "Epoch 783/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0034\n",
      "Epoch 784/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 9.1995e-0 - 0s 119us/step - loss: 0.0014 - val_loss: 0.0031\n",
      "Epoch 785/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0040\n",
      "Epoch 786/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0018 - val_loss: 0.0028\n",
      "Epoch 787/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0015 - val_loss: 0.0031\n",
      "Epoch 788/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0015 - val_loss: 0.0031\n",
      "Epoch 789/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0029\n",
      "Epoch 790/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0014 - val_loss: 0.0030\n",
      "Epoch 791/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0034\n",
      "Epoch 792/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0031\n",
      "Epoch 793/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0031\n",
      "Epoch 794/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0016 - val_loss: 0.0030\n",
      "Epoch 795/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.001 - 0s 118us/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 796/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0018 - val_loss: 0.0033\n",
      "Epoch 797/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0018 - val_loss: 0.0034\n",
      "Epoch 798/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0015 - val_loss: 0.0031\n",
      "Epoch 799/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0032\n",
      "Epoch 800/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0030\n",
      "Epoch 801/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0029\n",
      "Epoch 802/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0014 - val_loss: 0.0029\n",
      "Epoch 803/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0014 - val_loss: 0.0031\n",
      "Epoch 804/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0016 - val_loss: 0.0030\n",
      "Epoch 805/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0016 - val_loss: 0.0034\n",
      "Epoch 806/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0035\n",
      "Epoch 807/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0016 - val_loss: 0.0029\n",
      "Epoch 808/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0016 - val_loss: 0.0030\n",
      "Epoch 809/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0036\n",
      "Epoch 810/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0028\n",
      "Epoch 811/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0030\n",
      "Epoch 812/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0046\n",
      "Epoch 813/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0031\n",
      "Epoch 814/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0029\n",
      "Epoch 815/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0019 - val_loss: 0.0052\n",
      "Epoch 816/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0037\n",
      "Epoch 817/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 818/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0036\n",
      "Epoch 819/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0030\n",
      "Epoch 820/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0030\n",
      "Epoch 821/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0030\n",
      "Epoch 822/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0033\n",
      "Epoch 823/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0030\n",
      "Epoch 824/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0014 - val_loss: 0.0030\n",
      "Epoch 825/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0033\n",
      "Epoch 826/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0030\n",
      "Epoch 827/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0031\n",
      "Epoch 828/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 829/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0035\n",
      "Epoch 830/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0035\n",
      "Epoch 831/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0038\n",
      "Epoch 832/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0032\n",
      "Epoch 833/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0018 - val_loss: 0.0030\n",
      "Epoch 834/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0016 - val_loss: 0.0038\n",
      "Epoch 835/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0031\n",
      "Epoch 836/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0033\n",
      "Epoch 837/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0014 - val_loss: 0.0033\n",
      "Epoch 838/1000\n",
      "143/143 [==============================] - 0s 167us/step - loss: 0.0014 - val_loss: 0.0031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 839/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0014 - val_loss: 0.0031\n",
      "Epoch 840/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0034\n",
      "Epoch 841/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0014 - val_loss: 0.0033\n",
      "Epoch 842/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0034\n",
      "Epoch 843/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0030\n",
      "Epoch 844/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0032\n",
      "Epoch 845/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0013 - val_loss: 0.0032\n",
      "Epoch 846/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0014 - val_loss: 0.0032\n",
      "Epoch 847/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0031\n",
      "Epoch 848/1000\n",
      "143/143 [==============================] - 0s 136us/step - loss: 0.0015 - val_loss: 0.0033\n",
      "Epoch 849/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0031\n",
      "Epoch 850/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0030\n",
      "Epoch 851/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0032\n",
      "Epoch 852/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0036\n",
      "Epoch 853/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0018 - val_loss: 0.0031\n",
      "Epoch 854/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0033\n",
      "Epoch 855/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0029\n",
      "Epoch 856/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0014 - val_loss: 0.0034\n",
      "Epoch 857/1000\n",
      "143/143 [==============================] - 0s 183us/step - loss: 0.0015 - val_loss: 0.0033\n",
      "Epoch 858/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0014 - val_loss: 0.0030\n",
      "Epoch 859/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0015 - val_loss: 0.0035\n",
      "Epoch 860/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0016 - val_loss: 0.0035\n",
      "Epoch 861/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0015 - val_loss: 0.0032\n",
      "Epoch 862/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0039\n",
      "Epoch 863/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0030\n",
      "Epoch 864/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0032\n",
      "Epoch 865/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0013 - val_loss: 0.0032\n",
      "Epoch 866/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0013 - val_loss: 0.0030\n",
      "Epoch 867/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0013 - val_loss: 0.0033\n",
      "Epoch 868/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0031\n",
      "Epoch 869/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0013 - val_loss: 0.0031\n",
      "Epoch 870/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0032\n",
      "Epoch 871/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0050\n",
      "Epoch 872/1000\n",
      "143/143 [==============================] - 0s 129us/step - loss: 0.0019 - val_loss: 0.0030\n",
      "Epoch 873/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0033\n",
      "Epoch 874/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0031\n",
      "Epoch 875/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0036\n",
      "Epoch 876/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0013 - val_loss: 0.0029\n",
      "Epoch 877/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0013 - val_loss: 0.0034\n",
      "Epoch 878/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0015 - val_loss: 0.0036\n",
      "Epoch 879/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0030\n",
      "Epoch 880/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0029\n",
      "Epoch 881/1000\n",
      "143/143 [==============================] - 0s 188us/step - loss: 0.0014 - val_loss: 0.0038\n",
      "Epoch 882/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0014 - val_loss: 0.0030\n",
      "Epoch 883/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0029\n",
      "Epoch 884/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0013 - val_loss: 0.0034\n",
      "Epoch 885/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0016 - val_loss: 0.0030\n",
      "Epoch 886/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0034\n",
      "Epoch 887/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0029\n",
      "Epoch 888/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0014 - val_loss: 0.0029\n",
      "Epoch 889/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0013 - val_loss: 0.0035\n",
      "Epoch 890/1000\n",
      "143/143 [==============================] - 0s 95us/step - loss: 0.0013 - val_loss: 0.0033\n",
      "Epoch 891/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0031\n",
      "Epoch 892/1000\n",
      "143/143 [==============================] - 0s 96us/step - loss: 0.0016 - val_loss: 0.0032\n",
      "Epoch 893/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0037\n",
      "Epoch 894/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0019 - val_loss: 0.0041\n",
      "Epoch 895/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0019 - val_loss: 0.0036\n",
      "Epoch 896/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 897/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0016 - val_loss: 0.0038\n",
      "Epoch 898/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0014 - val_loss: 0.0031\n",
      "Epoch 899/1000\n",
      "143/143 [==============================] - 0s 154us/step - loss: 0.0015 - val_loss: 0.0031\n",
      "Epoch 900/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0034\n",
      "Epoch 901/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0032\n",
      "Epoch 902/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0013 - val_loss: 0.0031\n",
      "Epoch 903/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0031\n",
      "Epoch 904/1000\n",
      "143/143 [==============================] - 0s 140us/step - loss: 0.0019 - val_loss: 0.0030\n",
      "Epoch 905/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0017 - val_loss: 0.0031\n",
      "Epoch 906/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0032\n",
      "Epoch 907/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0036\n",
      "Epoch 908/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0017 - val_loss: 0.0032\n",
      "Epoch 909/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0039\n",
      "Epoch 910/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0026 - val_loss: 0.0037\n",
      "Epoch 911/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.002 - 0s 126us/step - loss: 0.0020 - val_loss: 0.0031\n",
      "Epoch 912/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0017 - val_loss: 0.0037\n",
      "Epoch 913/1000\n",
      "143/143 [==============================] - 0s 167us/step - loss: 0.0014 - val_loss: 0.0029\n",
      "Epoch 914/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0015 - val_loss: 0.0028\n",
      "Epoch 915/1000\n",
      "143/143 [==============================] - 0s 167us/step - loss: 0.0013 - val_loss: 0.0039\n",
      "Epoch 916/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 160us/step - loss: 0.0013 - val_loss: 0.0029\n",
      "Epoch 917/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0033\n",
      "Epoch 918/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0039\n",
      "Epoch 919/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0036\n",
      "Epoch 920/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0018 - val_loss: 0.0037\n",
      "Epoch 921/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0030\n",
      "Epoch 922/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0030\n",
      "Epoch 923/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0012 - val_loss: 0.0038\n",
      "Epoch 924/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0016 - val_loss: 0.0031\n",
      "Epoch 925/1000\n",
      "143/143 [==============================] - 0s 147us/step - loss: 0.0014 - val_loss: 0.0029\n",
      "Epoch 926/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0015 - val_loss: 0.0035\n",
      "Epoch 927/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0032\n",
      "Epoch 928/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0015 - val_loss: 0.0032\n",
      "Epoch 929/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0017 - val_loss: 0.0034\n",
      "Epoch 930/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0017 - val_loss: 0.0035\n",
      "Epoch 931/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0020 - val_loss: 0.0033\n",
      "Epoch 932/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0015 - val_loss: 0.0031\n",
      "Epoch 933/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0013 - val_loss: 0.0031\n",
      "Epoch 934/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0035\n",
      "Epoch 935/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0035\n",
      "Epoch 936/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0030\n",
      "Epoch 937/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0013 - val_loss: 0.0032\n",
      "Epoch 938/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0032\n",
      "Epoch 939/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0031\n",
      "Epoch 940/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0012 - val_loss: 0.0035\n",
      "Epoch 941/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 0.0033\n",
      "Epoch 942/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0030\n",
      "Epoch 943/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0013 - val_loss: 0.0034\n",
      "Epoch 944/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0012 - val_loss: 0.0031\n",
      "Epoch 945/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0013 - val_loss: 0.0033\n",
      "Epoch 946/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0014 - val_loss: 0.0033\n",
      "Epoch 947/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0031\n",
      "Epoch 948/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0012 - val_loss: 0.0034\n",
      "Epoch 949/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0012 - val_loss: 0.0030\n",
      "Epoch 950/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0035\n",
      "Epoch 951/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0033\n",
      "Epoch 952/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0013 - val_loss: 0.0032\n",
      "Epoch 953/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0013 - val_loss: 0.0033\n",
      "Epoch 954/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0012 - val_loss: 0.0030\n",
      "Epoch 955/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0032\n",
      "Epoch 956/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0031\n",
      "Epoch 957/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0014 - val_loss: 0.0032\n",
      "Epoch 958/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0040\n",
      "Epoch 959/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0032\n",
      "Epoch 960/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0034\n",
      "Epoch 961/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0032\n",
      "Epoch 962/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0013 - val_loss: 0.0030\n",
      "Epoch 963/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0014 - val_loss: 0.0036\n",
      "Epoch 964/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0014 - val_loss: 0.0039\n",
      "Epoch 965/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0036\n",
      "Epoch 966/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0033\n",
      "Epoch 967/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0018 - val_loss: 0.0045\n",
      "Epoch 968/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0031\n",
      "Epoch 969/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0030\n",
      "Epoch 970/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0019 - val_loss: 0.0054\n",
      "Epoch 971/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0030 - val_loss: 0.0034\n",
      "Epoch 972/1000\n",
      "143/143 [==============================] - 0s 136us/step - loss: 0.0017 - val_loss: 0.0034\n",
      "Epoch 973/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0019 - val_loss: 0.0038\n",
      "Epoch 974/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0037\n",
      "Epoch 975/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0037\n",
      "Epoch 976/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0032\n",
      "Epoch 977/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 978/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0030\n",
      "Epoch 979/1000\n",
      "143/143 [==============================] - 0s 174us/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 980/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0014 - val_loss: 0.0035\n",
      "Epoch 981/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0014 - val_loss: 0.0033\n",
      "Epoch 982/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0030\n",
      "Epoch 983/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0032\n",
      "Epoch 984/1000\n",
      "143/143 [==============================] - 0s 140us/step - loss: 0.0012 - val_loss: 0.0032\n",
      "Epoch 985/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0013 - val_loss: 0.0031\n",
      "Epoch 986/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0033\n",
      "Epoch 987/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0033\n",
      "Epoch 988/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0036\n",
      "Epoch 989/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0033\n",
      "Epoch 990/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 991/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0038\n",
      "Epoch 992/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.001 - 0s 139us/step - loss: 0.0018 - val_loss: 0.0045\n",
      "Epoch 993/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0031\n",
      "Epoch 994/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0038\n",
      "Epoch 995/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0047\n",
      "Epoch 996/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0036\n",
      "Epoch 997/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 998/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 999/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0031\n",
      "Epoch 1000/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0035\n",
      "0.01423204317688942\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 0.77011985, -0.13769837, -0.389316  , -0.2538361 , -0.223971  ],\n",
       "        [ 0.08921811,  0.0023488 ,  1.1988966 , -0.6461715 , -0.05000739],\n",
       "        [-1.2783828 , -0.0096215 , -0.24032642,  0.6306417 , -0.17771125],\n",
       "        [-0.53668785,  0.0428123 ,  0.3491278 ,  0.23928878, -0.3634658 ],\n",
       "        [-0.12259349,  1.1676067 , -1.1196691 ,  0.17181726, -0.22769843],\n",
       "        [ 0.76557314, -0.3997987 ,  0.46486834, -0.40649703,  0.53394455],\n",
       "        [-0.4209577 ,  0.1317288 ,  1.5598445 , -0.40733224,  0.35997045],\n",
       "        [-0.32572052, -0.04426997,  0.35625598,  0.02966321,  0.24931712],\n",
       "        [-0.29078418,  0.5018781 , -0.47523856,  0.5272559 ,  0.77191764],\n",
       "        [ 0.7485471 , -0.19148222,  1.2126558 , -0.99541795, -0.2157849 ],\n",
       "        [-0.18963644,  0.9253079 ,  0.04138198, -0.02924821, -0.43484977],\n",
       "        [ 0.29253843, -0.7553612 , -1.1454885 ,  1.9062465 ,  0.31471717],\n",
       "        [ 0.40441692, -0.76354337, -0.47684422, -0.40905067, -0.01620788],\n",
       "        [ 1.3591845 ,  1.0019535 ,  0.0448996 ,  0.8419995 ,  0.7853654 ],\n",
       "        [ 0.17267527, -0.51241547, -0.2579225 ,  0.73398346, -0.5905496 ],\n",
       "        [ 0.35457966, -0.17967492,  0.30239   , -0.18758366,  0.3888096 ],\n",
       "        [-0.03355142, -0.16834502, -0.36546808, -0.26001045, -0.17549455],\n",
       "        [-0.08874843,  0.42383844, -0.86972016,  0.5136055 ,  0.16736467],\n",
       "        [-0.32806998,  0.7915777 , -1.130741  ,  0.8119323 ,  0.10276932],\n",
       "        [-0.35942933,  0.84279877, -0.20901816,  0.29436603,  0.23812355],\n",
       "        [-2.20508   , -0.3080084 ,  0.7111716 , -0.34422094,  0.0883875 ],\n",
       "        [-0.7660603 , -0.13067558,  0.28091955,  0.9983737 , -0.41105053]],\n",
       "       dtype=float32),\n",
       " array([-0.50756556, -0.22716399, -0.12183359, -0.00709832, -0.12418667],\n",
       "       dtype=float32),\n",
       " array([[ 1.59098893e-01,  3.15719932e-01,  4.53465044e-01,\n",
       "         -8.23324472e-02,  3.69149923e-01, -7.89229333e-01,\n",
       "         -8.44937786e-02, -5.65118790e-01, -8.26388597e-02,\n",
       "         -1.48041904e-01],\n",
       "        [ 1.87558159e-01,  2.55745312e-04, -2.10939378e-01,\n",
       "         -1.35448007e-02, -1.98130459e-01, -2.01839373e-01,\n",
       "         -1.26725301e-01, -4.08653229e-01, -5.22264242e-02,\n",
       "         -9.56059620e-02],\n",
       "        [-4.29813704e-03,  7.17907697e-02, -1.81764007e-01,\n",
       "         -2.77142990e-02, -4.97621521e-02, -5.88320233e-02,\n",
       "         -8.44517946e-02, -6.02115333e-01, -5.49217463e-02,\n",
       "         -1.43420205e-01],\n",
       "        [ 2.38202125e-01,  5.05702719e-02, -1.66986901e-02,\n",
       "         -1.33343428e-01,  3.63094091e-01, -6.80142045e-01,\n",
       "          1.19084425e-01, -7.09669471e-01, -1.00155331e-01,\n",
       "         -9.72791612e-02],\n",
       "        [ 1.82213113e-02, -1.99166879e-01,  4.86418128e-01,\n",
       "          3.48988883e-02, -2.53053874e-01,  7.78675228e-02,\n",
       "         -5.41744940e-02,  2.47182295e-01,  2.62770969e-02,\n",
       "          2.88380384e-02]], dtype=float32),\n",
       " array([-0.06631672,  0.24930322,  0.22074403,  0.04062507,  0.01826145,\n",
       "        -0.0863746 , -0.16444841, -0.05499896,  0.00650429, -0.04743893],\n",
       "       dtype=float32),\n",
       " array([[ 0.00417642],\n",
       "        [ 0.01221584],\n",
       "        [ 0.1598964 ],\n",
       "        [-0.00381707],\n",
       "        [ 0.01843854],\n",
       "        [-0.34941626],\n",
       "        [-0.00052389],\n",
       "        [-0.41106892],\n",
       "        [-0.00250222],\n",
       "        [-0.00421088]], dtype=float32),\n",
       " array([0.15619293], dtype=float32)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_automobile, history_automobile, evaluate_automobile=NN_model_structure_regression_linear(X_train_automobile, X_val_automobile, Y_train_automobile, Y_val_automobile, adam2, 32, 1000, x_test_automobile, y_test_automobile)\n",
    "model_automobile.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_automobile.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_automobile_linear_4th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_28 (Dense)             (None, 5)                 115       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 186\n",
      "Trainable params: 186\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 143 samples, validate on 31 samples\n",
      "Epoch 1/1000\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0735 - val_loss: 0.0446\n",
      "Epoch 2/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0414 - val_loss: 0.0330\n",
      "Epoch 3/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0356 - val_loss: 0.0225\n",
      "Epoch 4/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0258 - val_loss: 0.0168\n",
      "Epoch 5/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0240 - val_loss: 0.0140\n",
      "Epoch 6/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0197 - val_loss: 0.0128\n",
      "Epoch 7/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0162 - val_loss: 0.0084\n",
      "Epoch 8/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0134 - val_loss: 0.0061\n",
      "Epoch 9/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0122 - val_loss: 0.0056\n",
      "Epoch 10/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0111 - val_loss: 0.0069\n",
      "Epoch 11/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0107 - val_loss: 0.0053\n",
      "Epoch 12/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0105 - val_loss: 0.0053\n",
      "Epoch 13/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0096 - val_loss: 0.0067\n",
      "Epoch 14/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0091 - val_loss: 0.0055\n",
      "Epoch 15/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0088 - val_loss: 0.0057\n",
      "Epoch 16/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0087 - val_loss: 0.0058\n",
      "Epoch 17/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0084 - val_loss: 0.0060\n",
      "Epoch 18/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0083 - val_loss: 0.0065\n",
      "Epoch 19/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0085 - val_loss: 0.0056\n",
      "Epoch 20/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0089 - val_loss: 0.0066\n",
      "Epoch 21/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0081 - val_loss: 0.0057\n",
      "Epoch 22/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0081 - val_loss: 0.0060\n",
      "Epoch 23/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0083 - val_loss: 0.0057\n",
      "Epoch 24/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0088 - val_loss: 0.0076\n",
      "Epoch 25/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0081 - val_loss: 0.0057\n",
      "Epoch 26/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0085 - val_loss: 0.0064\n",
      "Epoch 27/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0089 - val_loss: 0.0076\n",
      "Epoch 28/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0079 - val_loss: 0.0057\n",
      "Epoch 29/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0080 - val_loss: 0.0065\n",
      "Epoch 30/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0077 - val_loss: 0.0064\n",
      "Epoch 31/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0074 - val_loss: 0.0057\n",
      "Epoch 32/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0080 - val_loss: 0.0059\n",
      "Epoch 33/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0082 - val_loss: 0.0077\n",
      "Epoch 34/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0078 - val_loss: 0.0055\n",
      "Epoch 35/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0089 - val_loss: 0.0054\n",
      "Epoch 36/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0085 - val_loss: 0.0085\n",
      "Epoch 37/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0088 - val_loss: 0.0055\n",
      "Epoch 38/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0074 - val_loss: 0.0066\n",
      "Epoch 39/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0076 - val_loss: 0.0065\n",
      "Epoch 40/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0073 - val_loss: 0.0061\n",
      "Epoch 41/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0072 - val_loss: 0.0063\n",
      "Epoch 42/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0071 - val_loss: 0.0063\n",
      "Epoch 43/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0070 - val_loss: 0.0062\n",
      "Epoch 44/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0071 - val_loss: 0.0065\n",
      "Epoch 45/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0071 - val_loss: 0.0060\n",
      "Epoch 46/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0068 - val_loss: 0.0071\n",
      "Epoch 47/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0072 - val_loss: 0.0065\n",
      "Epoch 48/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0068 - val_loss: 0.0060\n",
      "Epoch 49/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0070 - val_loss: 0.0063\n",
      "Epoch 50/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0073 - val_loss: 0.0069\n",
      "Epoch 51/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0070 - val_loss: 0.0058\n",
      "Epoch 52/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0068 - val_loss: 0.0069\n",
      "Epoch 53/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0072 - val_loss: 0.0068\n",
      "Epoch 54/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0071 - val_loss: 0.0059\n",
      "Epoch 55/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0067 - val_loss: 0.0068\n",
      "Epoch 56/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0070 - val_loss: 0.0061\n",
      "Epoch 57/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0068 - val_loss: 0.0068\n",
      "Epoch 58/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0068 - val_loss: 0.0060\n",
      "Epoch 59/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0066 - val_loss: 0.0065\n",
      "Epoch 60/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0068 - val_loss: 0.0067\n",
      "Epoch 61/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0069 - val_loss: 0.0058\n",
      "Epoch 62/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0067 - val_loss: 0.0072\n",
      "Epoch 63/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0067 - val_loss: 0.0058\n",
      "Epoch 64/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0069 - val_loss: 0.0061\n",
      "Epoch 65/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0069 - val_loss: 0.0071\n",
      "Epoch 66/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0064 - val_loss: 0.0056\n",
      "Epoch 67/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0070 - val_loss: 0.0068\n",
      "Epoch 68/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0070 - val_loss: 0.0072\n",
      "Epoch 69/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 138us/step - loss: 0.0076 - val_loss: 0.0058\n",
      "Epoch 70/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0067 - val_loss: 0.0071\n",
      "Epoch 71/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0065 - val_loss: 0.0062\n",
      "Epoch 72/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0064 - val_loss: 0.0063\n",
      "Epoch 73/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0065 - val_loss: 0.0065\n",
      "Epoch 74/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0063 - val_loss: 0.0060\n",
      "Epoch 75/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0064 - val_loss: 0.0067\n",
      "Epoch 76/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0065 - val_loss: 0.0063\n",
      "Epoch 77/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0069 - val_loss: 0.0058\n",
      "Epoch 78/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 79/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0067 - val_loss: 0.0060\n",
      "Epoch 80/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0067 - val_loss: 0.0059\n",
      "Epoch 81/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0065 - val_loss: 0.0075\n",
      "Epoch 82/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0063 - val_loss: 0.0059\n",
      "Epoch 83/1000\n",
      "143/143 [==============================] - 0s 130us/step - loss: 0.0066 - val_loss: 0.0060\n",
      "Epoch 84/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0066 - val_loss: 0.0073\n",
      "Epoch 85/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0064 - val_loss: 0.0059\n",
      "Epoch 86/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0065 - val_loss: 0.0066\n",
      "Epoch 87/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0062 - val_loss: 0.0062\n",
      "Epoch 88/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0064 - val_loss: 0.0062\n",
      "Epoch 89/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0063 - val_loss: 0.0064\n",
      "Epoch 90/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0062 - val_loss: 0.0059\n",
      "Epoch 91/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0062 - val_loss: 0.0067\n",
      "Epoch 92/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0063 - val_loss: 0.0067\n",
      "Epoch 93/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0060 - val_loss: 0.0061\n",
      "Epoch 94/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0062 - val_loss: 0.0066\n",
      "Epoch 95/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0060 - val_loss: 0.0070\n",
      "Epoch 96/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0062 - val_loss: 0.0064\n",
      "Epoch 97/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0064 - val_loss: 0.0063\n",
      "Epoch 98/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0062 - val_loss: 0.0077\n",
      "Epoch 99/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0068 - val_loss: 0.0058\n",
      "Epoch 100/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0061 - val_loss: 0.0069\n",
      "Epoch 101/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0061 - val_loss: 0.0065\n",
      "Epoch 102/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0064 - val_loss: 0.0062\n",
      "Epoch 103/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0066 - val_loss: 0.0073\n",
      "Epoch 104/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0060 - val_loss: 0.0058\n",
      "Epoch 105/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0062 - val_loss: 0.0065\n",
      "Epoch 106/1000\n",
      "143/143 [==============================] - 0s 181us/step - loss: 0.0060 - val_loss: 0.0070\n",
      "Epoch 107/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0063 - val_loss: 0.0064\n",
      "Epoch 108/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0061 - val_loss: 0.0058\n",
      "Epoch 109/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0058 - val_loss: 0.0070\n",
      "Epoch 110/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0061 - val_loss: 0.0066\n",
      "Epoch 111/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0059 - val_loss: 0.0062\n",
      "Epoch 112/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0061 - val_loss: 0.0062\n",
      "Epoch 113/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0058 - val_loss: 0.0074\n",
      "Epoch 114/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0063 - val_loss: 0.0063\n",
      "Epoch 115/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0061 - val_loss: 0.0062\n",
      "Epoch 116/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0058 - val_loss: 0.0063\n",
      "Epoch 117/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0058 - val_loss: 0.0066\n",
      "Epoch 118/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0059 - val_loss: 0.0062\n",
      "Epoch 119/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0058 - val_loss: 0.0069\n",
      "Epoch 120/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0058 - val_loss: 0.0063\n",
      "Epoch 121/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0060 - val_loss: 0.0062\n",
      "Epoch 122/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 123/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0059 - val_loss: 0.0056\n",
      "Epoch 124/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0063 - val_loss: 0.0071\n",
      "Epoch 125/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0063 - val_loss: 0.0065\n",
      "Epoch 126/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0056 - val_loss: 0.0058\n",
      "Epoch 127/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0060 - val_loss: 0.0063\n",
      "Epoch 128/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0058 - val_loss: 0.0066\n",
      "Epoch 129/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0058 - val_loss: 0.0061\n",
      "Epoch 130/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0060 - val_loss: 0.0060\n",
      "Epoch 131/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0059 - val_loss: 0.0070\n",
      "Epoch 132/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0061 - val_loss: 0.0058\n",
      "Epoch 133/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0058 - val_loss: 0.0066\n",
      "Epoch 134/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0057 - val_loss: 0.0059\n",
      "Epoch 135/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0058 - val_loss: 0.0063\n",
      "Epoch 136/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0057 - val_loss: 0.0060\n",
      "Epoch 137/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0057 - val_loss: 0.0061\n",
      "Epoch 138/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0056 - val_loss: 0.0059\n",
      "Epoch 139/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0056 - val_loss: 0.0061\n",
      "Epoch 140/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0057 - val_loss: 0.0060\n",
      "Epoch 141/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0058 - val_loss: 0.0062\n",
      "Epoch 142/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0059 - val_loss: 0.0061\n",
      "Epoch 143/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0059 - val_loss: 0.0060\n",
      "Epoch 144/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0056 - val_loss: 0.0062\n",
      "Epoch 145/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0056 - val_loss: 0.0058\n",
      "Epoch 146/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 98us/step - loss: 0.0057 - val_loss: 0.0061\n",
      "Epoch 147/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0056 - val_loss: 0.0058\n",
      "Epoch 148/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0057 - val_loss: 0.0061\n",
      "Epoch 149/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0055 - val_loss: 0.0066\n",
      "Epoch 150/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0057 - val_loss: 0.0059\n",
      "Epoch 151/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0056 - val_loss: 0.0062\n",
      "Epoch 152/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0056 - val_loss: 0.0059\n",
      "Epoch 153/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0057 - val_loss: 0.0062\n",
      "Epoch 154/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0060 - val_loss: 0.0059\n",
      "Epoch 155/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0056 - val_loss: 0.0063\n",
      "Epoch 156/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0055 - val_loss: 0.0059\n",
      "Epoch 157/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0056 - val_loss: 0.0062\n",
      "Epoch 158/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0055 - val_loss: 0.0063\n",
      "Epoch 159/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0056 - val_loss: 0.0059\n",
      "Epoch 160/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0058 - val_loss: 0.0064\n",
      "Epoch 161/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0056 - val_loss: 0.0057\n",
      "Epoch 162/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0055 - val_loss: 0.0067\n",
      "Epoch 163/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0059 - val_loss: 0.0059\n",
      "Epoch 164/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0058 - val_loss: 0.0058\n",
      "Epoch 165/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0054 - val_loss: 0.0069\n",
      "Epoch 166/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0056 - val_loss: 0.0055\n",
      "Epoch 167/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0057 - val_loss: 0.0058\n",
      "Epoch 168/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0054 - val_loss: 0.0056\n",
      "Epoch 169/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0056 - val_loss: 0.0060\n",
      "Epoch 170/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0054 - val_loss: 0.0056\n",
      "Epoch 171/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0055 - val_loss: 0.0061\n",
      "Epoch 172/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0055 - val_loss: 0.0058\n",
      "Epoch 173/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0055 - val_loss: 0.0062\n",
      "Epoch 174/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0054 - val_loss: 0.0056\n",
      "Epoch 175/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0056 - val_loss: 0.0064\n",
      "Epoch 176/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0059 - val_loss: 0.0062\n",
      "Epoch 177/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0053 - val_loss: 0.0054\n",
      "Epoch 178/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0057 - val_loss: 0.0066\n",
      "Epoch 179/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0059 - val_loss: 0.0058\n",
      "Epoch 180/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0056 - val_loss: 0.0057\n",
      "Epoch 181/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0053 - val_loss: 0.0068\n",
      "Epoch 182/1000\n",
      "143/143 [==============================] - 0s 293us/step - loss: 0.0056 - val_loss: 0.0057\n",
      "Epoch 183/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0054 - val_loss: 0.0063\n",
      "Epoch 184/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0055 - val_loss: 0.0062\n",
      "Epoch 185/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0055 - val_loss: 0.0059\n",
      "Epoch 186/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0053 - val_loss: 0.0064\n",
      "Epoch 187/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0053 - val_loss: 0.0055\n",
      "Epoch 188/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0055 - val_loss: 0.0060\n",
      "Epoch 189/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0055 - val_loss: 0.0060\n",
      "Epoch 190/1000\n",
      "143/143 [==============================] - 0s 223us/step - loss: 0.0053 - val_loss: 0.0057\n",
      "Epoch 191/1000\n",
      "143/143 [==============================] - 0s 188us/step - loss: 0.0053 - val_loss: 0.0068\n",
      "Epoch 192/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0055 - val_loss: 0.0060\n",
      "Epoch 193/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0053 - val_loss: 0.0059\n",
      "Epoch 194/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0053 - val_loss: 0.0059\n",
      "Epoch 195/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0059\n",
      "Epoch 196/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0058\n",
      "Epoch 197/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0055 - val_loss: 0.0056\n",
      "Epoch 198/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0056 - val_loss: 0.0057\n",
      "Epoch 199/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0052 - val_loss: 0.0068\n",
      "Epoch 200/1000\n",
      "143/143 [==============================] - 0s 188us/step - loss: 0.0056 - val_loss: 0.0057\n",
      "Epoch 201/1000\n",
      "143/143 [==============================] - 0s 171us/step - loss: 0.0053 - val_loss: 0.0064\n",
      "Epoch 202/1000\n",
      "143/143 [==============================] - 0s 181us/step - loss: 0.0053 - val_loss: 0.0060\n",
      "Epoch 203/1000\n",
      "143/143 [==============================] - 0s 181us/step - loss: 0.0053 - val_loss: 0.0060\n",
      "Epoch 204/1000\n",
      "143/143 [==============================] - 0s 174us/step - loss: 0.0052 - val_loss: 0.0064\n",
      "Epoch 205/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0053 - val_loss: 0.0059\n",
      "Epoch 206/1000\n",
      "143/143 [==============================] - 0s 181us/step - loss: 0.0055 - val_loss: 0.0061\n",
      "Epoch 207/1000\n",
      "143/143 [==============================] - 0s 181us/step - loss: 0.0059 - val_loss: 0.0059\n",
      "Epoch 208/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0056 - val_loss: 0.0057\n",
      "Epoch 209/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0066 - val_loss: 0.0063\n",
      "Epoch 210/1000\n",
      "143/143 [==============================] - 0s 188us/step - loss: 0.0063 - val_loss: 0.0054\n",
      "Epoch 211/1000\n",
      "143/143 [==============================] - 0s 174us/step - loss: 0.0052 - val_loss: 0.0066\n",
      "Epoch 212/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0059 - val_loss: 0.0054\n",
      "Epoch 213/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0057 - val_loss: 0.0056\n",
      "Epoch 214/1000\n",
      "143/143 [==============================] - 0s 140us/step - loss: 0.0053 - val_loss: 0.0062\n",
      "Epoch 215/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0052 - val_loss: 0.0053\n",
      "Epoch 216/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0061 - val_loss: 0.0062\n",
      "Epoch 217/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0057 - val_loss: 0.0059\n",
      "Epoch 218/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0053 - val_loss: 0.0055\n",
      "Epoch 219/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0058 - val_loss: 0.0062\n",
      "Epoch 220/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0052 - val_loss: 0.0053\n",
      "Epoch 221/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0052 - val_loss: 0.0069\n",
      "Epoch 222/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0063 - val_loss: 0.0057\n",
      "Epoch 223/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 146us/step - loss: 0.0062 - val_loss: 0.0057\n",
      "Epoch 224/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0054 - val_loss: 0.0065\n",
      "Epoch 225/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0059 - val_loss: 0.0056\n",
      "Epoch 226/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0053 - val_loss: 0.0065\n",
      "Epoch 227/1000\n",
      "143/143 [==============================] - 0s 244us/step - loss: 0.0054 - val_loss: 0.0056\n",
      "Epoch 228/1000\n",
      "143/143 [==============================] - 0s 237us/step - loss: 0.0055 - val_loss: 0.0063\n",
      "Epoch 229/1000\n",
      "143/143 [==============================] - 0s 195us/step - loss: 0.0063 - val_loss: 0.0066\n",
      "Epoch 230/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0051 - val_loss: 0.0054\n",
      "Epoch 231/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0067\n",
      "Epoch 232/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0054 - val_loss: 0.0055\n",
      "Epoch 233/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0056 - val_loss: 0.0057\n",
      "Epoch 234/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0056 - val_loss: 0.0065\n",
      "Epoch 235/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0054 - val_loss: 0.0052\n",
      "Epoch 236/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0052 - val_loss: 0.0066\n",
      "Epoch 237/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0058 - val_loss: 0.0055\n",
      "Epoch 238/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0062 - val_loss: 0.0054\n",
      "Epoch 239/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0050 - val_loss: 0.0070\n",
      "Epoch 240/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0057 - val_loss: 0.0053\n",
      "Epoch 241/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0056 - val_loss: 0.0055\n",
      "Epoch 242/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0050 - val_loss: 0.0063\n",
      "Epoch 243/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0053 - val_loss: 0.0054\n",
      "Epoch 244/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0053 - val_loss: 0.0053\n",
      "Epoch 245/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0051 - val_loss: 0.0063\n",
      "Epoch 246/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0053 - val_loss: 0.0057\n",
      "Epoch 247/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0053 - val_loss: 0.0059\n",
      "Epoch 248/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0055 - val_loss: 0.0059\n",
      "Epoch 249/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0057 - val_loss: 0.0053\n",
      "Epoch 250/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0068\n",
      "Epoch 251/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0054 - val_loss: 0.0052\n",
      "Epoch 252/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0059\n",
      "Epoch 253/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0056\n",
      "Epoch 254/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0056\n",
      "Epoch 255/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0060\n",
      "Epoch 256/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0051 - val_loss: 0.0054\n",
      "Epoch 257/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0053 - val_loss: 0.0062\n",
      "Epoch 258/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0053\n",
      "Epoch 259/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0053 - val_loss: 0.0060\n",
      "Epoch 260/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0053 - val_loss: 0.0057\n",
      "Epoch 261/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0051 - val_loss: 0.0055\n",
      "Epoch 262/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0061\n",
      "Epoch 263/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0053 - val_loss: 0.0057\n",
      "Epoch 264/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0054 - val_loss: 0.0054\n",
      "Epoch 265/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0055 - val_loss: 0.0064\n",
      "Epoch 266/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0053 - val_loss: 0.0051\n",
      "Epoch 267/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0054 - val_loss: 0.0061\n",
      "Epoch 268/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0052 - val_loss: 0.0052\n",
      "Epoch 269/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0053 - val_loss: 0.0061\n",
      "Epoch 270/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0050 - val_loss: 0.0053\n",
      "Epoch 271/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0060\n",
      "Epoch 272/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0053 - val_loss: 0.0053\n",
      "Epoch 273/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0050 - val_loss: 0.0059\n",
      "Epoch 274/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0054\n",
      "Epoch 275/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0053\n",
      "Epoch 276/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0059\n",
      "Epoch 277/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0051 - val_loss: 0.0060\n",
      "Epoch 278/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0054 - val_loss: 0.0058\n",
      "Epoch 279/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0056\n",
      "Epoch 280/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0064\n",
      "Epoch 281/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0055\n",
      "Epoch 282/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0054\n",
      "Epoch 283/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0051 - val_loss: 0.0061\n",
      "Epoch 284/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0052 - val_loss: 0.0053\n",
      "Epoch 285/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0055 - val_loss: 0.0058\n",
      "Epoch 286/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0057\n",
      "Epoch 287/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0058 - val_loss: 0.0052\n",
      "Epoch 288/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0058 - val_loss: 0.0063\n",
      "Epoch 289/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0051\n",
      "Epoch 290/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0049 - val_loss: 0.0064\n",
      "Epoch 291/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0052 - val_loss: 0.0055\n",
      "Epoch 292/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0057\n",
      "Epoch 293/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0058\n",
      "Epoch 294/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0050 - val_loss: 0.0058\n",
      "Epoch 295/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0056\n",
      "Epoch 296/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0058\n",
      "Epoch 297/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0049 - val_loss: 0.0054\n",
      "Epoch 298/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.006 - 0s 119us/step - loss: 0.0050 - val_loss: 0.0055\n",
      "Epoch 299/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0057\n",
      "Epoch 300/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0058\n",
      "Epoch 301/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0055\n",
      "Epoch 302/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0050 - val_loss: 0.0054\n",
      "Epoch 303/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0049 - val_loss: 0.0059\n",
      "Epoch 304/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0053\n",
      "Epoch 305/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0051 - val_loss: 0.0055\n",
      "Epoch 306/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0053\n",
      "Epoch 307/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0051 - val_loss: 0.0053\n",
      "Epoch 308/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0049 - val_loss: 0.0052\n",
      "Epoch 309/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0052 - val_loss: 0.0058\n",
      "Epoch 310/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0062 - val_loss: 0.0057\n",
      "Epoch 311/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 312/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0059 - val_loss: 0.0061\n",
      "Epoch 313/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0048 - val_loss: 0.0052\n",
      "Epoch 314/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0055 - val_loss: 0.0066\n",
      "Epoch 315/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0052\n",
      "Epoch 316/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0050 - val_loss: 0.0057\n",
      "Epoch 317/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0053\n",
      "Epoch 318/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0055 - val_loss: 0.0052\n",
      "Epoch 319/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0051 - val_loss: 0.0056\n",
      "Epoch 320/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 321/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0048 - val_loss: 0.0064\n",
      "Epoch 322/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0053 - val_loss: 0.0053\n",
      "Epoch 323/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0052 - val_loss: 0.0055\n",
      "Epoch 324/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0054 - val_loss: 0.0061\n",
      "Epoch 325/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0054\n",
      "Epoch 326/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0061\n",
      "Epoch 327/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0055\n",
      "Epoch 328/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0049 - val_loss: 0.0055\n",
      "Epoch 329/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0056\n",
      "Epoch 330/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0049 - val_loss: 0.0053\n",
      "Epoch 331/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0056 - val_loss: 0.0055\n",
      "Epoch 332/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0055 - val_loss: 0.0059\n",
      "Epoch 333/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0050\n",
      "Epoch 334/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0057 - val_loss: 0.0061\n",
      "Epoch 335/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0051\n",
      "Epoch 336/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0061\n",
      "Epoch 337/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0057 - val_loss: 0.0052\n",
      "Epoch 338/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 339/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0062\n",
      "Epoch 340/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0052 - val_loss: 0.0052\n",
      "Epoch 341/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0054\n",
      "Epoch 342/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0054\n",
      "Epoch 343/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0050 - val_loss: 0.0056\n",
      "Epoch 344/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0056\n",
      "Epoch 345/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0049 - val_loss: 0.0054\n",
      "Epoch 346/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0049 - val_loss: 0.0056\n",
      "Epoch 347/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0059\n",
      "Epoch 348/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0049 - val_loss: 0.0052\n",
      "Epoch 349/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0049 - val_loss: 0.0056\n",
      "Epoch 350/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0049 - val_loss: 0.0055\n",
      "Epoch 351/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0048 - val_loss: 0.0056\n",
      "Epoch 352/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0048 - val_loss: 0.0054\n",
      "Epoch 353/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0056\n",
      "Epoch 354/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0050 - val_loss: 0.0058\n",
      "Epoch 355/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 356/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0058\n",
      "Epoch 357/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0051\n",
      "Epoch 358/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0053\n",
      "Epoch 359/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0049 - val_loss: 0.0056\n",
      "Epoch 360/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0048 - val_loss: 0.0056\n",
      "Epoch 361/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0050 - val_loss: 0.0055\n",
      "Epoch 362/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0063\n",
      "Epoch 363/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0052\n",
      "Epoch 364/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0056 - val_loss: 0.0056\n",
      "Epoch 365/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0053 - val_loss: 0.0067\n",
      "Epoch 366/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0055 - val_loss: 0.0052\n",
      "Epoch 367/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0052 - val_loss: 0.0059\n",
      "Epoch 368/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0052\n",
      "Epoch 369/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0056\n",
      "Epoch 370/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0048 - val_loss: 0.0058\n",
      "Epoch 371/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0051 - val_loss: 0.0055\n",
      "Epoch 372/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0053\n",
      "Epoch 373/1000\n",
      "143/143 [==============================] - 0s 149us/step - loss: 0.0048 - val_loss: 0.0056\n",
      "Epoch 374/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0048 - val_loss: 0.0053\n",
      "Epoch 375/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0048 - val_loss: 0.0059\n",
      "Epoch 376/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0049 - val_loss: 0.0054\n",
      "Epoch 377/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 118us/step - loss: 0.0050 - val_loss: 0.0055\n",
      "Epoch 378/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0049 - val_loss: 0.0053\n",
      "Epoch 379/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0053\n",
      "Epoch 380/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0059\n",
      "Epoch 381/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 382/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0063\n",
      "Epoch 383/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0052 - val_loss: 0.0052\n",
      "Epoch 384/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0051 - val_loss: 0.0053\n",
      "Epoch 385/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0056\n",
      "Epoch 386/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0048 - val_loss: 0.0052\n",
      "Epoch 387/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0060\n",
      "Epoch 388/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0047 - val_loss: 0.0052\n",
      "Epoch 389/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0050 - val_loss: 0.0054\n",
      "Epoch 390/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0053\n",
      "Epoch 391/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0055\n",
      "Epoch 392/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0048 - val_loss: 0.0053\n",
      "Epoch 393/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0048 - val_loss: 0.0056\n",
      "Epoch 394/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0052\n",
      "Epoch 395/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0051 - val_loss: 0.0056\n",
      "Epoch 396/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 397/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0054 - val_loss: 0.0058\n",
      "Epoch 398/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0050\n",
      "Epoch 399/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0059\n",
      "Epoch 400/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0052\n",
      "Epoch 401/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0048 - val_loss: 0.0054\n",
      "Epoch 402/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0055\n",
      "Epoch 403/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0048 - val_loss: 0.0055\n",
      "Epoch 404/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0048 - val_loss: 0.0055\n",
      "Epoch 405/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0048 - val_loss: 0.0055\n",
      "Epoch 406/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0048 - val_loss: 0.0052\n",
      "Epoch 407/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0048 - val_loss: 0.0055\n",
      "Epoch 408/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0047 - val_loss: 0.0054\n",
      "Epoch 409/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0048 - val_loss: 0.0057\n",
      "Epoch 410/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0047 - val_loss: 0.0052\n",
      "Epoch 411/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0048 - val_loss: 0.0056\n",
      "Epoch 412/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0048 - val_loss: 0.0053\n",
      "Epoch 413/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0047 - val_loss: 0.0057\n",
      "Epoch 414/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0049 - val_loss: 0.0053\n",
      "Epoch 415/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0048 - val_loss: 0.0056\n",
      "Epoch 416/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 417/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0049 - val_loss: 0.0053\n",
      "Epoch 418/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0047 - val_loss: 0.0054\n",
      "Epoch 419/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0047 - val_loss: 0.0052\n",
      "Epoch 420/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0049 - val_loss: 0.0054\n",
      "Epoch 421/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0048 - val_loss: 0.0051\n",
      "Epoch 422/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0050 - val_loss: 0.0055\n",
      "Epoch 423/1000\n",
      "143/143 [==============================] - 0s 174us/step - loss: 0.0048 - val_loss: 0.0051\n",
      "Epoch 424/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0047 - val_loss: 0.0056\n",
      "Epoch 425/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0047 - val_loss: 0.0052\n",
      "Epoch 426/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0046 - val_loss: 0.0059\n",
      "Epoch 427/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0049 - val_loss: 0.0054\n",
      "Epoch 428/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0048 - val_loss: 0.0051\n",
      "Epoch 429/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0046 - val_loss: 0.0062\n",
      "Epoch 430/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0048 - val_loss: 0.0051\n",
      "Epoch 431/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0047 - val_loss: 0.0053\n",
      "Epoch 432/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0049 - val_loss: 0.0053\n",
      "Epoch 433/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0047 - val_loss: 0.0051\n",
      "Epoch 434/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0048 - val_loss: 0.0051\n",
      "Epoch 435/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0050 - val_loss: 0.0053\n",
      "Epoch 436/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0049 - val_loss: 0.0061\n",
      "Epoch 437/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0052 - val_loss: 0.0051\n",
      "Epoch 438/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0049 - val_loss: 0.0062\n",
      "Epoch 439/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0053 - val_loss: 0.0051\n",
      "Epoch 440/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0052 - val_loss: 0.0058\n",
      "Epoch 441/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 442/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0052 - val_loss: 0.0058\n",
      "Epoch 443/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0053 - val_loss: 0.0049\n",
      "Epoch 444/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0046 - val_loss: 0.0059\n",
      "Epoch 445/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0047 - val_loss: 0.0051\n",
      "Epoch 446/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0057\n",
      "Epoch 447/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0048 - val_loss: 0.0055\n",
      "Epoch 448/1000\n",
      "143/143 [==============================] - 0s 167us/step - loss: 0.0049 - val_loss: 0.0053\n",
      "Epoch 449/1000\n",
      "143/143 [==============================] - 0s 167us/step - loss: 0.0051 - val_loss: 0.0052\n",
      "Epoch 450/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0050 - val_loss: 0.0058\n",
      "Epoch 451/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 452/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0052 - val_loss: 0.0065\n",
      "Epoch 453/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 454/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0051 - val_loss: 0.0063\n",
      "Epoch 455/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0047 - val_loss: 0.0051\n",
      "Epoch 456/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0048 - val_loss: 0.0061\n",
      "Epoch 457/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0049 - val_loss: 0.0055\n",
      "Epoch 458/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0051\n",
      "Epoch 459/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0056\n",
      "Epoch 460/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0052\n",
      "Epoch 461/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0054\n",
      "Epoch 462/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0051\n",
      "Epoch 463/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0056\n",
      "Epoch 464/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0060\n",
      "Epoch 465/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0050\n",
      "Epoch 466/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0051 - val_loss: 0.0058\n",
      "Epoch 467/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0053\n",
      "Epoch 468/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0053\n",
      "Epoch 469/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0057\n",
      "Epoch 470/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0051\n",
      "Epoch 471/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0056\n",
      "Epoch 472/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0050 - val_loss: 0.0054\n",
      "Epoch 473/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0052\n",
      "Epoch 474/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0051 - val_loss: 0.0061\n",
      "Epoch 475/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0051\n",
      "Epoch 476/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0065\n",
      "Epoch 477/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 478/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0060\n",
      "Epoch 479/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0055 - val_loss: 0.0052\n",
      "Epoch 480/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0054 - val_loss: 0.0052\n",
      "Epoch 481/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0048 - val_loss: 0.0056\n",
      "Epoch 482/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 483/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0054\n",
      "Epoch 484/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0050\n",
      "Epoch 485/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0052\n",
      "Epoch 486/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0050\n",
      "Epoch 487/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0055\n",
      "Epoch 488/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0054\n",
      "Epoch 489/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0057\n",
      "Epoch 490/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0057\n",
      "Epoch 491/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0051\n",
      "Epoch 492/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0055\n",
      "Epoch 493/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0046 - val_loss: 0.0052\n",
      "Epoch 494/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0057\n",
      "Epoch 495/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0055\n",
      "Epoch 496/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0057 - val_loss: 0.0058\n",
      "Epoch 497/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0048\n",
      "Epoch 498/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0067\n",
      "Epoch 499/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 500/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0060\n",
      "Epoch 501/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0058 - val_loss: 0.0056\n",
      "Epoch 502/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0049\n",
      "Epoch 503/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0059\n",
      "Epoch 504/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 505/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0065\n",
      "Epoch 506/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0052 - val_loss: 0.0052\n",
      "Epoch 507/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0049 - val_loss: 0.0059\n",
      "Epoch 508/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0047 - val_loss: 0.0050\n",
      "Epoch 509/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0061\n",
      "Epoch 510/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0047 - val_loss: 0.0051\n",
      "Epoch 511/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0048 - val_loss: 0.0055\n",
      "Epoch 512/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0057\n",
      "Epoch 513/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 514/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0047 - val_loss: 0.0055\n",
      "Epoch 515/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0052\n",
      "Epoch 516/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0051\n",
      "Epoch 517/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0057\n",
      "Epoch 518/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0051\n",
      "Epoch 519/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0058\n",
      "Epoch 520/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0056\n",
      "Epoch 521/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0052\n",
      "Epoch 522/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0055\n",
      "Epoch 523/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0047 - val_loss: 0.0055\n",
      "Epoch 524/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0052\n",
      "Epoch 525/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0054\n",
      "Epoch 526/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0054\n",
      "Epoch 527/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0045 - val_loss: 0.0053\n",
      "Epoch 528/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0056\n",
      "Epoch 529/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0046 - val_loss: 0.0053\n",
      "Epoch 530/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0053\n",
      "Epoch 531/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0053\n",
      "Epoch 532/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0056\n",
      "Epoch 533/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0058 - val_loss: 0.0052\n",
      "Epoch 534/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0051\n",
      "Epoch 535/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0049 - val_loss: 0.0058\n",
      "Epoch 536/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0044 - val_loss: 0.0049\n",
      "Epoch 537/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0059\n",
      "Epoch 538/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 539/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0053\n",
      "Epoch 540/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0050\n",
      "Epoch 541/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0051\n",
      "Epoch 542/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0053\n",
      "Epoch 543/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0051\n",
      "Epoch 544/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0045 - val_loss: 0.0055\n",
      "Epoch 545/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0046 - val_loss: 0.0055\n",
      "Epoch 546/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0054\n",
      "Epoch 547/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0056\n",
      "Epoch 548/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0053\n",
      "Epoch 549/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0058\n",
      "Epoch 550/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0052\n",
      "Epoch 551/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0049 - val_loss: 0.0054\n",
      "Epoch 552/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0057\n",
      "Epoch 553/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 554/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0048 - val_loss: 0.0052\n",
      "Epoch 555/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0055\n",
      "Epoch 556/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0051\n",
      "Epoch 557/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0046 - val_loss: 0.0054\n",
      "Epoch 558/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 559/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0055\n",
      "Epoch 560/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0050\n",
      "Epoch 561/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0054\n",
      "Epoch 562/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0052\n",
      "Epoch 563/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0053\n",
      "Epoch 564/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0067\n",
      "Epoch 565/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0052\n",
      "Epoch 566/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0056 - val_loss: 0.0056\n",
      "Epoch 567/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0066\n",
      "Epoch 568/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 569/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0062\n",
      "Epoch 570/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0052\n",
      "Epoch 571/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0053\n",
      "Epoch 572/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0047 - val_loss: 0.0053\n",
      "Epoch 573/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0048 - val_loss: 0.0053\n",
      "Epoch 574/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0053\n",
      "Epoch 575/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0062\n",
      "Epoch 576/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0044 - val_loss: 0.0050\n",
      "Epoch 577/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0048 - val_loss: 0.0059\n",
      "Epoch 578/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0052\n",
      "Epoch 579/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 580/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0058\n",
      "Epoch 581/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0050\n",
      "Epoch 582/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0050 - val_loss: 0.0058\n",
      "Epoch 583/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0050\n",
      "Epoch 584/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0055\n",
      "Epoch 585/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0048 - val_loss: 0.0051\n",
      "Epoch 586/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0057\n",
      "Epoch 587/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 588/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0045 - val_loss: 0.0054\n",
      "Epoch 589/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0046 - val_loss: 0.0055\n",
      "Epoch 590/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0050\n",
      "Epoch 591/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0054\n",
      "Epoch 592/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0051\n",
      "Epoch 593/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0054\n",
      "Epoch 594/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0050\n",
      "Epoch 595/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0044 - val_loss: 0.0056\n",
      "Epoch 596/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0052\n",
      "Epoch 597/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0051\n",
      "Epoch 598/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0045 - val_loss: 0.0052\n",
      "Epoch 599/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0050 - val_loss: 0.0057\n",
      "Epoch 600/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0052\n",
      "Epoch 601/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0051\n",
      "Epoch 602/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0049 - val_loss: 0.0054\n",
      "Epoch 603/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0046 - val_loss: 0.0050\n",
      "Epoch 604/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0053\n",
      "Epoch 605/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0046 - val_loss: 0.0055\n",
      "Epoch 606/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0056\n",
      "Epoch 607/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0045 - val_loss: 0.0053\n",
      "Epoch 608/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0058\n",
      "Epoch 609/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0052\n",
      "Epoch 610/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0046 - val_loss: 0.0052\n",
      "Epoch 611/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0057\n",
      "Epoch 612/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0048 - val_loss: 0.0052\n",
      "Epoch 613/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0045 - val_loss: 0.0065\n",
      "Epoch 614/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0047 - val_loss: 0.0050\n",
      "Epoch 615/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0054\n",
      "Epoch 616/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0056\n",
      "Epoch 617/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0046 - val_loss: 0.0050\n",
      "Epoch 618/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0056\n",
      "Epoch 619/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0052\n",
      "Epoch 620/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0052\n",
      "Epoch 621/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0050\n",
      "Epoch 622/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0050\n",
      "Epoch 623/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0054\n",
      "Epoch 624/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0046 - val_loss: 0.0051\n",
      "Epoch 625/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0052\n",
      "Epoch 626/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0058\n",
      "Epoch 627/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0048 - val_loss: 0.0050\n",
      "Epoch 628/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0048 - val_loss: 0.0054\n",
      "Epoch 629/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 630/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0055\n",
      "Epoch 631/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0049\n",
      "Epoch 632/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0048 - val_loss: 0.0054\n",
      "Epoch 633/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0045 - val_loss: 0.0054\n",
      "Epoch 634/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0052\n",
      "Epoch 635/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0054\n",
      "Epoch 636/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0059\n",
      "Epoch 637/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0054\n",
      "Epoch 638/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0052\n",
      "Epoch 639/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0056\n",
      "Epoch 640/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0054\n",
      "Epoch 641/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0052\n",
      "Epoch 642/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0052\n",
      "Epoch 643/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0058\n",
      "Epoch 644/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0047 - val_loss: 0.0054\n",
      "Epoch 645/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0044 - val_loss: 0.0054\n",
      "Epoch 646/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0044 - val_loss: 0.0057\n",
      "Epoch 647/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0053\n",
      "Epoch 648/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0045 - val_loss: 0.0055\n",
      "Epoch 649/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0057\n",
      "Epoch 650/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0048 - val_loss: 0.0053\n",
      "Epoch 651/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0059\n",
      "Epoch 652/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0051\n",
      "Epoch 653/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0051\n",
      "Epoch 654/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0054\n",
      "Epoch 655/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0044 - val_loss: 0.0054\n",
      "Epoch 656/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0044 - val_loss: 0.0050\n",
      "Epoch 657/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0045 - val_loss: 0.0055\n",
      "Epoch 658/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0050\n",
      "Epoch 659/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0048 - val_loss: 0.0058\n",
      "Epoch 660/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0049 - val_loss: 0.0048\n",
      "Epoch 661/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0060 - val_loss: 0.0056\n",
      "Epoch 662/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0056 - val_loss: 0.0056\n",
      "Epoch 663/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0051 - val_loss: 0.0047\n",
      "Epoch 664/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0048 - val_loss: 0.0059\n",
      "Epoch 665/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0047\n",
      "Epoch 666/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0055\n",
      "Epoch 667/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.004 - 0s 119us/step - loss: 0.0046 - val_loss: 0.0051\n",
      "Epoch 668/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0056 - val_loss: 0.0054\n",
      "Epoch 669/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 670/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0048 - val_loss: 0.0061\n",
      "Epoch 671/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 672/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0048 - val_loss: 0.0057\n",
      "Epoch 673/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 674/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0052\n",
      "Epoch 675/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0051\n",
      "Epoch 676/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0053\n",
      "Epoch 677/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 678/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0050 - val_loss: 0.0053\n",
      "Epoch 679/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0057\n",
      "Epoch 680/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0049\n",
      "Epoch 681/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0057\n",
      "Epoch 682/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0053\n",
      "Epoch 683/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0057\n",
      "Epoch 684/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0046 - val_loss: 0.0052\n",
      "Epoch 685/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 686/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.006 - 0s 119us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 687/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0053 - val_loss: 0.0047\n",
      "Epoch 688/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0055\n",
      "Epoch 689/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 690/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0057\n",
      "Epoch 691/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0044 - val_loss: 0.0050\n",
      "Epoch 692/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0054\n",
      "Epoch 693/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0051\n",
      "Epoch 694/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0055\n",
      "Epoch 695/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0051\n",
      "Epoch 696/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0047 - val_loss: 0.0052\n",
      "Epoch 697/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0050 - val_loss: 0.0053\n",
      "Epoch 698/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0045 - val_loss: 0.0049\n",
      "Epoch 699/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0042 - val_loss: 0.0060\n",
      "Epoch 700/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0049 - val_loss: 0.0048\n",
      "Epoch 701/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0046 - val_loss: 0.0052\n",
      "Epoch 702/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0053\n",
      "Epoch 703/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.004 - 0s 112us/step - loss: 0.0043 - val_loss: 0.0049\n",
      "Epoch 704/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0055\n",
      "Epoch 705/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 706/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0057\n",
      "Epoch 707/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0044 - val_loss: 0.0050\n",
      "Epoch 708/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0043 - val_loss: 0.0056\n",
      "Epoch 709/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0047 - val_loss: 0.0050\n",
      "Epoch 710/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0048 - val_loss: 0.0052\n",
      "Epoch 711/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0056 - val_loss: 0.0055\n",
      "Epoch 712/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0058 - val_loss: 0.0053\n",
      "Epoch 713/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0057 - val_loss: 0.0062\n",
      "Epoch 714/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0048\n",
      "Epoch 715/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0063\n",
      "Epoch 716/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0048 - val_loss: 0.0048\n",
      "Epoch 717/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0056\n",
      "Epoch 718/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0052\n",
      "Epoch 719/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0043 - val_loss: 0.0051\n",
      "Epoch 720/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0055\n",
      "Epoch 721/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0053\n",
      "Epoch 722/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0051\n",
      "Epoch 723/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0052\n",
      "Epoch 724/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0057\n",
      "Epoch 725/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 726/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0059\n",
      "Epoch 727/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 728/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0049 - val_loss: 0.0056\n",
      "Epoch 729/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 730/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0055\n",
      "Epoch 731/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0052\n",
      "Epoch 732/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0050\n",
      "Epoch 733/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0052\n",
      "Epoch 734/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0051\n",
      "Epoch 735/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0052\n",
      "Epoch 736/1000\n",
      "143/143 [==============================] - 0s 167us/step - loss: 0.0044 - val_loss: 0.0053\n",
      "Epoch 737/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0044 - val_loss: 0.0056\n",
      "Epoch 738/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0050\n",
      "Epoch 739/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0058\n",
      "Epoch 740/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0050\n",
      "Epoch 741/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0054\n",
      "Epoch 742/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0050\n",
      "Epoch 743/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0055\n",
      "Epoch 744/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0051\n",
      "Epoch 745/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0052\n",
      "Epoch 746/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0046 - val_loss: 0.0051\n",
      "Epoch 747/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0052\n",
      "Epoch 748/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0054\n",
      "Epoch 749/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0052\n",
      "Epoch 750/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0060\n",
      "Epoch 751/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0054\n",
      "Epoch 752/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0052\n",
      "Epoch 753/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0053\n",
      "Epoch 754/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 755/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0058\n",
      "Epoch 756/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0050\n",
      "Epoch 757/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0051\n",
      "Epoch 758/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0052\n",
      "Epoch 759/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0058\n",
      "Epoch 760/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0054\n",
      "Epoch 761/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0060\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 762/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0048 - val_loss: 0.0052\n",
      "Epoch 763/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0048 - val_loss: 0.0060\n",
      "Epoch 764/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0047 - val_loss: 0.0053\n",
      "Epoch 765/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0051\n",
      "Epoch 766/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0055\n",
      "Epoch 767/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0048 - val_loss: 0.0053\n",
      "Epoch 768/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0061\n",
      "Epoch 769/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0051\n",
      "Epoch 770/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0052\n",
      "Epoch 771/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0052\n",
      "Epoch 772/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0049\n",
      "Epoch 773/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0048 - val_loss: 0.0052\n",
      "Epoch 774/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0059\n",
      "Epoch 775/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0050\n",
      "Epoch 776/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0055\n",
      "Epoch 777/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0049\n",
      "Epoch 778/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0058\n",
      "Epoch 779/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0044 - val_loss: 0.0050\n",
      "Epoch 780/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0049 - val_loss: 0.0057\n",
      "Epoch 781/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0049\n",
      "Epoch 782/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0050 - val_loss: 0.0055\n",
      "Epoch 783/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0049\n",
      "Epoch 784/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0056\n",
      "Epoch 785/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0043 - val_loss: 0.0052\n",
      "Epoch 786/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0044 - val_loss: 0.0053\n",
      "Epoch 787/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0050\n",
      "Epoch 788/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0054\n",
      "Epoch 789/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0054\n",
      "Epoch 790/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0052\n",
      "Epoch 791/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0057\n",
      "Epoch 792/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0052\n",
      "Epoch 793/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0051\n",
      "Epoch 794/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0055\n",
      "Epoch 795/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0044 - val_loss: 0.0052\n",
      "Epoch 796/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0053\n",
      "Epoch 797/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0042 - val_loss: 0.0057\n",
      "Epoch 798/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0046 - val_loss: 0.0054\n",
      "Epoch 799/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0054\n",
      "Epoch 800/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0044 - val_loss: 0.0051\n",
      "Epoch 801/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0057\n",
      "Epoch 802/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0044 - val_loss: 0.0053\n",
      "Epoch 803/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0054\n",
      "Epoch 804/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0049 - val_loss: 0.0053\n",
      "Epoch 805/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0048 - val_loss: 0.0058\n",
      "Epoch 806/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0052\n",
      "Epoch 807/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0046 - val_loss: 0.0059\n",
      "Epoch 808/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0052\n",
      "Epoch 809/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0061\n",
      "Epoch 810/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0050\n",
      "Epoch 811/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0054\n",
      "Epoch 812/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0050\n",
      "Epoch 813/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0044 - val_loss: 0.0055\n",
      "Epoch 814/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0051\n",
      "Epoch 815/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0052\n",
      "Epoch 816/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0055\n",
      "Epoch 817/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0052\n",
      "Epoch 818/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0043 - val_loss: 0.0052\n",
      "Epoch 819/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0051\n",
      "Epoch 820/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0043 - val_loss: 0.0050\n",
      "Epoch 821/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0055\n",
      "Epoch 822/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0050\n",
      "Epoch 823/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0044 - val_loss: 0.0054\n",
      "Epoch 824/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0053\n",
      "Epoch 825/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0051\n",
      "Epoch 826/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0044 - val_loss: 0.0052\n",
      "Epoch 827/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0053\n",
      "Epoch 828/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0050 - val_loss: 0.0051\n",
      "Epoch 829/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 830/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0044 - val_loss: 0.0055\n",
      "Epoch 831/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0043 - val_loss: 0.0049\n",
      "Epoch 832/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0053\n",
      "Epoch 833/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0050\n",
      "Epoch 834/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0053\n",
      "Epoch 835/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0053\n",
      "Epoch 836/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0043 - val_loss: 0.0052\n",
      "Epoch 837/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0051\n",
      "Epoch 838/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0042 - val_loss: 0.0056\n",
      "Epoch 839/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 126us/step - loss: 0.0043 - val_loss: 0.0049\n",
      "Epoch 840/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0053\n",
      "Epoch 841/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0052 - val_loss: 0.0051\n",
      "Epoch 842/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0058 - val_loss: 0.0053\n",
      "Epoch 843/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0059\n",
      "Epoch 844/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0049\n",
      "Epoch 845/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0053\n",
      "Epoch 846/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 847/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0042 - val_loss: 0.0058\n",
      "Epoch 848/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 849/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0054\n",
      "Epoch 850/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 851/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0058\n",
      "Epoch 852/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0052\n",
      "Epoch 853/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0051\n",
      "Epoch 854/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0056\n",
      "Epoch 855/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0050\n",
      "Epoch 856/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0054\n",
      "Epoch 857/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0051\n",
      "Epoch 858/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0054\n",
      "Epoch 859/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0055\n",
      "Epoch 860/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0044 - val_loss: 0.0056\n",
      "Epoch 861/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0044 - val_loss: 0.0053\n",
      "Epoch 862/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0051\n",
      "Epoch 863/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0047 - val_loss: 0.0057\n",
      "Epoch 864/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0050\n",
      "Epoch 865/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0063\n",
      "Epoch 866/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0050\n",
      "Epoch 867/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0047 - val_loss: 0.0057\n",
      "Epoch 868/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0044 - val_loss: 0.0055\n",
      "Epoch 869/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0053\n",
      "Epoch 870/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0053\n",
      "Epoch 871/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0056\n",
      "Epoch 872/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0053\n",
      "Epoch 873/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0043 - val_loss: 0.0053\n",
      "Epoch 874/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0046 - val_loss: 0.0056\n",
      "Epoch 875/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0053\n",
      "Epoch 876/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0048 - val_loss: 0.0053\n",
      "Epoch 877/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0053 - val_loss: 0.0050\n",
      "Epoch 878/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0051\n",
      "Epoch 879/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0057\n",
      "Epoch 880/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0051\n",
      "Epoch 881/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0054\n",
      "Epoch 882/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0050\n",
      "Epoch 883/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0058\n",
      "Epoch 884/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 885/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0058\n",
      "Epoch 886/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0049\n",
      "Epoch 887/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0061\n",
      "Epoch 888/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 889/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0059\n",
      "Epoch 890/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0051\n",
      "Epoch 891/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0045 - val_loss: 0.0053\n",
      "Epoch 892/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0043 - val_loss: 0.0057\n",
      "Epoch 893/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0050\n",
      "Epoch 894/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0052\n",
      "Epoch 895/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0055\n",
      "Epoch 896/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0052\n",
      "Epoch 897/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0043 - val_loss: 0.0050\n",
      "Epoch 898/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0053\n",
      "Epoch 899/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0054\n",
      "Epoch 900/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0054\n",
      "Epoch 901/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0043 - val_loss: 0.0050\n",
      "Epoch 902/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0048 - val_loss: 0.0059\n",
      "Epoch 903/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0050 - val_loss: 0.0052\n",
      "Epoch 904/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0055\n",
      "Epoch 905/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0045 - val_loss: 0.0059\n",
      "Epoch 906/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0045 - val_loss: 0.0050\n",
      "Epoch 907/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0043 - val_loss: 0.0064\n",
      "Epoch 908/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0044 - val_loss: 0.0049\n",
      "Epoch 909/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0063\n",
      "Epoch 910/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0049\n",
      "Epoch 911/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 912/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0044 - val_loss: 0.0059\n",
      "Epoch 913/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0050\n",
      "Epoch 914/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0058\n",
      "Epoch 915/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0052\n",
      "Epoch 916/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 118us/step - loss: 0.0042 - val_loss: 0.0060\n",
      "Epoch 917/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0051\n",
      "Epoch 918/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0044 - val_loss: 0.0062\n",
      "Epoch 919/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0053\n",
      "Epoch 920/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0054\n",
      "Epoch 921/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0054\n",
      "Epoch 922/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0056\n",
      "Epoch 923/1000\n",
      "143/143 [==============================] - 0s 166us/step - loss: 0.0047 - val_loss: 0.0052\n",
      "Epoch 924/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0049 - val_loss: 0.0053\n",
      "Epoch 925/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0045 - val_loss: 0.0054\n",
      "Epoch 926/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0047 - val_loss: 0.0061\n",
      "Epoch 927/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0041 - val_loss: 0.0049\n",
      "Epoch 928/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0056\n",
      "Epoch 929/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0051\n",
      "Epoch 930/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0051\n",
      "Epoch 931/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0043 - val_loss: 0.0058\n",
      "Epoch 932/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0043 - val_loss: 0.0051\n",
      "Epoch 933/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0059\n",
      "Epoch 934/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0053\n",
      "Epoch 935/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0053 - val_loss: 0.0056\n",
      "Epoch 936/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0051 - val_loss: 0.0055\n",
      "Epoch 937/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0051\n",
      "Epoch 938/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0055\n",
      "Epoch 939/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0043 - val_loss: 0.0050\n",
      "Epoch 940/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0043 - val_loss: 0.0059\n",
      "Epoch 941/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0044 - val_loss: 0.0051\n",
      "Epoch 942/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0043 - val_loss: 0.0055\n",
      "Epoch 943/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0043 - val_loss: 0.0050\n",
      "Epoch 944/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0047 - val_loss: 0.0053\n",
      "Epoch 945/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0046 - val_loss: 0.0054\n",
      "Epoch 946/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0053\n",
      "Epoch 947/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0058\n",
      "Epoch 948/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0042 - val_loss: 0.0050\n",
      "Epoch 949/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0043 - val_loss: 0.0055\n",
      "Epoch 950/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0051\n",
      "Epoch 951/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0056\n",
      "Epoch 952/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0054\n",
      "Epoch 953/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0044 - val_loss: 0.0055\n",
      "Epoch 954/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0054\n",
      "Epoch 955/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0053\n",
      "Epoch 956/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0060\n",
      "Epoch 957/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0052\n",
      "Epoch 958/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0054\n",
      "Epoch 959/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0051\n",
      "Epoch 960/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0051\n",
      "Epoch 961/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0060\n",
      "Epoch 962/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0050\n",
      "Epoch 963/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0060\n",
      "Epoch 964/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0051\n",
      "Epoch 965/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0060\n",
      "Epoch 966/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0051\n",
      "Epoch 967/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0059\n",
      "Epoch 968/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0053\n",
      "Epoch 969/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0056\n",
      "Epoch 970/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0054\n",
      "Epoch 971/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0056\n",
      "Epoch 972/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0052\n",
      "Epoch 973/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0056\n",
      "Epoch 974/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0055 - val_loss: 0.0055\n",
      "Epoch 975/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0053 - val_loss: 0.0051\n",
      "Epoch 976/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0068\n",
      "Epoch 977/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0049\n",
      "Epoch 978/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0062\n",
      "Epoch 979/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0051\n",
      "Epoch 980/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0055\n",
      "Epoch 981/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0056\n",
      "Epoch 982/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0050\n",
      "Epoch 983/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0057\n",
      "Epoch 984/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0051\n",
      "Epoch 985/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0060\n",
      "Epoch 986/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0050\n",
      "Epoch 987/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0042 - val_loss: 0.0056\n",
      "Epoch 988/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0050\n",
      "Epoch 989/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0050\n",
      "Epoch 990/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0054\n",
      "Epoch 991/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0051\n",
      "Epoch 992/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0051\n",
      "Epoch 993/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0053\n",
      "Epoch 994/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0052\n",
      "Epoch 995/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0045 - val_loss: 0.0056\n",
      "Epoch 996/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0045 - val_loss: 0.0053\n",
      "Epoch 997/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0042 - val_loss: 0.0054\n",
      "Epoch 998/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0055\n",
      "Epoch 999/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0053\n",
      "Epoch 1000/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0054\n",
      "0.009161117486655712\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 0.27699775, -0.11898243, -0.1849051 , -0.35272053, -0.29750234],\n",
       "        [-0.09878635, -0.1995936 ,  0.11862897, -0.6791794 , -0.45516005],\n",
       "        [-0.21170785, -0.6452235 ,  0.3015029 , -0.13705756, -0.68083054],\n",
       "        [ 0.10301439, -0.28390822, -0.7136075 , -0.59993064, -0.32103184],\n",
       "        [-0.07862579, -0.32691836, -0.16447996, -0.10245146, -0.33501786],\n",
       "        [ 0.4859878 ,  0.16239613, -0.08858379, -0.7230032 ,  0.01499158],\n",
       "        [-0.16386111, -0.3686412 , -0.5145171 , -0.3729404 ,  0.04434313],\n",
       "        [ 0.13794753, -0.24486601, -0.6222135 , -0.1241038 , -0.28423244],\n",
       "        [-0.1279248 , -0.6881453 , -0.02266933,  0.1662033 , -0.22163618],\n",
       "        [ 0.4761381 ,  0.17807613,  0.3697165 , -0.35462818,  0.0276014 ],\n",
       "        [-0.6101771 , -0.53002983, -0.4555932 ,  0.1663567 ,  0.18200853],\n",
       "        [ 0.11236661, -0.6064761 , -0.5279909 , -0.135238  ,  0.0280204 ],\n",
       "        [-0.23301362, -0.66832936, -0.14710973, -0.37173527,  0.03468972],\n",
       "        [ 2.3423698 , -0.15120347, -0.5470916 , -0.44383174, -0.6518665 ],\n",
       "        [ 0.22668128,  0.04921258, -0.07596811, -0.03847939, -0.01695684],\n",
       "        [-0.0410056 , -0.58063704, -0.13517833, -0.37048355, -0.25528154],\n",
       "        [-0.08502058, -0.6036371 , -0.14082824, -0.0175462 ,  0.08081281],\n",
       "        [ 0.5362391 , -0.14031427, -0.05308327,  0.17752276, -0.06011627],\n",
       "        [-0.9924353 , -0.11514422, -0.2374731 , -0.26936367, -0.52022326],\n",
       "        [ 0.6081466 , -0.5589261 , -0.48457924, -0.29544196, -0.33985963],\n",
       "        [-2.652741  ,  0.06899648,  0.21451199, -0.755997  , -0.2806796 ],\n",
       "        [ 0.48860452, -0.3702909 ,  0.05629291, -0.56188333, -0.1130993 ]],\n",
       "       dtype=float32),\n",
       " array([-0.11495918, -0.2742079 , -0.12936933, -0.32839212, -0.18391606],\n",
       "       dtype=float32),\n",
       " array([[-0.45634693, -0.42889434, -0.0846743 , -0.48903063, -0.50272584,\n",
       "         -0.42770904,  0.74946237, -0.2756899 , -0.5618155 , -0.5624351 ],\n",
       "        [-0.22809482, -0.6294729 , -0.2769634 ,  0.24921584, -0.01277167,\n",
       "          0.46297878, -0.4143596 , -0.07079282,  0.0619837 ,  0.16746944],\n",
       "        [-0.30949277, -0.9011402 , -0.24221304, -0.10370369,  0.20308042,\n",
       "         -0.23403335,  0.21527094, -0.56445146, -0.33754104, -0.5008142 ],\n",
       "        [-0.30452335, -0.10588595,  0.66578746, -0.82910776,  0.52288544,\n",
       "         -0.07017154,  0.10624257,  0.07762359, -0.53500473, -0.44390652],\n",
       "        [ 0.43835372, -0.30207747,  0.06611268, -0.45583403, -0.90005666,\n",
       "          0.46380478, -0.2003019 , -0.13029097, -0.26115897, -0.34496215]],\n",
       "       dtype=float32),\n",
       " array([ 0.        , -0.3175866 , -0.17737354, -0.50945413, -0.15850684,\n",
       "         0.        , -0.00712461, -0.2868198 ,  0.        ,  0.        ],\n",
       "       dtype=float32),\n",
       " array([[-0.22657406],\n",
       "        [-0.17359579],\n",
       "        [-0.2593634 ],\n",
       "        [-0.38862133],\n",
       "        [-0.12304112],\n",
       "        [-0.16011828],\n",
       "        [ 0.7371372 ],\n",
       "        [-0.06775887],\n",
       "        [ 0.02763796],\n",
       "        [ 0.69778436]], dtype=float32),\n",
       " array([0.07285734], dtype=float32)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_automobile, history_automobile, evaluate_automobile=NN_model_structure_regression_relu(X_train_automobile, X_val_automobile, Y_train_automobile, Y_val_automobile, adam2, 32, 1000, x_test_automobile, y_test_automobile)\n",
    "model_automobile.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_automobile.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_automobile_relu_4th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_31 (Dense)             (None, 5)                 115       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 186\n",
      "Trainable params: 186\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 143 samples, validate on 31 samples\n",
      "Epoch 1/1000\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0550 - val_loss: 0.0261\n",
      "Epoch 2/1000\n",
      "143/143 [==============================] - 0s 128us/step - loss: 0.0362 - val_loss: 0.0153\n",
      "Epoch 3/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0187 - val_loss: 0.0085\n",
      "Epoch 4/1000\n",
      "143/143 [==============================] - 0s 129us/step - loss: 0.0140 - val_loss: 0.0064\n",
      "Epoch 5/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0116 - val_loss: 0.0102\n",
      "Epoch 6/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0125 - val_loss: 0.0092\n",
      "Epoch 7/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0131 - val_loss: 0.0053\n",
      "Epoch 8/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0101 - val_loss: 0.0030\n",
      "Epoch 9/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0092 - val_loss: 0.0035\n",
      "Epoch 10/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0086 - val_loss: 0.0045\n",
      "Epoch 11/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0089 - val_loss: 0.0051\n",
      "Epoch 12/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0083 - val_loss: 0.0035\n",
      "Epoch 13/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0081 - val_loss: 0.0035\n",
      "Epoch 14/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0092 - val_loss: 0.0058\n",
      "Epoch 15/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0077 - val_loss: 0.0048\n",
      "Epoch 16/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0082 - val_loss: 0.0051\n",
      "Epoch 17/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0075 - val_loss: 0.0037\n",
      "Epoch 18/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0079 - val_loss: 0.0039\n",
      "Epoch 19/1000\n",
      "143/143 [==============================] - 0s 844us/step - loss: 0.0080 - val_loss: 0.0055\n",
      "Epoch 20/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0082 - val_loss: 0.0042\n",
      "Epoch 21/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0080 - val_loss: 0.0044\n",
      "Epoch 22/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0073 - val_loss: 0.0043\n",
      "Epoch 23/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0073 - val_loss: 0.0063\n",
      "Epoch 24/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0079 - val_loss: 0.0047\n",
      "Epoch 25/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0074 - val_loss: 0.0082\n",
      "Epoch 26/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0087 - val_loss: 0.0042\n",
      "Epoch 27/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0077 - val_loss: 0.0045\n",
      "Epoch 28/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0075 - val_loss: 0.0058\n",
      "Epoch 29/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0075 - val_loss: 0.0040\n",
      "Epoch 30/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0069 - val_loss: 0.0047\n",
      "Epoch 31/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0076 - val_loss: 0.0051\n",
      "Epoch 32/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0076 - val_loss: 0.0066\n",
      "Epoch 33/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0077 - val_loss: 0.0042\n",
      "Epoch 34/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0068 - val_loss: 0.0046\n",
      "Epoch 35/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0066 - val_loss: 0.0048\n",
      "Epoch 36/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0065 - val_loss: 0.0045\n",
      "Epoch 37/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0065 - val_loss: 0.0044\n",
      "Epoch 38/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0063 - val_loss: 0.0047\n",
      "Epoch 39/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0064 - val_loss: 0.0048\n",
      "Epoch 40/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0062 - val_loss: 0.0046\n",
      "Epoch 41/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0063 - val_loss: 0.0057\n",
      "Epoch 42/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0066 - val_loss: 0.0047\n",
      "Epoch 43/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0068 - val_loss: 0.0049\n",
      "Epoch 44/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0065 - val_loss: 0.0044\n",
      "Epoch 45/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0062 - val_loss: 0.0043\n",
      "Epoch 46/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0064 - val_loss: 0.0049\n",
      "Epoch 47/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0062 - val_loss: 0.0040\n",
      "Epoch 48/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0060 - val_loss: 0.0061\n",
      "Epoch 49/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0067 - val_loss: 0.0046\n",
      "Epoch 50/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0061 - val_loss: 0.0050\n",
      "Epoch 51/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0058 - val_loss: 0.0038\n",
      "Epoch 52/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0066 - val_loss: 0.0049\n",
      "Epoch 53/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0060 - val_loss: 0.0049\n",
      "Epoch 54/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0060 - val_loss: 0.0058\n",
      "Epoch 55/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0062 - val_loss: 0.0047\n",
      "Epoch 56/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0059 - val_loss: 0.0048\n",
      "Epoch 57/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0057 - val_loss: 0.0041\n",
      "Epoch 58/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0059 - val_loss: 0.0060\n",
      "Epoch 59/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0061 - val_loss: 0.0042\n",
      "Epoch 60/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0061 - val_loss: 0.0050\n",
      "Epoch 61/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0065 - val_loss: 0.0058\n",
      "Epoch 62/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0075 - val_loss: 0.0058\n",
      "Epoch 63/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0072 - val_loss: 0.0089\n",
      "Epoch 64/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0075 - val_loss: 0.0044\n",
      "Epoch 65/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0073 - val_loss: 0.0047\n",
      "Epoch 66/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0068 - val_loss: 0.0065\n",
      "Epoch 67/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0070 - val_loss: 0.0051\n",
      "Epoch 68/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0079 - val_loss: 0.0076\n",
      "Epoch 69/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0057 - val_loss: 0.0055\n",
      "Epoch 70/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0072 - val_loss: 0.0086\n",
      "Epoch 71/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0069 - val_loss: 0.0054\n",
      "Epoch 72/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0073 - val_loss: 0.0055\n",
      "Epoch 73/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0069 - val_loss: 0.0045\n",
      "Epoch 74/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0079 - val_loss: 0.0052\n",
      "Epoch 75/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0083 - val_loss: 0.0082\n",
      "Epoch 76/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0079 - val_loss: 0.0044\n",
      "Epoch 77/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0061 - val_loss: 0.0049\n",
      "Epoch 78/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0057 - val_loss: 0.0037\n",
      "Epoch 79/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0056 - val_loss: 0.0045\n",
      "Epoch 80/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 81/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0056 - val_loss: 0.0053\n",
      "Epoch 82/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0057 - val_loss: 0.0040\n",
      "Epoch 83/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0059 - val_loss: 0.0074\n",
      "Epoch 84/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0064 - val_loss: 0.0047\n",
      "Epoch 85/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0062 - val_loss: 0.0050\n",
      "Epoch 86/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0060 - val_loss: 0.0041\n",
      "Epoch 87/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0053\n",
      "Epoch 88/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0054 - val_loss: 0.0044\n",
      "Epoch 89/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0052 - val_loss: 0.0056\n",
      "Epoch 90/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0058 - val_loss: 0.0045\n",
      "Epoch 91/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0057 - val_loss: 0.0077\n",
      "Epoch 92/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.007 - 0s 119us/step - loss: 0.0070 - val_loss: 0.0050\n",
      "Epoch 93/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0063 - val_loss: 0.0062\n",
      "Epoch 94/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0053 - val_loss: 0.0042\n",
      "Epoch 95/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0059 - val_loss: 0.0056\n",
      "Epoch 96/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0040\n",
      "Epoch 97/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 98/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0051 - val_loss: 0.0041\n",
      "Epoch 99/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0047\n",
      "Epoch 100/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0053 - val_loss: 0.0044\n",
      "Epoch 101/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0052 - val_loss: 0.0044\n",
      "Epoch 102/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0055 - val_loss: 0.0045\n",
      "Epoch 103/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0061 - val_loss: 0.0061\n",
      "Epoch 104/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0064 - val_loss: 0.0039\n",
      "Epoch 105/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0050\n",
      "Epoch 106/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0053 - val_loss: 0.0043\n",
      "Epoch 107/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0040\n",
      "Epoch 108/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0043\n",
      "Epoch 109/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0050 - val_loss: 0.0043\n",
      "Epoch 110/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0041\n",
      "Epoch 111/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0041\n",
      "Epoch 112/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0048 - val_loss: 0.0040\n",
      "Epoch 113/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0045\n",
      "Epoch 114/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0042\n",
      "Epoch 115/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0039\n",
      "Epoch 116/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0045\n",
      "Epoch 117/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0039\n",
      "Epoch 118/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0052 - val_loss: 0.0043\n",
      "Epoch 119/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0040\n",
      "Epoch 120/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0048\n",
      "Epoch 121/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0041\n",
      "Epoch 122/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 123/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0042\n",
      "Epoch 124/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0051 - val_loss: 0.0061\n",
      "Epoch 125/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0038\n",
      "Epoch 126/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0046 - val_loss: 0.0052\n",
      "Epoch 127/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.004 - 0s 126us/step - loss: 0.0051 - val_loss: 0.0040\n",
      "Epoch 128/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0054\n",
      "Epoch 129/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0049 - val_loss: 0.0041\n",
      "Epoch 130/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0041\n",
      "Epoch 131/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0037\n",
      "Epoch 132/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0054 - val_loss: 0.0037\n",
      "Epoch 133/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0048 - val_loss: 0.0041\n",
      "Epoch 134/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0049 - val_loss: 0.0042\n",
      "Epoch 135/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0035\n",
      "Epoch 136/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0039\n",
      "Epoch 137/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0035\n",
      "Epoch 138/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0035\n",
      "Epoch 139/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0058\n",
      "Epoch 140/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0052 - val_loss: 0.0040\n",
      "Epoch 141/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0036\n",
      "Epoch 142/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0036\n",
      "Epoch 143/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0033\n",
      "Epoch 144/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0035\n",
      "Epoch 145/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0039\n",
      "Epoch 146/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0034\n",
      "Epoch 147/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0035\n",
      "Epoch 148/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0034\n",
      "Epoch 149/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0032\n",
      "Epoch 150/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0032\n",
      "Epoch 151/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 152/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0044\n",
      "Epoch 153/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0055\n",
      "Epoch 154/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0032\n",
      "Epoch 155/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0042\n",
      "Epoch 156/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0032\n",
      "Epoch 157/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0031\n",
      "Epoch 158/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0034\n",
      "Epoch 159/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0030\n",
      "Epoch 160/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0029\n",
      "Epoch 161/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0042 - val_loss: 0.0032\n",
      "Epoch 162/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0030\n",
      "Epoch 163/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0039\n",
      "Epoch 164/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0051 - val_loss: 0.0035\n",
      "Epoch 165/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0047 - val_loss: 0.0038\n",
      "Epoch 166/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0030\n",
      "Epoch 167/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0035\n",
      "Epoch 168/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0058 - val_loss: 0.0055\n",
      "Epoch 169/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0056 - val_loss: 0.0043\n",
      "Epoch 170/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0063\n",
      "Epoch 171/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0054 - val_loss: 0.0030\n",
      "Epoch 172/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0035\n",
      "Epoch 173/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0030\n",
      "Epoch 174/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0065\n",
      "Epoch 175/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0056 - val_loss: 0.0040\n",
      "Epoch 176/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0044\n",
      "Epoch 177/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0046 - val_loss: 0.0033\n",
      "Epoch 178/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0031\n",
      "Epoch 179/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0045 - val_loss: 0.0030\n",
      "Epoch 180/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0030\n",
      "Epoch 181/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0028\n",
      "Epoch 182/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0034\n",
      "Epoch 183/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0029\n",
      "Epoch 184/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0029\n",
      "Epoch 185/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0027\n",
      "Epoch 186/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0033\n",
      "Epoch 187/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0029\n",
      "Epoch 188/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0045\n",
      "Epoch 189/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0049\n",
      "Epoch 190/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0056 - val_loss: 0.0069\n",
      "Epoch 191/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0062 - val_loss: 0.0049\n",
      "Epoch 192/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0053 - val_loss: 0.0064\n",
      "Epoch 193/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0055 - val_loss: 0.0036\n",
      "Epoch 194/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0041 - val_loss: 0.0060\n",
      "Epoch 195/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0053 - val_loss: 0.0052\n",
      "Epoch 196/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0058 - val_loss: 0.0086\n",
      "Epoch 197/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0075 - val_loss: 0.0040\n",
      "Epoch 198/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0052\n",
      "Epoch 199/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0058 - val_loss: 0.0023\n",
      "Epoch 200/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0053 - val_loss: 0.0026\n",
      "Epoch 201/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0064 - val_loss: 0.0039\n",
      "Epoch 202/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0057 - val_loss: 0.0033\n",
      "Epoch 203/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0057 - val_loss: 0.0050\n",
      "Epoch 204/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0053 - val_loss: 0.0029\n",
      "Epoch 205/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0042 - val_loss: 0.0045\n",
      "Epoch 206/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0047 - val_loss: 0.0030\n",
      "Epoch 207/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0052 - val_loss: 0.0037\n",
      "Epoch 208/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0027\n",
      "Epoch 209/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0031\n",
      "Epoch 210/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0024\n",
      "Epoch 211/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0022\n",
      "Epoch 212/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0028\n",
      "Epoch 213/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0024\n",
      "Epoch 214/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0025\n",
      "Epoch 215/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0027\n",
      "Epoch 216/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0039 - val_loss: 0.0026\n",
      "Epoch 217/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0025\n",
      "Epoch 218/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0040 - val_loss: 0.0024\n",
      "Epoch 219/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0040 - val_loss: 0.0030\n",
      "Epoch 220/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0025\n",
      "Epoch 221/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0040 - val_loss: 0.0027\n",
      "Epoch 222/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0024\n",
      "Epoch 223/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 224/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0025\n",
      "Epoch 225/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0041 - val_loss: 0.0038\n",
      "Epoch 226/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0025\n",
      "Epoch 227/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0026\n",
      "Epoch 228/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0024\n",
      "Epoch 229/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0030\n",
      "Epoch 230/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0025\n",
      "Epoch 231/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0026\n",
      "Epoch 232/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0024\n",
      "Epoch 233/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0037 - val_loss: 0.0024\n",
      "Epoch 234/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0024\n",
      "Epoch 235/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0036 - val_loss: 0.0029\n",
      "Epoch 236/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0027\n",
      "Epoch 237/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0049 - val_loss: 0.0043\n",
      "Epoch 238/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0044 - val_loss: 0.0031\n",
      "Epoch 239/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0034\n",
      "Epoch 240/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0042 - val_loss: 0.0025\n",
      "Epoch 241/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0025\n",
      "Epoch 242/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0042 - val_loss: 0.0030\n",
      "Epoch 243/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0023\n",
      "Epoch 244/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0032\n",
      "Epoch 245/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0032\n",
      "Epoch 246/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0046 - val_loss: 0.0033\n",
      "Epoch 247/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0024\n",
      "Epoch 248/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0024\n",
      "Epoch 249/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0024\n",
      "Epoch 250/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 251/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0037 - val_loss: 0.0026\n",
      "Epoch 252/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0023\n",
      "Epoch 253/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0022\n",
      "Epoch 254/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0036 - val_loss: 0.0021\n",
      "Epoch 255/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0035 - val_loss: 0.0023\n",
      "Epoch 256/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 257/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 258/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0038 - val_loss: 0.0023\n",
      "Epoch 259/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0038 - val_loss: 0.0028\n",
      "Epoch 260/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0037 - val_loss: 0.0027\n",
      "Epoch 261/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0043 - val_loss: 0.0030\n",
      "Epoch 262/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 263/1000\n",
      "143/143 [==============================] - 0s 136us/step - loss: 0.0040 - val_loss: 0.0020\n",
      "Epoch 264/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 265/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0038 - val_loss: 0.0024\n",
      "Epoch 266/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0037 - val_loss: 0.0029\n",
      "Epoch 267/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0040 - val_loss: 0.0020\n",
      "Epoch 268/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0024\n",
      "Epoch 269/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0035 - val_loss: 0.0021\n",
      "Epoch 270/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 271/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0040 - val_loss: 0.0035\n",
      "Epoch 272/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0045 - val_loss: 0.0025\n",
      "Epoch 273/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0041 - val_loss: 0.0024\n",
      "Epoch 274/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 275/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 276/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 277/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0034 - val_loss: 0.0021\n",
      "Epoch 278/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 279/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0034 - val_loss: 0.0021\n",
      "Epoch 280/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 281/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 282/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 283/1000\n",
      "143/143 [==============================] - 0s 136us/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 284/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0041 - val_loss: 0.0020\n",
      "Epoch 285/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0038 - val_loss: 0.0019\n",
      "Epoch 286/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0034 - val_loss: 0.0023\n",
      "Epoch 287/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 288/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0034 - val_loss: 0.0025\n",
      "Epoch 289/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 290/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0033 - val_loss: 0.0021\n",
      "Epoch 291/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0034 - val_loss: 0.0021\n",
      "Epoch 292/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0033 - val_loss: 0.0021\n",
      "Epoch 293/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 294/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0020\n",
      "Epoch 295/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0021\n",
      "Epoch 296/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0034 - val_loss: 0.0021\n",
      "Epoch 297/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0035 - val_loss: 0.0027\n",
      "Epoch 298/1000\n",
      "143/143 [==============================] - 0s 136us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 299/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0033 - val_loss: 0.0020\n",
      "Epoch 300/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 153us/step - loss: 0.0035 - val_loss: 0.0022\n",
      "Epoch 301/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 302/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0044 - val_loss: 0.0028\n",
      "Epoch 303/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0027\n",
      "Epoch 304/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0025\n",
      "Epoch 305/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 306/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0058 - val_loss: 0.0031\n",
      "Epoch 307/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0045 - val_loss: 0.0022\n",
      "Epoch 308/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0036 - val_loss: 0.0021\n",
      "Epoch 309/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 310/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 311/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0021\n",
      "Epoch 312/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0042 - val_loss: 0.0027\n",
      "Epoch 313/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0020\n",
      "Epoch 314/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0021\n",
      "Epoch 315/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0036 - val_loss: 0.0017\n",
      "Epoch 316/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 317/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0038 - val_loss: 0.0026\n",
      "Epoch 318/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0019\n",
      "Epoch 319/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 320/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0035 - val_loss: 0.0022\n",
      "Epoch 321/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0020\n",
      "Epoch 322/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0023\n",
      "Epoch 323/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 324/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0035 - val_loss: 0.0023\n",
      "Epoch 325/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0021\n",
      "Epoch 326/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 327/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0033 - val_loss: 0.0018\n",
      "Epoch 328/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0017\n",
      "Epoch 329/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0036 - val_loss: 0.0026\n",
      "Epoch 330/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0019\n",
      "Epoch 331/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0024\n",
      "Epoch 332/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 333/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0032 - val_loss: 0.0029\n",
      "Epoch 334/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0040 - val_loss: 0.0022\n",
      "Epoch 335/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0040 - val_loss: 0.0027\n",
      "Epoch 336/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0023\n",
      "Epoch 337/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0023\n",
      "Epoch 338/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0021\n",
      "Epoch 339/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0017\n",
      "Epoch 340/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 341/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 342/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0024\n",
      "Epoch 343/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0025\n",
      "Epoch 344/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 345/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0017\n",
      "Epoch 346/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 347/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0033 - val_loss: 0.0019\n",
      "Epoch 348/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0034 - val_loss: 0.0031\n",
      "Epoch 349/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0018\n",
      "Epoch 350/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0019\n",
      "Epoch 351/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0035 - val_loss: 0.0016\n",
      "Epoch 352/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0016\n",
      "Epoch 353/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0021\n",
      "Epoch 354/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 355/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0016\n",
      "Epoch 356/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0033 - val_loss: 0.0017\n",
      "Epoch 357/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0032 - val_loss: 0.0017\n",
      "Epoch 358/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0016\n",
      "Epoch 359/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0018\n",
      "Epoch 360/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0018\n",
      "Epoch 361/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0031 - val_loss: 0.0018\n",
      "Epoch 362/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0019\n",
      "Epoch 363/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0017\n",
      "Epoch 364/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0016\n",
      "Epoch 365/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0016\n",
      "Epoch 366/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0019\n",
      "Epoch 367/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0019\n",
      "Epoch 368/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 369/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 370/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0040 - val_loss: 0.0034\n",
      "Epoch 371/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0033\n",
      "Epoch 372/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0025\n",
      "Epoch 373/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 374/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0039 - val_loss: 0.0023\n",
      "Epoch 375/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0021\n",
      "Epoch 376/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0017\n",
      "Epoch 377/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0016\n",
      "Epoch 378/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 379/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0042 - val_loss: 0.0022\n",
      "Epoch 380/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0043 - val_loss: 0.0028\n",
      "Epoch 381/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0039 - val_loss: 0.0026\n",
      "Epoch 382/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 383/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0037\n",
      "Epoch 384/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0051 - val_loss: 0.0034\n",
      "Epoch 385/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0029\n",
      "Epoch 386/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0021\n",
      "Epoch 387/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0036 - val_loss: 0.0017\n",
      "Epoch 388/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0017\n",
      "Epoch 389/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0041 - val_loss: 0.0018\n",
      "Epoch 390/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 391/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 392/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0016\n",
      "Epoch 393/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0017\n",
      "Epoch 394/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0017\n",
      "Epoch 395/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0017\n",
      "Epoch 396/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0016\n",
      "Epoch 397/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0016\n",
      "Epoch 398/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0018\n",
      "Epoch 399/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0016\n",
      "Epoch 400/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0019\n",
      "Epoch 401/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0030 - val_loss: 0.0017\n",
      "Epoch 402/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0017\n",
      "Epoch 403/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0016\n",
      "Epoch 404/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0020\n",
      "Epoch 405/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0035 - val_loss: 0.0021\n",
      "Epoch 406/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0026\n",
      "Epoch 407/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0040 - val_loss: 0.0027\n",
      "Epoch 408/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0034\n",
      "Epoch 409/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0027\n",
      "Epoch 410/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0031\n",
      "Epoch 411/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0027\n",
      "Epoch 412/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0022\n",
      "Epoch 413/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 414/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0022\n",
      "Epoch 415/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0020\n",
      "Epoch 416/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0026\n",
      "Epoch 417/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0017\n",
      "Epoch 418/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0016\n",
      "Epoch 419/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0016\n",
      "Epoch 420/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0018\n",
      "Epoch 421/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0030 - val_loss: 0.0017\n",
      "Epoch 422/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0021\n",
      "Epoch 423/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0022\n",
      "Epoch 424/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0026\n",
      "Epoch 425/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 426/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 427/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0016\n",
      "Epoch 428/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 429/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0018\n",
      "Epoch 430/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0019\n",
      "Epoch 431/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0023\n",
      "Epoch 432/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.003 - 0s 119us/step - loss: 0.0032 - val_loss: 0.0017\n",
      "Epoch 433/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0019\n",
      "Epoch 434/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0020\n",
      "Epoch 435/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 436/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0021\n",
      "Epoch 437/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0028\n",
      "Epoch 438/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 439/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 440/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0033 - val_loss: 0.0017\n",
      "Epoch 441/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0016\n",
      "Epoch 442/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0018\n",
      "Epoch 443/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0016\n",
      "Epoch 444/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0029 - val_loss: 0.0016\n",
      "Epoch 445/1000\n",
      "143/143 [==============================] - 0s 130us/step - loss: 0.0029 - val_loss: 0.0016\n",
      "Epoch 446/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0017\n",
      "Epoch 447/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0029 - val_loss: 0.0016\n",
      "Epoch 448/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0018\n",
      "Epoch 449/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0015\n",
      "Epoch 450/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0028 - val_loss: 0.0018\n",
      "Epoch 451/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0016\n",
      "Epoch 452/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0018\n",
      "Epoch 453/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0019\n",
      "Epoch 454/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 126us/step - loss: 0.0030 - val_loss: 0.0023\n",
      "Epoch 455/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0018\n",
      "Epoch 456/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0019\n",
      "Epoch 457/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0032 - val_loss: 0.0019\n",
      "Epoch 458/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0023\n",
      "Epoch 459/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 460/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0022\n",
      "Epoch 461/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0016\n",
      "Epoch 462/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0029 - val_loss: 0.0015\n",
      "Epoch 463/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0014\n",
      "Epoch 464/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0022\n",
      "Epoch 465/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0032 - val_loss: 0.0018\n",
      "Epoch 466/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0017\n",
      "Epoch 467/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0016\n",
      "Epoch 468/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0029 - val_loss: 0.0017\n",
      "Epoch 469/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0030 - val_loss: 0.0018\n",
      "Epoch 470/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0017\n",
      "Epoch 471/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0017\n",
      "Epoch 472/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0017\n",
      "Epoch 473/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0016\n",
      "Epoch 474/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 475/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0034 - val_loss: 0.0019\n",
      "Epoch 476/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0018\n",
      "Epoch 477/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0020\n",
      "Epoch 478/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 479/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 480/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 481/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0017\n",
      "Epoch 482/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 483/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0019\n",
      "Epoch 484/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0017\n",
      "Epoch 485/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0018\n",
      "Epoch 486/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0017\n",
      "Epoch 487/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0017\n",
      "Epoch 488/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0015\n",
      "Epoch 489/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0017\n",
      "Epoch 490/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0018\n",
      "Epoch 491/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0016\n",
      "Epoch 492/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0017\n",
      "Epoch 493/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0016\n",
      "Epoch 494/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0019\n",
      "Epoch 495/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0030 - val_loss: 0.0016\n",
      "Epoch 496/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0028 - val_loss: 0.0016\n",
      "Epoch 497/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0018\n",
      "Epoch 498/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0030 - val_loss: 0.0018\n",
      "Epoch 499/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0030 - val_loss: 0.0024\n",
      "Epoch 500/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0019\n",
      "Epoch 501/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0020\n",
      "Epoch 502/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0016\n",
      "Epoch 503/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 504/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0028 - val_loss: 0.0016\n",
      "Epoch 505/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0016\n",
      "Epoch 506/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0019\n",
      "Epoch 507/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0017\n",
      "Epoch 508/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0015\n",
      "Epoch 509/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0017\n",
      "Epoch 510/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 511/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0027 - val_loss: 0.0016\n",
      "Epoch 512/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 513/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0016\n",
      "Epoch 514/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0017\n",
      "Epoch 515/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0026\n",
      "Epoch 516/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 517/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0031 - val_loss: 0.0022\n",
      "Epoch 518/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0019\n",
      "Epoch 519/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0022\n",
      "Epoch 520/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0030 - val_loss: 0.0019\n",
      "Epoch 521/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0036 - val_loss: 0.0017\n",
      "Epoch 522/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0033 - val_loss: 0.0018\n",
      "Epoch 523/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0017\n",
      "Epoch 524/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0020\n",
      "Epoch 525/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0017\n",
      "Epoch 526/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0018\n",
      "Epoch 527/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0017\n",
      "Epoch 528/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0018\n",
      "Epoch 529/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0018\n",
      "Epoch 530/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0027 - val_loss: 0.0016\n",
      "Epoch 531/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0016\n",
      "Epoch 532/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 533/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0018\n",
      "Epoch 534/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 535/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0016\n",
      "Epoch 536/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0020\n",
      "Epoch 537/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0022\n",
      "Epoch 538/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0029\n",
      "Epoch 539/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 540/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0031\n",
      "Epoch 541/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0025\n",
      "Epoch 542/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0023\n",
      "Epoch 543/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0032 - val_loss: 0.0018\n",
      "Epoch 544/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0030 - val_loss: 0.0017\n",
      "Epoch 545/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0015\n",
      "Epoch 546/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 547/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 548/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0016\n",
      "Epoch 549/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 550/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0027 - val_loss: 0.0018\n",
      "Epoch 551/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0016\n",
      "Epoch 552/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0028 - val_loss: 0.0015\n",
      "Epoch 553/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0016\n",
      "Epoch 554/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0021\n",
      "Epoch 555/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0018\n",
      "Epoch 556/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0028 - val_loss: 0.0017\n",
      "Epoch 557/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0016\n",
      "Epoch 558/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 559/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0028 - val_loss: 0.0018\n",
      "Epoch 560/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.002 - 0s 119us/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 561/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0029 - val_loss: 0.0027\n",
      "Epoch 562/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0027\n",
      "Epoch 563/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 564/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0019\n",
      "Epoch 565/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0031 - val_loss: 0.0018\n",
      "Epoch 566/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0017\n",
      "Epoch 567/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0032 - val_loss: 0.0017\n",
      "Epoch 568/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0022\n",
      "Epoch 569/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 570/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0026\n",
      "Epoch 571/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0018\n",
      "Epoch 572/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 573/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 574/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0023\n",
      "Epoch 575/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0020\n",
      "Epoch 576/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0023\n",
      "Epoch 577/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0020\n",
      "Epoch 578/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0020\n",
      "Epoch 579/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0029 - val_loss: 0.0016\n",
      "Epoch 580/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 581/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 582/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 583/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 584/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 585/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0020\n",
      "Epoch 586/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0024\n",
      "Epoch 587/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0018\n",
      "Epoch 588/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0028 - val_loss: 0.0016\n",
      "Epoch 589/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0027 - val_loss: 0.0016\n",
      "Epoch 590/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0030 - val_loss: 0.0020\n",
      "Epoch 591/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0025\n",
      "Epoch 592/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0021\n",
      "Epoch 593/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0035 - val_loss: 0.0016\n",
      "Epoch 594/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0028 - val_loss: 0.0021\n",
      "Epoch 595/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0023\n",
      "Epoch 596/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0034 - val_loss: 0.0024\n",
      "Epoch 597/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0023\n",
      "Epoch 598/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0036 - val_loss: 0.0032\n",
      "Epoch 599/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0024\n",
      "Epoch 600/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0027\n",
      "Epoch 601/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0017\n",
      "Epoch 602/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 603/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 604/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 605/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 606/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0018\n",
      "Epoch 607/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 608/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 609/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 610/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0017\n",
      "Epoch 611/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0026 - val_loss: 0.0016\n",
      "Epoch 612/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0016\n",
      "Epoch 613/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0018\n",
      "Epoch 614/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0016\n",
      "Epoch 615/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 616/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 617/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 618/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0027 - val_loss: 0.0016\n",
      "Epoch 619/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 620/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 621/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0026 - val_loss: 0.0021\n",
      "Epoch 622/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0029 - val_loss: 0.0018\n",
      "Epoch 623/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 624/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0032 - val_loss: 0.0020\n",
      "Epoch 625/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0022\n",
      "Epoch 626/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0026 - val_loss: 0.0020\n",
      "Epoch 627/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 628/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0018\n",
      "Epoch 629/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0019\n",
      "Epoch 630/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 631/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 632/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0020\n",
      "Epoch 633/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 634/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 635/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 636/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0019\n",
      "Epoch 637/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0026 - val_loss: 0.0020\n",
      "Epoch 638/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 639/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 640/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 641/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 642/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 643/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 644/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 645/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 646/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 647/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 648/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0019\n",
      "Epoch 649/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0020\n",
      "Epoch 650/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0020\n",
      "Epoch 651/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 652/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0029 - val_loss: 0.0018\n",
      "Epoch 653/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 654/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 655/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 656/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0027 - val_loss: 0.0018\n",
      "Epoch 657/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 658/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 659/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 660/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0018\n",
      "Epoch 661/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0019\n",
      "Epoch 662/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 663/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0020\n",
      "Epoch 664/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 665/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 666/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 667/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 668/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 669/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 670/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 671/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 672/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 673/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 674/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0021\n",
      "Epoch 675/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0022\n",
      "Epoch 676/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0017\n",
      "Epoch 677/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 678/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0023\n",
      "Epoch 679/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0019\n",
      "Epoch 680/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0019\n",
      "Epoch 681/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 682/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 683/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 684/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0020\n",
      "Epoch 685/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0030\n",
      "Epoch 686/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0025\n",
      "Epoch 687/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0021\n",
      "Epoch 688/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 689/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 690/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0020\n",
      "Epoch 691/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0021\n",
      "Epoch 692/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 693/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0021\n",
      "Epoch 694/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 695/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0020\n",
      "Epoch 696/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 697/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 698/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0020\n",
      "Epoch 699/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 700/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 701/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 702/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0024 - val_loss: 0.0020\n",
      "Epoch 703/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 704/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 705/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 706/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 707/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 708/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0020\n",
      "Epoch 709/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 710/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 711/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 712/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 713/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0020\n",
      "Epoch 714/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 715/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 716/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0019\n",
      "Epoch 717/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0020\n",
      "Epoch 718/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0026\n",
      "Epoch 719/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 720/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 721/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 722/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 723/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0019\n",
      "Epoch 724/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 725/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 726/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 727/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 728/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0027 - val_loss: 0.0021\n",
      "Epoch 729/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0030 - val_loss: 0.0020\n",
      "Epoch 730/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 731/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 732/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 733/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0020\n",
      "Epoch 734/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 735/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0028 - val_loss: 0.0019\n",
      "Epoch 736/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0018\n",
      "Epoch 737/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 738/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0024\n",
      "Epoch 739/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0034\n",
      "Epoch 740/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0025\n",
      "Epoch 741/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0033 - val_loss: 0.0024\n",
      "Epoch 742/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0018\n",
      "Epoch 743/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0020\n",
      "Epoch 744/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 745/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 746/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 747/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 748/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 749/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 750/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0017\n",
      "Epoch 751/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 752/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 753/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0019\n",
      "Epoch 754/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 755/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 756/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 757/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0022\n",
      "Epoch 758/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 759/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0024 - val_loss: 0.0020\n",
      "Epoch 760/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0019\n",
      "Epoch 761/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 762/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 111us/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 763/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0035\n",
      "Epoch 764/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0019\n",
      "Epoch 765/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 766/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 767/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 768/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 769/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0023\n",
      "Epoch 770/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0020\n",
      "Epoch 771/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0019\n",
      "Epoch 772/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0023\n",
      "Epoch 773/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0019\n",
      "Epoch 774/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0026 - val_loss: 0.0021\n",
      "Epoch 775/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 776/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 777/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0027 - val_loss: 0.0019\n",
      "Epoch 778/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0025 - val_loss: 0.0022\n",
      "Epoch 779/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0021\n",
      "Epoch 780/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 781/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 782/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 783/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 784/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 785/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0019\n",
      "Epoch 786/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 787/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0020\n",
      "Epoch 788/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 789/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 790/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 791/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 792/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0027 - val_loss: 0.0023\n",
      "Epoch 793/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 794/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0024\n",
      "Epoch 795/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 796/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0020\n",
      "Epoch 797/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0021\n",
      "Epoch 798/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0024 - val_loss: 0.0019\n",
      "Epoch 799/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0019\n",
      "Epoch 800/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 801/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 802/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0027 - val_loss: 0.0022\n",
      "Epoch 803/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0020\n",
      "Epoch 804/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 805/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 806/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0031\n",
      "Epoch 807/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0021\n",
      "Epoch 808/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0021\n",
      "Epoch 809/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 810/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 811/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 812/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 813/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 814/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 815/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 816/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0019\n",
      "Epoch 817/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 818/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0024 - val_loss: 0.0019\n",
      "Epoch 819/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 820/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0019\n",
      "Epoch 821/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 822/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0020\n",
      "Epoch 823/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 824/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 825/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 826/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 827/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0019\n",
      "Epoch 828/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 829/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 830/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 831/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 832/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0025 - val_loss: 0.0020\n",
      "Epoch 833/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 834/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 835/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 836/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0020\n",
      "Epoch 837/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 838/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 839/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 118us/step - loss: 0.0026 - val_loss: 0.0020\n",
      "Epoch 840/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 841/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 842/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 843/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 844/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 845/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 846/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 847/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 848/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 849/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0024\n",
      "Epoch 850/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 851/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 852/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 853/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0021\n",
      "Epoch 854/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 855/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0026\n",
      "Epoch 856/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 857/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0023\n",
      "Epoch 858/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0027\n",
      "Epoch 859/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 860/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0021\n",
      "Epoch 861/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 862/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0027\n",
      "Epoch 863/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0021\n",
      "Epoch 864/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 865/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 866/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 867/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0022\n",
      "Epoch 868/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 869/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 870/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 871/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0019\n",
      "Epoch 872/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0027 - val_loss: 0.0024\n",
      "Epoch 873/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 874/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0024 - val_loss: 0.0020\n",
      "Epoch 875/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 876/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0020\n",
      "Epoch 877/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 878/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0021\n",
      "Epoch 879/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 880/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 881/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 882/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0020\n",
      "Epoch 883/1000\n",
      "143/143 [==============================] - 0s 167us/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 884/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0020\n",
      "Epoch 885/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 886/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 887/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 888/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 889/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 890/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 891/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 892/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 893/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 894/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 895/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 896/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 897/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 898/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 899/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0025\n",
      "Epoch 900/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0028 - val_loss: 0.0019\n",
      "Epoch 901/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0022\n",
      "Epoch 902/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 903/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 904/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 905/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 906/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0022\n",
      "Epoch 907/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0020\n",
      "Epoch 908/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0023\n",
      "Epoch 909/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0021\n",
      "Epoch 910/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 911/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0021\n",
      "Epoch 912/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0025 - val_loss: 0.0021\n",
      "Epoch 913/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 914/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 915/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0026\n",
      "Epoch 916/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0019\n",
      "Epoch 917/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 918/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 919/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 920/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 921/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 922/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 923/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 924/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 925/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 926/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 927/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0024 - val_loss: 0.0020\n",
      "Epoch 928/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 929/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0024 - val_loss: 0.0020\n",
      "Epoch 930/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 931/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 932/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 933/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 934/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 935/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 936/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 937/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 938/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 939/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 940/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0024 - val_loss: 0.0019\n",
      "Epoch 941/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 942/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 943/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 944/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 945/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 946/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 947/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 948/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 949/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 950/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 951/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 952/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 953/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 954/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 955/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 956/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 957/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0020\n",
      "Epoch 958/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 959/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 960/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0020\n",
      "Epoch 961/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0024 - val_loss: 0.0019\n",
      "Epoch 962/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0028\n",
      "Epoch 963/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 964/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0020\n",
      "Epoch 965/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 966/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 967/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 968/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 969/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 970/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 971/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 972/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 973/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 974/1000\n",
      "143/143 [==============================] - 0s 140us/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 975/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0024 - val_loss: 0.0019\n",
      "Epoch 976/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 977/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 978/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 979/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 980/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 981/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 982/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0022\n",
      "Epoch 983/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 984/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 985/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 986/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 987/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 988/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 989/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 990/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 991/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0035\n",
      "Epoch 992/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0027 - val_loss: 0.0020\n",
      "Epoch 993/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 994/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 995/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 996/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 997/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0024 - val_loss: 0.0020\n",
      "Epoch 998/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 999/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0019\n",
      "Epoch 1000/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0026\n",
      "0.012258177623152733\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-5.13971508e-01, -8.73917520e-01,  7.02551365e-01,\n",
       "          3.56984437e-02,  1.97673336e-01],\n",
       "        [-3.68911237e-01, -1.96639985e-01, -3.85284096e-01,\n",
       "         -8.48502040e-01, -4.27544922e-01],\n",
       "        [-2.61735290e-01, -1.91894129e-01, -1.49801761e-01,\n",
       "         -7.85320252e-03,  1.45972162e-01],\n",
       "        [ 3.97986084e-01, -4.42281395e-01,  1.93476871e-01,\n",
       "         -7.18864322e-01,  3.80972505e-01],\n",
       "        [-4.25278217e-01,  9.80827734e-02, -3.69470209e-01,\n",
       "         -8.91145289e-01, -1.07779056e-01],\n",
       "        [ 2.13314686e-03, -6.27325356e-01,  9.25354481e-01,\n",
       "         -5.92765629e-01,  2.18107790e-01],\n",
       "        [-4.29032296e-02, -4.02274042e-01, -2.92055637e-01,\n",
       "         -5.63374996e-01, -1.34276533e+00],\n",
       "        [-6.51183486e-01,  3.39411162e-02, -9.26785320e-02,\n",
       "          4.97012511e-02,  1.57500759e-01],\n",
       "        [-5.10955215e-01, -3.23823959e-01,  2.49338686e-01,\n",
       "         -1.79187089e-01, -2.71118671e-01],\n",
       "        [-3.14902812e-01, -2.21453775e-02, -7.23139569e-02,\n",
       "          1.09237030e-01,  7.49017149e-02],\n",
       "        [ 2.13985786e-01, -7.06960499e-01, -5.76455951e-01,\n",
       "         -1.58757761e-01, -1.18340051e+00],\n",
       "        [-4.76491541e-01, -5.62185287e-01,  5.07812560e-01,\n",
       "         -5.52946568e-01,  2.00213313e+00],\n",
       "        [-6.30868971e-01, -5.87470174e-01, -2.15814903e-01,\n",
       "         -5.68391800e-01, -3.37922305e-01],\n",
       "        [-4.72309411e-01, -6.37461841e-01,  1.24168050e+00,\n",
       "         -1.76178828e-01,  5.02301037e-01],\n",
       "        [-1.37580350e-01, -6.45798087e-01, -1.52901992e-01,\n",
       "         -4.37001050e-01, -3.17142218e-01],\n",
       "        [-3.35348219e-01, -8.02231193e-01, -4.12241727e-01,\n",
       "         -6.36350811e-01, -2.36881465e-01],\n",
       "        [ 2.38438427e-01, -1.89608082e-01,  7.64739394e-01,\n",
       "          4.64814529e-02,  9.90872383e-01],\n",
       "        [ 1.70032084e-01, -7.94101238e-01,  2.10118353e-01,\n",
       "         -1.87096298e-01, -4.66642022e-01],\n",
       "        [-5.96626520e-01,  8.86140317e-02, -5.33875704e-01,\n",
       "         -6.89823806e-01, -1.50270414e+00],\n",
       "        [ 2.14156196e-01, -6.80520058e-01,  1.78411990e-01,\n",
       "         -4.20569122e-01, -2.51647919e-01],\n",
       "        [-5.45034826e-01, -6.26840532e-01, -2.64061475e+00,\n",
       "         -3.39740247e-01,  4.55590010e-01],\n",
       "        [-2.01426707e-02, -2.13064119e-01,  3.47792991e-02,\n",
       "         -1.40631661e-01, -3.39320928e-01]], dtype=float32),\n",
       " array([-0.20652208, -0.42017788, -0.27218342, -0.3119144 ,  0.2195347 ],\n",
       "       dtype=float32),\n",
       " array([[-1.34668387e-02, -8.19763899e-01,  2.26270840e-01,\n",
       "         -1.23434979e-02, -4.11505520e-01, -8.87511149e-02,\n",
       "         -3.61489773e-01,  1.17789745e-01, -8.24815333e-01,\n",
       "         -2.15808935e-02],\n",
       "        [-1.38831347e-01, -1.53415352e-01, -1.78123534e-01,\n",
       "         -2.53468722e-01, -5.36498666e-01,  1.02092505e-01,\n",
       "          3.50859910e-01, -7.79920220e-01, -7.29492068e-01,\n",
       "         -2.17943758e-01],\n",
       "        [-1.16305661e+00,  1.77891612e-01, -2.25033998e-01,\n",
       "         -4.43796694e-01,  1.16402781e+00, -3.23396236e-01,\n",
       "         -7.59119019e-02,  2.03205389e-03,  3.19433141e+00,\n",
       "         -2.48878226e-01],\n",
       "        [ 2.34611183e-02, -3.10695022e-01, -2.43141502e-01,\n",
       "          1.05057366e-01,  1.19282492e-01,  6.50408030e-01,\n",
       "         -8.33185017e-02,  5.96097469e-01, -6.23504162e-01,\n",
       "         -4.96208578e-01],\n",
       "        [-1.34472370e+00, -7.87951052e-01,  3.04178149e-01,\n",
       "         -9.09560099e-02,  8.46489787e-01, -7.28610337e-01,\n",
       "          7.08161116e-01, -9.28156137e-01, -6.52872515e+00,\n",
       "         -6.85477793e-01]], dtype=float32),\n",
       " array([-0.37684658, -0.4073757 , -0.19768393, -0.17261785,  0.06339768,\n",
       "        -0.19938585,  0.05390341, -0.849428  , -1.5773114 , -0.27406043],\n",
       "       dtype=float32),\n",
       " array([[-0.40048513],\n",
       "        [ 0.42921066],\n",
       "        [-0.22218059],\n",
       "        [-0.42515078],\n",
       "        [ 0.6476278 ],\n",
       "        [ 0.47797352],\n",
       "        [-0.59082913],\n",
       "        [ 0.0578002 ],\n",
       "        [ 0.6786625 ],\n",
       "        [ 0.33631125]], dtype=float32),\n",
       " array([0.0072138], dtype=float32)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_automobile, history_automobile, evaluate_automobile=NN_model_structure_regression_sigmoid(X_train_automobile, X_val_automobile, Y_train_automobile, Y_val_automobile, adam2, 32, 1000, x_test_automobile, y_test_automobile)\n",
    "model_automobile.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_automobile.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_automobile_sigmoid_4th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_34 (Dense)             (None, 5)                 115       \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 186\n",
      "Trainable params: 186\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 143 samples, validate on 31 samples\n",
      "Epoch 1/1000\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1099 - val_loss: 0.0646\n",
      "Epoch 2/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0476 - val_loss: 0.0339\n",
      "Epoch 3/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0432 - val_loss: 0.0513\n",
      "Epoch 4/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0462 - val_loss: 0.0248\n",
      "Epoch 5/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0446 - val_loss: 0.0253\n",
      "Epoch 6/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0405 - val_loss: 0.0383\n",
      "Epoch 7/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0380 - val_loss: 0.0251\n",
      "Epoch 8/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0403 - val_loss: 0.0272\n",
      "Epoch 9/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0387 - val_loss: 0.0309\n",
      "Epoch 10/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0382 - val_loss: 0.0248\n",
      "Epoch 11/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0388 - val_loss: 0.0289\n",
      "Epoch 12/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 13/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 14/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0370 - val_loss: 0.0270\n",
      "Epoch 15/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 16/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0270\n",
      "Epoch 17/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0370 - val_loss: 0.0284\n",
      "Epoch 18/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0375 - val_loss: 0.0270\n",
      "Epoch 19/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0389 - val_loss: 0.0249\n",
      "Epoch 20/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0370 - val_loss: 0.0308\n",
      "Epoch 21/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0380 - val_loss: 0.0278\n",
      "Epoch 22/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0376 - val_loss: 0.0254\n",
      "Epoch 23/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0391 - val_loss: 0.0298\n",
      "Epoch 24/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0365 - val_loss: 0.0253\n",
      "Epoch 25/1000\n",
      "143/143 [==============================] - 0s 129us/step - loss: 0.0385 - val_loss: 0.0253\n",
      "Epoch 26/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0300\n",
      "Epoch 27/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0381 - val_loss: 0.0288\n",
      "Epoch 28/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0377 - val_loss: 0.0252\n",
      "Epoch 29/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0373 - val_loss: 0.0270\n",
      "Epoch 30/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0288\n",
      "Epoch 31/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0371 - val_loss: 0.0268\n",
      "Epoch 32/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0253\n",
      "Epoch 33/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0374 - val_loss: 0.0261\n",
      "Epoch 34/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0366 - val_loss: 0.0290\n",
      "Epoch 35/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0373 - val_loss: 0.0284\n",
      "Epoch 36/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0368 - val_loss: 0.0261\n",
      "Epoch 37/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0371 - val_loss: 0.0260\n",
      "Epoch 38/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0374 - val_loss: 0.0275\n",
      "Epoch 39/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0377 - val_loss: 0.0261\n",
      "Epoch 40/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0370 - val_loss: 0.0287\n",
      "Epoch 41/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0371 - val_loss: 0.0277\n",
      "Epoch 42/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0374 - val_loss: 0.0261\n",
      "Epoch 43/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 44/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 45/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0283\n",
      "Epoch 46/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0274\n",
      "Epoch 47/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0373 - val_loss: 0.0261\n",
      "Epoch 48/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0367 - val_loss: 0.0281\n",
      "Epoch 49/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0376 - val_loss: 0.0293\n",
      "Epoch 50/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0368 - val_loss: 0.0263\n",
      "Epoch 51/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0377 - val_loss: 0.0252\n",
      "Epoch 52/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0371 - val_loss: 0.0278\n",
      "Epoch 53/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0371 - val_loss: 0.0284\n",
      "Epoch 54/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0374 - val_loss: 0.0259\n",
      "Epoch 55/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0276\n",
      "Epoch 56/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0276\n",
      "Epoch 57/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0370 - val_loss: 0.0268\n",
      "Epoch 58/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0368 - val_loss: 0.0277\n",
      "Epoch 59/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0271\n",
      "Epoch 60/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0371 - val_loss: 0.0260\n",
      "Epoch 61/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0370 - val_loss: 0.0270\n",
      "Epoch 62/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0285\n",
      "Epoch 63/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0267\n",
      "Epoch 64/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 65/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 66/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 67/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0285\n",
      "Epoch 68/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0271\n",
      "Epoch 69/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0262\n",
      "Epoch 70/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0275\n",
      "Epoch 71/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0374 - val_loss: 0.0263\n",
      "Epoch 72/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0372 - val_loss: 0.0276\n",
      "Epoch 73/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0370 - val_loss: 0.0261\n",
      "Epoch 74/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0369 - val_loss: 0.0274\n",
      "Epoch 75/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 76/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0280\n",
      "Epoch 77/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 78/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0373 - val_loss: 0.0257\n",
      "Epoch 79/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0370 - val_loss: 0.0275\n",
      "Epoch 80/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0285\n",
      "Epoch 81/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0374 - val_loss: 0.0266\n",
      "Epoch 82/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0291\n",
      "Epoch 83/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0372 - val_loss: 0.0275\n",
      "Epoch 84/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0259\n",
      "Epoch 85/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0379 - val_loss: 0.0258\n",
      "Epoch 86/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0374 - val_loss: 0.0296\n",
      "Epoch 87/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0373 - val_loss: 0.0273\n",
      "Epoch 88/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0271\n",
      "Epoch 89/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0367 - val_loss: 0.0259\n",
      "Epoch 90/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0370 - val_loss: 0.0263\n",
      "Epoch 91/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0367 - val_loss: 0.0286\n",
      "Epoch 92/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0371 - val_loss: 0.0277\n",
      "Epoch 93/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 94/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0376 - val_loss: 0.0256\n",
      "Epoch 95/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0374 - val_loss: 0.0285\n",
      "Epoch 96/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0278\n",
      "Epoch 97/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0372 - val_loss: 0.0257\n",
      "Epoch 98/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0370 - val_loss: 0.0269\n",
      "Epoch 99/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0277\n",
      "Epoch 100/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0374 - val_loss: 0.0299\n",
      "Epoch 101/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0370 - val_loss: 0.0265\n",
      "Epoch 102/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0257\n",
      "Epoch 103/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0371 - val_loss: 0.0263\n",
      "Epoch 104/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0366 - val_loss: 0.0283\n",
      "Epoch 105/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0370 - val_loss: 0.0300\n",
      "Epoch 106/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0371 - val_loss: 0.0272\n",
      "Epoch 107/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0368 - val_loss: 0.0260\n",
      "Epoch 108/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0370 - val_loss: 0.0270\n",
      "Epoch 109/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 110/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 111/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 112/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0368 - val_loss: 0.0275\n",
      "Epoch 113/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0372 - val_loss: 0.0264\n",
      "Epoch 114/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0276\n",
      "Epoch 115/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 116/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0271\n",
      "Epoch 117/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0369 - val_loss: 0.0280\n",
      "Epoch 118/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0274\n",
      "Epoch 119/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 120/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0371 - val_loss: 0.0260\n",
      "Epoch 121/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0369 - val_loss: 0.0277\n",
      "Epoch 122/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0370 - val_loss: 0.0281\n",
      "Epoch 123/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0367 - val_loss: 0.0264\n",
      "Epoch 124/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0371 - val_loss: 0.0255\n",
      "Epoch 125/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0370 - val_loss: 0.0272\n",
      "Epoch 126/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0369 - val_loss: 0.0284\n",
      "Epoch 127/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0373 - val_loss: 0.0298\n",
      "Epoch 128/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0372 - val_loss: 0.0270\n",
      "Epoch 129/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 130/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0371 - val_loss: 0.0284\n",
      "Epoch 131/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0267\n",
      "Epoch 132/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 133/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 134/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0370 - val_loss: 0.0259\n",
      "Epoch 135/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0369 - val_loss: 0.0284\n",
      "Epoch 136/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0370 - val_loss: 0.0289\n",
      "Epoch 137/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 138/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0376 - val_loss: 0.0252\n",
      "Epoch 139/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0373 - val_loss: 0.0268\n",
      "Epoch 140/1000\n",
      "143/143 [==============================] - 0s 151us/step - loss: 0.0370 - val_loss: 0.0274\n",
      "Epoch 141/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0277\n",
      "Epoch 142/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0271\n",
      "Epoch 143/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 144/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0372 - val_loss: 0.0277\n",
      "Epoch 145/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0372 - val_loss: 0.0261\n",
      "Epoch 146/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 123us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 147/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0368 - val_loss: 0.0276\n",
      "Epoch 148/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0369 - val_loss: 0.0277\n",
      "Epoch 149/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 150/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 151/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0370 - val_loss: 0.0264\n",
      "Epoch 152/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0279\n",
      "Epoch 153/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0373 - val_loss: 0.0267\n",
      "Epoch 154/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0367 - val_loss: 0.0284\n",
      "Epoch 155/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0373 - val_loss: 0.0283\n",
      "Epoch 156/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0373 - val_loss: 0.0260\n",
      "Epoch 157/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0370 - val_loss: 0.0274\n",
      "Epoch 158/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0277\n",
      "Epoch 159/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 160/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 161/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0264\n",
      "Epoch 162/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 163/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0283\n",
      "Epoch 164/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0278\n",
      "Epoch 165/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 166/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 167/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0268\n",
      "Epoch 168/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0372 - val_loss: 0.0256\n",
      "Epoch 169/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0371 - val_loss: 0.0264\n",
      "Epoch 170/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0367 - val_loss: 0.0284\n",
      "Epoch 171/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0371 - val_loss: 0.0290\n",
      "Epoch 172/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0274\n",
      "Epoch 173/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0372 - val_loss: 0.0255\n",
      "Epoch 174/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0372 - val_loss: 0.0261\n",
      "Epoch 175/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 176/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0372 - val_loss: 0.0288\n",
      "Epoch 177/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 178/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.026 - 0s 111us/step - loss: 0.0370 - val_loss: 0.0261\n",
      "Epoch 179/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0274\n",
      "Epoch 180/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0271\n",
      "Epoch 181/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0370 - val_loss: 0.0265\n",
      "Epoch 182/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0373 - val_loss: 0.0280\n",
      "Epoch 183/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 184/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0370 - val_loss: 0.0267\n",
      "Epoch 185/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0275\n",
      "Epoch 186/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0283\n",
      "Epoch 187/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0373 - val_loss: 0.0284\n",
      "Epoch 188/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0258\n",
      "Epoch 189/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0256\n",
      "Epoch 190/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0376 - val_loss: 0.0275\n",
      "Epoch 191/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0370 - val_loss: 0.0266\n",
      "Epoch 192/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0372 - val_loss: 0.0276\n",
      "Epoch 193/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0276\n",
      "Epoch 194/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0261\n",
      "Epoch 195/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0374 - val_loss: 0.0258\n",
      "Epoch 196/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 197/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0283\n",
      "Epoch 198/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0370 - val_loss: 0.0276\n",
      "Epoch 199/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0281\n",
      "Epoch 200/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0373 - val_loss: 0.0260\n",
      "Epoch 201/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 202/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 203/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0277\n",
      "Epoch 204/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0372 - val_loss: 0.0261\n",
      "Epoch 205/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0264\n",
      "Epoch 206/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0367 - val_loss: 0.0283\n",
      "Epoch 207/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0373 - val_loss: 0.0299\n",
      "Epoch 208/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0375 - val_loss: 0.0266\n",
      "Epoch 209/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0258\n",
      "Epoch 210/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0372 - val_loss: 0.0258\n",
      "Epoch 211/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 212/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0285\n",
      "Epoch 213/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0281\n",
      "Epoch 214/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0264\n",
      "Epoch 215/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0371 - val_loss: 0.0259\n",
      "Epoch 216/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0264\n",
      "Epoch 217/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0272\n",
      "Epoch 218/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 219/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0276\n",
      "Epoch 220/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 221/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0261\n",
      "Epoch 222/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0370 - val_loss: 0.0263\n",
      "Epoch 223/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0263\n",
      "Epoch 224/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0277\n",
      "Epoch 225/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0278\n",
      "Epoch 226/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 227/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 228/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0274\n",
      "Epoch 229/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 230/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0371 - val_loss: 0.0279\n",
      "Epoch 231/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 232/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0267\n",
      "Epoch 233/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0260\n",
      "Epoch 234/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0370 - val_loss: 0.0267\n",
      "Epoch 235/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0373 - val_loss: 0.0263\n",
      "Epoch 236/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0367 - val_loss: 0.0281\n",
      "Epoch 237/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0283\n",
      "Epoch 238/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0285\n",
      "Epoch 239/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0274\n",
      "Epoch 240/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0263\n",
      "Epoch 241/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0371 - val_loss: 0.0260\n",
      "Epoch 242/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 243/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0287\n",
      "Epoch 244/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0277\n",
      "Epoch 245/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 246/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0370 - val_loss: 0.0268\n",
      "Epoch 247/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0278\n",
      "Epoch 248/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 249/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0369 - val_loss: 0.0261\n",
      "Epoch 250/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0370 - val_loss: 0.0265\n",
      "Epoch 251/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0374 - val_loss: 0.0281\n",
      "Epoch 252/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0370 - val_loss: 0.0265\n",
      "Epoch 253/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0368 - val_loss: 0.0264\n",
      "Epoch 254/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0263\n",
      "Epoch 255/1000\n",
      "143/143 [==============================] - 0s 130us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 256/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0370 - val_loss: 0.0283\n",
      "Epoch 257/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0371 - val_loss: 0.0268\n",
      "Epoch 258/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0371 - val_loss: 0.0264\n",
      "Epoch 259/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0367 - val_loss: 0.0285\n",
      "Epoch 260/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0372 - val_loss: 0.0289\n",
      "Epoch 261/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0270\n",
      "Epoch 262/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0262\n",
      "Epoch 263/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 264/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0268\n",
      "Epoch 265/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 266/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0280\n",
      "Epoch 267/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 268/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 269/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 270/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 271/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 272/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 273/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0261\n",
      "Epoch 274/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 275/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0279\n",
      "Epoch 276/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 277/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 278/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0270\n",
      "Epoch 279/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 280/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0260\n",
      "Epoch 281/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 282/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 283/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0265\n",
      "Epoch 284/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 285/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 286/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0263\n",
      "Epoch 287/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 288/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 289/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 290/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 291/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0274\n",
      "Epoch 292/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 293/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0263\n",
      "Epoch 294/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 295/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0280\n",
      "Epoch 296/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0274\n",
      "Epoch 297/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 298/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0371 - val_loss: 0.0262\n",
      "Epoch 299/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 300/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0283\n",
      "Epoch 301/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 302/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0260\n",
      "Epoch 303/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0263\n",
      "Epoch 304/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 305/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0275\n",
      "Epoch 306/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0268\n",
      "Epoch 307/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0261\n",
      "Epoch 308/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0371 - val_loss: 0.0260\n",
      "Epoch 309/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0279\n",
      "Epoch 310/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0280\n",
      "Epoch 311/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 312/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 313/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0367 - val_loss: 0.0263\n",
      "Epoch 314/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0260\n",
      "Epoch 315/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0370 - val_loss: 0.0260\n",
      "Epoch 316/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0271\n",
      "Epoch 317/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 318/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 319/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0262\n",
      "Epoch 320/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0263\n",
      "Epoch 321/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 322/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0371 - val_loss: 0.0289\n",
      "Epoch 323/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0270\n",
      "Epoch 324/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 325/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0263\n",
      "Epoch 326/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0276\n",
      "Epoch 327/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0369 - val_loss: 0.0278\n",
      "Epoch 328/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 329/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 330/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 331/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0263\n",
      "Epoch 332/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0373 - val_loss: 0.0284\n",
      "Epoch 333/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0277\n",
      "Epoch 334/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0373 - val_loss: 0.0260\n",
      "Epoch 335/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0268\n",
      "Epoch 336/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 337/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 338/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0275\n",
      "Epoch 339/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0274\n",
      "Epoch 340/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0277\n",
      "Epoch 341/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 342/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0370 - val_loss: 0.0261\n",
      "Epoch 343/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 344/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 345/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0281\n",
      "Epoch 346/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0276\n",
      "Epoch 347/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 348/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 349/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0372 - val_loss: 0.0260\n",
      "Epoch 350/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0367 - val_loss: 0.0274\n",
      "Epoch 351/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0372 - val_loss: 0.0294\n",
      "Epoch 352/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0279\n",
      "Epoch 353/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0259\n",
      "Epoch 354/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0380 - val_loss: 0.0252\n",
      "Epoch 355/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0372 - val_loss: 0.0268\n",
      "Epoch 356/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0283\n",
      "Epoch 357/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0276\n",
      "Epoch 358/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 359/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0367 - val_loss: 0.0260\n",
      "Epoch 360/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0260\n",
      "Epoch 361/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0263\n",
      "Epoch 362/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0368 - val_loss: 0.0280\n",
      "Epoch 363/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0370 - val_loss: 0.0285\n",
      "Epoch 364/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 365/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0370 - val_loss: 0.0258\n",
      "Epoch 366/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0262\n",
      "Epoch 367/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 368/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 369/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 370/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 371/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0371 - val_loss: 0.0271\n",
      "Epoch 372/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0260\n",
      "Epoch 373/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0262\n",
      "Epoch 374/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0271\n",
      "Epoch 375/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 376/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0285\n",
      "Epoch 377/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0276\n",
      "Epoch 378/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0370 - val_loss: 0.0268\n",
      "Epoch 379/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 380/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0368 - val_loss: 0.0280\n",
      "Epoch 381/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0277\n",
      "Epoch 382/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0266\n",
      "Epoch 383/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 384/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 385/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 386/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 387/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 388/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0274\n",
      "Epoch 389/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0278\n",
      "Epoch 390/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0371 - val_loss: 0.0267\n",
      "Epoch 391/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 392/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0370 - val_loss: 0.0266\n",
      "Epoch 393/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 394/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 395/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 396/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0277\n",
      "Epoch 397/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0278\n",
      "Epoch 398/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0278\n",
      "Epoch 399/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 400/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0262\n",
      "Epoch 401/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0263\n",
      "Epoch 402/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 403/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0268\n",
      "Epoch 404/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0274\n",
      "Epoch 405/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0268\n",
      "Epoch 406/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0276\n",
      "Epoch 407/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0278\n",
      "Epoch 408/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0371 - val_loss: 0.0284\n",
      "Epoch 409/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0371 - val_loss: 0.0269\n",
      "Epoch 410/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 411/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0372 - val_loss: 0.0259\n",
      "Epoch 412/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 413/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0367 - val_loss: 0.0284\n",
      "Epoch 414/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0371 - val_loss: 0.0286\n",
      "Epoch 415/1000\n",
      "143/143 [==============================] - 0s 181us/step - loss: 0.0370 - val_loss: 0.0276\n",
      "Epoch 416/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 417/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0262\n",
      "Epoch 418/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0259\n",
      "Epoch 419/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0370 - val_loss: 0.0259\n",
      "Epoch 420/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 421/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 422/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 423/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 424/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0264\n",
      "Epoch 425/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0261\n",
      "Epoch 426/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0263\n",
      "Epoch 427/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 428/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0367 - val_loss: 0.0276\n",
      "Epoch 429/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0290\n",
      "Epoch 430/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0281\n",
      "Epoch 431/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0367 - val_loss: 0.0266\n",
      "Epoch 432/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0260\n",
      "Epoch 433/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0262\n",
      "Epoch 434/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0372 - val_loss: 0.0272\n",
      "Epoch 435/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 436/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 437/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0278\n",
      "Epoch 438/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0280\n",
      "Epoch 439/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 440/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 441/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0372 - val_loss: 0.0260\n",
      "Epoch 442/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0370 - val_loss: 0.0266\n",
      "Epoch 443/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 444/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0266\n",
      "Epoch 445/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0276\n",
      "Epoch 446/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0286\n",
      "Epoch 447/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0279\n",
      "Epoch 448/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0367 - val_loss: 0.0265\n",
      "Epoch 449/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0373 - val_loss: 0.0256\n",
      "Epoch 450/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0371 - val_loss: 0.0262\n",
      "Epoch 451/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 452/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0280\n",
      "Epoch 453/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0278\n",
      "Epoch 454/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 123us/step - loss: 0.0369 - val_loss: 0.0268\n",
      "Epoch 455/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0262\n",
      "Epoch 456/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0372 - val_loss: 0.0257\n",
      "Epoch 457/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0371 - val_loss: 0.0259\n",
      "Epoch 458/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 459/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0275\n",
      "Epoch 460/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0287\n",
      "Epoch 461/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0278\n",
      "Epoch 462/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 463/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 464/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 465/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0372 - val_loss: 0.0280\n",
      "Epoch 466/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0270\n",
      "Epoch 467/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 468/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 469/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 470/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 471/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 472/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 473/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 474/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 475/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 476/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 477/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0283\n",
      "Epoch 478/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0281\n",
      "Epoch 479/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 480/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 481/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0263\n",
      "Epoch 482/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 483/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0371 - val_loss: 0.0282\n",
      "Epoch 484/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 485/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0373 - val_loss: 0.0262\n",
      "Epoch 486/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0268\n",
      "Epoch 487/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0368 - val_loss: 0.0275\n",
      "Epoch 488/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0369 - val_loss: 0.0283\n",
      "Epoch 489/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0276\n",
      "Epoch 490/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 491/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 492/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 493/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 494/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 495/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 496/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 497/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0276\n",
      "Epoch 498/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0278\n",
      "Epoch 499/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 500/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0260\n",
      "Epoch 501/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0262\n",
      "Epoch 502/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0279\n",
      "Epoch 503/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0286\n",
      "Epoch 504/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0370 - val_loss: 0.0278\n",
      "Epoch 505/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 506/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 507/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 508/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0281\n",
      "Epoch 509/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0283\n",
      "Epoch 510/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 511/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 512/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 513/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 514/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 515/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 516/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 517/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 518/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 519/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0276\n",
      "Epoch 520/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 521/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 522/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 523/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0271\n",
      "Epoch 524/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 525/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 526/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 527/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 528/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0371 - val_loss: 0.0266\n",
      "Epoch 529/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 530/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 531/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0275\n",
      "Epoch 532/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 533/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 534/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 535/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 536/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0268\n",
      "Epoch 537/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 538/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0371 - val_loss: 0.0286\n",
      "Epoch 539/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0277\n",
      "Epoch 540/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0367 - val_loss: 0.0263\n",
      "Epoch 541/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0258\n",
      "Epoch 542/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0259\n",
      "Epoch 543/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 544/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0367 - val_loss: 0.0275\n",
      "Epoch 545/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0279\n",
      "Epoch 546/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0280\n",
      "Epoch 547/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 548/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0261\n",
      "Epoch 549/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0260\n",
      "Epoch 550/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0263\n",
      "Epoch 551/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 552/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0276\n",
      "Epoch 553/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0274\n",
      "Epoch 554/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0276\n",
      "Epoch 555/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 556/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 557/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 558/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0271\n",
      "Epoch 559/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 560/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 561/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0270\n",
      "Epoch 562/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 563/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0274\n",
      "Epoch 564/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 565/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 566/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 567/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0263\n",
      "Epoch 568/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 569/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 570/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0275\n",
      "Epoch 571/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 572/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 573/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0263\n",
      "Epoch 574/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0370 - val_loss: 0.0266\n",
      "Epoch 575/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 576/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 577/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0279\n",
      "Epoch 578/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0370 - val_loss: 0.0281\n",
      "Epoch 579/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 580/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 581/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0264\n",
      "Epoch 582/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0263\n",
      "Epoch 583/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 584/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0280\n",
      "Epoch 585/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0278\n",
      "Epoch 586/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 587/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 588/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0262\n",
      "Epoch 589/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0370 - val_loss: 0.0261\n",
      "Epoch 590/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 591/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 592/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0270\n",
      "Epoch 593/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 594/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0276\n",
      "Epoch 595/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0278\n",
      "Epoch 596/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0275\n",
      "Epoch 597/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 598/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 599/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 600/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 601/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0275\n",
      "Epoch 602/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0274\n",
      "Epoch 603/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 604/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0370 - val_loss: 0.0262\n",
      "Epoch 605/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0268\n",
      "Epoch 606/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 607/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0275\n",
      "Epoch 608/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0277\n",
      "Epoch 609/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0283\n",
      "Epoch 610/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0279\n",
      "Epoch 611/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0370 - val_loss: 0.0268\n",
      "Epoch 612/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 613/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 614/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 615/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 616/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 617/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 618/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 619/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0280\n",
      "Epoch 620/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0274\n",
      "Epoch 621/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0277\n",
      "Epoch 622/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 623/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0264\n",
      "Epoch 624/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0261\n",
      "Epoch 625/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0261\n",
      "Epoch 626/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0270\n",
      "Epoch 627/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 628/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 629/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 630/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 631/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 632/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 633/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0274\n",
      "Epoch 634/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0268\n",
      "Epoch 635/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 636/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 637/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 638/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0277\n",
      "Epoch 639/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.038 - 0s 119us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 640/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 641/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0263\n",
      "Epoch 642/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 643/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0275\n",
      "Epoch 644/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0277\n",
      "Epoch 645/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 646/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 647/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 648/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 649/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0370 - val_loss: 0.0276\n",
      "Epoch 650/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 651/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0369 - val_loss: 0.0263\n",
      "Epoch 652/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0271\n",
      "Epoch 653/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 654/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 655/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 656/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0276\n",
      "Epoch 657/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 658/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 659/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 660/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 661/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 662/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 663/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0279\n",
      "Epoch 664/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 665/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0368 - val_loss: 0.0260\n",
      "Epoch 666/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0260\n",
      "Epoch 667/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 668/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0367 - val_loss: 0.0275\n",
      "Epoch 669/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0283\n",
      "Epoch 670/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0369 - val_loss: 0.0283\n",
      "Epoch 671/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0276\n",
      "Epoch 672/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0276\n",
      "Epoch 673/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 674/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 675/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 676/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 677/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 678/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 679/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0276\n",
      "Epoch 680/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 681/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 682/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0265\n",
      "Epoch 683/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 684/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0278\n",
      "Epoch 685/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0282\n",
      "Epoch 686/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0274\n",
      "Epoch 687/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 688/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0263\n",
      "Epoch 689/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 690/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0279\n",
      "Epoch 691/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0278\n",
      "Epoch 692/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 693/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 694/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 695/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 696/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 697/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 698/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0275\n",
      "Epoch 699/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 700/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 701/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 702/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 703/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 704/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 705/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 706/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0268\n",
      "Epoch 707/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 708/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 709/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0367 - val_loss: 0.0265\n",
      "Epoch 710/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0371 - val_loss: 0.0258\n",
      "Epoch 711/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0263\n",
      "Epoch 712/1000\n",
      "143/143 [==============================] - 0s 131us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 713/1000\n",
      "143/143 [==============================] - 0s 127us/step - loss: 0.0368 - val_loss: 0.0279\n",
      "Epoch 714/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0282\n",
      "Epoch 715/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0278\n",
      "Epoch 716/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 717/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 718/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0264\n",
      "Epoch 719/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 720/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 721/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0369 - val_loss: 0.0280\n",
      "Epoch 722/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0279\n",
      "Epoch 723/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 724/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0262\n",
      "Epoch 725/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0263\n",
      "Epoch 726/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 727/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0371 - val_loss: 0.0277\n",
      "Epoch 728/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 729/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 730/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0270\n",
      "Epoch 731/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 732/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 733/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0277\n",
      "Epoch 734/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0371 - val_loss: 0.0282\n",
      "Epoch 735/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 736/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0367 - val_loss: 0.0264\n",
      "Epoch 737/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0369 - val_loss: 0.0261\n",
      "Epoch 738/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 739/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 740/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 741/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 742/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 743/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0368 - val_loss: 0.0275\n",
      "Epoch 744/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0277\n",
      "Epoch 745/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0281\n",
      "Epoch 746/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0369 - val_loss: 0.0280\n",
      "Epoch 747/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 748/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 749/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 750/1000\n",
      "143/143 [==============================] - 0s 128us/step - loss: 0.0368 - val_loss: 0.0260\n",
      "Epoch 751/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0369 - val_loss: 0.0263\n",
      "Epoch 752/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0271\n",
      "Epoch 753/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 754/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 755/1000\n",
      "143/143 [==============================] - 0s 127us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 756/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 757/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0282\n",
      "Epoch 758/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0281\n",
      "Epoch 759/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0280\n",
      "Epoch 760/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 761/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 762/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 763/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0268\n",
      "Epoch 764/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 765/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0274\n",
      "Epoch 766/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 767/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 768/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 769/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 770/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 771/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 772/1000\n",
      "143/143 [==============================] - 0s 129us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 773/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 774/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 775/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 776/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0276\n",
      "Epoch 777/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 778/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 779/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 780/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 781/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0264\n",
      "Epoch 782/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 783/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 784/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 785/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 786/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 787/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 788/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 789/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 790/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 791/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 792/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 793/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 794/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0263\n",
      "Epoch 795/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 796/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 797/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0276\n",
      "Epoch 798/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0368 - val_loss: 0.0275\n",
      "Epoch 799/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 800/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 801/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0271\n",
      "Epoch 802/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0367 - val_loss: 0.0264\n",
      "Epoch 803/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0260\n",
      "Epoch 804/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 805/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0276\n",
      "Epoch 806/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0372 - val_loss: 0.0282\n",
      "Epoch 807/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 808/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 809/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0263\n",
      "Epoch 810/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0369 - val_loss: 0.0262\n",
      "Epoch 811/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 812/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0369 - val_loss: 0.0274\n",
      "Epoch 813/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 814/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 815/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0276\n",
      "Epoch 816/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0275\n",
      "Epoch 817/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 818/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 819/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 820/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 821/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 822/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 823/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 824/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0369 - val_loss: 0.0268\n",
      "Epoch 825/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 826/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 827/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0268\n",
      "Epoch 828/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 829/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 830/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 831/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 832/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 833/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 834/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 835/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 836/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 837/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0277\n",
      "Epoch 838/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 839/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 118us/step - loss: 0.0367 - val_loss: 0.0268\n",
      "Epoch 840/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0260\n",
      "Epoch 841/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0370 - val_loss: 0.0262\n",
      "Epoch 842/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0369 - val_loss: 0.0270\n",
      "Epoch 843/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0277\n",
      "Epoch 844/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0368 - val_loss: 0.0277\n",
      "Epoch 845/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 846/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0367 - val_loss: 0.0263\n",
      "Epoch 847/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0259\n",
      "Epoch 848/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0371 - val_loss: 0.0257\n",
      "Epoch 849/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0371 - val_loss: 0.0266\n",
      "Epoch 850/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 851/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0281\n",
      "Epoch 852/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 853/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 854/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 855/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0263\n",
      "Epoch 856/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 857/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0274\n",
      "Epoch 858/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0368 - val_loss: 0.0275\n",
      "Epoch 859/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 860/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 861/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0264\n",
      "Epoch 862/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 863/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0271\n",
      "Epoch 864/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 865/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 866/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0270\n",
      "Epoch 867/1000\n",
      "143/143 [==============================] - 0s 127us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 868/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0369 - val_loss: 0.0278\n",
      "Epoch 869/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0270\n",
      "Epoch 870/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 871/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 872/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0368 - val_loss: 0.0276\n",
      "Epoch 873/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0277\n",
      "Epoch 874/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 875/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 876/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 877/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0263\n",
      "Epoch 878/1000\n",
      "143/143 [==============================] - 0s 131us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 879/1000\n",
      "143/143 [==============================] - 0s 128us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 880/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0278\n",
      "Epoch 881/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0279\n",
      "Epoch 882/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 883/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0264\n",
      "Epoch 884/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0262\n",
      "Epoch 885/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 886/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 887/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 888/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0268\n",
      "Epoch 889/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 890/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 891/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 892/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0262\n",
      "Epoch 893/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 894/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0370 - val_loss: 0.0264\n",
      "Epoch 895/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0278\n",
      "Epoch 896/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0370 - val_loss: 0.0280\n",
      "Epoch 897/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0369 - val_loss: 0.0270\n",
      "Epoch 898/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0271\n",
      "Epoch 899/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 900/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0264\n",
      "Epoch 901/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 902/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 903/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0371 - val_loss: 0.0279\n",
      "Epoch 904/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 905/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 906/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 907/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0263\n",
      "Epoch 908/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 909/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 910/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0283\n",
      "Epoch 911/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0281\n",
      "Epoch 912/1000\n",
      "143/143 [==============================] - 0s 181us/step - loss: 0.0370 - val_loss: 0.0272\n",
      "Epoch 913/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 914/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0369 - val_loss: 0.0278\n",
      "Epoch 915/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 916/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 146us/step - loss: 0.0369 - val_loss: 0.0270\n",
      "Epoch 917/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 918/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 919/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 920/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 921/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 922/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 923/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 924/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 925/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 926/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 927/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 928/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0278\n",
      "Epoch 929/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0281\n",
      "Epoch 930/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0278\n",
      "Epoch 931/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0274\n",
      "Epoch 932/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 933/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0277\n",
      "Epoch 934/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0276\n",
      "Epoch 935/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 936/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 937/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 938/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 939/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 940/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 941/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 942/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 943/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 944/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 945/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 946/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 947/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 948/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 949/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 950/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 951/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 952/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 953/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 954/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 955/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 956/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 957/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 958/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 959/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 960/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 961/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 962/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0277\n",
      "Epoch 963/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 964/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 965/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0279\n",
      "Epoch 966/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 967/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 968/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0262\n",
      "Epoch 969/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 970/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 971/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 972/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 973/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 974/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 975/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 976/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 977/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 978/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 979/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 980/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 981/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0278\n",
      "Epoch 982/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0277\n",
      "Epoch 983/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0274\n",
      "Epoch 984/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0280\n",
      "Epoch 985/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 986/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0263\n",
      "Epoch 987/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 988/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0270\n",
      "Epoch 989/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 990/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 991/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 992/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 993/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 109us/step - loss: 0.0369 - val_loss: 0.0279\n",
      "Epoch 994/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 995/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 996/1000\n",
      "143/143 [==============================] - 0s 127us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 997/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 998/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 999/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 1000/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0277\n",
      "0.05466809496283531\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.7362302 , -0.34700462, -0.21741125,  0.10767622,  0.1187201 ],\n",
       "        [ 0.15514073, -0.13727006, -0.36625674, -0.7738427 , -0.24979556],\n",
       "        [-0.16641387, -0.787171  ,  0.07648029, -0.7710066 , -0.3812341 ],\n",
       "        [-0.27433494,  0.09526598, -0.12003659,  0.4616266 , -0.10050523],\n",
       "        [-0.2565565 ,  0.12006301, -0.4283556 , -0.6810467 , -0.74825037],\n",
       "        [-0.53693134, -0.1402363 , -0.5823151 , -0.22366117, -0.7371609 ],\n",
       "        [-0.02991432,  0.03270359, -0.5839709 , -0.37584418, -0.33775702],\n",
       "        [-0.7393341 , -0.7265014 ,  0.09733699, -0.1441744 , -0.04916781],\n",
       "        [ 0.04535153, -0.48583838, -0.7888207 , -0.48617864, -0.34668413],\n",
       "        [ 0.07686548, -0.6614542 ,  0.02235546, -0.27742395, -0.23424542],\n",
       "        [-0.38731056, -0.5159101 , -0.15201674, -0.54715705, -0.11502233],\n",
       "        [-0.6899172 ,  0.15163928, -0.61180955, -0.37086022, -0.07552928],\n",
       "        [-0.77343833, -0.11249179, -0.34697387,  0.06881394, -0.6452153 ],\n",
       "        [-0.76510584, -0.16197503, -0.19070327, -0.00103318, -0.6140017 ],\n",
       "        [-0.00741755, -0.60809016, -0.5041945 , -0.20966966, -0.42468402],\n",
       "        [-0.01825639, -0.22563924, -0.12966329, -0.4950713 , -0.07754361],\n",
       "        [-0.02866968, -0.5854454 , -0.09239982, -0.24684235, -0.78709674],\n",
       "        [-0.5625651 , -0.5571109 ,  0.07769746, -0.00098978,  0.0341692 ],\n",
       "        [-0.6280284 , -0.5159295 , -0.23663819, -0.8833488 ,  0.0041505 ],\n",
       "        [-0.46750665, -0.4480425 , -0.44069424, -0.01292848, -0.3365215 ],\n",
       "        [-0.35620752, -0.6398707 , -0.8022563 , -0.11058886, -0.51202065],\n",
       "        [-0.4720449 , -0.00488874, -0.65370977, -0.34197313, -0.286917  ]],\n",
       "       dtype=float32),\n",
       " array([-0.3149807 , -0.31754157, -0.34827152, -0.2901135 , -0.35232976],\n",
       "       dtype=float32),\n",
       " array([[ 0.36544916,  0.6331516 , -0.0080055 ,  0.45905223, -0.30511343,\n",
       "         -0.11061001,  0.32791057, -0.7373376 ,  0.37944365, -0.07369772],\n",
       "        [ 0.06283241,  0.8217967 ,  0.12871166,  0.65477324, -0.77070105,\n",
       "         -0.05900415, -0.22644612, -0.533373  ,  0.8986646 ,  0.2208065 ],\n",
       "        [ 0.16712487,  0.664445  ,  0.5092403 , -0.08410829, -0.8832765 ,\n",
       "          0.9204989 ,  0.06670164,  0.07287564, -0.25228545, -0.12186079],\n",
       "        [ 0.21050452,  0.39265463, -0.1155966 ,  0.3988845 ,  0.6640692 ,\n",
       "         -0.10466906,  0.31885418,  0.4995033 ,  0.9908213 , -0.03379717],\n",
       "        [ 0.11862668,  0.6476521 ,  0.8666305 , -0.18172787, -0.85243875,\n",
       "          0.5752024 , -0.23707241,  0.02105694,  0.07826453,  0.10156241]],\n",
       "       dtype=float32),\n",
       " array([-2.9706788e-36, -3.7159697e-30,  3.6572614e-35, -1.3146332e-32,\n",
       "        -7.8219431e-04,  1.6120053e-03,  7.4279034e-25,  6.7236348e-27,\n",
       "        -4.8762841e-32,  1.7208374e-31], dtype=float32),\n",
       " array([[ 2.09303212e-35],\n",
       "        [-5.83498243e-30],\n",
       "        [ 1.37014456e-35],\n",
       "        [-1.20642425e-32],\n",
       "        [-2.46157194e-03],\n",
       "        [ 5.11369575e-03],\n",
       "        [ 8.60697242e-25],\n",
       "        [ 8.35701987e-27],\n",
       "        [ 2.10980124e-31],\n",
       "        [ 1.83075487e-31]], dtype=float32),\n",
       " array([0.21434058], dtype=float32)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_automobile, history_automobile, evaluate_automobile=NN_model_structure_regression_tanh(X_train_automobile, X_val_automobile, Y_train_automobile, Y_val_automobile, adam2, 32, 1000, x_test_automobile, y_test_automobile)\n",
    "model_automobile.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_automobile.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_automobile_tanh_4th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_37 (Dense)             (None, 5)                 20        \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 91\n",
      "Trainable params: 91\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 32 samples, validate on 7 samples\n",
      "Epoch 1/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 37.9589 - val_loss: 30.9343\n",
      "Epoch 2/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 34.6051 - val_loss: 28.8673\n",
      "Epoch 3/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 30.8466 - val_loss: 25.9429\n",
      "Epoch 4/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 26.4639 - val_loss: 21.8582\n",
      "Epoch 5/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 21.2937 - val_loss: 16.5346\n",
      "Epoch 6/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 15.5186 - val_loss: 10.3104\n",
      "Epoch 7/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.5483 - val_loss: 4.2767\n",
      "Epoch 8/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2392 - val_loss: 0.5524\n",
      "Epoch 9/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2499 - val_loss: 1.4233\n",
      "Epoch 10/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.1298 - val_loss: 4.4106\n",
      "Epoch 11/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6594 - val_loss: 4.6611\n",
      "Epoch 12/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.3642 - val_loss: 2.7709\n",
      "Epoch 13/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2340 - val_loss: 1.2804\n",
      "Epoch 14/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 2.6132 - val_loss: 1.1815\n",
      "Epoch 15/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5986 - val_loss: 1.9169\n",
      "Epoch 16/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.3586 - val_loss: 2.5680\n",
      "Epoch 17/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4462 - val_loss: 2.7013\n",
      "Epoch 18/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4827 - val_loss: 2.3371\n",
      "Epoch 19/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.3429 - val_loss: 1.6851\n",
      "Epoch 20/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.0565 - val_loss: 0.9874\n",
      "Epoch 21/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.7181 - val_loss: 0.4420\n",
      "Epoch 22/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.4342 - val_loss: 0.1605\n",
      "Epoch 23/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.2831 - val_loss: 0.1460\n",
      "Epoch 24/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.2818 - val_loss: 0.3026\n",
      "Epoch 25/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.3778 - val_loss: 0.4866\n",
      "Epoch 26/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.4786 - val_loss: 0.5833\n",
      "Epoch 27/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.5090 - val_loss: 0.5571\n",
      "Epoch 28/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.4510 - val_loss: 0.4450\n",
      "Epoch 29/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.3411 - val_loss: 0.3147\n",
      "Epoch 30/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.2356 - val_loss: 0.2211\n",
      "Epoch 31/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1762 - val_loss: 0.1851\n",
      "Epoch 32/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1727 - val_loss: 0.1943\n",
      "Epoch 33/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.2066 - val_loss: 0.2194\n",
      "Epoch 34/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.2469 - val_loss: 0.2324\n",
      "Epoch 35/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.2668 - val_loss: 0.2183\n",
      "Epoch 36/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.2546 - val_loss: 0.1780\n",
      "Epoch 37/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.2140 - val_loss: 0.1238\n",
      "Epoch 38/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1596 - val_loss: 0.0721\n",
      "Epoch 39/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1086 - val_loss: 0.0355\n",
      "Epoch 40/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0738 - val_loss: 0.0188\n",
      "Epoch 41/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0589 - val_loss: 0.0182\n",
      "Epoch 42/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0594 - val_loss: 0.0250\n",
      "Epoch 43/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0659 - val_loss: 0.0308\n",
      "Epoch 44/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0695 - val_loss: 0.0317\n",
      "Epoch 45/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0658 - val_loss: 0.0293\n",
      "Epoch 46/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0559 - val_loss: 0.0280\n",
      "Epoch 47/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0439 - val_loss: 0.0317\n",
      "Epoch 48/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0339 - val_loss: 0.0420\n",
      "Epoch 49/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0285 - val_loss: 0.0572\n",
      "Epoch 50/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0276 - val_loss: 0.0741\n",
      "Epoch 51/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0296 - val_loss: 0.0889\n",
      "Epoch 52/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0325 - val_loss: 0.0992\n",
      "Epoch 53/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0348 - val_loss: 0.1035\n",
      "Epoch 54/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0356 - val_loss: 0.1020\n",
      "Epoch 55/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0346 - val_loss: 0.0958\n",
      "Epoch 56/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0322 - val_loss: 0.0866\n",
      "Epoch 57/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0290 - val_loss: 0.0764\n",
      "Epoch 58/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0256 - val_loss: 0.0669\n",
      "Epoch 59/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0228 - val_loss: 0.0596\n",
      "Epoch 60/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0209 - val_loss: 0.0550\n",
      "Epoch 61/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0201 - val_loss: 0.0533\n",
      "Epoch 62/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0203 - val_loss: 0.0538\n",
      "Epoch 63/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0209 - val_loss: 0.0553\n",
      "Epoch 64/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0213 - val_loss: 0.0566\n",
      "Epoch 65/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0209 - val_loss: 0.0570\n",
      "Epoch 66/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0197 - val_loss: 0.0560\n",
      "Epoch 67/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0179 - val_loss: 0.0540\n",
      "Epoch 68/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0160 - val_loss: 0.0513\n",
      "Epoch 69/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0146 - val_loss: 0.0484\n",
      "Epoch 70/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0140 - val_loss: 0.0454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0140 - val_loss: 0.0425\n",
      "Epoch 72/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0142 - val_loss: 0.0395\n",
      "Epoch 73/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0144 - val_loss: 0.0364\n",
      "Epoch 74/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0141 - val_loss: 0.0331\n",
      "Epoch 75/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0133 - val_loss: 0.0299\n",
      "Epoch 76/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0122 - val_loss: 0.0270\n",
      "Epoch 77/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0111 - val_loss: 0.0247\n",
      "Epoch 78/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0104 - val_loss: 0.0229\n",
      "Epoch 79/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0101 - val_loss: 0.0215\n",
      "Epoch 80/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0101 - val_loss: 0.0203\n",
      "Epoch 81/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0103 - val_loss: 0.0192\n",
      "Epoch 82/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0104 - val_loss: 0.0180\n",
      "Epoch 83/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0103 - val_loss: 0.0167\n",
      "Epoch 84/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0100 - val_loss: 0.0156\n",
      "Epoch 85/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0096 - val_loss: 0.0146\n",
      "Epoch 86/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0092 - val_loss: 0.0139\n",
      "Epoch 87/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0090 - val_loss: 0.0135\n",
      "Epoch 88/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0089 - val_loss: 0.0133\n",
      "Epoch 89/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0088 - val_loss: 0.0133\n",
      "Epoch 90/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0088 - val_loss: 0.0133\n",
      "Epoch 91/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0088 - val_loss: 0.0133\n",
      "Epoch 92/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0087 - val_loss: 0.0132\n",
      "Epoch 93/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0085 - val_loss: 0.0130\n",
      "Epoch 94/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0083 - val_loss: 0.0128\n",
      "Epoch 95/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0081 - val_loss: 0.0125\n",
      "Epoch 96/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0079 - val_loss: 0.0122\n",
      "Epoch 97/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0078 - val_loss: 0.0119\n",
      "Epoch 98/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0077 - val_loss: 0.0115\n",
      "Epoch 99/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0076 - val_loss: 0.0111\n",
      "Epoch 100/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0075 - val_loss: 0.0107\n",
      "Epoch 101/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0074 - val_loss: 0.0104\n",
      "Epoch 102/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0073 - val_loss: 0.0102\n",
      "Epoch 103/1000\n",
      "32/32 [==============================] - 0s 132us/step - loss: 0.0072 - val_loss: 0.0101\n",
      "Epoch 104/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0071 - val_loss: 0.0101\n",
      "Epoch 105/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0070 - val_loss: 0.0102\n",
      "Epoch 106/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0069 - val_loss: 0.0104\n",
      "Epoch 107/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0068 - val_loss: 0.0107\n",
      "Epoch 108/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0067 - val_loss: 0.0109\n",
      "Epoch 109/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0066 - val_loss: 0.0111\n",
      "Epoch 110/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0065 - val_loss: 0.0113\n",
      "Epoch 111/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0064 - val_loss: 0.0113\n",
      "Epoch 112/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0063 - val_loss: 0.0112\n",
      "Epoch 113/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0062 - val_loss: 0.0111\n",
      "Epoch 114/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0061 - val_loss: 0.0108\n",
      "Epoch 115/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0060 - val_loss: 0.0106\n",
      "Epoch 116/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0060 - val_loss: 0.0103\n",
      "Epoch 117/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0059 - val_loss: 0.0100\n",
      "Epoch 118/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0058 - val_loss: 0.0098\n",
      "Epoch 119/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0057 - val_loss: 0.0097\n",
      "Epoch 120/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0057 - val_loss: 0.0096\n",
      "Epoch 121/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0056 - val_loss: 0.0095\n",
      "Epoch 122/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0055 - val_loss: 0.0095\n",
      "Epoch 123/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0054 - val_loss: 0.0096\n",
      "Epoch 124/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0054 - val_loss: 0.0096\n",
      "Epoch 125/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0053 - val_loss: 0.0097\n",
      "Epoch 126/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0052 - val_loss: 0.0097\n",
      "Epoch 127/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0052 - val_loss: 0.0097\n",
      "Epoch 128/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0051 - val_loss: 0.0096\n",
      "Epoch 129/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0050 - val_loss: 0.0095\n",
      "Epoch 130/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0050 - val_loss: 0.0094\n",
      "Epoch 131/1000\n",
      "32/32 [==============================] - 0s 172us/step - loss: 0.0049 - val_loss: 0.0092\n",
      "Epoch 132/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0048 - val_loss: 0.0090\n",
      "Epoch 133/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0048 - val_loss: 0.0088\n",
      "Epoch 134/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0047 - val_loss: 0.0086\n",
      "Epoch 135/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0046 - val_loss: 0.0084\n",
      "Epoch 136/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0046 - val_loss: 0.0083\n",
      "Epoch 137/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0045 - val_loss: 0.0081\n",
      "Epoch 138/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0045 - val_loss: 0.0081\n",
      "Epoch 139/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0044 - val_loss: 0.0080\n",
      "Epoch 140/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0044 - val_loss: 0.0079\n",
      "Epoch 141/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0043 - val_loss: 0.0078\n",
      "Epoch 142/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0042 - val_loss: 0.0078\n",
      "Epoch 143/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0042 - val_loss: 0.0077\n",
      "Epoch 144/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0041 - val_loss: 0.0076\n",
      "Epoch 145/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0041 - val_loss: 0.0075\n",
      "Epoch 146/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0040 - val_loss: 0.0074\n",
      "Epoch 147/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0040 - val_loss: 0.0073\n",
      "Epoch 148/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0039 - val_loss: 0.0071\n",
      "Epoch 149/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0039 - val_loss: 0.0070\n",
      "Epoch 150/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0038 - val_loss: 0.0069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0038 - val_loss: 0.0068\n",
      "Epoch 152/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0037 - val_loss: 0.0067\n",
      "Epoch 153/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0037 - val_loss: 0.0066\n",
      "Epoch 154/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0037 - val_loss: 0.0065\n",
      "Epoch 155/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0036 - val_loss: 0.0064\n",
      "Epoch 156/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0036 - val_loss: 0.0063\n",
      "Epoch 157/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0035 - val_loss: 0.0062\n",
      "Epoch 158/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0035 - val_loss: 0.0062\n",
      "Epoch 159/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0034 - val_loss: 0.0061\n",
      "Epoch 160/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0034 - val_loss: 0.0060\n",
      "Epoch 161/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0034 - val_loss: 0.0059\n",
      "Epoch 162/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 0.0059\n",
      "Epoch 163/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 0.0058\n",
      "Epoch 164/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0032 - val_loss: 0.0057\n",
      "Epoch 165/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0032 - val_loss: 0.0057\n",
      "Epoch 166/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0032 - val_loss: 0.0056\n",
      "Epoch 167/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0031 - val_loss: 0.0055\n",
      "Epoch 168/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0031 - val_loss: 0.0055\n",
      "Epoch 169/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0031 - val_loss: 0.0054\n",
      "Epoch 170/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0030 - val_loss: 0.0053\n",
      "Epoch 171/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 0.0053\n",
      "Epoch 172/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 0.0052\n",
      "Epoch 173/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0029 - val_loss: 0.0052\n",
      "Epoch 174/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0029 - val_loss: 0.0051\n",
      "Epoch 175/1000\n",
      "32/32 [==============================] - 0s 132us/step - loss: 0.0029 - val_loss: 0.0050\n",
      "Epoch 176/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0028 - val_loss: 0.0050\n",
      "Epoch 177/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0028 - val_loss: 0.0049\n",
      "Epoch 178/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0028 - val_loss: 0.0049\n",
      "Epoch 179/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0027 - val_loss: 0.0048\n",
      "Epoch 180/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0027 - val_loss: 0.0048\n",
      "Epoch 181/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0027 - val_loss: 0.0047\n",
      "Epoch 182/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0026 - val_loss: 0.0047\n",
      "Epoch 183/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 0.0046\n",
      "Epoch 184/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0026 - val_loss: 0.0046\n",
      "Epoch 185/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 0.0046\n",
      "Epoch 186/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 0.0045\n",
      "Epoch 187/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0025 - val_loss: 0.0045\n",
      "Epoch 188/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0025 - val_loss: 0.0044\n",
      "Epoch 189/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.0044\n",
      "Epoch 190/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.0043\n",
      "Epoch 191/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.0043\n",
      "Epoch 192/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0024 - val_loss: 0.0042\n",
      "Epoch 193/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0023 - val_loss: 0.0042\n",
      "Epoch 194/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.0042\n",
      "Epoch 195/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.0041\n",
      "Epoch 196/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0023 - val_loss: 0.0041\n",
      "Epoch 197/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.0041\n",
      "Epoch 198/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0040\n",
      "Epoch 199/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0040\n",
      "Epoch 200/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0039\n",
      "Epoch 201/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0022 - val_loss: 0.0039\n",
      "Epoch 202/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0021 - val_loss: 0.0039\n",
      "Epoch 203/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0038\n",
      "Epoch 204/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0038\n",
      "Epoch 205/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0021 - val_loss: 0.0038\n",
      "Epoch 206/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0021 - val_loss: 0.0037\n",
      "Epoch 207/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0020 - val_loss: 0.0037\n",
      "Epoch 208/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0020 - val_loss: 0.0037\n",
      "Epoch 209/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0020 - val_loss: 0.0036\n",
      "Epoch 210/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0036\n",
      "Epoch 211/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0020 - val_loss: 0.0036\n",
      "Epoch 212/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0020 - val_loss: 0.0035\n",
      "Epoch 213/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0035\n",
      "Epoch 214/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0019 - val_loss: 0.0035\n",
      "Epoch 215/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 0.0035\n",
      "Epoch 216/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0034\n",
      "Epoch 217/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0034\n",
      "Epoch 218/1000\n",
      "32/32 [==============================] - 0s 158us/step - loss: 0.0019 - val_loss: 0.0034\n",
      "Epoch 219/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0033\n",
      "Epoch 220/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0018 - val_loss: 0.0033\n",
      "Epoch 221/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 0.0033\n",
      "Epoch 222/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0033\n",
      "Epoch 223/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0018 - val_loss: 0.0032\n",
      "Epoch 224/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0032\n",
      "Epoch 225/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0018 - val_loss: 0.0032\n",
      "Epoch 226/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 0.0032\n",
      "Epoch 227/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0031\n",
      "Epoch 228/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 0.0031\n",
      "Epoch 229/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 230/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0031\n",
      "Epoch 231/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 0.0030\n",
      "Epoch 232/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0030\n",
      "Epoch 233/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 0.0030\n",
      "Epoch 234/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0030\n",
      "Epoch 235/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 0.0030\n",
      "Epoch 236/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0029\n",
      "Epoch 237/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0029\n",
      "Epoch 238/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 0.0029\n",
      "Epoch 239/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0029\n",
      "Epoch 240/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 241/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 242/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0028\n",
      "Epoch 243/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0015 - val_loss: 0.0028\n",
      "Epoch 244/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0015 - val_loss: 0.0028\n",
      "Epoch 245/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0015 - val_loss: 0.0027\n",
      "Epoch 246/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0027\n",
      "Epoch 247/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0027\n",
      "Epoch 248/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0015 - val_loss: 0.0027\n",
      "Epoch 249/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 0.0027\n",
      "Epoch 250/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0027\n",
      "Epoch 251/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0014 - val_loss: 0.0026\n",
      "Epoch 252/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0026\n",
      "Epoch 253/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0026\n",
      "Epoch 254/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0026\n",
      "Epoch 255/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0026\n",
      "Epoch 256/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0026\n",
      "Epoch 257/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0014 - val_loss: 0.0025\n",
      "Epoch 258/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 0.0025\n",
      "Epoch 259/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0014 - val_loss: 0.0025\n",
      "Epoch 260/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0025\n",
      "Epoch 261/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0014 - val_loss: 0.0025\n",
      "Epoch 262/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 0.0025\n",
      "Epoch 263/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0013 - val_loss: 0.0024\n",
      "Epoch 264/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0024\n",
      "Epoch 265/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0024\n",
      "Epoch 266/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0024\n",
      "Epoch 267/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0024\n",
      "Epoch 268/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0013 - val_loss: 0.0024\n",
      "Epoch 269/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 0.0024\n",
      "Epoch 270/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 0.0023\n",
      "Epoch 271/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0013 - val_loss: 0.0023\n",
      "Epoch 272/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0013 - val_loss: 0.0023\n",
      "Epoch 273/1000\n",
      "32/32 [==============================] - 0s 810us/step - loss: 0.0013 - val_loss: 0.0023\n",
      "Epoch 274/1000\n",
      "32/32 [==============================] - 0s 748us/step - loss: 0.0013 - val_loss: 0.0023\n",
      "Epoch 275/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 0.0023\n",
      "Epoch 276/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 0.0023\n",
      "Epoch 277/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 0.0023\n",
      "Epoch 278/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 279/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 280/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 281/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 282/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 283/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 284/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 285/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 286/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 287/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 288/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 289/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 290/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0021\n",
      "Epoch 291/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0021\n",
      "Epoch 292/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 0.0021\n",
      "Epoch 293/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0021\n",
      "Epoch 294/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0021\n",
      "Epoch 295/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 296/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 297/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 298/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 299/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 300/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 301/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 302/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 303/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 304/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 305/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 306/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 307/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 308/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 0.0019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 309/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0010 - val_loss: 0.0019\n",
      "Epoch 310/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 0.0019\n",
      "Epoch 311/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 0.0019\n",
      "Epoch 312/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0010 - val_loss: 0.0019\n",
      "Epoch 313/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 0.0019\n",
      "Epoch 314/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 0.0019\n",
      "Epoch 315/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 0.0019\n",
      "Epoch 316/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 0.0019\n",
      "Epoch 317/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 0.0018\n",
      "Epoch 318/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.9594e-04 - val_loss: 0.0018\n",
      "Epoch 319/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.9122e-04 - val_loss: 0.0018\n",
      "Epoch 320/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.8653e-04 - val_loss: 0.0018\n",
      "Epoch 321/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.8188e-04 - val_loss: 0.0018\n",
      "Epoch 322/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.7726e-04 - val_loss: 0.0018\n",
      "Epoch 323/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.7269e-04 - val_loss: 0.0018\n",
      "Epoch 324/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.6815e-04 - val_loss: 0.0018\n",
      "Epoch 325/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.6365e-04 - val_loss: 0.0018\n",
      "Epoch 326/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.5918e-04 - val_loss: 0.0018\n",
      "Epoch 327/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.5475e-04 - val_loss: 0.0018\n",
      "Epoch 328/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.5036e-04 - val_loss: 0.0018\n",
      "Epoch 329/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.4599e-04 - val_loss: 0.0017\n",
      "Epoch 330/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4167e-04 - val_loss: 0.0017\n",
      "Epoch 331/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.3737e-04 - val_loss: 0.0017\n",
      "Epoch 332/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.3310e-04 - val_loss: 0.0017\n",
      "Epoch 333/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.2887e-04 - val_loss: 0.0017\n",
      "Epoch 334/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.2467e-04 - val_loss: 0.0017\n",
      "Epoch 335/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.2050e-04 - val_loss: 0.0017\n",
      "Epoch 336/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.1636e-04 - val_loss: 0.0017\n",
      "Epoch 337/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1225e-04 - val_loss: 0.0017\n",
      "Epoch 338/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.0818e-04 - val_loss: 0.0017\n",
      "Epoch 339/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 9.0413e-04 - val_loss: 0.0017\n",
      "Epoch 340/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.0011e-04 - val_loss: 0.0017\n",
      "Epoch 341/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9611e-04 - val_loss: 0.0017\n",
      "Epoch 342/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9216e-04 - val_loss: 0.0017\n",
      "Epoch 343/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.8822e-04 - val_loss: 0.0016\n",
      "Epoch 344/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.8431e-04 - val_loss: 0.0016\n",
      "Epoch 345/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.8044e-04 - val_loss: 0.0016\n",
      "Epoch 346/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.7659e-04 - val_loss: 0.0016\n",
      "Epoch 347/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.7276e-04 - val_loss: 0.0016\n",
      "Epoch 348/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.6897e-04 - val_loss: 0.0016\n",
      "Epoch 349/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.6519e-04 - val_loss: 0.0016\n",
      "Epoch 350/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.6144e-04 - val_loss: 0.0016\n",
      "Epoch 351/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.5772e-04 - val_loss: 0.0016\n",
      "Epoch 352/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.5403e-04 - val_loss: 0.0016\n",
      "Epoch 353/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5036e-04 - val_loss: 0.0016\n",
      "Epoch 354/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.4671e-04 - val_loss: 0.0016\n",
      "Epoch 355/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 8.4308e-04 - val_loss: 0.0016\n",
      "Epoch 356/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.3949e-04 - val_loss: 0.0016\n",
      "Epoch 357/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.3592e-04 - val_loss: 0.0016\n",
      "Epoch 358/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.3236e-04 - val_loss: 0.0015\n",
      "Epoch 359/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2884e-04 - val_loss: 0.0015\n",
      "Epoch 360/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.2533e-04 - val_loss: 0.0015\n",
      "Epoch 361/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.2185e-04 - val_loss: 0.0015\n",
      "Epoch 362/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.1839e-04 - val_loss: 0.0015\n",
      "Epoch 363/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.1495e-04 - val_loss: 0.0015\n",
      "Epoch 364/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.1153e-04 - val_loss: 0.0015\n",
      "Epoch 365/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.0814e-04 - val_loss: 0.0015\n",
      "Epoch 366/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.0477e-04 - val_loss: 0.0015\n",
      "Epoch 367/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.0142e-04 - val_loss: 0.0015\n",
      "Epoch 368/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.9809e-04 - val_loss: 0.0015\n",
      "Epoch 369/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.9478e-04 - val_loss: 0.0015\n",
      "Epoch 370/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.9149e-04 - val_loss: 0.0015\n",
      "Epoch 371/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8822e-04 - val_loss: 0.0015\n",
      "Epoch 372/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8497e-04 - val_loss: 0.0015\n",
      "Epoch 373/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.8174e-04 - val_loss: 0.0015\n",
      "Epoch 374/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.7853e-04 - val_loss: 0.0015\n",
      "Epoch 375/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7534e-04 - val_loss: 0.0014\n",
      "Epoch 376/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.7218e-04 - val_loss: 0.0014\n",
      "Epoch 377/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6902e-04 - val_loss: 0.0014\n",
      "Epoch 378/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 7.6589e-04 - val_loss: 0.0014\n",
      "Epoch 379/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.6278e-04 - val_loss: 0.0014\n",
      "Epoch 380/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5969e-04 - val_loss: 0.0014\n",
      "Epoch 381/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.5661e-04 - val_loss: 0.0014\n",
      "Epoch 382/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5355e-04 - val_loss: 0.0014\n",
      "Epoch 383/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.5051e-04 - val_loss: 0.0014\n",
      "Epoch 384/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.4749e-04 - val_loss: 0.0014\n",
      "Epoch 385/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.4449e-04 - val_loss: 0.0014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 386/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4150e-04 - val_loss: 0.0014\n",
      "Epoch 387/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.3853e-04 - val_loss: 0.0014\n",
      "Epoch 388/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.3558e-04 - val_loss: 0.0014\n",
      "Epoch 389/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3264e-04 - val_loss: 0.0014\n",
      "Epoch 390/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2972e-04 - val_loss: 0.0014\n",
      "Epoch 391/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2682e-04 - val_loss: 0.0014\n",
      "Epoch 392/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.2394e-04 - val_loss: 0.0014\n",
      "Epoch 393/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.2107e-04 - val_loss: 0.0014\n",
      "Epoch 394/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1821e-04 - val_loss: 0.0014\n",
      "Epoch 395/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1538e-04 - val_loss: 0.0013\n",
      "Epoch 396/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.1256e-04 - val_loss: 0.0013\n",
      "Epoch 397/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0975e-04 - val_loss: 0.0013\n",
      "Epoch 398/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0697e-04 - val_loss: 0.0013\n",
      "Epoch 399/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 7.0420e-04 - val_loss: 0.0013\n",
      "Epoch 400/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0144e-04 - val_loss: 0.0013\n",
      "Epoch 401/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9869e-04 - val_loss: 0.0013\n",
      "Epoch 402/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.9597e-04 - val_loss: 0.0013\n",
      "Epoch 403/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9326e-04 - val_loss: 0.0013\n",
      "Epoch 404/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.9056e-04 - val_loss: 0.0013\n",
      "Epoch 405/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.8788e-04 - val_loss: 0.0013\n",
      "Epoch 406/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.8521e-04 - val_loss: 0.0013\n",
      "Epoch 407/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8255e-04 - val_loss: 0.0013\n",
      "Epoch 408/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.7991e-04 - val_loss: 0.0013\n",
      "Epoch 409/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.7729e-04 - val_loss: 0.0013\n",
      "Epoch 410/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.7468e-04 - val_loss: 0.0013\n",
      "Epoch 411/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 6.7209e-04 - val_loss: 0.0013\n",
      "Epoch 412/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6951e-04 - val_loss: 0.0013\n",
      "Epoch 413/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.6694e-04 - val_loss: 0.0013\n",
      "Epoch 414/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.6438e-04 - val_loss: 0.0013\n",
      "Epoch 415/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.6184e-04 - val_loss: 0.0013\n",
      "Epoch 416/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5932e-04 - val_loss: 0.0013\n",
      "Epoch 417/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.5681e-04 - val_loss: 0.0012\n",
      "Epoch 418/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.5430e-04 - val_loss: 0.0012\n",
      "Epoch 419/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.5182e-04 - val_loss: 0.0012\n",
      "Epoch 420/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4933e-04 - val_loss: 0.0012\n",
      "Epoch 421/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4689e-04 - val_loss: 0.0012\n",
      "Epoch 422/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4443e-04 - val_loss: 0.0012\n",
      "Epoch 423/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.4200e-04 - val_loss: 0.0012\n",
      "Epoch 424/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3957e-04 - val_loss: 0.0012\n",
      "Epoch 425/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.3716e-04 - val_loss: 0.0012\n",
      "Epoch 426/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.3477e-04 - val_loss: 0.0012\n",
      "Epoch 427/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.3238e-04 - val_loss: 0.0012\n",
      "Epoch 428/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 6.3001e-04 - val_loss: 0.0012\n",
      "Epoch 429/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.2765e-04 - val_loss: 0.0012\n",
      "Epoch 430/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.2529e-04 - val_loss: 0.0012\n",
      "Epoch 431/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2296e-04 - val_loss: 0.0012\n",
      "Epoch 432/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.2063e-04 - val_loss: 0.0012\n",
      "Epoch 433/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1833e-04 - val_loss: 0.0012\n",
      "Epoch 434/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.1603e-04 - val_loss: 0.0012\n",
      "Epoch 435/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1374e-04 - val_loss: 0.0012\n",
      "Epoch 436/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.1146e-04 - val_loss: 0.0012\n",
      "Epoch 437/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.0920e-04 - val_loss: 0.0012\n",
      "Epoch 438/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.0694e-04 - val_loss: 0.0012\n",
      "Epoch 439/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.0469e-04 - val_loss: 0.0012\n",
      "Epoch 440/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 6.0247e-04 - val_loss: 0.0012\n",
      "Epoch 441/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0024e-04 - val_loss: 0.0012\n",
      "Epoch 442/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9803e-04 - val_loss: 0.0011\n",
      "Epoch 443/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.9584e-04 - val_loss: 0.0011\n",
      "Epoch 444/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9365e-04 - val_loss: 0.0011\n",
      "Epoch 445/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.9147e-04 - val_loss: 0.0011\n",
      "Epoch 446/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8931e-04 - val_loss: 0.0011\n",
      "Epoch 447/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8715e-04 - val_loss: 0.0011\n",
      "Epoch 448/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.8501e-04 - val_loss: 0.0011\n",
      "Epoch 449/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.8287e-04 - val_loss: 0.0011\n",
      "Epoch 450/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 5.8076e-04 - val_loss: 0.0011\n",
      "Epoch 451/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.7864e-04 - val_loss: 0.0011\n",
      "Epoch 452/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.7654e-04 - val_loss: 0.0011\n",
      "Epoch 453/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.7444e-04 - val_loss: 0.0011\n",
      "Epoch 454/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7237e-04 - val_loss: 0.0011\n",
      "Epoch 455/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.7029e-04 - val_loss: 0.0011\n",
      "Epoch 456/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 5.6823e-04 - val_loss: 0.0011\n",
      "Epoch 457/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.6618e-04 - val_loss: 0.0011\n",
      "Epoch 458/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6413e-04 - val_loss: 0.0011\n",
      "Epoch 459/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6211e-04 - val_loss: 0.0011\n",
      "Epoch 460/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.6008e-04 - val_loss: 0.0011\n",
      "Epoch 461/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.5806e-04 - val_loss: 0.0011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 462/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5607e-04 - val_loss: 0.0011\n",
      "Epoch 463/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5407e-04 - val_loss: 0.0011\n",
      "Epoch 464/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5209e-04 - val_loss: 0.0011\n",
      "Epoch 465/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.5012e-04 - val_loss: 0.0011\n",
      "Epoch 466/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4816e-04 - val_loss: 0.0011\n",
      "Epoch 467/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4620e-04 - val_loss: 0.0011\n",
      "Epoch 468/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.4425e-04 - val_loss: 0.0011\n",
      "Epoch 469/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.4232e-04 - val_loss: 0.0011\n",
      "Epoch 470/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4039e-04 - val_loss: 0.0010\n",
      "Epoch 471/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3847e-04 - val_loss: 0.0010\n",
      "Epoch 472/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3656e-04 - val_loss: 0.0010\n",
      "Epoch 473/1000\n",
      "32/32 [==============================] - 0s 176us/step - loss: 5.3466e-04 - val_loss: 0.0010\n",
      "Epoch 474/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.3277e-04 - val_loss: 0.0010\n",
      "Epoch 475/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.3089e-04 - val_loss: 0.0010\n",
      "Epoch 476/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.2901e-04 - val_loss: 0.0010\n",
      "Epoch 477/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2715e-04 - val_loss: 0.0010\n",
      "Epoch 478/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.2530e-04 - val_loss: 0.0010\n",
      "Epoch 479/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.2345e-04 - val_loss: 0.0010\n",
      "Epoch 480/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.2161e-04 - val_loss: 0.0010\n",
      "Epoch 481/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1978e-04 - val_loss: 0.0010\n",
      "Epoch 482/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1796e-04 - val_loss: 0.0010\n",
      "Epoch 483/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1614e-04 - val_loss: 0.0010\n",
      "Epoch 484/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.1434e-04 - val_loss: 0.0010\n",
      "Epoch 485/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1254e-04 - val_loss: 0.0010\n",
      "Epoch 486/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.1076e-04 - val_loss: 9.9831e-04\n",
      "Epoch 487/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.0898e-04 - val_loss: 9.9528e-04\n",
      "Epoch 488/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0721e-04 - val_loss: 9.9225e-04\n",
      "Epoch 489/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.0544e-04 - val_loss: 9.8926e-04\n",
      "Epoch 490/1000\n",
      "32/32 [==============================] - 0s 176us/step - loss: 5.0369e-04 - val_loss: 9.8624e-04\n",
      "Epoch 491/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0194e-04 - val_loss: 9.8327e-04\n",
      "Epoch 492/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.0020e-04 - val_loss: 9.8030e-04\n",
      "Epoch 493/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9847e-04 - val_loss: 9.7735e-04\n",
      "Epoch 494/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9675e-04 - val_loss: 9.7440e-04\n",
      "Epoch 495/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.9503e-04 - val_loss: 9.7146e-04\n",
      "Epoch 496/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 4.9333e-04 - val_loss: 9.6856e-04\n",
      "Epoch 497/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.9163e-04 - val_loss: 9.6564e-04\n",
      "Epoch 498/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.8993e-04 - val_loss: 9.6275e-04\n",
      "Epoch 499/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.8825e-04 - val_loss: 9.5987e-04\n",
      "Epoch 500/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.8657e-04 - val_loss: 9.5701e-04\n",
      "Epoch 501/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.8490e-04 - val_loss: 9.5415e-04\n",
      "Epoch 502/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8324e-04 - val_loss: 9.5130e-04\n",
      "Epoch 503/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.8159e-04 - val_loss: 9.4847e-04\n",
      "Epoch 504/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.7994e-04 - val_loss: 9.4564e-04\n",
      "Epoch 505/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.7830e-04 - val_loss: 9.4284e-04\n",
      "Epoch 506/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7667e-04 - val_loss: 9.4004e-04\n",
      "Epoch 507/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7504e-04 - val_loss: 9.3727e-04\n",
      "Epoch 508/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7343e-04 - val_loss: 9.3448e-04\n",
      "Epoch 509/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.7181e-04 - val_loss: 9.3173e-04\n",
      "Epoch 510/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7021e-04 - val_loss: 9.2897e-04\n",
      "Epoch 511/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 4.6861e-04 - val_loss: 9.2626e-04\n",
      "Epoch 512/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.6703e-04 - val_loss: 9.2352e-04\n",
      "Epoch 513/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.6544e-04 - val_loss: 9.2079e-04\n",
      "Epoch 514/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6387e-04 - val_loss: 9.1807e-04\n",
      "Epoch 515/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.6230e-04 - val_loss: 9.1538e-04\n",
      "Epoch 516/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6073e-04 - val_loss: 9.1270e-04\n",
      "Epoch 517/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.5918e-04 - val_loss: 9.1003e-04\n",
      "Epoch 518/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.5764e-04 - val_loss: 9.0739e-04\n",
      "Epoch 519/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5610e-04 - val_loss: 9.0475e-04\n",
      "Epoch 520/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.5457e-04 - val_loss: 9.0209e-04\n",
      "Epoch 521/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5303e-04 - val_loss: 8.9945e-04\n",
      "Epoch 522/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5152e-04 - val_loss: 8.9685e-04\n",
      "Epoch 523/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5000e-04 - val_loss: 8.9424e-04\n",
      "Epoch 524/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.4849e-04 - val_loss: 8.9163e-04\n",
      "Epoch 525/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.4700e-04 - val_loss: 8.8908e-04\n",
      "Epoch 526/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4550e-04 - val_loss: 8.8649e-04\n",
      "Epoch 527/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4401e-04 - val_loss: 8.8393e-04\n",
      "Epoch 528/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.4254e-04 - val_loss: 8.8136e-04\n",
      "Epoch 529/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4105e-04 - val_loss: 8.7881e-04\n",
      "Epoch 530/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.3959e-04 - val_loss: 8.7627e-04\n",
      "Epoch 531/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.3813e-04 - val_loss: 8.7374e-04\n",
      "Epoch 532/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.3667e-04 - val_loss: 8.7123e-04\n",
      "Epoch 533/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3523e-04 - val_loss: 8.6873e-04\n",
      "Epoch 534/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.3378e-04 - val_loss: 8.6624e-04\n",
      "Epoch 535/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3234e-04 - val_loss: 8.6374e-04\n",
      "Epoch 536/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3091e-04 - val_loss: 8.6128e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 537/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2949e-04 - val_loss: 8.5882e-04\n",
      "Epoch 538/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.2807e-04 - val_loss: 8.5636e-04\n",
      "Epoch 539/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2666e-04 - val_loss: 8.5392e-04\n",
      "Epoch 540/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2525e-04 - val_loss: 8.5149e-04\n",
      "Epoch 541/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.2385e-04 - val_loss: 8.4904e-04\n",
      "Epoch 542/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2245e-04 - val_loss: 8.4664e-04\n",
      "Epoch 543/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.2107e-04 - val_loss: 8.4422e-04\n",
      "Epoch 544/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.1969e-04 - val_loss: 8.4183e-04\n",
      "Epoch 545/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1831e-04 - val_loss: 8.3944e-04\n",
      "Epoch 546/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.1694e-04 - val_loss: 8.3706e-04\n",
      "Epoch 547/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1557e-04 - val_loss: 8.3468e-04\n",
      "Epoch 548/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.1421e-04 - val_loss: 8.3232e-04\n",
      "Epoch 549/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.1286e-04 - val_loss: 8.2997e-04\n",
      "Epoch 550/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.1151e-04 - val_loss: 8.2763e-04\n",
      "Epoch 551/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1017e-04 - val_loss: 8.2529e-04\n",
      "Epoch 552/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.0884e-04 - val_loss: 8.2298e-04\n",
      "Epoch 553/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.0751e-04 - val_loss: 8.2067e-04\n",
      "Epoch 554/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0618e-04 - val_loss: 8.1835e-04\n",
      "Epoch 555/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0486e-04 - val_loss: 8.1604e-04\n",
      "Epoch 556/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0355e-04 - val_loss: 8.1376e-04\n",
      "Epoch 557/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0224e-04 - val_loss: 8.1149e-04\n",
      "Epoch 558/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 4.0094e-04 - val_loss: 8.0921e-04\n",
      "Epoch 559/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9964e-04 - val_loss: 8.0693e-04\n",
      "Epoch 560/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.9835e-04 - val_loss: 8.0468e-04\n",
      "Epoch 561/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.9706e-04 - val_loss: 8.0245e-04\n",
      "Epoch 562/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.9577e-04 - val_loss: 8.0019e-04\n",
      "Epoch 563/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.9450e-04 - val_loss: 7.9797e-04\n",
      "Epoch 564/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9323e-04 - val_loss: 7.9574e-04\n",
      "Epoch 565/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9196e-04 - val_loss: 7.9353e-04\n",
      "Epoch 566/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9070e-04 - val_loss: 7.9132e-04\n",
      "Epoch 567/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8944e-04 - val_loss: 7.8911e-04\n",
      "Epoch 568/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.8820e-04 - val_loss: 7.8693e-04\n",
      "Epoch 569/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8695e-04 - val_loss: 7.8476e-04\n",
      "Epoch 570/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.8571e-04 - val_loss: 7.8259e-04\n",
      "Epoch 571/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8447e-04 - val_loss: 7.8040e-04\n",
      "Epoch 572/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8324e-04 - val_loss: 7.7826e-04\n",
      "Epoch 573/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.8202e-04 - val_loss: 7.7610e-04\n",
      "Epoch 574/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.8080e-04 - val_loss: 7.7398e-04\n",
      "Epoch 575/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7959e-04 - val_loss: 7.7185e-04\n",
      "Epoch 576/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.7838e-04 - val_loss: 7.6971e-04\n",
      "Epoch 577/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.7718e-04 - val_loss: 7.6757e-04\n",
      "Epoch 578/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.7597e-04 - val_loss: 7.6548e-04\n",
      "Epoch 579/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7477e-04 - val_loss: 7.6338e-04\n",
      "Epoch 580/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.7359e-04 - val_loss: 7.6129e-04\n",
      "Epoch 581/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.7240e-04 - val_loss: 7.5919e-04\n",
      "Epoch 582/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.7122e-04 - val_loss: 7.5713e-04\n",
      "Epoch 583/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7005e-04 - val_loss: 7.5504e-04\n",
      "Epoch 584/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6887e-04 - val_loss: 7.5299e-04\n",
      "Epoch 585/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6771e-04 - val_loss: 7.5092e-04\n",
      "Epoch 586/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6655e-04 - val_loss: 7.4887e-04\n",
      "Epoch 587/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6539e-04 - val_loss: 7.4684e-04\n",
      "Epoch 588/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6424e-04 - val_loss: 7.4478e-04\n",
      "Epoch 589/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6309e-04 - val_loss: 7.4277e-04\n",
      "Epoch 590/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6194e-04 - val_loss: 7.4074e-04\n",
      "Epoch 591/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6080e-04 - val_loss: 7.3872e-04\n",
      "Epoch 592/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5967e-04 - val_loss: 7.3673e-04\n",
      "Epoch 593/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5854e-04 - val_loss: 7.3471e-04\n",
      "Epoch 594/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5742e-04 - val_loss: 7.3275e-04\n",
      "Epoch 595/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5630e-04 - val_loss: 7.3076e-04\n",
      "Epoch 596/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5518e-04 - val_loss: 7.2878e-04\n",
      "Epoch 597/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5407e-04 - val_loss: 7.2680e-04\n",
      "Epoch 598/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5296e-04 - val_loss: 7.2484e-04\n",
      "Epoch 599/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5186e-04 - val_loss: 7.2290e-04\n",
      "Epoch 600/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5076e-04 - val_loss: 7.2093e-04\n",
      "Epoch 601/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4966e-04 - val_loss: 7.1900e-04\n",
      "Epoch 602/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4858e-04 - val_loss: 7.1705e-04\n",
      "Epoch 603/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4749e-04 - val_loss: 7.1512e-04\n",
      "Epoch 604/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4641e-04 - val_loss: 7.1320e-04\n",
      "Epoch 605/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.4533e-04 - val_loss: 7.1127e-04\n",
      "Epoch 606/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4426e-04 - val_loss: 7.0938e-04\n",
      "Epoch 607/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.4319e-04 - val_loss: 7.0745e-04\n",
      "Epoch 608/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4213e-04 - val_loss: 7.0556e-04\n",
      "Epoch 609/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4107e-04 - val_loss: 7.0370e-04\n",
      "Epoch 610/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4001e-04 - val_loss: 7.0182e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 611/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3896e-04 - val_loss: 6.9993e-04\n",
      "Epoch 612/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3791e-04 - val_loss: 6.9806e-04\n",
      "Epoch 613/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3687e-04 - val_loss: 6.9621e-04\n",
      "Epoch 614/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3583e-04 - val_loss: 6.9435e-04\n",
      "Epoch 615/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.3479e-04 - val_loss: 6.9251e-04\n",
      "Epoch 616/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3376e-04 - val_loss: 6.9066e-04\n",
      "Epoch 617/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3274e-04 - val_loss: 6.8883e-04\n",
      "Epoch 618/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3171e-04 - val_loss: 6.8698e-04\n",
      "Epoch 619/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3069e-04 - val_loss: 6.8516e-04\n",
      "Epoch 620/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2967e-04 - val_loss: 6.8333e-04\n",
      "Epoch 621/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2866e-04 - val_loss: 6.8150e-04\n",
      "Epoch 622/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2765e-04 - val_loss: 6.7969e-04\n",
      "Epoch 623/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2665e-04 - val_loss: 6.7790e-04\n",
      "Epoch 624/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2565e-04 - val_loss: 6.7610e-04\n",
      "Epoch 625/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2465e-04 - val_loss: 6.7435e-04\n",
      "Epoch 626/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.2367e-04 - val_loss: 6.7255e-04\n",
      "Epoch 627/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2268e-04 - val_loss: 6.7078e-04\n",
      "Epoch 628/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2169e-04 - val_loss: 6.6902e-04\n",
      "Epoch 629/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2071e-04 - val_loss: 6.6725e-04\n",
      "Epoch 630/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1974e-04 - val_loss: 6.6549e-04\n",
      "Epoch 631/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1876e-04 - val_loss: 6.6373e-04\n",
      "Epoch 632/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1779e-04 - val_loss: 6.6199e-04\n",
      "Epoch 633/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1683e-04 - val_loss: 6.6025e-04\n",
      "Epoch 634/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1586e-04 - val_loss: 6.5852e-04\n",
      "Epoch 635/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1490e-04 - val_loss: 6.5679e-04\n",
      "Epoch 636/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1395e-04 - val_loss: 6.5506e-04\n",
      "Epoch 637/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1300e-04 - val_loss: 6.5335e-04\n",
      "Epoch 638/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1205e-04 - val_loss: 6.5165e-04\n",
      "Epoch 639/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1110e-04 - val_loss: 6.4991e-04\n",
      "Epoch 640/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1016e-04 - val_loss: 6.4823e-04\n",
      "Epoch 641/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0923e-04 - val_loss: 6.4653e-04\n",
      "Epoch 642/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0829e-04 - val_loss: 6.4485e-04\n",
      "Epoch 643/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0736e-04 - val_loss: 6.4317e-04\n",
      "Epoch 644/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0644e-04 - val_loss: 6.4149e-04\n",
      "Epoch 645/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0551e-04 - val_loss: 6.3982e-04\n",
      "Epoch 646/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0460e-04 - val_loss: 6.3814e-04\n",
      "Epoch 647/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0368e-04 - val_loss: 6.3647e-04\n",
      "Epoch 648/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0276e-04 - val_loss: 6.3482e-04\n",
      "Epoch 649/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0186e-04 - val_loss: 6.3319e-04\n",
      "Epoch 650/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0095e-04 - val_loss: 6.3153e-04\n",
      "Epoch 651/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0005e-04 - val_loss: 6.2989e-04\n",
      "Epoch 652/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 2.9915e-04 - val_loss: 6.2826e-04\n",
      "Epoch 653/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9825e-04 - val_loss: 6.2663e-04\n",
      "Epoch 654/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9736e-04 - val_loss: 6.2503e-04\n",
      "Epoch 655/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9647e-04 - val_loss: 6.2340e-04\n",
      "Epoch 656/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9559e-04 - val_loss: 6.2177e-04\n",
      "Epoch 657/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9470e-04 - val_loss: 6.2018e-04\n",
      "Epoch 658/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9382e-04 - val_loss: 6.1858e-04\n",
      "Epoch 659/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9295e-04 - val_loss: 6.1696e-04\n",
      "Epoch 660/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9207e-04 - val_loss: 6.1539e-04\n",
      "Epoch 661/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9121e-04 - val_loss: 6.1381e-04\n",
      "Epoch 662/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9034e-04 - val_loss: 6.1223e-04\n",
      "Epoch 663/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8949e-04 - val_loss: 6.1065e-04\n",
      "Epoch 664/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8862e-04 - val_loss: 6.0908e-04\n",
      "Epoch 665/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8777e-04 - val_loss: 6.0752e-04\n",
      "Epoch 666/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8691e-04 - val_loss: 6.0594e-04\n",
      "Epoch 667/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8606e-04 - val_loss: 6.0439e-04\n",
      "Epoch 668/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8522e-04 - val_loss: 6.0284e-04\n",
      "Epoch 669/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8437e-04 - val_loss: 6.0129e-04\n",
      "Epoch 670/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8352e-04 - val_loss: 5.9975e-04\n",
      "Epoch 671/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8269e-04 - val_loss: 5.9821e-04\n",
      "Epoch 672/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8185e-04 - val_loss: 5.9669e-04\n",
      "Epoch 673/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8102e-04 - val_loss: 5.9516e-04\n",
      "Epoch 674/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8020e-04 - val_loss: 5.9364e-04\n",
      "Epoch 675/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.7937e-04 - val_loss: 5.9212e-04\n",
      "Epoch 676/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.7854e-04 - val_loss: 5.9061e-04\n",
      "Epoch 677/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.7773e-04 - val_loss: 5.8908e-04\n",
      "Epoch 678/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.7691e-04 - val_loss: 5.8761e-04\n",
      "Epoch 679/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.7610e-04 - val_loss: 5.8611e-04\n",
      "Epoch 680/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.7529e-04 - val_loss: 5.8462e-04\n",
      "Epoch 681/1000\n",
      "32/32 [==============================] - 0s 132us/step - loss: 2.7448e-04 - val_loss: 5.8312e-04\n",
      "Epoch 682/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.7367e-04 - val_loss: 5.8164e-04\n",
      "Epoch 683/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.7287e-04 - val_loss: 5.8016e-04\n",
      "Epoch 684/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.7207e-04 - val_loss: 5.7869e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 685/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.7127e-04 - val_loss: 5.7723e-04\n",
      "Epoch 686/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.7048e-04 - val_loss: 5.7576e-04\n",
      "Epoch 687/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6969e-04 - val_loss: 5.7428e-04\n",
      "Epoch 688/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 2.6890e-04 - val_loss: 5.7284e-04\n",
      "Epoch 689/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.6812e-04 - val_loss: 5.7140e-04\n",
      "Epoch 690/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.6734e-04 - val_loss: 5.6994e-04\n",
      "Epoch 691/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.6655e-04 - val_loss: 5.6850e-04\n",
      "Epoch 692/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.6578e-04 - val_loss: 5.6707e-04\n",
      "Epoch 693/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 2.6501e-04 - val_loss: 5.6564e-04\n",
      "Epoch 694/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6424e-04 - val_loss: 5.6421e-04\n",
      "Epoch 695/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.6347e-04 - val_loss: 5.6278e-04\n",
      "Epoch 696/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6271e-04 - val_loss: 5.6137e-04\n",
      "Epoch 697/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6194e-04 - val_loss: 5.5995e-04\n",
      "Epoch 698/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6118e-04 - val_loss: 5.5854e-04\n",
      "Epoch 699/1000\n",
      "32/32 [==============================] - 0s 129us/step - loss: 2.6042e-04 - val_loss: 5.5713e-04\n",
      "Epoch 700/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5967e-04 - val_loss: 5.5574e-04\n",
      "Epoch 701/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.5892e-04 - val_loss: 5.5433e-04\n",
      "Epoch 702/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5817e-04 - val_loss: 5.5294e-04\n",
      "Epoch 703/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5742e-04 - val_loss: 5.5155e-04\n",
      "Epoch 704/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5668e-04 - val_loss: 5.5018e-04\n",
      "Epoch 705/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.5594e-04 - val_loss: 5.4879e-04\n",
      "Epoch 706/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.5520e-04 - val_loss: 5.4742e-04\n",
      "Epoch 707/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.5447e-04 - val_loss: 5.4605e-04\n",
      "Epoch 708/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5373e-04 - val_loss: 5.4468e-04\n",
      "Epoch 709/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 2.5300e-04 - val_loss: 5.4330e-04\n",
      "Epoch 710/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5227e-04 - val_loss: 5.4196e-04\n",
      "Epoch 711/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.5154e-04 - val_loss: 5.4059e-04\n",
      "Epoch 712/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.5082e-04 - val_loss: 5.3926e-04\n",
      "Epoch 713/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5010e-04 - val_loss: 5.3789e-04\n",
      "Epoch 714/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.4939e-04 - val_loss: 5.3655e-04\n",
      "Epoch 715/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.4867e-04 - val_loss: 5.3522e-04\n",
      "Epoch 716/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.4796e-04 - val_loss: 5.3389e-04\n",
      "Epoch 717/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.4724e-04 - val_loss: 5.3255e-04\n",
      "Epoch 718/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 2.4654e-04 - val_loss: 5.3123e-04\n",
      "Epoch 719/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4583e-04 - val_loss: 5.2991e-04\n",
      "Epoch 720/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.4513e-04 - val_loss: 5.2857e-04\n",
      "Epoch 721/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 2.4443e-04 - val_loss: 5.2727e-04\n",
      "Epoch 722/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4373e-04 - val_loss: 5.2596e-04\n",
      "Epoch 723/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.4304e-04 - val_loss: 5.2464e-04\n",
      "Epoch 724/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.4234e-04 - val_loss: 5.2335e-04\n",
      "Epoch 725/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.4165e-04 - val_loss: 5.2205e-04\n",
      "Epoch 726/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4096e-04 - val_loss: 5.2076e-04\n",
      "Epoch 727/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.4027e-04 - val_loss: 5.1946e-04\n",
      "Epoch 728/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.3960e-04 - val_loss: 5.1818e-04\n",
      "Epoch 729/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3891e-04 - val_loss: 5.1691e-04\n",
      "Epoch 730/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3824e-04 - val_loss: 5.1562e-04\n",
      "Epoch 731/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3756e-04 - val_loss: 5.1436e-04\n",
      "Epoch 732/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.3688e-04 - val_loss: 5.1308e-04\n",
      "Epoch 733/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3621e-04 - val_loss: 5.1183e-04\n",
      "Epoch 734/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3554e-04 - val_loss: 5.1055e-04\n",
      "Epoch 735/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3487e-04 - val_loss: 5.0929e-04\n",
      "Epoch 736/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3421e-04 - val_loss: 5.0803e-04\n",
      "Epoch 737/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3355e-04 - val_loss: 5.0677e-04\n",
      "Epoch 738/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3289e-04 - val_loss: 5.0552e-04\n",
      "Epoch 739/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.3223e-04 - val_loss: 5.0428e-04\n",
      "Epoch 740/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3157e-04 - val_loss: 5.0303e-04\n",
      "Epoch 741/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3092e-04 - val_loss: 5.0180e-04\n",
      "Epoch 742/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 2.3026e-04 - val_loss: 5.0056e-04\n",
      "Epoch 743/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2962e-04 - val_loss: 4.9933e-04\n",
      "Epoch 744/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2897e-04 - val_loss: 4.9811e-04\n",
      "Epoch 745/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.2833e-04 - val_loss: 4.9689e-04\n",
      "Epoch 746/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.2768e-04 - val_loss: 4.9566e-04\n",
      "Epoch 747/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.2704e-04 - val_loss: 4.9446e-04\n",
      "Epoch 748/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2640e-04 - val_loss: 4.9326e-04\n",
      "Epoch 749/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2577e-04 - val_loss: 4.9203e-04\n",
      "Epoch 750/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.2513e-04 - val_loss: 4.9084e-04\n",
      "Epoch 751/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.2450e-04 - val_loss: 4.8964e-04\n",
      "Epoch 752/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.2387e-04 - val_loss: 4.8845e-04\n",
      "Epoch 753/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2325e-04 - val_loss: 4.8723e-04\n",
      "Epoch 754/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.2262e-04 - val_loss: 4.8604e-04\n",
      "Epoch 755/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2199e-04 - val_loss: 4.8485e-04\n",
      "Epoch 756/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.2137e-04 - val_loss: 4.8366e-04\n",
      "Epoch 757/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.2075e-04 - val_loss: 4.8248e-04\n",
      "Epoch 758/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 2.2014e-04 - val_loss: 4.8129e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 759/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.1952e-04 - val_loss: 4.8013e-04\n",
      "Epoch 760/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.1891e-04 - val_loss: 4.7898e-04\n",
      "Epoch 761/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1830e-04 - val_loss: 4.7779e-04\n",
      "Epoch 762/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1769e-04 - val_loss: 4.7663e-04\n",
      "Epoch 763/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.1708e-04 - val_loss: 4.7548e-04\n",
      "Epoch 764/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.1648e-04 - val_loss: 4.7433e-04\n",
      "Epoch 765/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1588e-04 - val_loss: 4.7317e-04\n",
      "Epoch 766/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1527e-04 - val_loss: 4.7203e-04\n",
      "Epoch 767/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1468e-04 - val_loss: 4.7087e-04\n",
      "Epoch 768/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.1408e-04 - val_loss: 4.6974e-04\n",
      "Epoch 769/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.1349e-04 - val_loss: 4.6860e-04\n",
      "Epoch 770/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1289e-04 - val_loss: 4.6745e-04\n",
      "Epoch 771/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1230e-04 - val_loss: 4.6631e-04\n",
      "Epoch 772/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.1172e-04 - val_loss: 4.6519e-04\n",
      "Epoch 773/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1113e-04 - val_loss: 4.6404e-04\n",
      "Epoch 774/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 2.1054e-04 - val_loss: 4.6293e-04\n",
      "Epoch 775/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.0996e-04 - val_loss: 4.6182e-04\n",
      "Epoch 776/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 2.0938e-04 - val_loss: 4.6070e-04\n",
      "Epoch 777/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 2.0880e-04 - val_loss: 4.5958e-04\n",
      "Epoch 778/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0823e-04 - val_loss: 4.5848e-04\n",
      "Epoch 779/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0765e-04 - val_loss: 4.5737e-04\n",
      "Epoch 780/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.0708e-04 - val_loss: 4.5626e-04\n",
      "Epoch 781/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 2.0651e-04 - val_loss: 4.5516e-04\n",
      "Epoch 782/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.0594e-04 - val_loss: 4.5406e-04\n",
      "Epoch 783/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.0537e-04 - val_loss: 4.5296e-04\n",
      "Epoch 784/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.0480e-04 - val_loss: 4.5188e-04\n",
      "Epoch 785/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0424e-04 - val_loss: 4.5078e-04\n",
      "Epoch 786/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0368e-04 - val_loss: 4.4971e-04\n",
      "Epoch 787/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.0312e-04 - val_loss: 4.4861e-04\n",
      "Epoch 788/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.0256e-04 - val_loss: 4.4754e-04\n",
      "Epoch 789/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.0200e-04 - val_loss: 4.4646e-04\n",
      "Epoch 790/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.0145e-04 - val_loss: 4.4538e-04\n",
      "Epoch 791/1000\n",
      "32/32 [==============================] - 0s 145us/step - loss: 2.0089e-04 - val_loss: 4.4431e-04\n",
      "Epoch 792/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0034e-04 - val_loss: 4.4325e-04\n",
      "Epoch 793/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9980e-04 - val_loss: 4.4218e-04\n",
      "Epoch 794/1000\n",
      "32/32 [==============================] - 0s 165us/step - loss: 1.9925e-04 - val_loss: 4.4112e-04\n",
      "Epoch 795/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9870e-04 - val_loss: 4.4005e-04\n",
      "Epoch 796/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9816e-04 - val_loss: 4.3900e-04\n",
      "Epoch 797/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9762e-04 - val_loss: 4.3796e-04\n",
      "Epoch 798/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9708e-04 - val_loss: 4.3689e-04\n",
      "Epoch 799/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9654e-04 - val_loss: 4.3586e-04\n",
      "Epoch 800/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9600e-04 - val_loss: 4.3481e-04\n",
      "Epoch 801/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9547e-04 - val_loss: 4.3379e-04\n",
      "Epoch 802/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.9494e-04 - val_loss: 4.3273e-04\n",
      "Epoch 803/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.9440e-04 - val_loss: 4.3170e-04\n",
      "Epoch 804/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9387e-04 - val_loss: 4.3067e-04\n",
      "Epoch 805/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9334e-04 - val_loss: 4.2964e-04\n",
      "Epoch 806/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.9282e-04 - val_loss: 4.2861e-04\n",
      "Epoch 807/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.9229e-04 - val_loss: 4.2760e-04\n",
      "Epoch 808/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.9177e-04 - val_loss: 4.2657e-04\n",
      "Epoch 809/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9125e-04 - val_loss: 4.2555e-04\n",
      "Epoch 810/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 1.9073e-04 - val_loss: 4.2453e-04\n",
      "Epoch 811/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.9021e-04 - val_loss: 4.2352e-04\n",
      "Epoch 812/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8970e-04 - val_loss: 4.2252e-04\n",
      "Epoch 813/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8918e-04 - val_loss: 4.2151e-04\n",
      "Epoch 814/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8867e-04 - val_loss: 4.2049e-04\n",
      "Epoch 815/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8815e-04 - val_loss: 4.1950e-04\n",
      "Epoch 816/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8764e-04 - val_loss: 4.1851e-04\n",
      "Epoch 817/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8714e-04 - val_loss: 4.1751e-04\n",
      "Epoch 818/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8663e-04 - val_loss: 4.1652e-04\n",
      "Epoch 819/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 1.8612e-04 - val_loss: 4.1553e-04\n",
      "Epoch 820/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8562e-04 - val_loss: 4.1453e-04\n",
      "Epoch 821/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 1.8512e-04 - val_loss: 4.1356e-04\n",
      "Epoch 822/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8462e-04 - val_loss: 4.1258e-04\n",
      "Epoch 823/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8412e-04 - val_loss: 4.1160e-04\n",
      "Epoch 824/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8363e-04 - val_loss: 4.1063e-04\n",
      "Epoch 825/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8313e-04 - val_loss: 4.0965e-04\n",
      "Epoch 826/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.8264e-04 - val_loss: 4.0868e-04\n",
      "Epoch 827/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8215e-04 - val_loss: 4.0769e-04\n",
      "Epoch 828/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8166e-04 - val_loss: 4.0673e-04\n",
      "Epoch 829/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8116e-04 - val_loss: 4.0577e-04\n",
      "Epoch 830/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8068e-04 - val_loss: 4.0482e-04\n",
      "Epoch 831/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8019e-04 - val_loss: 4.0385e-04\n",
      "Epoch 832/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.7971e-04 - val_loss: 4.0289e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 833/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.7923e-04 - val_loss: 4.0195e-04\n",
      "Epoch 834/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 1.7874e-04 - val_loss: 4.0101e-04\n",
      "Epoch 835/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7827e-04 - val_loss: 4.0006e-04\n",
      "Epoch 836/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7779e-04 - val_loss: 3.9911e-04\n",
      "Epoch 837/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7731e-04 - val_loss: 3.9816e-04\n",
      "Epoch 838/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7684e-04 - val_loss: 3.9722e-04\n",
      "Epoch 839/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7636e-04 - val_loss: 3.9628e-04\n",
      "Epoch 840/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7589e-04 - val_loss: 3.9535e-04\n",
      "Epoch 841/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7542e-04 - val_loss: 3.9442e-04\n",
      "Epoch 842/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7495e-04 - val_loss: 3.9348e-04\n",
      "Epoch 843/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7448e-04 - val_loss: 3.9256e-04\n",
      "Epoch 844/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7401e-04 - val_loss: 3.9164e-04\n",
      "Epoch 845/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7355e-04 - val_loss: 3.9072e-04\n",
      "Epoch 846/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7309e-04 - val_loss: 3.8979e-04\n",
      "Epoch 847/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7262e-04 - val_loss: 3.8887e-04\n",
      "Epoch 848/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7217e-04 - val_loss: 3.8797e-04\n",
      "Epoch 849/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7170e-04 - val_loss: 3.8705e-04\n",
      "Epoch 850/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7125e-04 - val_loss: 3.8615e-04\n",
      "Epoch 851/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7079e-04 - val_loss: 3.8523e-04\n",
      "Epoch 852/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7034e-04 - val_loss: 3.8433e-04\n",
      "Epoch 853/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6988e-04 - val_loss: 3.8343e-04\n",
      "Epoch 854/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6943e-04 - val_loss: 3.8253e-04\n",
      "Epoch 855/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 1.6898e-04 - val_loss: 3.8163e-04\n",
      "Epoch 856/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6853e-04 - val_loss: 3.8073e-04\n",
      "Epoch 857/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6808e-04 - val_loss: 3.7985e-04\n",
      "Epoch 858/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6764e-04 - val_loss: 3.7895e-04\n",
      "Epoch 859/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6719e-04 - val_loss: 3.7806e-04\n",
      "Epoch 860/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6675e-04 - val_loss: 3.7718e-04\n",
      "Epoch 861/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6631e-04 - val_loss: 3.7630e-04\n",
      "Epoch 862/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6587e-04 - val_loss: 3.7541e-04\n",
      "Epoch 863/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6542e-04 - val_loss: 3.7453e-04\n",
      "Epoch 864/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6499e-04 - val_loss: 3.7366e-04\n",
      "Epoch 865/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6455e-04 - val_loss: 3.7279e-04\n",
      "Epoch 866/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6412e-04 - val_loss: 3.7192e-04\n",
      "Epoch 867/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6368e-04 - val_loss: 3.7104e-04\n",
      "Epoch 868/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6325e-04 - val_loss: 3.7018e-04\n",
      "Epoch 869/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6282e-04 - val_loss: 3.6932e-04\n",
      "Epoch 870/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6239e-04 - val_loss: 3.6846e-04\n",
      "Epoch 871/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6196e-04 - val_loss: 3.6760e-04\n",
      "Epoch 872/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6153e-04 - val_loss: 3.6674e-04\n",
      "Epoch 873/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6111e-04 - val_loss: 3.6588e-04\n",
      "Epoch 874/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6068e-04 - val_loss: 3.6502e-04\n",
      "Epoch 875/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6026e-04 - val_loss: 3.6418e-04\n",
      "Epoch 876/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5983e-04 - val_loss: 3.6333e-04\n",
      "Epoch 877/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5941e-04 - val_loss: 3.6249e-04\n",
      "Epoch 878/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5899e-04 - val_loss: 3.6163e-04\n",
      "Epoch 879/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5857e-04 - val_loss: 3.6079e-04\n",
      "Epoch 880/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5816e-04 - val_loss: 3.5994e-04\n",
      "Epoch 881/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5774e-04 - val_loss: 3.5912e-04\n",
      "Epoch 882/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5733e-04 - val_loss: 3.5828e-04\n",
      "Epoch 883/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5691e-04 - val_loss: 3.5745e-04\n",
      "Epoch 884/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5650e-04 - val_loss: 3.5663e-04\n",
      "Epoch 885/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5609e-04 - val_loss: 3.5579e-04\n",
      "Epoch 886/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5568e-04 - val_loss: 3.5497e-04\n",
      "Epoch 887/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5528e-04 - val_loss: 3.5415e-04\n",
      "Epoch 888/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5487e-04 - val_loss: 3.5331e-04\n",
      "Epoch 889/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5446e-04 - val_loss: 3.5249e-04\n",
      "Epoch 890/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5406e-04 - val_loss: 3.5168e-04\n",
      "Epoch 891/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5366e-04 - val_loss: 3.5085e-04\n",
      "Epoch 892/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5325e-04 - val_loss: 3.5004e-04\n",
      "Epoch 893/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.5285e-04 - val_loss: 3.4924e-04\n",
      "Epoch 894/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5245e-04 - val_loss: 3.4842e-04\n",
      "Epoch 895/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5205e-04 - val_loss: 3.4762e-04\n",
      "Epoch 896/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5166e-04 - val_loss: 3.4681e-04\n",
      "Epoch 897/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5126e-04 - val_loss: 3.4602e-04\n",
      "Epoch 898/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5086e-04 - val_loss: 3.4521e-04\n",
      "Epoch 899/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5047e-04 - val_loss: 3.4440e-04\n",
      "Epoch 900/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5008e-04 - val_loss: 3.4360e-04\n",
      "Epoch 901/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4969e-04 - val_loss: 3.4282e-04\n",
      "Epoch 902/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4930e-04 - val_loss: 3.4203e-04\n",
      "Epoch 903/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4891e-04 - val_loss: 3.4123e-04\n",
      "Epoch 904/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4852e-04 - val_loss: 3.4044e-04\n",
      "Epoch 905/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4813e-04 - val_loss: 3.3967e-04\n",
      "Epoch 906/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4775e-04 - val_loss: 3.3886e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 907/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4736e-04 - val_loss: 3.3809e-04\n",
      "Epoch 908/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4698e-04 - val_loss: 3.3731e-04\n",
      "Epoch 909/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4660e-04 - val_loss: 3.3654e-04\n",
      "Epoch 910/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4622e-04 - val_loss: 3.3575e-04\n",
      "Epoch 911/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4584e-04 - val_loss: 3.3498e-04\n",
      "Epoch 912/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4546e-04 - val_loss: 3.3421e-04\n",
      "Epoch 913/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4508e-04 - val_loss: 3.3344e-04\n",
      "Epoch 914/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4471e-04 - val_loss: 3.3266e-04\n",
      "Epoch 915/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4433e-04 - val_loss: 3.3190e-04\n",
      "Epoch 916/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.4396e-04 - val_loss: 3.3114e-04\n",
      "Epoch 917/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4358e-04 - val_loss: 3.3037e-04\n",
      "Epoch 918/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4321e-04 - val_loss: 3.2961e-04\n",
      "Epoch 919/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4284e-04 - val_loss: 3.2885e-04\n",
      "Epoch 920/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4247e-04 - val_loss: 3.2810e-04\n",
      "Epoch 921/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4210e-04 - val_loss: 3.2734e-04\n",
      "Epoch 922/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4174e-04 - val_loss: 3.2659e-04\n",
      "Epoch 923/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4137e-04 - val_loss: 3.2585e-04\n",
      "Epoch 924/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4100e-04 - val_loss: 3.2509e-04\n",
      "Epoch 925/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4064e-04 - val_loss: 3.2434e-04\n",
      "Epoch 926/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4028e-04 - val_loss: 3.2359e-04\n",
      "Epoch 927/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3991e-04 - val_loss: 3.2285e-04\n",
      "Epoch 928/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3955e-04 - val_loss: 3.2211e-04\n",
      "Epoch 929/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3919e-04 - val_loss: 3.2137e-04\n",
      "Epoch 930/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3883e-04 - val_loss: 3.2063e-04\n",
      "Epoch 931/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3848e-04 - val_loss: 3.1990e-04\n",
      "Epoch 932/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3812e-04 - val_loss: 3.1917e-04\n",
      "Epoch 933/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3776e-04 - val_loss: 3.1843e-04\n",
      "Epoch 934/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3741e-04 - val_loss: 3.1771e-04\n",
      "Epoch 935/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3706e-04 - val_loss: 3.1697e-04\n",
      "Epoch 936/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3670e-04 - val_loss: 3.1624e-04\n",
      "Epoch 937/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3635e-04 - val_loss: 3.1552e-04\n",
      "Epoch 938/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3600e-04 - val_loss: 3.1479e-04\n",
      "Epoch 939/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3565e-04 - val_loss: 3.1408e-04\n",
      "Epoch 940/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3530e-04 - val_loss: 3.1335e-04\n",
      "Epoch 941/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.3495e-04 - val_loss: 3.1265e-04\n",
      "Epoch 942/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3461e-04 - val_loss: 3.1192e-04\n",
      "Epoch 943/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3426e-04 - val_loss: 3.1122e-04\n",
      "Epoch 944/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3392e-04 - val_loss: 3.1050e-04\n",
      "Epoch 945/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3357e-04 - val_loss: 3.0979e-04\n",
      "Epoch 946/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3323e-04 - val_loss: 3.0909e-04\n",
      "Epoch 947/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3289e-04 - val_loss: 3.0837e-04\n",
      "Epoch 948/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3255e-04 - val_loss: 3.0767e-04\n",
      "Epoch 949/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3221e-04 - val_loss: 3.0696e-04\n",
      "Epoch 950/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3187e-04 - val_loss: 3.0626e-04\n",
      "Epoch 951/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3153e-04 - val_loss: 3.0555e-04\n",
      "Epoch 952/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3119e-04 - val_loss: 3.0486e-04\n",
      "Epoch 953/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3086e-04 - val_loss: 3.0416e-04\n",
      "Epoch 954/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3053e-04 - val_loss: 3.0347e-04\n",
      "Epoch 955/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3019e-04 - val_loss: 3.0278e-04\n",
      "Epoch 956/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2986e-04 - val_loss: 3.0209e-04\n",
      "Epoch 957/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2953e-04 - val_loss: 3.0140e-04\n",
      "Epoch 958/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2920e-04 - val_loss: 3.0070e-04\n",
      "Epoch 959/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2887e-04 - val_loss: 3.0003e-04\n",
      "Epoch 960/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.2854e-04 - val_loss: 2.9934e-04\n",
      "Epoch 961/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2821e-04 - val_loss: 2.9867e-04\n",
      "Epoch 962/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2789e-04 - val_loss: 2.9798e-04\n",
      "Epoch 963/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2756e-04 - val_loss: 2.9731e-04\n",
      "Epoch 964/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2724e-04 - val_loss: 2.9663e-04\n",
      "Epoch 965/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2691e-04 - val_loss: 2.9594e-04\n",
      "Epoch 966/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2659e-04 - val_loss: 2.9528e-04\n",
      "Epoch 967/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2627e-04 - val_loss: 2.9461e-04\n",
      "Epoch 968/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2594e-04 - val_loss: 2.9393e-04\n",
      "Epoch 969/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2562e-04 - val_loss: 2.9326e-04\n",
      "Epoch 970/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 1.2530e-04 - val_loss: 2.9259e-04\n",
      "Epoch 971/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.2499e-04 - val_loss: 2.9192e-04\n",
      "Epoch 972/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2467e-04 - val_loss: 2.9127e-04\n",
      "Epoch 973/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 1.2435e-04 - val_loss: 2.9060e-04\n",
      "Epoch 974/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2403e-04 - val_loss: 2.8994e-04\n",
      "Epoch 975/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2372e-04 - val_loss: 2.8928e-04\n",
      "Epoch 976/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 1.2340e-04 - val_loss: 2.8862e-04\n",
      "Epoch 977/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2309e-04 - val_loss: 2.8797e-04\n",
      "Epoch 978/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2278e-04 - val_loss: 2.8731e-04\n",
      "Epoch 979/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.2247e-04 - val_loss: 2.8667e-04\n",
      "Epoch 980/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2216e-04 - val_loss: 2.8601e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 981/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2185e-04 - val_loss: 2.8536e-04\n",
      "Epoch 982/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2154e-04 - val_loss: 2.8470e-04\n",
      "Epoch 983/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2123e-04 - val_loss: 2.8406e-04\n",
      "Epoch 984/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2093e-04 - val_loss: 2.8341e-04\n",
      "Epoch 985/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2062e-04 - val_loss: 2.8278e-04\n",
      "Epoch 986/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2031e-04 - val_loss: 2.8214e-04\n",
      "Epoch 987/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2001e-04 - val_loss: 2.8151e-04\n",
      "Epoch 988/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.1971e-04 - val_loss: 2.8087e-04\n",
      "Epoch 989/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1941e-04 - val_loss: 2.8022e-04\n",
      "Epoch 990/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1910e-04 - val_loss: 2.7959e-04\n",
      "Epoch 991/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1880e-04 - val_loss: 2.7896e-04\n",
      "Epoch 992/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1850e-04 - val_loss: 2.7832e-04\n",
      "Epoch 993/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1820e-04 - val_loss: 2.7770e-04\n",
      "Epoch 994/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1790e-04 - val_loss: 2.7707e-04\n",
      "Epoch 995/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.1761e-04 - val_loss: 2.7644e-04\n",
      "Epoch 996/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1731e-04 - val_loss: 2.7581e-04\n",
      "Epoch 997/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1701e-04 - val_loss: 2.7519e-04\n",
      "Epoch 998/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1672e-04 - val_loss: 2.7457e-04\n",
      "Epoch 999/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1643e-04 - val_loss: 2.7394e-04\n",
      "Epoch 1000/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1613e-04 - val_loss: 2.7331e-04\n",
      "0.000160690164193511\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.03381181, -0.3474659 ,  0.3099932 ,  0.04641125, -0.54604703],\n",
       "        [ 1.6053275 ,  1.123105  ,  1.3587947 , -0.01824942,  0.04935107],\n",
       "        [-0.8546664 , -0.38093972, -0.1344669 , -0.0933515 ,  0.06211767]],\n",
       "       dtype=float32),\n",
       " array([-0.4976979 ,  0.20110993, -0.5414311 , -0.6343815 , -0.3522789 ],\n",
       "       dtype=float32),\n",
       " array([[ 0.07417494, -0.41589704,  0.55593395, -0.00704514,  0.51312464,\n",
       "          0.41571623,  0.3063983 ,  0.19992325,  0.16977036,  0.28271267],\n",
       "        [ 0.45295957,  0.16003783, -0.16648567, -0.24375196, -0.51488686,\n",
       "         -0.53548414,  0.5703676 ,  0.5804981 , -0.21556725,  0.21207303],\n",
       "        [ 0.34049514,  0.16236426, -0.35982284, -0.15736818, -0.3317503 ,\n",
       "         -0.2867387 ,  0.31016004, -0.3557103 ,  0.10073322, -0.5229236 ],\n",
       "        [-0.2679118 ,  0.44353116, -0.37480614,  0.3137848 ,  0.3577983 ,\n",
       "         -0.4050256 , -0.5077242 , -0.35024166,  0.4548997 ,  0.353473  ],\n",
       "        [-0.33070466,  0.23976596,  0.14400178,  0.31234246,  0.3524444 ,\n",
       "          0.10685314,  0.16357392,  0.4771747 ,  0.15965363,  0.3617012 ]],\n",
       "       dtype=float32),\n",
       " array([ 0.81597555,  0.7970515 ,  0.79322696, -0.7900967 ,  0.70579445,\n",
       "         0.79157853, -0.80875736,  0.82080245, -0.81571394, -0.8093744 ],\n",
       "       dtype=float32),\n",
       " array([[ 0.67901075],\n",
       "        [ 0.51346785],\n",
       "        [ 0.48664385],\n",
       "        [-0.4923414 ],\n",
       "        [ 0.21785934],\n",
       "        [ 0.5158722 ],\n",
       "        [-0.5878766 ],\n",
       "        [ 0.67262596],\n",
       "        [-0.71796286],\n",
       "        [-0.73432565]], dtype=float32),\n",
       " array([0.86015254], dtype=float32)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_challenger, history_challenger, evaluate_challenger=NN_model_structure_regression_linear(X_train_challenger, X_val_challenger, Y_train_challenger, Y_val_challenger, adam2, 32, 1000, x_test_challenger, y_test_challenger)\n",
    "model_challenger.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_challenger.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_challenger_linear_4th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_40 (Dense)             (None, 5)                 20        \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 91\n",
      "Trainable params: 91\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 32 samples, validate on 7 samples\n",
      "Epoch 1/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 36.1846 - val_loss: 33.2344\n",
      "Epoch 2/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 33.8544 - val_loss: 29.3290\n",
      "Epoch 3/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 30.4727 - val_loss: 24.0637\n",
      "Epoch 4/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 25.8759 - val_loss: 17.7219\n",
      "Epoch 5/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 20.1282 - val_loss: 10.9163\n",
      "Epoch 6/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 13.6183 - val_loss: 4.8216\n",
      "Epoch 7/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.4209 - val_loss: 1.2845\n",
      "Epoch 8/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.3160 - val_loss: 2.6778\n",
      "Epoch 9/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.9055 - val_loss: 7.1492\n",
      "Epoch 10/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.1104 - val_loss: 7.9249\n",
      "Epoch 11/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.1036 - val_loss: 5.7075\n",
      "Epoch 12/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7768 - val_loss: 3.0401\n",
      "Epoch 13/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.7982 - val_loss: 1.4155\n",
      "Epoch 14/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9347 - val_loss: 0.9554\n",
      "Epoch 15/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.3102 - val_loss: 1.2898\n",
      "Epoch 16/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5142 - val_loss: 1.9350\n",
      "Epoch 17/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.0237 - val_loss: 2.5284\n",
      "Epoch 18/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.4546 - val_loss: 2.8703\n",
      "Epoch 19/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6171 - val_loss: 2.8758\n",
      "Epoch 20/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.4565 - val_loss: 2.6125\n",
      "Epoch 21/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.0298 - val_loss: 2.1629\n",
      "Epoch 22/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4719 - val_loss: 1.6384\n",
      "Epoch 23/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.9616 - val_loss: 1.1496\n",
      "Epoch 24/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.6477 - val_loss: 0.7718\n",
      "Epoch 25/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.5882 - val_loss: 0.5327\n",
      "Epoch 26/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.7090 - val_loss: 0.4078\n",
      "Epoch 27/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.8512 - val_loss: 0.3490\n",
      "Epoch 28/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.8961 - val_loss: 0.3171\n",
      "Epoch 29/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.8134 - val_loss: 0.3000\n",
      "Epoch 30/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.6514 - val_loss: 0.3049\n",
      "Epoch 31/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.4777 - val_loss: 0.3356\n",
      "Epoch 32/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.3480 - val_loss: 0.3914\n",
      "Epoch 33/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.2891 - val_loss: 0.4638\n",
      "Epoch 34/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.2936 - val_loss: 0.5388\n",
      "Epoch 35/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.3382 - val_loss: 0.6009\n",
      "Epoch 36/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.3920 - val_loss: 0.6374\n",
      "Epoch 37/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.4297 - val_loss: 0.6415\n",
      "Epoch 38/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.4357 - val_loss: 0.6131\n",
      "Epoch 39/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.4067 - val_loss: 0.5582\n",
      "Epoch 40/1000\n",
      "32/32 [==============================] - 0s 217us/step - loss: 0.3496 - val_loss: 0.4870\n",
      "Epoch 41/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.2781 - val_loss: 0.3981\n",
      "Epoch 42/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.2060 - val_loss: 0.3089\n",
      "Epoch 43/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.1491 - val_loss: 0.2363\n",
      "Epoch 44/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1187 - val_loss: 0.1840\n",
      "Epoch 45/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1151 - val_loss: 0.1497\n",
      "Epoch 46/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.1302 - val_loss: 0.1280\n",
      "Epoch 47/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.1504 - val_loss: 0.1128\n",
      "Epoch 48/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1629 - val_loss: 0.1008\n",
      "Epoch 49/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.1608 - val_loss: 0.0918\n",
      "Epoch 50/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1445 - val_loss: 0.0878\n",
      "Epoch 51/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1203 - val_loss: 0.0908\n",
      "Epoch 52/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0963 - val_loss: 0.1010\n",
      "Epoch 53/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0789 - val_loss: 0.1160\n",
      "Epoch 54/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0704 - val_loss: 0.1319\n",
      "Epoch 55/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0696 - val_loss: 0.1443\n",
      "Epoch 56/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0729 - val_loss: 0.1496\n",
      "Epoch 57/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0763 - val_loss: 0.1461\n",
      "Epoch 58/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0768 - val_loss: 0.1341\n",
      "Epoch 59/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0732 - val_loss: 0.1158\n",
      "Epoch 60/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0660 - val_loss: 0.0946\n",
      "Epoch 61/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0570 - val_loss: 0.0738\n",
      "Epoch 62/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0481 - val_loss: 0.0561\n",
      "Epoch 63/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0411 - val_loss: 0.0431\n",
      "Epoch 64/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0369 - val_loss: 0.0351\n",
      "Epoch 65/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0353 - val_loss: 0.0310\n",
      "Epoch 66/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0355 - val_loss: 0.0293\n",
      "Epoch 67/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0363 - val_loss: 0.0285\n",
      "Epoch 68/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0365 - val_loss: 0.0275\n",
      "Epoch 69/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0355 - val_loss: 0.0257\n",
      "Epoch 70/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0332 - val_loss: 0.0234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0302 - val_loss: 0.0211\n",
      "Epoch 72/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0270 - val_loss: 0.0192\n",
      "Epoch 73/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0243 - val_loss: 0.0181\n",
      "Epoch 74/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0224 - val_loss: 0.0178\n",
      "Epoch 75/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0213 - val_loss: 0.0182\n",
      "Epoch 76/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0208 - val_loss: 0.0188\n",
      "Epoch 77/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0205 - val_loss: 0.0192\n",
      "Epoch 78/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0201 - val_loss: 0.0191\n",
      "Epoch 79/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0194 - val_loss: 0.0183\n",
      "Epoch 80/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0184 - val_loss: 0.0170\n",
      "Epoch 81/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0173 - val_loss: 0.0153\n",
      "Epoch 82/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0162 - val_loss: 0.0134\n",
      "Epoch 83/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0154 - val_loss: 0.0117\n",
      "Epoch 84/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0148 - val_loss: 0.0102\n",
      "Epoch 85/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0145 - val_loss: 0.0090\n",
      "Epoch 86/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0143 - val_loss: 0.0082\n",
      "Epoch 87/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0141 - val_loss: 0.0077\n",
      "Epoch 88/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0138 - val_loss: 0.0074\n",
      "Epoch 89/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0133 - val_loss: 0.0073\n",
      "Epoch 90/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0127 - val_loss: 0.0073\n",
      "Epoch 91/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0121 - val_loss: 0.0074\n",
      "Epoch 92/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0115 - val_loss: 0.0075\n",
      "Epoch 93/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0111 - val_loss: 0.0076\n",
      "Epoch 94/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0108 - val_loss: 0.0076\n",
      "Epoch 95/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0106 - val_loss: 0.0077\n",
      "Epoch 96/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0105 - val_loss: 0.0077\n",
      "Epoch 97/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0104 - val_loss: 0.0076\n",
      "Epoch 98/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0103 - val_loss: 0.0075\n",
      "Epoch 99/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0101 - val_loss: 0.0073\n",
      "Epoch 100/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0098 - val_loss: 0.0071\n",
      "Epoch 101/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0095 - val_loss: 0.0068\n",
      "Epoch 102/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0093 - val_loss: 0.0066\n",
      "Epoch 103/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0090 - val_loss: 0.0063\n",
      "Epoch 104/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0088 - val_loss: 0.0061\n",
      "Epoch 105/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0086 - val_loss: 0.0060\n",
      "Epoch 106/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0085 - val_loss: 0.0058\n",
      "Epoch 107/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0084 - val_loss: 0.0057\n",
      "Epoch 108/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0083 - val_loss: 0.0055\n",
      "Epoch 109/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0082 - val_loss: 0.0055\n",
      "Epoch 110/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0080 - val_loss: 0.0054\n",
      "Epoch 111/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0079 - val_loss: 0.0053\n",
      "Epoch 112/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0078 - val_loss: 0.0053\n",
      "Epoch 113/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0076 - val_loss: 0.0053\n",
      "Epoch 114/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0075 - val_loss: 0.0052\n",
      "Epoch 115/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0074 - val_loss: 0.0052\n",
      "Epoch 116/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 0.0073 - val_loss: 0.0052\n",
      "Epoch 117/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0072 - val_loss: 0.0051\n",
      "Epoch 118/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0071 - val_loss: 0.0051\n",
      "Epoch 119/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0070 - val_loss: 0.0050\n",
      "Epoch 120/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0069 - val_loss: 0.0050\n",
      "Epoch 121/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0069 - val_loss: 0.0049\n",
      "Epoch 122/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0067 - val_loss: 0.0048\n",
      "Epoch 123/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0066 - val_loss: 0.0047\n",
      "Epoch 124/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0065 - val_loss: 0.0046\n",
      "Epoch 125/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0064 - val_loss: 0.0046\n",
      "Epoch 126/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0063 - val_loss: 0.0045\n",
      "Epoch 127/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0062 - val_loss: 0.0045\n",
      "Epoch 128/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0061 - val_loss: 0.0044\n",
      "Epoch 129/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0060 - val_loss: 0.0043\n",
      "Epoch 130/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0059 - val_loss: 0.0043\n",
      "Epoch 131/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0058 - val_loss: 0.0042\n",
      "Epoch 132/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0058 - val_loss: 0.0041\n",
      "Epoch 133/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0057 - val_loss: 0.0040\n",
      "Epoch 134/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0056 - val_loss: 0.0039\n",
      "Epoch 135/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0055 - val_loss: 0.0039\n",
      "Epoch 136/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0054 - val_loss: 0.0038\n",
      "Epoch 137/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0053 - val_loss: 0.0037\n",
      "Epoch 138/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0052 - val_loss: 0.0036\n",
      "Epoch 139/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0052 - val_loss: 0.0036\n",
      "Epoch 140/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0051 - val_loss: 0.0035\n",
      "Epoch 141/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0050 - val_loss: 0.0034\n",
      "Epoch 142/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0049 - val_loss: 0.0034\n",
      "Epoch 143/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0049 - val_loss: 0.0033\n",
      "Epoch 144/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0048 - val_loss: 0.0033\n",
      "Epoch 145/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0047 - val_loss: 0.0032\n",
      "Epoch 146/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0046 - val_loss: 0.0032\n",
      "Epoch 147/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0046 - val_loss: 0.0031\n",
      "Epoch 148/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0045 - val_loss: 0.0031\n",
      "Epoch 149/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0044 - val_loss: 0.0030\n",
      "Epoch 150/1000\n",
      "32/32 [==============================] - 0s 164us/step - loss: 0.0043 - val_loss: 0.0030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0043 - val_loss: 0.0029\n",
      "Epoch 152/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0042 - val_loss: 0.0029\n",
      "Epoch 153/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0041 - val_loss: 0.0028\n",
      "Epoch 154/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0040 - val_loss: 0.0028\n",
      "Epoch 155/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0039 - val_loss: 0.0028\n",
      "Epoch 156/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0039 - val_loss: 0.0027\n",
      "Epoch 157/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0038 - val_loss: 0.0027\n",
      "Epoch 158/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0037 - val_loss: 0.0027\n",
      "Epoch 159/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0036 - val_loss: 0.0026\n",
      "Epoch 160/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 0.0036 - val_loss: 0.0026\n",
      "Epoch 161/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0035 - val_loss: 0.0026\n",
      "Epoch 162/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0034 - val_loss: 0.0025\n",
      "Epoch 163/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0033 - val_loss: 0.0025\n",
      "Epoch 164/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0033 - val_loss: 0.0024\n",
      "Epoch 165/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 0.0024\n",
      "Epoch 166/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0031 - val_loss: 0.0024\n",
      "Epoch 167/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0031 - val_loss: 0.0023\n",
      "Epoch 168/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 0.0030 - val_loss: 0.0023\n",
      "Epoch 169/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 0.0022\n",
      "Epoch 170/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 0.0022\n",
      "Epoch 171/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 172/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 0.0021\n",
      "Epoch 173/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 0.0021\n",
      "Epoch 174/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 0.0021\n",
      "Epoch 175/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0026 - val_loss: 0.0020\n",
      "Epoch 176/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 0.0020\n",
      "Epoch 177/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 0.0020\n",
      "Epoch 178/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 0.0020\n",
      "Epoch 179/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.0019\n",
      "Epoch 180/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0024 - val_loss: 0.0019\n",
      "Epoch 181/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 182/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 183/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 184/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 185/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 186/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 187/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 188/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 189/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 190/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 191/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 192/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 193/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 194/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 195/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 196/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 197/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 198/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 199/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 200/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 201/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 202/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 203/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 204/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 205/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 206/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 207/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 208/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 209/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 210/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 211/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 212/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 213/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 214/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 215/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 216/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 9.8893e-04\n",
      "Epoch 217/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 9.6699e-04\n",
      "Epoch 218/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 9.4554e-04\n",
      "Epoch 219/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 9.2459e-04\n",
      "Epoch 220/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0012 - val_loss: 9.0418e-04\n",
      "Epoch 221/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 8.8427e-04\n",
      "Epoch 222/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 8.6493e-04\n",
      "Epoch 223/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 8.4616e-04\n",
      "Epoch 224/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 8.2796e-04\n",
      "Epoch 225/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 8.1033e-04\n",
      "Epoch 226/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 7.9327e-04\n",
      "Epoch 227/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 7.7680e-04\n",
      "Epoch 228/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 7.6090e-04\n",
      "Epoch 229/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.9377e-04 - val_loss: 7.4558e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 230/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.7759e-04 - val_loss: 7.3077e-04\n",
      "Epoch 231/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 9.6178e-04 - val_loss: 7.1647e-04\n",
      "Epoch 232/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4632e-04 - val_loss: 7.0267e-04\n",
      "Epoch 233/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3123e-04 - val_loss: 6.8931e-04\n",
      "Epoch 234/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1648e-04 - val_loss: 6.7640e-04\n",
      "Epoch 235/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.0246e-04 - val_loss: 6.6380e-04\n",
      "Epoch 236/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.8812e-04 - val_loss: 6.5154e-04\n",
      "Epoch 237/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7448e-04 - val_loss: 6.3962e-04\n",
      "Epoch 238/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.6116e-04 - val_loss: 6.2800e-04\n",
      "Epoch 239/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.4814e-04 - val_loss: 6.1669e-04\n",
      "Epoch 240/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3542e-04 - val_loss: 6.0573e-04\n",
      "Epoch 241/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.2297e-04 - val_loss: 5.9505e-04\n",
      "Epoch 242/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.1077e-04 - val_loss: 5.8473e-04\n",
      "Epoch 243/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.9885e-04 - val_loss: 5.7475e-04\n",
      "Epoch 244/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8719e-04 - val_loss: 5.6513e-04\n",
      "Epoch 245/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.7579e-04 - val_loss: 5.5586e-04\n",
      "Epoch 246/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6466e-04 - val_loss: 5.4694e-04\n",
      "Epoch 247/1000\n",
      "32/32 [==============================] - 0s 118us/step - loss: 7.5379e-04 - val_loss: 5.3836e-04\n",
      "Epoch 248/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.4318e-04 - val_loss: 5.3014e-04\n",
      "Epoch 249/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3282e-04 - val_loss: 5.2220e-04\n",
      "Epoch 250/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2269e-04 - val_loss: 5.1456e-04\n",
      "Epoch 251/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1281e-04 - val_loss: 5.0719e-04\n",
      "Epoch 252/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.0315e-04 - val_loss: 5.0005e-04\n",
      "Epoch 253/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.9370e-04 - val_loss: 4.9311e-04\n",
      "Epoch 254/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8447e-04 - val_loss: 4.8634e-04\n",
      "Epoch 255/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.7545e-04 - val_loss: 4.7976e-04\n",
      "Epoch 256/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.6664e-04 - val_loss: 4.7331e-04\n",
      "Epoch 257/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.5802e-04 - val_loss: 4.6702e-04\n",
      "Epoch 258/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.4960e-04 - val_loss: 4.6084e-04\n",
      "Epoch 259/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4137e-04 - val_loss: 4.5481e-04\n",
      "Epoch 260/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.3332e-04 - val_loss: 4.4893e-04\n",
      "Epoch 261/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.2546e-04 - val_loss: 4.4321e-04\n",
      "Epoch 262/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1778e-04 - val_loss: 4.3765e-04\n",
      "Epoch 263/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.1027e-04 - val_loss: 4.3227e-04\n",
      "Epoch 264/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0293e-04 - val_loss: 4.2707e-04\n",
      "Epoch 265/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.9575e-04 - val_loss: 4.2207e-04\n",
      "Epoch 266/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8874e-04 - val_loss: 4.1725e-04\n",
      "Epoch 267/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.8187e-04 - val_loss: 4.1263e-04\n",
      "Epoch 268/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.7516e-04 - val_loss: 4.0819e-04\n",
      "Epoch 269/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6859e-04 - val_loss: 4.0393e-04\n",
      "Epoch 270/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6218e-04 - val_loss: 3.9982e-04\n",
      "Epoch 271/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5589e-04 - val_loss: 3.9587e-04\n",
      "Epoch 272/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.4976e-04 - val_loss: 3.9205e-04\n",
      "Epoch 273/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4375e-04 - val_loss: 3.8834e-04\n",
      "Epoch 274/1000\n",
      "32/32 [==============================] - 0s 169us/step - loss: 5.3787e-04 - val_loss: 3.8474e-04\n",
      "Epoch 275/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3211e-04 - val_loss: 3.8123e-04\n",
      "Epoch 276/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.2649e-04 - val_loss: 3.7779e-04\n",
      "Epoch 277/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.2098e-04 - val_loss: 3.7442e-04\n",
      "Epoch 278/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1558e-04 - val_loss: 3.7111e-04\n",
      "Epoch 279/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1031e-04 - val_loss: 3.6787e-04\n",
      "Epoch 280/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0514e-04 - val_loss: 3.6468e-04\n",
      "Epoch 281/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0008e-04 - val_loss: 3.6155e-04\n",
      "Epoch 282/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.9513e-04 - val_loss: 3.5848e-04\n",
      "Epoch 283/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9028e-04 - val_loss: 3.5549e-04\n",
      "Epoch 284/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8553e-04 - val_loss: 3.5257e-04\n",
      "Epoch 285/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8088e-04 - val_loss: 3.4972e-04\n",
      "Epoch 286/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7633e-04 - val_loss: 3.4697e-04\n",
      "Epoch 287/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7187e-04 - val_loss: 3.4430e-04\n",
      "Epoch 288/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 4.6749e-04 - val_loss: 3.4172e-04\n",
      "Epoch 289/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6322e-04 - val_loss: 3.3922e-04\n",
      "Epoch 290/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5902e-04 - val_loss: 3.3681e-04\n",
      "Epoch 291/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5491e-04 - val_loss: 3.3447e-04\n",
      "Epoch 292/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.5298e-04 - val_loss: 3.3214e-04\n",
      "Epoch 293/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5158e-04 - val_loss: 3.2980e-04\n",
      "Epoch 294/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5015e-04 - val_loss: 3.2744e-04\n",
      "Epoch 295/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4871e-04 - val_loss: 3.2509e-04\n",
      "Epoch 296/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4725e-04 - val_loss: 3.2280e-04\n",
      "Epoch 297/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4580e-04 - val_loss: 3.2060e-04\n",
      "Epoch 298/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.4437e-04 - val_loss: 3.1854e-04\n",
      "Epoch 299/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.4296e-04 - val_loss: 3.1663e-04\n",
      "Epoch 300/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4158e-04 - val_loss: 3.1490e-04\n",
      "Epoch 301/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.4024e-04 - val_loss: 3.1334e-04\n",
      "Epoch 302/1000\n",
      "32/32 [==============================] - 0s 173us/step - loss: 4.3892e-04 - val_loss: 3.1193e-04\n",
      "Epoch 303/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3763e-04 - val_loss: 3.1066e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 304/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3636e-04 - val_loss: 3.0949e-04\n",
      "Epoch 305/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.3511e-04 - val_loss: 3.0841e-04\n",
      "Epoch 306/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.3388e-04 - val_loss: 3.0737e-04\n",
      "Epoch 307/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.3265e-04 - val_loss: 3.0635e-04\n",
      "Epoch 308/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3144e-04 - val_loss: 3.0535e-04\n",
      "Epoch 309/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3024e-04 - val_loss: 3.0433e-04\n",
      "Epoch 310/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 4.2906e-04 - val_loss: 3.0328e-04\n",
      "Epoch 311/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2789e-04 - val_loss: 3.0222e-04\n",
      "Epoch 312/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.2672e-04 - val_loss: 3.0114e-04\n",
      "Epoch 313/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.2560e-04 - val_loss: 3.0003e-04\n",
      "Epoch 314/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2448e-04 - val_loss: 2.9891e-04\n",
      "Epoch 315/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.2338e-04 - val_loss: 2.9780e-04\n",
      "Epoch 316/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2231e-04 - val_loss: 2.9668e-04\n",
      "Epoch 317/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2125e-04 - val_loss: 2.9561e-04\n",
      "Epoch 318/1000\n",
      "32/32 [==============================] - 0s 160us/step - loss: 4.2021e-04 - val_loss: 2.9456e-04\n",
      "Epoch 319/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.1919e-04 - val_loss: 2.9355e-04\n",
      "Epoch 320/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.1817e-04 - val_loss: 2.9259e-04\n",
      "Epoch 321/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1717e-04 - val_loss: 2.9166e-04\n",
      "Epoch 322/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.1619e-04 - val_loss: 2.9080e-04\n",
      "Epoch 323/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1522e-04 - val_loss: 2.8996e-04\n",
      "Epoch 324/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.1426e-04 - val_loss: 2.8917e-04\n",
      "Epoch 325/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.1331e-04 - val_loss: 2.8839e-04\n",
      "Epoch 326/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.1237e-04 - val_loss: 2.8763e-04\n",
      "Epoch 327/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.1145e-04 - val_loss: 2.8688e-04\n",
      "Epoch 328/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1053e-04 - val_loss: 2.8613e-04\n",
      "Epoch 329/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0963e-04 - val_loss: 2.8537e-04\n",
      "Epoch 330/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.0874e-04 - val_loss: 2.8461e-04\n",
      "Epoch 331/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0787e-04 - val_loss: 2.8383e-04\n",
      "Epoch 332/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.0700e-04 - val_loss: 2.8303e-04\n",
      "Epoch 333/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.0614e-04 - val_loss: 2.8223e-04\n",
      "Epoch 334/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 4.0529e-04 - val_loss: 2.8142e-04\n",
      "Epoch 335/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0446e-04 - val_loss: 2.8060e-04\n",
      "Epoch 336/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.0363e-04 - val_loss: 2.7979e-04\n",
      "Epoch 337/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0280e-04 - val_loss: 2.7899e-04\n",
      "Epoch 338/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0199e-04 - val_loss: 2.7819e-04\n",
      "Epoch 339/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.0119e-04 - val_loss: 2.7742e-04\n",
      "Epoch 340/1000\n",
      "32/32 [==============================] - 0s 133us/step - loss: 4.0040e-04 - val_loss: 2.7665e-04\n",
      "Epoch 341/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.9961e-04 - val_loss: 2.7590e-04\n",
      "Epoch 342/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.9883e-04 - val_loss: 2.7516e-04\n",
      "Epoch 343/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.9806e-04 - val_loss: 2.7446e-04\n",
      "Epoch 344/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9730e-04 - val_loss: 2.7375e-04\n",
      "Epoch 345/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.9654e-04 - val_loss: 2.7307e-04\n",
      "Epoch 346/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.9579e-04 - val_loss: 2.7239e-04\n",
      "Epoch 347/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9505e-04 - val_loss: 2.7171e-04\n",
      "Epoch 348/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9432e-04 - val_loss: 2.7104e-04\n",
      "Epoch 349/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.9359e-04 - val_loss: 2.7038e-04\n",
      "Epoch 350/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9287e-04 - val_loss: 2.6973e-04\n",
      "Epoch 351/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9216e-04 - val_loss: 2.6907e-04\n",
      "Epoch 352/1000\n",
      "32/32 [==============================] - 0s 130us/step - loss: 3.9145e-04 - val_loss: 2.6844e-04\n",
      "Epoch 353/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9076e-04 - val_loss: 2.6780e-04\n",
      "Epoch 354/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.9006e-04 - val_loss: 2.6716e-04\n",
      "Epoch 355/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8937e-04 - val_loss: 2.6655e-04\n",
      "Epoch 356/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 3.8869e-04 - val_loss: 2.6594e-04\n",
      "Epoch 357/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.8801e-04 - val_loss: 2.6534e-04\n",
      "Epoch 358/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8734e-04 - val_loss: 2.6476e-04\n",
      "Epoch 359/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.8668e-04 - val_loss: 2.6418e-04\n",
      "Epoch 360/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 3.8602e-04 - val_loss: 2.6362e-04\n",
      "Epoch 361/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8536e-04 - val_loss: 2.6307e-04\n",
      "Epoch 362/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.8471e-04 - val_loss: 2.6253e-04\n",
      "Epoch 363/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8406e-04 - val_loss: 2.6200e-04\n",
      "Epoch 364/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 3.8342e-04 - val_loss: 2.6147e-04\n",
      "Epoch 365/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.8279e-04 - val_loss: 2.6097e-04\n",
      "Epoch 366/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8217e-04 - val_loss: 2.6044e-04\n",
      "Epoch 367/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8154e-04 - val_loss: 2.5994e-04\n",
      "Epoch 368/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8092e-04 - val_loss: 2.5943e-04\n",
      "Epoch 369/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.8030e-04 - val_loss: 2.5893e-04\n",
      "Epoch 370/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7969e-04 - val_loss: 2.5842e-04\n",
      "Epoch 371/1000\n",
      "32/32 [==============================] - 0s 177us/step - loss: 3.7908e-04 - val_loss: 2.5792e-04\n",
      "Epoch 372/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.7848e-04 - val_loss: 2.5743e-04\n",
      "Epoch 373/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7788e-04 - val_loss: 2.5695e-04\n",
      "Epoch 374/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7729e-04 - val_loss: 2.5647e-04\n",
      "Epoch 375/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7670e-04 - val_loss: 2.5599e-04\n",
      "Epoch 376/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.7611e-04 - val_loss: 2.5553e-04\n",
      "Epoch 377/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.7553e-04 - val_loss: 2.5507e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 378/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7495e-04 - val_loss: 2.5461e-04\n",
      "Epoch 379/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 3.7438e-04 - val_loss: 2.5416e-04\n",
      "Epoch 380/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.7380e-04 - val_loss: 2.5372e-04\n",
      "Epoch 381/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.7323e-04 - val_loss: 2.5328e-04\n",
      "Epoch 382/1000\n",
      "32/32 [==============================] - 0s 171us/step - loss: 3.7267e-04 - val_loss: 2.5285e-04\n",
      "Epoch 383/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7211e-04 - val_loss: 2.5243e-04\n",
      "Epoch 384/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 3.7155e-04 - val_loss: 2.5201e-04\n",
      "Epoch 385/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.7099e-04 - val_loss: 2.5159e-04\n",
      "Epoch 386/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.7045e-04 - val_loss: 2.5117e-04\n",
      "Epoch 387/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6990e-04 - val_loss: 2.5077e-04\n",
      "Epoch 388/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6936e-04 - val_loss: 2.5036e-04\n",
      "Epoch 389/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 3.6882e-04 - val_loss: 2.4996e-04\n",
      "Epoch 390/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 3.6828e-04 - val_loss: 2.4956e-04\n",
      "Epoch 391/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6775e-04 - val_loss: 2.4916e-04\n",
      "Epoch 392/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6721e-04 - val_loss: 2.4877e-04\n",
      "Epoch 393/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6668e-04 - val_loss: 2.4837e-04\n",
      "Epoch 394/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.6616e-04 - val_loss: 2.4797e-04\n",
      "Epoch 395/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6563e-04 - val_loss: 2.4759e-04\n",
      "Epoch 396/1000\n",
      "32/32 [==============================] - 0s 160us/step - loss: 3.6512e-04 - val_loss: 2.4720e-04\n",
      "Epoch 397/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.6460e-04 - val_loss: 2.4683e-04\n",
      "Epoch 398/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6409e-04 - val_loss: 2.4644e-04\n",
      "Epoch 399/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6358e-04 - val_loss: 2.4605e-04\n",
      "Epoch 400/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6306e-04 - val_loss: 2.4568e-04\n",
      "Epoch 401/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6256e-04 - val_loss: 2.4530e-04\n",
      "Epoch 402/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6206e-04 - val_loss: 2.4493e-04\n",
      "Epoch 403/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6155e-04 - val_loss: 2.4457e-04\n",
      "Epoch 404/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6105e-04 - val_loss: 2.4421e-04\n",
      "Epoch 405/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6056e-04 - val_loss: 2.4385e-04\n",
      "Epoch 406/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6007e-04 - val_loss: 2.4348e-04\n",
      "Epoch 407/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 3.5957e-04 - val_loss: 2.4313e-04\n",
      "Epoch 408/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5908e-04 - val_loss: 2.4277e-04\n",
      "Epoch 409/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5860e-04 - val_loss: 2.4241e-04\n",
      "Epoch 410/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5811e-04 - val_loss: 2.4206e-04\n",
      "Epoch 411/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5762e-04 - val_loss: 2.4171e-04\n",
      "Epoch 412/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5714e-04 - val_loss: 2.4136e-04\n",
      "Epoch 413/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5668e-04 - val_loss: 2.4102e-04\n",
      "Epoch 414/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5620e-04 - val_loss: 2.4067e-04\n",
      "Epoch 415/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5572e-04 - val_loss: 2.4033e-04\n",
      "Epoch 416/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5526e-04 - val_loss: 2.3999e-04\n",
      "Epoch 417/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5478e-04 - val_loss: 2.3965e-04\n",
      "Epoch 418/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5431e-04 - val_loss: 2.3930e-04\n",
      "Epoch 419/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5385e-04 - val_loss: 2.3897e-04\n",
      "Epoch 420/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5339e-04 - val_loss: 2.3864e-04\n",
      "Epoch 421/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5293e-04 - val_loss: 2.3831e-04\n",
      "Epoch 422/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5247e-04 - val_loss: 2.3798e-04\n",
      "Epoch 423/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5201e-04 - val_loss: 2.3765e-04\n",
      "Epoch 424/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.5155e-04 - val_loss: 2.3733e-04\n",
      "Epoch 425/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5111e-04 - val_loss: 2.3699e-04\n",
      "Epoch 426/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5065e-04 - val_loss: 2.3667e-04\n",
      "Epoch 427/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.5021e-04 - val_loss: 2.3635e-04\n",
      "Epoch 428/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4976e-04 - val_loss: 2.3602e-04\n",
      "Epoch 429/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4931e-04 - val_loss: 2.3571e-04\n",
      "Epoch 430/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4887e-04 - val_loss: 2.3539e-04\n",
      "Epoch 431/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4843e-04 - val_loss: 2.3506e-04\n",
      "Epoch 432/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4799e-04 - val_loss: 2.3475e-04\n",
      "Epoch 433/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.4755e-04 - val_loss: 2.3443e-04\n",
      "Epoch 434/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4711e-04 - val_loss: 2.3412e-04\n",
      "Epoch 435/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4668e-04 - val_loss: 2.3381e-04\n",
      "Epoch 436/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4625e-04 - val_loss: 2.3350e-04\n",
      "Epoch 437/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4582e-04 - val_loss: 2.3318e-04\n",
      "Epoch 438/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.4538e-04 - val_loss: 2.3289e-04\n",
      "Epoch 439/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4497e-04 - val_loss: 2.3257e-04\n",
      "Epoch 440/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4454e-04 - val_loss: 2.3228e-04\n",
      "Epoch 441/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.4411e-04 - val_loss: 2.3197e-04\n",
      "Epoch 442/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4369e-04 - val_loss: 2.3167e-04\n",
      "Epoch 443/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4327e-04 - val_loss: 2.3137e-04\n",
      "Epoch 444/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4284e-04 - val_loss: 2.3107e-04\n",
      "Epoch 445/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4243e-04 - val_loss: 2.3077e-04\n",
      "Epoch 446/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 3.4201e-04 - val_loss: 2.3048e-04\n",
      "Epoch 447/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.4160e-04 - val_loss: 2.3018e-04\n",
      "Epoch 448/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4119e-04 - val_loss: 2.2989e-04\n",
      "Epoch 449/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4078e-04 - val_loss: 2.2959e-04\n",
      "Epoch 450/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 3.4036e-04 - val_loss: 2.2930e-04\n",
      "Epoch 451/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3996e-04 - val_loss: 2.2901e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 452/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3955e-04 - val_loss: 2.2873e-04\n",
      "Epoch 453/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3914e-04 - val_loss: 2.2843e-04\n",
      "Epoch 454/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3874e-04 - val_loss: 2.2815e-04\n",
      "Epoch 455/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3834e-04 - val_loss: 2.2786e-04\n",
      "Epoch 456/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3793e-04 - val_loss: 2.2758e-04\n",
      "Epoch 457/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.3754e-04 - val_loss: 2.2731e-04\n",
      "Epoch 458/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3714e-04 - val_loss: 2.2701e-04\n",
      "Epoch 459/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3674e-04 - val_loss: 2.2674e-04\n",
      "Epoch 460/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.3634e-04 - val_loss: 2.2646e-04\n",
      "Epoch 461/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3595e-04 - val_loss: 2.2619e-04\n",
      "Epoch 462/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3556e-04 - val_loss: 2.2590e-04\n",
      "Epoch 463/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.3516e-04 - val_loss: 2.2563e-04\n",
      "Epoch 464/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3478e-04 - val_loss: 2.2536e-04\n",
      "Epoch 465/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3438e-04 - val_loss: 2.2509e-04\n",
      "Epoch 466/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 3.3400e-04 - val_loss: 2.2481e-04\n",
      "Epoch 467/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3361e-04 - val_loss: 2.2455e-04\n",
      "Epoch 468/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3323e-04 - val_loss: 2.2427e-04\n",
      "Epoch 469/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3284e-04 - val_loss: 2.2400e-04\n",
      "Epoch 470/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3246e-04 - val_loss: 2.2373e-04\n",
      "Epoch 471/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3208e-04 - val_loss: 2.2346e-04\n",
      "Epoch 472/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3170e-04 - val_loss: 2.2320e-04\n",
      "Epoch 473/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3132e-04 - val_loss: 2.2293e-04\n",
      "Epoch 474/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3095e-04 - val_loss: 2.2267e-04\n",
      "Epoch 475/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3057e-04 - val_loss: 2.2241e-04\n",
      "Epoch 476/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3020e-04 - val_loss: 2.2215e-04\n",
      "Epoch 477/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2982e-04 - val_loss: 2.2188e-04\n",
      "Epoch 478/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.2945e-04 - val_loss: 2.2163e-04\n",
      "Epoch 479/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2907e-04 - val_loss: 2.2137e-04\n",
      "Epoch 480/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2870e-04 - val_loss: 2.2111e-04\n",
      "Epoch 481/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2833e-04 - val_loss: 2.2086e-04\n",
      "Epoch 482/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2797e-04 - val_loss: 2.2060e-04\n",
      "Epoch 483/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2760e-04 - val_loss: 2.2035e-04\n",
      "Epoch 484/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2724e-04 - val_loss: 2.2010e-04\n",
      "Epoch 485/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2687e-04 - val_loss: 2.1985e-04\n",
      "Epoch 486/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2651e-04 - val_loss: 2.1960e-04\n",
      "Epoch 487/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2615e-04 - val_loss: 2.1934e-04\n",
      "Epoch 488/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.2578e-04 - val_loss: 2.1910e-04\n",
      "Epoch 489/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2543e-04 - val_loss: 2.1884e-04\n",
      "Epoch 490/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2507e-04 - val_loss: 2.1860e-04\n",
      "Epoch 491/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2471e-04 - val_loss: 2.1836e-04\n",
      "Epoch 492/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2435e-04 - val_loss: 2.1811e-04\n",
      "Epoch 493/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.2400e-04 - val_loss: 2.1787e-04\n",
      "Epoch 494/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2364e-04 - val_loss: 2.1763e-04\n",
      "Epoch 495/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 3.2329e-04 - val_loss: 2.1738e-04\n",
      "Epoch 496/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2294e-04 - val_loss: 2.1714e-04\n",
      "Epoch 497/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2258e-04 - val_loss: 2.1690e-04\n",
      "Epoch 498/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2224e-04 - val_loss: 2.1665e-04\n",
      "Epoch 499/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.2193e-04 - val_loss: 2.1643e-04\n",
      "Epoch 500/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2169e-04 - val_loss: 2.1617e-04\n",
      "Epoch 501/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2144e-04 - val_loss: 2.1594e-04\n",
      "Epoch 502/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2120e-04 - val_loss: 2.1570e-04\n",
      "Epoch 503/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2096e-04 - val_loss: 2.1545e-04\n",
      "Epoch 504/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 3.2072e-04 - val_loss: 2.1521e-04\n",
      "Epoch 505/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.2048e-04 - val_loss: 2.1497e-04\n",
      "Epoch 506/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2024e-04 - val_loss: 2.1475e-04\n",
      "Epoch 507/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2000e-04 - val_loss: 2.1453e-04\n",
      "Epoch 508/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 3.1977e-04 - val_loss: 2.1433e-04\n",
      "Epoch 509/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1953e-04 - val_loss: 2.1415e-04\n",
      "Epoch 510/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1931e-04 - val_loss: 2.1397e-04\n",
      "Epoch 511/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1907e-04 - val_loss: 2.1383e-04\n",
      "Epoch 512/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1885e-04 - val_loss: 2.1370e-04\n",
      "Epoch 513/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1861e-04 - val_loss: 2.1360e-04\n",
      "Epoch 514/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 3.1839e-04 - val_loss: 2.1351e-04\n",
      "Epoch 515/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.1816e-04 - val_loss: 2.1344e-04\n",
      "Epoch 516/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1793e-04 - val_loss: 2.1338e-04\n",
      "Epoch 517/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1771e-04 - val_loss: 2.1331e-04\n",
      "Epoch 518/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1748e-04 - val_loss: 2.1325e-04\n",
      "Epoch 519/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1726e-04 - val_loss: 2.1320e-04\n",
      "Epoch 520/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1704e-04 - val_loss: 2.1314e-04\n",
      "Epoch 521/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1681e-04 - val_loss: 2.1306e-04\n",
      "Epoch 522/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1660e-04 - val_loss: 2.1299e-04\n",
      "Epoch 523/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1638e-04 - val_loss: 2.1291e-04\n",
      "Epoch 524/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1616e-04 - val_loss: 2.1281e-04\n",
      "Epoch 525/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1594e-04 - val_loss: 2.1270e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 526/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1573e-04 - val_loss: 2.1259e-04\n",
      "Epoch 527/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1551e-04 - val_loss: 2.1248e-04\n",
      "Epoch 528/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1529e-04 - val_loss: 2.1235e-04\n",
      "Epoch 529/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1508e-04 - val_loss: 2.1223e-04\n",
      "Epoch 530/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1487e-04 - val_loss: 2.1211e-04\n",
      "Epoch 531/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1465e-04 - val_loss: 2.1200e-04\n",
      "Epoch 532/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.1444e-04 - val_loss: 2.1189e-04\n",
      "Epoch 533/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.1422e-04 - val_loss: 2.1178e-04\n",
      "Epoch 534/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1401e-04 - val_loss: 2.1168e-04\n",
      "Epoch 535/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1380e-04 - val_loss: 2.1159e-04\n",
      "Epoch 536/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1359e-04 - val_loss: 2.1148e-04\n",
      "Epoch 537/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1338e-04 - val_loss: 2.1140e-04\n",
      "Epoch 538/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1317e-04 - val_loss: 2.1130e-04\n",
      "Epoch 539/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.1296e-04 - val_loss: 2.1121e-04\n",
      "Epoch 540/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1276e-04 - val_loss: 2.1112e-04\n",
      "Epoch 541/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1254e-04 - val_loss: 2.1102e-04\n",
      "Epoch 542/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.1234e-04 - val_loss: 2.1093e-04\n",
      "Epoch 543/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1213e-04 - val_loss: 2.1082e-04\n",
      "Epoch 544/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1193e-04 - val_loss: 2.1071e-04\n",
      "Epoch 545/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1172e-04 - val_loss: 2.1059e-04\n",
      "Epoch 546/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1152e-04 - val_loss: 2.1048e-04\n",
      "Epoch 547/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1131e-04 - val_loss: 2.1035e-04\n",
      "Epoch 548/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1111e-04 - val_loss: 2.1023e-04\n",
      "Epoch 549/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1090e-04 - val_loss: 2.1010e-04\n",
      "Epoch 550/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.1070e-04 - val_loss: 2.0997e-04\n",
      "Epoch 551/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1050e-04 - val_loss: 2.0984e-04\n",
      "Epoch 552/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.1029e-04 - val_loss: 2.0971e-04\n",
      "Epoch 553/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1010e-04 - val_loss: 2.0957e-04\n",
      "Epoch 554/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0989e-04 - val_loss: 2.0944e-04\n",
      "Epoch 555/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0969e-04 - val_loss: 2.0930e-04\n",
      "Epoch 556/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0949e-04 - val_loss: 2.0917e-04\n",
      "Epoch 557/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0929e-04 - val_loss: 2.0903e-04\n",
      "Epoch 558/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0908e-04 - val_loss: 2.0890e-04\n",
      "Epoch 559/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.0888e-04 - val_loss: 2.0876e-04\n",
      "Epoch 560/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0869e-04 - val_loss: 2.0862e-04\n",
      "Epoch 561/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0849e-04 - val_loss: 2.0849e-04\n",
      "Epoch 562/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.0829e-04 - val_loss: 2.0834e-04\n",
      "Epoch 563/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0808e-04 - val_loss: 2.0820e-04\n",
      "Epoch 564/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0789e-04 - val_loss: 2.0806e-04\n",
      "Epoch 565/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.0769e-04 - val_loss: 2.0792e-04\n",
      "Epoch 566/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0749e-04 - val_loss: 2.0778e-04\n",
      "Epoch 567/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0729e-04 - val_loss: 2.0763e-04\n",
      "Epoch 568/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0709e-04 - val_loss: 2.0748e-04\n",
      "Epoch 569/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0690e-04 - val_loss: 2.0734e-04\n",
      "Epoch 570/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.0670e-04 - val_loss: 2.0719e-04\n",
      "Epoch 571/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.0651e-04 - val_loss: 2.0704e-04\n",
      "Epoch 572/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0631e-04 - val_loss: 2.0689e-04\n",
      "Epoch 573/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.0612e-04 - val_loss: 2.0674e-04\n",
      "Epoch 574/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.0592e-04 - val_loss: 2.0660e-04\n",
      "Epoch 575/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0572e-04 - val_loss: 2.0643e-04\n",
      "Epoch 576/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0553e-04 - val_loss: 2.0629e-04\n",
      "Epoch 577/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.0533e-04 - val_loss: 2.0613e-04\n",
      "Epoch 578/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0514e-04 - val_loss: 2.0598e-04\n",
      "Epoch 579/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0494e-04 - val_loss: 2.0583e-04\n",
      "Epoch 580/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0475e-04 - val_loss: 2.0567e-04\n",
      "Epoch 581/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.0456e-04 - val_loss: 2.0552e-04\n",
      "Epoch 582/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.0436e-04 - val_loss: 2.0537e-04\n",
      "Epoch 583/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0416e-04 - val_loss: 2.0521e-04\n",
      "Epoch 584/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0397e-04 - val_loss: 2.0506e-04\n",
      "Epoch 585/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0378e-04 - val_loss: 2.0490e-04\n",
      "Epoch 586/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0359e-04 - val_loss: 2.0475e-04\n",
      "Epoch 587/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0340e-04 - val_loss: 2.0459e-04\n",
      "Epoch 588/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0320e-04 - val_loss: 2.0444e-04\n",
      "Epoch 589/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0301e-04 - val_loss: 2.0429e-04\n",
      "Epoch 590/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0282e-04 - val_loss: 2.0413e-04\n",
      "Epoch 591/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.0262e-04 - val_loss: 2.0399e-04\n",
      "Epoch 592/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0243e-04 - val_loss: 2.0383e-04\n",
      "Epoch 593/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0224e-04 - val_loss: 2.0367e-04\n",
      "Epoch 594/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0205e-04 - val_loss: 2.0352e-04\n",
      "Epoch 595/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0186e-04 - val_loss: 2.0337e-04\n",
      "Epoch 596/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0167e-04 - val_loss: 2.0321e-04\n",
      "Epoch 597/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0147e-04 - val_loss: 2.0307e-04\n",
      "Epoch 598/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0128e-04 - val_loss: 2.0292e-04\n",
      "Epoch 599/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.0110e-04 - val_loss: 2.0276e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 600/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0090e-04 - val_loss: 2.0261e-04\n",
      "Epoch 601/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0071e-04 - val_loss: 2.0245e-04\n",
      "Epoch 602/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0052e-04 - val_loss: 2.0229e-04\n",
      "Epoch 603/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0033e-04 - val_loss: 2.0214e-04\n",
      "Epoch 604/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0015e-04 - val_loss: 2.0199e-04\n",
      "Epoch 605/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9995e-04 - val_loss: 2.0183e-04\n",
      "Epoch 606/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9976e-04 - val_loss: 2.0169e-04\n",
      "Epoch 607/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 2.9958e-04 - val_loss: 2.0153e-04\n",
      "Epoch 608/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.9938e-04 - val_loss: 2.0138e-04\n",
      "Epoch 609/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9920e-04 - val_loss: 2.0123e-04\n",
      "Epoch 610/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9901e-04 - val_loss: 2.0109e-04\n",
      "Epoch 611/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9882e-04 - val_loss: 2.0093e-04\n",
      "Epoch 612/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9863e-04 - val_loss: 2.0079e-04\n",
      "Epoch 613/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.9844e-04 - val_loss: 2.0063e-04\n",
      "Epoch 614/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9825e-04 - val_loss: 2.0048e-04\n",
      "Epoch 615/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9807e-04 - val_loss: 2.0033e-04\n",
      "Epoch 616/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9788e-04 - val_loss: 2.0017e-04\n",
      "Epoch 617/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 2.9769e-04 - val_loss: 2.0003e-04\n",
      "Epoch 618/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.9750e-04 - val_loss: 1.9989e-04\n",
      "Epoch 619/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.9732e-04 - val_loss: 1.9973e-04\n",
      "Epoch 620/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 2.9712e-04 - val_loss: 1.9958e-04\n",
      "Epoch 621/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9703e-04 - val_loss: 1.9932e-04\n",
      "Epoch 622/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9679e-04 - val_loss: 1.9911e-04\n",
      "Epoch 623/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.9666e-04 - val_loss: 1.9896e-04\n",
      "Epoch 624/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.9653e-04 - val_loss: 1.9888e-04\n",
      "Epoch 625/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.9640e-04 - val_loss: 1.9888e-04\n",
      "Epoch 626/1000\n",
      "32/32 [==============================] - 0s 219us/step - loss: 2.9625e-04 - val_loss: 1.9893e-04\n",
      "Epoch 627/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 2.9609e-04 - val_loss: 1.9905e-04\n",
      "Epoch 628/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9592e-04 - val_loss: 1.9922e-04\n",
      "Epoch 629/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9574e-04 - val_loss: 1.9942e-04\n",
      "Epoch 630/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.9556e-04 - val_loss: 1.9965e-04\n",
      "Epoch 631/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.9538e-04 - val_loss: 1.9987e-04\n",
      "Epoch 632/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9520e-04 - val_loss: 2.0009e-04\n",
      "Epoch 633/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9503e-04 - val_loss: 2.0029e-04\n",
      "Epoch 634/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9486e-04 - val_loss: 2.0044e-04\n",
      "Epoch 635/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9469e-04 - val_loss: 2.0055e-04\n",
      "Epoch 636/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9453e-04 - val_loss: 2.0057e-04\n",
      "Epoch 637/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 2.9435e-04 - val_loss: 2.0054e-04\n",
      "Epoch 638/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.9417e-04 - val_loss: 2.0042e-04\n",
      "Epoch 639/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9399e-04 - val_loss: 2.0024e-04\n",
      "Epoch 640/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.9380e-04 - val_loss: 2.0000e-04\n",
      "Epoch 641/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9361e-04 - val_loss: 1.9970e-04\n",
      "Epoch 642/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9342e-04 - val_loss: 1.9938e-04\n",
      "Epoch 643/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 2.9324e-04 - val_loss: 1.9903e-04\n",
      "Epoch 644/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9305e-04 - val_loss: 1.9869e-04\n",
      "Epoch 645/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9286e-04 - val_loss: 1.9835e-04\n",
      "Epoch 646/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9268e-04 - val_loss: 1.9803e-04\n",
      "Epoch 647/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9249e-04 - val_loss: 1.9775e-04\n",
      "Epoch 648/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.9231e-04 - val_loss: 1.9751e-04\n",
      "Epoch 649/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9213e-04 - val_loss: 1.9730e-04\n",
      "Epoch 650/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9194e-04 - val_loss: 1.9714e-04\n",
      "Epoch 651/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9175e-04 - val_loss: 1.9701e-04\n",
      "Epoch 652/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9156e-04 - val_loss: 1.9690e-04\n",
      "Epoch 653/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9137e-04 - val_loss: 1.9681e-04\n",
      "Epoch 654/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9118e-04 - val_loss: 1.9674e-04\n",
      "Epoch 655/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9100e-04 - val_loss: 1.9665e-04\n",
      "Epoch 656/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9081e-04 - val_loss: 1.9656e-04\n",
      "Epoch 657/1000\n",
      "32/32 [==============================] - 0s 122us/step - loss: 2.9063e-04 - val_loss: 1.9645e-04\n",
      "Epoch 658/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.9044e-04 - val_loss: 1.9630e-04\n",
      "Epoch 659/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9026e-04 - val_loss: 1.9614e-04\n",
      "Epoch 660/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 2.9007e-04 - val_loss: 1.9595e-04\n",
      "Epoch 661/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8989e-04 - val_loss: 1.9573e-04\n",
      "Epoch 662/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8970e-04 - val_loss: 1.9549e-04\n",
      "Epoch 663/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8952e-04 - val_loss: 1.9524e-04\n",
      "Epoch 664/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8934e-04 - val_loss: 1.9498e-04\n",
      "Epoch 665/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8915e-04 - val_loss: 1.9471e-04\n",
      "Epoch 666/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.8897e-04 - val_loss: 1.9445e-04\n",
      "Epoch 667/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8878e-04 - val_loss: 1.9420e-04\n",
      "Epoch 668/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8860e-04 - val_loss: 1.9394e-04\n",
      "Epoch 669/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8841e-04 - val_loss: 1.9372e-04\n",
      "Epoch 670/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8823e-04 - val_loss: 1.9351e-04\n",
      "Epoch 671/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8805e-04 - val_loss: 1.9331e-04\n",
      "Epoch 672/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8787e-04 - val_loss: 1.9313e-04\n",
      "Epoch 673/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8769e-04 - val_loss: 1.9295e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 674/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8750e-04 - val_loss: 1.9279e-04\n",
      "Epoch 675/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8765e-04 - val_loss: 1.9254e-04\n",
      "Epoch 676/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8720e-04 - val_loss: 1.9235e-04\n",
      "Epoch 677/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8707e-04 - val_loss: 1.9223e-04\n",
      "Epoch 678/1000\n",
      "32/32 [==============================] - 0s 132us/step - loss: 2.8696e-04 - val_loss: 1.9217e-04\n",
      "Epoch 679/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8683e-04 - val_loss: 1.9217e-04\n",
      "Epoch 680/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8669e-04 - val_loss: 1.9224e-04\n",
      "Epoch 681/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8653e-04 - val_loss: 1.9236e-04\n",
      "Epoch 682/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 2.8637e-04 - val_loss: 1.9251e-04\n",
      "Epoch 683/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.8619e-04 - val_loss: 1.9271e-04\n",
      "Epoch 684/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8602e-04 - val_loss: 1.9291e-04\n",
      "Epoch 685/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8585e-04 - val_loss: 1.9312e-04\n",
      "Epoch 686/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8568e-04 - val_loss: 1.9331e-04\n",
      "Epoch 687/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8552e-04 - val_loss: 1.9347e-04\n",
      "Epoch 688/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8536e-04 - val_loss: 1.9358e-04\n",
      "Epoch 689/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8519e-04 - val_loss: 1.9362e-04\n",
      "Epoch 690/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8503e-04 - val_loss: 1.9360e-04\n",
      "Epoch 691/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8486e-04 - val_loss: 1.9352e-04\n",
      "Epoch 692/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8468e-04 - val_loss: 1.9335e-04\n",
      "Epoch 693/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8450e-04 - val_loss: 1.9312e-04\n",
      "Epoch 694/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8431e-04 - val_loss: 1.9284e-04\n",
      "Epoch 695/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8413e-04 - val_loss: 1.9251e-04\n",
      "Epoch 696/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8395e-04 - val_loss: 1.9215e-04\n",
      "Epoch 697/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8377e-04 - val_loss: 1.9180e-04\n",
      "Epoch 698/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.8359e-04 - val_loss: 1.9144e-04\n",
      "Epoch 699/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8341e-04 - val_loss: 1.9110e-04\n",
      "Epoch 700/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8322e-04 - val_loss: 1.9079e-04\n",
      "Epoch 701/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8304e-04 - val_loss: 1.9051e-04\n",
      "Epoch 702/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8286e-04 - val_loss: 1.9028e-04\n",
      "Epoch 703/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8268e-04 - val_loss: 1.9010e-04\n",
      "Epoch 704/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8250e-04 - val_loss: 1.8994e-04\n",
      "Epoch 705/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.8231e-04 - val_loss: 1.8982e-04\n",
      "Epoch 706/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8213e-04 - val_loss: 1.8972e-04\n",
      "Epoch 707/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8195e-04 - val_loss: 1.8964e-04\n",
      "Epoch 708/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8177e-04 - val_loss: 1.8955e-04\n",
      "Epoch 709/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8158e-04 - val_loss: 1.8946e-04\n",
      "Epoch 710/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8140e-04 - val_loss: 1.8935e-04\n",
      "Epoch 711/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8122e-04 - val_loss: 1.8922e-04\n",
      "Epoch 712/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8104e-04 - val_loss: 1.8906e-04\n",
      "Epoch 713/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8086e-04 - val_loss: 1.8887e-04\n",
      "Epoch 714/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8068e-04 - val_loss: 1.8866e-04\n",
      "Epoch 715/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8050e-04 - val_loss: 1.8843e-04\n",
      "Epoch 716/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8032e-04 - val_loss: 1.8819e-04\n",
      "Epoch 717/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8014e-04 - val_loss: 1.8792e-04\n",
      "Epoch 718/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.7996e-04 - val_loss: 1.8766e-04\n",
      "Epoch 719/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7978e-04 - val_loss: 1.8740e-04\n",
      "Epoch 720/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.7961e-04 - val_loss: 1.8714e-04\n",
      "Epoch 721/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7942e-04 - val_loss: 1.8690e-04\n",
      "Epoch 722/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7925e-04 - val_loss: 1.8668e-04\n",
      "Epoch 723/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.7912e-04 - val_loss: 1.8641e-04\n",
      "Epoch 724/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7895e-04 - val_loss: 1.8622e-04\n",
      "Epoch 725/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7884e-04 - val_loss: 1.8609e-04\n",
      "Epoch 726/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7873e-04 - val_loss: 1.8604e-04\n",
      "Epoch 727/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.7861e-04 - val_loss: 1.8607e-04\n",
      "Epoch 728/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7848e-04 - val_loss: 1.8616e-04\n",
      "Epoch 729/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.7833e-04 - val_loss: 1.8629e-04\n",
      "Epoch 730/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7816e-04 - val_loss: 1.8649e-04\n",
      "Epoch 731/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.7799e-04 - val_loss: 1.8671e-04\n",
      "Epoch 732/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7782e-04 - val_loss: 1.8694e-04\n",
      "Epoch 733/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.7765e-04 - val_loss: 1.8717e-04\n",
      "Epoch 734/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.7748e-04 - val_loss: 1.8738e-04\n",
      "Epoch 735/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7733e-04 - val_loss: 1.8754e-04\n",
      "Epoch 736/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7717e-04 - val_loss: 1.8766e-04\n",
      "Epoch 737/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7701e-04 - val_loss: 1.8771e-04\n",
      "Epoch 738/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7685e-04 - val_loss: 1.8767e-04\n",
      "Epoch 739/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7668e-04 - val_loss: 1.8757e-04\n",
      "Epoch 740/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7651e-04 - val_loss: 1.8738e-04\n",
      "Epoch 741/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.7633e-04 - val_loss: 1.8713e-04\n",
      "Epoch 742/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7615e-04 - val_loss: 1.8682e-04\n",
      "Epoch 743/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7597e-04 - val_loss: 1.8647e-04\n",
      "Epoch 744/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7578e-04 - val_loss: 1.8609e-04\n",
      "Epoch 745/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 2.7561e-04 - val_loss: 1.8571e-04\n",
      "Epoch 746/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 2.7543e-04 - val_loss: 1.8535e-04\n",
      "Epoch 747/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.7525e-04 - val_loss: 1.8500e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 748/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.7508e-04 - val_loss: 1.8469e-04\n",
      "Epoch 749/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.7490e-04 - val_loss: 1.8442e-04\n",
      "Epoch 750/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.7472e-04 - val_loss: 1.8421e-04\n",
      "Epoch 751/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.7454e-04 - val_loss: 1.8402e-04\n",
      "Epoch 752/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7436e-04 - val_loss: 1.8388e-04\n",
      "Epoch 753/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.7418e-04 - val_loss: 1.8378e-04\n",
      "Epoch 754/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.7400e-04 - val_loss: 1.8369e-04\n",
      "Epoch 755/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7382e-04 - val_loss: 1.8361e-04\n",
      "Epoch 756/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7364e-04 - val_loss: 1.8354e-04\n",
      "Epoch 757/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7346e-04 - val_loss: 1.8346e-04\n",
      "Epoch 758/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.7329e-04 - val_loss: 1.8335e-04\n",
      "Epoch 759/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7311e-04 - val_loss: 1.8321e-04\n",
      "Epoch 760/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7294e-04 - val_loss: 1.8305e-04\n",
      "Epoch 761/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.7276e-04 - val_loss: 1.8286e-04\n",
      "Epoch 762/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 2.7258e-04 - val_loss: 1.8264e-04\n",
      "Epoch 763/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.7241e-04 - val_loss: 1.8240e-04\n",
      "Epoch 764/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7223e-04 - val_loss: 1.8214e-04\n",
      "Epoch 765/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7205e-04 - val_loss: 1.8188e-04\n",
      "Epoch 766/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7187e-04 - val_loss: 1.8160e-04\n",
      "Epoch 767/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.7170e-04 - val_loss: 1.8135e-04\n",
      "Epoch 768/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7152e-04 - val_loss: 1.8110e-04\n",
      "Epoch 769/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7164e-04 - val_loss: 1.8082e-04\n",
      "Epoch 770/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7124e-04 - val_loss: 1.8060e-04\n",
      "Epoch 771/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7114e-04 - val_loss: 1.8047e-04\n",
      "Epoch 772/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.7104e-04 - val_loss: 1.8042e-04\n",
      "Epoch 773/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.7092e-04 - val_loss: 1.8044e-04\n",
      "Epoch 774/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7079e-04 - val_loss: 1.8054e-04\n",
      "Epoch 775/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7064e-04 - val_loss: 1.8071e-04\n",
      "Epoch 776/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.7048e-04 - val_loss: 1.8092e-04\n",
      "Epoch 777/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7031e-04 - val_loss: 1.8117e-04\n",
      "Epoch 778/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.7015e-04 - val_loss: 1.8142e-04\n",
      "Epoch 779/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.6998e-04 - val_loss: 1.8167e-04\n",
      "Epoch 780/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.6982e-04 - val_loss: 1.8189e-04\n",
      "Epoch 781/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6967e-04 - val_loss: 1.8207e-04\n",
      "Epoch 782/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6952e-04 - val_loss: 1.8219e-04\n",
      "Epoch 783/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6936e-04 - val_loss: 1.8223e-04\n",
      "Epoch 784/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.6920e-04 - val_loss: 1.8219e-04\n",
      "Epoch 785/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 2.6904e-04 - val_loss: 1.8207e-04\n",
      "Epoch 786/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 2.6887e-04 - val_loss: 1.8187e-04\n",
      "Epoch 787/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6869e-04 - val_loss: 1.8160e-04\n",
      "Epoch 788/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.6851e-04 - val_loss: 1.8128e-04\n",
      "Epoch 789/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6834e-04 - val_loss: 1.8091e-04\n",
      "Epoch 790/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.6816e-04 - val_loss: 1.8054e-04\n",
      "Epoch 791/1000\n",
      "32/32 [==============================] - 0s 137us/step - loss: 2.6798e-04 - val_loss: 1.8015e-04\n",
      "Epoch 792/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.6780e-04 - val_loss: 1.7979e-04\n",
      "Epoch 793/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.6763e-04 - val_loss: 1.7945e-04\n",
      "Epoch 794/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.6746e-04 - val_loss: 1.7915e-04\n",
      "Epoch 795/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.6729e-04 - val_loss: 1.7890e-04\n",
      "Epoch 796/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.6711e-04 - val_loss: 1.7869e-04\n",
      "Epoch 797/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 2.6694e-04 - val_loss: 1.7853e-04\n",
      "Epoch 798/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6676e-04 - val_loss: 1.7840e-04\n",
      "Epoch 799/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.6658e-04 - val_loss: 1.7831e-04\n",
      "Epoch 800/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.6641e-04 - val_loss: 1.7823e-04\n",
      "Epoch 801/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.6623e-04 - val_loss: 1.7816e-04\n",
      "Epoch 802/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.6605e-04 - val_loss: 1.7809e-04\n",
      "Epoch 803/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.6588e-04 - val_loss: 1.7801e-04\n",
      "Epoch 804/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 2.6571e-04 - val_loss: 1.7790e-04\n",
      "Epoch 805/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6553e-04 - val_loss: 1.7775e-04\n",
      "Epoch 806/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6536e-04 - val_loss: 1.7758e-04\n",
      "Epoch 807/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6519e-04 - val_loss: 1.7738e-04\n",
      "Epoch 808/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6501e-04 - val_loss: 1.7715e-04\n",
      "Epoch 809/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6484e-04 - val_loss: 1.7691e-04\n",
      "Epoch 810/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6467e-04 - val_loss: 1.7665e-04\n",
      "Epoch 811/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.6450e-04 - val_loss: 1.7639e-04\n",
      "Epoch 812/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6432e-04 - val_loss: 1.7612e-04\n",
      "Epoch 813/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.6415e-04 - val_loss: 1.7586e-04\n",
      "Epoch 814/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6441e-04 - val_loss: 1.7559e-04\n",
      "Epoch 815/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 2.6387e-04 - val_loss: 1.7537e-04\n",
      "Epoch 816/1000\n",
      "32/32 [==============================] - 0s 217us/step - loss: 2.6377e-04 - val_loss: 1.7524e-04\n",
      "Epoch 817/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6368e-04 - val_loss: 1.7519e-04\n",
      "Epoch 818/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6357e-04 - val_loss: 1.7523e-04\n",
      "Epoch 819/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.6345e-04 - val_loss: 1.7534e-04\n",
      "Epoch 820/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6330e-04 - val_loss: 1.7550e-04\n",
      "Epoch 821/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6314e-04 - val_loss: 1.7573e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 822/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.6298e-04 - val_loss: 1.7599e-04\n",
      "Epoch 823/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.6281e-04 - val_loss: 1.7626e-04\n",
      "Epoch 824/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.6265e-04 - val_loss: 1.7652e-04\n",
      "Epoch 825/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.6249e-04 - val_loss: 1.7674e-04\n",
      "Epoch 826/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.6234e-04 - val_loss: 1.7693e-04\n",
      "Epoch 827/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6220e-04 - val_loss: 1.7704e-04\n",
      "Epoch 828/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.6205e-04 - val_loss: 1.7708e-04\n",
      "Epoch 829/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6189e-04 - val_loss: 1.7703e-04\n",
      "Epoch 830/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6173e-04 - val_loss: 1.7690e-04\n",
      "Epoch 831/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.6156e-04 - val_loss: 1.7668e-04\n",
      "Epoch 832/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6138e-04 - val_loss: 1.7640e-04\n",
      "Epoch 833/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6121e-04 - val_loss: 1.7607e-04\n",
      "Epoch 834/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6104e-04 - val_loss: 1.7570e-04\n",
      "Epoch 835/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.6086e-04 - val_loss: 1.7532e-04\n",
      "Epoch 836/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6069e-04 - val_loss: 1.7494e-04\n",
      "Epoch 837/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6052e-04 - val_loss: 1.7458e-04\n",
      "Epoch 838/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.6035e-04 - val_loss: 1.7426e-04\n",
      "Epoch 839/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.6018e-04 - val_loss: 1.7397e-04\n",
      "Epoch 840/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6001e-04 - val_loss: 1.7373e-04\n",
      "Epoch 841/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.5984e-04 - val_loss: 1.7354e-04\n",
      "Epoch 842/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5967e-04 - val_loss: 1.7340e-04\n",
      "Epoch 843/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.5949e-04 - val_loss: 1.7329e-04\n",
      "Epoch 844/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.5932e-04 - val_loss: 1.7321e-04\n",
      "Epoch 845/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.5915e-04 - val_loss: 1.7314e-04\n",
      "Epoch 846/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.5897e-04 - val_loss: 1.7307e-04\n",
      "Epoch 847/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.5880e-04 - val_loss: 1.7299e-04\n",
      "Epoch 848/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.5863e-04 - val_loss: 1.7291e-04\n",
      "Epoch 849/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.5846e-04 - val_loss: 1.7279e-04\n",
      "Epoch 850/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.5829e-04 - val_loss: 1.7264e-04\n",
      "Epoch 851/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5812e-04 - val_loss: 1.7246e-04\n",
      "Epoch 852/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5795e-04 - val_loss: 1.7225e-04\n",
      "Epoch 853/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.5778e-04 - val_loss: 1.7202e-04\n",
      "Epoch 854/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.5761e-04 - val_loss: 1.7177e-04\n",
      "Epoch 855/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.5744e-04 - val_loss: 1.7151e-04\n",
      "Epoch 856/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5727e-04 - val_loss: 1.7125e-04\n",
      "Epoch 857/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5710e-04 - val_loss: 1.7099e-04\n",
      "Epoch 858/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.5719e-04 - val_loss: 1.7071e-04\n",
      "Epoch 859/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5683e-04 - val_loss: 1.7050e-04\n",
      "Epoch 860/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.5674e-04 - val_loss: 1.7037e-04\n",
      "Epoch 861/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5665e-04 - val_loss: 1.7032e-04\n",
      "Epoch 862/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.5654e-04 - val_loss: 1.7035e-04\n",
      "Epoch 863/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5642e-04 - val_loss: 1.7046e-04\n",
      "Epoch 864/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.5628e-04 - val_loss: 1.7063e-04\n",
      "Epoch 865/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5612e-04 - val_loss: 1.7086e-04\n",
      "Epoch 866/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5596e-04 - val_loss: 1.7112e-04\n",
      "Epoch 867/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.5580e-04 - val_loss: 1.7139e-04\n",
      "Epoch 868/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5564e-04 - val_loss: 1.7166e-04\n",
      "Epoch 869/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.5549e-04 - val_loss: 1.7189e-04\n",
      "Epoch 870/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5534e-04 - val_loss: 1.7207e-04\n",
      "Epoch 871/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.5519e-04 - val_loss: 1.7219e-04\n",
      "Epoch 872/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.5505e-04 - val_loss: 1.7221e-04\n",
      "Epoch 873/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.5490e-04 - val_loss: 1.7216e-04\n",
      "Epoch 874/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5474e-04 - val_loss: 1.7202e-04\n",
      "Epoch 875/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.5457e-04 - val_loss: 1.7180e-04\n",
      "Epoch 876/1000\n",
      "32/32 [==============================] - 0s 172us/step - loss: 2.5440e-04 - val_loss: 1.7152e-04\n",
      "Epoch 877/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.5423e-04 - val_loss: 1.7116e-04\n",
      "Epoch 878/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5406e-04 - val_loss: 1.7080e-04\n",
      "Epoch 879/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5389e-04 - val_loss: 1.7041e-04\n",
      "Epoch 880/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5372e-04 - val_loss: 1.7004e-04\n",
      "Epoch 881/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5355e-04 - val_loss: 1.6968e-04\n",
      "Epoch 882/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5339e-04 - val_loss: 1.6936e-04\n",
      "Epoch 883/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.5322e-04 - val_loss: 1.6909e-04\n",
      "Epoch 884/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5305e-04 - val_loss: 1.6887e-04\n",
      "Epoch 885/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.5288e-04 - val_loss: 1.6869e-04\n",
      "Epoch 886/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.5271e-04 - val_loss: 1.6857e-04\n",
      "Epoch 887/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5255e-04 - val_loss: 1.6847e-04\n",
      "Epoch 888/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.5237e-04 - val_loss: 1.6840e-04\n",
      "Epoch 889/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5220e-04 - val_loss: 1.6834e-04\n",
      "Epoch 890/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 2.5203e-04 - val_loss: 1.6828e-04\n",
      "Epoch 891/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.5186e-04 - val_loss: 1.6820e-04\n",
      "Epoch 892/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.5170e-04 - val_loss: 1.6811e-04\n",
      "Epoch 893/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5153e-04 - val_loss: 1.6798e-04\n",
      "Epoch 894/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5137e-04 - val_loss: 1.6783e-04\n",
      "Epoch 895/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.5120e-04 - val_loss: 1.6764e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 896/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5104e-04 - val_loss: 1.6742e-04\n",
      "Epoch 897/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5087e-04 - val_loss: 1.6718e-04\n",
      "Epoch 898/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.5070e-04 - val_loss: 1.6693e-04\n",
      "Epoch 899/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.5053e-04 - val_loss: 1.6667e-04\n",
      "Epoch 900/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5037e-04 - val_loss: 1.6641e-04\n",
      "Epoch 901/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.5020e-04 - val_loss: 1.6617e-04\n",
      "Epoch 902/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.5042e-04 - val_loss: 1.6589e-04\n",
      "Epoch 903/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.4993e-04 - val_loss: 1.6569e-04\n",
      "Epoch 904/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.4985e-04 - val_loss: 1.6557e-04\n",
      "Epoch 905/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.4976e-04 - val_loss: 1.6554e-04\n",
      "Epoch 906/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 2.4966e-04 - val_loss: 1.6560e-04\n",
      "Epoch 907/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 2.4954e-04 - val_loss: 1.6573e-04\n",
      "Epoch 908/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4940e-04 - val_loss: 1.6592e-04\n",
      "Epoch 909/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4925e-04 - val_loss: 1.6617e-04\n",
      "Epoch 910/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.4909e-04 - val_loss: 1.6643e-04\n",
      "Epoch 911/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4893e-04 - val_loss: 1.6672e-04\n",
      "Epoch 912/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.4878e-04 - val_loss: 1.6699e-04\n",
      "Epoch 913/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4863e-04 - val_loss: 1.6722e-04\n",
      "Epoch 914/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.4849e-04 - val_loss: 1.6739e-04\n",
      "Epoch 915/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4835e-04 - val_loss: 1.6749e-04\n",
      "Epoch 916/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4821e-04 - val_loss: 1.6751e-04\n",
      "Epoch 917/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4805e-04 - val_loss: 1.6745e-04\n",
      "Epoch 918/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4790e-04 - val_loss: 1.6729e-04\n",
      "Epoch 919/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.4774e-04 - val_loss: 1.6706e-04\n",
      "Epoch 920/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.4756e-04 - val_loss: 1.6677e-04\n",
      "Epoch 921/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.4739e-04 - val_loss: 1.6642e-04\n",
      "Epoch 922/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4723e-04 - val_loss: 1.6605e-04\n",
      "Epoch 923/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4706e-04 - val_loss: 1.6567e-04\n",
      "Epoch 924/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4690e-04 - val_loss: 1.6530e-04\n",
      "Epoch 925/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4673e-04 - val_loss: 1.6496e-04\n",
      "Epoch 926/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4657e-04 - val_loss: 1.6465e-04\n",
      "Epoch 927/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.4641e-04 - val_loss: 1.6441e-04\n",
      "Epoch 928/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4624e-04 - val_loss: 1.6420e-04\n",
      "Epoch 929/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.4608e-04 - val_loss: 1.6405e-04\n",
      "Epoch 930/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 2.4591e-04 - val_loss: 1.6394e-04\n",
      "Epoch 931/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4574e-04 - val_loss: 1.6386e-04\n",
      "Epoch 932/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4558e-04 - val_loss: 1.6379e-04\n",
      "Epoch 933/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4541e-04 - val_loss: 1.6374e-04\n",
      "Epoch 934/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.4524e-04 - val_loss: 1.6368e-04\n",
      "Epoch 935/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.4508e-04 - val_loss: 1.6360e-04\n",
      "Epoch 936/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4491e-04 - val_loss: 1.6350e-04\n",
      "Epoch 937/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4475e-04 - val_loss: 1.6337e-04\n",
      "Epoch 938/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.4459e-04 - val_loss: 1.6320e-04\n",
      "Epoch 939/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.4443e-04 - val_loss: 1.6300e-04\n",
      "Epoch 940/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.4426e-04 - val_loss: 1.6279e-04\n",
      "Epoch 941/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4410e-04 - val_loss: 1.6253e-04\n",
      "Epoch 942/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.4393e-04 - val_loss: 1.6227e-04\n",
      "Epoch 943/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.4377e-04 - val_loss: 1.6202e-04\n",
      "Epoch 944/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.4361e-04 - val_loss: 1.6177e-04\n",
      "Epoch 945/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.4345e-04 - val_loss: 1.6152e-04\n",
      "Epoch 946/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4367e-04 - val_loss: 1.6127e-04\n",
      "Epoch 947/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.4319e-04 - val_loss: 1.6108e-04\n",
      "Epoch 948/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.4310e-04 - val_loss: 1.6098e-04\n",
      "Epoch 949/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.4302e-04 - val_loss: 1.6097e-04\n",
      "Epoch 950/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4292e-04 - val_loss: 1.6103e-04\n",
      "Epoch 951/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4281e-04 - val_loss: 1.6119e-04\n",
      "Epoch 952/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 2.4267e-04 - val_loss: 1.6139e-04\n",
      "Epoch 953/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.4252e-04 - val_loss: 1.6165e-04\n",
      "Epoch 954/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.4236e-04 - val_loss: 1.6192e-04\n",
      "Epoch 955/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4221e-04 - val_loss: 1.6221e-04\n",
      "Epoch 956/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4206e-04 - val_loss: 1.6248e-04\n",
      "Epoch 957/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.4192e-04 - val_loss: 1.6271e-04\n",
      "Epoch 958/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.4178e-04 - val_loss: 1.6288e-04\n",
      "Epoch 959/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.4164e-04 - val_loss: 1.6297e-04\n",
      "Epoch 960/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4150e-04 - val_loss: 1.6298e-04\n",
      "Epoch 961/1000\n",
      "32/32 [==============================] - 0s 129us/step - loss: 2.4135e-04 - val_loss: 1.6290e-04\n",
      "Epoch 962/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.4120e-04 - val_loss: 1.6273e-04\n",
      "Epoch 963/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.4103e-04 - val_loss: 1.6248e-04\n",
      "Epoch 964/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4087e-04 - val_loss: 1.6218e-04\n",
      "Epoch 965/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4070e-04 - val_loss: 1.6183e-04\n",
      "Epoch 966/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.4054e-04 - val_loss: 1.6145e-04\n",
      "Epoch 967/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4038e-04 - val_loss: 1.6107e-04\n",
      "Epoch 968/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4022e-04 - val_loss: 1.6072e-04\n",
      "Epoch 969/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4006e-04 - val_loss: 1.6039e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 970/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.3990e-04 - val_loss: 1.6011e-04\n",
      "Epoch 971/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3974e-04 - val_loss: 1.5989e-04\n",
      "Epoch 972/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3958e-04 - val_loss: 1.5970e-04\n",
      "Epoch 973/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3941e-04 - val_loss: 1.5956e-04\n",
      "Epoch 974/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.3925e-04 - val_loss: 1.5947e-04\n",
      "Epoch 975/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3909e-04 - val_loss: 1.5940e-04\n",
      "Epoch 976/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3892e-04 - val_loss: 1.5935e-04\n",
      "Epoch 977/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3876e-04 - val_loss: 1.5930e-04\n",
      "Epoch 978/1000\n",
      "32/32 [==============================] - 0s 131us/step - loss: 2.3860e-04 - val_loss: 1.5924e-04\n",
      "Epoch 979/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.3844e-04 - val_loss: 1.5916e-04\n",
      "Epoch 980/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3828e-04 - val_loss: 1.5905e-04\n",
      "Epoch 981/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3812e-04 - val_loss: 1.5891e-04\n",
      "Epoch 982/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.3796e-04 - val_loss: 1.5873e-04\n",
      "Epoch 983/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3780e-04 - val_loss: 1.5852e-04\n",
      "Epoch 984/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3764e-04 - val_loss: 1.5829e-04\n",
      "Epoch 985/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3748e-04 - val_loss: 1.5803e-04\n",
      "Epoch 986/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3732e-04 - val_loss: 1.5777e-04\n",
      "Epoch 987/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3716e-04 - val_loss: 1.5753e-04\n",
      "Epoch 988/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3700e-04 - val_loss: 1.5727e-04\n",
      "Epoch 989/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3684e-04 - val_loss: 1.5704e-04\n",
      "Epoch 990/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3701e-04 - val_loss: 1.5680e-04\n",
      "Epoch 991/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3659e-04 - val_loss: 1.5663e-04\n",
      "Epoch 992/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3651e-04 - val_loss: 1.5655e-04\n",
      "Epoch 993/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3643e-04 - val_loss: 1.5655e-04\n",
      "Epoch 994/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3633e-04 - val_loss: 1.5664e-04\n",
      "Epoch 995/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3622e-04 - val_loss: 1.5680e-04\n",
      "Epoch 996/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3608e-04 - val_loss: 1.5702e-04\n",
      "Epoch 997/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3593e-04 - val_loss: 1.5728e-04\n",
      "Epoch 998/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3578e-04 - val_loss: 1.5757e-04\n",
      "Epoch 999/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3563e-04 - val_loss: 1.5785e-04\n",
      "Epoch 1000/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3548e-04 - val_loss: 1.5812e-04\n",
      "0.00013100859359838068\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.05441995, -1.1184036 , -1.089987  , -0.04960766,  0.00361442],\n",
       "        [-0.23498778,  0.19046225, -0.08051544,  0.26243466,  0.22370386],\n",
       "        [-0.40012318,  0.689701  , -0.6838393 , -0.21574509,  0.8638539 ]],\n",
       "       dtype=float32),\n",
       " array([ 0.6540333 ,  0.44112733,  0.2075105 , -0.8717559 ,  0.36762035],\n",
       "       dtype=float32),\n",
       " array([[-0.64835525, -0.21112813,  0.18977189, -0.38953063,  0.7055551 ,\n",
       "         -0.26851502,  0.30558392, -0.3648228 ,  0.6404661 , -0.26731387],\n",
       "        [-0.7194904 , -0.5184312 ,  0.2555632 , -0.8974837 ,  0.1651725 ,\n",
       "         -0.7520713 , -0.02376207,  0.5409103 ,  1.0019932 , -0.1418388 ],\n",
       "        [-0.3140415 , -0.729762  , -0.21931088, -0.8262984 ,  0.6427943 ,\n",
       "         -0.4043337 ,  0.5359972 ,  0.3964096 ,  0.13630104, -0.7974436 ],\n",
       "        [-0.23275997, -1.255268  ,  0.39702213, -0.06795792,  0.18600374,\n",
       "          0.6083439 , -0.06710818,  0.29643047,  0.26054835, -1.0486748 ],\n",
       "        [-0.32302654,  0.2552393 ,  0.03333183, -0.37752658,  0.11640461,\n",
       "          0.28828263, -0.84465   ,  0.16736816,  0.15127459, -0.97109675]],\n",
       "       dtype=float32),\n",
       " array([-0.4442967 , -0.707767  ,  0.77679807, -0.58758694,  0.80303615,\n",
       "         1.2247616 ,  0.70916736,  0.5496497 ,  0.8846374 , -0.6470098 ],\n",
       "       dtype=float32),\n",
       " array([[0.10268541],\n",
       "        [0.09255209],\n",
       "        [0.5709262 ],\n",
       "        [0.04774521],\n",
       "        [0.4886273 ],\n",
       "        [1.8403133 ],\n",
       "        [0.42941085],\n",
       "        [0.33392844],\n",
       "        [0.9542064 ],\n",
       "        [0.31492272]], dtype=float32),\n",
       " array([0.9040946], dtype=float32)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_challenger, history_challenger, evaluate_challenger=NN_model_structure_regression_relu(X_train_challenger, X_val_challenger, Y_train_challenger, Y_val_challenger, adam2, 32, 1000, x_test_challenger, y_test_challenger)\n",
    "model_challenger.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_challenger.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_challenger_relu_4th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_43 (Dense)             (None, 5)                 20        \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 91\n",
      "Trainable params: 91\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 32 samples, validate on 7 samples\n",
      "Epoch 1/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 54.1102 - val_loss: 51.3816\n",
      "Epoch 2/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 50.1043 - val_loss: 46.4266\n",
      "Epoch 3/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 45.1196 - val_loss: 41.1508\n",
      "Epoch 4/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 39.8683 - val_loss: 35.8955\n",
      "Epoch 5/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 34.7019 - val_loss: 30.8633\n",
      "Epoch 6/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 29.7899 - val_loss: 26.1612\n",
      "Epoch 7/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 25.2220 - val_loss: 21.8461\n",
      "Epoch 8/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 21.0608 - val_loss: 17.9522\n",
      "Epoch 9/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 17.3534 - val_loss: 14.5065\n",
      "Epoch 10/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 14.1166 - val_loss: 11.5232\n",
      "Epoch 11/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 11.3387 - val_loss: 8.9925\n",
      "Epoch 12/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.9827 - val_loss: 6.8688\n",
      "Epoch 13/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9989 - val_loss: 5.1174\n",
      "Epoch 14/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.3412 - val_loss: 3.7018\n",
      "Epoch 15/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.9710 - val_loss: 2.5796\n",
      "Epoch 16/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.8560 - val_loss: 1.7121\n",
      "Epoch 17/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9686 - val_loss: 1.0637\n",
      "Epoch 18/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.2813 - val_loss: 0.6019\n",
      "Epoch 19/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.7721 - val_loss: 0.2966\n",
      "Epoch 20/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.4182 - val_loss: 0.1199\n",
      "Epoch 21/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1965 - val_loss: 0.0459\n",
      "Epoch 22/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0837 - val_loss: 0.0509\n",
      "Epoch 23/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0571 - val_loss: 0.1130\n",
      "Epoch 24/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0950 - val_loss: 0.2131\n",
      "Epoch 25/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.1774 - val_loss: 0.3342\n",
      "Epoch 26/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.2864 - val_loss: 0.4623\n",
      "Epoch 27/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.4073 - val_loss: 0.5862\n",
      "Epoch 28/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.5270 - val_loss: 0.6971\n",
      "Epoch 29/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.6353 - val_loss: 0.7892\n",
      "Epoch 30/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.7255 - val_loss: 0.8587\n",
      "Epoch 31/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.7947 - val_loss: 0.9040\n",
      "Epoch 32/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.8402 - val_loss: 0.9251\n",
      "Epoch 33/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.8620 - val_loss: 0.9236\n",
      "Epoch 34/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.8611 - val_loss: 0.9016\n",
      "Epoch 35/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.8400 - val_loss: 0.8623\n",
      "Epoch 36/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.8017 - val_loss: 0.8091\n",
      "Epoch 37/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.7497 - val_loss: 0.7453\n",
      "Epoch 38/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.6875 - val_loss: 0.6746\n",
      "Epoch 39/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.6187 - val_loss: 0.5999\n",
      "Epoch 40/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.5464 - val_loss: 0.5243\n",
      "Epoch 41/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.4736 - val_loss: 0.4501\n",
      "Epoch 42/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.4026 - val_loss: 0.3793\n",
      "Epoch 43/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.3354 - val_loss: 0.3135\n",
      "Epoch 44/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.2735 - val_loss: 0.2538\n",
      "Epoch 45/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.2180 - val_loss: 0.2009\n",
      "Epoch 46/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.1694 - val_loss: 0.1550\n",
      "Epoch 47/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.1279 - val_loss: 0.1163\n",
      "Epoch 48/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0936 - val_loss: 0.0845\n",
      "Epoch 49/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0662 - val_loss: 0.0592\n",
      "Epoch 50/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0449 - val_loss: 0.0397\n",
      "Epoch 51/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0293 - val_loss: 0.0254\n",
      "Epoch 52/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0185 - val_loss: 0.0155\n",
      "Epoch 53/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0119 - val_loss: 0.0092\n",
      "Epoch 54/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0086 - val_loss: 0.0059\n",
      "Epoch 55/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0080 - val_loss: 0.0049\n",
      "Epoch 56/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0092 - val_loss: 0.0055\n",
      "Epoch 57/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0118 - val_loss: 0.0072\n",
      "Epoch 58/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0151 - val_loss: 0.0095\n",
      "Epoch 59/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0188 - val_loss: 0.0121\n",
      "Epoch 60/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0223 - val_loss: 0.0145\n",
      "Epoch 61/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0256 - val_loss: 0.0167\n",
      "Epoch 62/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0283 - val_loss: 0.0185\n",
      "Epoch 63/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0303 - val_loss: 0.0197\n",
      "Epoch 64/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0316 - val_loss: 0.0203\n",
      "Epoch 65/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0322 - val_loss: 0.0204\n",
      "Epoch 66/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0321 - val_loss: 0.0201\n",
      "Epoch 67/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0313 - val_loss: 0.0192\n",
      "Epoch 68/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0300 - val_loss: 0.0180\n",
      "Epoch 69/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0282 - val_loss: 0.0165\n",
      "Epoch 70/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0261 - val_loss: 0.0149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0238 - val_loss: 0.0131\n",
      "Epoch 72/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0213 - val_loss: 0.0113\n",
      "Epoch 73/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0188 - val_loss: 0.0096\n",
      "Epoch 74/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0163 - val_loss: 0.0079\n",
      "Epoch 75/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0139 - val_loss: 0.0064\n",
      "Epoch 76/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0117 - val_loss: 0.0051\n",
      "Epoch 77/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0097 - val_loss: 0.0040\n",
      "Epoch 78/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0079 - val_loss: 0.0031\n",
      "Epoch 79/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0063 - val_loss: 0.0024\n",
      "Epoch 80/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0050 - val_loss: 0.0019\n",
      "Epoch 81/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0040 - val_loss: 0.0015\n",
      "Epoch 82/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0031 - val_loss: 0.0013\n",
      "Epoch 83/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0025 - val_loss: 0.0013\n",
      "Epoch 84/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 85/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 86/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 87/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 88/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0013 - val_loss: 0.0021\n",
      "Epoch 89/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0024\n",
      "Epoch 90/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 0.0026\n",
      "Epoch 91/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0015 - val_loss: 0.0028\n",
      "Epoch 92/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0016 - val_loss: 0.0029\n",
      "Epoch 93/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0030\n",
      "Epoch 94/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0017 - val_loss: 0.0031\n",
      "Epoch 95/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 0.0032\n",
      "Epoch 96/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 0.0031\n",
      "Epoch 97/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0017 - val_loss: 0.0031\n",
      "Epoch 98/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0030\n",
      "Epoch 99/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 0.0029\n",
      "Epoch 100/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 101/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0015 - val_loss: 0.0026\n",
      "Epoch 102/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0025\n",
      "Epoch 103/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0023\n",
      "Epoch 104/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 105/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 106/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4363e-04 - val_loss: 0.0018\n",
      "Epoch 107/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.4085e-04 - val_loss: 0.0016\n",
      "Epoch 108/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.4503e-04 - val_loss: 0.0014\n",
      "Epoch 109/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 6.5748e-04 - val_loss: 0.0013\n",
      "Epoch 110/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.7902e-04 - val_loss: 0.0012\n",
      "Epoch 111/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.1006e-04 - val_loss: 0.0011\n",
      "Epoch 112/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5057e-04 - val_loss: 9.4590e-04\n",
      "Epoch 113/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0022e-04 - val_loss: 8.5072e-04\n",
      "Epoch 114/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.5842e-04 - val_loss: 7.6706e-04\n",
      "Epoch 115/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.2440e-04 - val_loss: 6.9414e-04\n",
      "Epoch 116/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9724e-04 - val_loss: 6.3105e-04\n",
      "Epoch 117/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.7597e-04 - val_loss: 5.7691e-04\n",
      "Epoch 118/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5960e-04 - val_loss: 5.3070e-04\n",
      "Epoch 119/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4716e-04 - val_loss: 4.9147e-04\n",
      "Epoch 120/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.3775e-04 - val_loss: 4.5829e-04\n",
      "Epoch 121/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3055e-04 - val_loss: 4.3031e-04\n",
      "Epoch 122/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.2485e-04 - val_loss: 4.0674e-04\n",
      "Epoch 123/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2003e-04 - val_loss: 3.8693e-04\n",
      "Epoch 124/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.1559e-04 - val_loss: 3.7023e-04\n",
      "Epoch 125/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1117e-04 - val_loss: 3.5619e-04\n",
      "Epoch 126/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.0651e-04 - val_loss: 3.4437e-04\n",
      "Epoch 127/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0142e-04 - val_loss: 3.3444e-04\n",
      "Epoch 128/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.9580e-04 - val_loss: 3.2614e-04\n",
      "Epoch 129/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.8963e-04 - val_loss: 3.1922e-04\n",
      "Epoch 130/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.8293e-04 - val_loss: 3.1355e-04\n",
      "Epoch 131/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.7580e-04 - val_loss: 3.0897e-04\n",
      "Epoch 132/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.6832e-04 - val_loss: 3.0541e-04\n",
      "Epoch 133/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6062e-04 - val_loss: 3.0274e-04\n",
      "Epoch 134/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5282e-04 - val_loss: 3.0091e-04\n",
      "Epoch 135/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4505e-04 - val_loss: 2.9983e-04\n",
      "Epoch 136/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.3741e-04 - val_loss: 2.9946e-04\n",
      "Epoch 137/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.3003e-04 - val_loss: 2.9968e-04\n",
      "Epoch 138/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2296e-04 - val_loss: 3.0046e-04\n",
      "Epoch 139/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1632e-04 - val_loss: 3.0169e-04\n",
      "Epoch 140/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1011e-04 - val_loss: 3.0332e-04\n",
      "Epoch 141/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0439e-04 - val_loss: 3.0523e-04\n",
      "Epoch 142/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.9166e-05 - val_loss: 3.0737e-04\n",
      "Epoch 143/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.4439e-05 - val_loss: 3.0963e-04\n",
      "Epoch 144/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.0192e-05 - val_loss: 3.1190e-04\n",
      "Epoch 145/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.6397e-05 - val_loss: 3.1417e-04\n",
      "Epoch 146/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.3032e-05 - val_loss: 3.1632e-04\n",
      "Epoch 147/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.0043e-05 - val_loss: 3.1830e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 148/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.7401e-05 - val_loss: 3.2004e-04\n",
      "Epoch 149/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5060e-05 - val_loss: 3.2148e-04\n",
      "Epoch 150/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2972e-05 - val_loss: 3.2260e-04\n",
      "Epoch 151/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.1100e-05 - val_loss: 3.2337e-04\n",
      "Epoch 152/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9405e-05 - val_loss: 3.2375e-04\n",
      "Epoch 153/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.7856e-05 - val_loss: 3.2377e-04\n",
      "Epoch 154/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.6428e-05 - val_loss: 3.2340e-04\n",
      "Epoch 155/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5089e-05 - val_loss: 3.2263e-04\n",
      "Epoch 156/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3819e-05 - val_loss: 3.2152e-04\n",
      "Epoch 157/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2607e-05 - val_loss: 3.2005e-04\n",
      "Epoch 158/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.1442e-05 - val_loss: 3.1827e-04\n",
      "Epoch 159/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0312e-05 - val_loss: 3.1619e-04\n",
      "Epoch 160/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.9212e-05 - val_loss: 3.1385e-04\n",
      "Epoch 161/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.8144e-05 - val_loss: 3.1129e-04\n",
      "Epoch 162/1000\n",
      "32/32 [==============================] - 0s 161us/step - loss: 5.7107e-05 - val_loss: 3.0852e-04\n",
      "Epoch 163/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.6092e-05 - val_loss: 3.0560e-04\n",
      "Epoch 164/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 5.5112e-05 - val_loss: 3.0256e-04\n",
      "Epoch 165/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4168e-05 - val_loss: 2.9943e-04\n",
      "Epoch 166/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.3258e-05 - val_loss: 2.9626e-04\n",
      "Epoch 167/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.2390e-05 - val_loss: 2.9304e-04\n",
      "Epoch 168/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 5.1559e-05 - val_loss: 2.8984e-04\n",
      "Epoch 169/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.0774e-05 - val_loss: 2.8666e-04\n",
      "Epoch 170/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 5.0030e-05 - val_loss: 2.8354e-04\n",
      "Epoch 171/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9332e-05 - val_loss: 2.8047e-04\n",
      "Epoch 172/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.8679e-05 - val_loss: 2.7749e-04\n",
      "Epoch 173/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8069e-05 - val_loss: 2.7462e-04\n",
      "Epoch 174/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.7500e-05 - val_loss: 2.7186e-04\n",
      "Epoch 175/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 4.6971e-05 - val_loss: 2.6921e-04\n",
      "Epoch 176/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.6482e-05 - val_loss: 2.6667e-04\n",
      "Epoch 177/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 4.6025e-05 - val_loss: 2.6429e-04\n",
      "Epoch 178/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 4.5601e-05 - val_loss: 2.6203e-04\n",
      "Epoch 179/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.5211e-05 - val_loss: 2.5989e-04\n",
      "Epoch 180/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.4846e-05 - val_loss: 2.5790e-04\n",
      "Epoch 181/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4505e-05 - val_loss: 2.5606e-04\n",
      "Epoch 182/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.4188e-05 - val_loss: 2.5434e-04\n",
      "Epoch 183/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.3894e-05 - val_loss: 2.5272e-04\n",
      "Epoch 184/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.3613e-05 - val_loss: 2.5126e-04\n",
      "Epoch 185/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3353e-05 - val_loss: 2.4991e-04\n",
      "Epoch 186/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.3105e-05 - val_loss: 2.4866e-04\n",
      "Epoch 187/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.2871e-05 - val_loss: 2.4753e-04\n",
      "Epoch 188/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2650e-05 - val_loss: 2.4649e-04\n",
      "Epoch 189/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2439e-05 - val_loss: 2.4556e-04\n",
      "Epoch 190/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2239e-05 - val_loss: 2.4469e-04\n",
      "Epoch 191/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2046e-05 - val_loss: 2.4392e-04\n",
      "Epoch 192/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.1865e-05 - val_loss: 2.4322e-04\n",
      "Epoch 193/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1691e-05 - val_loss: 2.4258e-04\n",
      "Epoch 194/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1525e-05 - val_loss: 2.4202e-04\n",
      "Epoch 195/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1369e-05 - val_loss: 2.4151e-04\n",
      "Epoch 196/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1217e-05 - val_loss: 2.4103e-04\n",
      "Epoch 197/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1071e-05 - val_loss: 2.4061e-04\n",
      "Epoch 198/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0937e-05 - val_loss: 2.4022e-04\n",
      "Epoch 199/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.0806e-05 - val_loss: 2.3987e-04\n",
      "Epoch 200/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0683e-05 - val_loss: 2.3955e-04\n",
      "Epoch 201/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.0567e-05 - val_loss: 2.3924e-04\n",
      "Epoch 202/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.0455e-05 - val_loss: 2.3896e-04\n",
      "Epoch 203/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0350e-05 - val_loss: 2.3866e-04\n",
      "Epoch 204/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0247e-05 - val_loss: 2.3841e-04\n",
      "Epoch 205/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0156e-05 - val_loss: 2.3815e-04\n",
      "Epoch 206/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.0065e-05 - val_loss: 2.3790e-04\n",
      "Epoch 207/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9981e-05 - val_loss: 2.3765e-04\n",
      "Epoch 208/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9900e-05 - val_loss: 2.3737e-04\n",
      "Epoch 209/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.9819e-05 - val_loss: 2.3713e-04\n",
      "Epoch 210/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9748e-05 - val_loss: 2.3687e-04\n",
      "Epoch 211/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9678e-05 - val_loss: 2.3661e-04\n",
      "Epoch 212/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9612e-05 - val_loss: 2.3633e-04\n",
      "Epoch 213/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.9548e-05 - val_loss: 2.3607e-04\n",
      "Epoch 214/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9488e-05 - val_loss: 2.3579e-04\n",
      "Epoch 215/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9431e-05 - val_loss: 2.3551e-04\n",
      "Epoch 216/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.9376e-05 - val_loss: 2.3521e-04\n",
      "Epoch 217/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9322e-05 - val_loss: 2.3492e-04\n",
      "Epoch 218/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.9271e-05 - val_loss: 2.3460e-04\n",
      "Epoch 219/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 3.9221e-05 - val_loss: 2.3429e-04\n",
      "Epoch 220/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9174e-05 - val_loss: 2.3398e-04\n",
      "Epoch 221/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.9128e-05 - val_loss: 2.3366e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 222/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.9084e-05 - val_loss: 2.3335e-04\n",
      "Epoch 223/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9043e-05 - val_loss: 2.3303e-04\n",
      "Epoch 224/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.9001e-05 - val_loss: 2.3271e-04\n",
      "Epoch 225/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.8963e-05 - val_loss: 2.3239e-04\n",
      "Epoch 226/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.8923e-05 - val_loss: 2.3208e-04\n",
      "Epoch 227/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8888e-05 - val_loss: 2.3175e-04\n",
      "Epoch 228/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8851e-05 - val_loss: 2.3144e-04\n",
      "Epoch 229/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.8817e-05 - val_loss: 2.3113e-04\n",
      "Epoch 230/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8784e-05 - val_loss: 2.3081e-04\n",
      "Epoch 231/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8750e-05 - val_loss: 2.3051e-04\n",
      "Epoch 232/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8718e-05 - val_loss: 2.3020e-04\n",
      "Epoch 233/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8688e-05 - val_loss: 2.2992e-04\n",
      "Epoch 234/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.8659e-05 - val_loss: 2.2963e-04\n",
      "Epoch 235/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8629e-05 - val_loss: 2.2934e-04\n",
      "Epoch 236/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.8599e-05 - val_loss: 2.2907e-04\n",
      "Epoch 237/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8573e-05 - val_loss: 2.2881e-04\n",
      "Epoch 238/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8545e-05 - val_loss: 2.2855e-04\n",
      "Epoch 239/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8519e-05 - val_loss: 2.2830e-04\n",
      "Epoch 240/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8494e-05 - val_loss: 2.2805e-04\n",
      "Epoch 241/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8467e-05 - val_loss: 2.2781e-04\n",
      "Epoch 242/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8442e-05 - val_loss: 2.2758e-04\n",
      "Epoch 243/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8418e-05 - val_loss: 2.2737e-04\n",
      "Epoch 244/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.8394e-05 - val_loss: 2.2715e-04\n",
      "Epoch 245/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8371e-05 - val_loss: 2.2695e-04\n",
      "Epoch 246/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.8349e-05 - val_loss: 2.2674e-04\n",
      "Epoch 247/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.8325e-05 - val_loss: 2.2655e-04\n",
      "Epoch 248/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8303e-05 - val_loss: 2.2637e-04\n",
      "Epoch 249/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8283e-05 - val_loss: 2.2617e-04\n",
      "Epoch 250/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.8258e-05 - val_loss: 2.2601e-04\n",
      "Epoch 251/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.8239e-05 - val_loss: 2.2584e-04\n",
      "Epoch 252/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8217e-05 - val_loss: 2.2569e-04\n",
      "Epoch 253/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.8198e-05 - val_loss: 2.2551e-04\n",
      "Epoch 254/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.8175e-05 - val_loss: 2.2536e-04\n",
      "Epoch 255/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.8155e-05 - val_loss: 2.2521e-04\n",
      "Epoch 256/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8136e-05 - val_loss: 2.2507e-04\n",
      "Epoch 257/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8116e-05 - val_loss: 2.2492e-04\n",
      "Epoch 258/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8095e-05 - val_loss: 2.2479e-04\n",
      "Epoch 259/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8078e-05 - val_loss: 2.2466e-04\n",
      "Epoch 260/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8058e-05 - val_loss: 2.2452e-04\n",
      "Epoch 261/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8039e-05 - val_loss: 2.2438e-04\n",
      "Epoch 262/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.8019e-05 - val_loss: 2.2427e-04\n",
      "Epoch 263/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8003e-05 - val_loss: 2.2414e-04\n",
      "Epoch 264/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7983e-05 - val_loss: 2.2401e-04\n",
      "Epoch 265/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7965e-05 - val_loss: 2.2389e-04\n",
      "Epoch 266/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.7946e-05 - val_loss: 2.2378e-04\n",
      "Epoch 267/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.7929e-05 - val_loss: 2.2365e-04\n",
      "Epoch 268/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.7909e-05 - val_loss: 2.2354e-04\n",
      "Epoch 269/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.7892e-05 - val_loss: 2.2341e-04\n",
      "Epoch 270/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.7873e-05 - val_loss: 2.2331e-04\n",
      "Epoch 271/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7856e-05 - val_loss: 2.2319e-04\n",
      "Epoch 272/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.7839e-05 - val_loss: 2.2307e-04\n",
      "Epoch 273/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.7820e-05 - val_loss: 2.2296e-04\n",
      "Epoch 274/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7802e-05 - val_loss: 2.2285e-04\n",
      "Epoch 275/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7787e-05 - val_loss: 2.2275e-04\n",
      "Epoch 276/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7769e-05 - val_loss: 2.2264e-04\n",
      "Epoch 277/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.7752e-05 - val_loss: 2.2252e-04\n",
      "Epoch 278/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7735e-05 - val_loss: 2.2241e-04\n",
      "Epoch 279/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7717e-05 - val_loss: 2.2230e-04\n",
      "Epoch 280/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.7699e-05 - val_loss: 2.2219e-04\n",
      "Epoch 281/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.7682e-05 - val_loss: 2.2208e-04\n",
      "Epoch 282/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7665e-05 - val_loss: 2.2199e-04\n",
      "Epoch 283/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.7649e-05 - val_loss: 2.2188e-04\n",
      "Epoch 284/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.7632e-05 - val_loss: 2.2178e-04\n",
      "Epoch 285/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.7616e-05 - val_loss: 2.2168e-04\n",
      "Epoch 286/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7599e-05 - val_loss: 2.2158e-04\n",
      "Epoch 287/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.7583e-05 - val_loss: 2.2147e-04\n",
      "Epoch 288/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.7565e-05 - val_loss: 2.2137e-04\n",
      "Epoch 289/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.7550e-05 - val_loss: 2.2127e-04\n",
      "Epoch 290/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7534e-05 - val_loss: 2.2117e-04\n",
      "Epoch 291/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.7517e-05 - val_loss: 2.2107e-04\n",
      "Epoch 292/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7500e-05 - val_loss: 2.2098e-04\n",
      "Epoch 293/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7484e-05 - val_loss: 2.2087e-04\n",
      "Epoch 294/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.7467e-05 - val_loss: 2.2077e-04\n",
      "Epoch 295/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7450e-05 - val_loss: 2.2069e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 296/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7435e-05 - val_loss: 2.2058e-04\n",
      "Epoch 297/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.7418e-05 - val_loss: 2.2049e-04\n",
      "Epoch 298/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.7402e-05 - val_loss: 2.2039e-04\n",
      "Epoch 299/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.7385e-05 - val_loss: 2.2031e-04\n",
      "Epoch 300/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7370e-05 - val_loss: 2.2021e-04\n",
      "Epoch 301/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.7353e-05 - val_loss: 2.2012e-04\n",
      "Epoch 302/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7337e-05 - val_loss: 2.2003e-04\n",
      "Epoch 303/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.7320e-05 - val_loss: 2.1995e-04\n",
      "Epoch 304/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7306e-05 - val_loss: 2.1984e-04\n",
      "Epoch 305/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 3.7288e-05 - val_loss: 2.1976e-04\n",
      "Epoch 306/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7274e-05 - val_loss: 2.1968e-04\n",
      "Epoch 307/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.7259e-05 - val_loss: 2.1959e-04\n",
      "Epoch 308/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 3.7243e-05 - val_loss: 2.1949e-04\n",
      "Epoch 309/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.7225e-05 - val_loss: 2.1941e-04\n",
      "Epoch 310/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7210e-05 - val_loss: 2.1933e-04\n",
      "Epoch 311/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7194e-05 - val_loss: 2.1925e-04\n",
      "Epoch 312/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7179e-05 - val_loss: 2.1916e-04\n",
      "Epoch 313/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7163e-05 - val_loss: 2.1908e-04\n",
      "Epoch 314/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7148e-05 - val_loss: 2.1899e-04\n",
      "Epoch 315/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7131e-05 - val_loss: 2.1891e-04\n",
      "Epoch 316/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7116e-05 - val_loss: 2.1883e-04\n",
      "Epoch 317/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 3.7101e-05 - val_loss: 2.1874e-04\n",
      "Epoch 318/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.7085e-05 - val_loss: 2.1866e-04\n",
      "Epoch 319/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7069e-05 - val_loss: 2.1858e-04\n",
      "Epoch 320/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.7053e-05 - val_loss: 2.1851e-04\n",
      "Epoch 321/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.7039e-05 - val_loss: 2.1843e-04\n",
      "Epoch 322/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7023e-05 - val_loss: 2.1835e-04\n",
      "Epoch 323/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7008e-05 - val_loss: 2.1827e-04\n",
      "Epoch 324/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6992e-05 - val_loss: 2.1819e-04\n",
      "Epoch 325/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6976e-05 - val_loss: 2.1810e-04\n",
      "Epoch 326/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6959e-05 - val_loss: 2.1803e-04\n",
      "Epoch 327/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6945e-05 - val_loss: 2.1794e-04\n",
      "Epoch 328/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6928e-05 - val_loss: 2.1788e-04\n",
      "Epoch 329/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6914e-05 - val_loss: 2.1779e-04\n",
      "Epoch 330/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6898e-05 - val_loss: 2.1773e-04\n",
      "Epoch 331/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6883e-05 - val_loss: 2.1766e-04\n",
      "Epoch 332/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6869e-05 - val_loss: 2.1758e-04\n",
      "Epoch 333/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6852e-05 - val_loss: 2.1750e-04\n",
      "Epoch 334/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6837e-05 - val_loss: 2.1742e-04\n",
      "Epoch 335/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6821e-05 - val_loss: 2.1735e-04\n",
      "Epoch 336/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6807e-05 - val_loss: 2.1726e-04\n",
      "Epoch 337/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6789e-05 - val_loss: 2.1720e-04\n",
      "Epoch 338/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6776e-05 - val_loss: 2.1712e-04\n",
      "Epoch 339/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6760e-05 - val_loss: 2.1705e-04\n",
      "Epoch 340/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6746e-05 - val_loss: 2.1697e-04\n",
      "Epoch 341/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6729e-05 - val_loss: 2.1690e-04\n",
      "Epoch 342/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6715e-05 - val_loss: 2.1683e-04\n",
      "Epoch 343/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6699e-05 - val_loss: 2.1674e-04\n",
      "Epoch 344/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6683e-05 - val_loss: 2.1667e-04\n",
      "Epoch 345/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6670e-05 - val_loss: 2.1660e-04\n",
      "Epoch 346/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6654e-05 - val_loss: 2.1651e-04\n",
      "Epoch 347/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6637e-05 - val_loss: 2.1644e-04\n",
      "Epoch 348/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6624e-05 - val_loss: 2.1637e-04\n",
      "Epoch 349/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6610e-05 - val_loss: 2.1629e-04\n",
      "Epoch 350/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6593e-05 - val_loss: 2.1622e-04\n",
      "Epoch 351/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6578e-05 - val_loss: 2.1614e-04\n",
      "Epoch 352/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6563e-05 - val_loss: 2.1607e-04\n",
      "Epoch 353/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6549e-05 - val_loss: 2.1600e-04\n",
      "Epoch 354/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6534e-05 - val_loss: 2.1592e-04\n",
      "Epoch 355/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6518e-05 - val_loss: 2.1584e-04\n",
      "Epoch 356/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6504e-05 - val_loss: 2.1576e-04\n",
      "Epoch 357/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6487e-05 - val_loss: 2.1570e-04\n",
      "Epoch 358/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6473e-05 - val_loss: 2.1562e-04\n",
      "Epoch 359/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6459e-05 - val_loss: 2.1555e-04\n",
      "Epoch 360/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6444e-05 - val_loss: 2.1548e-04\n",
      "Epoch 361/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6428e-05 - val_loss: 2.1540e-04\n",
      "Epoch 362/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6412e-05 - val_loss: 2.1534e-04\n",
      "Epoch 363/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6398e-05 - val_loss: 2.1526e-04\n",
      "Epoch 364/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6384e-05 - val_loss: 2.1519e-04\n",
      "Epoch 365/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6368e-05 - val_loss: 2.1511e-04\n",
      "Epoch 366/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6353e-05 - val_loss: 2.1506e-04\n",
      "Epoch 367/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6339e-05 - val_loss: 2.1499e-04\n",
      "Epoch 368/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6323e-05 - val_loss: 2.1490e-04\n",
      "Epoch 369/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6307e-05 - val_loss: 2.1483e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 370/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.6293e-05 - val_loss: 2.1477e-04\n",
      "Epoch 371/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6278e-05 - val_loss: 2.1470e-04\n",
      "Epoch 372/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6264e-05 - val_loss: 2.1462e-04\n",
      "Epoch 373/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6248e-05 - val_loss: 2.1455e-04\n",
      "Epoch 374/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6233e-05 - val_loss: 2.1448e-04\n",
      "Epoch 375/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6220e-05 - val_loss: 2.1441e-04\n",
      "Epoch 376/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6205e-05 - val_loss: 2.1434e-04\n",
      "Epoch 377/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6190e-05 - val_loss: 2.1425e-04\n",
      "Epoch 378/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6173e-05 - val_loss: 2.1419e-04\n",
      "Epoch 379/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6160e-05 - val_loss: 2.1412e-04\n",
      "Epoch 380/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6146e-05 - val_loss: 2.1405e-04\n",
      "Epoch 381/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6131e-05 - val_loss: 2.1398e-04\n",
      "Epoch 382/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6117e-05 - val_loss: 2.1390e-04\n",
      "Epoch 383/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6100e-05 - val_loss: 2.1383e-04\n",
      "Epoch 384/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6087e-05 - val_loss: 2.1376e-04\n",
      "Epoch 385/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6072e-05 - val_loss: 2.1369e-04\n",
      "Epoch 386/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6058e-05 - val_loss: 2.1361e-04\n",
      "Epoch 387/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6042e-05 - val_loss: 2.1354e-04\n",
      "Epoch 388/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6027e-05 - val_loss: 2.1348e-04\n",
      "Epoch 389/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6014e-05 - val_loss: 2.1341e-04\n",
      "Epoch 390/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.6000e-05 - val_loss: 2.1334e-04\n",
      "Epoch 391/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5985e-05 - val_loss: 2.1327e-04\n",
      "Epoch 392/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5970e-05 - val_loss: 2.1320e-04\n",
      "Epoch 393/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.5955e-05 - val_loss: 2.1313e-04\n",
      "Epoch 394/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5942e-05 - val_loss: 2.1306e-04\n",
      "Epoch 395/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5926e-05 - val_loss: 2.1300e-04\n",
      "Epoch 396/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 3.5913e-05 - val_loss: 2.1291e-04\n",
      "Epoch 397/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.5896e-05 - val_loss: 2.1285e-04\n",
      "Epoch 398/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5882e-05 - val_loss: 2.1277e-04\n",
      "Epoch 399/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5867e-05 - val_loss: 2.1271e-04\n",
      "Epoch 400/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5854e-05 - val_loss: 2.1264e-04\n",
      "Epoch 401/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5840e-05 - val_loss: 2.1257e-04\n",
      "Epoch 402/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 3.5825e-05 - val_loss: 2.1250e-04\n",
      "Epoch 403/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5810e-05 - val_loss: 2.1242e-04\n",
      "Epoch 404/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5795e-05 - val_loss: 2.1234e-04\n",
      "Epoch 405/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5780e-05 - val_loss: 2.1228e-04\n",
      "Epoch 406/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5766e-05 - val_loss: 2.1221e-04\n",
      "Epoch 407/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5751e-05 - val_loss: 2.1215e-04\n",
      "Epoch 408/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5737e-05 - val_loss: 2.1207e-04\n",
      "Epoch 409/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5722e-05 - val_loss: 2.1201e-04\n",
      "Epoch 410/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5709e-05 - val_loss: 2.1194e-04\n",
      "Epoch 411/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5694e-05 - val_loss: 2.1187e-04\n",
      "Epoch 412/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5680e-05 - val_loss: 2.1180e-04\n",
      "Epoch 413/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5665e-05 - val_loss: 2.1173e-04\n",
      "Epoch 414/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5650e-05 - val_loss: 2.1166e-04\n",
      "Epoch 415/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5637e-05 - val_loss: 2.1159e-04\n",
      "Epoch 416/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5622e-05 - val_loss: 2.1151e-04\n",
      "Epoch 417/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5606e-05 - val_loss: 2.1144e-04\n",
      "Epoch 418/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5592e-05 - val_loss: 2.1138e-04\n",
      "Epoch 419/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5579e-05 - val_loss: 2.1130e-04\n",
      "Epoch 420/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5564e-05 - val_loss: 2.1124e-04\n",
      "Epoch 421/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5550e-05 - val_loss: 2.1117e-04\n",
      "Epoch 422/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5536e-05 - val_loss: 2.1111e-04\n",
      "Epoch 423/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5522e-05 - val_loss: 2.1103e-04\n",
      "Epoch 424/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.5507e-05 - val_loss: 2.1096e-04\n",
      "Epoch 425/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5492e-05 - val_loss: 2.1088e-04\n",
      "Epoch 426/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5476e-05 - val_loss: 2.1083e-04\n",
      "Epoch 427/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5465e-05 - val_loss: 2.1076e-04\n",
      "Epoch 428/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5451e-05 - val_loss: 2.1068e-04\n",
      "Epoch 429/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5436e-05 - val_loss: 2.1061e-04\n",
      "Epoch 430/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5421e-05 - val_loss: 2.1053e-04\n",
      "Epoch 431/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5404e-05 - val_loss: 2.1048e-04\n",
      "Epoch 432/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5393e-05 - val_loss: 2.1041e-04\n",
      "Epoch 433/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 3.5379e-05 - val_loss: 2.1035e-04\n",
      "Epoch 434/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5365e-05 - val_loss: 2.1028e-04\n",
      "Epoch 435/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5351e-05 - val_loss: 2.1021e-04\n",
      "Epoch 436/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.5337e-05 - val_loss: 2.1014e-04\n",
      "Epoch 437/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5323e-05 - val_loss: 2.1007e-04\n",
      "Epoch 438/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5307e-05 - val_loss: 2.1000e-04\n",
      "Epoch 439/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5294e-05 - val_loss: 2.0992e-04\n",
      "Epoch 440/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5279e-05 - val_loss: 2.0985e-04\n",
      "Epoch 441/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.5263e-05 - val_loss: 2.0978e-04\n",
      "Epoch 442/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5250e-05 - val_loss: 2.0973e-04\n",
      "Epoch 443/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5237e-05 - val_loss: 2.0966e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 444/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5223e-05 - val_loss: 2.0959e-04\n",
      "Epoch 445/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5209e-05 - val_loss: 2.0952e-04\n",
      "Epoch 446/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5194e-05 - val_loss: 2.0945e-04\n",
      "Epoch 447/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5180e-05 - val_loss: 2.0939e-04\n",
      "Epoch 448/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5167e-05 - val_loss: 2.0931e-04\n",
      "Epoch 449/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5151e-05 - val_loss: 2.0924e-04\n",
      "Epoch 450/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5137e-05 - val_loss: 2.0918e-04\n",
      "Epoch 451/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5124e-05 - val_loss: 2.0911e-04\n",
      "Epoch 452/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5109e-05 - val_loss: 2.0904e-04\n",
      "Epoch 453/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5095e-05 - val_loss: 2.0897e-04\n",
      "Epoch 454/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5082e-05 - val_loss: 2.0890e-04\n",
      "Epoch 455/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.5068e-05 - val_loss: 2.0884e-04\n",
      "Epoch 456/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5055e-05 - val_loss: 2.0876e-04\n",
      "Epoch 457/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5038e-05 - val_loss: 2.0868e-04\n",
      "Epoch 458/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5024e-05 - val_loss: 2.0863e-04\n",
      "Epoch 459/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5012e-05 - val_loss: 2.0856e-04\n",
      "Epoch 460/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4997e-05 - val_loss: 2.0849e-04\n",
      "Epoch 461/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4983e-05 - val_loss: 2.0842e-04\n",
      "Epoch 462/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4969e-05 - val_loss: 2.0835e-04\n",
      "Epoch 463/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4954e-05 - val_loss: 2.0829e-04\n",
      "Epoch 464/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4941e-05 - val_loss: 2.0822e-04\n",
      "Epoch 465/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4928e-05 - val_loss: 2.0815e-04\n",
      "Epoch 466/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4913e-05 - val_loss: 2.0808e-04\n",
      "Epoch 467/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4899e-05 - val_loss: 2.0802e-04\n",
      "Epoch 468/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4887e-05 - val_loss: 2.0795e-04\n",
      "Epoch 469/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4871e-05 - val_loss: 2.0789e-04\n",
      "Epoch 470/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4859e-05 - val_loss: 2.0781e-04\n",
      "Epoch 471/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4844e-05 - val_loss: 2.0774e-04\n",
      "Epoch 472/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4830e-05 - val_loss: 2.0767e-04\n",
      "Epoch 473/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4816e-05 - val_loss: 2.0761e-04\n",
      "Epoch 474/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4802e-05 - val_loss: 2.0754e-04\n",
      "Epoch 475/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.4788e-05 - val_loss: 2.0748e-04\n",
      "Epoch 476/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4775e-05 - val_loss: 2.0740e-04\n",
      "Epoch 477/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4761e-05 - val_loss: 2.0734e-04\n",
      "Epoch 478/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.4746e-05 - val_loss: 2.0727e-04\n",
      "Epoch 479/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4732e-05 - val_loss: 2.0720e-04\n",
      "Epoch 480/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4720e-05 - val_loss: 2.0713e-04\n",
      "Epoch 481/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4705e-05 - val_loss: 2.0706e-04\n",
      "Epoch 482/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4690e-05 - val_loss: 2.0700e-04\n",
      "Epoch 483/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4677e-05 - val_loss: 2.0692e-04\n",
      "Epoch 484/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 3.4662e-05 - val_loss: 2.0686e-04\n",
      "Epoch 485/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4648e-05 - val_loss: 2.0681e-04\n",
      "Epoch 486/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4637e-05 - val_loss: 2.0673e-04\n",
      "Epoch 487/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4622e-05 - val_loss: 2.0666e-04\n",
      "Epoch 488/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4609e-05 - val_loss: 2.0659e-04\n",
      "Epoch 489/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.4594e-05 - val_loss: 2.0653e-04\n",
      "Epoch 490/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4582e-05 - val_loss: 2.0645e-04\n",
      "Epoch 491/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4566e-05 - val_loss: 2.0639e-04\n",
      "Epoch 492/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4554e-05 - val_loss: 2.0632e-04\n",
      "Epoch 493/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4539e-05 - val_loss: 2.0626e-04\n",
      "Epoch 494/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4525e-05 - val_loss: 2.0619e-04\n",
      "Epoch 495/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4512e-05 - val_loss: 2.0611e-04\n",
      "Epoch 496/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4497e-05 - val_loss: 2.0604e-04\n",
      "Epoch 497/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4483e-05 - val_loss: 2.0599e-04\n",
      "Epoch 498/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4470e-05 - val_loss: 2.0592e-04\n",
      "Epoch 499/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4455e-05 - val_loss: 2.0585e-04\n",
      "Epoch 500/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4443e-05 - val_loss: 2.0579e-04\n",
      "Epoch 501/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 3.4430e-05 - val_loss: 2.0571e-04\n",
      "Epoch 502/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 3.4415e-05 - val_loss: 2.0565e-04\n",
      "Epoch 503/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4401e-05 - val_loss: 2.0558e-04\n",
      "Epoch 504/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4389e-05 - val_loss: 2.0551e-04\n",
      "Epoch 505/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4374e-05 - val_loss: 2.0544e-04\n",
      "Epoch 506/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4360e-05 - val_loss: 2.0539e-04\n",
      "Epoch 507/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4348e-05 - val_loss: 2.0532e-04\n",
      "Epoch 508/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4334e-05 - val_loss: 2.0525e-04\n",
      "Epoch 509/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4320e-05 - val_loss: 2.0519e-04\n",
      "Epoch 510/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4307e-05 - val_loss: 2.0511e-04\n",
      "Epoch 511/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4292e-05 - val_loss: 2.0504e-04\n",
      "Epoch 512/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4279e-05 - val_loss: 2.0498e-04\n",
      "Epoch 513/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4266e-05 - val_loss: 2.0491e-04\n",
      "Epoch 514/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4251e-05 - val_loss: 2.0484e-04\n",
      "Epoch 515/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.4237e-05 - val_loss: 2.0478e-04\n",
      "Epoch 516/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4226e-05 - val_loss: 2.0472e-04\n",
      "Epoch 517/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4212e-05 - val_loss: 2.0464e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 518/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4196e-05 - val_loss: 2.0458e-04\n",
      "Epoch 519/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4184e-05 - val_loss: 2.0451e-04\n",
      "Epoch 520/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4171e-05 - val_loss: 2.0444e-04\n",
      "Epoch 521/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4156e-05 - val_loss: 2.0439e-04\n",
      "Epoch 522/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4144e-05 - val_loss: 2.0432e-04\n",
      "Epoch 523/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4130e-05 - val_loss: 2.0424e-04\n",
      "Epoch 524/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4115e-05 - val_loss: 2.0418e-04\n",
      "Epoch 525/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4102e-05 - val_loss: 2.0412e-04\n",
      "Epoch 526/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4089e-05 - val_loss: 2.0403e-04\n",
      "Epoch 527/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4074e-05 - val_loss: 2.0397e-04\n",
      "Epoch 528/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4061e-05 - val_loss: 2.0391e-04\n",
      "Epoch 529/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4048e-05 - val_loss: 2.0384e-04\n",
      "Epoch 530/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.4034e-05 - val_loss: 2.0377e-04\n",
      "Epoch 531/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4020e-05 - val_loss: 2.0370e-04\n",
      "Epoch 532/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4006e-05 - val_loss: 2.0364e-04\n",
      "Epoch 533/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3993e-05 - val_loss: 2.0357e-04\n",
      "Epoch 534/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3979e-05 - val_loss: 2.0351e-04\n",
      "Epoch 535/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3967e-05 - val_loss: 2.0345e-04\n",
      "Epoch 536/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3954e-05 - val_loss: 2.0337e-04\n",
      "Epoch 537/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.3939e-05 - val_loss: 2.0331e-04\n",
      "Epoch 538/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3926e-05 - val_loss: 2.0325e-04\n",
      "Epoch 539/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3912e-05 - val_loss: 2.0318e-04\n",
      "Epoch 540/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3900e-05 - val_loss: 2.0310e-04\n",
      "Epoch 541/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3885e-05 - val_loss: 2.0304e-04\n",
      "Epoch 542/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3872e-05 - val_loss: 2.0298e-04\n",
      "Epoch 543/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3859e-05 - val_loss: 2.0291e-04\n",
      "Epoch 544/1000\n",
      "32/32 [==============================] - 0s 137us/step - loss: 3.3845e-05 - val_loss: 2.0285e-04\n",
      "Epoch 545/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3832e-05 - val_loss: 2.0278e-04\n",
      "Epoch 546/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3818e-05 - val_loss: 2.0272e-04\n",
      "Epoch 547/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3805e-05 - val_loss: 2.0265e-04\n",
      "Epoch 548/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3793e-05 - val_loss: 2.0257e-04\n",
      "Epoch 549/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3778e-05 - val_loss: 2.0252e-04\n",
      "Epoch 550/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3766e-05 - val_loss: 2.0245e-04\n",
      "Epoch 551/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3752e-05 - val_loss: 2.0238e-04\n",
      "Epoch 552/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3738e-05 - val_loss: 2.0231e-04\n",
      "Epoch 553/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3725e-05 - val_loss: 2.0226e-04\n",
      "Epoch 554/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3713e-05 - val_loss: 2.0219e-04\n",
      "Epoch 555/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.3698e-05 - val_loss: 2.0211e-04\n",
      "Epoch 556/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3684e-05 - val_loss: 2.0205e-04\n",
      "Epoch 557/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3671e-05 - val_loss: 2.0200e-04\n",
      "Epoch 558/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3659e-05 - val_loss: 2.0191e-04\n",
      "Epoch 559/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3644e-05 - val_loss: 2.0185e-04\n",
      "Epoch 560/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3632e-05 - val_loss: 2.0178e-04\n",
      "Epoch 561/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.3618e-05 - val_loss: 2.0173e-04\n",
      "Epoch 562/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3605e-05 - val_loss: 2.0166e-04\n",
      "Epoch 563/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3592e-05 - val_loss: 2.0159e-04\n",
      "Epoch 564/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3579e-05 - val_loss: 2.0152e-04\n",
      "Epoch 565/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3564e-05 - val_loss: 2.0146e-04\n",
      "Epoch 566/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3552e-05 - val_loss: 2.0140e-04\n",
      "Epoch 567/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3539e-05 - val_loss: 2.0132e-04\n",
      "Epoch 568/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.3525e-05 - val_loss: 2.0125e-04\n",
      "Epoch 569/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3510e-05 - val_loss: 2.0119e-04\n",
      "Epoch 570/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3498e-05 - val_loss: 2.0112e-04\n",
      "Epoch 571/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.3484e-05 - val_loss: 2.0106e-04\n",
      "Epoch 572/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3473e-05 - val_loss: 2.0099e-04\n",
      "Epoch 573/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3459e-05 - val_loss: 2.0093e-04\n",
      "Epoch 574/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3446e-05 - val_loss: 2.0086e-04\n",
      "Epoch 575/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3432e-05 - val_loss: 2.0081e-04\n",
      "Epoch 576/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3421e-05 - val_loss: 2.0073e-04\n",
      "Epoch 577/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3407e-05 - val_loss: 2.0066e-04\n",
      "Epoch 578/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3392e-05 - val_loss: 2.0061e-04\n",
      "Epoch 579/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.3381e-05 - val_loss: 2.0053e-04\n",
      "Epoch 580/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3367e-05 - val_loss: 2.0047e-04\n",
      "Epoch 581/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3354e-05 - val_loss: 2.0040e-04\n",
      "Epoch 582/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.3340e-05 - val_loss: 2.0034e-04\n",
      "Epoch 583/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3327e-05 - val_loss: 2.0028e-04\n",
      "Epoch 584/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3314e-05 - val_loss: 2.0022e-04\n",
      "Epoch 585/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3302e-05 - val_loss: 2.0015e-04\n",
      "Epoch 586/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3288e-05 - val_loss: 2.0008e-04\n",
      "Epoch 587/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3275e-05 - val_loss: 2.0002e-04\n",
      "Epoch 588/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3262e-05 - val_loss: 1.9995e-04\n",
      "Epoch 589/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3249e-05 - val_loss: 1.9989e-04\n",
      "Epoch 590/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3235e-05 - val_loss: 1.9981e-04\n",
      "Epoch 591/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3222e-05 - val_loss: 1.9975e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 592/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3208e-05 - val_loss: 1.9969e-04\n",
      "Epoch 593/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 3.3195e-05 - val_loss: 1.9962e-04\n",
      "Epoch 594/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3182e-05 - val_loss: 1.9955e-04\n",
      "Epoch 595/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3169e-05 - val_loss: 1.9948e-04\n",
      "Epoch 596/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3155e-05 - val_loss: 1.9942e-04\n",
      "Epoch 597/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3143e-05 - val_loss: 1.9937e-04\n",
      "Epoch 598/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3130e-05 - val_loss: 1.9930e-04\n",
      "Epoch 599/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3117e-05 - val_loss: 1.9923e-04\n",
      "Epoch 600/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 3.3104e-05 - val_loss: 1.9916e-04\n",
      "Epoch 601/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3090e-05 - val_loss: 1.9910e-04\n",
      "Epoch 602/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3077e-05 - val_loss: 1.9903e-04\n",
      "Epoch 603/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3065e-05 - val_loss: 1.9897e-04\n",
      "Epoch 604/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3052e-05 - val_loss: 1.9891e-04\n",
      "Epoch 605/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.3039e-05 - val_loss: 1.9884e-04\n",
      "Epoch 606/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3025e-05 - val_loss: 1.9877e-04\n",
      "Epoch 607/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3012e-05 - val_loss: 1.9870e-04\n",
      "Epoch 608/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2999e-05 - val_loss: 1.9864e-04\n",
      "Epoch 609/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2985e-05 - val_loss: 1.9858e-04\n",
      "Epoch 610/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2973e-05 - val_loss: 1.9851e-04\n",
      "Epoch 611/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2960e-05 - val_loss: 1.9845e-04\n",
      "Epoch 612/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.2947e-05 - val_loss: 1.9838e-04\n",
      "Epoch 613/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2933e-05 - val_loss: 1.9833e-04\n",
      "Epoch 614/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.2922e-05 - val_loss: 1.9826e-04\n",
      "Epoch 615/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2909e-05 - val_loss: 1.9818e-04\n",
      "Epoch 616/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2895e-05 - val_loss: 1.9812e-04\n",
      "Epoch 617/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2882e-05 - val_loss: 1.9806e-04\n",
      "Epoch 618/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2869e-05 - val_loss: 1.9799e-04\n",
      "Epoch 619/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2856e-05 - val_loss: 1.9793e-04\n",
      "Epoch 620/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2844e-05 - val_loss: 1.9786e-04\n",
      "Epoch 621/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2829e-05 - val_loss: 1.9781e-04\n",
      "Epoch 622/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2818e-05 - val_loss: 1.9774e-04\n",
      "Epoch 623/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2806e-05 - val_loss: 1.9768e-04\n",
      "Epoch 624/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 3.2792e-05 - val_loss: 1.9761e-04\n",
      "Epoch 625/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2779e-05 - val_loss: 1.9755e-04\n",
      "Epoch 626/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2766e-05 - val_loss: 1.9748e-04\n",
      "Epoch 627/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2753e-05 - val_loss: 1.9741e-04\n",
      "Epoch 628/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2740e-05 - val_loss: 1.9735e-04\n",
      "Epoch 629/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 3.2728e-05 - val_loss: 1.9728e-04\n",
      "Epoch 630/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2714e-05 - val_loss: 1.9722e-04\n",
      "Epoch 631/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2701e-05 - val_loss: 1.9715e-04\n",
      "Epoch 632/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2689e-05 - val_loss: 1.9709e-04\n",
      "Epoch 633/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2675e-05 - val_loss: 1.9702e-04\n",
      "Epoch 634/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2661e-05 - val_loss: 1.9695e-04\n",
      "Epoch 635/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2649e-05 - val_loss: 1.9688e-04\n",
      "Epoch 636/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2636e-05 - val_loss: 1.9683e-04\n",
      "Epoch 637/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2624e-05 - val_loss: 1.9677e-04\n",
      "Epoch 638/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2611e-05 - val_loss: 1.9670e-04\n",
      "Epoch 639/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2598e-05 - val_loss: 1.9664e-04\n",
      "Epoch 640/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2586e-05 - val_loss: 1.9658e-04\n",
      "Epoch 641/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2575e-05 - val_loss: 1.9651e-04\n",
      "Epoch 642/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2560e-05 - val_loss: 1.9644e-04\n",
      "Epoch 643/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 3.2547e-05 - val_loss: 1.9637e-04\n",
      "Epoch 644/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2534e-05 - val_loss: 1.9631e-04\n",
      "Epoch 645/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2521e-05 - val_loss: 1.9624e-04\n",
      "Epoch 646/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2507e-05 - val_loss: 1.9618e-04\n",
      "Epoch 647/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2495e-05 - val_loss: 1.9612e-04\n",
      "Epoch 648/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2482e-05 - val_loss: 1.9605e-04\n",
      "Epoch 649/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2469e-05 - val_loss: 1.9600e-04\n",
      "Epoch 650/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2458e-05 - val_loss: 1.9592e-04\n",
      "Epoch 651/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2443e-05 - val_loss: 1.9586e-04\n",
      "Epoch 652/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2431e-05 - val_loss: 1.9580e-04\n",
      "Epoch 653/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2419e-05 - val_loss: 1.9573e-04\n",
      "Epoch 654/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.2405e-05 - val_loss: 1.9567e-04\n",
      "Epoch 655/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2392e-05 - val_loss: 1.9561e-04\n",
      "Epoch 656/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2381e-05 - val_loss: 1.9553e-04\n",
      "Epoch 657/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.2365e-05 - val_loss: 1.9548e-04\n",
      "Epoch 658/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2354e-05 - val_loss: 1.9542e-04\n",
      "Epoch 659/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2343e-05 - val_loss: 1.9535e-04\n",
      "Epoch 660/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2329e-05 - val_loss: 1.9529e-04\n",
      "Epoch 661/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2316e-05 - val_loss: 1.9523e-04\n",
      "Epoch 662/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2304e-05 - val_loss: 1.9516e-04\n",
      "Epoch 663/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2291e-05 - val_loss: 1.9509e-04\n",
      "Epoch 664/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2277e-05 - val_loss: 1.9502e-04\n",
      "Epoch 665/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2265e-05 - val_loss: 1.9497e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 666/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.2253e-05 - val_loss: 1.9490e-04\n",
      "Epoch 667/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.2239e-05 - val_loss: 1.9484e-04\n",
      "Epoch 668/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2228e-05 - val_loss: 1.9478e-04\n",
      "Epoch 669/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2215e-05 - val_loss: 1.9471e-04\n",
      "Epoch 670/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2201e-05 - val_loss: 1.9464e-04\n",
      "Epoch 671/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2187e-05 - val_loss: 1.9457e-04\n",
      "Epoch 672/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.2175e-05 - val_loss: 1.9451e-04\n",
      "Epoch 673/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2164e-05 - val_loss: 1.9445e-04\n",
      "Epoch 674/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2150e-05 - val_loss: 1.9439e-04\n",
      "Epoch 675/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2139e-05 - val_loss: 1.9432e-04\n",
      "Epoch 676/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2125e-05 - val_loss: 1.9426e-04\n",
      "Epoch 677/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 3.2112e-05 - val_loss: 1.9420e-04\n",
      "Epoch 678/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2100e-05 - val_loss: 1.9413e-04\n",
      "Epoch 679/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2088e-05 - val_loss: 1.9407e-04\n",
      "Epoch 680/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2075e-05 - val_loss: 1.9401e-04\n",
      "Epoch 681/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.2064e-05 - val_loss: 1.9394e-04\n",
      "Epoch 682/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2049e-05 - val_loss: 1.9387e-04\n",
      "Epoch 683/1000\n",
      "32/32 [==============================] - 0s 164us/step - loss: 3.2036e-05 - val_loss: 1.9381e-04\n",
      "Epoch 684/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2024e-05 - val_loss: 1.9376e-04\n",
      "Epoch 685/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2012e-05 - val_loss: 1.9368e-04\n",
      "Epoch 686/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1998e-05 - val_loss: 1.9362e-04\n",
      "Epoch 687/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1985e-05 - val_loss: 1.9357e-04\n",
      "Epoch 688/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1975e-05 - val_loss: 1.9350e-04\n",
      "Epoch 689/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1962e-05 - val_loss: 1.9343e-04\n",
      "Epoch 690/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.1949e-05 - val_loss: 1.9337e-04\n",
      "Epoch 691/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1937e-05 - val_loss: 1.9330e-04\n",
      "Epoch 692/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1924e-05 - val_loss: 1.9324e-04\n",
      "Epoch 693/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1911e-05 - val_loss: 1.9319e-04\n",
      "Epoch 694/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1899e-05 - val_loss: 1.9311e-04\n",
      "Epoch 695/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.1886e-05 - val_loss: 1.9305e-04\n",
      "Epoch 696/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1874e-05 - val_loss: 1.9299e-04\n",
      "Epoch 697/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1862e-05 - val_loss: 1.9293e-04\n",
      "Epoch 698/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1849e-05 - val_loss: 1.9286e-04\n",
      "Epoch 699/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1836e-05 - val_loss: 1.9279e-04\n",
      "Epoch 700/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1823e-05 - val_loss: 1.9274e-04\n",
      "Epoch 701/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1811e-05 - val_loss: 1.9267e-04\n",
      "Epoch 702/1000\n",
      "32/32 [==============================] - 0s 172us/step - loss: 3.1799e-05 - val_loss: 1.9261e-04\n",
      "Epoch 703/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1786e-05 - val_loss: 1.9254e-04\n",
      "Epoch 704/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1773e-05 - val_loss: 1.9248e-04\n",
      "Epoch 705/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.1761e-05 - val_loss: 1.9242e-04\n",
      "Epoch 706/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1748e-05 - val_loss: 1.9236e-04\n",
      "Epoch 707/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1736e-05 - val_loss: 1.9230e-04\n",
      "Epoch 708/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1725e-05 - val_loss: 1.9223e-04\n",
      "Epoch 709/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.1712e-05 - val_loss: 1.9217e-04\n",
      "Epoch 710/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1699e-05 - val_loss: 1.9210e-04\n",
      "Epoch 711/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1686e-05 - val_loss: 1.9203e-04\n",
      "Epoch 712/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1674e-05 - val_loss: 1.9197e-04\n",
      "Epoch 713/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1660e-05 - val_loss: 1.9191e-04\n",
      "Epoch 714/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1649e-05 - val_loss: 1.9184e-04\n",
      "Epoch 715/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1635e-05 - val_loss: 1.9178e-04\n",
      "Epoch 716/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1624e-05 - val_loss: 1.9172e-04\n",
      "Epoch 717/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1611e-05 - val_loss: 1.9165e-04\n",
      "Epoch 718/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1598e-05 - val_loss: 1.9159e-04\n",
      "Epoch 719/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1586e-05 - val_loss: 1.9152e-04\n",
      "Epoch 720/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1574e-05 - val_loss: 1.9146e-04\n",
      "Epoch 721/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1560e-05 - val_loss: 1.9140e-04\n",
      "Epoch 722/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1549e-05 - val_loss: 1.9133e-04\n",
      "Epoch 723/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1536e-05 - val_loss: 1.9127e-04\n",
      "Epoch 724/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1524e-05 - val_loss: 1.9121e-04\n",
      "Epoch 725/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1511e-05 - val_loss: 1.9115e-04\n",
      "Epoch 726/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1499e-05 - val_loss: 1.9109e-04\n",
      "Epoch 727/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1487e-05 - val_loss: 1.9102e-04\n",
      "Epoch 728/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1474e-05 - val_loss: 1.9096e-04\n",
      "Epoch 729/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.1462e-05 - val_loss: 1.9090e-04\n",
      "Epoch 730/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.1449e-05 - val_loss: 1.9083e-04\n",
      "Epoch 731/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1437e-05 - val_loss: 1.9077e-04\n",
      "Epoch 732/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1426e-05 - val_loss: 1.9070e-04\n",
      "Epoch 733/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1412e-05 - val_loss: 1.9065e-04\n",
      "Epoch 734/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1399e-05 - val_loss: 1.9059e-04\n",
      "Epoch 735/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1388e-05 - val_loss: 1.9052e-04\n",
      "Epoch 736/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.1376e-05 - val_loss: 1.9046e-04\n",
      "Epoch 737/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1363e-05 - val_loss: 1.9040e-04\n",
      "Epoch 738/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1351e-05 - val_loss: 1.9033e-04\n",
      "Epoch 739/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1338e-05 - val_loss: 1.9028e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 740/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1327e-05 - val_loss: 1.9021e-04\n",
      "Epoch 741/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 3.1314e-05 - val_loss: 1.9015e-04\n",
      "Epoch 742/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1302e-05 - val_loss: 1.9008e-04\n",
      "Epoch 743/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1290e-05 - val_loss: 1.9001e-04\n",
      "Epoch 744/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1278e-05 - val_loss: 1.8995e-04\n",
      "Epoch 745/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1265e-05 - val_loss: 1.8989e-04\n",
      "Epoch 746/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1253e-05 - val_loss: 1.8983e-04\n",
      "Epoch 747/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1240e-05 - val_loss: 1.8976e-04\n",
      "Epoch 748/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1227e-05 - val_loss: 1.8970e-04\n",
      "Epoch 749/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1215e-05 - val_loss: 1.8964e-04\n",
      "Epoch 750/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1203e-05 - val_loss: 1.8958e-04\n",
      "Epoch 751/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1191e-05 - val_loss: 1.8951e-04\n",
      "Epoch 752/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1179e-05 - val_loss: 1.8945e-04\n",
      "Epoch 753/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.1167e-05 - val_loss: 1.8939e-04\n",
      "Epoch 754/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1154e-05 - val_loss: 1.8933e-04\n",
      "Epoch 755/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1143e-05 - val_loss: 1.8926e-04\n",
      "Epoch 756/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1129e-05 - val_loss: 1.8920e-04\n",
      "Epoch 757/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1118e-05 - val_loss: 1.8915e-04\n",
      "Epoch 758/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1106e-05 - val_loss: 1.8908e-04\n",
      "Epoch 759/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1093e-05 - val_loss: 1.8901e-04\n",
      "Epoch 760/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1080e-05 - val_loss: 1.8896e-04\n",
      "Epoch 761/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1070e-05 - val_loss: 1.8889e-04\n",
      "Epoch 762/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1056e-05 - val_loss: 1.8882e-04\n",
      "Epoch 763/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1044e-05 - val_loss: 1.8876e-04\n",
      "Epoch 764/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1032e-05 - val_loss: 1.8870e-04\n",
      "Epoch 765/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1020e-05 - val_loss: 1.8864e-04\n",
      "Epoch 766/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1007e-05 - val_loss: 1.8858e-04\n",
      "Epoch 767/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0995e-05 - val_loss: 1.8851e-04\n",
      "Epoch 768/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0983e-05 - val_loss: 1.8845e-04\n",
      "Epoch 769/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0970e-05 - val_loss: 1.8839e-04\n",
      "Epoch 770/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0959e-05 - val_loss: 1.8832e-04\n",
      "Epoch 771/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0945e-05 - val_loss: 1.8827e-04\n",
      "Epoch 772/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0936e-05 - val_loss: 1.8821e-04\n",
      "Epoch 773/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0922e-05 - val_loss: 1.8815e-04\n",
      "Epoch 774/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0912e-05 - val_loss: 1.8808e-04\n",
      "Epoch 775/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0898e-05 - val_loss: 1.8801e-04\n",
      "Epoch 776/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.0886e-05 - val_loss: 1.8794e-04\n",
      "Epoch 777/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0873e-05 - val_loss: 1.8789e-04\n",
      "Epoch 778/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0862e-05 - val_loss: 1.8782e-04\n",
      "Epoch 779/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0850e-05 - val_loss: 1.8776e-04\n",
      "Epoch 780/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.0837e-05 - val_loss: 1.8770e-04\n",
      "Epoch 781/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0827e-05 - val_loss: 1.8764e-04\n",
      "Epoch 782/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0812e-05 - val_loss: 1.8757e-04\n",
      "Epoch 783/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0801e-05 - val_loss: 1.8750e-04\n",
      "Epoch 784/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0788e-05 - val_loss: 1.8745e-04\n",
      "Epoch 785/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0777e-05 - val_loss: 1.8739e-04\n",
      "Epoch 786/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0764e-05 - val_loss: 1.8733e-04\n",
      "Epoch 787/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0753e-05 - val_loss: 1.8727e-04\n",
      "Epoch 788/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0741e-05 - val_loss: 1.8720e-04\n",
      "Epoch 789/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0727e-05 - val_loss: 1.8715e-04\n",
      "Epoch 790/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0717e-05 - val_loss: 1.8708e-04\n",
      "Epoch 791/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0703e-05 - val_loss: 1.8703e-04\n",
      "Epoch 792/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0694e-05 - val_loss: 1.8697e-04\n",
      "Epoch 793/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0681e-05 - val_loss: 1.8691e-04\n",
      "Epoch 794/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0669e-05 - val_loss: 1.8684e-04\n",
      "Epoch 795/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0656e-05 - val_loss: 1.8677e-04\n",
      "Epoch 796/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0644e-05 - val_loss: 1.8671e-04\n",
      "Epoch 797/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0632e-05 - val_loss: 1.8665e-04\n",
      "Epoch 798/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0620e-05 - val_loss: 1.8659e-04\n",
      "Epoch 799/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0608e-05 - val_loss: 1.8653e-04\n",
      "Epoch 800/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0596e-05 - val_loss: 1.8646e-04\n",
      "Epoch 801/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0583e-05 - val_loss: 1.8640e-04\n",
      "Epoch 802/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0571e-05 - val_loss: 1.8633e-04\n",
      "Epoch 803/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0559e-05 - val_loss: 1.8628e-04\n",
      "Epoch 804/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0548e-05 - val_loss: 1.8621e-04\n",
      "Epoch 805/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0536e-05 - val_loss: 1.8616e-04\n",
      "Epoch 806/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0525e-05 - val_loss: 1.8609e-04\n",
      "Epoch 807/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0511e-05 - val_loss: 1.8603e-04\n",
      "Epoch 808/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.0500e-05 - val_loss: 1.8597e-04\n",
      "Epoch 809/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0488e-05 - val_loss: 1.8591e-04\n",
      "Epoch 810/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0476e-05 - val_loss: 1.8585e-04\n",
      "Epoch 811/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 3.0464e-05 - val_loss: 1.8578e-04\n",
      "Epoch 812/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.0452e-05 - val_loss: 1.8573e-04\n",
      "Epoch 813/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0441e-05 - val_loss: 1.8567e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 814/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0429e-05 - val_loss: 1.8560e-04\n",
      "Epoch 815/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0416e-05 - val_loss: 1.8553e-04\n",
      "Epoch 816/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0404e-05 - val_loss: 1.8548e-04\n",
      "Epoch 817/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0393e-05 - val_loss: 1.8542e-04\n",
      "Epoch 818/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0381e-05 - val_loss: 1.8535e-04\n",
      "Epoch 819/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0368e-05 - val_loss: 1.8529e-04\n",
      "Epoch 820/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0357e-05 - val_loss: 1.8523e-04\n",
      "Epoch 821/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0344e-05 - val_loss: 1.8517e-04\n",
      "Epoch 822/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0333e-05 - val_loss: 1.8510e-04\n",
      "Epoch 823/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0319e-05 - val_loss: 1.8504e-04\n",
      "Epoch 824/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0308e-05 - val_loss: 1.8498e-04\n",
      "Epoch 825/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0297e-05 - val_loss: 1.8493e-04\n",
      "Epoch 826/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0286e-05 - val_loss: 1.8486e-04\n",
      "Epoch 827/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0273e-05 - val_loss: 1.8479e-04\n",
      "Epoch 828/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0261e-05 - val_loss: 1.8474e-04\n",
      "Epoch 829/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0250e-05 - val_loss: 1.8468e-04\n",
      "Epoch 830/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0238e-05 - val_loss: 1.8461e-04\n",
      "Epoch 831/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0225e-05 - val_loss: 1.8455e-04\n",
      "Epoch 832/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0213e-05 - val_loss: 1.8448e-04\n",
      "Epoch 833/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0200e-05 - val_loss: 1.8443e-04\n",
      "Epoch 834/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0189e-05 - val_loss: 1.8437e-04\n",
      "Epoch 835/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.0178e-05 - val_loss: 1.8430e-04\n",
      "Epoch 836/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0165e-05 - val_loss: 1.8424e-04\n",
      "Epoch 837/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0154e-05 - val_loss: 1.8418e-04\n",
      "Epoch 838/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0142e-05 - val_loss: 1.8411e-04\n",
      "Epoch 839/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0129e-05 - val_loss: 1.8405e-04\n",
      "Epoch 840/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0117e-05 - val_loss: 1.8400e-04\n",
      "Epoch 841/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0106e-05 - val_loss: 1.8394e-04\n",
      "Epoch 842/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0095e-05 - val_loss: 1.8388e-04\n",
      "Epoch 843/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0083e-05 - val_loss: 1.8382e-04\n",
      "Epoch 844/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0072e-05 - val_loss: 1.8375e-04\n",
      "Epoch 845/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0059e-05 - val_loss: 1.8369e-04\n",
      "Epoch 846/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0048e-05 - val_loss: 1.8362e-04\n",
      "Epoch 847/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0035e-05 - val_loss: 1.8357e-04\n",
      "Epoch 848/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0024e-05 - val_loss: 1.8351e-04\n",
      "Epoch 849/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0012e-05 - val_loss: 1.8345e-04\n",
      "Epoch 850/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0000e-05 - val_loss: 1.8338e-04\n",
      "Epoch 851/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9988e-05 - val_loss: 1.8332e-04\n",
      "Epoch 852/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9977e-05 - val_loss: 1.8326e-04\n",
      "Epoch 853/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9966e-05 - val_loss: 1.8320e-04\n",
      "Epoch 854/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9952e-05 - val_loss: 1.8314e-04\n",
      "Epoch 855/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9941e-05 - val_loss: 1.8307e-04\n",
      "Epoch 856/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9929e-05 - val_loss: 1.8301e-04\n",
      "Epoch 857/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9917e-05 - val_loss: 1.8296e-04\n",
      "Epoch 858/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9906e-05 - val_loss: 1.8290e-04\n",
      "Epoch 859/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9895e-05 - val_loss: 1.8284e-04\n",
      "Epoch 860/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9884e-05 - val_loss: 1.8277e-04\n",
      "Epoch 861/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9870e-05 - val_loss: 1.8271e-04\n",
      "Epoch 862/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9858e-05 - val_loss: 1.8266e-04\n",
      "Epoch 863/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9847e-05 - val_loss: 1.8259e-04\n",
      "Epoch 864/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9836e-05 - val_loss: 1.8253e-04\n",
      "Epoch 865/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9824e-05 - val_loss: 1.8247e-04\n",
      "Epoch 866/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.9812e-05 - val_loss: 1.8241e-04\n",
      "Epoch 867/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9801e-05 - val_loss: 1.8234e-04\n",
      "Epoch 868/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9789e-05 - val_loss: 1.8229e-04\n",
      "Epoch 869/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9778e-05 - val_loss: 1.8222e-04\n",
      "Epoch 870/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9765e-05 - val_loss: 1.8216e-04\n",
      "Epoch 871/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9753e-05 - val_loss: 1.8209e-04\n",
      "Epoch 872/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9741e-05 - val_loss: 1.8204e-04\n",
      "Epoch 873/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9730e-05 - val_loss: 1.8198e-04\n",
      "Epoch 874/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9719e-05 - val_loss: 1.8192e-04\n",
      "Epoch 875/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9707e-05 - val_loss: 1.8186e-04\n",
      "Epoch 876/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9695e-05 - val_loss: 1.8180e-04\n",
      "Epoch 877/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9682e-05 - val_loss: 1.8173e-04\n",
      "Epoch 878/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9671e-05 - val_loss: 1.8168e-04\n",
      "Epoch 879/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9660e-05 - val_loss: 1.8161e-04\n",
      "Epoch 880/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9648e-05 - val_loss: 1.8156e-04\n",
      "Epoch 881/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9637e-05 - val_loss: 1.8150e-04\n",
      "Epoch 882/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9625e-05 - val_loss: 1.8143e-04\n",
      "Epoch 883/1000\n",
      "32/32 [==============================] - 0s 158us/step - loss: 2.9613e-05 - val_loss: 1.8138e-04\n",
      "Epoch 884/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9602e-05 - val_loss: 1.8130e-04\n",
      "Epoch 885/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9589e-05 - val_loss: 1.8125e-04\n",
      "Epoch 886/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9578e-05 - val_loss: 1.8119e-04\n",
      "Epoch 887/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9566e-05 - val_loss: 1.8113e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 888/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9555e-05 - val_loss: 1.8106e-04\n",
      "Epoch 889/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9543e-05 - val_loss: 1.8101e-04\n",
      "Epoch 890/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9532e-05 - val_loss: 1.8094e-04\n",
      "Epoch 891/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9519e-05 - val_loss: 1.8089e-04\n",
      "Epoch 892/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9508e-05 - val_loss: 1.8082e-04\n",
      "Epoch 893/1000\n",
      "32/32 [==============================] - 0s 374us/step - loss: 2.9497e-05 - val_loss: 1.8077e-04\n",
      "Epoch 894/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 2.9485e-05 - val_loss: 1.8071e-04\n",
      "Epoch 895/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9474e-05 - val_loss: 1.8064e-04\n",
      "Epoch 896/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.9462e-05 - val_loss: 1.8058e-04\n",
      "Epoch 897/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9449e-05 - val_loss: 1.8052e-04\n",
      "Epoch 898/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.9438e-05 - val_loss: 1.8046e-04\n",
      "Epoch 899/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9427e-05 - val_loss: 1.8040e-04\n",
      "Epoch 900/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9416e-05 - val_loss: 1.8034e-04\n",
      "Epoch 901/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9404e-05 - val_loss: 1.8029e-04\n",
      "Epoch 902/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9393e-05 - val_loss: 1.8022e-04\n",
      "Epoch 903/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9381e-05 - val_loss: 1.8017e-04\n",
      "Epoch 904/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9370e-05 - val_loss: 1.8010e-04\n",
      "Epoch 905/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.9358e-05 - val_loss: 1.8004e-04\n",
      "Epoch 906/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.9346e-05 - val_loss: 1.7999e-04\n",
      "Epoch 907/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9336e-05 - val_loss: 1.7993e-04\n",
      "Epoch 908/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9324e-05 - val_loss: 1.7986e-04\n",
      "Epoch 909/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9311e-05 - val_loss: 1.7979e-04\n",
      "Epoch 910/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9299e-05 - val_loss: 1.7973e-04\n",
      "Epoch 911/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 2.9288e-05 - val_loss: 1.7967e-04\n",
      "Epoch 912/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9276e-05 - val_loss: 1.7961e-04\n",
      "Epoch 913/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9265e-05 - val_loss: 1.7956e-04\n",
      "Epoch 914/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9254e-05 - val_loss: 1.7950e-04\n",
      "Epoch 915/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9243e-05 - val_loss: 1.7944e-04\n",
      "Epoch 916/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9231e-05 - val_loss: 1.7937e-04\n",
      "Epoch 917/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9219e-05 - val_loss: 1.7932e-04\n",
      "Epoch 918/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9208e-05 - val_loss: 1.7926e-04\n",
      "Epoch 919/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.9197e-05 - val_loss: 1.7919e-04\n",
      "Epoch 920/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9185e-05 - val_loss: 1.7914e-04\n",
      "Epoch 921/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9174e-05 - val_loss: 1.7908e-04\n",
      "Epoch 922/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9162e-05 - val_loss: 1.7902e-04\n",
      "Epoch 923/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9151e-05 - val_loss: 1.7896e-04\n",
      "Epoch 924/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9140e-05 - val_loss: 1.7890e-04\n",
      "Epoch 925/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9127e-05 - val_loss: 1.7885e-04\n",
      "Epoch 926/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9117e-05 - val_loss: 1.7878e-04\n",
      "Epoch 927/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9104e-05 - val_loss: 1.7871e-04\n",
      "Epoch 928/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9092e-05 - val_loss: 1.7865e-04\n",
      "Epoch 929/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9082e-05 - val_loss: 1.7860e-04\n",
      "Epoch 930/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9071e-05 - val_loss: 1.7854e-04\n",
      "Epoch 931/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9059e-05 - val_loss: 1.7847e-04\n",
      "Epoch 932/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9048e-05 - val_loss: 1.7841e-04\n",
      "Epoch 933/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9036e-05 - val_loss: 1.7836e-04\n",
      "Epoch 934/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9025e-05 - val_loss: 1.7829e-04\n",
      "Epoch 935/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9012e-05 - val_loss: 1.7823e-04\n",
      "Epoch 936/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9001e-05 - val_loss: 1.7817e-04\n",
      "Epoch 937/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8990e-05 - val_loss: 1.7811e-04\n",
      "Epoch 938/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8978e-05 - val_loss: 1.7805e-04\n",
      "Epoch 939/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8966e-05 - val_loss: 1.7799e-04\n",
      "Epoch 940/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8956e-05 - val_loss: 1.7793e-04\n",
      "Epoch 941/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8944e-05 - val_loss: 1.7788e-04\n",
      "Epoch 942/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8934e-05 - val_loss: 1.7782e-04\n",
      "Epoch 943/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8921e-05 - val_loss: 1.7775e-04\n",
      "Epoch 944/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8910e-05 - val_loss: 1.7769e-04\n",
      "Epoch 945/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8899e-05 - val_loss: 1.7764e-04\n",
      "Epoch 946/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8887e-05 - val_loss: 1.7758e-04\n",
      "Epoch 947/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8876e-05 - val_loss: 1.7752e-04\n",
      "Epoch 948/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8865e-05 - val_loss: 1.7746e-04\n",
      "Epoch 949/1000\n",
      "32/32 [==============================] - 0s 172us/step - loss: 2.8854e-05 - val_loss: 1.7740e-04\n",
      "Epoch 950/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8841e-05 - val_loss: 1.7734e-04\n",
      "Epoch 951/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8831e-05 - val_loss: 1.7728e-04\n",
      "Epoch 952/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8820e-05 - val_loss: 1.7721e-04\n",
      "Epoch 953/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8807e-05 - val_loss: 1.7716e-04\n",
      "Epoch 954/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8796e-05 - val_loss: 1.7710e-04\n",
      "Epoch 955/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8786e-05 - val_loss: 1.7704e-04\n",
      "Epoch 956/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8775e-05 - val_loss: 1.7698e-04\n",
      "Epoch 957/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8763e-05 - val_loss: 1.7691e-04\n",
      "Epoch 958/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8751e-05 - val_loss: 1.7686e-04\n",
      "Epoch 959/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8740e-05 - val_loss: 1.7679e-04\n",
      "Epoch 960/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8728e-05 - val_loss: 1.7674e-04\n",
      "Epoch 961/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8717e-05 - val_loss: 1.7669e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 962/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8707e-05 - val_loss: 1.7663e-04\n",
      "Epoch 963/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8695e-05 - val_loss: 1.7656e-04\n",
      "Epoch 964/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8684e-05 - val_loss: 1.7651e-04\n",
      "Epoch 965/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8672e-05 - val_loss: 1.7645e-04\n",
      "Epoch 966/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8662e-05 - val_loss: 1.7638e-04\n",
      "Epoch 967/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 2.8649e-05 - val_loss: 1.7632e-04\n",
      "Epoch 968/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8638e-05 - val_loss: 1.7626e-04\n",
      "Epoch 969/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8626e-05 - val_loss: 1.7621e-04\n",
      "Epoch 970/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8617e-05 - val_loss: 1.7615e-04\n",
      "Epoch 971/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8605e-05 - val_loss: 1.7608e-04\n",
      "Epoch 972/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8593e-05 - val_loss: 1.7602e-04\n",
      "Epoch 973/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8582e-05 - val_loss: 1.7596e-04\n",
      "Epoch 974/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8570e-05 - val_loss: 1.7591e-04\n",
      "Epoch 975/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8560e-05 - val_loss: 1.7584e-04\n",
      "Epoch 976/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8548e-05 - val_loss: 1.7579e-04\n",
      "Epoch 977/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8537e-05 - val_loss: 1.7573e-04\n",
      "Epoch 978/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8525e-05 - val_loss: 1.7566e-04\n",
      "Epoch 979/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8513e-05 - val_loss: 1.7560e-04\n",
      "Epoch 980/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8502e-05 - val_loss: 1.7555e-04\n",
      "Epoch 981/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8492e-05 - val_loss: 1.7550e-04\n",
      "Epoch 982/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8481e-05 - val_loss: 1.7543e-04\n",
      "Epoch 983/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8468e-05 - val_loss: 1.7537e-04\n",
      "Epoch 984/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8458e-05 - val_loss: 1.7532e-04\n",
      "Epoch 985/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8447e-05 - val_loss: 1.7525e-04\n",
      "Epoch 986/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8435e-05 - val_loss: 1.7519e-04\n",
      "Epoch 987/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8423e-05 - val_loss: 1.7513e-04\n",
      "Epoch 988/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8413e-05 - val_loss: 1.7508e-04\n",
      "Epoch 989/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8403e-05 - val_loss: 1.7502e-04\n",
      "Epoch 990/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8391e-05 - val_loss: 1.7496e-04\n",
      "Epoch 991/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8379e-05 - val_loss: 1.7489e-04\n",
      "Epoch 992/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8368e-05 - val_loss: 1.7484e-04\n",
      "Epoch 993/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8357e-05 - val_loss: 1.7478e-04\n",
      "Epoch 994/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8347e-05 - val_loss: 1.7473e-04\n",
      "Epoch 995/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8335e-05 - val_loss: 1.7466e-04\n",
      "Epoch 996/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8324e-05 - val_loss: 1.7461e-04\n",
      "Epoch 997/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8313e-05 - val_loss: 1.7454e-04\n",
      "Epoch 998/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8302e-05 - val_loss: 1.7449e-04\n",
      "Epoch 999/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.8291e-05 - val_loss: 1.7442e-04\n",
      "Epoch 1000/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8279e-05 - val_loss: 1.7436e-04\n",
      "6.643438973696902e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-1.7516611 , -1.0727636 ,  0.33554658, -1.7723533 , -1.4196906 ],\n",
       "        [ 1.0386201 ,  0.2245127 ,  0.5973799 ,  1.1976243 ,  2.0291827 ],\n",
       "        [-1.0725785 ,  0.47832027, -0.21666795, -0.4841909 , -1.2826316 ]],\n",
       "       dtype=float32),\n",
       " array([ 1.1539018 , -0.08100377, -0.42295343,  1.2260271 ,  1.2702115 ],\n",
       "       dtype=float32),\n",
       " array([[-0.71083605,  1.427217  , -1.2271223 ,  1.0533453 ,  1.133176  ,\n",
       "         -1.3103006 ,  1.6028196 , -1.0257083 , -1.1024768 , -1.257393  ],\n",
       "        [-0.27695006,  1.0491157 , -0.811491  ,  0.22327346,  0.8358492 ,\n",
       "         -0.81335235,  0.88017726, -0.23114969, -0.28163013, -0.9056954 ],\n",
       "        [-0.7298522 ,  1.3782674 , -0.22334653,  0.05625325,  0.78991735,\n",
       "         -0.30199686,  0.14316753, -0.47533807, -0.77453405, -0.8926529 ],\n",
       "        [-1.0017633 ,  0.84321386, -0.5846765 ,  1.1983545 ,  0.93464047,\n",
       "         -1.4007223 ,  1.074967  , -0.9138205 , -0.761947  , -1.483029  ],\n",
       "        [-0.75683326,  1.495155  , -1.4809438 ,  1.1769336 ,  1.1533526 ,\n",
       "         -1.0243055 ,  0.70964944, -0.7236894 , -0.5180648 , -0.80201066]],\n",
       "       dtype=float32),\n",
       " array([-0.8972825 ,  1.5028954 , -0.8847992 ,  0.89729506,  1.3822296 ,\n",
       "        -0.76822335,  1.4424891 , -0.84143573, -0.5571609 , -0.8675026 ],\n",
       "       dtype=float32),\n",
       " array([[0.50219727],\n",
       "        [1.2080742 ],\n",
       "        [0.41665193],\n",
       "        [0.96481854],\n",
       "        [1.4235349 ],\n",
       "        [0.60353655],\n",
       "        [1.2771455 ],\n",
       "        [0.5424019 ],\n",
       "        [0.74376225],\n",
       "        [0.46926746]], dtype=float32),\n",
       " array([1.1238854], dtype=float32)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_challenger, history_challenger, evaluate_challenger=NN_model_structure_regression_sigmoid(X_train_challenger, X_val_challenger, Y_train_challenger, Y_val_challenger, adam2, 32, 1000, x_test_challenger, y_test_challenger)\n",
    "model_challenger.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_challenger.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_challenger_sigmoid_4th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_46 (Dense)             (None, 5)                 20        \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 91\n",
      "Trainable params: 91\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 32 samples, validate on 7 samples\n",
      "Epoch 1/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 38.2277 - val_loss: 32.7347\n",
      "Epoch 2/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 33.0227 - val_loss: 26.7791\n",
      "Epoch 3/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 26.4424 - val_loss: 20.5451\n",
      "Epoch 4/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 19.6291 - val_loss: 14.6306\n",
      "Epoch 5/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 13.3312 - val_loss: 9.3135\n",
      "Epoch 6/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.0112 - val_loss: 4.9751\n",
      "Epoch 7/1000\n",
      "32/32 [==============================] - 0s 169us/step - loss: 4.0242 - val_loss: 2.0157\n",
      "Epoch 8/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4914 - val_loss: 0.4636\n",
      "Epoch 9/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.2839 - val_loss: 0.0915\n",
      "Epoch 10/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1285 - val_loss: 0.4704\n",
      "Epoch 11/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.5960 - val_loss: 1.0856\n",
      "Epoch 12/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.2343 - val_loss: 1.5718\n",
      "Epoch 13/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7155 - val_loss: 1.7680\n",
      "Epoch 14/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9008 - val_loss: 1.6742\n",
      "Epoch 15/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.7983 - val_loss: 1.3720\n",
      "Epoch 16/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4902 - val_loss: 0.9698\n",
      "Epoch 17/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0817 - val_loss: 0.5709\n",
      "Epoch 18/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.6720 - val_loss: 0.2556\n",
      "Epoch 19/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.3378 - val_loss: 0.0719\n",
      "Epoch 20/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1257 - val_loss: 0.0310\n",
      "Epoch 21/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0493 - val_loss: 0.1096\n",
      "Epoch 22/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0913 - val_loss: 0.2588\n",
      "Epoch 23/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.2094 - val_loss: 0.4196\n",
      "Epoch 24/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.3494 - val_loss: 0.5399\n",
      "Epoch 25/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.4601 - val_loss: 0.5887\n",
      "Epoch 26/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.5091 - val_loss: 0.5614\n",
      "Epoch 27/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.4894 - val_loss: 0.4736\n",
      "Epoch 28/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.4151 - val_loss: 0.3522\n",
      "Epoch 29/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.3103 - val_loss: 0.2255\n",
      "Epoch 30/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.2004 - val_loss: 0.1171\n",
      "Epoch 31/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.1060 - val_loss: 0.0420\n",
      "Epoch 32/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0402 - val_loss: 0.0058\n",
      "Epoch 33/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0075 - val_loss: 0.0054\n",
      "Epoch 34/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0051 - val_loss: 0.0313\n",
      "Epoch 35/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0249 - val_loss: 0.0705\n",
      "Epoch 36/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0556 - val_loss: 0.1102\n",
      "Epoch 37/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0862 - val_loss: 0.1402\n",
      "Epoch 38/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.1081 - val_loss: 0.1544\n",
      "Epoch 39/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1166 - val_loss: 0.1516\n",
      "Epoch 40/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1111 - val_loss: 0.1344\n",
      "Epoch 41/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0944 - val_loss: 0.1078\n",
      "Epoch 42/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0714 - val_loss: 0.0778\n",
      "Epoch 43/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0474 - val_loss: 0.0497\n",
      "Epoch 44/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0272 - val_loss: 0.0276\n",
      "Epoch 45/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0135 - val_loss: 0.0132\n",
      "Epoch 46/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0075 - val_loss: 0.0067\n",
      "Epoch 47/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0083 - val_loss: 0.0065\n",
      "Epoch 48/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0137 - val_loss: 0.0099\n",
      "Epoch 49/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0210 - val_loss: 0.0144\n",
      "Epoch 50/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0274 - val_loss: 0.0176\n",
      "Epoch 51/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0310 - val_loss: 0.0185\n",
      "Epoch 52/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0310 - val_loss: 0.0168\n",
      "Epoch 53/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0274 - val_loss: 0.0131\n",
      "Epoch 54/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0215 - val_loss: 0.0087\n",
      "Epoch 55/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0146 - val_loss: 0.0046\n",
      "Epoch 56/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0083 - val_loss: 0.0017\n",
      "Epoch 57/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0036 - val_loss: 4.9971e-04\n",
      "Epoch 58/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.3754e-04 - val_loss: 8.5825e-04\n",
      "Epoch 59/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.1591e-04 - val_loss: 0.0024\n",
      "Epoch 60/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 61/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0035 - val_loss: 0.0063\n",
      "Epoch 62/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0056 - val_loss: 0.0076\n",
      "Epoch 63/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0072 - val_loss: 0.0080\n",
      "Epoch 64/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0079 - val_loss: 0.0074\n",
      "Epoch 65/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0076 - val_loss: 0.0061\n",
      "Epoch 66/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0065 - val_loss: 0.0044\n",
      "Epoch 67/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0049 - val_loss: 0.0027\n",
      "Epoch 68/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0031 - val_loss: 0.0013\n",
      "Epoch 69/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 3.8078e-04\n",
      "Epoch 70/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0465e-04 - val_loss: 5.0730e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.4930e-04 - val_loss: 2.3040e-04\n",
      "Epoch 72/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.0974e-04 - val_loss: 7.5468e-04\n",
      "Epoch 73/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.3124e-04 - val_loss: 0.0014\n",
      "Epoch 74/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 75/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 76/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 77/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 78/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 79/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 80/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0012 - val_loss: 9.4008e-04\n",
      "Epoch 81/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.1342e-04 - val_loss: 5.0666e-04\n",
      "Epoch 82/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4650e-04 - val_loss: 2.0612e-04\n",
      "Epoch 83/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2165e-04 - val_loss: 5.4111e-05\n",
      "Epoch 84/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.8072e-05 - val_loss: 3.2101e-05\n",
      "Epoch 85/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0004e-04 - val_loss: 9.8505e-05\n",
      "Epoch 86/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.2925e-04 - val_loss: 2.0293e-04\n",
      "Epoch 87/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8003e-04 - val_loss: 2.9946e-04\n",
      "Epoch 88/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0345e-04 - val_loss: 3.5619e-04\n",
      "Epoch 89/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.6714e-04 - val_loss: 3.5960e-04\n",
      "Epoch 90/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.5964e-04 - val_loss: 3.1379e-04\n",
      "Epoch 91/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8888e-04 - val_loss: 2.3556e-04\n",
      "Epoch 92/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.7669e-04 - val_loss: 1.4773e-04\n",
      "Epoch 93/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.5107e-04 - val_loss: 7.2081e-05\n",
      "Epoch 94/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.3845e-04 - val_loss: 2.4154e-05\n",
      "Epoch 95/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.7854e-05 - val_loss: 1.0388e-05\n",
      "Epoch 96/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7821e-05 - val_loss: 2.8083e-05\n",
      "Epoch 97/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6368e-05 - val_loss: 6.7509e-05\n",
      "Epoch 98/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3369e-05 - val_loss: 1.1532e-04\n",
      "Epoch 99/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.4363e-05 - val_loss: 1.5832e-04\n",
      "Epoch 100/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2469e-04 - val_loss: 1.8641e-04\n",
      "Epoch 101/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5287e-04 - val_loss: 1.9440e-04\n",
      "Epoch 102/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6261e-04 - val_loss: 1.8236e-04\n",
      "Epoch 103/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5327e-04 - val_loss: 1.5469e-04\n",
      "Epoch 104/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2893e-04 - val_loss: 1.1838e-04\n",
      "Epoch 105/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6501e-05 - val_loss: 8.1003e-05\n",
      "Epoch 106/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3616e-05 - val_loss: 4.8924e-05\n",
      "Epoch 107/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6696e-05 - val_loss: 2.6162e-05\n",
      "Epoch 108/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9662e-05 - val_loss: 1.3944e-05\n",
      "Epoch 109/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3503e-05 - val_loss: 1.1019e-05\n",
      "Epoch 110/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6588e-05 - val_loss: 1.4456e-05\n",
      "Epoch 111/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5528e-05 - val_loss: 2.0676e-05\n",
      "Epoch 112/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.6291e-05 - val_loss: 2.6415e-05\n",
      "Epoch 113/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5248e-05 - val_loss: 2.9443e-05\n",
      "Epoch 114/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.9953e-05 - val_loss: 2.8870e-05\n",
      "Epoch 115/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9467e-05 - val_loss: 2.5068e-05\n",
      "Epoch 116/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4289e-05 - val_loss: 1.9344e-05\n",
      "Epoch 117/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5979e-05 - val_loss: 1.3398e-05\n",
      "Epoch 118/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.6592e-05 - val_loss: 8.8154e-06\n",
      "Epoch 119/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8082e-05 - val_loss: 6.6700e-06\n",
      "Epoch 120/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1878e-05 - val_loss: 7.3162e-06\n",
      "Epoch 121/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.6416e-06 - val_loss: 1.0408e-05\n",
      "Epoch 122/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.2553e-06 - val_loss: 1.5054e-05\n",
      "Epoch 123/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.9885e-06 - val_loss: 2.0105e-05\n",
      "Epoch 124/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2787e-05 - val_loss: 2.4453e-05\n",
      "Epoch 125/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5572e-05 - val_loss: 2.7248e-05\n",
      "Epoch 126/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.7496e-05 - val_loss: 2.8062e-05\n",
      "Epoch 127/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8097e-05 - val_loss: 2.6890e-05\n",
      "Epoch 128/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7326e-05 - val_loss: 2.4107e-05\n",
      "Epoch 129/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5484e-05 - val_loss: 2.0322e-05\n",
      "Epoch 130/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3081e-05 - val_loss: 1.6192e-05\n",
      "Epoch 131/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0674e-05 - val_loss: 1.2303e-05\n",
      "Epoch 132/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7313e-06 - val_loss: 9.0763e-06\n",
      "Epoch 133/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5324e-06 - val_loss: 6.7002e-06\n",
      "Epoch 134/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1346e-06 - val_loss: 5.1720e-06\n",
      "Epoch 135/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.4090e-06 - val_loss: 4.3390e-06\n",
      "Epoch 136/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0976e-06 - val_loss: 3.9804e-06\n",
      "Epoch 137/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.8983e-06 - val_loss: 3.8701e-06\n",
      "Epoch 138/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.5473e-06 - val_loss: 3.8446e-06\n",
      "Epoch 139/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.8718e-06 - val_loss: 3.8173e-06\n",
      "Epoch 140/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.8080e-06 - val_loss: 3.7794e-06\n",
      "Epoch 141/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4051e-06 - val_loss: 3.7797e-06\n",
      "Epoch 142/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7825e-06 - val_loss: 3.8843e-06\n",
      "Epoch 143/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0941e-06 - val_loss: 4.1564e-06\n",
      "Epoch 144/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.4833e-06 - val_loss: 4.6175e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0516e-06 - val_loss: 5.2474e-06\n",
      "Epoch 146/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8390e-06 - val_loss: 5.9768e-06\n",
      "Epoch 147/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8335e-06 - val_loss: 6.7141e-06\n",
      "Epoch 148/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 6.9723e-06 - val_loss: 7.3676e-06\n",
      "Epoch 149/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.1790e-06 - val_loss: 7.8441e-06\n",
      "Epoch 150/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.3724e-06 - val_loss: 8.0941e-06\n",
      "Epoch 151/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4953e-06 - val_loss: 8.1018e-06\n",
      "Epoch 152/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5161e-06 - val_loss: 7.8850e-06\n",
      "Epoch 153/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.4385e-06 - val_loss: 7.4948e-06\n",
      "Epoch 154/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2879e-06 - val_loss: 6.9943e-06\n",
      "Epoch 155/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.1033e-06 - val_loss: 6.4557e-06\n",
      "Epoch 156/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.9280e-06 - val_loss: 5.9334e-06\n",
      "Epoch 157/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7924e-06 - val_loss: 5.4728e-06\n",
      "Epoch 158/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.7156e-06 - val_loss: 5.0956e-06\n",
      "Epoch 159/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6993e-06 - val_loss: 4.8080e-06\n",
      "Epoch 160/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.7295e-06 - val_loss: 4.6048e-06\n",
      "Epoch 161/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7859e-06 - val_loss: 4.4746e-06\n",
      "Epoch 162/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.8465e-06 - val_loss: 4.4018e-06\n",
      "Epoch 163/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8907e-06 - val_loss: 4.3725e-06\n",
      "Epoch 164/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.9098e-06 - val_loss: 4.3829e-06\n",
      "Epoch 165/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8994e-06 - val_loss: 4.4251e-06\n",
      "Epoch 166/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8662e-06 - val_loss: 4.4996e-06\n",
      "Epoch 167/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8185e-06 - val_loss: 4.6037e-06\n",
      "Epoch 168/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.7694e-06 - val_loss: 4.7340e-06\n",
      "Epoch 169/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7273e-06 - val_loss: 4.8829e-06\n",
      "Epoch 170/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.7007e-06 - val_loss: 5.0424e-06\n",
      "Epoch 171/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6910e-06 - val_loss: 5.1965e-06\n",
      "Epoch 172/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6949e-06 - val_loss: 5.3341e-06\n",
      "Epoch 173/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7078e-06 - val_loss: 5.4438e-06\n",
      "Epoch 174/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7242e-06 - val_loss: 5.5194e-06\n",
      "Epoch 175/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7378e-06 - val_loss: 5.5523e-06\n",
      "Epoch 176/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.7446e-06 - val_loss: 5.5414e-06\n",
      "Epoch 177/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7424e-06 - val_loss: 5.4973e-06\n",
      "Epoch 178/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7341e-06 - val_loss: 5.4226e-06\n",
      "Epoch 179/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.7215e-06 - val_loss: 5.3259e-06\n",
      "Epoch 180/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7069e-06 - val_loss: 5.2203e-06\n",
      "Epoch 181/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6938e-06 - val_loss: 5.1111e-06\n",
      "Epoch 182/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 6.6844e-06 - val_loss: 5.0088e-06\n",
      "Epoch 183/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.6797e-06 - val_loss: 4.9183e-06\n",
      "Epoch 184/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6791e-06 - val_loss: 4.8409e-06\n",
      "Epoch 185/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.6825e-06 - val_loss: 4.7830e-06\n",
      "Epoch 186/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.6863e-06 - val_loss: 4.7402e-06\n",
      "Epoch 187/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.6899e-06 - val_loss: 4.7165e-06\n",
      "Epoch 188/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.6930e-06 - val_loss: 4.7097e-06\n",
      "Epoch 189/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.6922e-06 - val_loss: 4.7196e-06\n",
      "Epoch 190/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.6898e-06 - val_loss: 4.7414e-06\n",
      "Epoch 191/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6862e-06 - val_loss: 4.7735e-06\n",
      "Epoch 192/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6819e-06 - val_loss: 4.8149e-06\n",
      "Epoch 193/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6777e-06 - val_loss: 4.8618e-06\n",
      "Epoch 194/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.6742e-06 - val_loss: 4.9119e-06\n",
      "Epoch 195/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6729e-06 - val_loss: 4.9578e-06\n",
      "Epoch 196/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6726e-06 - val_loss: 5.0014e-06\n",
      "Epoch 197/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.6735e-06 - val_loss: 5.0345e-06\n",
      "Epoch 198/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6733e-06 - val_loss: 5.0609e-06\n",
      "Epoch 199/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.6742e-06 - val_loss: 5.0759e-06\n",
      "Epoch 200/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6738e-06 - val_loss: 5.0828e-06\n",
      "Epoch 201/1000\n",
      "32/32 [==============================] - 0s 122us/step - loss: 6.6745e-06 - val_loss: 5.0779e-06\n",
      "Epoch 202/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.6732e-06 - val_loss: 5.0646e-06\n",
      "Epoch 203/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.6716e-06 - val_loss: 5.0446e-06\n",
      "Epoch 204/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6702e-06 - val_loss: 5.0204e-06\n",
      "Epoch 205/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.6685e-06 - val_loss: 4.9958e-06\n",
      "Epoch 206/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6671e-06 - val_loss: 4.9685e-06\n",
      "Epoch 207/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6660e-06 - val_loss: 4.9446e-06\n",
      "Epoch 208/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.6653e-06 - val_loss: 4.9221e-06\n",
      "Epoch 209/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.6651e-06 - val_loss: 4.9048e-06\n",
      "Epoch 210/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6637e-06 - val_loss: 4.8914e-06\n",
      "Epoch 211/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.6645e-06 - val_loss: 4.8852e-06\n",
      "Epoch 212/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.6640e-06 - val_loss: 4.8826e-06\n",
      "Epoch 213/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6640e-06 - val_loss: 4.8850e-06\n",
      "Epoch 214/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.6627e-06 - val_loss: 4.8917e-06\n",
      "Epoch 215/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.6631e-06 - val_loss: 4.9024e-06\n",
      "Epoch 216/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.6614e-06 - val_loss: 4.9155e-06\n",
      "Epoch 217/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.6602e-06 - val_loss: 4.9291e-06\n",
      "Epoch 218/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6587e-06 - val_loss: 4.9466e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 219/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.6590e-06 - val_loss: 4.9576e-06\n",
      "Epoch 220/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6588e-06 - val_loss: 4.9725e-06\n",
      "Epoch 221/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.6580e-06 - val_loss: 4.9833e-06\n",
      "Epoch 222/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6567e-06 - val_loss: 4.9918e-06\n",
      "Epoch 223/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6574e-06 - val_loss: 4.9967e-06\n",
      "Epoch 224/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.6566e-06 - val_loss: 4.9992e-06\n",
      "Epoch 225/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.6558e-06 - val_loss: 4.9989e-06\n",
      "Epoch 226/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6552e-06 - val_loss: 4.9961e-06\n",
      "Epoch 227/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.6545e-06 - val_loss: 4.9920e-06\n",
      "Epoch 228/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.6547e-06 - val_loss: 4.9881e-06\n",
      "Epoch 229/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.6536e-06 - val_loss: 4.9790e-06\n",
      "Epoch 230/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6527e-06 - val_loss: 4.9726e-06\n",
      "Epoch 231/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6517e-06 - val_loss: 4.9663e-06\n",
      "Epoch 232/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6526e-06 - val_loss: 4.9596e-06\n",
      "Epoch 233/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6520e-06 - val_loss: 4.9536e-06\n",
      "Epoch 234/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.6510e-06 - val_loss: 4.9488e-06\n",
      "Epoch 235/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.6503e-06 - val_loss: 4.9453e-06\n",
      "Epoch 236/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.6500e-06 - val_loss: 4.9444e-06\n",
      "Epoch 237/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.6499e-06 - val_loss: 4.9433e-06\n",
      "Epoch 238/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6481e-06 - val_loss: 4.9454e-06\n",
      "Epoch 239/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.6479e-06 - val_loss: 4.9484e-06\n",
      "Epoch 240/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.6477e-06 - val_loss: 4.9509e-06\n",
      "Epoch 241/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6474e-06 - val_loss: 4.9535e-06\n",
      "Epoch 242/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.6466e-06 - val_loss: 4.9586e-06\n",
      "Epoch 243/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.6457e-06 - val_loss: 4.9618e-06\n",
      "Epoch 244/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6454e-06 - val_loss: 4.9660e-06\n",
      "Epoch 245/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6449e-06 - val_loss: 4.9678e-06\n",
      "Epoch 246/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.6439e-06 - val_loss: 4.9697e-06\n",
      "Epoch 247/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6433e-06 - val_loss: 4.9712e-06\n",
      "Epoch 248/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6422e-06 - val_loss: 4.9734e-06\n",
      "Epoch 249/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.6431e-06 - val_loss: 4.9721e-06\n",
      "Epoch 250/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6417e-06 - val_loss: 4.9710e-06\n",
      "Epoch 251/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 6.6411e-06 - val_loss: 4.9696e-06\n",
      "Epoch 252/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.6399e-06 - val_loss: 4.9680e-06\n",
      "Epoch 253/1000\n",
      "32/32 [==============================] - 0s 130us/step - loss: 6.6400e-06 - val_loss: 4.9650e-06\n",
      "Epoch 254/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6392e-06 - val_loss: 4.9631e-06\n",
      "Epoch 255/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6386e-06 - val_loss: 4.9619e-06\n",
      "Epoch 256/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6395e-06 - val_loss: 4.9577e-06\n",
      "Epoch 257/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.6368e-06 - val_loss: 4.9574e-06\n",
      "Epoch 258/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6377e-06 - val_loss: 4.9544e-06\n",
      "Epoch 259/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.6376e-06 - val_loss: 4.9537e-06\n",
      "Epoch 260/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.6354e-06 - val_loss: 4.9542e-06\n",
      "Epoch 261/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6358e-06 - val_loss: 4.9540e-06\n",
      "Epoch 262/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.6355e-06 - val_loss: 4.9533e-06\n",
      "Epoch 263/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 6.6341e-06 - val_loss: 4.9539e-06\n",
      "Epoch 264/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6344e-06 - val_loss: 4.9543e-06\n",
      "Epoch 265/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.6336e-06 - val_loss: 4.9552e-06\n",
      "Epoch 266/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6321e-06 - val_loss: 4.9569e-06\n",
      "Epoch 267/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6318e-06 - val_loss: 4.9593e-06\n",
      "Epoch 268/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6311e-06 - val_loss: 4.9587e-06\n",
      "Epoch 269/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6303e-06 - val_loss: 4.9589e-06\n",
      "Epoch 270/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.6303e-06 - val_loss: 4.9574e-06\n",
      "Epoch 271/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.6298e-06 - val_loss: 4.9577e-06\n",
      "Epoch 272/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6295e-06 - val_loss: 4.9578e-06\n",
      "Epoch 273/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.6285e-06 - val_loss: 4.9580e-06\n",
      "Epoch 274/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6280e-06 - val_loss: 4.9570e-06\n",
      "Epoch 275/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6271e-06 - val_loss: 4.9570e-06\n",
      "Epoch 276/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.6266e-06 - val_loss: 4.9553e-06\n",
      "Epoch 277/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.6261e-06 - val_loss: 4.9547e-06\n",
      "Epoch 278/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6256e-06 - val_loss: 4.9550e-06\n",
      "Epoch 279/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6256e-06 - val_loss: 4.9540e-06\n",
      "Epoch 280/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6246e-06 - val_loss: 4.9519e-06\n",
      "Epoch 281/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6244e-06 - val_loss: 4.9513e-06\n",
      "Epoch 282/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6241e-06 - val_loss: 4.9510e-06\n",
      "Epoch 283/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6231e-06 - val_loss: 4.9520e-06\n",
      "Epoch 284/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.6229e-06 - val_loss: 4.9510e-06\n",
      "Epoch 285/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.6220e-06 - val_loss: 4.9507e-06\n",
      "Epoch 286/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6206e-06 - val_loss: 4.9503e-06\n",
      "Epoch 287/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.6210e-06 - val_loss: 4.9498e-06\n",
      "Epoch 288/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6205e-06 - val_loss: 4.9500e-06\n",
      "Epoch 289/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6200e-06 - val_loss: 4.9499e-06\n",
      "Epoch 290/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6196e-06 - val_loss: 4.9492e-06\n",
      "Epoch 291/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6188e-06 - val_loss: 4.9504e-06\n",
      "Epoch 292/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.6177e-06 - val_loss: 4.9487e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 293/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.6172e-06 - val_loss: 4.9480e-06\n",
      "Epoch 294/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6171e-06 - val_loss: 4.9485e-06\n",
      "Epoch 295/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6158e-06 - val_loss: 4.9480e-06\n",
      "Epoch 296/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.6159e-06 - val_loss: 4.9484e-06\n",
      "Epoch 297/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.6150e-06 - val_loss: 4.9483e-06\n",
      "Epoch 298/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.6143e-06 - val_loss: 4.9480e-06\n",
      "Epoch 299/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6135e-06 - val_loss: 4.9473e-06\n",
      "Epoch 300/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6134e-06 - val_loss: 4.9477e-06\n",
      "Epoch 301/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.6129e-06 - val_loss: 4.9460e-06\n",
      "Epoch 302/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6122e-06 - val_loss: 4.9451e-06\n",
      "Epoch 303/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6116e-06 - val_loss: 4.9460e-06\n",
      "Epoch 304/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.6111e-06 - val_loss: 4.9449e-06\n",
      "Epoch 305/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 6.6102e-06 - val_loss: 4.9453e-06\n",
      "Epoch 306/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.6100e-06 - val_loss: 4.9452e-06\n",
      "Epoch 307/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.6095e-06 - val_loss: 4.9431e-06\n",
      "Epoch 308/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.6090e-06 - val_loss: 4.9424e-06\n",
      "Epoch 309/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6084e-06 - val_loss: 4.9413e-06\n",
      "Epoch 310/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.6074e-06 - val_loss: 4.9425e-06\n",
      "Epoch 311/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6068e-06 - val_loss: 4.9425e-06\n",
      "Epoch 312/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6064e-06 - val_loss: 4.9410e-06\n",
      "Epoch 313/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.6064e-06 - val_loss: 4.9403e-06\n",
      "Epoch 314/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.6056e-06 - val_loss: 4.9407e-06\n",
      "Epoch 315/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 6.6052e-06 - val_loss: 4.9408e-06\n",
      "Epoch 316/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.6040e-06 - val_loss: 4.9394e-06\n",
      "Epoch 317/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.6027e-06 - val_loss: 4.9388e-06\n",
      "Epoch 318/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6025e-06 - val_loss: 4.9394e-06\n",
      "Epoch 319/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6019e-06 - val_loss: 4.9391e-06\n",
      "Epoch 320/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6019e-06 - val_loss: 4.9392e-06\n",
      "Epoch 321/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.6006e-06 - val_loss: 4.9387e-06\n",
      "Epoch 322/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.6010e-06 - val_loss: 4.9391e-06\n",
      "Epoch 323/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.5997e-06 - val_loss: 4.9393e-06\n",
      "Epoch 324/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5993e-06 - val_loss: 4.9380e-06\n",
      "Epoch 325/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5981e-06 - val_loss: 4.9378e-06\n",
      "Epoch 326/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.5988e-06 - val_loss: 4.9371e-06\n",
      "Epoch 327/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5971e-06 - val_loss: 4.9380e-06\n",
      "Epoch 328/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.5972e-06 - val_loss: 4.9351e-06\n",
      "Epoch 329/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5960e-06 - val_loss: 4.9358e-06\n",
      "Epoch 330/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5962e-06 - val_loss: 4.9358e-06\n",
      "Epoch 331/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5950e-06 - val_loss: 4.9363e-06\n",
      "Epoch 332/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5956e-06 - val_loss: 4.9357e-06\n",
      "Epoch 333/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5949e-06 - val_loss: 4.9349e-06\n",
      "Epoch 334/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5940e-06 - val_loss: 4.9335e-06\n",
      "Epoch 335/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.5923e-06 - val_loss: 4.9344e-06\n",
      "Epoch 336/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5922e-06 - val_loss: 4.9337e-06\n",
      "Epoch 337/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5924e-06 - val_loss: 4.9332e-06\n",
      "Epoch 338/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5917e-06 - val_loss: 4.9328e-06\n",
      "Epoch 339/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5903e-06 - val_loss: 4.9326e-06\n",
      "Epoch 340/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 6.5896e-06 - val_loss: 4.9335e-06\n",
      "Epoch 341/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5891e-06 - val_loss: 4.9319e-06\n",
      "Epoch 342/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.5892e-06 - val_loss: 4.9321e-06\n",
      "Epoch 343/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5885e-06 - val_loss: 4.9310e-06\n",
      "Epoch 344/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.5878e-06 - val_loss: 4.9292e-06\n",
      "Epoch 345/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.5869e-06 - val_loss: 4.9296e-06\n",
      "Epoch 346/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5871e-06 - val_loss: 4.9305e-06\n",
      "Epoch 347/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5863e-06 - val_loss: 4.9294e-06\n",
      "Epoch 348/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5856e-06 - val_loss: 4.9300e-06\n",
      "Epoch 349/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5851e-06 - val_loss: 4.9298e-06\n",
      "Epoch 350/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5844e-06 - val_loss: 4.9297e-06\n",
      "Epoch 351/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 6.5837e-06 - val_loss: 4.9278e-06\n",
      "Epoch 352/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.5832e-06 - val_loss: 4.9269e-06\n",
      "Epoch 353/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.5829e-06 - val_loss: 4.9274e-06\n",
      "Epoch 354/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5824e-06 - val_loss: 4.9272e-06\n",
      "Epoch 355/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.5818e-06 - val_loss: 4.9272e-06\n",
      "Epoch 356/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5804e-06 - val_loss: 4.9260e-06\n",
      "Epoch 357/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.5800e-06 - val_loss: 4.9243e-06\n",
      "Epoch 358/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.5788e-06 - val_loss: 4.9247e-06\n",
      "Epoch 359/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5786e-06 - val_loss: 4.9259e-06\n",
      "Epoch 360/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.5783e-06 - val_loss: 4.9252e-06\n",
      "Epoch 361/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 6.5773e-06 - val_loss: 4.9248e-06\n",
      "Epoch 362/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5770e-06 - val_loss: 4.9247e-06\n",
      "Epoch 363/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5769e-06 - val_loss: 4.9245e-06\n",
      "Epoch 364/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.5766e-06 - val_loss: 4.9250e-06\n",
      "Epoch 365/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5764e-06 - val_loss: 4.9241e-06\n",
      "Epoch 366/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5750e-06 - val_loss: 4.9245e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 367/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.5742e-06 - val_loss: 4.9243e-06\n",
      "Epoch 368/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.5737e-06 - val_loss: 4.9237e-06\n",
      "Epoch 369/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5727e-06 - val_loss: 4.9230e-06\n",
      "Epoch 370/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.5724e-06 - val_loss: 4.9222e-06\n",
      "Epoch 371/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5719e-06 - val_loss: 4.9219e-06\n",
      "Epoch 372/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.5717e-06 - val_loss: 4.9213e-06\n",
      "Epoch 373/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5711e-06 - val_loss: 4.9209e-06\n",
      "Epoch 374/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.5700e-06 - val_loss: 4.9210e-06\n",
      "Epoch 375/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.5693e-06 - val_loss: 4.9211e-06\n",
      "Epoch 376/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5688e-06 - val_loss: 4.9222e-06\n",
      "Epoch 377/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.5691e-06 - val_loss: 4.9191e-06\n",
      "Epoch 378/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5683e-06 - val_loss: 4.9194e-06\n",
      "Epoch 379/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5675e-06 - val_loss: 4.9193e-06\n",
      "Epoch 380/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5669e-06 - val_loss: 4.9195e-06\n",
      "Epoch 381/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5663e-06 - val_loss: 4.9181e-06\n",
      "Epoch 382/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5660e-06 - val_loss: 4.9181e-06\n",
      "Epoch 383/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5642e-06 - val_loss: 4.9196e-06\n",
      "Epoch 384/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5649e-06 - val_loss: 4.9174e-06\n",
      "Epoch 385/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.5630e-06 - val_loss: 4.9168e-06\n",
      "Epoch 386/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5633e-06 - val_loss: 4.9184e-06\n",
      "Epoch 387/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5623e-06 - val_loss: 4.9155e-06\n",
      "Epoch 388/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.5619e-06 - val_loss: 4.9159e-06\n",
      "Epoch 389/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5612e-06 - val_loss: 4.9144e-06\n",
      "Epoch 390/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.5610e-06 - val_loss: 4.9150e-06\n",
      "Epoch 391/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5600e-06 - val_loss: 4.9155e-06\n",
      "Epoch 392/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.5598e-06 - val_loss: 4.9147e-06\n",
      "Epoch 393/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5584e-06 - val_loss: 4.9144e-06\n",
      "Epoch 394/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.5587e-06 - val_loss: 4.9147e-06\n",
      "Epoch 395/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5578e-06 - val_loss: 4.9147e-06\n",
      "Epoch 396/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5580e-06 - val_loss: 4.9147e-06\n",
      "Epoch 397/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5567e-06 - val_loss: 4.9131e-06\n",
      "Epoch 398/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.5559e-06 - val_loss: 4.9125e-06\n",
      "Epoch 399/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.5558e-06 - val_loss: 4.9123e-06\n",
      "Epoch 400/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.5552e-06 - val_loss: 4.9129e-06\n",
      "Epoch 401/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5537e-06 - val_loss: 4.9117e-06\n",
      "Epoch 402/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5540e-06 - val_loss: 4.9110e-06\n",
      "Epoch 403/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5530e-06 - val_loss: 4.9107e-06\n",
      "Epoch 404/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.5527e-06 - val_loss: 4.9130e-06\n",
      "Epoch 405/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5516e-06 - val_loss: 4.9096e-06\n",
      "Epoch 406/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.5516e-06 - val_loss: 4.9089e-06\n",
      "Epoch 407/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5504e-06 - val_loss: 4.9089e-06\n",
      "Epoch 408/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.5500e-06 - val_loss: 4.9091e-06\n",
      "Epoch 409/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.5489e-06 - val_loss: 4.9079e-06\n",
      "Epoch 410/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5482e-06 - val_loss: 4.9076e-06\n",
      "Epoch 411/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.5475e-06 - val_loss: 4.9076e-06\n",
      "Epoch 412/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5469e-06 - val_loss: 4.9083e-06\n",
      "Epoch 413/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5469e-06 - val_loss: 4.9065e-06\n",
      "Epoch 414/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.5472e-06 - val_loss: 4.9071e-06\n",
      "Epoch 415/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5457e-06 - val_loss: 4.9053e-06\n",
      "Epoch 416/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.5454e-06 - val_loss: 4.9074e-06\n",
      "Epoch 417/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5438e-06 - val_loss: 4.9042e-06\n",
      "Epoch 418/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.5433e-06 - val_loss: 4.9045e-06\n",
      "Epoch 419/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5428e-06 - val_loss: 4.9041e-06\n",
      "Epoch 420/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.5424e-06 - val_loss: 4.9056e-06\n",
      "Epoch 421/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5421e-06 - val_loss: 4.9038e-06\n",
      "Epoch 422/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5414e-06 - val_loss: 4.9044e-06\n",
      "Epoch 423/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5401e-06 - val_loss: 4.9036e-06\n",
      "Epoch 424/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.5406e-06 - val_loss: 4.9047e-06\n",
      "Epoch 425/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.5399e-06 - val_loss: 4.9031e-06\n",
      "Epoch 426/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.5392e-06 - val_loss: 4.9034e-06\n",
      "Epoch 427/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.5380e-06 - val_loss: 4.9012e-06\n",
      "Epoch 428/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.5373e-06 - val_loss: 4.9009e-06\n",
      "Epoch 429/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.5375e-06 - val_loss: 4.9008e-06\n",
      "Epoch 430/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.5366e-06 - val_loss: 4.9000e-06\n",
      "Epoch 431/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5360e-06 - val_loss: 4.9002e-06\n",
      "Epoch 432/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5350e-06 - val_loss: 4.9026e-06\n",
      "Epoch 433/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5356e-06 - val_loss: 4.9007e-06\n",
      "Epoch 434/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.5341e-06 - val_loss: 4.9012e-06\n",
      "Epoch 435/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.5342e-06 - val_loss: 4.8998e-06\n",
      "Epoch 436/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5329e-06 - val_loss: 4.8981e-06\n",
      "Epoch 437/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.5326e-06 - val_loss: 4.8982e-06\n",
      "Epoch 438/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5323e-06 - val_loss: 4.8977e-06\n",
      "Epoch 439/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5316e-06 - val_loss: 4.8983e-06\n",
      "Epoch 440/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5315e-06 - val_loss: 4.8990e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 441/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5305e-06 - val_loss: 4.8976e-06\n",
      "Epoch 442/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5295e-06 - val_loss: 4.8998e-06\n",
      "Epoch 443/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5290e-06 - val_loss: 4.8978e-06\n",
      "Epoch 444/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5286e-06 - val_loss: 4.8963e-06\n",
      "Epoch 445/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5279e-06 - val_loss: 4.8966e-06\n",
      "Epoch 446/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.5274e-06 - val_loss: 4.8964e-06\n",
      "Epoch 447/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.5263e-06 - val_loss: 4.8957e-06\n",
      "Epoch 448/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5264e-06 - val_loss: 4.8951e-06\n",
      "Epoch 449/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.5250e-06 - val_loss: 4.8945e-06\n",
      "Epoch 450/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 6.5250e-06 - val_loss: 4.8958e-06\n",
      "Epoch 451/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5238e-06 - val_loss: 4.8938e-06\n",
      "Epoch 452/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.5236e-06 - val_loss: 4.8924e-06\n",
      "Epoch 453/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5226e-06 - val_loss: 4.8934e-06\n",
      "Epoch 454/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.5219e-06 - val_loss: 4.8943e-06\n",
      "Epoch 455/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5222e-06 - val_loss: 4.8942e-06\n",
      "Epoch 456/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5219e-06 - val_loss: 4.8924e-06\n",
      "Epoch 457/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5206e-06 - val_loss: 4.8916e-06\n",
      "Epoch 458/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.5205e-06 - val_loss: 4.8921e-06\n",
      "Epoch 459/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 6.5197e-06 - val_loss: 4.8911e-06\n",
      "Epoch 460/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.5192e-06 - val_loss: 4.8909e-06\n",
      "Epoch 461/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5194e-06 - val_loss: 4.8906e-06\n",
      "Epoch 462/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5179e-06 - val_loss: 4.8902e-06\n",
      "Epoch 463/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5168e-06 - val_loss: 4.8896e-06\n",
      "Epoch 464/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.5169e-06 - val_loss: 4.8895e-06\n",
      "Epoch 465/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5152e-06 - val_loss: 4.8892e-06\n",
      "Epoch 466/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5151e-06 - val_loss: 4.8899e-06\n",
      "Epoch 467/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.5144e-06 - val_loss: 4.8887e-06\n",
      "Epoch 468/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5148e-06 - val_loss: 4.8870e-06\n",
      "Epoch 469/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.5131e-06 - val_loss: 4.8872e-06\n",
      "Epoch 470/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5127e-06 - val_loss: 4.8864e-06\n",
      "Epoch 471/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5117e-06 - val_loss: 4.8873e-06\n",
      "Epoch 472/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5112e-06 - val_loss: 4.8878e-06\n",
      "Epoch 473/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.5107e-06 - val_loss: 4.8861e-06\n",
      "Epoch 474/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5103e-06 - val_loss: 4.8852e-06\n",
      "Epoch 475/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5100e-06 - val_loss: 4.8859e-06\n",
      "Epoch 476/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.5087e-06 - val_loss: 4.8845e-06\n",
      "Epoch 477/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5081e-06 - val_loss: 4.8847e-06\n",
      "Epoch 478/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.5082e-06 - val_loss: 4.8849e-06\n",
      "Epoch 479/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5062e-06 - val_loss: 4.8846e-06\n",
      "Epoch 480/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.5061e-06 - val_loss: 4.8851e-06\n",
      "Epoch 481/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5056e-06 - val_loss: 4.8823e-06\n",
      "Epoch 482/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.5051e-06 - val_loss: 4.8828e-06\n",
      "Epoch 483/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.5051e-06 - val_loss: 4.8831e-06\n",
      "Epoch 484/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.5041e-06 - val_loss: 4.8824e-06\n",
      "Epoch 485/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5041e-06 - val_loss: 4.8821e-06\n",
      "Epoch 486/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5028e-06 - val_loss: 4.8813e-06\n",
      "Epoch 487/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.5021e-06 - val_loss: 4.8809e-06\n",
      "Epoch 488/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5010e-06 - val_loss: 4.8795e-06\n",
      "Epoch 489/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.5015e-06 - val_loss: 4.8796e-06\n",
      "Epoch 490/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.5004e-06 - val_loss: 4.8801e-06\n",
      "Epoch 491/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.5001e-06 - val_loss: 4.8804e-06\n",
      "Epoch 492/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4995e-06 - val_loss: 4.8804e-06\n",
      "Epoch 493/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4991e-06 - val_loss: 4.8786e-06\n",
      "Epoch 494/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4981e-06 - val_loss: 4.8786e-06\n",
      "Epoch 495/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4981e-06 - val_loss: 4.8780e-06\n",
      "Epoch 496/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4964e-06 - val_loss: 4.8765e-06\n",
      "Epoch 497/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4959e-06 - val_loss: 4.8768e-06\n",
      "Epoch 498/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4958e-06 - val_loss: 4.8772e-06\n",
      "Epoch 499/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4948e-06 - val_loss: 4.8760e-06\n",
      "Epoch 500/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4942e-06 - val_loss: 4.8755e-06\n",
      "Epoch 501/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4931e-06 - val_loss: 4.8764e-06\n",
      "Epoch 502/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4929e-06 - val_loss: 4.8756e-06\n",
      "Epoch 503/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4919e-06 - val_loss: 4.8768e-06\n",
      "Epoch 504/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4917e-06 - val_loss: 4.8754e-06\n",
      "Epoch 505/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4906e-06 - val_loss: 4.8759e-06\n",
      "Epoch 506/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4904e-06 - val_loss: 4.8749e-06\n",
      "Epoch 507/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4896e-06 - val_loss: 4.8750e-06\n",
      "Epoch 508/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 6.4889e-06 - val_loss: 4.8720e-06\n",
      "Epoch 509/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.4879e-06 - val_loss: 4.8728e-06\n",
      "Epoch 510/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4877e-06 - val_loss: 4.8728e-06\n",
      "Epoch 511/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4870e-06 - val_loss: 4.8728e-06\n",
      "Epoch 512/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4869e-06 - val_loss: 4.8718e-06\n",
      "Epoch 513/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4863e-06 - val_loss: 4.8715e-06\n",
      "Epoch 514/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.4859e-06 - val_loss: 4.8716e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 515/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4845e-06 - val_loss: 4.8719e-06\n",
      "Epoch 516/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4845e-06 - val_loss: 4.8713e-06\n",
      "Epoch 517/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4834e-06 - val_loss: 4.8707e-06\n",
      "Epoch 518/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4836e-06 - val_loss: 4.8711e-06\n",
      "Epoch 519/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4817e-06 - val_loss: 4.8714e-06\n",
      "Epoch 520/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4823e-06 - val_loss: 4.8697e-06\n",
      "Epoch 521/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.4809e-06 - val_loss: 4.8695e-06\n",
      "Epoch 522/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4807e-06 - val_loss: 4.8696e-06\n",
      "Epoch 523/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4800e-06 - val_loss: 4.8709e-06\n",
      "Epoch 524/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4797e-06 - val_loss: 4.8675e-06\n",
      "Epoch 525/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4789e-06 - val_loss: 4.8683e-06\n",
      "Epoch 526/1000\n",
      "32/32 [==============================] - 0s 131us/step - loss: 6.4791e-06 - val_loss: 4.8679e-06\n",
      "Epoch 527/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.4778e-06 - val_loss: 4.8673e-06\n",
      "Epoch 528/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4776e-06 - val_loss: 4.8663e-06\n",
      "Epoch 529/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4764e-06 - val_loss: 4.8662e-06\n",
      "Epoch 530/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4766e-06 - val_loss: 4.8658e-06\n",
      "Epoch 531/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4748e-06 - val_loss: 4.8657e-06\n",
      "Epoch 532/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4751e-06 - val_loss: 4.8653e-06\n",
      "Epoch 533/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.4741e-06 - val_loss: 4.8653e-06\n",
      "Epoch 534/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4729e-06 - val_loss: 4.8654e-06\n",
      "Epoch 535/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4728e-06 - val_loss: 4.8652e-06\n",
      "Epoch 536/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4719e-06 - val_loss: 4.8625e-06\n",
      "Epoch 537/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4718e-06 - val_loss: 4.8640e-06\n",
      "Epoch 538/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4716e-06 - val_loss: 4.8636e-06\n",
      "Epoch 539/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4704e-06 - val_loss: 4.8623e-06\n",
      "Epoch 540/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.4692e-06 - val_loss: 4.8616e-06\n",
      "Epoch 541/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4689e-06 - val_loss: 4.8607e-06\n",
      "Epoch 542/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4683e-06 - val_loss: 4.8606e-06\n",
      "Epoch 543/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4675e-06 - val_loss: 4.8605e-06\n",
      "Epoch 544/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4670e-06 - val_loss: 4.8607e-06\n",
      "Epoch 545/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4658e-06 - val_loss: 4.8604e-06\n",
      "Epoch 546/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4657e-06 - val_loss: 4.8594e-06\n",
      "Epoch 547/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.4651e-06 - val_loss: 4.8579e-06\n",
      "Epoch 548/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4644e-06 - val_loss: 4.8581e-06\n",
      "Epoch 549/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4633e-06 - val_loss: 4.8566e-06\n",
      "Epoch 550/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4621e-06 - val_loss: 4.8586e-06\n",
      "Epoch 551/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4620e-06 - val_loss: 4.8583e-06\n",
      "Epoch 552/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4614e-06 - val_loss: 4.8571e-06\n",
      "Epoch 553/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4609e-06 - val_loss: 4.8567e-06\n",
      "Epoch 554/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4599e-06 - val_loss: 4.8570e-06\n",
      "Epoch 555/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4602e-06 - val_loss: 4.8565e-06\n",
      "Epoch 556/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4591e-06 - val_loss: 4.8564e-06\n",
      "Epoch 557/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4588e-06 - val_loss: 4.8553e-06\n",
      "Epoch 558/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4576e-06 - val_loss: 4.8555e-06\n",
      "Epoch 559/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4573e-06 - val_loss: 4.8546e-06\n",
      "Epoch 560/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4568e-06 - val_loss: 4.8534e-06\n",
      "Epoch 561/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4564e-06 - val_loss: 4.8553e-06\n",
      "Epoch 562/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4559e-06 - val_loss: 4.8525e-06\n",
      "Epoch 563/1000\n",
      "32/32 [==============================] - 0s 192us/step - loss: 6.4554e-06 - val_loss: 4.8528e-06\n",
      "Epoch 564/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4546e-06 - val_loss: 4.8527e-06\n",
      "Epoch 565/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4536e-06 - val_loss: 4.8512e-06\n",
      "Epoch 566/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4531e-06 - val_loss: 4.8511e-06\n",
      "Epoch 567/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4524e-06 - val_loss: 4.8509e-06\n",
      "Epoch 568/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4516e-06 - val_loss: 4.8496e-06\n",
      "Epoch 569/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4508e-06 - val_loss: 4.8510e-06\n",
      "Epoch 570/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4510e-06 - val_loss: 4.8507e-06\n",
      "Epoch 571/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4500e-06 - val_loss: 4.8499e-06\n",
      "Epoch 572/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4495e-06 - val_loss: 4.8504e-06\n",
      "Epoch 573/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4490e-06 - val_loss: 4.8506e-06\n",
      "Epoch 574/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4482e-06 - val_loss: 4.8491e-06\n",
      "Epoch 575/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4473e-06 - val_loss: 4.8501e-06\n",
      "Epoch 576/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4473e-06 - val_loss: 4.8478e-06\n",
      "Epoch 577/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4462e-06 - val_loss: 4.8491e-06\n",
      "Epoch 578/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.4461e-06 - val_loss: 4.8483e-06\n",
      "Epoch 579/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4452e-06 - val_loss: 4.8482e-06\n",
      "Epoch 580/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4445e-06 - val_loss: 4.8468e-06\n",
      "Epoch 581/1000\n",
      "32/32 [==============================] - 0s 193us/step - loss: 6.4442e-06 - val_loss: 4.8460e-06\n",
      "Epoch 582/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4431e-06 - val_loss: 4.8463e-06\n",
      "Epoch 583/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4425e-06 - val_loss: 4.8468e-06\n",
      "Epoch 584/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4423e-06 - val_loss: 4.8461e-06\n",
      "Epoch 585/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4406e-06 - val_loss: 4.8445e-06\n",
      "Epoch 586/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4404e-06 - val_loss: 4.8453e-06\n",
      "Epoch 587/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4392e-06 - val_loss: 4.8460e-06\n",
      "Epoch 588/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4393e-06 - val_loss: 4.8430e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 589/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4382e-06 - val_loss: 4.8430e-06\n",
      "Epoch 590/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4375e-06 - val_loss: 4.8439e-06\n",
      "Epoch 591/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4373e-06 - val_loss: 4.8430e-06\n",
      "Epoch 592/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4363e-06 - val_loss: 4.8421e-06\n",
      "Epoch 593/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.4357e-06 - val_loss: 4.8409e-06\n",
      "Epoch 594/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4354e-06 - val_loss: 4.8418e-06\n",
      "Epoch 595/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4347e-06 - val_loss: 4.8424e-06\n",
      "Epoch 596/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4346e-06 - val_loss: 4.8421e-06\n",
      "Epoch 597/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.4337e-06 - val_loss: 4.8414e-06\n",
      "Epoch 598/1000\n",
      "32/32 [==============================] - 0s 174us/step - loss: 6.4341e-06 - val_loss: 4.8413e-06\n",
      "Epoch 599/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4330e-06 - val_loss: 4.8407e-06\n",
      "Epoch 600/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4324e-06 - val_loss: 4.8397e-06\n",
      "Epoch 601/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4317e-06 - val_loss: 4.8396e-06\n",
      "Epoch 602/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4308e-06 - val_loss: 4.8395e-06\n",
      "Epoch 603/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4293e-06 - val_loss: 4.8384e-06\n",
      "Epoch 604/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4288e-06 - val_loss: 4.8378e-06\n",
      "Epoch 605/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4283e-06 - val_loss: 4.8363e-06\n",
      "Epoch 606/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4278e-06 - val_loss: 4.8374e-06\n",
      "Epoch 607/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4273e-06 - val_loss: 4.8375e-06\n",
      "Epoch 608/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4269e-06 - val_loss: 4.8374e-06\n",
      "Epoch 609/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4268e-06 - val_loss: 4.8372e-06\n",
      "Epoch 610/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4254e-06 - val_loss: 4.8370e-06\n",
      "Epoch 611/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4247e-06 - val_loss: 4.8366e-06\n",
      "Epoch 612/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4238e-06 - val_loss: 4.8356e-06\n",
      "Epoch 613/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4232e-06 - val_loss: 4.8350e-06\n",
      "Epoch 614/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4232e-06 - val_loss: 4.8347e-06\n",
      "Epoch 615/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4228e-06 - val_loss: 4.8334e-06\n",
      "Epoch 616/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 6.4215e-06 - val_loss: 4.8338e-06\n",
      "Epoch 617/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4215e-06 - val_loss: 4.8323e-06\n",
      "Epoch 618/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4203e-06 - val_loss: 4.8316e-06\n",
      "Epoch 619/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4196e-06 - val_loss: 4.8321e-06\n",
      "Epoch 620/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4193e-06 - val_loss: 4.8319e-06\n",
      "Epoch 621/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4184e-06 - val_loss: 4.8314e-06\n",
      "Epoch 622/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4179e-06 - val_loss: 4.8309e-06\n",
      "Epoch 623/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4172e-06 - val_loss: 4.8307e-06\n",
      "Epoch 624/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4163e-06 - val_loss: 4.8293e-06\n",
      "Epoch 625/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.4151e-06 - val_loss: 4.8296e-06\n",
      "Epoch 626/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.4145e-06 - val_loss: 4.8292e-06\n",
      "Epoch 627/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4136e-06 - val_loss: 4.8289e-06\n",
      "Epoch 628/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4136e-06 - val_loss: 4.8284e-06\n",
      "Epoch 629/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4119e-06 - val_loss: 4.8288e-06\n",
      "Epoch 630/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4122e-06 - val_loss: 4.8285e-06\n",
      "Epoch 631/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4116e-06 - val_loss: 4.8279e-06\n",
      "Epoch 632/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4112e-06 - val_loss: 4.8275e-06\n",
      "Epoch 633/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4106e-06 - val_loss: 4.8272e-06\n",
      "Epoch 634/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4101e-06 - val_loss: 4.8258e-06\n",
      "Epoch 635/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.4088e-06 - val_loss: 4.8265e-06\n",
      "Epoch 636/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4083e-06 - val_loss: 4.8248e-06\n",
      "Epoch 637/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4084e-06 - val_loss: 4.8270e-06\n",
      "Epoch 638/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4075e-06 - val_loss: 4.8250e-06\n",
      "Epoch 639/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4065e-06 - val_loss: 4.8249e-06\n",
      "Epoch 640/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4059e-06 - val_loss: 4.8239e-06\n",
      "Epoch 641/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4046e-06 - val_loss: 4.8247e-06\n",
      "Epoch 642/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4051e-06 - val_loss: 4.8232e-06\n",
      "Epoch 643/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4043e-06 - val_loss: 4.8246e-06\n",
      "Epoch 644/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4033e-06 - val_loss: 4.8245e-06\n",
      "Epoch 645/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4039e-06 - val_loss: 4.8225e-06\n",
      "Epoch 646/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4029e-06 - val_loss: 4.8217e-06\n",
      "Epoch 647/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4023e-06 - val_loss: 4.8232e-06\n",
      "Epoch 648/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4014e-06 - val_loss: 4.8209e-06\n",
      "Epoch 649/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4004e-06 - val_loss: 4.8211e-06\n",
      "Epoch 650/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4001e-06 - val_loss: 4.8211e-06\n",
      "Epoch 651/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3988e-06 - val_loss: 4.8202e-06\n",
      "Epoch 652/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.3981e-06 - val_loss: 4.8207e-06\n",
      "Epoch 653/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3980e-06 - val_loss: 4.8194e-06\n",
      "Epoch 654/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3971e-06 - val_loss: 4.8198e-06\n",
      "Epoch 655/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 6.3968e-06 - val_loss: 4.8193e-06\n",
      "Epoch 656/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.3956e-06 - val_loss: 4.8180e-06\n",
      "Epoch 657/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3949e-06 - val_loss: 4.8181e-06\n",
      "Epoch 658/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.3940e-06 - val_loss: 4.8185e-06\n",
      "Epoch 659/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3941e-06 - val_loss: 4.8174e-06\n",
      "Epoch 660/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3924e-06 - val_loss: 4.8169e-06\n",
      "Epoch 661/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.3925e-06 - val_loss: 4.8157e-06\n",
      "Epoch 662/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.3917e-06 - val_loss: 4.8161e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 663/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3916e-06 - val_loss: 4.8155e-06\n",
      "Epoch 664/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.3899e-06 - val_loss: 4.8152e-06\n",
      "Epoch 665/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 6.3906e-06 - val_loss: 4.8143e-06\n",
      "Epoch 666/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.3887e-06 - val_loss: 4.8163e-06\n",
      "Epoch 667/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3884e-06 - val_loss: 4.8145e-06\n",
      "Epoch 668/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3876e-06 - val_loss: 4.8133e-06\n",
      "Epoch 669/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3871e-06 - val_loss: 4.8135e-06\n",
      "Epoch 670/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.3865e-06 - val_loss: 4.8142e-06\n",
      "Epoch 671/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3864e-06 - val_loss: 4.8128e-06\n",
      "Epoch 672/1000\n",
      "32/32 [==============================] - 0s 164us/step - loss: 6.3854e-06 - val_loss: 4.8135e-06\n",
      "Epoch 673/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3848e-06 - val_loss: 4.8118e-06\n",
      "Epoch 674/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.3837e-06 - val_loss: 4.8120e-06\n",
      "Epoch 675/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.3834e-06 - val_loss: 4.8129e-06\n",
      "Epoch 676/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3824e-06 - val_loss: 4.8124e-06\n",
      "Epoch 677/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3818e-06 - val_loss: 4.8117e-06\n",
      "Epoch 678/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3815e-06 - val_loss: 4.8106e-06\n",
      "Epoch 679/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.3813e-06 - val_loss: 4.8104e-06\n",
      "Epoch 680/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.3809e-06 - val_loss: 4.8100e-06\n",
      "Epoch 681/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3803e-06 - val_loss: 4.8101e-06\n",
      "Epoch 682/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.3790e-06 - val_loss: 4.8083e-06\n",
      "Epoch 683/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3777e-06 - val_loss: 4.8081e-06\n",
      "Epoch 684/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3772e-06 - val_loss: 4.8094e-06\n",
      "Epoch 685/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3770e-06 - val_loss: 4.8069e-06\n",
      "Epoch 686/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 6.3760e-06 - val_loss: 4.8062e-06\n",
      "Epoch 687/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.3753e-06 - val_loss: 4.8071e-06\n",
      "Epoch 688/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3742e-06 - val_loss: 4.8078e-06\n",
      "Epoch 689/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3738e-06 - val_loss: 4.8069e-06\n",
      "Epoch 690/1000\n",
      "32/32 [==============================] - 0s 161us/step - loss: 6.3732e-06 - val_loss: 4.8054e-06\n",
      "Epoch 691/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3726e-06 - val_loss: 4.8067e-06\n",
      "Epoch 692/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3722e-06 - val_loss: 4.8058e-06\n",
      "Epoch 693/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.3714e-06 - val_loss: 4.8045e-06\n",
      "Epoch 694/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3710e-06 - val_loss: 4.8052e-06\n",
      "Epoch 695/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3695e-06 - val_loss: 4.8053e-06\n",
      "Epoch 696/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.3698e-06 - val_loss: 4.8043e-06\n",
      "Epoch 697/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.3682e-06 - val_loss: 4.8041e-06\n",
      "Epoch 698/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3682e-06 - val_loss: 4.8041e-06\n",
      "Epoch 699/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.3671e-06 - val_loss: 4.8032e-06\n",
      "Epoch 700/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3675e-06 - val_loss: 4.8034e-06\n",
      "Epoch 701/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3669e-06 - val_loss: 4.8029e-06\n",
      "Epoch 702/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3663e-06 - val_loss: 4.8014e-06\n",
      "Epoch 703/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3650e-06 - val_loss: 4.8017e-06\n",
      "Epoch 704/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3648e-06 - val_loss: 4.8020e-06\n",
      "Epoch 705/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3638e-06 - val_loss: 4.8001e-06\n",
      "Epoch 706/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 6.3632e-06 - val_loss: 4.7995e-06\n",
      "Epoch 707/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3623e-06 - val_loss: 4.8012e-06\n",
      "Epoch 708/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3622e-06 - val_loss: 4.7984e-06\n",
      "Epoch 709/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.3608e-06 - val_loss: 4.7990e-06\n",
      "Epoch 710/1000\n",
      "32/32 [==============================] - 0s 158us/step - loss: 6.3606e-06 - val_loss: 4.7988e-06\n",
      "Epoch 711/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3600e-06 - val_loss: 4.7997e-06\n",
      "Epoch 712/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3601e-06 - val_loss: 4.7982e-06\n",
      "Epoch 713/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 6.3587e-06 - val_loss: 4.7975e-06\n",
      "Epoch 714/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.3580e-06 - val_loss: 4.7975e-06\n",
      "Epoch 715/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3572e-06 - val_loss: 4.7970e-06\n",
      "Epoch 716/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.3560e-06 - val_loss: 4.7947e-06\n",
      "Epoch 717/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.3556e-06 - val_loss: 4.7956e-06\n",
      "Epoch 718/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.3555e-06 - val_loss: 4.7955e-06\n",
      "Epoch 719/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 6.3545e-06 - val_loss: 4.7960e-06\n",
      "Epoch 720/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.3536e-06 - val_loss: 4.7947e-06\n",
      "Epoch 721/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.3532e-06 - val_loss: 4.7949e-06\n",
      "Epoch 722/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.3524e-06 - val_loss: 4.7935e-06\n",
      "Epoch 723/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3518e-06 - val_loss: 4.7932e-06\n",
      "Epoch 724/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3509e-06 - val_loss: 4.7931e-06\n",
      "Epoch 725/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.3508e-06 - val_loss: 4.7926e-06\n",
      "Epoch 726/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3499e-06 - val_loss: 4.7922e-06\n",
      "Epoch 727/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.3490e-06 - val_loss: 4.7924e-06\n",
      "Epoch 728/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3481e-06 - val_loss: 4.7928e-06\n",
      "Epoch 729/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3480e-06 - val_loss: 4.7923e-06\n",
      "Epoch 730/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.3472e-06 - val_loss: 4.7897e-06\n",
      "Epoch 731/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 6.3466e-06 - val_loss: 4.7910e-06\n",
      "Epoch 732/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.3461e-06 - val_loss: 4.7893e-06\n",
      "Epoch 733/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.3456e-06 - val_loss: 4.7901e-06\n",
      "Epoch 734/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3451e-06 - val_loss: 4.7886e-06\n",
      "Epoch 735/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3440e-06 - val_loss: 4.7895e-06\n",
      "Epoch 736/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3437e-06 - val_loss: 4.7884e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 737/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3429e-06 - val_loss: 4.7890e-06\n",
      "Epoch 738/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3428e-06 - val_loss: 4.7886e-06\n",
      "Epoch 739/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3422e-06 - val_loss: 4.7881e-06\n",
      "Epoch 740/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.3412e-06 - val_loss: 4.7874e-06\n",
      "Epoch 741/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3407e-06 - val_loss: 4.7861e-06\n",
      "Epoch 742/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3392e-06 - val_loss: 4.7869e-06\n",
      "Epoch 743/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3389e-06 - val_loss: 4.7857e-06\n",
      "Epoch 744/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3377e-06 - val_loss: 4.7863e-06\n",
      "Epoch 745/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3375e-06 - val_loss: 4.7853e-06\n",
      "Epoch 746/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3366e-06 - val_loss: 4.7858e-06\n",
      "Epoch 747/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3355e-06 - val_loss: 4.7861e-06\n",
      "Epoch 748/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3351e-06 - val_loss: 4.7837e-06\n",
      "Epoch 749/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.3343e-06 - val_loss: 4.7841e-06\n",
      "Epoch 750/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3342e-06 - val_loss: 4.7832e-06\n",
      "Epoch 751/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.3340e-06 - val_loss: 4.7838e-06\n",
      "Epoch 752/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.3328e-06 - val_loss: 4.7826e-06\n",
      "Epoch 753/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.3331e-06 - val_loss: 4.7817e-06\n",
      "Epoch 754/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3317e-06 - val_loss: 4.7822e-06\n",
      "Epoch 755/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3314e-06 - val_loss: 4.7817e-06\n",
      "Epoch 756/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.3302e-06 - val_loss: 4.7816e-06\n",
      "Epoch 757/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3289e-06 - val_loss: 4.7801e-06\n",
      "Epoch 758/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.3283e-06 - val_loss: 4.7814e-06\n",
      "Epoch 759/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3283e-06 - val_loss: 4.7820e-06\n",
      "Epoch 760/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3272e-06 - val_loss: 4.7809e-06\n",
      "Epoch 761/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.3270e-06 - val_loss: 4.7803e-06\n",
      "Epoch 762/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.3266e-06 - val_loss: 4.7798e-06\n",
      "Epoch 763/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3253e-06 - val_loss: 4.7802e-06\n",
      "Epoch 764/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.3252e-06 - val_loss: 4.7781e-06\n",
      "Epoch 765/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3231e-06 - val_loss: 4.7784e-06\n",
      "Epoch 766/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3235e-06 - val_loss: 4.7777e-06\n",
      "Epoch 767/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3230e-06 - val_loss: 4.7778e-06\n",
      "Epoch 768/1000\n",
      "32/32 [==============================] - 0s 133us/step - loss: 6.3224e-06 - val_loss: 4.7771e-06\n",
      "Epoch 769/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.3212e-06 - val_loss: 4.7745e-06\n",
      "Epoch 770/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3205e-06 - val_loss: 4.7753e-06\n",
      "Epoch 771/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.3197e-06 - val_loss: 4.7758e-06\n",
      "Epoch 772/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3187e-06 - val_loss: 4.7745e-06\n",
      "Epoch 773/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 6.3177e-06 - val_loss: 4.7743e-06\n",
      "Epoch 774/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.3173e-06 - val_loss: 4.7744e-06\n",
      "Epoch 775/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3167e-06 - val_loss: 4.7743e-06\n",
      "Epoch 776/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3157e-06 - val_loss: 4.7734e-06\n",
      "Epoch 777/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3164e-06 - val_loss: 4.7732e-06\n",
      "Epoch 778/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.3149e-06 - val_loss: 4.7739e-06\n",
      "Epoch 779/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3140e-06 - val_loss: 4.7724e-06\n",
      "Epoch 780/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.3140e-06 - val_loss: 4.7718e-06\n",
      "Epoch 781/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3140e-06 - val_loss: 4.7710e-06\n",
      "Epoch 782/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3126e-06 - val_loss: 4.7715e-06\n",
      "Epoch 783/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 6.3120e-06 - val_loss: 4.7705e-06\n",
      "Epoch 784/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3114e-06 - val_loss: 4.7713e-06\n",
      "Epoch 785/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.3107e-06 - val_loss: 4.7692e-06\n",
      "Epoch 786/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3104e-06 - val_loss: 4.7693e-06\n",
      "Epoch 787/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3094e-06 - val_loss: 4.7692e-06\n",
      "Epoch 788/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3089e-06 - val_loss: 4.7687e-06\n",
      "Epoch 789/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.3080e-06 - val_loss: 4.7671e-06\n",
      "Epoch 790/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3073e-06 - val_loss: 4.7679e-06\n",
      "Epoch 791/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.3063e-06 - val_loss: 4.7671e-06\n",
      "Epoch 792/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3060e-06 - val_loss: 4.7662e-06\n",
      "Epoch 793/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3052e-06 - val_loss: 4.7660e-06\n",
      "Epoch 794/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3043e-06 - val_loss: 4.7670e-06\n",
      "Epoch 795/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3040e-06 - val_loss: 4.7657e-06\n",
      "Epoch 796/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.3033e-06 - val_loss: 4.7663e-06\n",
      "Epoch 797/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3027e-06 - val_loss: 4.7644e-06\n",
      "Epoch 798/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3023e-06 - val_loss: 4.7651e-06\n",
      "Epoch 799/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3012e-06 - val_loss: 4.7651e-06\n",
      "Epoch 800/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3010e-06 - val_loss: 4.7642e-06\n",
      "Epoch 801/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.2992e-06 - val_loss: 4.7629e-06\n",
      "Epoch 802/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2988e-06 - val_loss: 4.7644e-06\n",
      "Epoch 803/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2985e-06 - val_loss: 4.7620e-06\n",
      "Epoch 804/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2977e-06 - val_loss: 4.7627e-06\n",
      "Epoch 805/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2970e-06 - val_loss: 4.7612e-06\n",
      "Epoch 806/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.2964e-06 - val_loss: 4.7614e-06\n",
      "Epoch 807/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.2949e-06 - val_loss: 4.7613e-06\n",
      "Epoch 808/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2950e-06 - val_loss: 4.7615e-06\n",
      "Epoch 809/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.2952e-06 - val_loss: 4.7591e-06\n",
      "Epoch 810/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.2934e-06 - val_loss: 4.7602e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 811/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2935e-06 - val_loss: 4.7591e-06\n",
      "Epoch 812/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2927e-06 - val_loss: 4.7588e-06\n",
      "Epoch 813/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.2915e-06 - val_loss: 4.7576e-06\n",
      "Epoch 814/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2913e-06 - val_loss: 4.7587e-06\n",
      "Epoch 815/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.2902e-06 - val_loss: 4.7595e-06\n",
      "Epoch 816/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2899e-06 - val_loss: 4.7586e-06\n",
      "Epoch 817/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2892e-06 - val_loss: 4.7565e-06\n",
      "Epoch 818/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2882e-06 - val_loss: 4.7580e-06\n",
      "Epoch 819/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2872e-06 - val_loss: 4.7563e-06\n",
      "Epoch 820/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2870e-06 - val_loss: 4.7563e-06\n",
      "Epoch 821/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.2863e-06 - val_loss: 4.7554e-06\n",
      "Epoch 822/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.2855e-06 - val_loss: 4.7561e-06\n",
      "Epoch 823/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.2850e-06 - val_loss: 4.7544e-06\n",
      "Epoch 824/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2845e-06 - val_loss: 4.7552e-06\n",
      "Epoch 825/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.2835e-06 - val_loss: 4.7543e-06\n",
      "Epoch 826/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.2832e-06 - val_loss: 4.7546e-06\n",
      "Epoch 827/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2823e-06 - val_loss: 4.7528e-06\n",
      "Epoch 828/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.2815e-06 - val_loss: 4.7538e-06\n",
      "Epoch 829/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.2811e-06 - val_loss: 4.7538e-06\n",
      "Epoch 830/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2803e-06 - val_loss: 4.7532e-06\n",
      "Epoch 831/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2797e-06 - val_loss: 4.7520e-06\n",
      "Epoch 832/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2787e-06 - val_loss: 4.7518e-06\n",
      "Epoch 833/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2778e-06 - val_loss: 4.7503e-06\n",
      "Epoch 834/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2776e-06 - val_loss: 4.7505e-06\n",
      "Epoch 835/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 6.2762e-06 - val_loss: 4.7503e-06\n",
      "Epoch 836/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2762e-06 - val_loss: 4.7502e-06\n",
      "Epoch 837/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2757e-06 - val_loss: 4.7493e-06\n",
      "Epoch 838/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2751e-06 - val_loss: 4.7485e-06\n",
      "Epoch 839/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.2731e-06 - val_loss: 4.7483e-06\n",
      "Epoch 840/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2733e-06 - val_loss: 4.7488e-06\n",
      "Epoch 841/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2737e-06 - val_loss: 4.7475e-06\n",
      "Epoch 842/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.2725e-06 - val_loss: 4.7478e-06\n",
      "Epoch 843/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2708e-06 - val_loss: 4.7460e-06\n",
      "Epoch 844/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2705e-06 - val_loss: 4.7448e-06\n",
      "Epoch 845/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2690e-06 - val_loss: 4.7447e-06\n",
      "Epoch 846/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2684e-06 - val_loss: 4.7454e-06\n",
      "Epoch 847/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.2681e-06 - val_loss: 4.7435e-06\n",
      "Epoch 848/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.2673e-06 - val_loss: 4.7451e-06\n",
      "Epoch 849/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.2668e-06 - val_loss: 4.7440e-06\n",
      "Epoch 850/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.2657e-06 - val_loss: 4.7443e-06\n",
      "Epoch 851/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.2657e-06 - val_loss: 4.7428e-06\n",
      "Epoch 852/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2643e-06 - val_loss: 4.7427e-06\n",
      "Epoch 853/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.2641e-06 - val_loss: 4.7417e-06\n",
      "Epoch 854/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.2636e-06 - val_loss: 4.7412e-06\n",
      "Epoch 855/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2625e-06 - val_loss: 4.7404e-06\n",
      "Epoch 856/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.2618e-06 - val_loss: 4.7407e-06\n",
      "Epoch 857/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2612e-06 - val_loss: 4.7419e-06\n",
      "Epoch 858/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2606e-06 - val_loss: 4.7407e-06\n",
      "Epoch 859/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.2602e-06 - val_loss: 4.7399e-06\n",
      "Epoch 860/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.2592e-06 - val_loss: 4.7389e-06\n",
      "Epoch 861/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2586e-06 - val_loss: 4.7405e-06\n",
      "Epoch 862/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2579e-06 - val_loss: 4.7404e-06\n",
      "Epoch 863/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2572e-06 - val_loss: 4.7392e-06\n",
      "Epoch 864/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2569e-06 - val_loss: 4.7391e-06\n",
      "Epoch 865/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.2563e-06 - val_loss: 4.7388e-06\n",
      "Epoch 866/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2553e-06 - val_loss: 4.7374e-06\n",
      "Epoch 867/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2542e-06 - val_loss: 4.7372e-06\n",
      "Epoch 868/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 6.2535e-06 - val_loss: 4.7362e-06\n",
      "Epoch 869/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.2529e-06 - val_loss: 4.7356e-06\n",
      "Epoch 870/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2519e-06 - val_loss: 4.7359e-06\n",
      "Epoch 871/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2514e-06 - val_loss: 4.7347e-06\n",
      "Epoch 872/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2510e-06 - val_loss: 4.7348e-06\n",
      "Epoch 873/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2505e-06 - val_loss: 4.7334e-06\n",
      "Epoch 874/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2494e-06 - val_loss: 4.7338e-06\n",
      "Epoch 875/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2487e-06 - val_loss: 4.7345e-06\n",
      "Epoch 876/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2484e-06 - val_loss: 4.7326e-06\n",
      "Epoch 877/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2479e-06 - val_loss: 4.7324e-06\n",
      "Epoch 878/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.2473e-06 - val_loss: 4.7331e-06\n",
      "Epoch 879/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2470e-06 - val_loss: 4.7330e-06\n",
      "Epoch 880/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2464e-06 - val_loss: 4.7309e-06\n",
      "Epoch 881/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2456e-06 - val_loss: 4.7323e-06\n",
      "Epoch 882/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.2444e-06 - val_loss: 4.7304e-06\n",
      "Epoch 883/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2432e-06 - val_loss: 4.7307e-06\n",
      "Epoch 884/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2432e-06 - val_loss: 4.7303e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 885/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.2428e-06 - val_loss: 4.7280e-06\n",
      "Epoch 886/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2415e-06 - val_loss: 4.7287e-06\n",
      "Epoch 887/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2401e-06 - val_loss: 4.7287e-06\n",
      "Epoch 888/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.2396e-06 - val_loss: 4.7280e-06\n",
      "Epoch 889/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.2399e-06 - val_loss: 4.7276e-06\n",
      "Epoch 890/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2387e-06 - val_loss: 4.7259e-06\n",
      "Epoch 891/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2382e-06 - val_loss: 4.7265e-06\n",
      "Epoch 892/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.2372e-06 - val_loss: 4.7264e-06\n",
      "Epoch 893/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.2367e-06 - val_loss: 4.7268e-06\n",
      "Epoch 894/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2360e-06 - val_loss: 4.7250e-06\n",
      "Epoch 895/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2354e-06 - val_loss: 4.7255e-06\n",
      "Epoch 896/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.2341e-06 - val_loss: 4.7233e-06\n",
      "Epoch 897/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2329e-06 - val_loss: 4.7242e-06\n",
      "Epoch 898/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.2330e-06 - val_loss: 4.7241e-06\n",
      "Epoch 899/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.2322e-06 - val_loss: 4.7227e-06\n",
      "Epoch 900/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.2316e-06 - val_loss: 4.7232e-06\n",
      "Epoch 901/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.2309e-06 - val_loss: 4.7235e-06\n",
      "Epoch 902/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.2302e-06 - val_loss: 4.7220e-06\n",
      "Epoch 903/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2292e-06 - val_loss: 4.7225e-06\n",
      "Epoch 904/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.2289e-06 - val_loss: 4.7217e-06\n",
      "Epoch 905/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 6.2285e-06 - val_loss: 4.7211e-06\n",
      "Epoch 906/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2275e-06 - val_loss: 4.7206e-06\n",
      "Epoch 907/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 6.2274e-06 - val_loss: 4.7198e-06\n",
      "Epoch 908/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.2263e-06 - val_loss: 4.7202e-06\n",
      "Epoch 909/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2256e-06 - val_loss: 4.7197e-06\n",
      "Epoch 910/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2250e-06 - val_loss: 4.7188e-06\n",
      "Epoch 911/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2243e-06 - val_loss: 4.7183e-06\n",
      "Epoch 912/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.2236e-06 - val_loss: 4.7179e-06\n",
      "Epoch 913/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2236e-06 - val_loss: 4.7185e-06\n",
      "Epoch 914/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2222e-06 - val_loss: 4.7182e-06\n",
      "Epoch 915/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.2211e-06 - val_loss: 4.7169e-06\n",
      "Epoch 916/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2205e-06 - val_loss: 4.7167e-06\n",
      "Epoch 917/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2201e-06 - val_loss: 4.7175e-06\n",
      "Epoch 918/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.2187e-06 - val_loss: 4.7169e-06\n",
      "Epoch 919/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2185e-06 - val_loss: 4.7156e-06\n",
      "Epoch 920/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.2175e-06 - val_loss: 4.7142e-06\n",
      "Epoch 921/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.2175e-06 - val_loss: 4.7146e-06\n",
      "Epoch 922/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 6.2159e-06 - val_loss: 4.7141e-06\n",
      "Epoch 923/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2159e-06 - val_loss: 4.7141e-06\n",
      "Epoch 924/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.2152e-06 - val_loss: 4.7128e-06\n",
      "Epoch 925/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2139e-06 - val_loss: 4.7135e-06\n",
      "Epoch 926/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.2137e-06 - val_loss: 4.7124e-06\n",
      "Epoch 927/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2127e-06 - val_loss: 4.7119e-06\n",
      "Epoch 928/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2120e-06 - val_loss: 4.7125e-06\n",
      "Epoch 929/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.2112e-06 - val_loss: 4.7108e-06\n",
      "Epoch 930/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.2104e-06 - val_loss: 4.7119e-06\n",
      "Epoch 931/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.2102e-06 - val_loss: 4.7097e-06\n",
      "Epoch 932/1000\n",
      "32/32 [==============================] - 0s 171us/step - loss: 6.2096e-06 - val_loss: 4.7105e-06\n",
      "Epoch 933/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.2081e-06 - val_loss: 4.7105e-06\n",
      "Epoch 934/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2083e-06 - val_loss: 4.7084e-06\n",
      "Epoch 935/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.2076e-06 - val_loss: 4.7074e-06\n",
      "Epoch 936/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2059e-06 - val_loss: 4.7088e-06\n",
      "Epoch 937/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2065e-06 - val_loss: 4.7082e-06\n",
      "Epoch 938/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.2054e-06 - val_loss: 4.7086e-06\n",
      "Epoch 939/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.2046e-06 - val_loss: 4.7067e-06\n",
      "Epoch 940/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.2040e-06 - val_loss: 4.7075e-06\n",
      "Epoch 941/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2032e-06 - val_loss: 4.7064e-06\n",
      "Epoch 942/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2025e-06 - val_loss: 4.7054e-06\n",
      "Epoch 943/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.2012e-06 - val_loss: 4.7048e-06\n",
      "Epoch 944/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.2009e-06 - val_loss: 4.7053e-06\n",
      "Epoch 945/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2005e-06 - val_loss: 4.7056e-06\n",
      "Epoch 946/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.1997e-06 - val_loss: 4.7045e-06\n",
      "Epoch 947/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1986e-06 - val_loss: 4.7035e-06\n",
      "Epoch 948/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1981e-06 - val_loss: 4.7043e-06\n",
      "Epoch 949/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1976e-06 - val_loss: 4.7031e-06\n",
      "Epoch 950/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1960e-06 - val_loss: 4.7025e-06\n",
      "Epoch 951/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1961e-06 - val_loss: 4.7018e-06\n",
      "Epoch 952/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1946e-06 - val_loss: 4.7021e-06\n",
      "Epoch 953/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1945e-06 - val_loss: 4.7019e-06\n",
      "Epoch 954/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.1937e-06 - val_loss: 4.7003e-06\n",
      "Epoch 955/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.1924e-06 - val_loss: 4.6994e-06\n",
      "Epoch 956/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1916e-06 - val_loss: 4.6998e-06\n",
      "Epoch 957/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1911e-06 - val_loss: 4.6999e-06\n",
      "Epoch 958/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 6.1907e-06 - val_loss: 4.6992e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 959/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.1902e-06 - val_loss: 4.6990e-06\n",
      "Epoch 960/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1894e-06 - val_loss: 4.6977e-06\n",
      "Epoch 961/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 6.1884e-06 - val_loss: 4.6983e-06\n",
      "Epoch 962/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.1884e-06 - val_loss: 4.6978e-06\n",
      "Epoch 963/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.1878e-06 - val_loss: 4.6971e-06\n",
      "Epoch 964/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1874e-06 - val_loss: 4.6973e-06\n",
      "Epoch 965/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1865e-06 - val_loss: 4.6974e-06\n",
      "Epoch 966/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1856e-06 - val_loss: 4.6952e-06\n",
      "Epoch 967/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 6.1843e-06 - val_loss: 4.6961e-06\n",
      "Epoch 968/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1840e-06 - val_loss: 4.6951e-06\n",
      "Epoch 969/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1836e-06 - val_loss: 4.6954e-06\n",
      "Epoch 970/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1830e-06 - val_loss: 4.6950e-06\n",
      "Epoch 971/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1818e-06 - val_loss: 4.6926e-06\n",
      "Epoch 972/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1809e-06 - val_loss: 4.6950e-06\n",
      "Epoch 973/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1808e-06 - val_loss: 4.6941e-06\n",
      "Epoch 974/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1801e-06 - val_loss: 4.6928e-06\n",
      "Epoch 975/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1794e-06 - val_loss: 4.6928e-06\n",
      "Epoch 976/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 6.1781e-06 - val_loss: 4.6922e-06\n",
      "Epoch 977/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.1779e-06 - val_loss: 4.6922e-06\n",
      "Epoch 978/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1777e-06 - val_loss: 4.6916e-06\n",
      "Epoch 979/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1761e-06 - val_loss: 4.6906e-06\n",
      "Epoch 980/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.1759e-06 - val_loss: 4.6910e-06\n",
      "Epoch 981/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1743e-06 - val_loss: 4.6916e-06\n",
      "Epoch 982/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1737e-06 - val_loss: 4.6898e-06\n",
      "Epoch 983/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.1729e-06 - val_loss: 4.6888e-06\n",
      "Epoch 984/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 6.1723e-06 - val_loss: 4.6887e-06\n",
      "Epoch 985/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 6.1713e-06 - val_loss: 4.6880e-06\n",
      "Epoch 986/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.1712e-06 - val_loss: 4.6884e-06\n",
      "Epoch 987/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1703e-06 - val_loss: 4.6875e-06\n",
      "Epoch 988/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1690e-06 - val_loss: 4.6869e-06\n",
      "Epoch 989/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.1689e-06 - val_loss: 4.6872e-06\n",
      "Epoch 990/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1678e-06 - val_loss: 4.6858e-06\n",
      "Epoch 991/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1671e-06 - val_loss: 4.6855e-06\n",
      "Epoch 992/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1675e-06 - val_loss: 4.6847e-06\n",
      "Epoch 993/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.1660e-06 - val_loss: 4.6845e-06\n",
      "Epoch 994/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1655e-06 - val_loss: 4.6851e-06\n",
      "Epoch 995/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1651e-06 - val_loss: 4.6838e-06\n",
      "Epoch 996/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.1635e-06 - val_loss: 4.6823e-06\n",
      "Epoch 997/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1634e-06 - val_loss: 4.6841e-06\n",
      "Epoch 998/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.1620e-06 - val_loss: 4.6826e-06\n",
      "Epoch 999/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 6.1618e-06 - val_loss: 4.6809e-06\n",
      "Epoch 1000/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1607e-06 - val_loss: 4.6805e-06\n",
      "2.464947328917333e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.19875017, -0.02785967,  0.87802655, -0.47592303, -0.9999145 ],\n",
       "        [ 1.3686749 ,  0.22447065, -0.17783053,  0.55345887,  1.0579501 ],\n",
       "        [-1.6373907 ,  0.02080915,  1.1541448 , -1.5417757 ,  0.99988127]],\n",
       "       dtype=float32),\n",
       " array([ 0.9039354 , -0.55581725,  0.8894419 ,  0.6240607 ,  0.8773968 ],\n",
       "       dtype=float32),\n",
       " array([[-0.51839405,  1.3563112 , -0.86715317,  0.8473021 , -0.44729438,\n",
       "         -0.83752525,  1.0757352 ,  1.037819  , -0.6472389 , -0.7182746 ],\n",
       "        [-0.3013458 ,  0.74765426, -0.25244546,  0.8013971 , -0.6675782 ,\n",
       "          0.1064247 ,  0.0852048 ,  0.4600611 , -0.40873614,  0.14464477],\n",
       "        [-1.307476  ,  1.1251708 , -0.5906554 ,  0.62776226, -0.8181569 ,\n",
       "          0.53651416,  1.0106112 ,  0.5936515 , -1.4444305 , -0.3708293 ],\n",
       "        [-1.2465279 ,  0.4874122 , -0.8355048 ,  0.26276734, -1.3249125 ,\n",
       "         -0.34477514,  0.8060374 ,  0.19794548, -1.2009432 ,  0.09766385],\n",
       "        [-1.4315686 ,  0.37393025, -0.50850296,  1.1384532 , -1.4738679 ,\n",
       "         -1.0053837 ,  1.1889037 ,  0.55040807, -1.0488148 ,  0.5022587 ]],\n",
       "       dtype=float32),\n",
       " array([-0.76020765,  0.85167617, -0.784734  ,  0.8020319 , -0.8400861 ,\n",
       "         0.09630448,  0.79678845,  0.79498166, -0.7815905 , -0.18879423],\n",
       "       dtype=float32),\n",
       " array([[-1.30500543e+00],\n",
       "        [ 8.93897593e-01],\n",
       "        [-1.22425586e-01],\n",
       "        [ 4.55618590e-01],\n",
       "        [-7.63413846e-01],\n",
       "        [ 3.00359679e-03],\n",
       "        [ 8.75107825e-01],\n",
       "        [-2.58217335e-01],\n",
       "        [-1.14693201e+00],\n",
       "        [ 7.37840484e-04]], dtype=float32),\n",
       " array([0.69945645], dtype=float32)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_challenger, history_challenger, evaluate_challenger=NN_model_structure_regression_tanh(X_train_challenger, X_val_challenger, Y_train_challenger, Y_val_challenger, adam2, 32, 1000, x_test_challenger, y_test_challenger)\n",
    "model_challenger.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_challenger.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_challenger_tanh_4th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
