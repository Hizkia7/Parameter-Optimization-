{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import seaborn as sns\n",
    "from random import seed\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import  MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, LSTM, BatchNormalization\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras import callbacks\n",
    "from keras import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate Dataset\n",
    "#Airfoil Self-Noise\n",
    "df_airfoil=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Airfoil_self_noise.csv')\n",
    "\n",
    "#Automobile\n",
    "df_automobile=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Automobile_data.txt')\n",
    "\n",
    "#Autompg\n",
    "df_autompg=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Auto-mpg.csv')\n",
    "\n",
    "#ChallengerUSA\n",
    "df_challenger=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Challenger USA Space Shuttle O-Ring.csv')\n",
    "\n",
    "#Combine Cycle Power\n",
    "df_combine=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Combine Cycle Power Plant.csv')\n",
    "\n",
    "#Computer Hardware\n",
    "df_computer=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Computer Hardware.csv')\n",
    "\n",
    "#Concrete Compressive Strength\n",
    "df_concrete_compressive_strength=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Concrete Compressive Strength.csv')\n",
    "\n",
    "#Concrete Slump Test\n",
    "df_concrete1=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Concrete Slump Test.csv')\n",
    "df_concrete2=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Concrete Slump Test.csv')\n",
    "df_concrete3=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Concrete Slump Test.csv')\n",
    "\n",
    "#Energy Efficiency\n",
    "df_energy1=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Energy Efficiency.csv')\n",
    "df_energy2=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Energy Efficiency.csv')\n",
    "\n",
    "#Fertility Diagnosis\n",
    "df_fertility=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\fertility_Diagnosis.csv')\n",
    "\n",
    "#Forest Fires\n",
    "df_forest=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\forestfires.csv')\n",
    "\n",
    "#Housing\n",
    "df_housing=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Housing.csv')\n",
    "\n",
    "#Istanbul Stock Exchange\n",
    "df_istanbul=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Istanbul Stock Exchange.csv')\n",
    "\n",
    "#WDBC\n",
    "df_wdbc=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\wdbc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:66: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#remove Nan columns of df_energy1\n",
    "df_energy1=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Energy Efficiency.csv')\n",
    "df_energy1.drop(df_energy1.columns[11],inplace=True, axis = 1)\n",
    "df_energy1.drop(df_energy1.columns[10],inplace=True, axis = 1)\n",
    "\n",
    "#remove Nan columns of df_energy2\n",
    "df_energy2=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Energy Efficiency.csv')\n",
    "df_energy2.drop(df_energy2.columns[11],inplace=True, axis = 1)\n",
    "df_energy2.drop(df_energy2.columns[10],inplace=True, axis = 1)\n",
    "\n",
    "#remove question marks\n",
    "#df_automobile\n",
    "imp= Imputer(missing_values=\"NaN\", strategy=\"mean\")\n",
    "df_automobile=df_automobile.replace(\"?\", np.NaN)\n",
    "df_automobile['num-of-doors'] = df_automobile['num-of-doors'].fillna(\"four\")\n",
    "for i in df_automobile.columns:\n",
    "    if df_automobile[i].isnull().sum()>0:\n",
    "        df_automobile[i]=imp.fit_transform(df_automobile[[i]])\n",
    "#df_automobile = df_automobile[(df_automobile.astype(str) != '?').all(axis=1)]\n",
    "#df_automobile.reset_index(drop=True, inplace=True)\n",
    "df_automobile = df_automobile.drop(['engine-location'], axis=1)\n",
    "#df_autompg\n",
    "df_autompg = df_autompg[(df_autompg.astype(str) != '?').all(axis=1)]\n",
    "df_autompg.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#convert string to number\n",
    "le=LabelEncoder()\n",
    "#df_automobile\n",
    "string_automobile=df_automobile[['make','fuel-type','aspiration','num-of-doors', 'body-style', 'drive-wheels', 'engine-type', 'num-of-cylinders', 'fuel-system']]\n",
    "df_automobile[['make','fuel-type','aspiration','num-of-doors', 'body-style', 'drive-wheels', 'engine-type', 'num-of-cylinders', 'fuel-system']]=string_automobile.apply(le.fit_transform)\n",
    "encoder=df_automobile[['make','fuel-type','aspiration','num-of-doors', 'body-style', 'drive-wheels', 'engine-type', 'num-of-cylinders', 'fuel-system']].astype(np.int64)\n",
    "df_automobile[['make','fuel-type','aspiration','num-of-doors', 'body-style', 'drive-wheels', 'engine-type', 'num-of-cylinders', 'fuel-system']]=encoder\n",
    "a=df_automobile[['normalized-losses','horsepower','price']].astype(np.int64)\n",
    "b=df_automobile[['bore','stroke','peak-rpm']].astype(float)\n",
    "df_automobile[['normalized-losses','horsepower','price']]=a\n",
    "df_automobile[['bore','stroke','peak-rpm']]=b\n",
    "#df_computer\n",
    "string_computer=df_computer[['Vendor','Model']]\n",
    "df_computer[['Vendor','Model']]=string_computer.apply(le.fit_transform)\n",
    "df_computer[['Vendor','Model']]=df_computer[['Vendor','Model']].astype(np.int64)\n",
    "\n",
    "#dropna spesific column & special preprocessing\n",
    "#df_forest\n",
    "df_forest=df_forest[(df_forest['area'].astype(int) != 0)] \n",
    "df_forest.reset_index(drop=True, inplace=True)\n",
    "num_features=10\n",
    "dimension=(num_features+1)*9+10\n",
    "population_size=(2*dimension+1)*2\n",
    "df_forest=df_forest[:population_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_data1(df,num_features):\n",
    "    dimension=(num_features+1)*9+10\n",
    "    population_size=(2*dimension+1)*2\n",
    "    df=df.dropna()\n",
    "    df=df[:population_size]\n",
    "    df\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection(df):\n",
    "    cor=df.corr()\n",
    "    plt.figure(figsize=(100,50))\n",
    "    sns.set(font_scale=3)\n",
    "    sns.heatmap(cor, annot=True, cmap=plt.cm.Blues)\n",
    "    plt.show()\n",
    "    return cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split1(x, y):\n",
    "    x_train, x_test, y_train, y_test= train_test_split(x, y, test_size=0.15, random_state=42)\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_data2(df):\n",
    "    train_size = 0.85*len(df)\n",
    "    train_size = int(train_size)\n",
    "    df_train = df[:train_size]\n",
    "    df_test = df[train_size:]\n",
    "    print(len(df_test))\n",
    "    print(len(df_train))\n",
    "    validation_size=len(df_test)/len(df_train)\n",
    "    print(validation_size)\n",
    "    return df_train, df_test, validation_size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#df_airfoil=preprocessing_data1(df_airfoil,5)\n",
    "#df_automobile=preprocessing_data1(df_automobile,22)\n",
    "#df_autompg=preprocessing_data1(df_autompg,7)\n",
    "#df_challenger=preprocessing_data1(df_challenger,3)\n",
    "#df_combine=preprocessing_data1(df_combine,4)\n",
    "#df_computer=preprocessing_data1(df_computer,9)\n",
    "#df_concrete_compressive_strength=preprocessing_data1(df_concrete_compressive_strength,8)\n",
    "#df_concrete1=preprocessing_data1(df_concrete1,7)\n",
    "#df_concrete2=preprocessing_data1(df_concrete2,7)\n",
    "#df_concrete3=preprocessing_data1(df_concrete3,7)\n",
    "#df_energy1=preprocessing_data1(df_energy1,8)\n",
    "#df_energy2=preprocessing_data1(df_energy2,8)\n",
    "\n",
    "#df_fertility=preprocessing_data1(df_fertility,9)\n",
    "for i in df_fertility:\n",
    "    df_fertility.Diagnosis[df_fertility.Diagnosis == 'N'] = 1\n",
    "    df_fertility.Diagnosis[df_fertility.Diagnosis == 'O'] = 2\n",
    "df_fertility['Diagnosis']=df_fertility['Diagnosis'].astype(np.int64)\n",
    "\n",
    "#df_forest=preprocessing_data1(df_forest,10)\n",
    "#df_housing=preprocessing_data1(df_housing,13)\n",
    "\n",
    "#df_istanbul=preprocessing_data1(df_istanbul,7)\n",
    "new_header = df_istanbul.iloc[0]\n",
    "df_istanbul = df_istanbul[1:]\n",
    "df_istanbul.columns = new_header\n",
    "df_istanbul[['ISE1','ISE2','SP','DAX','FTSE','NIKKEI','BOVESPA','EU','EM']]=df_istanbul[['ISE1','ISE2','SP','DAX','FTSE','NIKKEI','BOVESPA','EU','EM']].astype(np.float64)\n",
    "\n",
    "\n",
    "#df_wdbc=preprocessing_data1(df_wdbc,10)\n",
    "df_wdbc.drop(df_wdbc.columns[0], axis=1, inplace = True)\n",
    "df_wdbc.columns=['id','diagnosis','radius_mean','texture_mean','perimeter_mean','area_mean','smoothness_mean','compactness_mean','concavity_mean','concave points_mean','symmetry_mean','fractal_dimension_mean','radius_se','texture_se','perimeter_se','area_se','smoothness_se','compactness_se','concavity_se','concave points_se','symmetry_se','fractal_dimension_se','radius_worst','texture_worst','perimeter_worst','area_worst','smoothness_worst','compactness_worst','concavity_worst','concave points_worst','symmetry_worst','fractal_dimension_worst']\n",
    "for i in df_wdbc:\n",
    "    df_wdbc.diagnosis[df_wdbc.diagnosis == 'M'] = 1\n",
    "    df_wdbc.diagnosis[df_wdbc.diagnosis == 'B'] = 2\n",
    "df_wdbc['diagnosis']=df_wdbc['diagnosis'].astype(np.object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Frequency  Angle of Attack  Chord length  Free-stream velocity  \\\n",
      "0        800              0.0        0.3048                  71.3   \n",
      "1       1000              0.0        0.3048                  71.3   \n",
      "2       1250              0.0        0.3048                  71.3   \n",
      "3       1600              0.0        0.3048                  71.3   \n",
      "4       2000              0.0        0.3048                  71.3   \n",
      "\n",
      "   Suction side displacement thickness  Scaled sound pressure level  \n",
      "0                             0.002663                      126.201  \n",
      "1                             0.002663                      125.201  \n",
      "2                             0.002663                      125.951  \n",
      "3                             0.002663                      127.591  \n",
      "4                             0.002663                      127.461  \n",
      "    Mpg  Cylinders  Displacement Horsepower  Weight  Acceleration  Model Year  \\\n",
      "0  18.0          8         307.0        130    3504          12.0          70   \n",
      "1  15.0          8         350.0        165    3693          11.5          70   \n",
      "2  18.0          8         318.0        150    3436          11.0          70   \n",
      "3  16.0          8         304.0        150    3433          12.0          70   \n",
      "4  17.0          8         302.0        140    3449          10.5          70   \n",
      "\n",
      "   Origin                   Car Name  \n",
      "0       1  chevrolet chevelle malibu  \n",
      "1       1          buick skylark 320  \n",
      "2       1         plymouth satellite  \n",
      "3       1              amc rebel sst  \n",
      "4       1                ford torino  \n",
      "   symboling  normalized-losses  make  fuel-type  aspiration  num-of-doors  \\\n",
      "0          3                122     0          1           0             1   \n",
      "1          3                122     0          1           0             1   \n",
      "2          1                122     0          1           0             1   \n",
      "3          2                164     1          1           0             0   \n",
      "4          2                164     1          1           0             0   \n",
      "\n",
      "   body-style  drive-wheels  wheel-base  length  ...  engine-size  \\\n",
      "0           0             2        88.6   168.8  ...          130   \n",
      "1           0             2        88.6   168.8  ...          130   \n",
      "2           2             2        94.5   171.2  ...          152   \n",
      "3           3             1        99.8   176.6  ...          109   \n",
      "4           3             0        99.4   176.6  ...          136   \n",
      "\n",
      "   fuel-system  bore  stroke  compression-ratio  horsepower  peak-rpm  \\\n",
      "0            5  3.47    2.68                9.0         111    5000.0   \n",
      "1            5  3.47    2.68                9.0         111    5000.0   \n",
      "2            5  2.68    3.47                9.0         154    5000.0   \n",
      "3            5  3.19    3.40               10.0         102    5500.0   \n",
      "4            5  3.19    3.40                8.0         115    5500.0   \n",
      "\n",
      "   city-mpg  highway-mpg  price  \n",
      "0        21           27  13495  \n",
      "1        21           27  16500  \n",
      "2        19           26  16500  \n",
      "3        24           30  13950  \n",
      "4        18           22  17450  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "   Number of O-rings  Thermal Distress  Launch Temperature  \\\n",
      "0                  6                 0                  66   \n",
      "1                  6                 1                  70   \n",
      "2                  6                 0                  69   \n",
      "3                  6                 0                  68   \n",
      "4                  6                 0                  67   \n",
      "\n",
      "   Leak-Check Pressure  Temporal Order of Flight  \n",
      "0                   50                         1  \n",
      "1                   50                         2  \n",
      "2                   50                         3  \n",
      "3                   50                         4  \n",
      "4                   50                         5  \n"
     ]
    }
   ],
   "source": [
    "print(df_airfoil.head())\n",
    "print(df_autompg.head())\n",
    "print(df_automobile.head())\n",
    "print(df_challenger.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:62: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#Train and Test 17 datasets\n",
    "#Airfoil\n",
    "x_airfoil = df_airfoil.drop(['Scaled sound pressure level'], axis = 1)\n",
    "y_airfoil = df_airfoil['Scaled sound pressure level']\n",
    "#Wdbc\n",
    "x_wdbc = df_wdbc[['radius_mean','perimeter_mean','area_mean','concavity_mean','concave points_mean','radius_worst','perimeter_worst','area_worst','concave points_worst']]\n",
    "y_wdbc = df_wdbc['diagnosis']\n",
    "labelencoder_Y = LabelEncoder()\n",
    "y_wdbc = labelencoder_Y.fit_transform(y_wdbc)\n",
    "#Automobile\n",
    "x_automobile = df_automobile.drop(['price','make','body-style'], axis = 1)\n",
    "y_automobile = df_automobile['price']\n",
    "y_automobile = np.reshape(y_automobile.values, (-1,1))\n",
    "#Autompg\n",
    "x_autompg = df_autompg.drop(['Mpg','Car Name'], axis = 1)\n",
    "y_autompg = df_autompg['Mpg']\n",
    "#Challenger\n",
    "x_challenger = df_challenger.drop(['Number of O-rings','Temporal Order of Flight'], axis = 1)\n",
    "y_challenger = df_challenger['Number of O-rings']\n",
    "#Combine\n",
    "x_combine = df_combine.drop(['PE'], axis = 1)\n",
    "y_combine = df_combine['PE']\n",
    "y_combine = np.reshape(y_combine.values, (-1,1))\n",
    "#Computer\n",
    "x_computer = df_computer.drop(['ERP'], axis = 1)\n",
    "y_computer = df_computer['ERP']\n",
    "y_computer = np.reshape(y_computer.values, (-1,1))\n",
    "#Concrete_compressive_strength\n",
    "x_concrete_compressive_strength = df_concrete_compressive_strength.drop(['CCS'], axis = 1)\n",
    "y_concrete_compressive_strength = df_concrete_compressive_strength['CCS']\n",
    "y_concrete_compressive_strength = np.reshape(y_concrete_compressive_strength.values, (-1,1))\n",
    "#Concrete1\n",
    "x_concrete1 = df_concrete1.drop(['No','Compressive Strength (28-day)(Mpa)'], axis = 1)\n",
    "y_concrete1 = df_concrete1['Compressive Strength (28-day)(Mpa)']\n",
    "#Concrete2\n",
    "x_concrete2 = df_concrete2.drop(['No','SLUMP(cm)'], axis = 1)\n",
    "y_concrete2 = df_concrete2['SLUMP(cm)']\n",
    "y_concrete2 = np.reshape(y_concrete2.values, (-1,1))\n",
    "#Concrete3\n",
    "x_concrete3 = df_concrete3.drop(['No','FLOW(cm)'], axis = 1)\n",
    "y_concrete3 = df_concrete3['FLOW(cm)']\n",
    "y_concrete3 = np.reshape(y_concrete3.values, (-1,1))\n",
    "#Energy1\n",
    "x_energy1 = df_energy1.drop(['Y1'], axis = 1)\n",
    "y_energy1 = df_energy1['Y1']\n",
    "#Energy2\n",
    "x_energy2 = df_energy2.drop(['Y2'], axis = 1)\n",
    "y_energy2 = df_energy2['Y2']\n",
    "#Fertility\n",
    "x_fertility = df_fertility.drop(['Diagnosis'], axis = 1)\n",
    "y_fertility = df_fertility['Diagnosis']\n",
    "#Forest\n",
    "x_forest = df_forest.drop(['month','day','area'], axis = 1)\n",
    "y_forest = df_forest['area']\n",
    "y_forest = np.reshape(y_forest.values, (-1,1))\n",
    "#Housing\n",
    "x_housing = df_housing.drop(['MEDV'], axis = 1)\n",
    "y_housing = df_housing['MEDV']\n",
    "#Istanbul\n",
    "x_istanbul = df_istanbul.drop(['date','ISE1','ISE2'], axis = 1)\n",
    "y_istanbul = df_istanbul[['ISE1','ISE2']]\n",
    "y_istanbul['mean'] = y_istanbul.mean(axis=1)\n",
    "y_istanbul = y_istanbul['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_airfoil, x_test_airfoil, y_train_airfoil, y_test_airfoil = train_test_split1(x_airfoil, y_airfoil)\n",
    "x_train_automobile, x_test_automobile, y_train_automobile, y_test_automobile = train_test_split1(x_automobile, y_automobile)\n",
    "x_train_autompg, x_test_autompg, y_train_autompg, y_test_autompg = train_test_split1(x_autompg, y_autompg)\n",
    "x_train_challenger, x_test_challenger, y_train_challenger, y_test_challenger = train_test_split1(x_challenger, y_challenger)\n",
    "x_train_combine, x_test_combine, y_train_combine, y_test_combine = train_test_split1(x_combine, y_combine)\n",
    "x_train_computer, x_test_computer, y_train_computer, y_test_computer = train_test_split1(x_computer, y_computer)\n",
    "x_train_concrete_compressive_strength, x_test_concrete_compressive_strength, y_train_concrete_compressive_strength, y_test_concrete_compressive_strength = train_test_split1(x_concrete_compressive_strength, y_concrete_compressive_strength)\n",
    "x_train_concrete1, x_test_concrete1, y_train_concrete1, y_test_concrete1 = train_test_split1(x_concrete1, y_concrete1)\n",
    "x_train_concrete2, x_test_concrete2, y_train_concrete2, y_test_concrete2 = train_test_split1(x_concrete2, y_concrete2)\n",
    "x_train_concrete3, x_test_concrete3, y_train_concrete3, y_test_concrete3 = train_test_split1(x_concrete3, y_concrete3)\n",
    "x_train_energy1, x_test_energy1, y_train_energy1, y_test_energy1 = train_test_split1(x_energy1, y_energy1)\n",
    "x_train_energy2, x_test_energy2, y_train_energy2, y_test_energy2 = train_test_split1(x_energy2, y_energy2)\n",
    "x_train_fertility, x_test_fertility, y_train_fertility, y_test_fertility = train_test_split1(x_fertility, y_fertility)\n",
    "x_train_forest, x_test_forest, y_train_forest, y_test_forest = train_test_split1(x_forest, y_forest)\n",
    "x_train_housing, x_test_housing, y_train_housing, y_test_housing = train_test_split1(x_housing, y_housing)\n",
    "x_train_istanbul, x_test_istanbul, y_train_istanbul, y_test_istanbul = train_test_split1(x_istanbul, y_istanbul)\n",
    "x_train_wdbc, x_test_wdbc, y_train_wdbc, y_test_wdbc = train_test_split1(x_wdbc, y_wdbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_split(x_train, y_train):\n",
    "    X_train, X_val, Y_train, Y_val= train_test_split(x_train, y_train, test_size=0.176, random_state=42)\n",
    "    return X_train, X_val, Y_train, Y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_scaler(X_train, X_val, x_test):\n",
    "    sc=StandardScaler()\n",
    "    X_train=X_train.values\n",
    "    X_val=X_val.values\n",
    "    x_test=x_test.values\n",
    "    X_scale_train=sc.fit(X_train)\n",
    "    #X_scale_val=sc.fit(X_val)\n",
    "    #x_scale_test=sc.fit(x_test)\n",
    "    X_train=X_scale_train.transform(X_train)\n",
    "    X_val=X_scale_train.transform(X_val)\n",
    "    x_test=X_scale_train.transform(x_test)\n",
    "    return X_train, X_val, x_test, X_scale_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_scaler_automobile(X_train, X_val, x_test, Y_train, Y_val, y_test):\n",
    "    minmax_x=MinMaxScaler()\n",
    "    minmax_y=MinMaxScaler()\n",
    "    X_train=X_train.values\n",
    "    X_val=X_val.values\n",
    "    x_test=x_test.values\n",
    "    X_scale_train=minmax_x.fit(X_train)\n",
    "    #X_scale_val=min_max.fit(X_val)\n",
    "    #x_scale_test=min_max.fit(x_test)\n",
    "    Y_scale_train=minmax_y.fit(Y_train)\n",
    "    #Y_scale_val=min_max.fit(Y_val)\n",
    "    #y_scale_test=min_max.fit(y_test)\n",
    "    X_train=X_scale_train.transform(X_train)\n",
    "    X_val=X_scale_train.transform(X_val)\n",
    "    x_test=X_scale_train.transform(x_test)\n",
    "    Y_train=Y_scale_train.transform(Y_train)\n",
    "    Y_val=Y_scale_train.transform(Y_val)\n",
    "    y_test=Y_scale_train.transform(y_test)\n",
    "    return X_train, X_val, x_test, Y_train, Y_val, y_test, X_scale_train, Y_scale_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_scaler(X_train, X_val, x_test, Y_train, Y_val, y_test):\n",
    "    min_max=MinMaxScaler()\n",
    "    X_train=X_train.values\n",
    "    X_val=X_val.values\n",
    "    x_test=x_test.values\n",
    "    X_scale_train=min_max.fit(X_train)\n",
    "    X_scale_val=min_max.fit(X_val)\n",
    "    x_scale_test=min_max.fit(x_test)\n",
    "    Y_scale_train=min_max.fit(Y_train)\n",
    "    Y_scale_val=min_max.fit(Y_val)\n",
    "    y_scale_test=min_max.fit(y_test)\n",
    "    X_train=X_scale_train.transform(X_train)\n",
    "    X_val=X_scale_val.transform(X_val)\n",
    "    x_test=x_scale_test.transform(x_test)\n",
    "    Y_train=Y_scale_train.transform(Y_train)\n",
    "    Y_val=Y_scale_train.transform(Y_val)\n",
    "    y_test=y_scale_test.transform(y_test)\n",
    "    return X_train, X_val, x_test, Y_train, Y_val, y_test, min_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(X_train, X_val, x_test, Y_train, Y_val, y_test):\n",
    "    normalizer=Normalizer()\n",
    "    X_train=normalizer.fit_transform(X_train)\n",
    "    X_val=normalizer.fit_transform(X_val)\n",
    "    x_test=normalizer.fit_transform(x_test)\n",
    "    Y_train=normalizer.fit_transform(Y_train)\n",
    "    Y_val=normalizer.fit_transform(Y_val)\n",
    "    y_test=normalizer.fit_transform(y_test)\n",
    "    return X_train, X_val, x_test, Y_train, Y_val, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimizer list\n",
    "adam0 = optimizers.Adam(lr=0.1)\n",
    "adam1 = optimizers.Adam(lr=0.001)\n",
    "adam2 = optimizers.Adam(lr=0.01)\n",
    "adam3 = optimizers.Adam(lr=0.0001)\n",
    "adam4 = optimizers.Adam(lr=0.00001)\n",
    "sgd = optimizers.SGD(lr=0.00001, decay=1e-4, momentum=0.9, nesterov=True)\n",
    "RMSprop= optimizers.RMSprop(lr=0.01,rho=0.9)\n",
    "adagrad = optimizers.Adagrad(lr=0.01)\n",
    "adadelta = optimizers.Adadelta(lr=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_model_structure_regression_1(X_train, X_val, Y_train, Y_val, adam, size, epochs, x_test, y_test):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units = 5, input_dim = (X_train.shape[1])))\n",
    "    model.add(Activation('tanh'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(units = 5))\n",
    "    model.add(Activation('linear'))\n",
    "    model.add(Dense(units = 1))\n",
    "    model.compile(optimizer = adam , loss = 'mse')\n",
    "    model.summary()\n",
    "    history=model.fit(X_train,Y_train, batch_size=size,epochs=epochs, validation_data=(X_val, Y_val), shuffle=True)\n",
    "    evaluate = model.evaluate(x_test, y_test, verbose=2, batch_size=size)\n",
    "    print(evaluate)\n",
    "    return model, history, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_model_structure_regression_2(X_train, X_val, Y_train, Y_val, adam, size, epochs, x_test, y_test):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units = 5, input_dim = (X_train.shape[1])))\n",
    "    model.add(Activation('tanh'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(units = 10))\n",
    "    model.add(Activation('linear'))\n",
    "    model.add(Dense(units = 1))\n",
    "    model.compile(optimizer = adam , loss = 'mse')\n",
    "    model.summary()\n",
    "    history=model.fit(X_train,Y_train, batch_size=size,epochs=epochs, validation_data=(X_val, Y_val), shuffle=True)\n",
    "    evaluate = model.evaluate(x_test, y_test, verbose=2, batch_size=size)\n",
    "    print(evaluate)\n",
    "    return model, history, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_model_structure_regression_3(X_train, X_val, Y_train, Y_val, adam, size, epochs, x_test, y_test):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units = 5, input_dim = (X_train.shape[1])))\n",
    "    model.add(Activation('tanh'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(units = 15))\n",
    "    model.add(Activation('linear'))\n",
    "    model.add(Dense(units = 1))\n",
    "    model.compile(optimizer = adam , loss = 'mse')\n",
    "    model.summary()\n",
    "    history=model.fit(X_train,Y_train, batch_size=size,epochs=epochs, validation_data=(X_val, Y_val), shuffle=True)\n",
    "    evaluate = model.evaluate(x_test, y_test, verbose=2, batch_size=size)\n",
    "    print(evaluate)\n",
    "    return model, history, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_model_structure_regression_4(X_train, X_val, Y_train, Y_val, adam, size, epochs, x_test, y_test):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units = 10, input_dim = (X_train.shape[1])))\n",
    "    model.add(Activation('tanh'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(units = 5))\n",
    "    model.add(Activation('linear'))\n",
    "    model.add(Dense(units = 1))\n",
    "    model.compile(optimizer = adam , loss = 'mse')\n",
    "    model.summary()\n",
    "    history=model.fit(X_train,Y_train, batch_size=size,epochs=epochs, validation_data=(X_val, Y_val), shuffle=True)\n",
    "    evaluate = model.evaluate(x_test, y_test, verbose=2, batch_size=size)\n",
    "    print(evaluate)\n",
    "    return model, history, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_model_structure_regression_5(X_train, X_val, Y_train, Y_val, adam, size, epochs, x_test, y_test):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units = 10, input_dim = (X_train.shape[1])))\n",
    "    model.add(Activation('tanh'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(units = 10))\n",
    "    model.add(Activation('linear'))\n",
    "    model.add(Dense(units = 1))\n",
    "    model.compile(optimizer = adam , loss = 'mse')\n",
    "    model.summary()\n",
    "    history=model.fit(X_train,Y_train, batch_size=size,epochs=epochs, validation_data=(X_val, Y_val), shuffle=True)\n",
    "    evaluate = model.evaluate(x_test, y_test, verbose=2, batch_size=size)\n",
    "    print(evaluate)\n",
    "    return model, history, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_model_structure_regression_6(X_train, X_val, Y_train, Y_val, adam, size, epochs, x_test, y_test):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units = 10, input_dim = (X_train.shape[1])))\n",
    "    model.add(Activation('tanh'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(units = 15))\n",
    "    model.add(Activation('linear'))\n",
    "    model.add(Dense(units = 1))\n",
    "    model.compile(optimizer = adam , loss = 'mse')\n",
    "    model.summary()\n",
    "    history=model.fit(X_train,Y_train, batch_size=size,epochs=epochs, validation_data=(X_val, Y_val), shuffle=True)\n",
    "    evaluate = model.evaluate(x_test, y_test, verbose=2, batch_size=size)\n",
    "    print(evaluate)\n",
    "    return model, history, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_airfoil, X_val_airfoil, Y_train_airfoil, Y_val_airfoil = train_val_split(x_train_airfoil, y_train_airfoil)\n",
    "X_train_automobile, X_val_automobile, Y_train_automobile, Y_val_automobile = train_val_split(x_train_automobile, y_train_automobile)\n",
    "X_train_autompg, X_val_autompg, Y_train_autompg, Y_val_autompg = train_val_split(x_train_autompg, y_train_autompg)\n",
    "X_train_challenger, X_val_challenger, Y_train_challenger, Y_val_challenger = train_val_split(x_train_challenger, y_train_challenger)\n",
    "X_train_combine, X_val_combine, Y_train_combine, Y_val_combine = train_val_split(x_train_combine, y_train_combine)\n",
    "X_train_computer, X_val_computer, Y_train_computer, Y_val_computer = train_val_split(x_train_computer, y_train_computer)\n",
    "X_train_concrete_compressive_strength, X_val_concrete_compressive_strength, Y_train_concrete_compressive_strength, Y_val_concrete_compressive_strength = train_val_split(x_train_concrete_compressive_strength, y_train_concrete_compressive_strength)\n",
    "X_train_concrete1, X_val_concrete1, Y_train_concrete1, Y_val_concrete1 = train_val_split(x_train_concrete1, y_train_concrete1)\n",
    "X_train_concrete2, X_val_concrete2, Y_train_concrete2, Y_val_concrete2 = train_val_split(x_train_concrete2, y_train_concrete2)\n",
    "X_train_concrete3, X_val_concrete3, Y_train_concrete3, Y_val_concrete3 = train_val_split(x_train_concrete3, y_train_concrete3)\n",
    "X_train_energy1, X_val_energy1, Y_train_energy1, Y_val_energy1 = train_val_split(x_train_energy1, y_train_energy1)\n",
    "X_train_energy2, X_val_energy2, Y_train_energy2, Y_val_energy2 = train_val_split(x_train_energy2, y_train_energy2)\n",
    "X_train_fertility, X_val_fertility, Y_train_fertility, Y_val_fertility = train_val_split(x_train_fertility, y_train_fertility)\n",
    "X_train_forest, X_val_forest, Y_train_forest, Y_val_forest = train_val_split(x_train_forest, y_train_forest)\n",
    "X_train_housing, X_val_housing, Y_train_housing, Y_val_housing = train_val_split(x_train_housing, y_train_housing)\n",
    "X_train_istanbul, X_val_istanbul, Y_train_istanbul, Y_val_istanbul = train_val_split(x_train_istanbul, y_train_istanbul)\n",
    "X_train_wdbc, X_val_wdbc, Y_train_wdbc, Y_val_wdbc = train_val_split(x_train_wdbc, y_train_wdbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_airfoil, X_val_airfoil, x_test_airfoil, X_scale_train_airfoil=standard_scaler(X_train_airfoil, X_val_airfoil, x_test_airfoil)\n",
    "#X_train_automobile, X_val_automobile, x_test_automobile=standard_scaler(X_train_automobile, X_val_automobile, x_test_automobile)\n",
    "#X_train_automobile, X_val_automobile, x_test_automobile, Y_train_automobile, Y_val_automobile, y_test_automobile = normalization(X_train_automobile, X_val_automobile, x_test_automobile, Y_train_automobile, Y_val_automobile, y_test_automobile)\n",
    "X_train_automobile, X_val_automobile, x_test_automobile, Y_train_automobile, Y_val_automobile, y_test_automobile, X_scale_train_automobile, Y_scale_train_automobile=min_max_scaler_automobile(X_train_automobile, X_val_automobile, x_test_automobile, Y_train_automobile, Y_val_automobile, y_test_automobile)\n",
    "X_train_autompg, X_val_autompg, x_test_autompg, X_scale_train_autompg=standard_scaler(X_train_autompg, X_val_autompg, x_test_autompg)\n",
    "X_train_challenger, X_val_challenger, x_test_challenger, X_scale_train_challenger=standard_scaler(X_train_challenger, X_val_challenger, x_test_challenger)\n",
    "X_train_combine, X_val_combine, x_test_combine, Y_train_combine, Y_val_combine, y_test_combine, min_max_combine=min_max_scaler(X_train_combine, X_val_combine, x_test_combine, Y_train_combine, Y_val_combine, y_test_combine)\n",
    "X_train_computer, X_val_computer, x_test_computer, Y_train_computer, Y_val_computer, y_test_computer, min_max_computer=min_max_scaler(X_train_computer, X_val_computer, x_test_computer, Y_train_computer, Y_val_computer, y_test_computer)\n",
    "X_train_concrete_compressive_strength, X_val_concrete_compressive_strength, x_test_concrete_compressive_strength, Y_train_concrete_compressive_strength, Y_val_concrete_compressive_strength, y_test_concrete_compressive_strength, min_max_concrete_compressive_strength=min_max_scaler(X_train_concrete_compressive_strength, X_val_concrete_compressive_strength, x_test_concrete_compressive_strength, Y_train_concrete_compressive_strength, Y_val_concrete_compressive_strength, y_test_concrete_compressive_strength)\n",
    "X_train_concrete1, X_val_concrete1, x_test_concrete1, X_scale_train_concrete1=standard_scaler(X_train_concrete1, X_val_concrete1, x_test_concrete1)\n",
    "X_train_concrete2, X_val_concrete2, x_test_concrete2, Y_train_concrete2, Y_val_concrete2, y_test_concrete2, min_max_concrete2=min_max_scaler(X_train_concrete2, X_val_concrete2, x_test_concrete2, Y_train_concrete2, Y_val_concrete2, y_test_concrete2)\n",
    "X_train_concrete3, X_val_concrete3, x_test_concrete3, Y_train_concrete3, Y_val_concrete3, y_test_concrete3, min_max_concrete3=min_max_scaler(X_train_concrete3, X_val_concrete3, x_test_concrete3, Y_train_concrete3, Y_val_concrete3, y_test_concrete3)\n",
    "X_train_energy1, X_val_energy1, x_test_energy1, X_scale_train_energy1=standard_scaler(X_train_energy1, X_val_energy1, x_test_energy1)\n",
    "X_train_energy2, X_val_energy2, x_test_energy2, X_scale_train_energy2=standard_scaler(X_train_energy2, X_val_energy2, x_test_energy2)\n",
    "X_train_fertility, X_val_fertility, x_test_fertility, X_scale_train_fertility=standard_scaler(X_train_fertility, X_val_fertility, x_test_fertility)\n",
    "X_train_forest, X_val_forest, x_test_forest, Y_train_forest, Y_val_forest, y_test_forest, min_max_forest=min_max_scaler(X_train_forest, X_val_forest, x_test_forest, Y_train_forest, Y_val_forest, y_test_forest)\n",
    "X_train_housing, X_val_housing, x_test_housing, X_scale_train_housing=standard_scaler(X_train_housing, X_val_housing, x_test_housing)\n",
    "X_train_istanbul, X_val_istanbul, x_test_istanbul, X_scale_train_istanbul=standard_scaler(X_train_istanbul, X_val_istanbul, x_test_istanbul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 66\n",
      "Trainable params: 66\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 1052 samples, validate on 225 samples\n",
      "Epoch 1/1000\n",
      "1052/1052 [==============================] - 0s 411us/step - loss: 15286.7690 - val_loss: 14715.8223\n",
      "Epoch 2/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13127.7590 - val_loss: 10580.7141\n",
      "Epoch 3/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7279.1014 - val_loss: 3744.8199\n",
      "Epoch 4/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 1680.1373 - val_loss: 345.9781\n",
      "Epoch 5/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 105.7408 - val_loss: 33.3299\n",
      "Epoch 6/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 31.2294 - val_loss: 27.3572\n",
      "Epoch 7/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 25.4706 - val_loss: 25.7487\n",
      "Epoch 8/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 23.7839 - val_loss: 25.2867\n",
      "Epoch 9/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 23.0557 - val_loss: 25.1697\n",
      "Epoch 10/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 22.7234 - val_loss: 25.0074\n",
      "Epoch 11/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.3537 - val_loss: 25.0477\n",
      "Epoch 12/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.0889 - val_loss: 25.0065\n",
      "Epoch 13/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.1071 - val_loss: 25.1620\n",
      "Epoch 14/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 22.1340 - val_loss: 25.2473\n",
      "Epoch 15/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.9847 - val_loss: 25.1576\n",
      "Epoch 16/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 22.0160 - val_loss: 25.5783\n",
      "Epoch 17/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.1038 - val_loss: 25.2884\n",
      "Epoch 18/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.0715 - val_loss: 26.3251\n",
      "Epoch 19/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.0321 - val_loss: 25.1920\n",
      "Epoch 20/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.9931 - val_loss: 26.4799\n",
      "Epoch 21/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.1110 - val_loss: 25.5321\n",
      "Epoch 22/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.9161 - val_loss: 25.3796\n",
      "Epoch 23/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.0127 - val_loss: 25.9532\n",
      "Epoch 24/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.9797 - val_loss: 25.2126\n",
      "Epoch 25/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.2390 - val_loss: 25.2788\n",
      "Epoch 26/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 21.9710 - val_loss: 25.2795\n",
      "Epoch 27/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 22.0917 - val_loss: 25.6414\n",
      "Epoch 28/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 22.1855 - val_loss: 26.4005\n",
      "Epoch 29/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.3139 - val_loss: 26.5449\n",
      "Epoch 30/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.1383 - val_loss: 25.4025\n",
      "Epoch 31/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.8584 - val_loss: 25.9820\n",
      "Epoch 32/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.8379 - val_loss: 25.6383\n",
      "Epoch 33/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 22.3835 - val_loss: 25.8944\n",
      "Epoch 34/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.0590 - val_loss: 25.4257\n",
      "Epoch 35/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 22.1102 - val_loss: 25.5245\n",
      "Epoch 36/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 21.9986 - val_loss: 26.0734\n",
      "Epoch 37/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 22.0681 - val_loss: 25.3695\n",
      "Epoch 38/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 22.1284 - val_loss: 25.7244\n",
      "Epoch 39/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.3301 - val_loss: 26.5065\n",
      "Epoch 40/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.8554 - val_loss: 25.4243\n",
      "Epoch 41/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 21.9937 - val_loss: 27.1493\n",
      "Epoch 42/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 22.9920 - val_loss: 25.8355\n",
      "Epoch 43/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 22.1222 - val_loss: 25.6547\n",
      "Epoch 44/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.9344 - val_loss: 25.8818\n",
      "Epoch 45/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 22.3454 - val_loss: 25.6922\n",
      "Epoch 46/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.1967 - val_loss: 25.6306\n",
      "Epoch 47/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.8411 - val_loss: 26.7462\n",
      "Epoch 48/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.0893 - val_loss: 26.2496\n",
      "Epoch 49/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.8362 - val_loss: 25.5850\n",
      "Epoch 50/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 21.7461 - val_loss: 25.3896\n",
      "Epoch 51/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 21.9863 - val_loss: 25.7281\n",
      "Epoch 52/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.9826 - val_loss: 26.0609\n",
      "Epoch 53/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.8012 - val_loss: 25.3695\n",
      "Epoch 54/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.8675 - val_loss: 25.8165\n",
      "Epoch 55/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.3297 - val_loss: 25.2602\n",
      "Epoch 56/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.1207 - val_loss: 25.3771\n",
      "Epoch 57/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.1489 - val_loss: 27.0646\n",
      "Epoch 58/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 22.0204 - val_loss: 25.8972\n",
      "Epoch 59/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.8290 - val_loss: 25.8076\n",
      "Epoch 60/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.9139 - val_loss: 25.8680\n",
      "Epoch 61/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 21.9914 - val_loss: 26.1569\n",
      "Epoch 62/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.4218 - val_loss: 26.7497\n",
      "Epoch 63/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.8833 - val_loss: 25.3740\n",
      "Epoch 64/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.2669 - val_loss: 25.2893\n",
      "Epoch 65/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.8810 - val_loss: 26.0039\n",
      "Epoch 66/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 22.1261 - val_loss: 25.4663\n",
      "Epoch 67/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 21.8649 - val_loss: 25.3604\n",
      "Epoch 68/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 21.7162 - val_loss: 25.5009\n",
      "Epoch 69/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.9001 - val_loss: 25.6936\n",
      "Epoch 70/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 22.0035 - val_loss: 26.1389\n",
      "Epoch 71/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 22.0356 - val_loss: 26.0249\n",
      "Epoch 72/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 22.0018 - val_loss: 25.9081\n",
      "Epoch 73/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 21.8790 - val_loss: 26.2634\n",
      "Epoch 74/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 22.1655 - val_loss: 25.7205\n",
      "Epoch 75/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 21.8627 - val_loss: 25.4647\n",
      "Epoch 76/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.7317 - val_loss: 26.2059\n",
      "Epoch 77/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 23.4322 - val_loss: 25.5827\n",
      "Epoch 78/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.1539 - val_loss: 26.1673\n",
      "Epoch 79/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 21.9978 - val_loss: 26.0703\n",
      "Epoch 80/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.0354 - val_loss: 26.4347\n",
      "Epoch 81/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.8239 - val_loss: 25.4596\n",
      "Epoch 82/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 22.7943 - val_loss: 25.6469\n",
      "Epoch 83/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 22.0025 - val_loss: 26.4056\n",
      "Epoch 84/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 22.6919 - val_loss: 25.6075\n",
      "Epoch 85/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 21.6856 - val_loss: 25.9387\n",
      "Epoch 86/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.8014 - val_loss: 25.7666\n",
      "Epoch 87/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.8393 - val_loss: 25.8028\n",
      "Epoch 88/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.0686 - val_loss: 28.4247\n",
      "Epoch 89/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.4817 - val_loss: 25.3672\n",
      "Epoch 90/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.0617 - val_loss: 25.5511\n",
      "Epoch 91/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.6239 - val_loss: 25.8181\n",
      "Epoch 92/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 22.3529 - val_loss: 25.6258\n",
      "Epoch 93/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 22.0825 - val_loss: 25.3051\n",
      "Epoch 94/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.6937 - val_loss: 26.9217\n",
      "Epoch 95/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.8592 - val_loss: 25.9804\n",
      "Epoch 96/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.7054 - val_loss: 25.8906\n",
      "Epoch 97/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 22.5116 - val_loss: 26.9510\n",
      "Epoch 98/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.9430 - val_loss: 28.3949\n",
      "Epoch 99/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 21.9845 - val_loss: 26.0190\n",
      "Epoch 100/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.7575 - val_loss: 26.2075\n",
      "Epoch 101/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 23.1502 - val_loss: 25.9018\n",
      "Epoch 102/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 21.7324 - val_loss: 26.2272\n",
      "Epoch 103/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 21.8932 - val_loss: 26.0705\n",
      "Epoch 104/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.0506 - val_loss: 26.0795\n",
      "Epoch 105/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 22.0811 - val_loss: 26.0355\n",
      "Epoch 106/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.9284 - val_loss: 26.0214\n",
      "Epoch 107/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 22.3499 - val_loss: 25.9967\n",
      "Epoch 108/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 22.3607 - val_loss: 26.0795\n",
      "Epoch 109/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.3780 - val_loss: 27.0532\n",
      "Epoch 110/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 22.8291 - val_loss: 25.5506\n",
      "Epoch 111/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 22.2389 - val_loss: 28.5814\n",
      "Epoch 112/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 22.1185 - val_loss: 25.5107\n",
      "Epoch 113/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.6778 - val_loss: 26.5773\n",
      "Epoch 114/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.7971 - val_loss: 26.2779\n",
      "Epoch 115/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 22.6711 - val_loss: 29.1086\n",
      "Epoch 116/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 21.9702 - val_loss: 26.2037\n",
      "Epoch 117/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 22.0555 - val_loss: 25.5513\n",
      "Epoch 118/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.0511 - val_loss: 25.6327\n",
      "Epoch 119/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.5085 - val_loss: 25.7769\n",
      "Epoch 120/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 22.0158 - val_loss: 26.6912\n",
      "Epoch 121/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.2269 - val_loss: 26.3441\n",
      "Epoch 122/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 21.8483 - val_loss: 26.3012\n",
      "Epoch 123/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.9269 - val_loss: 26.3804\n",
      "Epoch 124/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.6058 - val_loss: 26.2962\n",
      "Epoch 125/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 21.5535 - val_loss: 25.4905\n",
      "Epoch 126/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.9782 - val_loss: 25.9106\n",
      "Epoch 127/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.0517 - val_loss: 25.9325\n",
      "Epoch 128/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.9545 - val_loss: 26.8403\n",
      "Epoch 129/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.8368 - val_loss: 25.2345\n",
      "Epoch 130/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 22.1924 - val_loss: 25.5693\n",
      "Epoch 131/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.7136 - val_loss: 25.7690\n",
      "Epoch 132/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 21.8170 - val_loss: 25.3929\n",
      "Epoch 133/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.8170 - val_loss: 25.7244\n",
      "Epoch 134/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.2818 - val_loss: 25.2216\n",
      "Epoch 135/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.9359 - val_loss: 25.8383\n",
      "Epoch 136/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.8439 - val_loss: 25.7023\n",
      "Epoch 137/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.9471 - val_loss: 25.4303\n",
      "Epoch 138/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.6817 - val_loss: 25.3810\n",
      "Epoch 139/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.7742 - val_loss: 26.5690\n",
      "Epoch 140/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.2437 - val_loss: 26.7113\n",
      "Epoch 141/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.8637 - val_loss: 26.2607\n",
      "Epoch 142/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 21.5677 - val_loss: 25.6067\n",
      "Epoch 143/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.2219 - val_loss: 26.2450\n",
      "Epoch 144/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.4557 - val_loss: 25.6124\n",
      "Epoch 145/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.5848 - val_loss: 26.6953\n",
      "Epoch 146/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.7013 - val_loss: 26.0434\n",
      "Epoch 147/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 22.2140 - val_loss: 25.9594\n",
      "Epoch 148/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.5475 - val_loss: 25.2302\n",
      "Epoch 149/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.9216 - val_loss: 28.9364\n",
      "Epoch 150/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.8183 - val_loss: 25.8929\n",
      "Epoch 151/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.8465 - val_loss: 25.3792\n",
      "Epoch 152/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.5388 - val_loss: 26.9596\n",
      "Epoch 153/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.2534 - val_loss: 25.8497\n",
      "Epoch 154/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.6349 - val_loss: 25.5310\n",
      "Epoch 155/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.0970 - val_loss: 26.6842\n",
      "Epoch 156/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.5601 - val_loss: 26.8078\n",
      "Epoch 157/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 21.5802 - val_loss: 27.0714\n",
      "Epoch 158/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.6375 - val_loss: 27.9087\n",
      "Epoch 159/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.6221 - val_loss: 25.4575\n",
      "Epoch 160/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 21.3701 - val_loss: 26.0628\n",
      "Epoch 161/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 21.7159 - val_loss: 25.5649\n",
      "Epoch 162/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 21.6473 - val_loss: 27.9416\n",
      "Epoch 163/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 21.6025 - val_loss: 24.5435\n",
      "Epoch 164/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.1844 - val_loss: 25.8653\n",
      "Epoch 165/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 21.3512 - val_loss: 25.1447\n",
      "Epoch 166/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.7258 - val_loss: 24.6606\n",
      "Epoch 167/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.0063 - val_loss: 24.5385\n",
      "Epoch 168/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 20.7028 - val_loss: 25.5814\n",
      "Epoch 169/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.1074 - val_loss: 25.1151\n",
      "Epoch 170/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 20.8074 - val_loss: 25.6542\n",
      "Epoch 171/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 21.1498 - val_loss: 25.4167\n",
      "Epoch 172/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.0673 - val_loss: 24.6734\n",
      "Epoch 173/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 20.6132 - val_loss: 25.5402\n",
      "Epoch 174/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 20.7648 - val_loss: 26.6136\n",
      "Epoch 175/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 20.9948 - val_loss: 25.8347\n",
      "Epoch 176/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.0895 - val_loss: 24.3675\n",
      "Epoch 177/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 21.2687 - val_loss: 24.7972\n",
      "Epoch 178/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 20.7780 - val_loss: 23.9995\n",
      "Epoch 179/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 20.7798 - val_loss: 24.3886\n",
      "Epoch 180/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 21.4172 - val_loss: 25.5352\n",
      "Epoch 181/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 20.5761 - val_loss: 25.3593\n",
      "Epoch 182/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 21.0556 - val_loss: 23.4624\n",
      "Epoch 183/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 20.8728 - val_loss: 24.1294\n",
      "Epoch 184/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 20.2151 - val_loss: 23.9674\n",
      "Epoch 185/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 20.1949 - val_loss: 25.3777\n",
      "Epoch 186/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 20.6629 - val_loss: 24.1864\n",
      "Epoch 187/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 20.5538 - val_loss: 25.9508\n",
      "Epoch 188/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 20.0405 - val_loss: 24.4242\n",
      "Epoch 189/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 19.8488 - val_loss: 24.8599\n",
      "Epoch 190/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 19.7617 - val_loss: 24.6476\n",
      "Epoch 191/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.9415 - val_loss: 23.0741\n",
      "Epoch 192/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.8172 - val_loss: 23.4241\n",
      "Epoch 193/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.7348 - val_loss: 22.0632\n",
      "Epoch 194/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.5832 - val_loss: 22.2498\n",
      "Epoch 195/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.3960 - val_loss: 22.3423\n",
      "Epoch 196/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.2942 - val_loss: 22.4088\n",
      "Epoch 197/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 18.9594 - val_loss: 22.2124\n",
      "Epoch 198/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.8829 - val_loss: 21.2678\n",
      "Epoch 199/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.2726 - val_loss: 23.3534\n",
      "Epoch 200/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.9916 - val_loss: 21.7198\n",
      "Epoch 201/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 17.6283 - val_loss: 21.5191\n",
      "Epoch 202/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 17.2943 - val_loss: 21.4031\n",
      "Epoch 203/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.3737 - val_loss: 23.3532\n",
      "Epoch 204/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.5941 - val_loss: 20.5213\n",
      "Epoch 205/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.0737 - val_loss: 20.0891\n",
      "Epoch 206/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 16.8586 - val_loss: 20.0350\n",
      "Epoch 207/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.2548 - val_loss: 20.6645\n",
      "Epoch 208/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.3197 - val_loss: 20.2046\n",
      "Epoch 209/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.4287 - val_loss: 21.0225\n",
      "Epoch 210/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.5496 - val_loss: 19.6315\n",
      "Epoch 211/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.1500 - val_loss: 21.1982\n",
      "Epoch 212/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 16.9050 - val_loss: 19.3390\n",
      "Epoch 213/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 16.7759 - val_loss: 19.2117\n",
      "Epoch 214/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 16.8920 - val_loss: 19.1640\n",
      "Epoch 215/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 89us/step - loss: 16.6407 - val_loss: 18.8315\n",
      "Epoch 216/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.0008 - val_loss: 18.9548\n",
      "Epoch 217/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 16.7312 - val_loss: 19.4881\n",
      "Epoch 218/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 16.4916 - val_loss: 18.6400\n",
      "Epoch 219/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 16.1571 - val_loss: 19.7297\n",
      "Epoch 220/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 16.3939 - val_loss: 18.9357\n",
      "Epoch 221/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 16.4312 - val_loss: 19.8506\n",
      "Epoch 222/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 16.3919 - val_loss: 19.0298\n",
      "Epoch 223/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 16.1944 - val_loss: 18.5236\n",
      "Epoch 224/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 16.1661 - val_loss: 19.5387\n",
      "Epoch 225/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 16.1159 - val_loss: 19.8889\n",
      "Epoch 226/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 15.9792 - val_loss: 17.7240\n",
      "Epoch 227/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 16.4165 - val_loss: 17.8370\n",
      "Epoch 228/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 15.6674 - val_loss: 18.0181\n",
      "Epoch 229/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 16.0451 - val_loss: 20.4882\n",
      "Epoch 230/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 16.0838 - val_loss: 17.8012\n",
      "Epoch 231/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 15.9480 - val_loss: 18.6841\n",
      "Epoch 232/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 15.4248 - val_loss: 18.4025\n",
      "Epoch 233/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 15.4495 - val_loss: 18.9835\n",
      "Epoch 234/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 15.2903 - val_loss: 17.7276\n",
      "Epoch 235/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 15.4730 - val_loss: 17.3493\n",
      "Epoch 236/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 16.3530 - val_loss: 17.8364\n",
      "Epoch 237/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 16.3403 - val_loss: 17.6172\n",
      "Epoch 238/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 15.7425 - val_loss: 17.1558\n",
      "Epoch 239/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.9526 - val_loss: 17.5773\n",
      "Epoch 240/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 15.5157 - val_loss: 17.4435\n",
      "Epoch 241/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 15.9251 - val_loss: 18.0445\n",
      "Epoch 242/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 15.1109 - val_loss: 17.8992\n",
      "Epoch 243/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 15.4291 - val_loss: 17.6028\n",
      "Epoch 244/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 15.4561 - val_loss: 16.6265\n",
      "Epoch 245/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 14.9330 - val_loss: 18.1222\n",
      "Epoch 246/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 15.0883 - val_loss: 17.8954\n",
      "Epoch 247/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.6642 - val_loss: 16.8344\n",
      "Epoch 248/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 14.6905 - val_loss: 17.5127\n",
      "Epoch 249/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.6836 - val_loss: 18.9959\n",
      "Epoch 250/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 15.2087 - val_loss: 18.5536\n",
      "Epoch 251/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.8889 - val_loss: 18.6195\n",
      "Epoch 252/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.6409 - val_loss: 18.9530\n",
      "Epoch 253/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.5250 - val_loss: 17.4148\n",
      "Epoch 254/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.6298 - val_loss: 18.2918\n",
      "Epoch 255/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.4332 - val_loss: 18.8666\n",
      "Epoch 256/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.0491 - val_loss: 16.4027\n",
      "Epoch 257/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.3432 - val_loss: 18.3895\n",
      "Epoch 258/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.2520 - val_loss: 16.5272\n",
      "Epoch 259/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 15.0401 - val_loss: 17.1578\n",
      "Epoch 260/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.4537 - val_loss: 16.3726\n",
      "Epoch 261/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.1071 - val_loss: 16.6728\n",
      "Epoch 262/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.7191 - val_loss: 18.1754\n",
      "Epoch 263/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.6699 - val_loss: 17.3591\n",
      "Epoch 264/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.6559 - val_loss: 16.7484\n",
      "Epoch 265/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.8760 - val_loss: 16.0098\n",
      "Epoch 266/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.9965 - val_loss: 17.7515\n",
      "Epoch 267/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.3731 - val_loss: 19.6999\n",
      "Epoch 268/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.8502 - val_loss: 17.1636\n",
      "Epoch 269/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.0309 - val_loss: 16.2690\n",
      "Epoch 270/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.1865 - val_loss: 16.4498\n",
      "Epoch 271/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.7329 - val_loss: 16.4534\n",
      "Epoch 272/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.1737 - val_loss: 17.3573\n",
      "Epoch 273/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.3993 - val_loss: 17.2788\n",
      "Epoch 274/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.4224 - val_loss: 16.6411\n",
      "Epoch 275/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.9243 - val_loss: 16.2903\n",
      "Epoch 276/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 12.9115 - val_loss: 17.2116\n",
      "Epoch 277/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.5618 - val_loss: 16.8408\n",
      "Epoch 278/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.4709 - val_loss: 19.9421\n",
      "Epoch 279/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.6529 - val_loss: 17.6208\n",
      "Epoch 280/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.9005 - val_loss: 16.0106\n",
      "Epoch 281/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 12.9760 - val_loss: 16.0350\n",
      "Epoch 282/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.9348 - val_loss: 16.5872\n",
      "Epoch 283/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.3296 - val_loss: 15.5068\n",
      "Epoch 284/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.7823 - val_loss: 15.1718\n",
      "Epoch 285/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 12.8254 - val_loss: 17.1680\n",
      "Epoch 286/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.8744 - val_loss: 15.7786\n",
      "Epoch 287/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 12.2043 - val_loss: 16.4098\n",
      "Epoch 288/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 12.5066 - val_loss: 15.6808\n",
      "Epoch 289/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 12.6543 - val_loss: 16.4376\n",
      "Epoch 290/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 92us/step - loss: 12.1017 - val_loss: 15.3037\n",
      "Epoch 291/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.1053 - val_loss: 15.6009\n",
      "Epoch 292/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.5652 - val_loss: 17.1044\n",
      "Epoch 293/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.1199 - val_loss: 18.9269\n",
      "Epoch 294/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.3455 - val_loss: 16.8889\n",
      "Epoch 295/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.2363 - val_loss: 14.6605\n",
      "Epoch 296/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.9010 - val_loss: 15.5539\n",
      "Epoch 297/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.8441 - val_loss: 14.6973\n",
      "Epoch 298/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.9165 - val_loss: 16.3392\n",
      "Epoch 299/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.6721 - val_loss: 14.3547\n",
      "Epoch 300/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.6172 - val_loss: 14.1433\n",
      "Epoch 301/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.2626 - val_loss: 14.6190\n",
      "Epoch 302/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.2510 - val_loss: 14.5514\n",
      "Epoch 303/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.1449 - val_loss: 14.4831\n",
      "Epoch 304/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.0879 - val_loss: 16.2334\n",
      "Epoch 305/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.5349 - val_loss: 14.1290\n",
      "Epoch 306/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.7141 - val_loss: 14.7470\n",
      "Epoch 307/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.3866 - val_loss: 14.7528\n",
      "Epoch 308/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 11.2550 - val_loss: 13.3573\n",
      "Epoch 309/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.3344 - val_loss: 14.3197\n",
      "Epoch 310/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.5260 - val_loss: 17.8202\n",
      "Epoch 311/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.3032 - val_loss: 14.9533\n",
      "Epoch 312/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.9423 - val_loss: 13.2884\n",
      "Epoch 313/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.1790 - val_loss: 13.9682\n",
      "Epoch 314/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.3809 - val_loss: 14.1958\n",
      "Epoch 315/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.4598 - val_loss: 13.5137\n",
      "Epoch 316/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.6927 - val_loss: 12.9730\n",
      "Epoch 317/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.9830 - val_loss: 12.7484\n",
      "Epoch 318/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.6374 - val_loss: 13.9164\n",
      "Epoch 319/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.9655 - val_loss: 13.4660\n",
      "Epoch 320/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.2802 - val_loss: 13.5931\n",
      "Epoch 321/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.4785 - val_loss: 12.8710\n",
      "Epoch 322/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.6140 - val_loss: 15.1694\n",
      "Epoch 323/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.0812 - val_loss: 14.1086\n",
      "Epoch 324/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.6563 - val_loss: 14.0023\n",
      "Epoch 325/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.6941 - val_loss: 13.8370\n",
      "Epoch 326/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.9857 - val_loss: 12.9635\n",
      "Epoch 327/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.9056 - val_loss: 14.7393\n",
      "Epoch 328/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 11.0754 - val_loss: 13.5226\n",
      "Epoch 329/1000\n",
      "1052/1052 [==============================] - 0s 112us/step - loss: 10.4910 - val_loss: 14.6904\n",
      "Epoch 330/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 10.7124 - val_loss: 12.8227\n",
      "Epoch 331/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.2017 - val_loss: 13.9393\n",
      "Epoch 332/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 10.3918 - val_loss: 13.6712\n",
      "Epoch 333/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 10.8239 - val_loss: 12.9024\n",
      "Epoch 334/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 10.0009 - val_loss: 13.8105\n",
      "Epoch 335/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.2365 - val_loss: 13.3031\n",
      "Epoch 336/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 10.4080 - val_loss: 12.8276\n",
      "Epoch 337/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 10.5026 - val_loss: 12.1150\n",
      "Epoch 338/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 10.1434 - val_loss: 13.5367\n",
      "Epoch 339/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.6830 - val_loss: 12.3578\n",
      "Epoch 340/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.9002 - val_loss: 13.6754\n",
      "Epoch 341/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.1288 - val_loss: 13.1739\n",
      "Epoch 342/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.0491 - val_loss: 12.4413\n",
      "Epoch 343/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.4025 - val_loss: 12.7097\n",
      "Epoch 344/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 10.1814 - val_loss: 12.4215\n",
      "Epoch 345/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.3176 - val_loss: 13.6910\n",
      "Epoch 346/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.7432 - val_loss: 12.1008\n",
      "Epoch 347/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.1393 - val_loss: 12.3863\n",
      "Epoch 348/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.9962 - val_loss: 14.1312\n",
      "Epoch 349/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.9915 - val_loss: 12.2277\n",
      "Epoch 350/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 10.1250 - val_loss: 12.3127\n",
      "Epoch 351/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.1816 - val_loss: 12.2617\n",
      "Epoch 352/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 10.0376 - val_loss: 11.5853\n",
      "Epoch 353/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.9574 - val_loss: 12.3757\n",
      "Epoch 354/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 10.5115 - val_loss: 11.8079\n",
      "Epoch 355/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.5247 - val_loss: 11.8483\n",
      "Epoch 356/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.5800 - val_loss: 12.3694\n",
      "Epoch 357/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.7353 - val_loss: 11.9584\n",
      "Epoch 358/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2555 - val_loss: 11.4116\n",
      "Epoch 359/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.4819 - val_loss: 12.0948\n",
      "Epoch 360/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.5430 - val_loss: 11.7444\n",
      "Epoch 361/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.5536 - val_loss: 11.2031\n",
      "Epoch 362/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.5497 - val_loss: 11.3371\n",
      "Epoch 363/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.3436 - val_loss: 12.2376\n",
      "Epoch 364/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2947 - val_loss: 11.4773\n",
      "Epoch 365/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2868 - val_loss: 11.3284\n",
      "Epoch 366/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.3597 - val_loss: 11.7060\n",
      "Epoch 367/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.4889 - val_loss: 12.2508\n",
      "Epoch 368/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.7105 - val_loss: 12.3595\n",
      "Epoch 369/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.8032 - val_loss: 12.7740\n",
      "Epoch 370/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.5470 - val_loss: 11.3621\n",
      "Epoch 371/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1290 - val_loss: 12.6294\n",
      "Epoch 372/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1891 - val_loss: 11.8683\n",
      "Epoch 373/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.8724 - val_loss: 12.0236\n",
      "Epoch 374/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.4409 - val_loss: 12.9818\n",
      "Epoch 375/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.4407 - val_loss: 13.6726\n",
      "Epoch 376/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.7993 - val_loss: 16.3109\n",
      "Epoch 377/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1536 - val_loss: 11.1092\n",
      "Epoch 378/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0046 - val_loss: 12.0680\n",
      "Epoch 379/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.3667 - val_loss: 12.5878\n",
      "Epoch 380/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1729 - val_loss: 11.3594\n",
      "Epoch 381/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.3377 - val_loss: 12.2832\n",
      "Epoch 382/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.2766 - val_loss: 11.4824\n",
      "Epoch 383/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.5590 - val_loss: 13.0817\n",
      "Epoch 384/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.0557 - val_loss: 13.7745\n",
      "Epoch 385/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.0752 - val_loss: 11.0989\n",
      "Epoch 386/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.4893 - val_loss: 11.8653\n",
      "Epoch 387/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9229 - val_loss: 10.9915\n",
      "Epoch 388/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.9379 - val_loss: 11.3187\n",
      "Epoch 389/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.3257 - val_loss: 12.0144\n",
      "Epoch 390/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.3551 - val_loss: 10.8880\n",
      "Epoch 391/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.9132 - val_loss: 12.0498\n",
      "Epoch 392/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.7607 - val_loss: 11.5412\n",
      "Epoch 393/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8768 - val_loss: 11.5819\n",
      "Epoch 394/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.9690 - val_loss: 10.9965\n",
      "Epoch 395/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.8042 - val_loss: 11.6363\n",
      "Epoch 396/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9778 - val_loss: 11.1077\n",
      "Epoch 397/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9976 - val_loss: 11.0136\n",
      "Epoch 398/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.3052 - val_loss: 11.3713\n",
      "Epoch 399/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0275 - val_loss: 11.0396\n",
      "Epoch 400/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0037 - val_loss: 10.6302\n",
      "Epoch 401/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.7615 - val_loss: 11.1814\n",
      "Epoch 402/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 9.0099 - val_loss: 11.4104\n",
      "Epoch 403/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.8973 - val_loss: 10.6106\n",
      "Epoch 404/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.8947 - val_loss: 11.5212\n",
      "Epoch 405/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.1863 - val_loss: 11.1373\n",
      "Epoch 406/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.3563 - val_loss: 11.5966\n",
      "Epoch 407/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.9463 - val_loss: 10.6235\n",
      "Epoch 408/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.8741 - val_loss: 12.4611\n",
      "Epoch 409/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 9.0198 - val_loss: 11.4212\n",
      "Epoch 410/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8417 - val_loss: 11.4711\n",
      "Epoch 411/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 9.0345 - val_loss: 10.6992\n",
      "Epoch 412/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.8725 - val_loss: 11.2001\n",
      "Epoch 413/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.5644 - val_loss: 11.2953\n",
      "Epoch 414/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.9597 - val_loss: 11.1624\n",
      "Epoch 415/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5702 - val_loss: 10.9168\n",
      "Epoch 416/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0072 - val_loss: 10.5251\n",
      "Epoch 417/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7060 - val_loss: 10.4056\n",
      "Epoch 418/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.8624 - val_loss: 10.4851\n",
      "Epoch 419/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0441 - val_loss: 12.3857\n",
      "Epoch 420/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.2150 - val_loss: 11.7664\n",
      "Epoch 421/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1508 - val_loss: 11.3153\n",
      "Epoch 422/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7048 - val_loss: 13.0122\n",
      "Epoch 423/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.9834 - val_loss: 13.2091\n",
      "Epoch 424/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8974 - val_loss: 10.5062\n",
      "Epoch 425/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7801 - val_loss: 10.8882\n",
      "Epoch 426/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7956 - val_loss: 10.4718\n",
      "Epoch 427/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4668 - val_loss: 11.0867\n",
      "Epoch 428/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5122 - val_loss: 11.3441\n",
      "Epoch 429/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8844 - val_loss: 10.8290\n",
      "Epoch 430/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5598 - val_loss: 10.6178\n",
      "Epoch 431/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4881 - val_loss: 10.3917\n",
      "Epoch 432/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.7805 - val_loss: 10.5786\n",
      "Epoch 433/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8199 - val_loss: 10.3897\n",
      "Epoch 434/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.8217 - val_loss: 10.4933\n",
      "Epoch 435/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.3660 - val_loss: 13.9212\n",
      "Epoch 436/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2661 - val_loss: 10.8917\n",
      "Epoch 437/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 7.7530 - 0s 89us/step - loss: 8.7642 - val_loss: 10.3128\n",
      "Epoch 438/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7994 - val_loss: 10.2067\n",
      "Epoch 439/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5206 - val_loss: 10.5168\n",
      "Epoch 440/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6227 - val_loss: 10.3628\n",
      "Epoch 441/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6496 - val_loss: 12.1718\n",
      "Epoch 442/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5538 - val_loss: 11.5853\n",
      "Epoch 443/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8529 - val_loss: 10.6758\n",
      "Epoch 444/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5876 - val_loss: 10.5835\n",
      "Epoch 445/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6735 - val_loss: 10.3949\n",
      "Epoch 446/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5375 - val_loss: 11.1040\n",
      "Epoch 447/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6263 - val_loss: 11.0892\n",
      "Epoch 448/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1727 - val_loss: 10.5561\n",
      "Epoch 449/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.1853 - val_loss: 11.8827\n",
      "Epoch 450/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7383 - val_loss: 10.2020\n",
      "Epoch 451/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7530 - val_loss: 10.5302\n",
      "Epoch 452/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8475 - val_loss: 10.1219\n",
      "Epoch 453/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6661 - val_loss: 10.2185\n",
      "Epoch 454/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8778 - val_loss: 12.0250\n",
      "Epoch 455/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.6106 - val_loss: 10.2058\n",
      "Epoch 456/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.4932 - val_loss: 11.2240\n",
      "Epoch 457/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8962 - val_loss: 10.8739\n",
      "Epoch 458/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5517 - val_loss: 11.8886\n",
      "Epoch 459/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.3434 - val_loss: 10.1316\n",
      "Epoch 460/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.2391 - val_loss: 12.0318\n",
      "Epoch 461/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.0106 - val_loss: 11.4911\n",
      "Epoch 462/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6044 - val_loss: 10.7300\n",
      "Epoch 463/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6509 - val_loss: 10.6643\n",
      "Epoch 464/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4335 - val_loss: 10.5645\n",
      "Epoch 465/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4662 - val_loss: 9.9095\n",
      "Epoch 466/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4477 - val_loss: 10.5464\n",
      "Epoch 467/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5408 - val_loss: 10.9970\n",
      "Epoch 468/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.5949 - val_loss: 10.4886\n",
      "Epoch 469/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5635 - val_loss: 10.6892\n",
      "Epoch 470/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.6783 - val_loss: 10.4539\n",
      "Epoch 471/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8200 - val_loss: 11.5247\n",
      "Epoch 472/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5152 - val_loss: 11.2798\n",
      "Epoch 473/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4968 - val_loss: 10.5863\n",
      "Epoch 474/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.4665 - val_loss: 11.2684\n",
      "Epoch 475/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.9224 - val_loss: 10.9277\n",
      "Epoch 476/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9130 - val_loss: 11.2823\n",
      "Epoch 477/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7026 - val_loss: 10.4522\n",
      "Epoch 478/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8675 - val_loss: 10.2827\n",
      "Epoch 479/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5655 - val_loss: 10.9587\n",
      "Epoch 480/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.5067 - val_loss: 11.1831\n",
      "Epoch 481/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6745 - val_loss: 10.8582\n",
      "Epoch 482/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4408 - val_loss: 10.6741\n",
      "Epoch 483/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5137 - val_loss: 13.7927\n",
      "Epoch 484/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0036 - val_loss: 10.6901\n",
      "Epoch 485/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0165 - val_loss: 10.3457\n",
      "Epoch 486/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3667 - val_loss: 10.2370\n",
      "Epoch 487/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5969 - val_loss: 11.2846\n",
      "Epoch 488/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5406 - val_loss: 10.3527\n",
      "Epoch 489/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4828 - val_loss: 10.5688\n",
      "Epoch 490/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.6038 - val_loss: 10.6907\n",
      "Epoch 491/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3032 - val_loss: 10.5335\n",
      "Epoch 492/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4554 - val_loss: 9.7941\n",
      "Epoch 493/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6434 - val_loss: 10.2411\n",
      "Epoch 494/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8875 - val_loss: 10.0998\n",
      "Epoch 495/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9410 - val_loss: 10.8349\n",
      "Epoch 496/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4059 - val_loss: 10.9181\n",
      "Epoch 497/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5399 - val_loss: 10.6800\n",
      "Epoch 498/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3558 - val_loss: 10.1613\n",
      "Epoch 499/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.4250 - val_loss: 10.1534\n",
      "Epoch 500/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3883 - val_loss: 10.1879\n",
      "Epoch 501/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.4933 - val_loss: 11.4333\n",
      "Epoch 502/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.1918 - val_loss: 9.9257\n",
      "Epoch 503/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3047 - val_loss: 10.4917\n",
      "Epoch 504/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3454 - val_loss: 10.3137\n",
      "Epoch 505/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.4690 - val_loss: 10.0979\n",
      "Epoch 506/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4984 - val_loss: 10.9934\n",
      "Epoch 507/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.5397 - val_loss: 10.4957\n",
      "Epoch 508/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6816 - val_loss: 10.7980\n",
      "Epoch 509/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5056 - val_loss: 10.3668\n",
      "Epoch 510/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6137 - val_loss: 11.1039\n",
      "Epoch 511/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5383 - val_loss: 12.0434\n",
      "Epoch 512/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6303 - val_loss: 10.1776\n",
      "Epoch 513/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3124 - val_loss: 10.3954\n",
      "Epoch 514/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.5954 - val_loss: 10.6819\n",
      "Epoch 515/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3682 - val_loss: 10.8072\n",
      "Epoch 516/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3986 - val_loss: 11.4149\n",
      "Epoch 517/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6163 - val_loss: 10.0788\n",
      "Epoch 518/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6787 - val_loss: 9.8074\n",
      "Epoch 519/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5500 - val_loss: 9.8115\n",
      "Epoch 520/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.1860 - val_loss: 10.2228\n",
      "Epoch 521/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4569 - val_loss: 10.5824\n",
      "Epoch 522/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.8311 - val_loss: 10.3463\n",
      "Epoch 523/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.7380 - val_loss: 10.5854\n",
      "Epoch 524/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2588 - val_loss: 10.5990\n",
      "Epoch 525/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.6789 - val_loss: 11.5642\n",
      "Epoch 526/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.6035 - val_loss: 10.3799\n",
      "Epoch 527/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.5838 - val_loss: 10.4684\n",
      "Epoch 528/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4106 - val_loss: 10.0707\n",
      "Epoch 529/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4165 - val_loss: 11.0256\n",
      "Epoch 530/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.3833 - val_loss: 9.6918\n",
      "Epoch 531/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4002 - val_loss: 10.8783\n",
      "Epoch 532/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6872 - val_loss: 10.6249\n",
      "Epoch 533/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5399 - val_loss: 10.0492\n",
      "Epoch 534/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.4608 - val_loss: 10.2846\n",
      "Epoch 535/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4110 - val_loss: 9.7462\n",
      "Epoch 536/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4010 - val_loss: 11.0733\n",
      "Epoch 537/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.7277 - val_loss: 10.3241\n",
      "Epoch 538/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5801 - val_loss: 11.3965\n",
      "Epoch 539/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3685 - val_loss: 10.0507\n",
      "Epoch 540/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7163 - val_loss: 10.9125\n",
      "Epoch 541/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7247 - val_loss: 10.9558\n",
      "Epoch 542/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5853 - val_loss: 10.3497\n",
      "Epoch 543/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8196 - val_loss: 9.7622\n",
      "Epoch 544/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6102 - val_loss: 9.5290\n",
      "Epoch 545/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4833 - val_loss: 9.5433\n",
      "Epoch 546/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3799 - val_loss: 12.2373\n",
      "Epoch 547/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3073 - val_loss: 9.9916\n",
      "Epoch 548/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3310 - val_loss: 12.5774\n",
      "Epoch 549/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.4458 - val_loss: 9.9406\n",
      "Epoch 550/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4383 - val_loss: 10.9457\n",
      "Epoch 551/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4274 - val_loss: 10.0248\n",
      "Epoch 552/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1849 - val_loss: 9.5392\n",
      "Epoch 553/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2083 - val_loss: 9.9362\n",
      "Epoch 554/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3010 - val_loss: 10.7062\n",
      "Epoch 555/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6865 - val_loss: 11.6991\n",
      "Epoch 556/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.4957 - val_loss: 10.5130\n",
      "Epoch 557/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3738 - val_loss: 9.8581\n",
      "Epoch 558/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5764 - val_loss: 10.1651\n",
      "Epoch 559/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5753 - val_loss: 9.9328\n",
      "Epoch 560/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.8763 - val_loss: 10.6603\n",
      "Epoch 561/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.3794 - val_loss: 10.5132\n",
      "Epoch 562/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1303 - val_loss: 9.6219\n",
      "Epoch 563/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6251 - val_loss: 11.3731\n",
      "Epoch 564/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3826 - val_loss: 9.8539\n",
      "Epoch 565/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.3078 - val_loss: 9.7578\n",
      "Epoch 566/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1550 - val_loss: 9.6919\n",
      "Epoch 567/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3910 - val_loss: 10.9043\n",
      "Epoch 568/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1492 - val_loss: 10.5023\n",
      "Epoch 569/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2292 - val_loss: 10.9381\n",
      "Epoch 570/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3324 - val_loss: 10.1629\n",
      "Epoch 571/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7096 - val_loss: 13.1289\n",
      "Epoch 572/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3802 - val_loss: 11.8724\n",
      "Epoch 573/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 8.5853 - val_loss: 9.6983\n",
      "Epoch 574/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 8.5220 - val_loss: 9.5809\n",
      "Epoch 575/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.2871 - val_loss: 10.5587\n",
      "Epoch 576/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.4489 - val_loss: 9.9599\n",
      "Epoch 577/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4052 - val_loss: 9.8531\n",
      "Epoch 578/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2162 - val_loss: 10.5481\n",
      "Epoch 579/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.9647 - val_loss: 10.4644\n",
      "Epoch 580/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.3269 - val_loss: 10.1167\n",
      "Epoch 581/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.3720 - val_loss: 9.7293\n",
      "Epoch 582/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5427 - val_loss: 11.3901\n",
      "Epoch 583/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4957 - val_loss: 9.9742\n",
      "Epoch 584/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6082 - val_loss: 9.4427\n",
      "Epoch 585/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0708 - val_loss: 9.8733\n",
      "Epoch 586/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4620 - val_loss: 9.4632\n",
      "Epoch 587/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.0758 - val_loss: 11.5609\n",
      "Epoch 588/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5497 - val_loss: 9.9205\n",
      "Epoch 589/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4159 - val_loss: 9.8022\n",
      "Epoch 590/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1998 - val_loss: 9.8721\n",
      "Epoch 591/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3812 - val_loss: 10.3298\n",
      "Epoch 592/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.3639 - val_loss: 11.2341\n",
      "Epoch 593/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.2746 - val_loss: 12.3464\n",
      "Epoch 594/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5089 - val_loss: 10.4106\n",
      "Epoch 595/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6045 - val_loss: 10.9687\n",
      "Epoch 596/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6247 - val_loss: 10.1714\n",
      "Epoch 597/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5342 - val_loss: 10.3282\n",
      "Epoch 598/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7484 - val_loss: 10.2477\n",
      "Epoch 599/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5046 - val_loss: 9.6659\n",
      "Epoch 600/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4128 - val_loss: 9.5292\n",
      "Epoch 601/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.1987 - val_loss: 9.4063\n",
      "Epoch 602/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4916 - val_loss: 9.4720\n",
      "Epoch 603/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1451 - val_loss: 10.4371\n",
      "Epoch 604/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4313 - val_loss: 9.7356\n",
      "Epoch 605/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5996 - val_loss: 9.3518\n",
      "Epoch 606/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1974 - val_loss: 9.9621\n",
      "Epoch 607/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5365 - val_loss: 10.2773\n",
      "Epoch 608/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0514 - val_loss: 9.7525\n",
      "Epoch 609/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3488 - val_loss: 9.5447\n",
      "Epoch 610/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5169 - val_loss: 9.7183\n",
      "Epoch 611/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2098 - val_loss: 9.7913\n",
      "Epoch 612/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3323 - val_loss: 12.2453\n",
      "Epoch 613/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9170 - val_loss: 13.2013\n",
      "Epoch 614/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.5563 - val_loss: 9.9225\n",
      "Epoch 615/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2292 - val_loss: 10.0755\n",
      "Epoch 616/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5516 - val_loss: 9.6474\n",
      "Epoch 617/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.4304 - val_loss: 9.5814\n",
      "Epoch 618/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4656 - val_loss: 10.5316\n",
      "Epoch 619/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0984 - val_loss: 9.6892\n",
      "Epoch 620/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3281 - val_loss: 10.1007\n",
      "Epoch 621/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2256 - val_loss: 9.5548\n",
      "Epoch 622/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.4428 - val_loss: 10.6101\n",
      "Epoch 623/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1469 - val_loss: 10.1737\n",
      "Epoch 624/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4443 - val_loss: 10.9285\n",
      "Epoch 625/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.3966 - val_loss: 10.3081\n",
      "Epoch 626/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2661 - val_loss: 9.9959\n",
      "Epoch 627/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0110 - val_loss: 10.1086\n",
      "Epoch 628/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3008 - val_loss: 9.6886\n",
      "Epoch 629/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.2990 - val_loss: 10.3490\n",
      "Epoch 630/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.2767 - val_loss: 10.3355\n",
      "Epoch 631/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2672 - val_loss: 10.3654\n",
      "Epoch 632/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.4175 - val_loss: 10.1556\n",
      "Epoch 633/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.7745 - val_loss: 9.9981\n",
      "Epoch 634/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2017 - val_loss: 11.1240\n",
      "Epoch 635/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4994 - val_loss: 9.6877\n",
      "Epoch 636/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.7122 - val_loss: 9.8685\n",
      "Epoch 637/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2629 - val_loss: 9.3628\n",
      "Epoch 638/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4128 - val_loss: 10.3431\n",
      "Epoch 639/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3852 - val_loss: 9.5497\n",
      "Epoch 640/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.4152 - val_loss: 10.7097\n",
      "Epoch 641/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3546 - val_loss: 9.5145\n",
      "Epoch 642/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4698 - val_loss: 11.2347\n",
      "Epoch 643/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1498 - val_loss: 10.2125\n",
      "Epoch 644/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.2046 - val_loss: 9.5795\n",
      "Epoch 645/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3488 - val_loss: 10.7385\n",
      "Epoch 646/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4257 - val_loss: 10.0588\n",
      "Epoch 647/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1962 - val_loss: 9.5118\n",
      "Epoch 648/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.4226 - val_loss: 9.9865\n",
      "Epoch 649/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4679 - val_loss: 10.9156\n",
      "Epoch 650/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.2858 - val_loss: 10.9172\n",
      "Epoch 651/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6236 - val_loss: 9.7901\n",
      "Epoch 652/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2253 - val_loss: 9.4115\n",
      "Epoch 653/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1472 - val_loss: 10.7571\n",
      "Epoch 654/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2486 - val_loss: 10.8881\n",
      "Epoch 655/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3739 - val_loss: 9.5835\n",
      "Epoch 656/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3152 - val_loss: 11.7608\n",
      "Epoch 657/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.3056 - val_loss: 9.5849\n",
      "Epoch 658/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5165 - val_loss: 9.7910\n",
      "Epoch 659/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5849 - val_loss: 10.0410\n",
      "Epoch 660/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2345 - val_loss: 10.3372\n",
      "Epoch 661/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2153 - val_loss: 11.7586\n",
      "Epoch 662/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3420 - val_loss: 10.6241\n",
      "Epoch 663/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5634 - val_loss: 10.1659\n",
      "Epoch 664/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3384 - val_loss: 10.0799\n",
      "Epoch 665/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.0807 - val_loss: 10.3030\n",
      "Epoch 666/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.4106 - val_loss: 9.6904\n",
      "Epoch 667/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8527 - val_loss: 9.4513\n",
      "Epoch 668/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2495 - val_loss: 10.7340\n",
      "Epoch 669/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.3092 - val_loss: 9.7568\n",
      "Epoch 670/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0619 - val_loss: 9.5288\n",
      "Epoch 671/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0726 - val_loss: 9.4091\n",
      "Epoch 672/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3191 - val_loss: 9.8370\n",
      "Epoch 673/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2662 - val_loss: 10.1489\n",
      "Epoch 674/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4008 - val_loss: 9.8634\n",
      "Epoch 675/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0555 - val_loss: 9.3649\n",
      "Epoch 676/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3506 - val_loss: 10.4105\n",
      "Epoch 677/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6454 - val_loss: 10.5799\n",
      "Epoch 678/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1556 - val_loss: 10.2557\n",
      "Epoch 679/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1604 - val_loss: 9.3754\n",
      "Epoch 680/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.1829 - val_loss: 11.0577\n",
      "Epoch 681/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2474 - val_loss: 10.1510\n",
      "Epoch 682/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2116 - val_loss: 9.5750\n",
      "Epoch 683/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7425 - val_loss: 13.0513\n",
      "Epoch 684/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.6056 - val_loss: 10.6648\n",
      "Epoch 685/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3518 - val_loss: 10.7213\n",
      "Epoch 686/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.1929 - val_loss: 10.8532\n",
      "Epoch 687/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3582 - val_loss: 12.5146\n",
      "Epoch 688/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3975 - val_loss: 10.4181\n",
      "Epoch 689/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3131 - val_loss: 11.1923\n",
      "Epoch 690/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1742 - val_loss: 10.9889\n",
      "Epoch 691/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3869 - val_loss: 9.4272\n",
      "Epoch 692/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6794 - val_loss: 10.0207\n",
      "Epoch 693/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6668 - val_loss: 11.2243\n",
      "Epoch 694/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4363 - val_loss: 9.4517\n",
      "Epoch 695/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1894 - val_loss: 9.5836\n",
      "Epoch 696/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2392 - val_loss: 10.2227\n",
      "Epoch 697/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4393 - val_loss: 9.3979\n",
      "Epoch 698/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3748 - val_loss: 11.0724\n",
      "Epoch 699/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2668 - val_loss: 9.4946\n",
      "Epoch 700/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3158 - val_loss: 10.0922\n",
      "Epoch 701/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2114 - val_loss: 10.4579\n",
      "Epoch 702/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2466 - val_loss: 9.7421\n",
      "Epoch 703/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.4011 - val_loss: 10.0803\n",
      "Epoch 704/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.6381 - val_loss: 9.5801\n",
      "Epoch 705/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.8544 - val_loss: 9.7825\n",
      "Epoch 706/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5825 - val_loss: 9.3468\n",
      "Epoch 707/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6433 - val_loss: 9.3363\n",
      "Epoch 708/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1657 - val_loss: 10.4603\n",
      "Epoch 709/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.5257 - val_loss: 9.7079\n",
      "Epoch 710/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3577 - val_loss: 9.4240\n",
      "Epoch 711/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2284 - val_loss: 9.2582\n",
      "Epoch 712/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1594 - val_loss: 9.3073\n",
      "Epoch 713/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.9878 - val_loss: 10.0886\n",
      "Epoch 714/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.4589 - val_loss: 9.9662\n",
      "Epoch 715/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7549 - val_loss: 9.9180\n",
      "Epoch 716/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5518 - val_loss: 9.9271\n",
      "Epoch 717/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.0611 - val_loss: 10.3036\n",
      "Epoch 718/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.9728 - val_loss: 10.3225\n",
      "Epoch 719/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.6681 - val_loss: 9.4115\n",
      "Epoch 720/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1211 - val_loss: 9.4355\n",
      "Epoch 721/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2114 - val_loss: 9.7486\n",
      "Epoch 722/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5842 - val_loss: 9.7223\n",
      "Epoch 723/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3774 - val_loss: 9.9373\n",
      "Epoch 724/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2653 - val_loss: 9.3050\n",
      "Epoch 725/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2802 - val_loss: 11.2196\n",
      "Epoch 726/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6771 - val_loss: 9.8232\n",
      "Epoch 727/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3672 - val_loss: 9.9000\n",
      "Epoch 728/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3586 - val_loss: 9.7323\n",
      "Epoch 729/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2412 - val_loss: 9.4624\n",
      "Epoch 730/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.4925 - val_loss: 11.1629\n",
      "Epoch 731/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2716 - val_loss: 10.3591\n",
      "Epoch 732/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2063 - val_loss: 10.6835\n",
      "Epoch 733/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.2559 - val_loss: 10.1304\n",
      "Epoch 734/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.0669 - val_loss: 9.3999\n",
      "Epoch 735/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3395 - val_loss: 10.0120\n",
      "Epoch 736/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.1916 - val_loss: 10.2477\n",
      "Epoch 737/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.5658 - val_loss: 9.7174\n",
      "Epoch 738/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.0538 - val_loss: 9.3009\n",
      "Epoch 739/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0570 - val_loss: 9.5071\n",
      "Epoch 740/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0210 - val_loss: 9.7620\n",
      "Epoch 741/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1786 - val_loss: 9.2591\n",
      "Epoch 742/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.0513 - val_loss: 9.2417\n",
      "Epoch 743/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1390 - val_loss: 10.1916\n",
      "Epoch 744/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.1891 - val_loss: 9.2661\n",
      "Epoch 745/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.2263 - val_loss: 9.3928\n",
      "Epoch 746/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.1472 - val_loss: 9.9285\n",
      "Epoch 747/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.1448 - val_loss: 12.0750\n",
      "Epoch 748/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.2488 - val_loss: 9.5808\n",
      "Epoch 749/1000\n",
      "1052/1052 [==============================] - 0s 111us/step - loss: 8.2937 - val_loss: 9.6129\n",
      "Epoch 750/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2728 - val_loss: 9.6125\n",
      "Epoch 751/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3862 - val_loss: 9.6877\n",
      "Epoch 752/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7033 - val_loss: 9.4924\n",
      "Epoch 753/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.9997 - val_loss: 9.2279\n",
      "Epoch 754/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3131 - val_loss: 10.0120\n",
      "Epoch 755/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7872 - val_loss: 9.2756\n",
      "Epoch 756/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1616 - val_loss: 9.4654\n",
      "Epoch 757/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7840 - val_loss: 11.0467\n",
      "Epoch 758/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2042 - val_loss: 9.2874\n",
      "Epoch 759/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1607 - val_loss: 9.4120\n",
      "Epoch 760/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4009 - val_loss: 9.7778\n",
      "Epoch 761/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.1660 - val_loss: 10.0251\n",
      "Epoch 762/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.9518 - val_loss: 9.3826\n",
      "Epoch 763/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.9999 - val_loss: 10.1818\n",
      "Epoch 764/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6715 - val_loss: 13.2848\n",
      "Epoch 765/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4458 - val_loss: 10.1948\n",
      "Epoch 766/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2833 - val_loss: 13.3327\n",
      "Epoch 767/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3958 - val_loss: 9.5068\n",
      "Epoch 768/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0915 - val_loss: 9.3926\n",
      "Epoch 769/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1510 - val_loss: 9.9698\n",
      "Epoch 770/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.9929 - val_loss: 10.8416\n",
      "Epoch 771/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1694 - val_loss: 9.5007\n",
      "Epoch 772/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2060 - val_loss: 9.3032\n",
      "Epoch 773/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5389 - val_loss: 9.6892\n",
      "Epoch 774/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0219 - val_loss: 10.7805\n",
      "Epoch 775/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3045 - val_loss: 9.6397\n",
      "Epoch 776/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3102 - val_loss: 10.2309\n",
      "Epoch 777/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1694 - val_loss: 9.5247\n",
      "Epoch 778/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5250 - val_loss: 10.9621\n",
      "Epoch 779/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1545 - val_loss: 10.1829\n",
      "Epoch 780/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0134 - val_loss: 9.6452\n",
      "Epoch 781/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1260 - val_loss: 10.2297\n",
      "Epoch 782/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1222 - val_loss: 9.3271\n",
      "Epoch 783/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2009 - val_loss: 10.7201\n",
      "Epoch 784/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6683 - val_loss: 9.7606\n",
      "Epoch 785/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2879 - val_loss: 10.9430\n",
      "Epoch 786/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2836 - val_loss: 10.0071\n",
      "Epoch 787/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.7167 - val_loss: 10.7192\n",
      "Epoch 788/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.2009 - val_loss: 9.7755\n",
      "Epoch 789/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4189 - val_loss: 10.1520\n",
      "Epoch 790/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3311 - val_loss: 10.4312\n",
      "Epoch 791/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2594 - val_loss: 9.0389\n",
      "Epoch 792/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1098 - val_loss: 9.7500\n",
      "Epoch 793/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0826 - val_loss: 9.1892\n",
      "Epoch 794/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1206 - val_loss: 9.3918\n",
      "Epoch 795/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2683 - val_loss: 10.2955\n",
      "Epoch 796/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4838 - val_loss: 9.9421\n",
      "Epoch 797/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.0182 - val_loss: 9.7834\n",
      "Epoch 798/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3374 - val_loss: 9.7837\n",
      "Epoch 799/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3883 - val_loss: 9.3239\n",
      "Epoch 800/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2669 - val_loss: 9.6778\n",
      "Epoch 801/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.2384 - val_loss: 9.4276\n",
      "Epoch 802/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.2011 - val_loss: 9.2184\n",
      "Epoch 803/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2713 - val_loss: 9.6648\n",
      "Epoch 804/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9526 - val_loss: 10.4692\n",
      "Epoch 805/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.2890 - val_loss: 11.9808\n",
      "Epoch 806/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5312 - val_loss: 9.7929\n",
      "Epoch 807/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.2773 - val_loss: 11.5164\n",
      "Epoch 808/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3105 - val_loss: 10.3203\n",
      "Epoch 809/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1947 - val_loss: 10.6279\n",
      "Epoch 810/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.6163 - val_loss: 9.6606\n",
      "Epoch 811/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2270 - val_loss: 9.0980\n",
      "Epoch 812/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2968 - val_loss: 10.2045\n",
      "Epoch 813/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7361 - val_loss: 10.1996\n",
      "Epoch 814/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.2230 - val_loss: 9.1884\n",
      "Epoch 815/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1198 - val_loss: 10.3503\n",
      "Epoch 816/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5051 - val_loss: 9.7805\n",
      "Epoch 817/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4422 - val_loss: 10.8674\n",
      "Epoch 818/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8553 - val_loss: 9.6518\n",
      "Epoch 819/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3262 - val_loss: 9.1312\n",
      "Epoch 820/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0481 - val_loss: 9.4408\n",
      "Epoch 821/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3517 - val_loss: 10.8233\n",
      "Epoch 822/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2718 - val_loss: 10.0813\n",
      "Epoch 823/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3892 - val_loss: 11.0176\n",
      "Epoch 824/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6137 - val_loss: 9.1332\n",
      "Epoch 825/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2417 - val_loss: 9.0923\n",
      "Epoch 826/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1576 - val_loss: 9.7847\n",
      "Epoch 827/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.1163 - val_loss: 11.0568\n",
      "Epoch 828/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5663 - val_loss: 9.8979\n",
      "Epoch 829/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6974 - val_loss: 9.7860\n",
      "Epoch 830/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1902 - val_loss: 10.3110\n",
      "Epoch 831/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2791 - val_loss: 9.3909\n",
      "Epoch 832/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.1208 - val_loss: 12.2364\n",
      "Epoch 833/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7962 - val_loss: 9.6122\n",
      "Epoch 834/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0606 - val_loss: 9.7294\n",
      "Epoch 835/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3577 - val_loss: 9.4776\n",
      "Epoch 836/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2396 - val_loss: 9.7307\n",
      "Epoch 837/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4518 - val_loss: 9.3461\n",
      "Epoch 838/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9369 - val_loss: 9.5616\n",
      "Epoch 839/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3562 - val_loss: 12.1194\n",
      "Epoch 840/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3691 - val_loss: 9.5343\n",
      "Epoch 841/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1654 - val_loss: 9.6565\n",
      "Epoch 842/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0819 - val_loss: 9.4071\n",
      "Epoch 843/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0792 - val_loss: 9.6835\n",
      "Epoch 844/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5267 - val_loss: 9.9873\n",
      "Epoch 845/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7617 - val_loss: 10.0239\n",
      "Epoch 846/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4076 - val_loss: 9.6351\n",
      "Epoch 847/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.9233 - val_loss: 10.2441\n",
      "Epoch 848/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3093 - val_loss: 10.5916\n",
      "Epoch 849/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1299 - val_loss: 9.2999\n",
      "Epoch 850/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3125 - val_loss: 9.3620\n",
      "Epoch 851/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.0350 - val_loss: 9.2176\n",
      "Epoch 852/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.2770 - val_loss: 9.1384\n",
      "Epoch 853/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4845 - val_loss: 9.7415\n",
      "Epoch 854/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.0385 - val_loss: 9.8247\n",
      "Epoch 855/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.3029 - val_loss: 9.7702\n",
      "Epoch 856/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.1273 - val_loss: 10.2454\n",
      "Epoch 857/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3016 - val_loss: 9.8508\n",
      "Epoch 858/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0539 - val_loss: 10.7304\n",
      "Epoch 859/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3321 - val_loss: 10.7377\n",
      "Epoch 860/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0519 - val_loss: 9.2259\n",
      "Epoch 861/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0142 - val_loss: 9.7144\n",
      "Epoch 862/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8230 - val_loss: 8.9958\n",
      "Epoch 863/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2996 - val_loss: 11.2400\n",
      "Epoch 864/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3340 - val_loss: 9.8884\n",
      "Epoch 865/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1593 - val_loss: 10.4878\n",
      "Epoch 866/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4542 - val_loss: 9.1737\n",
      "Epoch 867/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.1700 - val_loss: 13.0059\n",
      "Epoch 868/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4110 - val_loss: 11.9444\n",
      "Epoch 869/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2281 - val_loss: 10.1624\n",
      "Epoch 870/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.4674 - val_loss: 9.1886\n",
      "Epoch 871/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1851 - val_loss: 10.8198\n",
      "Epoch 872/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9980 - val_loss: 9.8411\n",
      "Epoch 873/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.9256 - val_loss: 10.2780\n",
      "Epoch 874/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1354 - val_loss: 11.0618\n",
      "Epoch 875/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5470 - val_loss: 10.6598\n",
      "Epoch 876/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9848 - val_loss: 9.2157\n",
      "Epoch 877/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1453 - val_loss: 10.1831\n",
      "Epoch 878/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7656 - val_loss: 11.1570\n",
      "Epoch 879/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1739 - val_loss: 10.1734\n",
      "Epoch 880/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.0433 - val_loss: 9.3337\n",
      "Epoch 881/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1472 - val_loss: 9.0038\n",
      "Epoch 882/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.0202 - val_loss: 9.3459\n",
      "Epoch 883/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3469 - val_loss: 9.0539\n",
      "Epoch 884/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.2474 - val_loss: 9.7545\n",
      "Epoch 885/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1357 - val_loss: 11.0586\n",
      "Epoch 886/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1935 - val_loss: 10.0899\n",
      "Epoch 887/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3218 - val_loss: 9.0813\n",
      "Epoch 888/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.4933 - val_loss: 9.9199\n",
      "Epoch 889/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.0298 - val_loss: 9.3418\n",
      "Epoch 890/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4601 - val_loss: 10.3850\n",
      "Epoch 891/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3966 - val_loss: 9.2843\n",
      "Epoch 892/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3063 - val_loss: 10.2630\n",
      "Epoch 893/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0459 - val_loss: 9.5173\n",
      "Epoch 894/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.0566 - val_loss: 9.1434\n",
      "Epoch 895/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.9766 - val_loss: 10.6730\n",
      "Epoch 896/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4679 - val_loss: 11.2795\n",
      "Epoch 897/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5065 - val_loss: 9.3782\n",
      "Epoch 898/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2968 - val_loss: 10.7718\n",
      "Epoch 899/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.9887 - val_loss: 10.5682\n",
      "Epoch 900/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.0801 - val_loss: 11.1308\n",
      "Epoch 901/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0116 - val_loss: 9.2057\n",
      "Epoch 902/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6546 - val_loss: 9.3449\n",
      "Epoch 903/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3460 - val_loss: 9.8453\n",
      "Epoch 904/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1612 - val_loss: 9.9048\n",
      "Epoch 905/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.5163 - val_loss: 11.0393\n",
      "Epoch 906/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3768 - val_loss: 9.9819\n",
      "Epoch 907/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3716 - val_loss: 9.9526\n",
      "Epoch 908/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1963 - val_loss: 9.7962\n",
      "Epoch 909/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.9867 - val_loss: 9.0977\n",
      "Epoch 910/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2531 - val_loss: 9.2726\n",
      "Epoch 911/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 8.0439 - val_loss: 10.9594\n",
      "Epoch 912/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.2486 - val_loss: 11.1194\n",
      "Epoch 913/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.1973 - val_loss: 10.5478\n",
      "Epoch 914/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.3439 - val_loss: 11.4754\n",
      "Epoch 915/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.3181 - val_loss: 9.8052\n",
      "Epoch 916/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 8.3332 - val_loss: 9.6293\n",
      "Epoch 917/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.1558 - val_loss: 10.1981\n",
      "Epoch 918/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 8.4510 - val_loss: 10.8143\n",
      "Epoch 919/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.9922 - val_loss: 10.3176\n",
      "Epoch 920/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.2722 - val_loss: 9.5962\n",
      "Epoch 921/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.9169 - val_loss: 9.6702\n",
      "Epoch 922/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.1031 - val_loss: 9.3817\n",
      "Epoch 923/1000\n",
      "1052/1052 [==============================] - 0s 119us/step - loss: 8.1004 - val_loss: 9.4458\n",
      "Epoch 924/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2903 - val_loss: 10.0563\n",
      "Epoch 925/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0494 - val_loss: 10.5990\n",
      "Epoch 926/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4398 - val_loss: 8.9692\n",
      "Epoch 927/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.9809 - val_loss: 9.2829\n",
      "Epoch 928/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.0179 - val_loss: 9.2654\n",
      "Epoch 929/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5202 - val_loss: 9.8500\n",
      "Epoch 930/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1540 - val_loss: 10.2427\n",
      "Epoch 931/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3528 - val_loss: 10.2022\n",
      "Epoch 932/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5524 - val_loss: 9.6556\n",
      "Epoch 933/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2254 - val_loss: 11.8380\n",
      "Epoch 934/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.2983 - val_loss: 9.7322\n",
      "Epoch 935/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0023 - val_loss: 9.2732\n",
      "Epoch 936/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0489 - val_loss: 9.5837\n",
      "Epoch 937/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.4197 - val_loss: 9.2176\n",
      "Epoch 938/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.5534 - val_loss: 9.9223\n",
      "Epoch 939/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.1345 - val_loss: 9.8210\n",
      "Epoch 940/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.9070 - val_loss: 9.1878\n",
      "Epoch 941/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1865 - val_loss: 10.5202\n",
      "Epoch 942/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3348 - val_loss: 9.9843\n",
      "Epoch 943/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.0140 - val_loss: 10.1159\n",
      "Epoch 944/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.9802 - val_loss: 9.3125\n",
      "Epoch 945/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2972 - val_loss: 9.7977\n",
      "Epoch 946/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1259 - val_loss: 9.6347\n",
      "Epoch 947/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1242 - val_loss: 9.6377\n",
      "Epoch 948/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4128 - val_loss: 9.5889\n",
      "Epoch 949/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3101 - val_loss: 10.8717\n",
      "Epoch 950/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4739 - val_loss: 9.3232\n",
      "Epoch 951/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3989 - val_loss: 9.7325\n",
      "Epoch 952/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.9280 - val_loss: 10.8436\n",
      "Epoch 953/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2838 - val_loss: 9.2855\n",
      "Epoch 954/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1800 - val_loss: 9.9607\n",
      "Epoch 955/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0113 - val_loss: 11.0005\n",
      "Epoch 956/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.0771 - val_loss: 9.2427\n",
      "Epoch 957/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1109 - val_loss: 9.5895\n",
      "Epoch 958/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5687 - val_loss: 9.6677\n",
      "Epoch 959/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1809 - val_loss: 9.2143\n",
      "Epoch 960/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7082 - val_loss: 9.5917\n",
      "Epoch 961/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5968 - val_loss: 9.9867\n",
      "Epoch 962/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1150 - val_loss: 10.7755\n",
      "Epoch 963/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.2956 - val_loss: 8.9702\n",
      "Epoch 964/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4527 - val_loss: 9.2944\n",
      "Epoch 965/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.1457 - val_loss: 9.3211\n",
      "Epoch 966/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1563 - val_loss: 9.2671\n",
      "Epoch 967/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1371 - val_loss: 10.0091\n",
      "Epoch 968/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9124 - val_loss: 10.4154\n",
      "Epoch 969/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1349 - val_loss: 10.0477\n",
      "Epoch 970/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2768 - val_loss: 9.3655\n",
      "Epoch 971/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.2863 - val_loss: 10.8218\n",
      "Epoch 972/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7846 - val_loss: 10.6231\n",
      "Epoch 973/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3537 - val_loss: 9.6327\n",
      "Epoch 974/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2696 - val_loss: 9.7711\n",
      "Epoch 975/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2722 - val_loss: 9.1773\n",
      "Epoch 976/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9821 - val_loss: 9.5210\n",
      "Epoch 977/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2838 - val_loss: 9.9615\n",
      "Epoch 978/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5899 - val_loss: 8.9906\n",
      "Epoch 979/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0543 - val_loss: 8.9369\n",
      "Epoch 980/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1631 - val_loss: 9.8080\n",
      "Epoch 981/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.0742 - val_loss: 9.8251\n",
      "Epoch 982/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4132 - val_loss: 9.9249\n",
      "Epoch 983/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.9799 - val_loss: 9.1558\n",
      "Epoch 984/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9895 - val_loss: 9.7419\n",
      "Epoch 985/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2153 - val_loss: 9.3626\n",
      "Epoch 986/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2436 - val_loss: 9.5531\n",
      "Epoch 987/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3818 - val_loss: 9.1757\n",
      "Epoch 988/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2098 - val_loss: 10.7327\n",
      "Epoch 989/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9695 - val_loss: 9.1749\n",
      "Epoch 990/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0435 - val_loss: 9.3953\n",
      "Epoch 991/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1533 - val_loss: 9.0282\n",
      "Epoch 992/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.1143 - val_loss: 9.1161\n",
      "Epoch 993/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.1365 - val_loss: 9.5036\n",
      "Epoch 994/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0339 - val_loss: 9.4392\n",
      "Epoch 995/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1509 - val_loss: 9.2528\n",
      "Epoch 996/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2549 - val_loss: 9.4472\n",
      "Epoch 997/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6514 - val_loss: 9.6530\n",
      "Epoch 998/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1388 - val_loss: 10.3061\n",
      "Epoch 999/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1072 - val_loss: 9.2417\n",
      "Epoch 1000/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3266 - val_loss: 11.1222\n",
      "8.754665066710615\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.68602866, -3.135599  , -0.16234018, -1.7945377 ,  4.101883  ],\n",
       "        [-1.3956003 ,  0.08365555, -0.20418075,  0.48436937, -0.23398285],\n",
       "        [-1.5491245 , -0.02433117, -0.2863726 ,  0.42261127,  0.7450873 ],\n",
       "        [ 0.26079416,  0.06222427,  0.126999  ,  0.03821959, -0.15199816],\n",
       "        [ 0.24986778, -2.3047254 , -0.18715408, -0.31507376,  0.3466104 ]],\n",
       "       dtype=float32),\n",
       " array([-0.6757135, -4.704725 ,  1.4873314, -1.2968112,  4.9995384],\n",
       "       dtype=float32),\n",
       " array([[-0.5912905 ,  0.9639903 ,  0.86775905, -0.18733127, -0.1524617 ],\n",
       "        [ 2.0874176 , -2.7747774 , -3.0484421 ,  2.0541475 , -2.9543111 ],\n",
       "        [-2.8790624 ,  1.9575367 ,  2.8257475 , -2.3929565 ,  2.4055622 ],\n",
       "        [-1.2688606 ,  0.41023287,  0.97238207, -0.63373667,  0.77693576],\n",
       "        [-2.1403685 ,  3.027027  ,  2.1291656 , -2.964412  ,  2.6085274 ]],\n",
       "       dtype=float32),\n",
       " array([-2.3099806,  2.3472826,  2.4673135, -2.244411 ,  2.2594266],\n",
       "       dtype=float32),\n",
       " array([[-2.585063 ],\n",
       "        [ 2.6480193],\n",
       "        [ 2.2933774],\n",
       "        [-3.1322324],\n",
       "        [ 2.9984777]], dtype=float32),\n",
       " array([2.0959537], dtype=float32)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_airfoil, history_airfoil, evaluate_airfoil=NN_model_structure_regression_1(X_train_airfoil, X_val_airfoil, Y_train_airfoil, Y_val_airfoil, adam2, 32, 1000, x_test_airfoil, y_test_airfoil)\n",
    "model_airfoil.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_airfoil.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_airfoil_structure1_4th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 101\n",
      "Trainable params: 101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1052 samples, validate on 225 samples\n",
      "Epoch 1/1000\n",
      "1052/1052 [==============================] - 0s 195us/step - loss: 8086.5213 - val_loss: 894.1624\n",
      "Epoch 2/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 193.2029 - val_loss: 71.3085\n",
      "Epoch 3/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 44.5522 - val_loss: 32.6586\n",
      "Epoch 4/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 33.6678 - val_loss: 29.9826\n",
      "Epoch 5/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 30.9145 - val_loss: 29.5709\n",
      "Epoch 6/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 29.0736 - val_loss: 28.2726\n",
      "Epoch 7/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 27.8700 - val_loss: 27.7943\n",
      "Epoch 8/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 27.1221 - val_loss: 27.9666\n",
      "Epoch 9/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 26.6448 - val_loss: 28.1664\n",
      "Epoch 10/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 26.0737 - val_loss: 27.2698\n",
      "Epoch 11/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 26.1055 - val_loss: 27.6556\n",
      "Epoch 12/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 25.3204 - val_loss: 27.2504\n",
      "Epoch 13/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 24.8707 - val_loss: 27.5950\n",
      "Epoch 14/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 24.8701 - val_loss: 27.2673\n",
      "Epoch 15/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 24.1680 - val_loss: 26.6896\n",
      "Epoch 16/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 23.8334 - val_loss: 27.0522\n",
      "Epoch 17/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 23.2539 - val_loss: 26.7608\n",
      "Epoch 18/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.4623 - val_loss: 27.3584\n",
      "Epoch 19/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.9891 - val_loss: 26.4364\n",
      "Epoch 20/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 21.4918 - val_loss: 26.6024\n",
      "Epoch 21/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 20.9629 - val_loss: 26.4574\n",
      "Epoch 22/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 20.5877 - val_loss: 26.1712\n",
      "Epoch 23/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 20.1773 - val_loss: 25.4091\n",
      "Epoch 24/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 19.9529 - val_loss: 25.2232\n",
      "Epoch 25/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 19.8405 - val_loss: 25.5938\n",
      "Epoch 26/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 19.3656 - val_loss: 24.7011\n",
      "Epoch 27/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 19.0295 - val_loss: 25.3570\n",
      "Epoch 28/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 19.2350 - val_loss: 25.3048\n",
      "Epoch 29/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 19.1381 - val_loss: 24.4566\n",
      "Epoch 30/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.5287 - val_loss: 24.5603\n",
      "Epoch 31/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.3977 - val_loss: 24.6463\n",
      "Epoch 32/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.4695 - val_loss: 24.2959\n",
      "Epoch 33/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.3174 - val_loss: 24.1990\n",
      "Epoch 34/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 18.1695 - val_loss: 24.0024\n",
      "Epoch 35/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 18.0636 - val_loss: 24.1233\n",
      "Epoch 36/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.9056 - val_loss: 23.9536\n",
      "Epoch 37/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.8293 - val_loss: 23.5124\n",
      "Epoch 38/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.6857 - val_loss: 22.8823\n",
      "Epoch 39/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.6325 - val_loss: 23.0208\n",
      "Epoch 40/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.4970 - val_loss: 22.8098\n",
      "Epoch 41/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.3999 - val_loss: 22.1859\n",
      "Epoch 42/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.6127 - val_loss: 22.2382\n",
      "Epoch 43/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.3021 - val_loss: 22.3052\n",
      "Epoch 44/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.0929 - val_loss: 22.5652\n",
      "Epoch 45/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.1313 - val_loss: 21.9987\n",
      "Epoch 46/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 16.9230 - val_loss: 22.1144\n",
      "Epoch 47/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.1172 - val_loss: 21.8152\n",
      "Epoch 48/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 16.7824 - val_loss: 22.3847\n",
      "Epoch 49/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 16.8044 - val_loss: 21.8426\n",
      "Epoch 50/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 16.6850 - val_loss: 21.5214\n",
      "Epoch 51/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 16.7735 - val_loss: 21.0751\n",
      "Epoch 52/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 16.8951 - val_loss: 21.3514\n",
      "Epoch 53/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 16.5499 - val_loss: 20.6183\n",
      "Epoch 54/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 16.3233 - val_loss: 20.4392\n",
      "Epoch 55/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 16.2351 - val_loss: 20.0005\n",
      "Epoch 56/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 16.2415 - val_loss: 20.0467\n",
      "Epoch 57/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 16.2974 - val_loss: 19.7703\n",
      "Epoch 58/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 16.1166 - val_loss: 19.5412\n",
      "Epoch 59/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 16.1076 - val_loss: 20.4589\n",
      "Epoch 60/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 15.9779 - val_loss: 19.5324\n",
      "Epoch 61/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 15.8900 - val_loss: 19.6760\n",
      "Epoch 62/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 15.9180 - val_loss: 19.7682\n",
      "Epoch 63/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 15.8595 - val_loss: 18.8753\n",
      "Epoch 64/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 15.6904 - val_loss: 19.9764\n",
      "Epoch 65/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 15.6587 - val_loss: 19.2782\n",
      "Epoch 66/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 15.5324 - val_loss: 19.7230\n",
      "Epoch 67/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 85us/step - loss: 15.7471 - val_loss: 18.2393\n",
      "Epoch 68/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 15.4787 - val_loss: 18.5063\n",
      "Epoch 69/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 15.3653 - val_loss: 19.0901\n",
      "Epoch 70/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 15.1842 - val_loss: 18.7734\n",
      "Epoch 71/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 15.3267 - val_loss: 18.0495\n",
      "Epoch 72/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 15.3618 - val_loss: 18.2890\n",
      "Epoch 73/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 15.1271 - val_loss: 18.4169\n",
      "Epoch 74/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 15.2676 - val_loss: 19.0929\n",
      "Epoch 75/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 14.9066 - val_loss: 17.5339\n",
      "Epoch 76/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.8854 - val_loss: 17.6971\n",
      "Epoch 77/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 15.0123 - val_loss: 17.7268\n",
      "Epoch 78/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 14.8935 - val_loss: 18.0295\n",
      "Epoch 79/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 15.1918 - val_loss: 17.5241\n",
      "Epoch 80/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.7288 - val_loss: 17.1924\n",
      "Epoch 81/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.8350 - val_loss: 17.3372\n",
      "Epoch 82/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 14.5617 - val_loss: 17.8554\n",
      "Epoch 83/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 14.5008 - val_loss: 17.0347\n",
      "Epoch 84/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 14.6481 - val_loss: 17.4397\n",
      "Epoch 85/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 14.3142 - val_loss: 17.3765\n",
      "Epoch 86/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 15.0934 - val_loss: 17.8116\n",
      "Epoch 87/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 15.2027 - val_loss: 20.4006\n",
      "Epoch 88/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.5955 - val_loss: 17.0362\n",
      "Epoch 89/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.2165 - val_loss: 17.0204\n",
      "Epoch 90/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 14.2214 - val_loss: 16.7868\n",
      "Epoch 91/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.6468 - val_loss: 18.3247\n",
      "Epoch 92/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.0051 - val_loss: 17.8014\n",
      "Epoch 93/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.5798 - val_loss: 19.5293\n",
      "Epoch 94/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.2534 - val_loss: 20.5384\n",
      "Epoch 95/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 14.2996 - val_loss: 18.0804\n",
      "Epoch 96/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 14.2243 - val_loss: 16.6086\n",
      "Epoch 97/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.9840 - val_loss: 16.3551\n",
      "Epoch 98/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 13.6698 - val_loss: 17.0323\n",
      "Epoch 99/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 13.4715 - val_loss: 15.9499\n",
      "Epoch 100/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 13.4202 - val_loss: 16.6977\n",
      "Epoch 101/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 13.4210 - val_loss: 16.7670\n",
      "Epoch 102/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.1665 - val_loss: 15.6380\n",
      "Epoch 103/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 13.4785 - val_loss: 16.1540\n",
      "Epoch 104/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.8870 - val_loss: 16.9197\n",
      "Epoch 105/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.3964 - val_loss: 17.4535\n",
      "Epoch 106/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.0246 - val_loss: 16.8648\n",
      "Epoch 107/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.3036 - val_loss: 17.3343\n",
      "Epoch 108/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.9408 - val_loss: 16.2907\n",
      "Epoch 109/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.6862 - val_loss: 16.5207\n",
      "Epoch 110/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 12.7886 - val_loss: 15.3518\n",
      "Epoch 111/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.9595 - val_loss: 16.2831\n",
      "Epoch 112/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.8622 - val_loss: 21.5949\n",
      "Epoch 113/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.5309 - val_loss: 21.0412\n",
      "Epoch 114/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.4710 - val_loss: 18.7565\n",
      "Epoch 115/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.5930 - val_loss: 15.5746\n",
      "Epoch 116/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.3625 - val_loss: 15.9916\n",
      "Epoch 117/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.4508 - val_loss: 16.6645\n",
      "Epoch 118/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.5670 - val_loss: 15.7790\n",
      "Epoch 119/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.2724 - val_loss: 16.7741\n",
      "Epoch 120/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.4252 - val_loss: 15.2147\n",
      "Epoch 121/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 12.0906 - val_loss: 15.2158\n",
      "Epoch 122/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.4988 - val_loss: 14.8977\n",
      "Epoch 123/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.5509 - val_loss: 15.4132\n",
      "Epoch 124/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.8924 - val_loss: 15.6243\n",
      "Epoch 125/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.8280 - val_loss: 15.4130\n",
      "Epoch 126/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.1837 - val_loss: 16.3191\n",
      "Epoch 127/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.6430 - val_loss: 13.5838\n",
      "Epoch 128/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.0020 - val_loss: 15.5509\n",
      "Epoch 129/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.4315 - val_loss: 13.6726\n",
      "Epoch 130/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.6478 - val_loss: 14.2167\n",
      "Epoch 131/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.5385 - val_loss: 13.8855\n",
      "Epoch 132/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 11.6748 - val_loss: 14.5887\n",
      "Epoch 133/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.2630 - val_loss: 14.7400\n",
      "Epoch 134/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 11.2225 - val_loss: 16.8136\n",
      "Epoch 135/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.9310 - val_loss: 16.3605\n",
      "Epoch 136/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.8005 - val_loss: 14.6491\n",
      "Epoch 137/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.2438 - val_loss: 12.9137\n",
      "Epoch 138/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.3752 - val_loss: 14.7573\n",
      "Epoch 139/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.0138 - val_loss: 14.3137\n",
      "Epoch 140/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.5614 - val_loss: 14.1566\n",
      "Epoch 141/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.3020 - val_loss: 13.8581\n",
      "Epoch 142/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.6484 - val_loss: 12.9908\n",
      "Epoch 143/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.4779 - val_loss: 15.9037\n",
      "Epoch 144/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.7216 - val_loss: 13.2426\n",
      "Epoch 145/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.3813 - val_loss: 12.4448\n",
      "Epoch 146/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.7859 - val_loss: 14.3341\n",
      "Epoch 147/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.7288 - val_loss: 15.0543\n",
      "Epoch 148/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.9901 - val_loss: 13.5901\n",
      "Epoch 149/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.6112 - val_loss: 13.1740\n",
      "Epoch 150/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.3807 - val_loss: 12.9334\n",
      "Epoch 151/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.1780 - val_loss: 13.0418\n",
      "Epoch 152/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.1593 - val_loss: 12.1459\n",
      "Epoch 153/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.7305 - val_loss: 14.3310\n",
      "Epoch 154/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.7544 - val_loss: 12.9916\n",
      "Epoch 155/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.9126 - val_loss: 13.0389\n",
      "Epoch 156/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.3866 - val_loss: 12.3198\n",
      "Epoch 157/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.4436 - val_loss: 13.4394\n",
      "Epoch 158/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.2784 - val_loss: 12.8978\n",
      "Epoch 159/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.0778 - val_loss: 14.3349\n",
      "Epoch 160/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.6433 - val_loss: 12.9758\n",
      "Epoch 161/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.6406 - val_loss: 12.9249\n",
      "Epoch 162/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.0712 - val_loss: 13.4025\n",
      "Epoch 163/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.9452 - val_loss: 13.0978\n",
      "Epoch 164/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.3902 - val_loss: 12.7173\n",
      "Epoch 165/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.2984 - val_loss: 11.8128\n",
      "Epoch 166/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.0877 - val_loss: 12.3874\n",
      "Epoch 167/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.8919 - val_loss: 13.5968\n",
      "Epoch 168/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.8511 - val_loss: 12.0472\n",
      "Epoch 169/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.6431 - val_loss: 11.7997\n",
      "Epoch 170/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.7910 - val_loss: 13.3231\n",
      "Epoch 171/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.7645 - val_loss: 11.8946\n",
      "Epoch 172/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.9416 - val_loss: 12.7240\n",
      "Epoch 173/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.5474 - val_loss: 14.7123\n",
      "Epoch 174/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.7979 - val_loss: 12.0003\n",
      "Epoch 175/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.4865 - val_loss: 12.1536\n",
      "Epoch 176/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.4485 - val_loss: 13.1745\n",
      "Epoch 177/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.0646 - val_loss: 12.0630\n",
      "Epoch 178/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.8424 - val_loss: 11.5744\n",
      "Epoch 179/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.2029 - val_loss: 13.1412\n",
      "Epoch 180/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.6939 - val_loss: 11.8982\n",
      "Epoch 181/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.7035 - val_loss: 13.0680\n",
      "Epoch 182/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.4663 - val_loss: 11.5341\n",
      "Epoch 183/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.4317 - val_loss: 11.4868\n",
      "Epoch 184/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.9545 - val_loss: 11.8865\n",
      "Epoch 185/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.8723 - val_loss: 13.2843\n",
      "Epoch 186/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.6399 - val_loss: 11.9238\n",
      "Epoch 187/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.2249 - val_loss: 11.8133\n",
      "Epoch 188/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.6089 - val_loss: 12.2382\n",
      "Epoch 189/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.4786 - val_loss: 12.3947\n",
      "Epoch 190/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.6880 - val_loss: 11.0782\n",
      "Epoch 191/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.4957 - val_loss: 12.0483\n",
      "Epoch 192/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.5834 - val_loss: 11.8768\n",
      "Epoch 193/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.5416 - val_loss: 13.3075\n",
      "Epoch 194/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.0968 - val_loss: 11.9849\n",
      "Epoch 195/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.3753 - val_loss: 11.9433\n",
      "Epoch 196/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.9442 - val_loss: 12.2943\n",
      "Epoch 197/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.5489 - val_loss: 12.2968\n",
      "Epoch 198/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.1117 - val_loss: 12.1659\n",
      "Epoch 199/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.3004 - val_loss: 13.1665\n",
      "Epoch 200/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.5828 - val_loss: 11.4535\n",
      "Epoch 201/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.3353 - val_loss: 11.1010\n",
      "Epoch 202/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.4006 - val_loss: 11.2933\n",
      "Epoch 203/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.3565 - val_loss: 12.1072\n",
      "Epoch 204/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.8913 - val_loss: 12.0124\n",
      "Epoch 205/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.4625 - val_loss: 11.2437\n",
      "Epoch 206/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.3655 - val_loss: 12.5039\n",
      "Epoch 207/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.0968 - val_loss: 11.0348\n",
      "Epoch 208/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.8345 - val_loss: 12.1953\n",
      "Epoch 209/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.1941 - val_loss: 12.0022\n",
      "Epoch 210/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.3473 - val_loss: 11.3343\n",
      "Epoch 211/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2591 - val_loss: 10.9928\n",
      "Epoch 212/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2715 - val_loss: 11.0546\n",
      "Epoch 213/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.4186 - val_loss: 11.2953\n",
      "Epoch 214/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.3796 - val_loss: 11.6275\n",
      "Epoch 215/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.3347 - val_loss: 11.9272\n",
      "Epoch 216/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.3703 - val_loss: 12.3469\n",
      "Epoch 217/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.5178 - val_loss: 11.4973\n",
      "Epoch 218/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.4480 - val_loss: 13.2823\n",
      "Epoch 219/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.5618 - val_loss: 10.9608\n",
      "Epoch 220/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.4135 - val_loss: 11.0736\n",
      "Epoch 221/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.1300 - val_loss: 13.5150\n",
      "Epoch 222/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.0814 - val_loss: 11.5033\n",
      "Epoch 223/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.5330 - val_loss: 11.4459\n",
      "Epoch 224/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.3754 - val_loss: 12.2857\n",
      "Epoch 225/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.5458 - val_loss: 15.6748\n",
      "Epoch 226/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.9716 - val_loss: 11.9984\n",
      "Epoch 227/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.9085 - val_loss: 15.9980\n",
      "Epoch 228/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.2530 - val_loss: 12.2780\n",
      "Epoch 229/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.6688 - val_loss: 11.7322\n",
      "Epoch 230/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.3077 - val_loss: 13.1213\n",
      "Epoch 231/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.2968 - val_loss: 11.6482\n",
      "Epoch 232/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1829 - val_loss: 11.6215\n",
      "Epoch 233/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.1509 - val_loss: 11.4122\n",
      "Epoch 234/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.2422 - val_loss: 16.5942\n",
      "Epoch 235/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.5792 - val_loss: 11.1135\n",
      "Epoch 236/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.2786 - val_loss: 11.4621\n",
      "Epoch 237/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0914 - val_loss: 11.0164\n",
      "Epoch 238/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.5559 - val_loss: 12.6571\n",
      "Epoch 239/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.0634 - val_loss: 11.6672\n",
      "Epoch 240/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9770 - val_loss: 10.9670\n",
      "Epoch 241/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.5638 - val_loss: 11.4218\n",
      "Epoch 242/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.1537 - val_loss: 11.2661\n",
      "Epoch 243/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 9.5617 - val_loss: 11.4134\n",
      "Epoch 244/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 9.5529 - val_loss: 11.5078\n",
      "Epoch 245/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.5157 - val_loss: 11.6687\n",
      "Epoch 246/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.0150 - val_loss: 11.0160\n",
      "Epoch 247/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0846 - val_loss: 11.4647\n",
      "Epoch 248/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 9.3790 - val_loss: 11.2050\n",
      "Epoch 249/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 9.4369 - val_loss: 11.2281\n",
      "Epoch 250/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.5522 - val_loss: 15.0605\n",
      "Epoch 251/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.1650 - val_loss: 10.9753\n",
      "Epoch 252/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 9.4843 - val_loss: 10.9668\n",
      "Epoch 253/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 8.9008 - val_loss: 11.9699\n",
      "Epoch 254/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.2246 - val_loss: 11.2782\n",
      "Epoch 255/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.3689 - val_loss: 12.1935\n",
      "Epoch 256/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.3225 - val_loss: 11.6505\n",
      "Epoch 257/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1185 - val_loss: 11.7003\n",
      "Epoch 258/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2133 - val_loss: 11.8812\n",
      "Epoch 259/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.4921 - val_loss: 12.1170\n",
      "Epoch 260/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2619 - val_loss: 11.5854\n",
      "Epoch 261/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.4541 - val_loss: 11.2613\n",
      "Epoch 262/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9701 - val_loss: 12.0179\n",
      "Epoch 263/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.2857 - val_loss: 11.4733\n",
      "Epoch 264/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.4447 - val_loss: 11.3794\n",
      "Epoch 265/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2941 - val_loss: 11.4509\n",
      "Epoch 266/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.4586 - val_loss: 11.3396\n",
      "Epoch 267/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.3352 - val_loss: 10.9635\n",
      "Epoch 268/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.3462 - val_loss: 11.1282\n",
      "Epoch 269/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.1418 - val_loss: 11.4611\n",
      "Epoch 270/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.1520 - val_loss: 12.2464\n",
      "Epoch 271/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.7340 - val_loss: 12.0424\n",
      "Epoch 272/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.3022 - val_loss: 15.3007\n",
      "Epoch 273/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.5872 - val_loss: 13.1267\n",
      "Epoch 274/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.4996 - val_loss: 12.1085\n",
      "Epoch 275/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.8506 - val_loss: 12.1117\n",
      "Epoch 276/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2492 - val_loss: 11.1459\n",
      "Epoch 277/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.9146 - val_loss: 11.7740\n",
      "Epoch 278/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.3558 - val_loss: 11.0827\n",
      "Epoch 279/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.6518 - val_loss: 11.0514\n",
      "Epoch 280/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.6133 - val_loss: 12.1911\n",
      "Epoch 281/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.5600 - val_loss: 12.6027\n",
      "Epoch 282/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.7222 - val_loss: 10.8051\n",
      "Epoch 283/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.2967 - val_loss: 12.2484\n",
      "Epoch 284/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.4048 - val_loss: 11.3430\n",
      "Epoch 285/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9794 - val_loss: 11.4924\n",
      "Epoch 286/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.4079 - val_loss: 13.2117\n",
      "Epoch 287/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.1275 - val_loss: 11.5132\n",
      "Epoch 288/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2874 - val_loss: 10.8784\n",
      "Epoch 289/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.9761 - val_loss: 11.2786\n",
      "Epoch 290/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1424 - val_loss: 11.8384\n",
      "Epoch 291/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0461 - val_loss: 11.1865\n",
      "Epoch 292/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8827 - val_loss: 11.7254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 293/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9102 - val_loss: 11.2765\n",
      "Epoch 294/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1810 - val_loss: 11.1563\n",
      "Epoch 295/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.4448 - val_loss: 11.2215\n",
      "Epoch 296/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.1650 - val_loss: 11.7158\n",
      "Epoch 297/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.9375 - val_loss: 11.5928\n",
      "Epoch 298/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2763 - val_loss: 11.2640\n",
      "Epoch 299/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.6485 - val_loss: 12.0461\n",
      "Epoch 300/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.7013 - val_loss: 11.2425\n",
      "Epoch 301/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9811 - val_loss: 11.4360\n",
      "Epoch 302/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9930 - val_loss: 11.7074\n",
      "Epoch 303/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.8302 - val_loss: 11.1596\n",
      "Epoch 304/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1166 - val_loss: 11.5232\n",
      "Epoch 305/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.7200 - val_loss: 14.8525\n",
      "Epoch 306/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.3374 - val_loss: 11.2884\n",
      "Epoch 307/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 10.1497 - val_loss: 12.4309\n",
      "Epoch 308/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.4790 - val_loss: 11.7944\n",
      "Epoch 309/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1061 - val_loss: 12.5479\n",
      "Epoch 310/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.4823 - val_loss: 11.1914\n",
      "Epoch 311/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1575 - val_loss: 11.6507\n",
      "Epoch 312/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.3000 - val_loss: 12.5362\n",
      "Epoch 313/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2820 - val_loss: 11.1175\n",
      "Epoch 314/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.7959 - val_loss: 11.3335\n",
      "Epoch 315/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.0637 - val_loss: 12.0651\n",
      "Epoch 316/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.8217 - val_loss: 11.1197\n",
      "Epoch 317/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9446 - val_loss: 11.4606\n",
      "Epoch 318/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0977 - val_loss: 13.6178\n",
      "Epoch 319/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1416 - val_loss: 12.1450\n",
      "Epoch 320/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1296 - val_loss: 11.2383\n",
      "Epoch 321/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.7866 - val_loss: 11.5722\n",
      "Epoch 322/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7516 - val_loss: 11.6186\n",
      "Epoch 323/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.9553 - val_loss: 11.1931\n",
      "Epoch 324/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.0730 - val_loss: 11.7439\n",
      "Epoch 325/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.8411 - val_loss: 11.0185\n",
      "Epoch 326/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2974 - val_loss: 11.8732\n",
      "Epoch 327/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7909 - val_loss: 11.4284\n",
      "Epoch 328/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2623 - val_loss: 11.2711\n",
      "Epoch 329/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.5131 - val_loss: 12.6855\n",
      "Epoch 330/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9995 - val_loss: 11.2557\n",
      "Epoch 331/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.5099 - val_loss: 12.2172\n",
      "Epoch 332/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1767 - val_loss: 14.1598\n",
      "Epoch 333/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.3719 - val_loss: 11.2187\n",
      "Epoch 334/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.6034 - val_loss: 10.9837\n",
      "Epoch 335/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8002 - val_loss: 11.3381\n",
      "Epoch 336/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2458 - val_loss: 10.8765\n",
      "Epoch 337/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9886 - val_loss: 13.7917\n",
      "Epoch 338/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.0032 - val_loss: 11.2367\n",
      "Epoch 339/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9459 - val_loss: 11.0997\n",
      "Epoch 340/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.8619 - val_loss: 14.4273\n",
      "Epoch 341/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.3273 - val_loss: 12.3113\n",
      "Epoch 342/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.5119 - val_loss: 11.4568\n",
      "Epoch 343/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1256 - val_loss: 12.3976\n",
      "Epoch 344/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9208 - val_loss: 10.7724\n",
      "Epoch 345/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0247 - val_loss: 11.1187\n",
      "Epoch 346/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.4568 - val_loss: 11.1234\n",
      "Epoch 347/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.7809 - val_loss: 10.8275\n",
      "Epoch 348/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7215 - val_loss: 11.1265\n",
      "Epoch 349/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7543 - val_loss: 11.0051\n",
      "Epoch 350/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0859 - val_loss: 11.2933\n",
      "Epoch 351/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8385 - val_loss: 11.7630\n",
      "Epoch 352/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1513 - val_loss: 11.5483\n",
      "Epoch 353/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9244 - val_loss: 10.7522\n",
      "Epoch 354/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0079 - val_loss: 12.7690\n",
      "Epoch 355/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9312 - val_loss: 11.6997\n",
      "Epoch 356/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.7723 - val_loss: 11.0095\n",
      "Epoch 357/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.5540 - val_loss: 11.1251\n",
      "Epoch 358/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.3200 - val_loss: 12.3130\n",
      "Epoch 359/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.8274 - val_loss: 11.0176\n",
      "Epoch 360/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9669 - val_loss: 10.8285\n",
      "Epoch 361/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8286 - val_loss: 11.3971\n",
      "Epoch 362/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0352 - val_loss: 10.7533\n",
      "Epoch 363/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9064 - val_loss: 11.1486\n",
      "Epoch 364/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7981 - val_loss: 12.1072\n",
      "Epoch 365/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.8694 - val_loss: 11.3824\n",
      "Epoch 366/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6531 - val_loss: 10.4750\n",
      "Epoch 367/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6834 - val_loss: 11.2481\n",
      "Epoch 368/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6772 - val_loss: 11.1232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 369/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7494 - val_loss: 10.6569\n",
      "Epoch 370/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8113 - val_loss: 11.4510\n",
      "Epoch 371/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.9199 - val_loss: 11.9405\n",
      "Epoch 372/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.6021 - val_loss: 10.9215\n",
      "Epoch 373/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9615 - val_loss: 10.5644\n",
      "Epoch 374/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.7052 - val_loss: 11.2154\n",
      "Epoch 375/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7115 - val_loss: 10.4234\n",
      "Epoch 376/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6890 - val_loss: 10.7421\n",
      "Epoch 377/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.5372 - val_loss: 11.9791\n",
      "Epoch 378/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6922 - val_loss: 10.8290\n",
      "Epoch 379/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.2011 - val_loss: 11.0279\n",
      "Epoch 380/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.8412 - val_loss: 10.8704\n",
      "Epoch 381/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.8381 - val_loss: 10.4699\n",
      "Epoch 382/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.6266 - val_loss: 10.5658\n",
      "Epoch 383/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5517 - val_loss: 10.3554\n",
      "Epoch 384/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5527 - val_loss: 10.4979\n",
      "Epoch 385/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4686 - val_loss: 11.3147\n",
      "Epoch 386/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9378 - val_loss: 11.4744\n",
      "Epoch 387/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.1278 - val_loss: 13.6628\n",
      "Epoch 388/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8219 - val_loss: 11.4438\n",
      "Epoch 389/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9623 - val_loss: 10.4771\n",
      "Epoch 390/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9788 - val_loss: 11.0582\n",
      "Epoch 391/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.2721 - val_loss: 12.3335\n",
      "Epoch 392/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7537 - val_loss: 13.4273\n",
      "Epoch 393/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1124 - val_loss: 10.5017\n",
      "Epoch 394/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6713 - val_loss: 12.6153\n",
      "Epoch 395/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.8164 - val_loss: 10.4979\n",
      "Epoch 396/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.9663 - val_loss: 11.0623\n",
      "Epoch 397/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8200 - val_loss: 10.5933\n",
      "Epoch 398/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5765 - val_loss: 11.3920\n",
      "Epoch 399/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.3725 - val_loss: 10.2621\n",
      "Epoch 400/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.3670 - val_loss: 12.8023\n",
      "Epoch 401/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8892 - val_loss: 10.8887\n",
      "Epoch 402/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.0442 - val_loss: 11.4268\n",
      "Epoch 403/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5442 - val_loss: 11.5682\n",
      "Epoch 404/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9484 - val_loss: 10.3659\n",
      "Epoch 405/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.8731 - val_loss: 10.6797\n",
      "Epoch 406/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.4600 - val_loss: 11.7518\n",
      "Epoch 407/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1946 - val_loss: 10.7667\n",
      "Epoch 408/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8753 - val_loss: 13.4802\n",
      "Epoch 409/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.0309 - val_loss: 10.3379\n",
      "Epoch 410/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.9001 - val_loss: 11.3946\n",
      "Epoch 411/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.1212 - val_loss: 10.6314\n",
      "Epoch 412/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.0689 - val_loss: 10.8412\n",
      "Epoch 413/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.6207 - val_loss: 10.4685\n",
      "Epoch 414/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.5646 - val_loss: 10.2218\n",
      "Epoch 415/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8029 - val_loss: 10.1506\n",
      "Epoch 416/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.4968 - val_loss: 10.3049\n",
      "Epoch 417/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.4716 - val_loss: 10.0966\n",
      "Epoch 418/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.5441 - val_loss: 10.2277\n",
      "Epoch 419/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.8191 - val_loss: 10.6182\n",
      "Epoch 420/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.8789 - val_loss: 10.8010\n",
      "Epoch 421/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 9.0981 - val_loss: 10.5846\n",
      "Epoch 422/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.7280 - val_loss: 12.4575\n",
      "Epoch 423/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.8242 - val_loss: 11.0790\n",
      "Epoch 424/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6575 - val_loss: 10.1762\n",
      "Epoch 425/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.5254 - val_loss: 10.7631\n",
      "Epoch 426/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9238 - val_loss: 15.4574\n",
      "Epoch 427/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0555 - val_loss: 10.7220\n",
      "Epoch 428/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6011 - val_loss: 10.2181\n",
      "Epoch 429/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4286 - val_loss: 10.2106\n",
      "Epoch 430/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6153 - val_loss: 10.3020\n",
      "Epoch 431/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4109 - val_loss: 10.3985\n",
      "Epoch 432/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8704 - val_loss: 12.5772\n",
      "Epoch 433/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9710 - val_loss: 10.3918\n",
      "Epoch 434/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0570 - val_loss: 14.5001\n",
      "Epoch 435/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.0761 - val_loss: 10.3584\n",
      "Epoch 436/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.8635 - val_loss: 11.0421\n",
      "Epoch 437/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7326 - val_loss: 10.0053\n",
      "Epoch 438/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0212 - val_loss: 12.2628\n",
      "Epoch 439/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6342 - val_loss: 10.2824\n",
      "Epoch 440/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.7476 - val_loss: 11.5451\n",
      "Epoch 441/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5744 - val_loss: 10.2012\n",
      "Epoch 442/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7610 - val_loss: 10.0739\n",
      "Epoch 443/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8957 - val_loss: 10.4339\n",
      "Epoch 444/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.7297 - val_loss: 10.3551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 445/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5745 - val_loss: 11.2492\n",
      "Epoch 446/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.9710 - val_loss: 10.3978\n",
      "Epoch 447/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7697 - val_loss: 11.7043\n",
      "Epoch 448/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8059 - val_loss: 11.1022\n",
      "Epoch 449/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.7294 - val_loss: 10.4936\n",
      "Epoch 450/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5253 - val_loss: 10.4917\n",
      "Epoch 451/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.3729 - val_loss: 10.7131\n",
      "Epoch 452/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4050 - val_loss: 11.1622\n",
      "Epoch 453/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5678 - val_loss: 10.6533\n",
      "Epoch 454/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8907 - val_loss: 10.7805\n",
      "Epoch 455/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5138 - val_loss: 11.2654\n",
      "Epoch 456/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9200 - val_loss: 10.0198\n",
      "Epoch 457/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8292 - val_loss: 10.0695\n",
      "Epoch 458/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.5100 - val_loss: 10.1145\n",
      "Epoch 459/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.4821 - val_loss: 10.6891\n",
      "Epoch 460/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.6317 - val_loss: 11.7571\n",
      "Epoch 461/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.7818 - val_loss: 10.6629\n",
      "Epoch 462/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7109 - val_loss: 10.9849\n",
      "Epoch 463/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4833 - val_loss: 10.4170\n",
      "Epoch 464/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8390 - val_loss: 10.4219\n",
      "Epoch 465/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7081 - val_loss: 10.0775\n",
      "Epoch 466/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3526 - val_loss: 9.8227\n",
      "Epoch 467/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5932 - val_loss: 10.3343\n",
      "Epoch 468/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3516 - val_loss: 10.7594\n",
      "Epoch 469/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5118 - val_loss: 10.2006\n",
      "Epoch 470/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3836 - val_loss: 10.7256\n",
      "Epoch 471/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.4327 - val_loss: 10.4979\n",
      "Epoch 472/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5379 - val_loss: 11.2547\n",
      "Epoch 473/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.6759 - val_loss: 10.2181\n",
      "Epoch 474/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.9876 - val_loss: 10.8077\n",
      "Epoch 475/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3083 - val_loss: 12.5113\n",
      "Epoch 476/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5395 - val_loss: 9.9130\n",
      "Epoch 477/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4720 - val_loss: 10.6688\n",
      "Epoch 478/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8404 - val_loss: 10.1589\n",
      "Epoch 479/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9976 - val_loss: 11.9073\n",
      "Epoch 480/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6477 - val_loss: 9.9112\n",
      "Epoch 481/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5283 - val_loss: 10.7108\n",
      "Epoch 482/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7578 - val_loss: 10.6691\n",
      "Epoch 483/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.4175 - val_loss: 10.8209\n",
      "Epoch 484/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.7424 - val_loss: 10.9872\n",
      "Epoch 485/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7666 - val_loss: 12.4072\n",
      "Epoch 486/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5886 - val_loss: 10.4485\n",
      "Epoch 487/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.0699 - val_loss: 10.1648\n",
      "Epoch 488/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4186 - val_loss: 9.7218\n",
      "Epoch 489/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5377 - val_loss: 10.5633\n",
      "Epoch 490/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3669 - val_loss: 10.6516\n",
      "Epoch 491/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.2273 - val_loss: 9.9517\n",
      "Epoch 492/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8946 - val_loss: 12.7601\n",
      "Epoch 493/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8701 - val_loss: 10.2456\n",
      "Epoch 494/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2921 - val_loss: 11.1732\n",
      "Epoch 495/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.5204 - val_loss: 11.0712\n",
      "Epoch 496/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6120 - val_loss: 9.8854\n",
      "Epoch 497/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5280 - val_loss: 9.8236\n",
      "Epoch 498/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3910 - val_loss: 10.3393\n",
      "Epoch 499/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.8520 - val_loss: 9.6674\n",
      "Epoch 500/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.2719 - val_loss: 9.7618\n",
      "Epoch 501/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2451 - val_loss: 9.9613\n",
      "Epoch 502/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.5126 - val_loss: 9.9389\n",
      "Epoch 503/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.9719 - val_loss: 10.3331\n",
      "Epoch 504/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3220 - val_loss: 11.0289\n",
      "Epoch 505/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.5312 - val_loss: 10.4642\n",
      "Epoch 506/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9598 - val_loss: 10.7417\n",
      "Epoch 507/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.6568 - val_loss: 10.8144\n",
      "Epoch 508/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2889 - val_loss: 9.8701\n",
      "Epoch 509/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5347 - val_loss: 10.4972\n",
      "Epoch 510/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8569 - val_loss: 11.2876\n",
      "Epoch 511/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.9933 - val_loss: 15.2848\n",
      "Epoch 512/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7612 - val_loss: 9.8455\n",
      "Epoch 513/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4214 - val_loss: 9.7048\n",
      "Epoch 514/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5295 - val_loss: 10.8014\n",
      "Epoch 515/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4884 - val_loss: 10.3586\n",
      "Epoch 516/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4325 - val_loss: 10.7264\n",
      "Epoch 517/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0811 - val_loss: 9.4823\n",
      "Epoch 518/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6467 - val_loss: 9.9479\n",
      "Epoch 519/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4228 - val_loss: 10.1035\n",
      "Epoch 520/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5828 - val_loss: 9.7413\n",
      "Epoch 521/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2896 - val_loss: 9.7037\n",
      "Epoch 522/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7721 - val_loss: 9.5791\n",
      "Epoch 523/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2837 - val_loss: 9.7376\n",
      "Epoch 524/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.3245 - val_loss: 10.2826\n",
      "Epoch 525/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5061 - val_loss: 9.9658\n",
      "Epoch 526/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.4555 - val_loss: 10.3034\n",
      "Epoch 527/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4974 - val_loss: 9.6459\n",
      "Epoch 528/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9307 - val_loss: 13.8487\n",
      "Epoch 529/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.3407 - val_loss: 9.8337\n",
      "Epoch 530/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2358 - val_loss: 10.1049\n",
      "Epoch 531/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0838 - val_loss: 10.1191\n",
      "Epoch 532/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3615 - val_loss: 9.6768\n",
      "Epoch 533/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.8090 - val_loss: 10.0056\n",
      "Epoch 534/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4799 - val_loss: 9.9450\n",
      "Epoch 535/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.5562 - val_loss: 9.5169\n",
      "Epoch 536/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2499 - val_loss: 10.1841\n",
      "Epoch 537/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2176 - val_loss: 9.7842\n",
      "Epoch 538/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.2833 - val_loss: 9.7417\n",
      "Epoch 539/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5373 - val_loss: 9.6176\n",
      "Epoch 540/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6828 - val_loss: 10.5880\n",
      "Epoch 541/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4279 - val_loss: 10.8155\n",
      "Epoch 542/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.4393 - val_loss: 10.3393\n",
      "Epoch 543/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7289 - val_loss: 9.6096\n",
      "Epoch 544/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6520 - val_loss: 9.5363\n",
      "Epoch 545/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.2999 - val_loss: 10.2699\n",
      "Epoch 546/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4563 - val_loss: 10.8003\n",
      "Epoch 547/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4968 - val_loss: 9.7779\n",
      "Epoch 548/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.8555 - val_loss: 9.5604\n",
      "Epoch 549/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7114 - val_loss: 9.8405\n",
      "Epoch 550/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4510 - val_loss: 9.7875\n",
      "Epoch 551/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4620 - val_loss: 11.5646\n",
      "Epoch 552/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.2688 - val_loss: 10.7561\n",
      "Epoch 553/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.2138 - val_loss: 9.8213\n",
      "Epoch 554/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.5059 - val_loss: 9.6526\n",
      "Epoch 555/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.2569 - val_loss: 9.4806\n",
      "Epoch 556/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1479 - val_loss: 10.3814\n",
      "Epoch 557/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3854 - val_loss: 10.6803\n",
      "Epoch 558/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5246 - val_loss: 9.7982\n",
      "Epoch 559/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.3010 - val_loss: 9.9482\n",
      "Epoch 560/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2326 - val_loss: 9.5720\n",
      "Epoch 561/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1353 - val_loss: 10.2304\n",
      "Epoch 562/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4586 - val_loss: 9.7930\n",
      "Epoch 563/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.2383 - val_loss: 10.8156\n",
      "Epoch 564/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3102 - val_loss: 10.7278\n",
      "Epoch 565/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4150 - val_loss: 10.4053\n",
      "Epoch 566/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4541 - val_loss: 9.7740\n",
      "Epoch 567/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.2987 - val_loss: 9.7425\n",
      "Epoch 568/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.6835 - val_loss: 9.7061\n",
      "Epoch 569/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5691 - val_loss: 9.5467\n",
      "Epoch 570/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2399 - val_loss: 9.9063\n",
      "Epoch 571/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0282 - val_loss: 9.8532\n",
      "Epoch 572/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2268 - val_loss: 10.3022\n",
      "Epoch 573/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4198 - val_loss: 10.1584\n",
      "Epoch 574/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3282 - val_loss: 10.3194\n",
      "Epoch 575/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3196 - val_loss: 9.7348\n",
      "Epoch 576/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.7308 - val_loss: 9.6478\n",
      "Epoch 577/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7180 - val_loss: 10.1512\n",
      "Epoch 578/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.3412 - val_loss: 10.3019\n",
      "Epoch 579/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6219 - val_loss: 9.7021\n",
      "Epoch 580/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.6538 - val_loss: 10.3818\n",
      "Epoch 581/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.4574 - val_loss: 9.8265\n",
      "Epoch 582/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0662 - val_loss: 11.4686\n",
      "Epoch 583/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4186 - val_loss: 11.1003\n",
      "Epoch 584/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.1916 - val_loss: 9.5798\n",
      "Epoch 585/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.6970 - val_loss: 9.6618\n",
      "Epoch 586/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.6074 - val_loss: 10.5814\n",
      "Epoch 587/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 8.4195 - val_loss: 9.4144\n",
      "Epoch 588/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.4318 - val_loss: 13.4180\n",
      "Epoch 589/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.6287 - val_loss: 9.7000\n",
      "Epoch 590/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.6120 - val_loss: 10.3289\n",
      "Epoch 591/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.4398 - val_loss: 9.6744\n",
      "Epoch 592/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 8.3602 - val_loss: 9.3931\n",
      "Epoch 593/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1479 - val_loss: 9.6967\n",
      "Epoch 594/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9783 - val_loss: 9.9732\n",
      "Epoch 595/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.4593 - val_loss: 9.9306\n",
      "Epoch 596/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.0156 - val_loss: 10.9586\n",
      "Epoch 597/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5492 - val_loss: 9.4683\n",
      "Epoch 598/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3308 - val_loss: 9.8671\n",
      "Epoch 599/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2074 - val_loss: 9.4054\n",
      "Epoch 600/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.4155 - val_loss: 9.5332\n",
      "Epoch 601/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6325 - val_loss: 10.0894\n",
      "Epoch 602/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6052 - val_loss: 10.4405\n",
      "Epoch 603/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.5599 - val_loss: 10.5251\n",
      "Epoch 604/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.4217 - val_loss: 10.1054\n",
      "Epoch 605/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.4823 - val_loss: 9.5852\n",
      "Epoch 606/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6417 - val_loss: 10.0956\n",
      "Epoch 607/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.5305 - val_loss: 12.9303\n",
      "Epoch 608/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4710 - val_loss: 10.3130\n",
      "Epoch 609/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1134 - val_loss: 10.8439\n",
      "Epoch 610/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.4322 - val_loss: 9.3453\n",
      "Epoch 611/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1279 - val_loss: 10.1023\n",
      "Epoch 612/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2720 - val_loss: 9.3479\n",
      "Epoch 613/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4126 - val_loss: 10.6452\n",
      "Epoch 614/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3406 - val_loss: 10.0133\n",
      "Epoch 615/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0926 - val_loss: 9.8258\n",
      "Epoch 616/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4304 - val_loss: 9.5768\n",
      "Epoch 617/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7264 - val_loss: 9.5323\n",
      "Epoch 618/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5694 - val_loss: 10.1582\n",
      "Epoch 619/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.2819 - val_loss: 9.8044\n",
      "Epoch 620/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7144 - val_loss: 10.3948\n",
      "Epoch 621/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2587 - val_loss: 10.0427\n",
      "Epoch 622/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.0891 - val_loss: 9.3507\n",
      "Epoch 623/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3409 - val_loss: 9.5659\n",
      "Epoch 624/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2401 - val_loss: 9.6728\n",
      "Epoch 625/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1834 - val_loss: 9.5012\n",
      "Epoch 626/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3582 - val_loss: 10.2171\n",
      "Epoch 627/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.9638 - val_loss: 9.6790\n",
      "Epoch 628/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5609 - val_loss: 12.4572\n",
      "Epoch 629/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4340 - val_loss: 9.8041\n",
      "Epoch 630/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.4526 - val_loss: 9.5579\n",
      "Epoch 631/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.2561 - val_loss: 11.4007\n",
      "Epoch 632/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2008 - val_loss: 10.3142\n",
      "Epoch 633/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2194 - val_loss: 9.9115\n",
      "Epoch 634/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9134 - val_loss: 9.6700\n",
      "Epoch 635/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.3374 - val_loss: 9.6233\n",
      "Epoch 636/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1015 - val_loss: 9.3455\n",
      "Epoch 637/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4160 - val_loss: 10.0427\n",
      "Epoch 638/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0883 - val_loss: 9.5453\n",
      "Epoch 639/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.2289 - val_loss: 10.2800\n",
      "Epoch 640/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.2328 - val_loss: 9.4527\n",
      "Epoch 641/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0645 - val_loss: 10.1828\n",
      "Epoch 642/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7127 - val_loss: 9.7056\n",
      "Epoch 643/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.5919 - val_loss: 9.7586\n",
      "Epoch 644/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1955 - val_loss: 9.4914\n",
      "Epoch 645/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1821 - val_loss: 9.9400\n",
      "Epoch 646/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4642 - val_loss: 9.5550\n",
      "Epoch 647/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3154 - val_loss: 10.2324\n",
      "Epoch 648/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6413 - val_loss: 10.1645\n",
      "Epoch 649/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4017 - val_loss: 9.5533\n",
      "Epoch 650/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4606 - val_loss: 9.9073\n",
      "Epoch 651/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6386 - val_loss: 9.4288\n",
      "Epoch 652/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0733 - val_loss: 10.4658\n",
      "Epoch 653/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6168 - val_loss: 9.8282\n",
      "Epoch 654/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2081 - val_loss: 10.5503\n",
      "Epoch 655/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.3919 - val_loss: 12.7556\n",
      "Epoch 656/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0987 - val_loss: 9.7394\n",
      "Epoch 657/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1251 - val_loss: 9.3243\n",
      "Epoch 658/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.4938 - val_loss: 9.5880\n",
      "Epoch 659/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1326 - val_loss: 9.1896\n",
      "Epoch 660/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.4556 - val_loss: 9.5106\n",
      "Epoch 661/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.6263 - val_loss: 9.6093\n",
      "Epoch 662/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6886 - val_loss: 9.9116\n",
      "Epoch 663/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5432 - val_loss: 9.7494\n",
      "Epoch 664/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2396 - val_loss: 11.2668\n",
      "Epoch 665/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.1721 - val_loss: 9.2081\n",
      "Epoch 666/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3218 - val_loss: 10.1750\n",
      "Epoch 667/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0609 - val_loss: 11.0321\n",
      "Epoch 668/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.2204 - val_loss: 9.5572\n",
      "Epoch 669/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4284 - val_loss: 10.0687\n",
      "Epoch 670/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4709 - val_loss: 9.9696\n",
      "Epoch 671/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.7746 - val_loss: 9.6071\n",
      "Epoch 672/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.4133 - val_loss: 9.9423\n",
      "Epoch 673/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2936 - val_loss: 9.6632\n",
      "Epoch 674/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.2049 - val_loss: 9.5595\n",
      "Epoch 675/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 8.1332 - val_loss: 10.6695\n",
      "Epoch 676/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4829 - val_loss: 9.4232\n",
      "Epoch 677/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2522 - val_loss: 9.8701\n",
      "Epoch 678/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4062 - val_loss: 9.3808\n",
      "Epoch 679/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4950 - val_loss: 11.0694\n",
      "Epoch 680/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9181 - val_loss: 9.4197\n",
      "Epoch 681/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.1410 - val_loss: 9.3984\n",
      "Epoch 682/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4365 - val_loss: 9.5887\n",
      "Epoch 683/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.6526 - val_loss: 9.8291\n",
      "Epoch 684/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1151 - val_loss: 9.4268\n",
      "Epoch 685/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1256 - val_loss: 9.5479\n",
      "Epoch 686/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1863 - val_loss: 9.6847\n",
      "Epoch 687/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.3192 - val_loss: 9.2253\n",
      "Epoch 688/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.0009 - val_loss: 9.5505\n",
      "Epoch 689/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.0227 - val_loss: 10.4637\n",
      "Epoch 690/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4579 - val_loss: 9.9058\n",
      "Epoch 691/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7149 - val_loss: 9.5452\n",
      "Epoch 692/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6608 - val_loss: 9.9749\n",
      "Epoch 693/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7582 - val_loss: 9.4092\n",
      "Epoch 694/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2848 - val_loss: 10.4822\n",
      "Epoch 695/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1890 - val_loss: 9.7022\n",
      "Epoch 696/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6976 - val_loss: 10.3010\n",
      "Epoch 697/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0858 - val_loss: 9.4550\n",
      "Epoch 698/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.4658 - val_loss: 11.6851\n",
      "Epoch 699/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3070 - val_loss: 10.4647\n",
      "Epoch 700/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.5087 - val_loss: 9.6271\n",
      "Epoch 701/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3702 - val_loss: 10.1332\n",
      "Epoch 702/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.4437 - val_loss: 11.8728\n",
      "Epoch 703/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.7197 - val_loss: 9.6845\n",
      "Epoch 704/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7305 - val_loss: 10.3111\n",
      "Epoch 705/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4030 - val_loss: 9.9600\n",
      "Epoch 706/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2241 - val_loss: 9.3961\n",
      "Epoch 707/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3127 - val_loss: 9.2097\n",
      "Epoch 708/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3026 - val_loss: 10.0388\n",
      "Epoch 709/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.3825 - val_loss: 10.9913\n",
      "Epoch 710/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1530 - val_loss: 9.1533\n",
      "Epoch 711/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2651 - val_loss: 11.3564\n",
      "Epoch 712/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2621 - val_loss: 10.8601\n",
      "Epoch 713/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1108 - val_loss: 9.9370\n",
      "Epoch 714/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1348 - val_loss: 10.9024\n",
      "Epoch 715/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3558 - val_loss: 9.2776\n",
      "Epoch 716/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4130 - val_loss: 9.5375\n",
      "Epoch 717/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8842 - val_loss: 9.1880\n",
      "Epoch 718/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.2355 - val_loss: 9.9309\n",
      "Epoch 719/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.8511 - val_loss: 10.3609\n",
      "Epoch 720/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3614 - val_loss: 9.1068\n",
      "Epoch 721/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1279 - val_loss: 9.9208\n",
      "Epoch 722/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.1963 - val_loss: 9.4638\n",
      "Epoch 723/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8681 - val_loss: 11.7203\n",
      "Epoch 724/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6959 - val_loss: 9.3169\n",
      "Epoch 725/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.1718 - val_loss: 9.4198\n",
      "Epoch 726/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.6063 - val_loss: 9.7997\n",
      "Epoch 727/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.0530 - val_loss: 9.9027\n",
      "Epoch 728/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3070 - val_loss: 10.1620\n",
      "Epoch 729/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3974 - val_loss: 9.7995\n",
      "Epoch 730/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.2459 - val_loss: 9.4221\n",
      "Epoch 731/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1206 - val_loss: 9.8135\n",
      "Epoch 732/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1481 - val_loss: 9.2666\n",
      "Epoch 733/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.9027 - val_loss: 12.6955\n",
      "Epoch 734/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0903 - val_loss: 9.6101\n",
      "Epoch 735/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1239 - val_loss: 10.9597\n",
      "Epoch 736/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.2169 - val_loss: 9.3308\n",
      "Epoch 737/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.1490 - val_loss: 11.0882\n",
      "Epoch 738/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.3305 - val_loss: 9.7711\n",
      "Epoch 739/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4507 - val_loss: 10.2238\n",
      "Epoch 740/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7308 - val_loss: 14.7638\n",
      "Epoch 741/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.7346 - val_loss: 9.2659\n",
      "Epoch 742/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4287 - val_loss: 10.2027\n",
      "Epoch 743/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4752 - val_loss: 10.9185\n",
      "Epoch 744/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3460 - val_loss: 9.3327\n",
      "Epoch 745/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1262 - val_loss: 10.8917\n",
      "Epoch 746/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4657 - val_loss: 9.5035\n",
      "Epoch 747/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.7330 - val_loss: 9.7736\n",
      "Epoch 748/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1109 - val_loss: 9.6665\n",
      "Epoch 749/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3617 - val_loss: 9.1165\n",
      "Epoch 750/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2906 - val_loss: 9.6808\n",
      "Epoch 751/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1830 - val_loss: 9.4161\n",
      "Epoch 752/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6343 - val_loss: 9.6927\n",
      "Epoch 753/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.4157 - val_loss: 13.7225\n",
      "Epoch 754/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2209 - val_loss: 9.8089\n",
      "Epoch 755/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.2096 - val_loss: 12.8379\n",
      "Epoch 756/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.4555 - val_loss: 9.1153\n",
      "Epoch 757/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.0130 - val_loss: 11.2213\n",
      "Epoch 758/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.9632 - val_loss: 9.2651\n",
      "Epoch 759/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.9981 - val_loss: 9.8822\n",
      "Epoch 760/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2852 - val_loss: 9.9291\n",
      "Epoch 761/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4614 - val_loss: 10.5145\n",
      "Epoch 762/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.1762 - val_loss: 9.8939\n",
      "Epoch 763/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.2860 - val_loss: 9.8250\n",
      "Epoch 764/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.2192 - val_loss: 9.5357\n",
      "Epoch 765/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.2548 - val_loss: 9.5681\n",
      "Epoch 766/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0017 - val_loss: 9.2778\n",
      "Epoch 767/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0741 - val_loss: 10.9584\n",
      "Epoch 768/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6077 - val_loss: 9.3424\n",
      "Epoch 769/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3770 - val_loss: 9.4471\n",
      "Epoch 770/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9660 - val_loss: 9.4590\n",
      "Epoch 771/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.2240 - val_loss: 9.2333\n",
      "Epoch 772/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3561 - val_loss: 11.6974\n",
      "Epoch 773/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.1326 - val_loss: 9.3787\n",
      "Epoch 774/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4370 - val_loss: 9.7922\n",
      "Epoch 775/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2028 - val_loss: 9.9014\n",
      "Epoch 776/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4192 - val_loss: 9.6871\n",
      "Epoch 777/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1384 - val_loss: 11.1657\n",
      "Epoch 778/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5147 - val_loss: 9.9289\n",
      "Epoch 779/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9983 - val_loss: 9.5233\n",
      "Epoch 780/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.2565 - val_loss: 10.1473\n",
      "Epoch 781/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.9667 - val_loss: 9.3863\n",
      "Epoch 782/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.1440 - val_loss: 9.3607\n",
      "Epoch 783/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1349 - val_loss: 10.2578\n",
      "Epoch 784/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4024 - val_loss: 10.0840\n",
      "Epoch 785/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2632 - val_loss: 10.2928\n",
      "Epoch 786/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.7834 - val_loss: 10.6875\n",
      "Epoch 787/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5692 - val_loss: 9.2809\n",
      "Epoch 788/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.5758 - val_loss: 9.2526\n",
      "Epoch 789/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4796 - val_loss: 11.8402\n",
      "Epoch 790/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2799 - val_loss: 10.6831\n",
      "Epoch 791/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.0520 - val_loss: 9.3094\n",
      "Epoch 792/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4041 - val_loss: 9.0912\n",
      "Epoch 793/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6781 - val_loss: 9.2130\n",
      "Epoch 794/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4159 - val_loss: 9.5216\n",
      "Epoch 795/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0742 - val_loss: 9.3367\n",
      "Epoch 796/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0709 - val_loss: 9.1527\n",
      "Epoch 797/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0506 - val_loss: 9.2602\n",
      "Epoch 798/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1189 - val_loss: 9.5452\n",
      "Epoch 799/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3792 - val_loss: 9.8628\n",
      "Epoch 800/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.4897 - val_loss: 10.8005\n",
      "Epoch 801/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2817 - val_loss: 10.4446\n",
      "Epoch 802/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1656 - val_loss: 9.8975\n",
      "Epoch 803/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7536 - val_loss: 11.0477\n",
      "Epoch 804/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1092 - val_loss: 10.0909\n",
      "Epoch 805/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0645 - val_loss: 9.6851\n",
      "Epoch 806/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2748 - val_loss: 9.3768\n",
      "Epoch 807/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1726 - val_loss: 9.5042\n",
      "Epoch 808/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6560 - val_loss: 9.7390\n",
      "Epoch 809/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1927 - val_loss: 9.3721\n",
      "Epoch 810/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3060 - val_loss: 9.1179\n",
      "Epoch 811/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0752 - val_loss: 9.4531\n",
      "Epoch 812/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3592 - val_loss: 10.8663\n",
      "Epoch 813/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.2516 - val_loss: 10.2754\n",
      "Epoch 814/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2972 - val_loss: 9.3592\n",
      "Epoch 815/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2611 - val_loss: 9.7087\n",
      "Epoch 816/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6476 - val_loss: 11.0037\n",
      "Epoch 817/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.1310 - val_loss: 9.9490\n",
      "Epoch 818/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2668 - val_loss: 9.3094\n",
      "Epoch 819/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2123 - val_loss: 9.8219\n",
      "Epoch 820/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.2495 - val_loss: 9.5461\n",
      "Epoch 821/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6351 - val_loss: 8.9323\n",
      "Epoch 822/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3913 - val_loss: 9.7871\n",
      "Epoch 823/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.7724 - val_loss: 10.2060\n",
      "Epoch 824/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4385 - val_loss: 9.2393\n",
      "Epoch 825/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6617 - val_loss: 9.7769\n",
      "Epoch 826/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.1694 - val_loss: 9.8331\n",
      "Epoch 827/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.1680 - val_loss: 9.5390\n",
      "Epoch 828/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5463 - val_loss: 9.5992\n",
      "Epoch 829/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3404 - val_loss: 9.7967\n",
      "Epoch 830/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5181 - val_loss: 9.8086\n",
      "Epoch 831/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1175 - val_loss: 9.9148\n",
      "Epoch 832/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1622 - val_loss: 9.3619\n",
      "Epoch 833/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.8671 - val_loss: 9.3495\n",
      "Epoch 834/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.4086 - val_loss: 10.7255\n",
      "Epoch 835/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0741 - val_loss: 9.4893\n",
      "Epoch 836/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.2265 - val_loss: 11.1599\n",
      "Epoch 837/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3555 - val_loss: 9.1659\n",
      "Epoch 838/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5875 - val_loss: 10.5370\n",
      "Epoch 839/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1741 - val_loss: 12.4279\n",
      "Epoch 840/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9570 - val_loss: 9.3855\n",
      "Epoch 841/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0195 - val_loss: 9.1106\n",
      "Epoch 842/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.0697 - val_loss: 10.5489\n",
      "Epoch 843/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2445 - val_loss: 9.2405\n",
      "Epoch 844/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9411 - val_loss: 9.4008\n",
      "Epoch 845/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5687 - val_loss: 9.8466\n",
      "Epoch 846/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5895 - val_loss: 9.0621\n",
      "Epoch 847/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5225 - val_loss: 9.8594\n",
      "Epoch 848/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1508 - val_loss: 9.4230\n",
      "Epoch 849/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9723 - val_loss: 9.4485\n",
      "Epoch 850/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1475 - val_loss: 9.7837\n",
      "Epoch 851/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6619 - val_loss: 9.8047\n",
      "Epoch 852/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1915 - val_loss: 10.9753\n",
      "Epoch 853/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7887 - val_loss: 9.7075\n",
      "Epoch 854/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4443 - val_loss: 9.9588\n",
      "Epoch 855/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1412 - val_loss: 9.4799\n",
      "Epoch 856/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2841 - val_loss: 9.4617\n",
      "Epoch 857/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4045 - val_loss: 10.0047\n",
      "Epoch 858/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3223 - val_loss: 9.2982\n",
      "Epoch 859/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3097 - val_loss: 9.4555\n",
      "Epoch 860/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8105 - val_loss: 10.2043\n",
      "Epoch 861/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1678 - val_loss: 9.8595\n",
      "Epoch 862/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1446 - val_loss: 9.4275\n",
      "Epoch 863/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2582 - val_loss: 9.0128\n",
      "Epoch 864/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.5495 - val_loss: 9.4725\n",
      "Epoch 865/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1522 - val_loss: 9.3948\n",
      "Epoch 866/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2694 - val_loss: 10.9187\n",
      "Epoch 867/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.0300 - val_loss: 9.4242\n",
      "Epoch 868/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4892 - val_loss: 10.2994\n",
      "Epoch 869/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9051 - val_loss: 9.4936\n",
      "Epoch 870/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9446 - val_loss: 9.4667\n",
      "Epoch 871/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.2415 - val_loss: 9.8691\n",
      "Epoch 872/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1410 - val_loss: 9.4016\n",
      "Epoch 873/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3877 - val_loss: 10.0604\n",
      "Epoch 874/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2777 - val_loss: 9.1107\n",
      "Epoch 875/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.7869 - val_loss: 10.0073\n",
      "Epoch 876/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5261 - val_loss: 9.2631\n",
      "Epoch 877/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1921 - val_loss: 10.1815\n",
      "Epoch 878/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1639 - val_loss: 10.9921\n",
      "Epoch 879/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2047 - val_loss: 9.8789\n",
      "Epoch 880/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3615 - val_loss: 10.5571\n",
      "Epoch 881/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2730 - val_loss: 9.6107\n",
      "Epoch 882/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4334 - val_loss: 11.0535\n",
      "Epoch 883/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5715 - val_loss: 9.5212\n",
      "Epoch 884/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.2605 - val_loss: 9.5107\n",
      "Epoch 885/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.2310 - val_loss: 10.3055\n",
      "Epoch 886/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6511 - val_loss: 9.8719\n",
      "Epoch 887/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2551 - val_loss: 9.3275\n",
      "Epoch 888/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.4489 - val_loss: 11.4200\n",
      "Epoch 889/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.8144 - val_loss: 9.6686\n",
      "Epoch 890/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2929 - val_loss: 9.4190\n",
      "Epoch 891/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.2026 - val_loss: 9.2501\n",
      "Epoch 892/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1473 - val_loss: 9.7809\n",
      "Epoch 893/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1433 - val_loss: 9.5217\n",
      "Epoch 894/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0314 - val_loss: 9.4741\n",
      "Epoch 895/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1053 - val_loss: 12.0303\n",
      "Epoch 896/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5250 - val_loss: 9.2305\n",
      "Epoch 897/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.9701 - val_loss: 9.0543\n",
      "Epoch 898/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.0568 - val_loss: 10.0738\n",
      "Epoch 899/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4073 - val_loss: 10.8523\n",
      "Epoch 900/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.3783 - val_loss: 9.2427\n",
      "Epoch 901/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.2337 - val_loss: 10.2266\n",
      "Epoch 902/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4911 - val_loss: 9.9139\n",
      "Epoch 903/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.2379 - val_loss: 11.5437\n",
      "Epoch 904/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.2554 - val_loss: 9.9170\n",
      "Epoch 905/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.0449 - val_loss: 9.9193\n",
      "Epoch 906/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2016 - val_loss: 9.4146\n",
      "Epoch 907/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2462 - val_loss: 11.7444\n",
      "Epoch 908/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7076 - val_loss: 9.8245\n",
      "Epoch 909/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.8923 - val_loss: 9.2174\n",
      "Epoch 910/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1444 - val_loss: 9.3270\n",
      "Epoch 911/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2430 - val_loss: 10.1412\n",
      "Epoch 912/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1566 - val_loss: 9.5608\n",
      "Epoch 913/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2921 - val_loss: 11.2162\n",
      "Epoch 914/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3050 - val_loss: 9.1131\n",
      "Epoch 915/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0313 - val_loss: 10.5531\n",
      "Epoch 916/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4440 - val_loss: 11.0994\n",
      "Epoch 917/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8156 - val_loss: 9.7933\n",
      "Epoch 918/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1000 - val_loss: 9.3711\n",
      "Epoch 919/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2569 - val_loss: 9.2385\n",
      "Epoch 920/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3118 - val_loss: 9.0761\n",
      "Epoch 921/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2713 - val_loss: 9.5772\n",
      "Epoch 922/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2449 - val_loss: 10.8197\n",
      "Epoch 923/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8590 - val_loss: 11.0303\n",
      "Epoch 924/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2734 - val_loss: 10.1191\n",
      "Epoch 925/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.9523 - val_loss: 8.9985\n",
      "Epoch 926/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.1001 - val_loss: 9.3759\n",
      "Epoch 927/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4638 - val_loss: 11.5754\n",
      "Epoch 928/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.4591 - val_loss: 9.2229\n",
      "Epoch 929/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 8.7553 - val_loss: 9.7682\n",
      "Epoch 930/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.2497 - val_loss: 9.6686\n",
      "Epoch 931/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.1832 - val_loss: 9.8691\n",
      "Epoch 932/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.5834 - val_loss: 10.5262\n",
      "Epoch 933/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6246 - val_loss: 11.0763\n",
      "Epoch 934/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.7287 - val_loss: 9.4587\n",
      "Epoch 935/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3441 - val_loss: 10.0482\n",
      "Epoch 936/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.0779 - val_loss: 10.0966\n",
      "Epoch 937/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.2286 - val_loss: 9.4476\n",
      "Epoch 938/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4190 - val_loss: 9.1214\n",
      "Epoch 939/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.4498 - val_loss: 9.1737\n",
      "Epoch 940/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.1651 - val_loss: 10.2583\n",
      "Epoch 941/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2597 - val_loss: 9.8766\n",
      "Epoch 942/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1549 - val_loss: 9.6271\n",
      "Epoch 943/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2313 - val_loss: 9.4055\n",
      "Epoch 944/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2046 - val_loss: 11.6345\n",
      "Epoch 945/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4417 - val_loss: 9.0480\n",
      "Epoch 946/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5027 - val_loss: 10.8855\n",
      "Epoch 947/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2541 - val_loss: 9.0730\n",
      "Epoch 948/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1299 - val_loss: 10.0763\n",
      "Epoch 949/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2050 - val_loss: 10.0663\n",
      "Epoch 950/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3663 - val_loss: 9.1394\n",
      "Epoch 951/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1496 - val_loss: 9.4311\n",
      "Epoch 952/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4384 - val_loss: 9.4000\n",
      "Epoch 953/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2538 - val_loss: 10.6422\n",
      "Epoch 954/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3974 - val_loss: 9.7705\n",
      "Epoch 955/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5403 - val_loss: 9.9566\n",
      "Epoch 956/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2621 - val_loss: 9.1161\n",
      "Epoch 957/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1127 - val_loss: 9.5504\n",
      "Epoch 958/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.0412 - val_loss: 9.0532\n",
      "Epoch 959/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1006 - val_loss: 9.1293\n",
      "Epoch 960/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7884 - val_loss: 9.1859\n",
      "Epoch 961/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5209 - val_loss: 10.8343\n",
      "Epoch 962/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6814 - val_loss: 9.1887\n",
      "Epoch 963/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.1086 - val_loss: 9.7412\n",
      "Epoch 964/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3174 - val_loss: 9.5113\n",
      "Epoch 965/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.3190 - val_loss: 9.8724\n",
      "Epoch 966/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4806 - val_loss: 9.2963\n",
      "Epoch 967/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3777 - val_loss: 9.2964\n",
      "Epoch 968/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.8887 - val_loss: 9.8034\n",
      "Epoch 969/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4616 - val_loss: 9.0964\n",
      "Epoch 970/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3657 - val_loss: 13.5544\n",
      "Epoch 971/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1502 - val_loss: 9.6125\n",
      "Epoch 972/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0136 - val_loss: 9.3297\n",
      "Epoch 973/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.3303 - val_loss: 10.0811\n",
      "Epoch 974/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.1165 - val_loss: 9.1218\n",
      "Epoch 975/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1697 - val_loss: 11.3575\n",
      "Epoch 976/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.0677 - val_loss: 9.1686\n",
      "Epoch 977/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1180 - val_loss: 9.6552\n",
      "Epoch 978/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.2790 - val_loss: 9.7953\n",
      "Epoch 979/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2290 - val_loss: 9.4941\n",
      "Epoch 980/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.4225 - val_loss: 10.8231\n",
      "Epoch 981/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6226 - val_loss: 9.3780\n",
      "Epoch 982/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.9895 - val_loss: 9.0464\n",
      "Epoch 983/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2023 - val_loss: 11.7077\n",
      "Epoch 984/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.6229 - val_loss: 9.9265\n",
      "Epoch 985/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.0503 - val_loss: 9.3989\n",
      "Epoch 986/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.7435 - val_loss: 8.9576\n",
      "Epoch 987/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4185 - val_loss: 9.1153\n",
      "Epoch 988/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0243 - val_loss: 10.3810\n",
      "Epoch 989/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1622 - val_loss: 9.3258\n",
      "Epoch 990/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0731 - val_loss: 10.2055\n",
      "Epoch 991/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4464 - val_loss: 9.3394\n",
      "Epoch 992/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3701 - val_loss: 9.5853\n",
      "Epoch 993/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0067 - val_loss: 9.1039\n",
      "Epoch 994/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.4097 - val_loss: 9.4961\n",
      "Epoch 995/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6762 - val_loss: 9.3581\n",
      "Epoch 996/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8442 - val_loss: 13.5343\n",
      "Epoch 997/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.3835 - val_loss: 9.9489\n",
      "Epoch 998/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1747 - val_loss: 8.8748\n",
      "Epoch 999/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3543 - val_loss: 9.5056\n",
      "Epoch 1000/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0198 - val_loss: 10.1143\n",
      "8.173690143939668\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-1.8543719 ,  3.994964  , -0.67607903,  3.3079267 , -0.14229144],\n",
       "        [ 0.47271243, -0.21911685, -1.3893162 , -0.07347753, -0.19800112],\n",
       "        [ 0.3873367 ,  0.7414873 , -1.5729681 , -0.00752882, -0.29400936],\n",
       "        [ 0.0279171 , -0.17475185,  0.24542645, -0.06149895,  0.12112733],\n",
       "        [-0.29920578,  0.32019627,  0.28489867,  2.546552  , -0.18457963]],\n",
       "       dtype=float32),\n",
       " array([-1.2868559,  4.9410443, -0.6747812,  4.751049 ,  1.3849336],\n",
       "       dtype=float32),\n",
       " array([[-0.31863678, -0.07661062, -0.6605434 ,  0.2682548 ,  0.5082065 ,\n",
       "          0.94094855, -0.62507105, -0.62306714, -1.0552505 ,  0.30977872],\n",
       "        [-2.4209397 , -1.3607966 , -2.3481767 ,  1.5450659 ,  2.557503  ,\n",
       "          2.1143527 , -1.9646051 , -2.5989234 , -2.2126536 ,  1.6150489 ],\n",
       "        [-0.20090845,  0.25121745, -0.64416987,  0.55724216,  0.80736554,\n",
       "         -0.16266158, -0.6740566 ,  0.34516183, -0.7820709 , -0.052527  ],\n",
       "        [-1.1974512 , -0.5985419 , -1.1082377 ,  0.90537584,  1.1875566 ,\n",
       "          1.9378694 , -1.7189672 , -1.7758653 , -1.3066247 ,  1.1914821 ],\n",
       "        [-0.94009626, -1.068199  , -1.6061697 ,  2.086198  ,  2.0843139 ,\n",
       "          1.6097702 , -1.7010211 , -0.89903224, -1.7152232 ,  2.0113628 ]],\n",
       "       dtype=float32),\n",
       " array([-2.3376176, -2.0598454, -2.3617268,  2.2930233,  2.3776307,\n",
       "         2.3514967, -2.3574   , -2.3062577, -2.3444898,  2.2931201],\n",
       "       dtype=float32),\n",
       " array([[-1.8307656],\n",
       "        [-1.1328889],\n",
       "        [-2.0066483],\n",
       "        [ 1.6126907],\n",
       "        [ 2.245087 ],\n",
       "        [ 2.1486948],\n",
       "        [-2.1570823],\n",
       "        [-1.7422837],\n",
       "        [-1.8532465],\n",
       "        [ 1.6473196]], dtype=float32),\n",
       " array([2.4840348], dtype=float32)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_airfoil, history_airfoil, evaluate_airfoil=NN_model_structure_regression_2(X_train_airfoil, X_val_airfoil, Y_train_airfoil, Y_val_airfoil, adam2, 32, 1000, x_test_airfoil, y_test_airfoil)\n",
    "model_airfoil.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_airfoil.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_airfoil_structure2_4th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 15)                90        \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 136\n",
      "Trainable params: 136\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1052 samples, validate on 225 samples\n",
      "Epoch 1/1000\n",
      "1052/1052 [==============================] - 0s 206us/step - loss: 7414.7170 - val_loss: 255.7131\n",
      "Epoch 2/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 172.8807 - val_loss: 41.6660\n",
      "Epoch 3/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 37.4980 - val_loss: 32.7218\n",
      "Epoch 4/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 29.6409 - val_loss: 28.7770\n",
      "Epoch 5/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 26.9862 - val_loss: 27.7921\n",
      "Epoch 6/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 26.5892 - val_loss: 28.8649\n",
      "Epoch 7/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 24.8115 - val_loss: 26.2854\n",
      "Epoch 8/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 24.5971 - val_loss: 26.3631\n",
      "Epoch 9/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 24.0215 - val_loss: 26.0336\n",
      "Epoch 10/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 23.3480 - val_loss: 25.6745\n",
      "Epoch 11/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 23.0093 - val_loss: 26.4348\n",
      "Epoch 12/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 23.2275 - val_loss: 25.5854\n",
      "Epoch 13/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 22.6606 - val_loss: 25.4258\n",
      "Epoch 14/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 22.9314 - val_loss: 25.5007\n",
      "Epoch 15/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.7989 - val_loss: 26.4165\n",
      "Epoch 16/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.2213 - val_loss: 26.3267\n",
      "Epoch 17/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 23.3560 - val_loss: 25.6167\n",
      "Epoch 18/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 22.3072 - val_loss: 25.4301\n",
      "Epoch 19/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.0665 - val_loss: 25.0272\n",
      "Epoch 20/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 22.1614 - val_loss: 26.9190\n",
      "Epoch 21/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 22.0309 - val_loss: 25.5203\n",
      "Epoch 22/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.0508 - val_loss: 25.1948\n",
      "Epoch 23/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.3364 - val_loss: 25.8995\n",
      "Epoch 24/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 21.9483 - val_loss: 25.9879\n",
      "Epoch 25/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 22.4085 - val_loss: 25.5727\n",
      "Epoch 26/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 21.9320 - val_loss: 26.0529\n",
      "Epoch 27/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 21.8783 - val_loss: 25.1110\n",
      "Epoch 28/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 22.1744 - val_loss: 27.2277\n",
      "Epoch 29/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 21.5814 - val_loss: 25.3477\n",
      "Epoch 30/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 21.8609 - val_loss: 27.3126\n",
      "Epoch 31/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 22.2651 - val_loss: 25.7982\n",
      "Epoch 32/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 22.4726 - val_loss: 25.2655\n",
      "Epoch 33/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 21.9506 - val_loss: 24.9503\n",
      "Epoch 34/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 21.7049 - val_loss: 25.6666\n",
      "Epoch 35/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 22.0059 - val_loss: 25.7345\n",
      "Epoch 36/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 21.3738 - val_loss: 25.0512\n",
      "Epoch 37/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 21.2210 - val_loss: 25.0323\n",
      "Epoch 38/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 21.1841 - val_loss: 24.9582\n",
      "Epoch 39/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.1629 - val_loss: 24.9427\n",
      "Epoch 40/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.2537 - val_loss: 24.6927\n",
      "Epoch 41/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 20.9591 - val_loss: 24.5958\n",
      "Epoch 42/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 20.7165 - val_loss: 25.9971\n",
      "Epoch 43/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 20.3799 - val_loss: 24.8419\n",
      "Epoch 44/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 20.3194 - val_loss: 25.2441\n",
      "Epoch 45/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 20.0737 - val_loss: 24.3888\n",
      "Epoch 46/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 19.9242 - val_loss: 26.1772\n",
      "Epoch 47/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 20.0908 - val_loss: 24.8871\n",
      "Epoch 48/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 19.6714 - val_loss: 25.1657\n",
      "Epoch 49/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 19.2850 - val_loss: 24.9677\n",
      "Epoch 50/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 19.1189 - val_loss: 25.5594\n",
      "Epoch 51/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 19.0746 - val_loss: 24.1318\n",
      "Epoch 52/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.9902 - val_loss: 25.2281\n",
      "Epoch 53/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.9930 - val_loss: 24.3239\n",
      "Epoch 54/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 19.2211 - val_loss: 24.1841\n",
      "Epoch 55/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.6814 - val_loss: 23.6297\n",
      "Epoch 56/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 18.4471 - val_loss: 23.7808\n",
      "Epoch 57/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.4200 - val_loss: 23.3450\n",
      "Epoch 58/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.5311 - val_loss: 23.7814\n",
      "Epoch 59/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.8221 - val_loss: 23.3140\n",
      "Epoch 60/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.2738 - val_loss: 23.3591\n",
      "Epoch 61/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.1638 - val_loss: 23.2600\n",
      "Epoch 62/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.1012 - val_loss: 22.7973\n",
      "Epoch 63/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.5050 - val_loss: 23.0898\n",
      "Epoch 64/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.9203 - val_loss: 22.8205\n",
      "Epoch 65/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.3855 - val_loss: 24.4308\n",
      "Epoch 66/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.0916 - val_loss: 22.6132\n",
      "Epoch 67/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.7074 - val_loss: 21.9960\n",
      "Epoch 68/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.7566 - val_loss: 22.6481\n",
      "Epoch 69/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.0430 - val_loss: 22.9468\n",
      "Epoch 70/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.6414 - val_loss: 22.0133\n",
      "Epoch 71/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.6613 - val_loss: 21.3819\n",
      "Epoch 72/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.0294 - val_loss: 23.2146\n",
      "Epoch 73/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.8521 - val_loss: 21.9729\n",
      "Epoch 74/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.3203 - val_loss: 20.4871\n",
      "Epoch 75/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.0795 - val_loss: 23.2516\n",
      "Epoch 76/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.5776 - val_loss: 21.4582\n",
      "Epoch 77/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.7321 - val_loss: 19.9021\n",
      "Epoch 78/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 16.9585 - val_loss: 19.9487\n",
      "Epoch 79/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 16.8270 - val_loss: 19.6152\n",
      "Epoch 80/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 16.8104 - val_loss: 19.2614\n",
      "Epoch 81/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 16.8375 - val_loss: 19.4706\n",
      "Epoch 82/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 16.6808 - val_loss: 19.7587\n",
      "Epoch 83/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 16.0831 - val_loss: 20.4155\n",
      "Epoch 84/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 16.8384 - val_loss: 21.8581\n",
      "Epoch 85/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 16.5405 - val_loss: 19.8520\n",
      "Epoch 86/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 16.0807 - val_loss: 18.7918\n",
      "Epoch 87/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 16.0917 - val_loss: 18.9218\n",
      "Epoch 88/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 15.7418 - val_loss: 20.0417\n",
      "Epoch 89/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 15.9854 - val_loss: 18.9856\n",
      "Epoch 90/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 15.7691 - val_loss: 19.3303\n",
      "Epoch 91/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 15.5180 - val_loss: 18.9152\n",
      "Epoch 92/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 15.9621 - val_loss: 19.7528\n",
      "Epoch 93/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 15.3166 - val_loss: 17.9936\n",
      "Epoch 94/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 15.4449 - val_loss: 18.4320\n",
      "Epoch 95/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 15.4265 - val_loss: 19.8359\n",
      "Epoch 96/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 15.1434 - val_loss: 18.3511\n",
      "Epoch 97/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 15.7631 - val_loss: 20.1689\n",
      "Epoch 98/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 15.5680 - val_loss: 19.9867\n",
      "Epoch 99/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 15.2920 - val_loss: 18.2583\n",
      "Epoch 100/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 15.3718 - val_loss: 17.8698\n",
      "Epoch 101/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 15.1613 - val_loss: 17.2104\n",
      "Epoch 102/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 14.9178 - val_loss: 17.8574\n",
      "Epoch 103/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 14.7767 - val_loss: 16.9972\n",
      "Epoch 104/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.4508 - val_loss: 17.4389\n",
      "Epoch 105/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.8672 - val_loss: 18.9659\n",
      "Epoch 106/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.8704 - val_loss: 17.1646\n",
      "Epoch 107/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 15.1789 - val_loss: 16.8960\n",
      "Epoch 108/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 15.2402 - val_loss: 18.7451\n",
      "Epoch 109/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 15.2225 - val_loss: 16.6667\n",
      "Epoch 110/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.2237 - val_loss: 16.4221\n",
      "Epoch 111/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.4200 - val_loss: 19.8129\n",
      "Epoch 112/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.3256 - val_loss: 16.5412\n",
      "Epoch 113/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.0790 - val_loss: 16.2319\n",
      "Epoch 114/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.9474 - val_loss: 16.3609\n",
      "Epoch 115/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 14.6930 - val_loss: 17.1728\n",
      "Epoch 116/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.8040 - val_loss: 16.4586\n",
      "Epoch 117/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 13.5277 - val_loss: 16.5058\n",
      "Epoch 118/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.4297 - val_loss: 16.3943\n",
      "Epoch 119/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.3538 - val_loss: 17.2728\n",
      "Epoch 120/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.0810 - val_loss: 15.9668\n",
      "Epoch 121/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.1070 - val_loss: 17.8885\n",
      "Epoch 122/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.1711 - val_loss: 16.8106\n",
      "Epoch 123/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.2554 - val_loss: 16.3664\n",
      "Epoch 124/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.0309 - val_loss: 16.9042\n",
      "Epoch 125/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 13.3737 - val_loss: 16.8010\n",
      "Epoch 126/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 12.7921 - val_loss: 17.8096\n",
      "Epoch 127/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.6472 - val_loss: 16.8176\n",
      "Epoch 128/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 12.6653 - val_loss: 16.4589\n",
      "Epoch 129/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 12.3394 - val_loss: 15.9042\n",
      "Epoch 130/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 12.3325 - val_loss: 15.3095\n",
      "Epoch 131/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.9664 - val_loss: 14.6183\n",
      "Epoch 132/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 12.3205 - val_loss: 16.4138\n",
      "Epoch 133/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.0811 - val_loss: 14.8087\n",
      "Epoch 134/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.6959 - val_loss: 17.0083\n",
      "Epoch 135/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.8883 - val_loss: 15.0500\n",
      "Epoch 136/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.2837 - val_loss: 14.5566\n",
      "Epoch 137/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.3414 - val_loss: 15.9819\n",
      "Epoch 138/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.7961 - val_loss: 15.0549\n",
      "Epoch 139/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.0678 - val_loss: 15.2677\n",
      "Epoch 140/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.1478 - val_loss: 14.9599\n",
      "Epoch 141/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.4288 - val_loss: 14.4409\n",
      "Epoch 142/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.4353 - val_loss: 14.6221\n",
      "Epoch 143/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.2318 - val_loss: 13.7670\n",
      "Epoch 144/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.7544 - val_loss: 14.0214\n",
      "Epoch 145/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.2072 - val_loss: 15.0848\n",
      "Epoch 146/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.5073 - val_loss: 14.8886\n",
      "Epoch 147/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.1314 - val_loss: 13.5594\n",
      "Epoch 148/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.5037 - val_loss: 14.0679\n",
      "Epoch 149/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.8905 - val_loss: 13.6491\n",
      "Epoch 150/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.2400 - val_loss: 12.9712\n",
      "Epoch 151/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.0686 - val_loss: 14.3685\n",
      "Epoch 152/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.9102 - val_loss: 12.6590\n",
      "Epoch 153/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.7142 - val_loss: 15.8735\n",
      "Epoch 154/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.7284 - val_loss: 12.4352\n",
      "Epoch 155/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 10.5079 - val_loss: 12.6357\n",
      "Epoch 156/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.3884 - val_loss: 16.7019\n",
      "Epoch 157/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.7383 - val_loss: 13.1508\n",
      "Epoch 158/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.5381 - val_loss: 12.1860\n",
      "Epoch 159/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.7381 - val_loss: 14.6835\n",
      "Epoch 160/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.0431 - val_loss: 13.0265\n",
      "Epoch 161/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.4098 - val_loss: 13.0981\n",
      "Epoch 162/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.1361 - val_loss: 12.7804\n",
      "Epoch 163/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.2173 - val_loss: 12.9068\n",
      "Epoch 164/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.3985 - val_loss: 12.4647\n",
      "Epoch 165/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.3515 - val_loss: 13.3008\n",
      "Epoch 166/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.7803 - val_loss: 11.9500\n",
      "Epoch 167/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.8632 - val_loss: 13.9741\n",
      "Epoch 168/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.2821 - val_loss: 14.2714\n",
      "Epoch 169/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.0845 - val_loss: 12.3368\n",
      "Epoch 170/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.2578 - val_loss: 13.4796\n",
      "Epoch 171/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.7292 - val_loss: 13.1600\n",
      "Epoch 172/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.6604 - val_loss: 11.7608\n",
      "Epoch 173/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.2063 - val_loss: 18.8851\n",
      "Epoch 174/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.1290 - val_loss: 13.0994\n",
      "Epoch 175/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.7751 - val_loss: 11.7521\n",
      "Epoch 176/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.8491 - val_loss: 12.2701\n",
      "Epoch 177/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.7366 - val_loss: 12.2889\n",
      "Epoch 178/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.5269 - val_loss: 12.6072\n",
      "Epoch 179/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.8107 - val_loss: 12.1749\n",
      "Epoch 180/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.6300 - val_loss: 11.7644\n",
      "Epoch 181/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.5753 - val_loss: 11.6085\n",
      "Epoch 182/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.6323 - val_loss: 11.5494\n",
      "Epoch 183/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.7606 - val_loss: 11.3287\n",
      "Epoch 184/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.7230 - val_loss: 12.3062\n",
      "Epoch 185/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.6884 - val_loss: 11.7877\n",
      "Epoch 186/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.2827 - val_loss: 12.7159\n",
      "Epoch 187/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.4918 - val_loss: 11.3902\n",
      "Epoch 188/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.5002 - val_loss: 11.4058\n",
      "Epoch 189/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.3823 - val_loss: 11.2990\n",
      "Epoch 190/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.7049 - val_loss: 12.0938\n",
      "Epoch 191/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.9748 - val_loss: 10.8019\n",
      "Epoch 192/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.4696 - val_loss: 13.2959\n",
      "Epoch 193/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.1693 - val_loss: 11.5380\n",
      "Epoch 194/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.3409 - val_loss: 10.7561\n",
      "Epoch 195/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1659 - val_loss: 11.3500\n",
      "Epoch 196/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.2972 - val_loss: 11.5268\n",
      "Epoch 197/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.3316 - val_loss: 11.0783\n",
      "Epoch 198/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.4995 - val_loss: 12.2615\n",
      "Epoch 199/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.7325 - val_loss: 12.2203\n",
      "Epoch 200/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.2917 - val_loss: 11.5377\n",
      "Epoch 201/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1563 - val_loss: 10.8876\n",
      "Epoch 202/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1778 - val_loss: 12.2737\n",
      "Epoch 203/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.4236 - val_loss: 13.1750\n",
      "Epoch 204/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.6051 - val_loss: 11.0072\n",
      "Epoch 205/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.4715 - val_loss: 12.3478\n",
      "Epoch 206/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.2656 - val_loss: 10.6895\n",
      "Epoch 207/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.3966 - val_loss: 11.9354\n",
      "Epoch 208/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.8825 - val_loss: 12.4248\n",
      "Epoch 209/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2689 - val_loss: 11.3374\n",
      "Epoch 210/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.4367 - val_loss: 10.8975\n",
      "Epoch 211/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.5536 - val_loss: 11.7025\n",
      "Epoch 212/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0259 - val_loss: 11.3760\n",
      "Epoch 213/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1771 - val_loss: 11.0368\n",
      "Epoch 214/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.3572 - val_loss: 10.9908\n",
      "Epoch 215/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.3027 - val_loss: 11.5554\n",
      "Epoch 216/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.3685 - val_loss: 12.1722\n",
      "Epoch 217/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.3622 - val_loss: 10.8644\n",
      "Epoch 218/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.3920 - val_loss: 10.5584\n",
      "Epoch 219/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.0639 - val_loss: 11.3435\n",
      "Epoch 220/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.1144 - val_loss: 11.9016\n",
      "Epoch 221/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.6076 - val_loss: 11.3290\n",
      "Epoch 222/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.3030 - val_loss: 12.3334\n",
      "Epoch 223/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0520 - val_loss: 11.0178\n",
      "Epoch 224/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.8842 - val_loss: 11.4534\n",
      "Epoch 225/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7146 - val_loss: 13.3094\n",
      "Epoch 226/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1869 - val_loss: 12.3484\n",
      "Epoch 227/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9897 - val_loss: 10.3227\n",
      "Epoch 228/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9522 - val_loss: 11.6843\n",
      "Epoch 229/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0153 - val_loss: 10.6155\n",
      "Epoch 230/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.3160 - val_loss: 11.7319\n",
      "Epoch 231/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.4102 - val_loss: 10.7737\n",
      "Epoch 232/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.4573 - val_loss: 11.2765\n",
      "Epoch 233/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0707 - val_loss: 12.1134\n",
      "Epoch 234/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0317 - val_loss: 10.5504\n",
      "Epoch 235/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.4623 - val_loss: 10.5016\n",
      "Epoch 236/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.1263 - val_loss: 13.3759\n",
      "Epoch 237/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.3746 - val_loss: 10.5856\n",
      "Epoch 238/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9830 - val_loss: 11.3088\n",
      "Epoch 239/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.9680 - val_loss: 10.6553\n",
      "Epoch 240/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.1002 - val_loss: 10.7928\n",
      "Epoch 241/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.2089 - val_loss: 10.9346\n",
      "Epoch 242/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.4050 - val_loss: 10.7035\n",
      "Epoch 243/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.1142 - val_loss: 10.6779\n",
      "Epoch 244/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8500 - val_loss: 10.5493\n",
      "Epoch 245/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1520 - val_loss: 10.4414\n",
      "Epoch 246/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1546 - val_loss: 12.4827\n",
      "Epoch 247/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8404 - val_loss: 11.3518\n",
      "Epoch 248/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.4430 - val_loss: 15.3492\n",
      "Epoch 249/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0075 - val_loss: 10.5103\n",
      "Epoch 250/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1149 - val_loss: 12.3985\n",
      "Epoch 251/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.8650 - val_loss: 10.8899\n",
      "Epoch 252/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8213 - val_loss: 10.7272\n",
      "Epoch 253/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.0430 - val_loss: 10.4015\n",
      "Epoch 254/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 8.7867 - val_loss: 11.1151\n",
      "Epoch 255/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.9400 - val_loss: 11.0082\n",
      "Epoch 256/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.9269 - val_loss: 10.6226\n",
      "Epoch 257/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.9976 - val_loss: 12.9158\n",
      "Epoch 258/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 8.9512 - val_loss: 12.0147\n",
      "Epoch 259/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.9929 - val_loss: 10.9298\n",
      "Epoch 260/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 8.9580 - val_loss: 10.9140\n",
      "Epoch 261/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.7278 - val_loss: 10.2835\n",
      "Epoch 262/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.1355 - val_loss: 11.9562\n",
      "Epoch 263/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.8715 - val_loss: 10.4588\n",
      "Epoch 264/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.7744 - val_loss: 10.2253\n",
      "Epoch 265/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0579 - val_loss: 10.4358\n",
      "Epoch 266/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1548 - val_loss: 11.9240\n",
      "Epoch 267/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.4854 - val_loss: 10.8093\n",
      "Epoch 268/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.6862 - val_loss: 10.5895\n",
      "Epoch 269/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.7503 - val_loss: 10.3975\n",
      "Epoch 270/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5241 - val_loss: 10.8356\n",
      "Epoch 271/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9652 - val_loss: 12.1345\n",
      "Epoch 272/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.3803 - val_loss: 10.8591\n",
      "Epoch 273/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.2785 - val_loss: 11.6243\n",
      "Epoch 274/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.9375 - val_loss: 10.0309\n",
      "Epoch 275/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.6635 - val_loss: 10.7050\n",
      "Epoch 276/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.5110 - val_loss: 10.6280\n",
      "Epoch 277/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.1136 - val_loss: 12.6028\n",
      "Epoch 278/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8536 - val_loss: 11.6880\n",
      "Epoch 279/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7094 - val_loss: 10.2849\n",
      "Epoch 280/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8233 - val_loss: 10.4835\n",
      "Epoch 281/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.4935 - val_loss: 10.9451\n",
      "Epoch 282/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7400 - val_loss: 9.9599\n",
      "Epoch 283/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6403 - val_loss: 10.9573\n",
      "Epoch 284/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 8.6112 - val_loss: 10.2301\n",
      "Epoch 285/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0078 - val_loss: 10.4640\n",
      "Epoch 286/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6780 - val_loss: 10.3553\n",
      "Epoch 287/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.9261 - val_loss: 9.9475\n",
      "Epoch 288/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.9243 - val_loss: 10.3816\n",
      "Epoch 289/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2083 - val_loss: 12.5339\n",
      "Epoch 290/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.3562 - val_loss: 10.7615\n",
      "Epoch 291/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.7021 - val_loss: 10.1222\n",
      "Epoch 292/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8225 - val_loss: 10.7318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 293/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.6128 - val_loss: 10.6045\n",
      "Epoch 294/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8200 - val_loss: 11.7327\n",
      "Epoch 295/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.0188 - val_loss: 10.3574\n",
      "Epoch 296/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.7219 - val_loss: 10.5063\n",
      "Epoch 297/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.1789 - val_loss: 10.5160\n",
      "Epoch 298/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.9410 - val_loss: 10.1723\n",
      "Epoch 299/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.6722 - val_loss: 10.1345\n",
      "Epoch 300/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.6388 - val_loss: 10.1877\n",
      "Epoch 301/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.9230 - val_loss: 10.2065\n",
      "Epoch 302/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8001 - val_loss: 13.2902\n",
      "Epoch 303/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.2130 - val_loss: 11.4827\n",
      "Epoch 304/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.7562 - val_loss: 12.6931\n",
      "Epoch 305/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.8622 - val_loss: 12.8739\n",
      "Epoch 306/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.2264 - val_loss: 11.4095\n",
      "Epoch 307/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.5200 - val_loss: 10.5525\n",
      "Epoch 308/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.8762 - val_loss: 10.4854\n",
      "Epoch 309/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.6741 - val_loss: 9.9366\n",
      "Epoch 310/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4891 - val_loss: 11.7750\n",
      "Epoch 311/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.5271 - val_loss: 13.3787\n",
      "Epoch 312/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1297 - val_loss: 12.2109\n",
      "Epoch 313/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 9.2772 - val_loss: 10.1744\n",
      "Epoch 314/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.7053 - val_loss: 12.1329\n",
      "Epoch 315/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.8399 - val_loss: 11.0247\n",
      "Epoch 316/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.7100 - val_loss: 10.5925\n",
      "Epoch 317/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.8572 - val_loss: 10.3226\n",
      "Epoch 318/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8656 - val_loss: 10.1206\n",
      "Epoch 319/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.7505 - val_loss: 9.7853\n",
      "Epoch 320/1000\n",
      "1052/1052 [==============================] - 0s 108us/step - loss: 8.6760 - val_loss: 10.2818\n",
      "Epoch 321/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.5110 - val_loss: 9.8215\n",
      "Epoch 322/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.7387 - val_loss: 10.1866\n",
      "Epoch 323/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.8291 - val_loss: 11.3307\n",
      "Epoch 324/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.2705 - val_loss: 10.4574\n",
      "Epoch 325/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6477 - val_loss: 10.4704\n",
      "Epoch 326/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6173 - val_loss: 9.9970\n",
      "Epoch 327/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5504 - val_loss: 11.1359\n",
      "Epoch 328/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 8.7782 - val_loss: 10.3185\n",
      "Epoch 329/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.8407 - val_loss: 11.2975\n",
      "Epoch 330/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 8.3786 - val_loss: 10.0209\n",
      "Epoch 331/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 9.0062 - val_loss: 10.4958\n",
      "Epoch 332/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 9.1534 - val_loss: 9.8196\n",
      "Epoch 333/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.6746 - val_loss: 10.4156\n",
      "Epoch 334/1000\n",
      "1052/1052 [==============================] - 0s 108us/step - loss: 8.7398 - val_loss: 9.7791\n",
      "Epoch 335/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.8649 - val_loss: 11.4937\n",
      "Epoch 336/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.0597 - val_loss: 10.2169\n",
      "Epoch 337/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.6683 - val_loss: 11.0699\n",
      "Epoch 338/1000\n",
      "1052/1052 [==============================] - 0s 109us/step - loss: 8.8279 - val_loss: 12.0831\n",
      "Epoch 339/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.0483 - val_loss: 9.8228\n",
      "Epoch 340/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.7627 - val_loss: 9.9859\n",
      "Epoch 341/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 8.7005 - val_loss: 10.6287\n",
      "Epoch 342/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.0198 - val_loss: 10.1374\n",
      "Epoch 343/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.3591 - val_loss: 9.8913\n",
      "Epoch 344/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7187 - val_loss: 9.8030\n",
      "Epoch 345/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4737 - val_loss: 11.4236\n",
      "Epoch 346/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5744 - val_loss: 13.3593\n",
      "Epoch 347/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.0346 - val_loss: 10.8528\n",
      "Epoch 348/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.6255 - val_loss: 10.5993\n",
      "Epoch 349/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.7595 - val_loss: 10.0652\n",
      "Epoch 350/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.7422 - val_loss: 10.5476\n",
      "Epoch 351/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.7176 - val_loss: 10.3683\n",
      "Epoch 352/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9752 - val_loss: 9.9284\n",
      "Epoch 353/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5273 - val_loss: 11.1124\n",
      "Epoch 354/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.4687 - val_loss: 10.7516\n",
      "Epoch 355/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.1537 - val_loss: 11.2434\n",
      "Epoch 356/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.6488 - val_loss: 10.8247\n",
      "Epoch 357/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.7236 - val_loss: 10.0949\n",
      "Epoch 358/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.8416 - val_loss: 11.6049\n",
      "Epoch 359/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.5366 - val_loss: 9.7724\n",
      "Epoch 360/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.7054 - val_loss: 9.9180\n",
      "Epoch 361/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.7629 - val_loss: 10.8564\n",
      "Epoch 362/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.5275 - val_loss: 11.4087\n",
      "Epoch 363/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4147 - val_loss: 10.2101\n",
      "Epoch 364/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.4546 - val_loss: 12.8640\n",
      "Epoch 365/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6500 - val_loss: 9.9581\n",
      "Epoch 366/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.9037 - val_loss: 10.1188\n",
      "Epoch 367/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.7562 - val_loss: 9.9416\n",
      "Epoch 368/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7401 - val_loss: 12.1111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 369/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5818 - val_loss: 10.0406\n",
      "Epoch 370/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5274 - val_loss: 10.6513\n",
      "Epoch 371/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.7223 - val_loss: 10.6137\n",
      "Epoch 372/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.6679 - val_loss: 9.8178\n",
      "Epoch 373/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.7214 - val_loss: 9.6695\n",
      "Epoch 374/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.6361 - val_loss: 10.0423\n",
      "Epoch 375/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4907 - val_loss: 11.0449\n",
      "Epoch 376/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.5439 - val_loss: 10.5725\n",
      "Epoch 377/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.4450 - val_loss: 9.9135\n",
      "Epoch 378/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.5791 - val_loss: 9.5009\n",
      "Epoch 379/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9051 - val_loss: 11.8536\n",
      "Epoch 380/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.9892 - val_loss: 13.8367\n",
      "Epoch 381/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1514 - val_loss: 9.6099\n",
      "Epoch 382/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.1028 - val_loss: 10.9793\n",
      "Epoch 383/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.9411 - val_loss: 9.9622\n",
      "Epoch 384/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7087 - val_loss: 11.5619\n",
      "Epoch 385/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.6018 - val_loss: 10.6450\n",
      "Epoch 386/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.0839 - val_loss: 11.9767\n",
      "Epoch 387/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6369 - val_loss: 10.2230\n",
      "Epoch 388/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.7096 - val_loss: 10.1576\n",
      "Epoch 389/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.6668 - val_loss: 12.0580\n",
      "Epoch 390/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3275 - val_loss: 9.8112\n",
      "Epoch 391/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1931 - val_loss: 10.3327\n",
      "Epoch 392/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5918 - val_loss: 10.0667\n",
      "Epoch 393/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.1167 - val_loss: 10.4285\n",
      "Epoch 394/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.5076 - val_loss: 10.4644\n",
      "Epoch 395/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1286 - val_loss: 13.6518\n",
      "Epoch 396/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1776 - val_loss: 10.9013\n",
      "Epoch 397/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.5296 - val_loss: 11.1761\n",
      "Epoch 398/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3914 - val_loss: 10.2915\n",
      "Epoch 399/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9477 - val_loss: 10.0130\n",
      "Epoch 400/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0328 - val_loss: 10.3227\n",
      "Epoch 401/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.4152 - val_loss: 9.8341\n",
      "Epoch 402/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2554 - val_loss: 10.3383\n",
      "Epoch 403/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8022 - val_loss: 10.9866\n",
      "Epoch 404/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8273 - val_loss: 10.5645\n",
      "Epoch 405/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.2277 - val_loss: 10.9464\n",
      "Epoch 406/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.1973 - val_loss: 9.5866\n",
      "Epoch 407/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.7960 - val_loss: 9.6478\n",
      "Epoch 408/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.2356 - val_loss: 9.5259\n",
      "Epoch 409/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3207 - val_loss: 11.0265\n",
      "Epoch 410/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2035 - val_loss: 9.7004\n",
      "Epoch 411/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3405 - val_loss: 10.8016\n",
      "Epoch 412/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5007 - val_loss: 12.3988\n",
      "Epoch 413/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.6277 - val_loss: 10.0514\n",
      "Epoch 414/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.5794 - val_loss: 11.9676\n",
      "Epoch 415/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.3509 - val_loss: 9.4982\n",
      "Epoch 416/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.3797 - val_loss: 9.6659\n",
      "Epoch 417/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.4724 - val_loss: 11.0231\n",
      "Epoch 418/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.5245 - val_loss: 9.7312\n",
      "Epoch 419/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.8260 - val_loss: 10.3328\n",
      "Epoch 420/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.3219 - val_loss: 10.8115\n",
      "Epoch 421/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.6876 - val_loss: 11.1070\n",
      "Epoch 422/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.5228 - val_loss: 10.0044\n",
      "Epoch 423/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.3740 - val_loss: 9.5952\n",
      "Epoch 424/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 8.6725 - val_loss: 11.0797\n",
      "Epoch 425/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2926 - val_loss: 10.7131\n",
      "Epoch 426/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.2622 - val_loss: 10.4043\n",
      "Epoch 427/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.5853 - val_loss: 10.4597\n",
      "Epoch 428/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 9.0607 - val_loss: 10.2314\n",
      "Epoch 429/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.5379 - val_loss: 10.2875\n",
      "Epoch 430/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6005 - val_loss: 9.7643\n",
      "Epoch 431/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5843 - val_loss: 11.3510\n",
      "Epoch 432/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.6942 - val_loss: 11.5961\n",
      "Epoch 433/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.3783 - val_loss: 9.6596\n",
      "Epoch 434/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 8.3652 - val_loss: 9.4601\n",
      "Epoch 435/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 8.4905 - val_loss: 10.0034\n",
      "Epoch 436/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.1828 - val_loss: 9.6328\n",
      "Epoch 437/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.3646 - val_loss: 11.7871\n",
      "Epoch 438/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3347 - val_loss: 10.0548\n",
      "Epoch 439/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7914 - val_loss: 10.0864\n",
      "Epoch 440/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.6143 - val_loss: 9.8512\n",
      "Epoch 441/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.3592 - val_loss: 9.9181\n",
      "Epoch 442/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4788 - val_loss: 12.9013\n",
      "Epoch 443/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.0384 - val_loss: 10.2980\n",
      "Epoch 444/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2820 - val_loss: 9.5576\n",
      "Epoch 445/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.7823 - val_loss: 9.7112\n",
      "Epoch 446/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9126 - val_loss: 13.2703\n",
      "Epoch 447/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0414 - val_loss: 9.7939\n",
      "Epoch 448/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.6168 - val_loss: 9.8060\n",
      "Epoch 449/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.4611 - val_loss: 10.0990\n",
      "Epoch 450/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6580 - val_loss: 9.3034\n",
      "Epoch 451/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.3933 - val_loss: 9.9213\n",
      "Epoch 452/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.7235 - val_loss: 10.3888\n",
      "Epoch 453/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2755 - val_loss: 12.3757\n",
      "Epoch 454/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.5871 - val_loss: 10.2666\n",
      "Epoch 455/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 8.8684 - val_loss: 10.5893\n",
      "Epoch 456/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.0240 - val_loss: 10.4575\n",
      "Epoch 457/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.5777 - val_loss: 9.4532\n",
      "Epoch 458/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.5437 - val_loss: 12.8860\n",
      "Epoch 459/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.4701 - val_loss: 10.0904\n",
      "Epoch 460/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.6932 - val_loss: 9.5383\n",
      "Epoch 461/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.6165 - val_loss: 9.8970\n",
      "Epoch 462/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.2265 - val_loss: 10.7336\n",
      "Epoch 463/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5112 - val_loss: 9.9241\n",
      "Epoch 464/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.3446 - val_loss: 10.0349\n",
      "Epoch 465/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5093 - val_loss: 9.3667\n",
      "Epoch 466/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3904 - val_loss: 10.4909\n",
      "Epoch 467/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.9044 - val_loss: 9.8562\n",
      "Epoch 468/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.8795 - val_loss: 9.8728\n",
      "Epoch 469/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2979 - val_loss: 9.7063\n",
      "Epoch 470/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.4402 - val_loss: 9.7021\n",
      "Epoch 471/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3983 - val_loss: 9.8879\n",
      "Epoch 472/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.7176 - val_loss: 11.3775\n",
      "Epoch 473/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 8.939 - 0s 78us/step - loss: 8.5821 - val_loss: 9.6504\n",
      "Epoch 474/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.4258 - val_loss: 9.3430\n",
      "Epoch 475/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4878 - val_loss: 9.5651\n",
      "Epoch 476/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.3204 - val_loss: 9.5463\n",
      "Epoch 477/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5120 - val_loss: 9.5897\n",
      "Epoch 478/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.5010 - val_loss: 10.4053\n",
      "Epoch 479/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.5436 - val_loss: 10.4666\n",
      "Epoch 480/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0570 - val_loss: 9.4199\n",
      "Epoch 481/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2522 - val_loss: 9.7102\n",
      "Epoch 482/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5074 - val_loss: 10.3944\n",
      "Epoch 483/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3922 - val_loss: 9.4463\n",
      "Epoch 484/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4030 - val_loss: 9.7245\n",
      "Epoch 485/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.2535 - val_loss: 9.9940\n",
      "Epoch 486/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.2136 - val_loss: 9.6522\n",
      "Epoch 487/1000\n",
      "1052/1052 [==============================] - 0s 108us/step - loss: 8.6892 - val_loss: 12.8648\n",
      "Epoch 488/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 8.9280 - val_loss: 10.9799\n",
      "Epoch 489/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.4723 - val_loss: 9.5109\n",
      "Epoch 490/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 8.2720 - val_loss: 9.5612\n",
      "Epoch 491/1000\n",
      "1052/1052 [==============================] - 0s 115us/step - loss: 8.9529 - val_loss: 10.5870\n",
      "Epoch 492/1000\n",
      "1052/1052 [==============================] - 0s 129us/step - loss: 8.5615 - val_loss: 10.4210\n",
      "Epoch 493/1000\n",
      "1052/1052 [==============================] - 0s 129us/step - loss: 8.8424 - val_loss: 12.6122\n",
      "Epoch 494/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 9.1546 - val_loss: 9.9461\n",
      "Epoch 495/1000\n",
      "1052/1052 [==============================] - 0s 111us/step - loss: 8.9300 - val_loss: 9.4860\n",
      "Epoch 496/1000\n",
      "1052/1052 [==============================] - 0s 114us/step - loss: 8.6656 - val_loss: 9.8560\n",
      "Epoch 497/1000\n",
      "1052/1052 [==============================] - 0s 109us/step - loss: 8.5600 - val_loss: 9.7719\n",
      "Epoch 498/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.8718 - val_loss: 9.9360\n",
      "Epoch 499/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7225 - val_loss: 11.0859\n",
      "Epoch 500/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4437 - val_loss: 10.1347\n",
      "Epoch 501/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1948 - val_loss: 9.9019\n",
      "Epoch 502/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1156 - val_loss: 11.1951\n",
      "Epoch 503/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.7155 - val_loss: 10.7481\n",
      "Epoch 504/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3666 - val_loss: 9.3618\n",
      "Epoch 505/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1522 - val_loss: 12.8401\n",
      "Epoch 506/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.9068 - val_loss: 11.2714\n",
      "Epoch 507/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7521 - val_loss: 10.2169\n",
      "Epoch 508/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.0406 - val_loss: 10.2914\n",
      "Epoch 509/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.5354 - val_loss: 9.2432\n",
      "Epoch 510/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.7263 - val_loss: 9.9914\n",
      "Epoch 511/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.1915 - val_loss: 10.0778\n",
      "Epoch 512/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.6924 - val_loss: 9.4241\n",
      "Epoch 513/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.7318 - val_loss: 12.6367\n",
      "Epoch 514/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.6965 - val_loss: 10.7990\n",
      "Epoch 515/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.6422 - val_loss: 10.9318\n",
      "Epoch 516/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.5830 - val_loss: 10.1742\n",
      "Epoch 517/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.5372 - val_loss: 10.5034\n",
      "Epoch 518/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.4187 - val_loss: 11.3112\n",
      "Epoch 519/1000\n",
      "1052/1052 [==============================] - 0s 158us/step - loss: 8.6996 - val_loss: 9.9061\n",
      "Epoch 520/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 8.6953 - val_loss: 17.1844\n",
      "Epoch 521/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 107us/step - loss: 9.4641 - val_loss: 9.8792\n",
      "Epoch 522/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 8.2980 - val_loss: 10.0922\n",
      "Epoch 523/1000\n",
      "1052/1052 [==============================] - 0s 113us/step - loss: 8.4192 - val_loss: 9.2446\n",
      "Epoch 524/1000\n",
      "1052/1052 [==============================] - 0s 113us/step - loss: 8.1037 - val_loss: 9.8793\n",
      "Epoch 525/1000\n",
      "1052/1052 [==============================] - 0s 108us/step - loss: 8.8315 - val_loss: 11.8610\n",
      "Epoch 526/1000\n",
      "1052/1052 [==============================] - 0s 116us/step - loss: 8.2666 - val_loss: 9.6604\n",
      "Epoch 527/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 8.3862 - val_loss: 10.1212\n",
      "Epoch 528/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2633 - val_loss: 12.1885\n",
      "Epoch 529/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4315 - val_loss: 10.0978\n",
      "Epoch 530/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3184 - val_loss: 9.2738\n",
      "Epoch 531/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.7450 - val_loss: 13.2884\n",
      "Epoch 532/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.7471 - val_loss: 9.4233\n",
      "Epoch 533/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3303 - val_loss: 9.6333\n",
      "Epoch 534/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.3515 - val_loss: 9.5669\n",
      "Epoch 535/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 8.7437 - val_loss: 10.4084\n",
      "Epoch 536/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 8.4809 - val_loss: 9.8008\n",
      "Epoch 537/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4062 - val_loss: 9.2926\n",
      "Epoch 538/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.4134 - val_loss: 9.3230\n",
      "Epoch 539/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 8.2310 - val_loss: 9.5593\n",
      "Epoch 540/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.4119 - val_loss: 11.0945\n",
      "Epoch 541/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.4695 - val_loss: 12.4202\n",
      "Epoch 542/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.2411 - val_loss: 9.5782\n",
      "Epoch 543/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.3511 - val_loss: 10.6105\n",
      "Epoch 544/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.6530 - val_loss: 10.1938\n",
      "Epoch 545/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.6938 - val_loss: 9.1190\n",
      "Epoch 546/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 8.4758 - val_loss: 9.2133\n",
      "Epoch 547/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.4456 - val_loss: 9.6056\n",
      "Epoch 548/1000\n",
      "1052/1052 [==============================] - 0s 108us/step - loss: 8.7060 - val_loss: 11.1778\n",
      "Epoch 549/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.4456 - val_loss: 9.4042\n",
      "Epoch 550/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.2214 - val_loss: 9.0550\n",
      "Epoch 551/1000\n",
      "1052/1052 [==============================] - 0s 108us/step - loss: 9.0920 - val_loss: 10.6090\n",
      "Epoch 552/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.6835 - val_loss: 9.3559\n",
      "Epoch 553/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.4499 - val_loss: 9.7062\n",
      "Epoch 554/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 8.3072 - val_loss: 9.2374\n",
      "Epoch 555/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 8.4026 - val_loss: 9.5491\n",
      "Epoch 556/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.4037 - val_loss: 9.5462\n",
      "Epoch 557/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 8.1803 - val_loss: 9.9881\n",
      "Epoch 558/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 8.1538 - val_loss: 10.1685\n",
      "Epoch 559/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 8.5918 - val_loss: 9.7492\n",
      "Epoch 560/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 8.2670 - val_loss: 11.1021\n",
      "Epoch 561/1000\n",
      "1052/1052 [==============================] - 0s 108us/step - loss: 8.6396 - val_loss: 10.1590\n",
      "Epoch 562/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.3162 - val_loss: 12.2375\n",
      "Epoch 563/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 8.8905 - val_loss: 8.9221\n",
      "Epoch 564/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.5755 - val_loss: 9.5227\n",
      "Epoch 565/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.9555 - val_loss: 9.4975\n",
      "Epoch 566/1000\n",
      "1052/1052 [==============================] - 0s 111us/step - loss: 8.1537 - val_loss: 9.5141\n",
      "Epoch 567/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 8.6475 - val_loss: 11.6455\n",
      "Epoch 568/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.5210 - val_loss: 9.6601\n",
      "Epoch 569/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.5679 - val_loss: 11.3341\n",
      "Epoch 570/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.6881 - val_loss: 12.8823\n",
      "Epoch 571/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.6135 - val_loss: 9.1430\n",
      "Epoch 572/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2008 - val_loss: 9.3160\n",
      "Epoch 573/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.7423 - val_loss: 9.3288\n",
      "Epoch 574/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 8.2899 - val_loss: 9.8859\n",
      "Epoch 575/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.5346 - val_loss: 11.3260\n",
      "Epoch 576/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 8.5012 - val_loss: 9.8190\n",
      "Epoch 577/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.5137 - val_loss: 10.6954\n",
      "Epoch 578/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6094 - val_loss: 10.1714\n",
      "Epoch 579/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.4768 - val_loss: 10.6749\n",
      "Epoch 580/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 8.3612 - val_loss: 9.9318\n",
      "Epoch 581/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 8.2410 - val_loss: 11.0653\n",
      "Epoch 582/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 8.3789 - val_loss: 9.9797\n",
      "Epoch 583/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 8.3415 - val_loss: 9.3107\n",
      "Epoch 584/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.3890 - val_loss: 9.3189\n",
      "Epoch 585/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 8.8072 - val_loss: 9.7468\n",
      "Epoch 586/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 8.8029 - val_loss: 10.2071\n",
      "Epoch 587/1000\n",
      "1052/1052 [==============================] - 0s 109us/step - loss: 8.2455 - val_loss: 9.3741\n",
      "Epoch 588/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 8.4587 - val_loss: 9.1718\n",
      "Epoch 589/1000\n",
      "1052/1052 [==============================] - 0s 113us/step - loss: 8.4777 - val_loss: 10.2822\n",
      "Epoch 590/1000\n",
      "1052/1052 [==============================] - 0s 121us/step - loss: 8.2429 - val_loss: 10.1074\n",
      "Epoch 591/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2382 - val_loss: 9.2204\n",
      "Epoch 592/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2749 - val_loss: 9.0472\n",
      "Epoch 593/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.4668 - val_loss: 9.4413\n",
      "Epoch 594/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3588 - val_loss: 9.7186\n",
      "Epoch 595/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2748 - val_loss: 12.2627\n",
      "Epoch 596/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.4077 - val_loss: 9.3022\n",
      "Epoch 597/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1313 - val_loss: 9.2048\n",
      "Epoch 598/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.4941 - val_loss: 11.2379\n",
      "Epoch 599/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.9141 - val_loss: 10.9841\n",
      "Epoch 600/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.5595 - val_loss: 9.7660\n",
      "Epoch 601/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.0672 - val_loss: 9.3423\n",
      "Epoch 602/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 8.2168 - val_loss: 9.6841\n",
      "Epoch 603/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2494 - val_loss: 9.1591\n",
      "Epoch 604/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.4948 - val_loss: 9.6594\n",
      "Epoch 605/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.8239 - val_loss: 9.6128\n",
      "Epoch 606/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6037 - val_loss: 10.1531\n",
      "Epoch 607/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.8963 - val_loss: 10.0130\n",
      "Epoch 608/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.6802 - val_loss: 9.4967\n",
      "Epoch 609/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0601 - val_loss: 9.3503\n",
      "Epoch 610/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3288 - val_loss: 8.9775\n",
      "Epoch 611/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2977 - val_loss: 9.1316\n",
      "Epoch 612/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2689 - val_loss: 9.8203\n",
      "Epoch 613/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2820 - val_loss: 9.8675\n",
      "Epoch 614/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3388 - val_loss: 9.2597\n",
      "Epoch 615/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8294 - val_loss: 9.5684\n",
      "Epoch 616/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7160 - val_loss: 9.6804\n",
      "Epoch 617/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1521 - val_loss: 11.1045\n",
      "Epoch 618/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8920 - val_loss: 11.0742\n",
      "Epoch 619/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8616 - val_loss: 10.2265\n",
      "Epoch 620/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9882 - val_loss: 10.1097\n",
      "Epoch 621/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.2661 - val_loss: 10.1058\n",
      "Epoch 622/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1778 - val_loss: 9.3393\n",
      "Epoch 623/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3245 - val_loss: 9.7254\n",
      "Epoch 624/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1668 - val_loss: 9.0382\n",
      "Epoch 625/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.2245 - val_loss: 10.1667\n",
      "Epoch 626/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.1314 - val_loss: 10.2448\n",
      "Epoch 627/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.4492 - val_loss: 10.5384\n",
      "Epoch 628/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 8.0279 - val_loss: 10.4601\n",
      "Epoch 629/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.5546 - val_loss: 9.7942\n",
      "Epoch 630/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.9054 - val_loss: 11.2537\n",
      "Epoch 631/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3612 - val_loss: 9.2775\n",
      "Epoch 632/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1199 - val_loss: 9.7628\n",
      "Epoch 633/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.1917 - val_loss: 10.0492\n",
      "Epoch 634/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.5242 - val_loss: 9.4965\n",
      "Epoch 635/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2701 - val_loss: 10.6034\n",
      "Epoch 636/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.5294 - val_loss: 10.2790\n",
      "Epoch 637/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3710 - val_loss: 9.0321\n",
      "Epoch 638/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.2062 - val_loss: 9.4051\n",
      "Epoch 639/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5066 - val_loss: 11.0736\n",
      "Epoch 640/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0163 - val_loss: 9.1669\n",
      "Epoch 641/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.2743 - val_loss: 10.2366\n",
      "Epoch 642/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3521 - val_loss: 8.9612\n",
      "Epoch 643/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3530 - val_loss: 12.0693\n",
      "Epoch 644/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.5776 - val_loss: 8.9055\n",
      "Epoch 645/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.4294 - val_loss: 9.0865\n",
      "Epoch 646/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0601 - val_loss: 9.4925\n",
      "Epoch 647/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.3018 - val_loss: 9.3412\n",
      "Epoch 648/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3164 - val_loss: 9.4334\n",
      "Epoch 649/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.1453 - val_loss: 11.5560\n",
      "Epoch 650/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.5807 - val_loss: 9.8720\n",
      "Epoch 651/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.1750 - val_loss: 10.1218\n",
      "Epoch 652/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3177 - val_loss: 11.8796\n",
      "Epoch 653/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.6938 - val_loss: 9.1572\n",
      "Epoch 654/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3760 - val_loss: 13.1982\n",
      "Epoch 655/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8373 - val_loss: 10.1905\n",
      "Epoch 656/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.1684 - val_loss: 9.6752\n",
      "Epoch 657/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.2251 - val_loss: 13.1417\n",
      "Epoch 658/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7374 - val_loss: 10.6174\n",
      "Epoch 659/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.9312 - val_loss: 11.3477\n",
      "Epoch 660/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.5388 - val_loss: 9.7386\n",
      "Epoch 661/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6592 - val_loss: 9.7726\n",
      "Epoch 662/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2778 - val_loss: 9.0341\n",
      "Epoch 663/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2447 - val_loss: 9.4191\n",
      "Epoch 664/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2110 - val_loss: 9.3209\n",
      "Epoch 665/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3864 - val_loss: 9.3581\n",
      "Epoch 666/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.5405 - val_loss: 10.2892\n",
      "Epoch 667/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0872 - val_loss: 9.4938\n",
      "Epoch 668/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2665 - val_loss: 9.4050\n",
      "Epoch 669/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1597 - val_loss: 9.9580\n",
      "Epoch 670/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.5945 - val_loss: 9.3405\n",
      "Epoch 671/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.2100 - val_loss: 9.3945\n",
      "Epoch 672/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3417 - val_loss: 9.8092\n",
      "Epoch 673/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1961 - val_loss: 9.8125\n",
      "Epoch 674/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.4242 - val_loss: 9.5708\n",
      "Epoch 675/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.8062 - val_loss: 11.7674\n",
      "Epoch 676/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6720 - val_loss: 11.7380\n",
      "Epoch 677/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3240 - val_loss: 9.6255\n",
      "Epoch 678/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4178 - val_loss: 9.3161\n",
      "Epoch 679/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.2443 - val_loss: 9.3348\n",
      "Epoch 680/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1347 - val_loss: 9.1874\n",
      "Epoch 681/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.0238 - val_loss: 9.8856\n",
      "Epoch 682/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6351 - val_loss: 11.5380\n",
      "Epoch 683/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.5160 - val_loss: 9.7892\n",
      "Epoch 684/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.3313 - val_loss: 9.4586\n",
      "Epoch 685/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0262 - val_loss: 9.4333\n",
      "Epoch 686/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.2420 - val_loss: 9.3485\n",
      "Epoch 687/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.2260 - val_loss: 10.0304\n",
      "Epoch 688/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.2670 - val_loss: 9.4995\n",
      "Epoch 689/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4934 - val_loss: 9.1429\n",
      "Epoch 690/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.5270 - val_loss: 9.7662\n",
      "Epoch 691/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.0977 - val_loss: 9.4789\n",
      "Epoch 692/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.4502 - val_loss: 9.7626\n",
      "Epoch 693/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1758 - val_loss: 9.0885\n",
      "Epoch 694/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2588 - val_loss: 9.4876\n",
      "Epoch 695/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.0334 - val_loss: 11.1232\n",
      "Epoch 696/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3024 - val_loss: 9.9856\n",
      "Epoch 697/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2839 - val_loss: 9.4210\n",
      "Epoch 698/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.2311 - val_loss: 10.2562\n",
      "Epoch 699/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2426 - val_loss: 11.7096\n",
      "Epoch 700/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1922 - val_loss: 11.3949\n",
      "Epoch 701/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3593 - val_loss: 9.3806\n",
      "Epoch 702/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2773 - val_loss: 10.9271\n",
      "Epoch 703/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.3976 - val_loss: 11.3423\n",
      "Epoch 704/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.1980 - val_loss: 13.5208\n",
      "Epoch 705/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8092 - val_loss: 10.2444\n",
      "Epoch 706/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2576 - val_loss: 9.6529\n",
      "Epoch 707/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7659 - val_loss: 12.6959\n",
      "Epoch 708/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7675 - val_loss: 10.7341\n",
      "Epoch 709/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2649 - val_loss: 9.4018\n",
      "Epoch 710/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.9690 - val_loss: 8.9026\n",
      "Epoch 711/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.7650 - val_loss: 9.4251\n",
      "Epoch 712/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2240 - val_loss: 9.5361\n",
      "Epoch 713/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.0700 - val_loss: 9.7330\n",
      "Epoch 714/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.2382 - val_loss: 10.6442\n",
      "Epoch 715/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.3265 - val_loss: 9.9368\n",
      "Epoch 716/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.3306 - val_loss: 10.0148\n",
      "Epoch 717/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.6608 - val_loss: 9.3136\n",
      "Epoch 718/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.3319 - val_loss: 11.3643\n",
      "Epoch 719/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.4606 - val_loss: 10.1164\n",
      "Epoch 720/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0643 - val_loss: 8.9514\n",
      "Epoch 721/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.4987 - val_loss: 9.6844\n",
      "Epoch 722/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7380 - val_loss: 9.8020\n",
      "Epoch 723/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.4101 - val_loss: 9.5635\n",
      "Epoch 724/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6028 - val_loss: 9.6647\n",
      "Epoch 725/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.6787 - val_loss: 9.4336\n",
      "Epoch 726/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.1054 - val_loss: 9.1353\n",
      "Epoch 727/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3577 - val_loss: 9.9397\n",
      "Epoch 728/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1947 - val_loss: 11.7411\n",
      "Epoch 729/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.0086 - val_loss: 9.5717\n",
      "Epoch 730/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.0142 - val_loss: 9.2914\n",
      "Epoch 731/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.0430 - val_loss: 8.9713\n",
      "Epoch 732/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1005 - val_loss: 9.7599\n",
      "Epoch 733/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0307 - val_loss: 9.8063\n",
      "Epoch 734/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6139 - val_loss: 11.4088\n",
      "Epoch 735/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1574 - val_loss: 9.0510\n",
      "Epoch 736/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.0592 - val_loss: 10.6827\n",
      "Epoch 737/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1625 - val_loss: 9.0470\n",
      "Epoch 738/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.2305 - val_loss: 9.0954\n",
      "Epoch 739/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.8871 - val_loss: 9.1664\n",
      "Epoch 740/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2452 - val_loss: 8.8894\n",
      "Epoch 741/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2039 - val_loss: 9.2789\n",
      "Epoch 742/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.9501 - val_loss: 9.5660\n",
      "Epoch 743/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 8.5793 - val_loss: 9.6384\n",
      "Epoch 744/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.3862 - val_loss: 12.3191\n",
      "Epoch 745/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.7179 - val_loss: 9.3113\n",
      "Epoch 746/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.2940 - val_loss: 9.8265\n",
      "Epoch 747/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.3047 - val_loss: 10.7568\n",
      "Epoch 748/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.1092 - val_loss: 8.9354\n",
      "Epoch 749/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 75us/step - loss: 8.5609 - val_loss: 8.9863\n",
      "Epoch 750/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 8.1214 - val_loss: 10.6584\n",
      "Epoch 751/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.1994 - val_loss: 10.3074\n",
      "Epoch 752/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.1838 - val_loss: 9.0213\n",
      "Epoch 753/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.1948 - val_loss: 9.7516\n",
      "Epoch 754/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.4795 - val_loss: 8.9225\n",
      "Epoch 755/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.0986 - val_loss: 8.8820\n",
      "Epoch 756/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5454 - val_loss: 9.8260\n",
      "Epoch 757/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.0132 - val_loss: 9.7578\n",
      "Epoch 758/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.1345 - val_loss: 9.9354\n",
      "Epoch 759/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 8.4306 - val_loss: 10.0373\n",
      "Epoch 760/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.4364 - val_loss: 9.1307\n",
      "Epoch 761/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.2612 - val_loss: 10.5677\n",
      "Epoch 762/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.3162 - val_loss: 9.3473\n",
      "Epoch 763/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.5576 - val_loss: 9.2345\n",
      "Epoch 764/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4054 - val_loss: 9.3849\n",
      "Epoch 765/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7766 - val_loss: 9.9964\n",
      "Epoch 766/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1062 - val_loss: 9.4992\n",
      "Epoch 767/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0779 - val_loss: 9.4000\n",
      "Epoch 768/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6529 - val_loss: 9.1324\n",
      "Epoch 769/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0353 - val_loss: 9.0702\n",
      "Epoch 770/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.0737 - val_loss: 8.9586\n",
      "Epoch 771/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.8856 - val_loss: 8.9744\n",
      "Epoch 772/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.1463 - val_loss: 11.8353\n",
      "Epoch 773/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.3758 - val_loss: 9.0726\n",
      "Epoch 774/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.7433 - val_loss: 9.6635\n",
      "Epoch 775/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.2091 - val_loss: 8.7988\n",
      "Epoch 776/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1088 - val_loss: 10.0809\n",
      "Epoch 777/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5629 - val_loss: 9.7631\n",
      "Epoch 778/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7808 - val_loss: 11.4500\n",
      "Epoch 779/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2043 - val_loss: 8.9966\n",
      "Epoch 780/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.8065 - val_loss: 9.0710\n",
      "Epoch 781/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1075 - val_loss: 10.3472\n",
      "Epoch 782/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0556 - val_loss: 9.9344\n",
      "Epoch 783/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1988 - val_loss: 8.9375\n",
      "Epoch 784/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9932 - val_loss: 8.8001\n",
      "Epoch 785/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.8534 - val_loss: 9.3042\n",
      "Epoch 786/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.9615 - val_loss: 9.0188\n",
      "Epoch 787/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0090 - val_loss: 10.3053\n",
      "Epoch 788/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5301 - val_loss: 9.2378\n",
      "Epoch 789/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0471 - val_loss: 9.2217\n",
      "Epoch 790/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 8.0827 - val_loss: 9.8416\n",
      "Epoch 791/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 7.9628 - val_loss: 9.2816\n",
      "Epoch 792/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.2218 - val_loss: 11.3510\n",
      "Epoch 793/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.5693 - val_loss: 9.2900\n",
      "Epoch 794/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.3320 - val_loss: 10.7511\n",
      "Epoch 795/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.0179 - val_loss: 10.8253\n",
      "Epoch 796/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1866 - val_loss: 9.8893\n",
      "Epoch 797/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2863 - val_loss: 10.1314\n",
      "Epoch 798/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2428 - val_loss: 9.1190\n",
      "Epoch 799/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3238 - val_loss: 8.9747\n",
      "Epoch 800/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.7736 - val_loss: 10.1320\n",
      "Epoch 801/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.6921 - val_loss: 10.6085\n",
      "Epoch 802/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2377 - val_loss: 9.4113\n",
      "Epoch 803/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2670 - val_loss: 8.8264\n",
      "Epoch 804/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1159 - val_loss: 8.6714\n",
      "Epoch 805/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.8643 - val_loss: 10.1011\n",
      "Epoch 806/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.2128 - val_loss: 10.5717\n",
      "Epoch 807/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.2876 - val_loss: 9.6242\n",
      "Epoch 808/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2156 - val_loss: 9.6898\n",
      "Epoch 809/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.3955 - val_loss: 11.3224\n",
      "Epoch 810/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.0220 - val_loss: 9.1567\n",
      "Epoch 811/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.7988 - val_loss: 9.1962\n",
      "Epoch 812/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0750 - val_loss: 9.2712\n",
      "Epoch 813/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.9824 - val_loss: 9.5828\n",
      "Epoch 814/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.9339 - val_loss: 9.0274\n",
      "Epoch 815/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.2510 - val_loss: 8.9493\n",
      "Epoch 816/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.9250 - val_loss: 9.0097\n",
      "Epoch 817/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.0293 - val_loss: 9.6697\n",
      "Epoch 818/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.0335 - val_loss: 9.4240\n",
      "Epoch 819/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.1778 - val_loss: 11.2787\n",
      "Epoch 820/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2715 - val_loss: 9.4063\n",
      "Epoch 821/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.8992 - val_loss: 10.0865\n",
      "Epoch 822/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2443 - val_loss: 9.7241\n",
      "Epoch 823/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2578 - val_loss: 10.2157\n",
      "Epoch 824/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.5411 - val_loss: 9.1850\n",
      "Epoch 825/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0806 - val_loss: 9.2065\n",
      "Epoch 826/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1415 - val_loss: 10.3894\n",
      "Epoch 827/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3565 - val_loss: 10.1855\n",
      "Epoch 828/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1808 - val_loss: 8.5742\n",
      "Epoch 829/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.2537 - val_loss: 9.7198\n",
      "Epoch 830/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 8.7759 - val_loss: 12.1050\n",
      "Epoch 831/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 7.9688 - val_loss: 8.9365\n",
      "Epoch 832/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5819 - val_loss: 9.1107\n",
      "Epoch 833/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7929 - val_loss: 9.4799\n",
      "Epoch 834/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1346 - val_loss: 9.1743\n",
      "Epoch 835/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.1131 - val_loss: 9.3912\n",
      "Epoch 836/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2895 - val_loss: 9.5717\n",
      "Epoch 837/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.8272 - val_loss: 9.2683\n",
      "Epoch 838/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.5387 - val_loss: 9.3784\n",
      "Epoch 839/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1494 - val_loss: 9.0422\n",
      "Epoch 840/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.4567 - val_loss: 8.9670\n",
      "Epoch 841/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1832 - val_loss: 10.8599\n",
      "Epoch 842/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2198 - val_loss: 9.6930\n",
      "Epoch 843/1000\n",
      "1052/1052 [==============================] - 0s 135us/step - loss: 8.4685 - val_loss: 9.0460\n",
      "Epoch 844/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.4033 - val_loss: 9.3754\n",
      "Epoch 845/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 8.0141 - val_loss: 8.9676\n",
      "Epoch 846/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.9959 - val_loss: 9.0894\n",
      "Epoch 847/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9148 - val_loss: 8.9610\n",
      "Epoch 848/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2363 - val_loss: 9.1935\n",
      "Epoch 849/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.9547 - val_loss: 8.6221\n",
      "Epoch 850/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.1854 - val_loss: 9.7287\n",
      "Epoch 851/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.9327 - val_loss: 8.8108\n",
      "Epoch 852/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9923 - val_loss: 10.0316\n",
      "Epoch 853/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2504 - val_loss: 8.7252\n",
      "Epoch 854/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0363 - val_loss: 9.8253\n",
      "Epoch 855/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9580 - val_loss: 9.9170\n",
      "Epoch 856/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.9631 - val_loss: 9.4178\n",
      "Epoch 857/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.0052 - val_loss: 8.8715\n",
      "Epoch 858/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.9565 - val_loss: 10.4066\n",
      "Epoch 859/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.9595 - val_loss: 9.3410\n",
      "Epoch 860/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.8729 - val_loss: 9.3061\n",
      "Epoch 861/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.5531 - val_loss: 10.5986\n",
      "Epoch 862/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3653 - val_loss: 9.1846\n",
      "Epoch 863/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.8172 - val_loss: 9.3310\n",
      "Epoch 864/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0813 - val_loss: 8.9419\n",
      "Epoch 865/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0064 - val_loss: 8.6087\n",
      "Epoch 866/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3310 - val_loss: 8.9665\n",
      "Epoch 867/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2097 - val_loss: 9.3122\n",
      "Epoch 868/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.3252 - val_loss: 9.3199\n",
      "Epoch 869/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1256 - val_loss: 9.3022\n",
      "Epoch 870/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.7537 - val_loss: 11.4984\n",
      "Epoch 871/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.5321 - val_loss: 8.8639\n",
      "Epoch 872/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 8.4110 - val_loss: 8.7941\n",
      "Epoch 873/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.0311 - val_loss: 9.2439\n",
      "Epoch 874/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.3990 - val_loss: 8.8838\n",
      "Epoch 875/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9050 - val_loss: 8.8938\n",
      "Epoch 876/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.0217 - val_loss: 8.4664\n",
      "Epoch 877/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.9577 - val_loss: 8.5309\n",
      "Epoch 878/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.9914 - val_loss: 8.7864\n",
      "Epoch 879/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1629 - val_loss: 8.9008\n",
      "Epoch 880/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3612 - val_loss: 8.7985\n",
      "Epoch 881/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.2630 - val_loss: 10.2893\n",
      "Epoch 882/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.8239 - val_loss: 9.5912\n",
      "Epoch 883/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.8976 - val_loss: 8.9188\n",
      "Epoch 884/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.0290 - val_loss: 8.7060\n",
      "Epoch 885/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.9698 - val_loss: 8.8671\n",
      "Epoch 886/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0967 - val_loss: 8.4708\n",
      "Epoch 887/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0099 - val_loss: 9.2168\n",
      "Epoch 888/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.8244 - val_loss: 8.8379\n",
      "Epoch 889/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.0421 - val_loss: 8.6247\n",
      "Epoch 890/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.9380 - val_loss: 9.0388\n",
      "Epoch 891/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 7.8221 - val_loss: 12.5031\n",
      "Epoch 892/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 8.0624 - val_loss: 8.6755\n",
      "Epoch 893/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.2195 - val_loss: 9.9040\n",
      "Epoch 894/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5288 - val_loss: 8.9806\n",
      "Epoch 895/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1717 - val_loss: 9.0449\n",
      "Epoch 896/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1988 - val_loss: 8.7406\n",
      "Epoch 897/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.7373 - val_loss: 8.8072\n",
      "Epoch 898/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5373 - val_loss: 8.4565\n",
      "Epoch 899/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2899 - val_loss: 9.5322\n",
      "Epoch 900/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.6388 - val_loss: 9.0156\n",
      "Epoch 901/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.1402 - val_loss: 9.2139\n",
      "Epoch 902/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.1058 - val_loss: 9.9899\n",
      "Epoch 903/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0396 - val_loss: 10.2065\n",
      "Epoch 904/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.2595 - val_loss: 9.0259\n",
      "Epoch 905/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1155 - val_loss: 8.9287\n",
      "Epoch 906/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2253 - val_loss: 8.8436\n",
      "Epoch 907/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.3040 - val_loss: 8.7304\n",
      "Epoch 908/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.8757 - val_loss: 8.7913\n",
      "Epoch 909/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.7159 - val_loss: 8.4473\n",
      "Epoch 910/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4016 - val_loss: 11.0160\n",
      "Epoch 911/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4548 - val_loss: 10.1605\n",
      "Epoch 912/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5100 - val_loss: 8.6142\n",
      "Epoch 913/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.2920 - val_loss: 9.2678\n",
      "Epoch 914/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0377 - val_loss: 8.6974\n",
      "Epoch 915/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.7286 - val_loss: 8.6709\n",
      "Epoch 916/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9205 - val_loss: 8.9166\n",
      "Epoch 917/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.0270 - val_loss: 9.0444\n",
      "Epoch 918/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.8264 - val_loss: 10.2645\n",
      "Epoch 919/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.9506 - val_loss: 8.3992\n",
      "Epoch 920/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1048 - val_loss: 8.8593\n",
      "Epoch 921/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 8.1766 - val_loss: 8.6890\n",
      "Epoch 922/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.0182 - val_loss: 8.8111\n",
      "Epoch 923/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.2071 - val_loss: 12.3178\n",
      "Epoch 924/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.8576 - val_loss: 8.7029\n",
      "Epoch 925/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.8155 - val_loss: 9.0338\n",
      "Epoch 926/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.9792 - val_loss: 9.3079\n",
      "Epoch 927/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 7.9276 - val_loss: 8.5761\n",
      "Epoch 928/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.9723 - val_loss: 9.1350\n",
      "Epoch 929/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1280 - val_loss: 9.1141\n",
      "Epoch 930/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.2963 - val_loss: 10.3471\n",
      "Epoch 931/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.5488 - val_loss: 8.6010\n",
      "Epoch 932/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.3785 - val_loss: 9.7525\n",
      "Epoch 933/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.4802 - val_loss: 8.4905\n",
      "Epoch 934/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9210 - val_loss: 8.9185\n",
      "Epoch 935/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9214 - val_loss: 8.4679\n",
      "Epoch 936/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.0222 - val_loss: 10.1012\n",
      "Epoch 937/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0331 - val_loss: 9.3051\n",
      "Epoch 938/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.0435 - val_loss: 8.5629\n",
      "Epoch 939/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.9035 - val_loss: 8.5348\n",
      "Epoch 940/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.0736 - val_loss: 9.0895\n",
      "Epoch 941/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1357 - val_loss: 8.9963\n",
      "Epoch 942/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.0841 - val_loss: 11.4490\n",
      "Epoch 943/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0677 - val_loss: 9.2506\n",
      "Epoch 944/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.9670 - val_loss: 8.8458\n",
      "Epoch 945/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4662 - val_loss: 8.8021\n",
      "Epoch 946/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.9811 - val_loss: 8.7947\n",
      "Epoch 947/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0992 - val_loss: 10.0162\n",
      "Epoch 948/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.0612 - val_loss: 8.6592\n",
      "Epoch 949/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1190 - val_loss: 9.0163\n",
      "Epoch 950/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1004 - val_loss: 10.8987\n",
      "Epoch 951/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9254 - val_loss: 8.6855\n",
      "Epoch 952/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2349 - val_loss: 8.5892\n",
      "Epoch 953/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.7808 - val_loss: 8.5282\n",
      "Epoch 954/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.0217 - val_loss: 8.3800\n",
      "Epoch 955/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.3605 - val_loss: 8.6583\n",
      "Epoch 956/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.8603 - val_loss: 9.2566\n",
      "Epoch 957/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.0236 - val_loss: 9.9745\n",
      "Epoch 958/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 7.7635 - val_loss: 8.4006\n",
      "Epoch 959/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.9708 - val_loss: 8.7648\n",
      "Epoch 960/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3041 - val_loss: 8.8130\n",
      "Epoch 961/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.5779 - val_loss: 9.2454\n",
      "Epoch 962/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.8990 - val_loss: 9.1332\n",
      "Epoch 963/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.0689 - val_loss: 9.6725\n",
      "Epoch 964/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.2652 - val_loss: 9.5816\n",
      "Epoch 965/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.8391 - val_loss: 8.5808\n",
      "Epoch 966/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 8.2404 - val_loss: 9.2809\n",
      "Epoch 967/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.0063 - val_loss: 9.5355\n",
      "Epoch 968/1000\n",
      "1052/1052 [==============================] - 0s 112us/step - loss: 8.3748 - val_loss: 9.3827\n",
      "Epoch 969/1000\n",
      "1052/1052 [==============================] - 0s 125us/step - loss: 7.6513 - val_loss: 8.5052\n",
      "Epoch 970/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.0246 - val_loss: 8.9569\n",
      "Epoch 971/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2401 - val_loss: 8.6950\n",
      "Epoch 972/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 7.9582 - val_loss: 8.5760\n",
      "Epoch 973/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.7748 - val_loss: 9.3102\n",
      "Epoch 974/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.1581 - val_loss: 8.5317\n",
      "Epoch 975/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 8.3079 - val_loss: 8.7032\n",
      "Epoch 976/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.8769 - val_loss: 8.6325\n",
      "Epoch 977/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.1935 - val_loss: 10.9166\n",
      "Epoch 978/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.5937 - val_loss: 10.1048\n",
      "Epoch 979/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0924 - val_loss: 8.4497\n",
      "Epoch 980/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.8577 - val_loss: 8.7891\n",
      "Epoch 981/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.8502 - val_loss: 8.6779\n",
      "Epoch 982/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 7.6223 - val_loss: 8.7338\n",
      "Epoch 983/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4895 - val_loss: 9.0511\n",
      "Epoch 984/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.4015 - val_loss: 8.9742\n",
      "Epoch 985/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.3597 - val_loss: 8.5650\n",
      "Epoch 986/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.9256 - val_loss: 8.5098\n",
      "Epoch 987/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 7.9605 - val_loss: 8.6327\n",
      "Epoch 988/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.0634 - val_loss: 8.7470\n",
      "Epoch 989/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.1702 - val_loss: 8.8606\n",
      "Epoch 990/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.9551 - val_loss: 10.6075\n",
      "Epoch 991/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.8865 - val_loss: 8.8326\n",
      "Epoch 992/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0035 - val_loss: 10.0166\n",
      "Epoch 993/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.9803 - val_loss: 9.4254\n",
      "Epoch 994/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.7994 - val_loss: 8.8002\n",
      "Epoch 995/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9791 - val_loss: 11.0733\n",
      "Epoch 996/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.2883 - val_loss: 9.6184\n",
      "Epoch 997/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 7.8086 - val_loss: 8.6180\n",
      "Epoch 998/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.7670 - val_loss: 8.6901\n",
      "Epoch 999/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.9452 - val_loss: 9.2003\n",
      "Epoch 1000/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.0630 - val_loss: 9.3298\n",
      "8.475253636858104\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-3.4302034 , -0.8061793 , -2.179475  , -0.28243268, -3.4678533 ],\n",
       "        [ 0.07419473, -1.8572897 ,  0.4691619 , -0.18793742,  0.13517979],\n",
       "        [ 0.01813842, -2.2457294 ,  0.35899064, -0.42275238, -0.81176287],\n",
       "        [ 0.04165632,  0.3591742 ,  0.01018146,  0.17718554,  0.13762471],\n",
       "        [-2.4569123 ,  0.83139926, -0.30249998, -0.37302366, -0.2756122 ]],\n",
       "       dtype=float32),\n",
       " array([-4.873136  , -1.092576  , -1.3773726 ,  0.67471004, -4.6214347 ],\n",
       "       dtype=float32),\n",
       " array([[-5.8510274e-01, -1.7874317e+00, -1.0559667e+00, -1.5869122e+00,\n",
       "          1.0325084e+00, -1.0920452e+00,  1.3409933e+00, -1.3368695e+00,\n",
       "          1.7452401e+00, -1.1981992e+00,  6.7222965e-01, -1.6194640e+00,\n",
       "          1.3226418e+00,  7.4678904e-01, -1.6411501e+00],\n",
       "        [ 4.4768420e-01, -9.2916481e-02,  6.0430057e-02,  5.5874336e-01,\n",
       "          4.0502824e-02,  3.7706462e-01,  3.5663873e-02, -1.6109066e-01,\n",
       "         -1.9389254e-01,  7.0198953e-01, -2.9571411e-01, -9.8940350e-02,\n",
       "         -1.6931999e-01, -5.4016858e-01,  6.4992899e-01],\n",
       "        [ 4.4212931e-01,  7.9179430e-01,  8.3487618e-01,  5.5848980e-01,\n",
       "         -3.2182932e-01,  2.6493311e-01, -6.5187556e-01,  7.8438860e-01,\n",
       "          2.1968532e-01,  5.0948203e-01, -1.1037261e-01,  2.1812657e-01,\n",
       "         -1.5967123e-01, -8.0586034e-01,  1.3536520e-01],\n",
       "        [-5.4485476e-01,  3.1366462e-01,  1.5927058e-01,  7.1975547e-01,\n",
       "         -4.2398617e-01,  4.9388549e-01, -7.4674982e-01,  8.4738797e-01,\n",
       "         -9.5815295e-01,  5.5486852e-01, -1.8955545e-03,  8.6326164e-01,\n",
       "         -4.0769705e-01,  1.1579530e-01,  7.4890399e-01],\n",
       "        [-9.9845505e-01, -2.3291142e+00, -1.7794383e+00, -2.1314416e+00,\n",
       "          2.3650246e+00, -2.0868914e+00,  1.9587487e+00, -2.3385034e+00,\n",
       "          2.1595125e+00, -2.0897682e+00,  2.0592923e+00, -2.2934556e+00,\n",
       "          1.8036981e+00,  1.9847831e+00, -2.2859666e+00]], dtype=float32),\n",
       " array([ 1.756243 ,  2.3373392,  2.2428448,  2.2705746, -2.29037  ,\n",
       "         2.283367 , -2.2353745,  2.295979 , -2.2582893,  2.2216804,\n",
       "        -2.1481223,  2.22737  , -2.2481365, -2.2334402,  2.2700977],\n",
       "       dtype=float32),\n",
       " array([[ 0.7219516],\n",
       "        [ 1.9021441],\n",
       "        [ 1.5265882],\n",
       "        [ 1.5529672],\n",
       "        [-1.6586524],\n",
       "        [ 1.6163439],\n",
       "        [-1.4702227],\n",
       "        [ 1.6883569],\n",
       "        [-1.6371402],\n",
       "        [ 1.4148477],\n",
       "        [-1.2808709],\n",
       "        [ 1.512352 ],\n",
       "        [-1.5140312],\n",
       "        [-1.4128777],\n",
       "        [ 1.604257 ]], dtype=float32),\n",
       " array([2.5376978], dtype=float32)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_airfoil, history_airfoil, evaluate_airfoil=NN_model_structure_regression_3(X_train_airfoil, X_val_airfoil, Y_train_airfoil, Y_val_airfoil, adam2, 32, 1000, x_test_airfoil, y_test_airfoil)\n",
    "model_airfoil.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_airfoil.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_airfoil_structure3_4th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 121\n",
      "Trainable params: 121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1052 samples, validate on 225 samples\n",
      "Epoch 1/1000\n",
      "1052/1052 [==============================] - 0s 235us/step - loss: 7272.5686 - val_loss: 708.5710\n",
      "Epoch 2/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 190.3240 - val_loss: 50.1986\n",
      "Epoch 3/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 37.0955 - val_loss: 30.3723\n",
      "Epoch 4/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 29.7038 - val_loss: 27.2536\n",
      "Epoch 5/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 25.9682 - val_loss: 26.1282\n",
      "Epoch 6/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 23.3485 - val_loss: 25.8627\n",
      "Epoch 7/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 21.6494 - val_loss: 25.5729\n",
      "Epoch 8/1000\n",
      "1052/1052 [==============================] - 0s 110us/step - loss: 20.1638 - val_loss: 24.8032\n",
      "Epoch 9/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 19.6344 - val_loss: 24.4951\n",
      "Epoch 10/1000\n",
      "1052/1052 [==============================] - 0s 109us/step - loss: 19.1380 - val_loss: 23.8255\n",
      "Epoch 11/1000\n",
      "1052/1052 [==============================] - 0s 114us/step - loss: 18.7492 - val_loss: 23.9995\n",
      "Epoch 12/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 18.5423 - val_loss: 23.4813\n",
      "Epoch 13/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 18.4171 - val_loss: 23.6195\n",
      "Epoch 14/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 18.4604 - val_loss: 23.5702\n",
      "Epoch 15/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 18.0637 - val_loss: 23.1987\n",
      "Epoch 16/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 18.2660 - val_loss: 23.0459\n",
      "Epoch 17/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 17.9135 - val_loss: 23.0096\n",
      "Epoch 18/1000\n",
      "1052/1052 [==============================] - 0s 109us/step - loss: 17.8806 - val_loss: 22.8911\n",
      "Epoch 19/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.9259 - val_loss: 22.9502\n",
      "Epoch 20/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.7701 - val_loss: 22.7064\n",
      "Epoch 21/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 17.7116 - val_loss: 22.7140\n",
      "Epoch 22/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.6816 - val_loss: 22.4928\n",
      "Epoch 23/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.6520 - val_loss: 22.2057\n",
      "Epoch 24/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.4229 - val_loss: 22.4421\n",
      "Epoch 25/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.4525 - val_loss: 22.3510\n",
      "Epoch 26/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.3387 - val_loss: 22.0737\n",
      "Epoch 27/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.3842 - val_loss: 22.2909\n",
      "Epoch 28/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 17.3602 - val_loss: 21.9345\n",
      "Epoch 29/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 17.1236 - val_loss: 22.1679\n",
      "Epoch 30/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.1774 - val_loss: 21.9049\n",
      "Epoch 31/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 17.0896 - val_loss: 21.4992\n",
      "Epoch 32/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 17.0178 - val_loss: 21.1559\n",
      "Epoch 33/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 16.9082 - val_loss: 21.8184\n",
      "Epoch 34/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 16.9830 - val_loss: 21.1412\n",
      "Epoch 35/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 16.7671 - val_loss: 20.8546\n",
      "Epoch 36/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 16.9314 - val_loss: 20.9824\n",
      "Epoch 37/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 16.8627 - val_loss: 20.7587\n",
      "Epoch 38/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 16.5782 - val_loss: 20.6595\n",
      "Epoch 39/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 16.5049 - val_loss: 20.4551\n",
      "Epoch 40/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 16.4796 - val_loss: 20.2317\n",
      "Epoch 41/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 16.3300 - val_loss: 21.1367\n",
      "Epoch 42/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 16.3393 - val_loss: 20.6663\n",
      "Epoch 43/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 16.1909 - val_loss: 20.0790\n",
      "Epoch 44/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 16.1418 - val_loss: 20.4395\n",
      "Epoch 45/1000\n",
      "1052/1052 [==============================] - 0s 164us/step - loss: 16.0035 - val_loss: 19.8149\n",
      "Epoch 46/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 16.0605 - val_loss: 20.3994\n",
      "Epoch 47/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 16.0048 - val_loss: 20.0029\n",
      "Epoch 48/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 15.7474 - val_loss: 19.4531\n",
      "Epoch 49/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 15.8212 - val_loss: 19.7315\n",
      "Epoch 50/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 15.7613 - val_loss: 19.1290\n",
      "Epoch 51/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 15.6985 - val_loss: 19.4920\n",
      "Epoch 52/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 15.7244 - val_loss: 19.1869\n",
      "Epoch 53/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 15.3648 - val_loss: 18.6584\n",
      "Epoch 54/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 15.6012 - val_loss: 18.6453\n",
      "Epoch 55/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 15.4484 - val_loss: 19.0611\n",
      "Epoch 56/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 15.5771 - val_loss: 18.4722\n",
      "Epoch 57/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 15.1683 - val_loss: 19.2246\n",
      "Epoch 58/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 15.2189 - val_loss: 18.2056\n",
      "Epoch 59/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 15.1832 - val_loss: 19.1689\n",
      "Epoch 60/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 15.0926 - val_loss: 17.9153\n",
      "Epoch 61/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 15.1434 - val_loss: 20.3823\n",
      "Epoch 62/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 15.3495 - val_loss: 18.2154\n",
      "Epoch 63/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 15.2975 - val_loss: 17.8168\n",
      "Epoch 64/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 15.1298 - val_loss: 18.2759\n",
      "Epoch 65/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.8089 - val_loss: 17.8357\n",
      "Epoch 66/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.9871 - val_loss: 18.0988\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 14.5839 - val_loss: 18.0702\n",
      "Epoch 68/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 14.9027 - val_loss: 18.3838\n",
      "Epoch 69/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 14.5523 - val_loss: 18.6571\n",
      "Epoch 70/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.5937 - val_loss: 17.9711\n",
      "Epoch 71/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.5932 - val_loss: 18.1478\n",
      "Epoch 72/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 14.4756 - val_loss: 17.3742\n",
      "Epoch 73/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 14.5896 - val_loss: 17.9517\n",
      "Epoch 74/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 14.3638 - val_loss: 17.3849\n",
      "Epoch 75/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 14.3937 - val_loss: 18.6486\n",
      "Epoch 76/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 14.4760 - val_loss: 19.4626\n",
      "Epoch 77/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 14.2625 - val_loss: 17.4526\n",
      "Epoch 78/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 14.3647 - val_loss: 17.8470\n",
      "Epoch 79/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 13.9852 - val_loss: 17.4903\n",
      "Epoch 80/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 14.3618 - val_loss: 17.3411\n",
      "Epoch 81/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.2452 - val_loss: 17.2779\n",
      "Epoch 82/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 14.3232 - val_loss: 17.9071\n",
      "Epoch 83/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.0424 - val_loss: 16.7337\n",
      "Epoch 84/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 14.2787 - val_loss: 17.0088\n",
      "Epoch 85/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.0365 - val_loss: 17.1172\n",
      "Epoch 86/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 14.6661 - val_loss: 17.1596\n",
      "Epoch 87/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.2204 - val_loss: 17.8253\n",
      "Epoch 88/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 13.8120 - val_loss: 16.7803\n",
      "Epoch 89/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.6751 - val_loss: 17.4798\n",
      "Epoch 90/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.8777 - val_loss: 18.2068\n",
      "Epoch 91/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.7494 - val_loss: 17.5981\n",
      "Epoch 92/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.6810 - val_loss: 18.4295\n",
      "Epoch 93/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.5545 - val_loss: 16.5385\n",
      "Epoch 94/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.5797 - val_loss: 16.5608\n",
      "Epoch 95/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.9601 - val_loss: 18.2030\n",
      "Epoch 96/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.5476 - val_loss: 16.3407\n",
      "Epoch 97/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.6153 - val_loss: 16.6564\n",
      "Epoch 98/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 13.8443 - val_loss: 16.4490\n",
      "Epoch 99/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 13.5843 - val_loss: 16.6380\n",
      "Epoch 100/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 13.7086 - val_loss: 18.3069\n",
      "Epoch 101/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 13.9735 - val_loss: 18.2334\n",
      "Epoch 102/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.3403 - val_loss: 18.4316\n",
      "Epoch 103/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.5756 - val_loss: 18.5557\n",
      "Epoch 104/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 12.9818 - val_loss: 16.6176\n",
      "Epoch 105/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.7012 - val_loss: 18.8737\n",
      "Epoch 106/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.0592 - val_loss: 15.9861\n",
      "Epoch 107/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 13.4352 - val_loss: 16.1967\n",
      "Epoch 108/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 12.8412 - val_loss: 18.6977\n",
      "Epoch 109/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.1358 - val_loss: 17.0131\n",
      "Epoch 110/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.5853 - val_loss: 16.2933\n",
      "Epoch 111/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 12.6148 - val_loss: 16.9651\n",
      "Epoch 112/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.3262 - val_loss: 15.9484\n",
      "Epoch 113/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.0996 - val_loss: 17.3235\n",
      "Epoch 114/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 12.1068 - val_loss: 16.3693\n",
      "Epoch 115/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.9791 - val_loss: 16.2036\n",
      "Epoch 116/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 12.3277 - val_loss: 15.6611\n",
      "Epoch 117/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 12.9930 - val_loss: 16.1896\n",
      "Epoch 118/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.9163 - val_loss: 14.8344\n",
      "Epoch 119/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 11.8656 - val_loss: 14.3680\n",
      "Epoch 120/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.5377 - val_loss: 15.2659\n",
      "Epoch 121/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.6177 - val_loss: 15.1882\n",
      "Epoch 122/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.3472 - val_loss: 14.2384\n",
      "Epoch 123/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.1828 - val_loss: 13.9099\n",
      "Epoch 124/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 10.7644 - val_loss: 13.8462\n",
      "Epoch 125/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.7894 - val_loss: 13.4902\n",
      "Epoch 126/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.5676 - val_loss: 13.6488\n",
      "Epoch 127/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 10.5707 - val_loss: 13.2224\n",
      "Epoch 128/1000\n",
      "1052/1052 [==============================] - 0s 109us/step - loss: 11.2812 - val_loss: 13.7512\n",
      "Epoch 129/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 10.6795 - val_loss: 14.4148\n",
      "Epoch 130/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 10.8135 - val_loss: 13.1264\n",
      "Epoch 131/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.4771 - val_loss: 12.9872\n",
      "Epoch 132/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 9.9729 - val_loss: 12.7021\n",
      "Epoch 133/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 10.1465 - val_loss: 13.7877\n",
      "Epoch 134/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 10.4733 - val_loss: 12.8183\n",
      "Epoch 135/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.6241 - val_loss: 12.0622\n",
      "Epoch 136/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 10.1534 - val_loss: 11.9848\n",
      "Epoch 137/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.8701 - val_loss: 12.5378\n",
      "Epoch 138/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.5953 - val_loss: 12.5684\n",
      "Epoch 139/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.4776 - val_loss: 12.5053\n",
      "Epoch 140/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.0396 - val_loss: 12.8970\n",
      "Epoch 141/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.2989 - val_loss: 12.6615\n",
      "Epoch 142/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.3055 - val_loss: 11.4051\n",
      "Epoch 143/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.3952 - val_loss: 12.3803\n",
      "Epoch 144/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1838 - val_loss: 11.0953\n",
      "Epoch 145/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.7914 - val_loss: 12.3388\n",
      "Epoch 146/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.4400 - val_loss: 10.9356\n",
      "Epoch 147/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.1356 - val_loss: 11.2754\n",
      "Epoch 148/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.3618 - val_loss: 12.6292\n",
      "Epoch 149/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.3463 - val_loss: 11.1780\n",
      "Epoch 150/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.9274 - val_loss: 11.0698\n",
      "Epoch 151/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.8902 - val_loss: 11.4610\n",
      "Epoch 152/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.2288 - val_loss: 11.1751\n",
      "Epoch 153/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.6301 - val_loss: 11.3589\n",
      "Epoch 154/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 9.0128 - val_loss: 10.6802\n",
      "Epoch 155/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.1801 - val_loss: 10.9989\n",
      "Epoch 156/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.0815 - val_loss: 12.6755\n",
      "Epoch 157/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.8042 - val_loss: 11.4366\n",
      "Epoch 158/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1011 - val_loss: 10.4643\n",
      "Epoch 159/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.8805 - val_loss: 11.5278\n",
      "Epoch 160/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.0567 - val_loss: 10.9092\n",
      "Epoch 161/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.2203 - val_loss: 12.1427\n",
      "Epoch 162/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.1506 - val_loss: 10.9928\n",
      "Epoch 163/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.0888 - val_loss: 10.7502\n",
      "Epoch 164/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.9006 - val_loss: 11.1154\n",
      "Epoch 165/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.9204 - val_loss: 10.7829\n",
      "Epoch 166/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.1024 - val_loss: 12.1763\n",
      "Epoch 167/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2409 - val_loss: 10.5694\n",
      "Epoch 168/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5736 - val_loss: 11.4884\n",
      "Epoch 169/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1344 - val_loss: 11.8411\n",
      "Epoch 170/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.0214 - val_loss: 10.6582\n",
      "Epoch 171/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.5865 - val_loss: 12.9307\n",
      "Epoch 172/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.1303 - val_loss: 10.4450\n",
      "Epoch 173/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 9.3050 - val_loss: 10.6501\n",
      "Epoch 174/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 9.1757 - val_loss: 10.3519\n",
      "Epoch 175/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1777 - val_loss: 12.2446\n",
      "Epoch 176/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.2769 - val_loss: 10.9420\n",
      "Epoch 177/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.7763 - val_loss: 11.0952\n",
      "Epoch 178/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.9281 - val_loss: 10.3707\n",
      "Epoch 179/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2361 - val_loss: 10.6817\n",
      "Epoch 180/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6595 - val_loss: 11.8052\n",
      "Epoch 181/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8981 - val_loss: 11.3187\n",
      "Epoch 182/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.8368 - val_loss: 11.2124\n",
      "Epoch 183/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9146 - val_loss: 10.6470\n",
      "Epoch 184/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6704 - val_loss: 10.4852\n",
      "Epoch 185/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.8390 - val_loss: 10.1560\n",
      "Epoch 186/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8484 - val_loss: 12.7930\n",
      "Epoch 187/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9833 - val_loss: 11.1862\n",
      "Epoch 188/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9351 - val_loss: 11.0279\n",
      "Epoch 189/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.1648 - val_loss: 10.1751\n",
      "Epoch 190/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5599 - val_loss: 10.6768\n",
      "Epoch 191/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.8421 - val_loss: 10.0348\n",
      "Epoch 192/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.0167 - val_loss: 10.4477\n",
      "Epoch 193/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6561 - val_loss: 10.8974\n",
      "Epoch 194/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9515 - val_loss: 11.1534\n",
      "Epoch 195/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.5724 - val_loss: 13.0066\n",
      "Epoch 196/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.8528 - val_loss: 10.7573\n",
      "Epoch 197/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.7340 - val_loss: 11.6186\n",
      "Epoch 198/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.3318 - val_loss: 11.3812\n",
      "Epoch 199/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.8051 - val_loss: 10.6164\n",
      "Epoch 200/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.5226 - val_loss: 11.3021\n",
      "Epoch 201/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.7921 - val_loss: 9.8201\n",
      "Epoch 202/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.5204 - val_loss: 10.5932\n",
      "Epoch 203/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8364 - val_loss: 10.1599\n",
      "Epoch 204/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6072 - val_loss: 10.2711\n",
      "Epoch 205/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.4776 - val_loss: 9.8259\n",
      "Epoch 206/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.7688 - val_loss: 10.5446\n",
      "Epoch 207/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.6520 - val_loss: 10.0213\n",
      "Epoch 208/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.7533 - val_loss: 10.8915\n",
      "Epoch 209/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5889 - val_loss: 10.6810\n",
      "Epoch 210/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.6801 - val_loss: 10.1750\n",
      "Epoch 211/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.7064 - val_loss: 10.3908\n",
      "Epoch 212/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 8.5524 - val_loss: 10.5933\n",
      "Epoch 213/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.9518 - val_loss: 11.1115\n",
      "Epoch 214/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.0423 - val_loss: 10.0350\n",
      "Epoch 215/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4610 - val_loss: 10.6705\n",
      "Epoch 216/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.6751 - val_loss: 11.0150\n",
      "Epoch 217/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.9433 - val_loss: 10.5068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 218/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.4303 - val_loss: 9.7630\n",
      "Epoch 219/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8887 - val_loss: 10.9500\n",
      "Epoch 220/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.8669 - val_loss: 10.7538\n",
      "Epoch 221/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.6400 - val_loss: 10.9118\n",
      "Epoch 222/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.4967 - val_loss: 10.2848\n",
      "Epoch 223/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.4974 - val_loss: 10.1049\n",
      "Epoch 224/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.5646 - val_loss: 11.3308\n",
      "Epoch 225/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8644 - val_loss: 11.1623\n",
      "Epoch 226/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6791 - val_loss: 11.4415\n",
      "Epoch 227/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.4114 - val_loss: 10.0118\n",
      "Epoch 228/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.1826 - val_loss: 10.3501\n",
      "Epoch 229/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.2049 - val_loss: 10.2134\n",
      "Epoch 230/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6752 - val_loss: 9.5206\n",
      "Epoch 231/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.9821 - val_loss: 9.9135\n",
      "Epoch 232/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2462 - val_loss: 10.7640\n",
      "Epoch 233/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3535 - val_loss: 10.4289\n",
      "Epoch 234/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.8050 - val_loss: 10.1240\n",
      "Epoch 235/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.6219 - val_loss: 11.1026\n",
      "Epoch 236/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.5377 - val_loss: 10.3861\n",
      "Epoch 237/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.6852 - val_loss: 9.8015\n",
      "Epoch 238/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.4875 - val_loss: 9.9037\n",
      "Epoch 239/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.4299 - val_loss: 10.4942\n",
      "Epoch 240/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.4060 - val_loss: 11.9698\n",
      "Epoch 241/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 8.6878 - val_loss: 10.5795\n",
      "Epoch 242/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 8.7946 - val_loss: 10.0568\n",
      "Epoch 243/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 8.7351 - val_loss: 9.8998\n",
      "Epoch 244/1000\n",
      "1052/1052 [==============================] - 0s 108us/step - loss: 8.6256 - val_loss: 9.4613\n",
      "Epoch 245/1000\n",
      "1052/1052 [==============================] - 0s 109us/step - loss: 8.4190 - val_loss: 9.6385\n",
      "Epoch 246/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3683 - val_loss: 11.3940\n",
      "Epoch 247/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 8.8226 - val_loss: 10.4554\n",
      "Epoch 248/1000\n",
      "1052/1052 [==============================] - 0s 109us/step - loss: 9.0724 - val_loss: 9.8223\n",
      "Epoch 249/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.5911 - val_loss: 9.9489\n",
      "Epoch 250/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4886 - val_loss: 9.4600\n",
      "Epoch 251/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5436 - val_loss: 9.6796\n",
      "Epoch 252/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5076 - val_loss: 10.3621\n",
      "Epoch 253/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2354 - val_loss: 11.0569\n",
      "Epoch 254/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.7431 - val_loss: 9.4475\n",
      "Epoch 255/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.5862 - val_loss: 10.6592\n",
      "Epoch 256/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5423 - val_loss: 10.0588\n",
      "Epoch 257/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.6675 - val_loss: 9.7458\n",
      "Epoch 258/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5851 - val_loss: 9.6693\n",
      "Epoch 259/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5775 - val_loss: 10.0291\n",
      "Epoch 260/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4656 - val_loss: 9.6189\n",
      "Epoch 261/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.3891 - val_loss: 11.3590\n",
      "Epoch 262/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9784 - val_loss: 11.3757\n",
      "Epoch 263/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8645 - val_loss: 11.2735\n",
      "Epoch 264/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4530 - val_loss: 9.7989\n",
      "Epoch 265/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.3276 - val_loss: 9.4287\n",
      "Epoch 266/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 8.7151 - val_loss: 12.1325\n",
      "Epoch 267/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.7256 - val_loss: 10.6346\n",
      "Epoch 268/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2123 - val_loss: 10.1289\n",
      "Epoch 269/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5476 - val_loss: 10.1587\n",
      "Epoch 270/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.2396 - val_loss: 10.1381\n",
      "Epoch 271/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1603 - val_loss: 11.1846\n",
      "Epoch 272/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.3407 - val_loss: 9.8650\n",
      "Epoch 273/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.3043 - val_loss: 10.1543\n",
      "Epoch 274/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5400 - val_loss: 9.9855\n",
      "Epoch 275/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.2941 - val_loss: 9.7485\n",
      "Epoch 276/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.3910 - val_loss: 9.8210\n",
      "Epoch 277/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2784 - val_loss: 9.7867\n",
      "Epoch 278/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.7117 - val_loss: 11.3635\n",
      "Epoch 279/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.7463 - val_loss: 9.7322\n",
      "Epoch 280/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.2814 - val_loss: 9.5507\n",
      "Epoch 281/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.4289 - val_loss: 11.0346\n",
      "Epoch 282/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4538 - val_loss: 9.9072\n",
      "Epoch 283/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 8.6607 - val_loss: 9.7932\n",
      "Epoch 284/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.2366 - val_loss: 10.1761\n",
      "Epoch 285/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.1800 - val_loss: 10.2954\n",
      "Epoch 286/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.9415 - val_loss: 10.7366\n",
      "Epoch 287/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7714 - val_loss: 9.5625\n",
      "Epoch 288/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.3012 - val_loss: 9.9177\n",
      "Epoch 289/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.4707 - val_loss: 9.5860\n",
      "Epoch 290/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4462 - val_loss: 9.4542\n",
      "Epoch 291/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3048 - val_loss: 11.2988\n",
      "Epoch 292/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5722 - val_loss: 10.3741\n",
      "Epoch 293/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5110 - val_loss: 12.3797\n",
      "Epoch 294/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.8104 - val_loss: 9.9410\n",
      "Epoch 295/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.2784 - val_loss: 11.7129\n",
      "Epoch 296/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.2579 - val_loss: 11.3321\n",
      "Epoch 297/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3914 - val_loss: 10.3814\n",
      "Epoch 298/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.2278 - val_loss: 9.6403\n",
      "Epoch 299/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.4452 - val_loss: 9.6528\n",
      "Epoch 300/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3375 - val_loss: 9.9428\n",
      "Epoch 301/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.0891 - val_loss: 10.0975\n",
      "Epoch 302/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.1811 - val_loss: 9.4832\n",
      "Epoch 303/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6472 - val_loss: 11.9605\n",
      "Epoch 304/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.6166 - val_loss: 10.1148\n",
      "Epoch 305/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3366 - val_loss: 9.2762\n",
      "Epoch 306/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2367 - val_loss: 9.5593\n",
      "Epoch 307/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2293 - val_loss: 9.6607\n",
      "Epoch 308/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.2724 - val_loss: 9.7945\n",
      "Epoch 309/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.2128 - val_loss: 9.7754\n",
      "Epoch 310/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.2460 - val_loss: 9.8818\n",
      "Epoch 311/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.2318 - val_loss: 9.4426\n",
      "Epoch 312/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2575 - val_loss: 9.6054\n",
      "Epoch 313/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2038 - val_loss: 10.4711\n",
      "Epoch 314/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1675 - val_loss: 10.0910\n",
      "Epoch 315/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0669 - val_loss: 9.6207\n",
      "Epoch 316/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1105 - val_loss: 9.2577\n",
      "Epoch 317/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2909 - val_loss: 9.6529\n",
      "Epoch 318/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.3226 - val_loss: 10.0965\n",
      "Epoch 319/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1950 - val_loss: 9.1858\n",
      "Epoch 320/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.5239 - val_loss: 11.0308\n",
      "Epoch 321/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5009 - val_loss: 9.6188\n",
      "Epoch 322/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0613 - val_loss: 11.4208\n",
      "Epoch 323/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.4603 - val_loss: 10.5659\n",
      "Epoch 324/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.0487 - val_loss: 11.2879\n",
      "Epoch 325/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.3386 - val_loss: 10.0809\n",
      "Epoch 326/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.2621 - val_loss: 10.7112\n",
      "Epoch 327/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3673 - val_loss: 9.8784\n",
      "Epoch 328/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.4427 - val_loss: 10.3447\n",
      "Epoch 329/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.1881 - val_loss: 9.0415\n",
      "Epoch 330/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.8998 - val_loss: 10.3398\n",
      "Epoch 331/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.7114 - val_loss: 9.9237\n",
      "Epoch 332/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0860 - val_loss: 9.1448\n",
      "Epoch 333/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4067 - val_loss: 9.3277\n",
      "Epoch 334/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.9131 - val_loss: 9.0650\n",
      "Epoch 335/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0192 - val_loss: 9.1960\n",
      "Epoch 336/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4111 - val_loss: 10.1191\n",
      "Epoch 337/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0257 - val_loss: 9.4895\n",
      "Epoch 338/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4445 - val_loss: 9.2936\n",
      "Epoch 339/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.0489 - val_loss: 9.5920\n",
      "Epoch 340/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.9573 - val_loss: 9.5614\n",
      "Epoch 341/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3217 - val_loss: 9.3944\n",
      "Epoch 342/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1640 - val_loss: 9.3505\n",
      "Epoch 343/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2110 - val_loss: 9.0504\n",
      "Epoch 344/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.0389 - val_loss: 9.5320\n",
      "Epoch 345/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1860 - val_loss: 9.8878\n",
      "Epoch 346/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0911 - val_loss: 9.1375\n",
      "Epoch 347/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.1364 - val_loss: 9.9916\n",
      "Epoch 348/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0844 - val_loss: 9.3732\n",
      "Epoch 349/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1920 - val_loss: 9.6631\n",
      "Epoch 350/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0157 - val_loss: 9.4300\n",
      "Epoch 351/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.2710 - val_loss: 9.9676\n",
      "Epoch 352/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3430 - val_loss: 10.6485\n",
      "Epoch 353/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.0891 - val_loss: 9.4202\n",
      "Epoch 354/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1608 - val_loss: 9.0931\n",
      "Epoch 355/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0149 - val_loss: 9.4342\n",
      "Epoch 356/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.0880 - val_loss: 10.0817\n",
      "Epoch 357/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2949 - val_loss: 9.8074\n",
      "Epoch 358/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1022 - val_loss: 9.4720\n",
      "Epoch 359/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3974 - val_loss: 9.1261\n",
      "Epoch 360/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.2875 - val_loss: 9.5487\n",
      "Epoch 361/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9195 - val_loss: 9.4888\n",
      "Epoch 362/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.1236 - val_loss: 10.4925\n",
      "Epoch 363/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1741 - val_loss: 9.0594\n",
      "Epoch 364/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3197 - val_loss: 10.3369\n",
      "Epoch 365/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.9649 - val_loss: 9.1565\n",
      "Epoch 366/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3335 - val_loss: 9.7632\n",
      "Epoch 367/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3119 - val_loss: 9.2880\n",
      "Epoch 368/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.8965 - val_loss: 10.0984\n",
      "Epoch 369/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1336 - val_loss: 9.3046\n",
      "Epoch 370/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0702 - val_loss: 9.2919\n",
      "Epoch 371/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3750 - val_loss: 9.7317\n",
      "Epoch 372/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0319 - val_loss: 9.4770\n",
      "Epoch 373/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.0560 - val_loss: 9.5039\n",
      "Epoch 374/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.9294 - val_loss: 9.1315\n",
      "Epoch 375/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9704 - val_loss: 8.9241\n",
      "Epoch 376/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.0506 - val_loss: 9.4576\n",
      "Epoch 377/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5407 - val_loss: 11.3749\n",
      "Epoch 378/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2231 - val_loss: 8.7622\n",
      "Epoch 379/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1910 - val_loss: 9.4731\n",
      "Epoch 380/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9992 - val_loss: 9.7555\n",
      "Epoch 381/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2013 - val_loss: 9.1775\n",
      "Epoch 382/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9611 - val_loss: 9.6314\n",
      "Epoch 383/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0795 - val_loss: 9.6460\n",
      "Epoch 384/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.9560 - val_loss: 8.7907\n",
      "Epoch 385/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.9064 - val_loss: 9.1554\n",
      "Epoch 386/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5526 - val_loss: 9.5028\n",
      "Epoch 387/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2237 - val_loss: 10.3205\n",
      "Epoch 388/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.1629 - val_loss: 10.0473\n",
      "Epoch 389/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9930 - val_loss: 10.8477\n",
      "Epoch 390/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0563 - val_loss: 9.5851\n",
      "Epoch 391/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0174 - val_loss: 10.6301\n",
      "Epoch 392/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1630 - val_loss: 8.9332\n",
      "Epoch 393/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8597 - val_loss: 10.7025\n",
      "Epoch 394/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.1017 - val_loss: 9.8190\n",
      "Epoch 395/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3710 - val_loss: 9.1655\n",
      "Epoch 396/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1153 - val_loss: 8.9190\n",
      "Epoch 397/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2168 - val_loss: 9.7467\n",
      "Epoch 398/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8077 - val_loss: 9.4658\n",
      "Epoch 399/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9998 - val_loss: 9.7405\n",
      "Epoch 400/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2525 - val_loss: 9.7540\n",
      "Epoch 401/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4641 - val_loss: 10.2130\n",
      "Epoch 402/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2490 - val_loss: 9.2533\n",
      "Epoch 403/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2091 - val_loss: 9.0740\n",
      "Epoch 404/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.8802 - val_loss: 10.1209\n",
      "Epoch 405/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.8807 - val_loss: 8.9254\n",
      "Epoch 406/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0777 - val_loss: 9.9092\n",
      "Epoch 407/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.9139 - val_loss: 9.8171\n",
      "Epoch 408/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.9767 - val_loss: 8.9201\n",
      "Epoch 409/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8287 - val_loss: 9.1964\n",
      "Epoch 410/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2135 - val_loss: 9.5672\n",
      "Epoch 411/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0137 - val_loss: 9.0268\n",
      "Epoch 412/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.8687 - val_loss: 8.7942\n",
      "Epoch 413/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 7.9000 - val_loss: 9.6162\n",
      "Epoch 414/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 7.7463 - val_loss: 9.8278\n",
      "Epoch 415/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 8.7835 - 0s 100us/step - loss: 8.5517 - val_loss: 10.6800\n",
      "Epoch 416/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 8.0079 - val_loss: 9.5539\n",
      "Epoch 417/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 7.9085 - val_loss: 10.2842\n",
      "Epoch 418/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.2497 - val_loss: 9.4690\n",
      "Epoch 419/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.9477 - val_loss: 8.8736\n",
      "Epoch 420/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.9519 - val_loss: 9.2793\n",
      "Epoch 421/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.9575 - val_loss: 8.9257\n",
      "Epoch 422/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.8754 - val_loss: 8.7499\n",
      "Epoch 423/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9185 - val_loss: 8.8540\n",
      "Epoch 424/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1766 - val_loss: 9.1673\n",
      "Epoch 425/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4774 - val_loss: 8.7137\n",
      "Epoch 426/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5757 - val_loss: 11.4979\n",
      "Epoch 427/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1287 - val_loss: 8.5675\n",
      "Epoch 428/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9135 - val_loss: 8.8871\n",
      "Epoch 429/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.7917 - val_loss: 9.7087\n",
      "Epoch 430/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.9167 - val_loss: 9.7594\n",
      "Epoch 431/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1613 - val_loss: 8.9364\n",
      "Epoch 432/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9757 - val_loss: 9.5886\n",
      "Epoch 433/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0705 - val_loss: 8.4838\n",
      "Epoch 434/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2600 - val_loss: 9.5805\n",
      "Epoch 435/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.1685 - val_loss: 9.7609\n",
      "Epoch 436/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9527 - val_loss: 8.4399\n",
      "Epoch 437/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.9744 - val_loss: 9.1683\n",
      "Epoch 438/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.0114 - val_loss: 9.3339\n",
      "Epoch 439/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.8455 - val_loss: 8.9229\n",
      "Epoch 440/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0909 - val_loss: 9.6887\n",
      "Epoch 441/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.7518 - val_loss: 8.8474\n",
      "Epoch 442/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.7953 - val_loss: 8.7835\n",
      "Epoch 443/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9844 - val_loss: 8.5574\n",
      "Epoch 444/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.8146 - val_loss: 9.4684\n",
      "Epoch 445/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9370 - val_loss: 9.2629\n",
      "Epoch 446/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.8958 - val_loss: 8.4671\n",
      "Epoch 447/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.9723 - val_loss: 9.2700\n",
      "Epoch 448/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4502 - val_loss: 9.3394\n",
      "Epoch 449/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1877 - val_loss: 8.8598\n",
      "Epoch 450/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0953 - val_loss: 9.1853\n",
      "Epoch 451/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.7202 - val_loss: 8.4887\n",
      "Epoch 452/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.9128 - val_loss: 8.9869\n",
      "Epoch 453/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1617 - val_loss: 9.7114\n",
      "Epoch 454/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.8588 - val_loss: 10.1862\n",
      "Epoch 455/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1939 - val_loss: 10.4510\n",
      "Epoch 456/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2632 - val_loss: 9.0626\n",
      "Epoch 457/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.9379 - val_loss: 8.8841\n",
      "Epoch 458/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.7136 - val_loss: 9.2101\n",
      "Epoch 459/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.8488 - val_loss: 9.5688\n",
      "Epoch 460/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.8215 - val_loss: 9.4498\n",
      "Epoch 461/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.8609 - val_loss: 8.4812\n",
      "Epoch 462/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.7103 - val_loss: 9.0110\n",
      "Epoch 463/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.7486 - val_loss: 9.7832\n",
      "Epoch 464/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9637 - val_loss: 8.7951\n",
      "Epoch 465/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0916 - val_loss: 9.0896\n",
      "Epoch 466/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.9592 - val_loss: 9.2170\n",
      "Epoch 467/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0908 - val_loss: 8.8155\n",
      "Epoch 468/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.8791 - val_loss: 9.6948\n",
      "Epoch 469/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.6135 - val_loss: 10.9183\n",
      "Epoch 470/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.9810 - val_loss: 10.4170\n",
      "Epoch 471/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.8092 - val_loss: 8.9084\n",
      "Epoch 472/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1805 - val_loss: 8.4285\n",
      "Epoch 473/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.7548 - val_loss: 10.3500\n",
      "Epoch 474/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.6867 - val_loss: 8.9457\n",
      "Epoch 475/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7012 - val_loss: 8.9157\n",
      "Epoch 476/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.5906 - val_loss: 11.5466\n",
      "Epoch 477/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9749 - val_loss: 9.3923\n",
      "Epoch 478/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.8629 - val_loss: 9.2525\n",
      "Epoch 479/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.8454 - val_loss: 9.7093\n",
      "Epoch 480/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.9203 - val_loss: 8.8279\n",
      "Epoch 481/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.7559 - val_loss: 10.2810\n",
      "Epoch 482/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9836 - val_loss: 9.0176\n",
      "Epoch 483/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.8232 - val_loss: 8.6070\n",
      "Epoch 484/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.5867 - val_loss: 8.7648\n",
      "Epoch 485/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2023 - val_loss: 10.0877\n",
      "Epoch 486/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0990 - val_loss: 8.5189\n",
      "Epoch 487/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.7899 - val_loss: 9.6424\n",
      "Epoch 488/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.7050 - val_loss: 10.1595\n",
      "Epoch 489/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9276 - val_loss: 8.5354\n",
      "Epoch 490/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.8135 - val_loss: 8.6282\n",
      "Epoch 491/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.6517 - val_loss: 10.0984\n",
      "Epoch 492/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.6453 - val_loss: 8.7571\n",
      "Epoch 493/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1115 - val_loss: 9.1520\n",
      "Epoch 494/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8516 - val_loss: 8.8566\n",
      "Epoch 495/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.7023 - val_loss: 9.0877\n",
      "Epoch 496/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.7608 - val_loss: 9.4040\n",
      "Epoch 497/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.6622 - val_loss: 8.8315\n",
      "Epoch 498/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.5561 - val_loss: 9.0968\n",
      "Epoch 499/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.7449 - val_loss: 8.6404\n",
      "Epoch 500/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.7728 - val_loss: 10.2966\n",
      "Epoch 501/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9183 - val_loss: 8.8336\n",
      "Epoch 502/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.4424 - val_loss: 8.9884\n",
      "Epoch 503/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.4740 - val_loss: 8.8468\n",
      "Epoch 504/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.6868 - val_loss: 10.3386\n",
      "Epoch 505/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8608 - val_loss: 9.1246\n",
      "Epoch 506/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9658 - val_loss: 9.4206\n",
      "Epoch 507/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.7591 - val_loss: 8.6872\n",
      "Epoch 508/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.6248 - val_loss: 8.7364\n",
      "Epoch 509/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.6015 - val_loss: 8.6278\n",
      "Epoch 510/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.8623 - val_loss: 8.9413\n",
      "Epoch 511/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.6609 - val_loss: 9.0531\n",
      "Epoch 512/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.6743 - val_loss: 8.8746\n",
      "Epoch 513/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.6683 - val_loss: 8.7880\n",
      "Epoch 514/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.6414 - val_loss: 10.2769\n",
      "Epoch 515/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8740 - val_loss: 9.3799\n",
      "Epoch 516/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.2938 - val_loss: 9.4951\n",
      "Epoch 517/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.6958 - val_loss: 8.8066\n",
      "Epoch 518/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.8812 - val_loss: 9.1182\n",
      "Epoch 519/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.7703 - val_loss: 9.7905\n",
      "Epoch 520/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.6872 - val_loss: 8.9666\n",
      "Epoch 521/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9364 - val_loss: 8.4902\n",
      "Epoch 522/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.9272 - val_loss: 8.6274\n",
      "Epoch 523/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8748 - val_loss: 9.4331\n",
      "Epoch 524/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.6393 - val_loss: 10.5536\n",
      "Epoch 525/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.8056 - val_loss: 8.7930\n",
      "Epoch 526/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.5351 - val_loss: 8.7041\n",
      "Epoch 527/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9292 - val_loss: 10.0714\n",
      "Epoch 528/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.8735 - val_loss: 9.6251\n",
      "Epoch 529/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.6254 - val_loss: 9.3192\n",
      "Epoch 530/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.8273 - val_loss: 10.6248\n",
      "Epoch 531/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9215 - val_loss: 12.2653\n",
      "Epoch 532/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.7633 - val_loss: 9.1786\n",
      "Epoch 533/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9017 - val_loss: 8.8845\n",
      "Epoch 534/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.6219 - val_loss: 9.0647\n",
      "Epoch 535/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8907 - val_loss: 9.0564\n",
      "Epoch 536/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9685 - val_loss: 9.1112\n",
      "Epoch 537/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.9179 - val_loss: 9.3573\n",
      "Epoch 538/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.7561 - val_loss: 8.9269\n",
      "Epoch 539/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.6735 - val_loss: 8.8864\n",
      "Epoch 540/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.6022 - val_loss: 10.7253\n",
      "Epoch 541/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.9944 - val_loss: 8.8875\n",
      "Epoch 542/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1722 - val_loss: 8.5753\n",
      "Epoch 543/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9238 - val_loss: 10.6465\n",
      "Epoch 544/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.0016 - val_loss: 9.2684\n",
      "Epoch 545/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.4951 - val_loss: 9.0321\n",
      "Epoch 546/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.2994 - val_loss: 11.0372\n",
      "Epoch 547/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 7.9562 - val_loss: 9.2239\n",
      "Epoch 548/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.8000 - val_loss: 8.5359\n",
      "Epoch 549/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0982 - val_loss: 9.3706\n",
      "Epoch 550/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.8896 - val_loss: 8.7880\n",
      "Epoch 551/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3123 - val_loss: 10.0889\n",
      "Epoch 552/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1079 - val_loss: 9.0935\n",
      "Epoch 553/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2855 - val_loss: 9.4137\n",
      "Epoch 554/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.5622 - val_loss: 9.5042\n",
      "Epoch 555/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.8245 - val_loss: 8.8903\n",
      "Epoch 556/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.5790 - val_loss: 9.2139\n",
      "Epoch 557/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.6982 - val_loss: 8.9196\n",
      "Epoch 558/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.4245 - val_loss: 9.0876\n",
      "Epoch 559/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.5269 - val_loss: 9.2368\n",
      "Epoch 560/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.5752 - val_loss: 9.8417\n",
      "Epoch 561/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.7212 - val_loss: 9.1307\n",
      "Epoch 562/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.5275 - val_loss: 9.5501\n",
      "Epoch 563/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.6390 - val_loss: 9.6556\n",
      "Epoch 564/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.4825 - val_loss: 8.7888\n",
      "Epoch 565/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.6628 - val_loss: 9.0660\n",
      "Epoch 566/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.8839 - val_loss: 9.5376\n",
      "Epoch 567/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.6818 - val_loss: 9.2802\n",
      "Epoch 568/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.5945 - val_loss: 9.1588\n",
      "Epoch 569/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.8810 - val_loss: 9.3403\n",
      "Epoch 570/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.0709 - val_loss: 10.4216\n",
      "Epoch 571/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.4494 - val_loss: 8.8650\n",
      "Epoch 572/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.6785 - val_loss: 8.9186\n",
      "Epoch 573/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.8870 - val_loss: 9.3887\n",
      "Epoch 574/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.8631 - val_loss: 9.0648\n",
      "Epoch 575/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.5233 - val_loss: 11.5142\n",
      "Epoch 576/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0823 - val_loss: 9.3389\n",
      "Epoch 577/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.8249 - val_loss: 9.0713\n",
      "Epoch 578/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.4746 - val_loss: 9.3816\n",
      "Epoch 579/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.5078 - val_loss: 8.8279\n",
      "Epoch 580/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.4543 - val_loss: 10.7093\n",
      "Epoch 581/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.2215 - val_loss: 8.7926\n",
      "Epoch 582/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 7.4914 - val_loss: 8.9029\n",
      "Epoch 583/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.6940 - val_loss: 9.3258\n",
      "Epoch 584/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.6422 - val_loss: 9.3620\n",
      "Epoch 585/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.5323 - val_loss: 9.6530\n",
      "Epoch 586/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.8921 - val_loss: 9.2463\n",
      "Epoch 587/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.5925 - val_loss: 8.7865\n",
      "Epoch 588/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.6254 - val_loss: 10.2606\n",
      "Epoch 589/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 7.5308 - val_loss: 9.3395\n",
      "Epoch 590/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.5668 - val_loss: 8.9774\n",
      "Epoch 591/1000\n",
      "1052/1052 [==============================] - 0s 108us/step - loss: 7.7314 - val_loss: 8.9781\n",
      "Epoch 592/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.6707 - val_loss: 9.3975\n",
      "Epoch 593/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.9475 - val_loss: 9.9236\n",
      "Epoch 594/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.5006 - val_loss: 8.9944\n",
      "Epoch 595/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.4968 - val_loss: 9.1080\n",
      "Epoch 596/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.6281 - val_loss: 9.2037\n",
      "Epoch 597/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.6836 - val_loss: 9.2869\n",
      "Epoch 598/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.5545 - val_loss: 9.3681\n",
      "Epoch 599/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.6470 - val_loss: 8.9285\n",
      "Epoch 600/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.6287 - val_loss: 9.2748\n",
      "Epoch 601/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.6785 - val_loss: 10.1517\n",
      "Epoch 602/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.4514 - val_loss: 8.6509\n",
      "Epoch 603/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.7836 - val_loss: 8.7017\n",
      "Epoch 604/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.5433 - val_loss: 9.5280\n",
      "Epoch 605/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0614 - val_loss: 8.6023\n",
      "Epoch 606/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.7619 - val_loss: 9.8582\n",
      "Epoch 607/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.5616 - val_loss: 9.2273\n",
      "Epoch 608/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.5068 - val_loss: 9.4393\n",
      "Epoch 609/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.7984 - val_loss: 9.2353\n",
      "Epoch 610/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.5880 - val_loss: 8.7013\n",
      "Epoch 611/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.5738 - val_loss: 8.8159\n",
      "Epoch 612/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.5344 - val_loss: 9.0095\n",
      "Epoch 613/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.6735 - val_loss: 8.8539\n",
      "Epoch 614/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.8098 - val_loss: 9.4630\n",
      "Epoch 615/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.5652 - val_loss: 8.8099\n",
      "Epoch 616/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.7567 - val_loss: 8.9260\n",
      "Epoch 617/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.6418 - val_loss: 9.3458\n",
      "Epoch 618/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.6744 - val_loss: 9.5484\n",
      "Epoch 619/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.6164 - val_loss: 9.0030\n",
      "Epoch 620/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.5536 - val_loss: 9.5465\n",
      "Epoch 621/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.5013 - val_loss: 10.2165\n",
      "Epoch 622/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.7427 - val_loss: 9.1382\n",
      "Epoch 623/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.8122 - val_loss: 8.7224\n",
      "Epoch 624/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.6176 - val_loss: 8.9767\n",
      "Epoch 625/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.7037 - val_loss: 9.6961\n",
      "Epoch 626/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0595 - val_loss: 8.8149\n",
      "Epoch 627/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.1138 - val_loss: 8.7173\n",
      "Epoch 628/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.5467 - val_loss: 8.9623\n",
      "Epoch 629/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.6171 - val_loss: 11.8673\n",
      "Epoch 630/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.8918 - val_loss: 8.7418\n",
      "Epoch 631/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.5620 - val_loss: 8.6525\n",
      "Epoch 632/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9039 - val_loss: 9.4079\n",
      "Epoch 633/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.4923 - val_loss: 9.5578\n",
      "Epoch 634/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1366 - val_loss: 8.5790\n",
      "Epoch 635/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.5841 - val_loss: 8.7956\n",
      "Epoch 636/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8480 - val_loss: 9.8687\n",
      "Epoch 637/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.7427 - val_loss: 8.8945\n",
      "Epoch 638/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.4803 - val_loss: 8.9130\n",
      "Epoch 639/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.5082 - val_loss: 8.9776\n",
      "Epoch 640/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.4684 - val_loss: 9.2041\n",
      "Epoch 641/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.6855 - val_loss: 10.0171\n",
      "Epoch 642/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.7643 - val_loss: 8.9525\n",
      "Epoch 643/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.6853 - val_loss: 8.7298\n",
      "Epoch 644/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.7086 - val_loss: 10.5216\n",
      "Epoch 645/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.6103 - val_loss: 9.2628\n",
      "Epoch 646/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.4563 - val_loss: 9.4405\n",
      "Epoch 647/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.3706 - val_loss: 9.1466\n",
      "Epoch 648/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.5119 - val_loss: 9.8014\n",
      "Epoch 649/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0218 - val_loss: 10.2840\n",
      "Epoch 650/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.6986 - val_loss: 8.9507\n",
      "Epoch 651/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.6023 - val_loss: 8.9847\n",
      "Epoch 652/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.6030 - val_loss: 8.7973\n",
      "Epoch 653/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.4334 - val_loss: 9.1038\n",
      "Epoch 654/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.3911 - val_loss: 8.6842\n",
      "Epoch 655/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.4580 - val_loss: 9.5510\n",
      "Epoch 656/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.6101 - val_loss: 9.3409\n",
      "Epoch 657/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9274 - val_loss: 9.2072\n",
      "Epoch 658/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.7370 - val_loss: 9.3070\n",
      "Epoch 659/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.6276 - val_loss: 9.1109\n",
      "Epoch 660/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9112 - val_loss: 8.4890\n",
      "Epoch 661/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.6612 - val_loss: 8.9128\n",
      "Epoch 662/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.5484 - val_loss: 8.8507\n",
      "Epoch 663/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.7253 - val_loss: 8.5316\n",
      "Epoch 664/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.6375 - val_loss: 9.5764\n",
      "Epoch 665/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.4551 - val_loss: 9.0354\n",
      "Epoch 666/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8433 - val_loss: 8.9330\n",
      "Epoch 667/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.8797 - val_loss: 8.6675\n",
      "Epoch 668/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.5018 - val_loss: 9.0002\n",
      "Epoch 669/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.4412 - val_loss: 9.9936\n",
      "Epoch 670/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.5414 - val_loss: 8.7937\n",
      "Epoch 671/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.4338 - val_loss: 9.9661\n",
      "Epoch 672/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.6436 - val_loss: 9.9616\n",
      "Epoch 673/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.4306 - val_loss: 8.6530\n",
      "Epoch 674/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.8047 - val_loss: 9.2796\n",
      "Epoch 675/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8457 - val_loss: 8.9344\n",
      "Epoch 676/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.4156 - val_loss: 9.5213\n",
      "Epoch 677/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.4929 - val_loss: 8.9623\n",
      "Epoch 678/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.6453 - val_loss: 8.8565\n",
      "Epoch 679/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.4886 - val_loss: 10.2143\n",
      "Epoch 680/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.4838 - val_loss: 9.2386\n",
      "Epoch 681/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.3673 - val_loss: 8.6798\n",
      "Epoch 682/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8656 - val_loss: 9.2991\n",
      "Epoch 683/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.6540 - val_loss: 9.3349\n",
      "Epoch 684/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.7839 - val_loss: 8.9371\n",
      "Epoch 685/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.5015 - val_loss: 9.6687\n",
      "Epoch 686/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.7266 - val_loss: 8.5984\n",
      "Epoch 687/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.4267 - val_loss: 8.5400\n",
      "Epoch 688/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.5784 - val_loss: 9.1950\n",
      "Epoch 689/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.4578 - val_loss: 9.3369\n",
      "Epoch 690/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.4011 - val_loss: 8.9020\n",
      "Epoch 691/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.5234 - val_loss: 9.0129\n",
      "Epoch 692/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.6601 - val_loss: 8.8089\n",
      "Epoch 693/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2744 - val_loss: 9.0345\n",
      "Epoch 694/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.5735 - val_loss: 9.0858\n",
      "Epoch 695/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.4764 - val_loss: 8.7220\n",
      "Epoch 696/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.7501 - val_loss: 8.6884\n",
      "Epoch 697/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.6944 - val_loss: 8.8429\n",
      "Epoch 698/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.7647 - val_loss: 8.8026\n",
      "Epoch 699/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.0051 - val_loss: 11.2610\n",
      "Epoch 700/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.8286 - val_loss: 9.0801\n",
      "Epoch 701/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.8029 - val_loss: 9.0193\n",
      "Epoch 702/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.5997 - val_loss: 8.5990\n",
      "Epoch 703/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.7373 - val_loss: 8.8052\n",
      "Epoch 704/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.7710 - val_loss: 8.8254\n",
      "Epoch 705/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.7972 - val_loss: 9.0177\n",
      "Epoch 706/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.3412 - val_loss: 8.7119\n",
      "Epoch 707/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.3081 - val_loss: 9.4862\n",
      "Epoch 708/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.5867 - val_loss: 9.2045\n",
      "Epoch 709/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.7306 - val_loss: 9.7421\n",
      "Epoch 710/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.5625 - val_loss: 8.8613\n",
      "Epoch 711/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8145 - val_loss: 9.1379\n",
      "Epoch 712/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.6321 - val_loss: 8.6513\n",
      "Epoch 713/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.8583 - val_loss: 8.8003\n",
      "Epoch 714/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0248 - val_loss: 10.7181\n",
      "Epoch 715/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0801 - val_loss: 8.9812\n",
      "Epoch 716/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8597 - val_loss: 8.7227\n",
      "Epoch 717/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.6626 - val_loss: 8.9212\n",
      "Epoch 718/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.4694 - val_loss: 8.7013\n",
      "Epoch 719/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.7504 - val_loss: 9.1401\n",
      "Epoch 720/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.7388 - val_loss: 8.8818\n",
      "Epoch 721/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.8360 - val_loss: 8.5452\n",
      "Epoch 722/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.5899 - val_loss: 8.5777\n",
      "Epoch 723/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.6332 - val_loss: 8.8474\n",
      "Epoch 724/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.5962 - val_loss: 8.8754\n",
      "Epoch 725/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.4214 - val_loss: 8.4923\n",
      "Epoch 726/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.4906 - val_loss: 8.9377\n",
      "Epoch 727/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 7.5403 - val_loss: 8.5607\n",
      "Epoch 728/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.4649 - val_loss: 9.2186\n",
      "Epoch 729/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.4381 - val_loss: 10.5689\n",
      "Epoch 730/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.6847 - val_loss: 8.9854\n",
      "Epoch 731/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.6848 - val_loss: 8.5333\n",
      "Epoch 732/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.8621 - val_loss: 8.9301\n",
      "Epoch 733/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.4638 - val_loss: 8.7422\n",
      "Epoch 734/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.5819 - val_loss: 8.5889\n",
      "Epoch 735/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.7064 - val_loss: 8.7667\n",
      "Epoch 736/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.5316 - val_loss: 8.7346\n",
      "Epoch 737/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.5660 - val_loss: 9.1233\n",
      "Epoch 738/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.5758 - val_loss: 9.0145\n",
      "Epoch 739/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.7962 - val_loss: 10.8418\n",
      "Epoch 740/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.8874 - val_loss: 9.6197\n",
      "Epoch 741/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.7893 - val_loss: 9.7262\n",
      "Epoch 742/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.6617 - val_loss: 8.4343\n",
      "Epoch 743/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.7765 - val_loss: 9.1656\n",
      "Epoch 744/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.4155 - val_loss: 9.8402\n",
      "Epoch 745/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.7842 - val_loss: 9.0985\n",
      "Epoch 746/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.8317 - val_loss: 8.6649\n",
      "Epoch 747/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0320 - val_loss: 9.0581\n",
      "Epoch 748/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.5280 - val_loss: 8.3537\n",
      "Epoch 749/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.5335 - val_loss: 9.0095\n",
      "Epoch 750/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.8313 - val_loss: 8.6961\n",
      "Epoch 751/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.6571 - val_loss: 9.1699\n",
      "Epoch 752/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.6971 - val_loss: 8.5429\n",
      "Epoch 753/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.4728 - val_loss: 8.9249\n",
      "Epoch 754/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.7931 - val_loss: 8.9870\n",
      "Epoch 755/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.3457 - val_loss: 8.5020\n",
      "Epoch 756/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.5271 - val_loss: 8.9644\n",
      "Epoch 757/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.5217 - val_loss: 8.7571\n",
      "Epoch 758/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.5212 - val_loss: 8.6879\n",
      "Epoch 759/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.5617 - val_loss: 8.9256\n",
      "Epoch 760/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.7564 - val_loss: 8.4816\n",
      "Epoch 761/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 7.7833 - val_loss: 9.0957\n",
      "Epoch 762/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1137 - val_loss: 8.7342\n",
      "Epoch 763/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 7.6776 - val_loss: 8.8126\n",
      "Epoch 764/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.8964 - val_loss: 10.2169\n",
      "Epoch 765/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.7537 - val_loss: 8.6050\n",
      "Epoch 766/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.2971 - val_loss: 8.6481\n",
      "Epoch 767/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.5155 - val_loss: 8.8388\n",
      "Epoch 768/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 7.3935 - val_loss: 8.7296\n",
      "Epoch 769/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.5612 - val_loss: 8.9574\n",
      "Epoch 770/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.5994 - val_loss: 9.0752\n",
      "Epoch 771/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.6448 - val_loss: 9.1409\n",
      "Epoch 772/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.3190 - val_loss: 8.6147\n",
      "Epoch 773/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.9474 - val_loss: 9.0345\n",
      "Epoch 774/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 7.3525 - val_loss: 8.8100\n",
      "Epoch 775/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1757 - val_loss: 11.1098\n",
      "Epoch 776/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.5832 - val_loss: 8.9505\n",
      "Epoch 777/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.5934 - val_loss: 8.8390\n",
      "Epoch 778/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.7027 - val_loss: 8.9957\n",
      "Epoch 779/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.4999 - val_loss: 8.9136\n",
      "Epoch 780/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.4341 - val_loss: 8.8010\n",
      "Epoch 781/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.4231 - val_loss: 8.7610\n",
      "Epoch 782/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.6511 - val_loss: 8.7577\n",
      "Epoch 783/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.4711 - val_loss: 9.2188\n",
      "Epoch 784/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.4770 - val_loss: 8.9016\n",
      "Epoch 785/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.6860 - val_loss: 10.6755\n",
      "Epoch 786/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.0148 - val_loss: 8.8040\n",
      "Epoch 787/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.3590 - val_loss: 9.1245\n",
      "Epoch 788/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.8406 - val_loss: 9.1443\n",
      "Epoch 789/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.6148 - val_loss: 9.3111\n",
      "Epoch 790/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.7804 - val_loss: 8.6808\n",
      "Epoch 791/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.4172 - val_loss: 10.7194\n",
      "Epoch 792/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.7113 - val_loss: 8.8246\n",
      "Epoch 793/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.5774 - val_loss: 9.6133\n",
      "Epoch 794/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.4749 - val_loss: 8.5614\n",
      "Epoch 795/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.6251 - val_loss: 8.8441\n",
      "Epoch 796/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.5154 - val_loss: 8.4967\n",
      "Epoch 797/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.4463 - val_loss: 9.2518\n",
      "Epoch 798/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.5741 - val_loss: 8.6774\n",
      "Epoch 799/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.7571 - val_loss: 8.7146\n",
      "Epoch 800/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.4560 - val_loss: 9.3053\n",
      "Epoch 801/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.5905 - val_loss: 10.1695\n",
      "Epoch 802/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.7220 - val_loss: 8.5431\n",
      "Epoch 803/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.5757 - val_loss: 9.2214\n",
      "Epoch 804/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.4634 - val_loss: 8.9297\n",
      "Epoch 805/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.5060 - val_loss: 8.3280\n",
      "Epoch 806/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.4796 - val_loss: 9.8380\n",
      "Epoch 807/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.8852 - val_loss: 9.6632\n",
      "Epoch 808/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.7538 - val_loss: 8.5736\n",
      "Epoch 809/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.5737 - val_loss: 10.6199\n",
      "Epoch 810/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.5994 - val_loss: 9.1171\n",
      "Epoch 811/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.4954 - val_loss: 8.6840\n",
      "Epoch 812/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.7244 - val_loss: 8.9459\n",
      "Epoch 813/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.7705 - val_loss: 9.2499\n",
      "Epoch 814/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.9535 - val_loss: 9.4101\n",
      "Epoch 815/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.5993 - val_loss: 8.7485\n",
      "Epoch 816/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.4678 - val_loss: 9.0042\n",
      "Epoch 817/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.6689 - val_loss: 8.4248\n",
      "Epoch 818/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.5904 - val_loss: 9.4178\n",
      "Epoch 819/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.5274 - val_loss: 8.6998\n",
      "Epoch 820/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.5347 - val_loss: 9.1660\n",
      "Epoch 821/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.5465 - val_loss: 9.2562\n",
      "Epoch 822/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.3967 - val_loss: 9.5245\n",
      "Epoch 823/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.4705 - val_loss: 9.7202\n",
      "Epoch 824/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.3366 - val_loss: 9.0062\n",
      "Epoch 825/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.5819 - val_loss: 9.3010\n",
      "Epoch 826/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8501 - val_loss: 8.4268\n",
      "Epoch 827/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0785 - val_loss: 11.2167\n",
      "Epoch 828/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6034 - val_loss: 10.0389\n",
      "Epoch 829/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9385 - val_loss: 9.0621\n",
      "Epoch 830/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.6003 - val_loss: 9.9951\n",
      "Epoch 831/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.4094 - val_loss: 8.8773\n",
      "Epoch 832/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.1659 - val_loss: 8.9267\n",
      "Epoch 833/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 7.8393 - val_loss: 9.1503\n",
      "Epoch 834/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.6110 - val_loss: 8.3999\n",
      "Epoch 835/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.6956 - val_loss: 11.7786\n",
      "Epoch 836/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.6437 - val_loss: 9.2923\n",
      "Epoch 837/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.6112 - val_loss: 8.9168\n",
      "Epoch 838/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.3808 - val_loss: 9.1723\n",
      "Epoch 839/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.6708 - val_loss: 9.0555\n",
      "Epoch 840/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.3746 - val_loss: 8.5161\n",
      "Epoch 841/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.6681 - val_loss: 8.7082\n",
      "Epoch 842/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.3865 - val_loss: 9.3242\n",
      "Epoch 843/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.6383 - val_loss: 9.1712\n",
      "Epoch 844/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.8123 - val_loss: 8.3593\n",
      "Epoch 845/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.6447 - val_loss: 8.3335\n",
      "Epoch 846/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.5502 - val_loss: 9.3417\n",
      "Epoch 847/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.7444 - val_loss: 8.7845\n",
      "Epoch 848/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.4783 - val_loss: 9.7545\n",
      "Epoch 849/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.5650 - val_loss: 10.7328\n",
      "Epoch 850/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.5962 - val_loss: 9.3129\n",
      "Epoch 851/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.4820 - val_loss: 8.5287\n",
      "Epoch 852/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.5744 - val_loss: 8.4161\n",
      "Epoch 853/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.5673 - val_loss: 9.1315\n",
      "Epoch 854/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.7774 - val_loss: 9.0006\n",
      "Epoch 855/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.4348 - val_loss: 8.7010\n",
      "Epoch 856/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.3762 - val_loss: 8.6900\n",
      "Epoch 857/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.4874 - val_loss: 12.7121\n",
      "Epoch 858/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.7270 - val_loss: 10.2121\n",
      "Epoch 859/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.5684 - val_loss: 8.6395\n",
      "Epoch 860/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.4012 - val_loss: 9.1544\n",
      "Epoch 861/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1420 - val_loss: 9.7888\n",
      "Epoch 862/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.3154 - val_loss: 9.0334\n",
      "Epoch 863/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.4180 - val_loss: 9.0264\n",
      "Epoch 864/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 7.4053 - val_loss: 8.4308\n",
      "Epoch 865/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.5760 - val_loss: 9.3382\n",
      "Epoch 866/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.6879 - val_loss: 8.6040\n",
      "Epoch 867/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.5455 - val_loss: 9.3183\n",
      "Epoch 868/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.7472 - val_loss: 9.6273\n",
      "Epoch 869/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.4236 - val_loss: 8.7779\n",
      "Epoch 870/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.4706 - val_loss: 8.8847\n",
      "Epoch 871/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.5402 - val_loss: 9.5306\n",
      "Epoch 872/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9433 - val_loss: 8.7052\n",
      "Epoch 873/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.3521 - val_loss: 8.5275\n",
      "Epoch 874/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.5694 - val_loss: 9.3887\n",
      "Epoch 875/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.4184 - val_loss: 9.3923\n",
      "Epoch 876/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.2591 - val_loss: 8.4547\n",
      "Epoch 877/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.3658 - val_loss: 9.0205\n",
      "Epoch 878/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.3014 - val_loss: 8.6229\n",
      "Epoch 879/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.3810 - val_loss: 9.7893\n",
      "Epoch 880/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.7144 - val_loss: 8.7252\n",
      "Epoch 881/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.2529 - val_loss: 8.4993\n",
      "Epoch 882/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.4602 - val_loss: 8.8680\n",
      "Epoch 883/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.7980 - val_loss: 8.8644\n",
      "Epoch 884/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 7.4797 - val_loss: 8.9914\n",
      "Epoch 885/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.2439 - val_loss: 8.9589\n",
      "Epoch 886/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.3065 - val_loss: 8.6933\n",
      "Epoch 887/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.6895 - val_loss: 8.8271\n",
      "Epoch 888/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.4730 - val_loss: 8.3565\n",
      "Epoch 889/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 7.6548 - val_loss: 9.4101\n",
      "Epoch 890/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.6453 - val_loss: 8.4868\n",
      "Epoch 891/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 7.3243 - val_loss: 8.5509\n",
      "Epoch 892/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.3884 - val_loss: 8.2568\n",
      "Epoch 893/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2465 - val_loss: 9.4815\n",
      "Epoch 894/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 7.7416 - val_loss: 9.2493\n",
      "Epoch 895/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 7.5233 - val_loss: 8.4910\n",
      "Epoch 896/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 7.4813 - val_loss: 8.8336\n",
      "Epoch 897/1000\n",
      "1052/1052 [==============================] - 0s 113us/step - loss: 7.2611 - val_loss: 9.3086\n",
      "Epoch 898/1000\n",
      "1052/1052 [==============================] - 0s 118us/step - loss: 7.2626 - val_loss: 8.2853\n",
      "Epoch 899/1000\n",
      "1052/1052 [==============================] - 0s 111us/step - loss: 7.3007 - val_loss: 8.6305\n",
      "Epoch 900/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.4009 - val_loss: 8.7918\n",
      "Epoch 901/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.4370 - val_loss: 8.1573\n",
      "Epoch 902/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 164us/step - loss: 7.5880 - val_loss: 9.3170\n",
      "Epoch 903/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.3582 - val_loss: 8.7570\n",
      "Epoch 904/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.2436 - val_loss: 8.5242\n",
      "Epoch 905/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.5533 - val_loss: 8.2357\n",
      "Epoch 906/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.3598 - val_loss: 8.3694\n",
      "Epoch 907/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.3317 - val_loss: 8.3237\n",
      "Epoch 908/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.4715 - val_loss: 8.1458\n",
      "Epoch 909/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.1962 - val_loss: 8.5664\n",
      "Epoch 910/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.4355 - val_loss: 8.3633\n",
      "Epoch 911/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.1346 - val_loss: 8.5908\n",
      "Epoch 912/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 7.3451 - val_loss: 8.1266\n",
      "Epoch 913/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.3496 - val_loss: 8.7982\n",
      "Epoch 914/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.3274 - val_loss: 8.7871\n",
      "Epoch 915/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 7.3338 - val_loss: 8.7363\n",
      "Epoch 916/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 7.5520 - val_loss: 8.4296\n",
      "Epoch 917/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 7.2697 - val_loss: 8.0662\n",
      "Epoch 918/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.3188 - val_loss: 8.2191\n",
      "Epoch 919/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.3855 - val_loss: 9.8862\n",
      "Epoch 920/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 7.9755 - val_loss: 9.3080\n",
      "Epoch 921/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.3094 - val_loss: 9.3015\n",
      "Epoch 922/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.5109 - val_loss: 8.1777\n",
      "Epoch 923/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.3200 - val_loss: 8.0073\n",
      "Epoch 924/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 7.3108 - val_loss: 9.2355\n",
      "Epoch 925/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.3278 - val_loss: 9.1730\n",
      "Epoch 926/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.4482 - val_loss: 8.2260\n",
      "Epoch 927/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.3850 - val_loss: 8.8283\n",
      "Epoch 928/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.5346 - val_loss: 9.4178\n",
      "Epoch 929/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 7.4135 - 0s 98us/step - loss: 7.4369 - val_loss: 9.5121\n",
      "Epoch 930/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 7.4119 - val_loss: 8.2253\n",
      "Epoch 931/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.3747 - val_loss: 8.5865\n",
      "Epoch 932/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.6878 - val_loss: 9.2536\n",
      "Epoch 933/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.2818 - val_loss: 9.1625\n",
      "Epoch 934/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.5347 - val_loss: 9.0350\n",
      "Epoch 935/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.7111 - val_loss: 10.3251\n",
      "Epoch 936/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 7.8097 - val_loss: 8.2232\n",
      "Epoch 937/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.2930 - val_loss: 8.9530\n",
      "Epoch 938/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.3133 - val_loss: 8.9575\n",
      "Epoch 939/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.2154 - val_loss: 8.3061\n",
      "Epoch 940/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.9891 - val_loss: 8.1205\n",
      "Epoch 941/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.8865 - val_loss: 8.2604\n",
      "Epoch 942/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.2618 - val_loss: 8.0753\n",
      "Epoch 943/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.5380 - val_loss: 8.4270\n",
      "Epoch 944/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.6914 - val_loss: 8.1268\n",
      "Epoch 945/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.2018 - val_loss: 9.8568\n",
      "Epoch 946/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.4854 - val_loss: 8.6334\n",
      "Epoch 947/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.2868 - val_loss: 8.0806\n",
      "Epoch 948/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.2942 - val_loss: 8.0243\n",
      "Epoch 949/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.3042 - val_loss: 10.5909\n",
      "Epoch 950/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.4052 - val_loss: 8.9652\n",
      "Epoch 951/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.8335 - val_loss: 9.5209\n",
      "Epoch 952/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.1235 - val_loss: 10.7203\n",
      "Epoch 953/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.4289 - val_loss: 8.6678\n",
      "Epoch 954/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 7.0991 - val_loss: 9.4142\n",
      "Epoch 955/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.4705 - val_loss: 8.1885\n",
      "Epoch 956/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.4059 - val_loss: 8.7523\n",
      "Epoch 957/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.6844 - val_loss: 7.8911\n",
      "Epoch 958/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.2401 - val_loss: 8.1809\n",
      "Epoch 959/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.7841 - val_loss: 9.2649\n",
      "Epoch 960/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.1477 - val_loss: 8.9679\n",
      "Epoch 961/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.2062 - val_loss: 8.0460\n",
      "Epoch 962/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.0395 - val_loss: 8.7163\n",
      "Epoch 963/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.2379 - val_loss: 7.8379\n",
      "Epoch 964/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.4498 - val_loss: 8.6282\n",
      "Epoch 965/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.1751 - val_loss: 8.1987\n",
      "Epoch 966/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.3709 - val_loss: 8.9469\n",
      "Epoch 967/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.0730 - val_loss: 9.0201\n",
      "Epoch 968/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.2199 - val_loss: 8.5665\n",
      "Epoch 969/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.2156 - val_loss: 7.8131\n",
      "Epoch 970/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.2084 - val_loss: 8.6427\n",
      "Epoch 971/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.2188 - val_loss: 8.3719\n",
      "Epoch 972/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.0298 - val_loss: 8.3770\n",
      "Epoch 973/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.0101 - val_loss: 12.1602\n",
      "Epoch 974/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.8853 - val_loss: 8.6892\n",
      "Epoch 975/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.2685 - val_loss: 9.1609\n",
      "Epoch 976/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.1867 - val_loss: 8.5925\n",
      "Epoch 977/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.2361 - val_loss: 7.9088\n",
      "Epoch 978/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.1152 - val_loss: 8.1664\n",
      "Epoch 979/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.1752 - val_loss: 8.1241\n",
      "Epoch 980/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.1141 - val_loss: 9.0826\n",
      "Epoch 981/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.0540 - val_loss: 9.6236\n",
      "Epoch 982/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.3812 - val_loss: 8.2963\n",
      "Epoch 983/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.2144 - val_loss: 8.3868\n",
      "Epoch 984/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.1700 - val_loss: 8.0391\n",
      "Epoch 985/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.9643 - val_loss: 8.4616\n",
      "Epoch 986/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.9314 - val_loss: 8.0146\n",
      "Epoch 987/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.3035 - val_loss: 8.4536\n",
      "Epoch 988/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.4111 - val_loss: 7.9479\n",
      "Epoch 989/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 7.6472 - val_loss: 8.0817\n",
      "Epoch 990/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.6628 - val_loss: 8.1153\n",
      "Epoch 991/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2728 - val_loss: 10.0793\n",
      "Epoch 992/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.6601 - val_loss: 8.6338\n",
      "Epoch 993/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.4939 - val_loss: 8.7302\n",
      "Epoch 994/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.1572 - val_loss: 9.6275\n",
      "Epoch 995/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.2873 - val_loss: 7.8269\n",
      "Epoch 996/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.5405 - val_loss: 8.1653\n",
      "Epoch 997/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.5118 - val_loss: 8.9056\n",
      "Epoch 998/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.1253 - val_loss: 8.4039\n",
      "Epoch 999/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.1844 - val_loss: 7.8621\n",
      "Epoch 1000/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 7.1537 - val_loss: 8.6176\n",
      "6.85115826868378\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-3.9251552 ,  3.884789  ,  0.88322246,  2.4796124 , -0.5934038 ,\n",
       "          4.207986  , -0.27696043, -0.28418627, -0.25000414,  0.28551295],\n",
       "        [-0.36719373, -0.19147044, -0.09302025, -0.12349726, -1.121923  ,\n",
       "         -0.08937724, -0.16827732, -0.17022455, -0.1597288 ,  1.4026983 ],\n",
       "        [-0.50859314, -0.09218717,  0.28319323, -0.1698862 , -1.825502  ,\n",
       "          1.1822263 , -0.35445282, -0.36069253, -0.3296788 ,  1.6317997 ],\n",
       "        [ 0.29454562, -0.08966386, -0.07818668,  0.20152716, -0.61068124,\n",
       "         -0.19608739,  0.47655243,  0.4922266 ,  0.41713476, -0.28005102],\n",
       "        [-3.8370223 ,  0.3724117 ,  0.8380013 ,  0.4623429 , -0.7293927 ,\n",
       "          0.23067601, -0.27980447, -0.28699806, -0.2540315 , -0.65354174]],\n",
       "       dtype=float32),\n",
       " array([-5.432587  ,  1.9754231 , -0.41158035,  3.2360444 ,  5.588499  ,\n",
       "         5.098453  ,  2.6730318 ,  2.656358  ,  2.7679121 ,  1.0600914 ],\n",
       "       dtype=float32),\n",
       " array([[-0.3393439 ,  0.29086336, -1.4540825 , -0.98546046,  1.270141  ],\n",
       "        [-1.3463675 ,  0.19241019, -0.612811  , -0.52817017,  0.99118894],\n",
       "        [-0.42538813,  0.4650029 , -0.48661476, -0.82901806,  0.53556484],\n",
       "        [ 1.8536266 , -1.5311843 ,  1.5114081 ,  1.6830914 , -1.4476568 ],\n",
       "        [ 0.99355364, -2.0493014 ,  1.8150781 ,  1.0865438 , -2.1577513 ],\n",
       "        [ 2.5640988 , -1.5770993 ,  2.12365   ,  2.6805515 , -2.7315407 ],\n",
       "        [ 2.1120195 , -2.092341  ,  2.1264913 ,  1.6414047 , -1.5431693 ],\n",
       "        [ 1.9139444 , -1.5845755 ,  1.9481484 ,  1.9911705 , -1.7311081 ],\n",
       "        [ 1.5587114 , -1.932469  ,  1.3687981 ,  1.6296802 , -1.8876396 ],\n",
       "        [-0.10041068,  0.72275615, -1.3030246 , -1.0051564 ,  0.42698383]],\n",
       "       dtype=float32),\n",
       " array([ 1.9041384, -1.8619859,  1.9380599,  1.9436315, -1.9910604],\n",
       "       dtype=float32),\n",
       " array([[ 1.7875149],\n",
       "        [-1.56246  ],\n",
       "        [ 1.8462996],\n",
       "        [ 1.8940392],\n",
       "        [-2.324535 ]], dtype=float32),\n",
       " array([2.1924999], dtype=float32)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_airfoil, history_airfoil, evaluate_airfoil=NN_model_structure_regression_4(X_train_airfoil, X_val_airfoil, Y_train_airfoil, Y_val_airfoil, adam2, 32, 1000, x_test_airfoil, y_test_airfoil)\n",
    "model_airfoil.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_airfoil.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_airfoil_structure4_4th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 181\n",
      "Trainable params: 181\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1052 samples, validate on 225 samples\n",
      "Epoch 1/1000\n",
      "1052/1052 [==============================] - 0s 261us/step - loss: 6562.4274 - val_loss: 553.8491\n",
      "Epoch 2/1000\n",
      "1052/1052 [==============================] - 0s 110us/step - loss: 207.1608 - val_loss: 60.0343\n",
      "Epoch 3/1000\n",
      "1052/1052 [==============================] - 0s 108us/step - loss: 43.1413 - val_loss: 34.4518\n",
      "Epoch 4/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 33.5119 - val_loss: 30.9178\n",
      "Epoch 5/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 29.1816 - val_loss: 28.5179\n",
      "Epoch 6/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 26.3950 - val_loss: 27.7867\n",
      "Epoch 7/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 24.4416 - val_loss: 26.7156\n",
      "Epoch 8/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 23.0475 - val_loss: 25.8492\n",
      "Epoch 9/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 22.2590 - val_loss: 25.0677\n",
      "Epoch 10/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 21.3881 - val_loss: 24.6456\n",
      "Epoch 11/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 20.2988 - val_loss: 24.6512\n",
      "Epoch 12/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 19.9399 - val_loss: 24.1744\n",
      "Epoch 13/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 19.6750 - val_loss: 23.7224\n",
      "Epoch 14/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 19.1394 - val_loss: 23.7655\n",
      "Epoch 15/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.9453 - val_loss: 22.9658\n",
      "Epoch 16/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.6750 - val_loss: 22.6682\n",
      "Epoch 17/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.3326 - val_loss: 22.3007\n",
      "Epoch 18/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 18.2519 - val_loss: 22.4650\n",
      "Epoch 19/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.0428 - val_loss: 22.1363\n",
      "Epoch 20/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.8351 - val_loss: 21.8558\n",
      "Epoch 21/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.7382 - val_loss: 21.6801\n",
      "Epoch 22/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 17.9477 - val_loss: 21.8352\n",
      "Epoch 23/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.6238 - val_loss: 21.5223\n",
      "Epoch 24/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.5147 - val_loss: 21.3637\n",
      "Epoch 25/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.4315 - val_loss: 21.2029\n",
      "Epoch 26/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 17.2613 - val_loss: 20.7709\n",
      "Epoch 27/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.2739 - val_loss: 21.3036\n",
      "Epoch 28/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.1421 - val_loss: 20.9093\n",
      "Epoch 29/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.5846 - val_loss: 20.8619\n",
      "Epoch 30/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.0929 - val_loss: 21.2814\n",
      "Epoch 31/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 16.9574 - val_loss: 20.3326\n",
      "Epoch 32/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 16.8775 - val_loss: 20.1192\n",
      "Epoch 33/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 16.7417 - val_loss: 20.1208\n",
      "Epoch 34/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 16.6886 - val_loss: 20.2166\n",
      "Epoch 35/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 16.7089 - val_loss: 20.3141\n",
      "Epoch 36/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 16.6246 - val_loss: 19.8136\n",
      "Epoch 37/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 16.5464 - val_loss: 20.1146\n",
      "Epoch 38/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 16.3572 - val_loss: 19.8763\n",
      "Epoch 39/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 16.3215 - val_loss: 19.3611\n",
      "Epoch 40/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 16.2331 - val_loss: 19.4116\n",
      "Epoch 41/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 16.4493 - val_loss: 19.6187\n",
      "Epoch 42/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 15.9074 - val_loss: 19.0982\n",
      "Epoch 43/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 16.1521 - val_loss: 20.5395\n",
      "Epoch 44/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 16.3467 - val_loss: 19.1844\n",
      "Epoch 45/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 15.8044 - val_loss: 19.0842\n",
      "Epoch 46/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 15.7733 - val_loss: 19.0882\n",
      "Epoch 47/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 15.6520 - val_loss: 18.9721\n",
      "Epoch 48/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 16.1921 - val_loss: 19.0649\n",
      "Epoch 49/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 15.7682 - val_loss: 18.5645\n",
      "Epoch 50/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 15.7047 - val_loss: 18.8471\n",
      "Epoch 51/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 15.2063 - val_loss: 18.8448\n",
      "Epoch 52/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 15.2712 - val_loss: 19.0668\n",
      "Epoch 53/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 15.4192 - val_loss: 18.0448\n",
      "Epoch 54/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 15.2125 - val_loss: 19.0973\n",
      "Epoch 55/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.9460 - val_loss: 18.2940\n",
      "Epoch 56/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 15.3007 - val_loss: 19.1340\n",
      "Epoch 57/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 15.1804 - val_loss: 18.2573\n",
      "Epoch 58/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.9752 - val_loss: 17.8879\n",
      "Epoch 59/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.8614 - val_loss: 18.0747\n",
      "Epoch 60/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.9492 - val_loss: 18.3321\n",
      "Epoch 61/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 15.0102 - val_loss: 17.7571\n",
      "Epoch 62/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.7531 - val_loss: 18.4086\n",
      "Epoch 63/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.6318 - val_loss: 17.2960\n",
      "Epoch 64/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.6172 - val_loss: 17.9642\n",
      "Epoch 65/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.6670 - val_loss: 17.7098\n",
      "Epoch 66/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.4280 - val_loss: 17.8157\n",
      "Epoch 67/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.6765 - val_loss: 17.4997\n",
      "Epoch 68/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.5646 - val_loss: 17.1268\n",
      "Epoch 69/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.7150 - val_loss: 17.8093\n",
      "Epoch 70/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.7578 - val_loss: 17.1609\n",
      "Epoch 71/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.4673 - val_loss: 17.3183\n",
      "Epoch 72/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.3204 - val_loss: 17.1021\n",
      "Epoch 73/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.4359 - val_loss: 18.2927\n",
      "Epoch 74/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 14.4323 - val_loss: 17.7781\n",
      "Epoch 75/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.6820 - val_loss: 18.6292\n",
      "Epoch 76/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.1355 - val_loss: 16.8942\n",
      "Epoch 77/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.8734 - val_loss: 19.2667\n",
      "Epoch 78/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 14.4856 - val_loss: 17.9342\n",
      "Epoch 79/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.1276 - val_loss: 19.3571\n",
      "Epoch 80/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.7099 - val_loss: 17.4281\n",
      "Epoch 81/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.6578 - val_loss: 18.2991\n",
      "Epoch 82/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.7738 - val_loss: 17.3414\n",
      "Epoch 83/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.6366 - val_loss: 17.0458\n",
      "Epoch 84/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.5139 - val_loss: 17.4091\n",
      "Epoch 85/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 13.6527 - val_loss: 19.1558\n",
      "Epoch 86/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.5322 - val_loss: 16.8601\n",
      "Epoch 87/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.4761 - val_loss: 16.9694\n",
      "Epoch 88/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.5134 - val_loss: 16.9428\n",
      "Epoch 89/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 13.3338 - val_loss: 17.1845\n",
      "Epoch 90/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 13.1077 - val_loss: 17.7272\n",
      "Epoch 91/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 13.7107 - val_loss: 17.9809\n",
      "Epoch 92/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 13.3428 - val_loss: 16.4921\n",
      "Epoch 93/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 13.1481 - val_loss: 17.1610\n",
      "Epoch 94/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 13.0057 - val_loss: 17.8814\n",
      "Epoch 95/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 12.9620 - val_loss: 16.8170\n",
      "Epoch 96/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 13.0874 - val_loss: 16.4790\n",
      "Epoch 97/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 12.9522 - val_loss: 16.4128\n",
      "Epoch 98/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.9939 - val_loss: 17.9775\n",
      "Epoch 99/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 12.9859 - val_loss: 17.2081\n",
      "Epoch 100/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.7783 - val_loss: 17.5604\n",
      "Epoch 101/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.9703 - val_loss: 18.4010\n",
      "Epoch 102/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.6676 - val_loss: 17.5473\n",
      "Epoch 103/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.5770 - val_loss: 16.3402\n",
      "Epoch 104/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.6480 - val_loss: 16.6597\n",
      "Epoch 105/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 12.5372 - val_loss: 18.2782\n",
      "Epoch 106/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.5334 - val_loss: 15.8115\n",
      "Epoch 107/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 12.6467 - val_loss: 17.1474\n",
      "Epoch 108/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 12.6428 - val_loss: 16.9790\n",
      "Epoch 109/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.7423 - val_loss: 16.4766\n",
      "Epoch 110/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.4789 - val_loss: 15.8749\n",
      "Epoch 111/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.0205 - val_loss: 15.8814\n",
      "Epoch 112/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.0804 - val_loss: 16.0292\n",
      "Epoch 113/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.6750 - val_loss: 14.9138\n",
      "Epoch 114/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.7297 - val_loss: 15.0985\n",
      "Epoch 115/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.8985 - val_loss: 16.2837\n",
      "Epoch 116/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.6977 - val_loss: 14.7336\n",
      "Epoch 117/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.6271 - val_loss: 14.5627\n",
      "Epoch 118/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.6654 - val_loss: 14.5910\n",
      "Epoch 119/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.9837 - val_loss: 14.6631\n",
      "Epoch 120/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.6199 - val_loss: 14.7247\n",
      "Epoch 121/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 11.5517 - val_loss: 14.3737\n",
      "Epoch 122/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.2912 - val_loss: 14.2926\n",
      "Epoch 123/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.5713 - val_loss: 14.0457\n",
      "Epoch 124/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 10.9825 - val_loss: 15.5145\n",
      "Epoch 125/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.1509 - val_loss: 13.8276\n",
      "Epoch 126/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.6324 - val_loss: 13.4585\n",
      "Epoch 127/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.7428 - val_loss: 14.3179\n",
      "Epoch 128/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.5209 - val_loss: 15.9173\n",
      "Epoch 129/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.9293 - val_loss: 13.6295\n",
      "Epoch 130/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.7953 - val_loss: 14.4996\n",
      "Epoch 131/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.1162 - val_loss: 13.3369\n",
      "Epoch 132/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.5610 - val_loss: 13.4598\n",
      "Epoch 133/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.8429 - val_loss: 13.0799\n",
      "Epoch 134/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.4473 - val_loss: 14.5056\n",
      "Epoch 135/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.5841 - val_loss: 17.8877\n",
      "Epoch 136/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.4387 - val_loss: 12.9370\n",
      "Epoch 137/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.1604 - val_loss: 15.6287\n",
      "Epoch 138/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.6661 - val_loss: 13.1861\n",
      "Epoch 139/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.6951 - val_loss: 12.3256\n",
      "Epoch 140/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.2459 - val_loss: 12.6263\n",
      "Epoch 141/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 10.1668 - val_loss: 12.0757\n",
      "Epoch 142/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.4083 - val_loss: 13.2149\n",
      "Epoch 143/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.7562 - val_loss: 12.4002\n",
      "Epoch 144/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.5113 - val_loss: 13.3197\n",
      "Epoch 145/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.9684 - val_loss: 14.3751\n",
      "Epoch 146/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.8651 - val_loss: 12.3391\n",
      "Epoch 147/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.8263 - val_loss: 12.6050\n",
      "Epoch 148/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.1308 - val_loss: 12.9746\n",
      "Epoch 149/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 10.4752 - val_loss: 13.3954\n",
      "Epoch 150/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.4442 - val_loss: 12.7787\n",
      "Epoch 151/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.0791 - val_loss: 13.3622\n",
      "Epoch 152/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.2110 - val_loss: 12.7659\n",
      "Epoch 153/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.1474 - val_loss: 12.6850\n",
      "Epoch 154/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.0988 - val_loss: 11.6792\n",
      "Epoch 155/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.2406 - val_loss: 12.6887\n",
      "Epoch 156/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.0796 - val_loss: 13.2278\n",
      "Epoch 157/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.8779 - val_loss: 12.1710\n",
      "Epoch 158/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.5660 - val_loss: 11.4590\n",
      "Epoch 159/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.9157 - val_loss: 11.8441\n",
      "Epoch 160/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.1613 - val_loss: 12.2517\n",
      "Epoch 161/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.8777 - val_loss: 13.1831\n",
      "Epoch 162/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.8781 - val_loss: 12.0463\n",
      "Epoch 163/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.5993 - val_loss: 12.3424\n",
      "Epoch 164/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.6491 - val_loss: 11.8245\n",
      "Epoch 165/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.8646 - val_loss: 13.1260\n",
      "Epoch 166/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.4490 - val_loss: 12.7068\n",
      "Epoch 167/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 10.3665 - val_loss: 12.1070\n",
      "Epoch 168/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.7114 - val_loss: 11.3634\n",
      "Epoch 169/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2258 - val_loss: 11.6103\n",
      "Epoch 170/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.6458 - val_loss: 11.5528\n",
      "Epoch 171/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.6284 - val_loss: 13.9546\n",
      "Epoch 172/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.1481 - val_loss: 12.9049\n",
      "Epoch 173/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.4656 - val_loss: 10.8776\n",
      "Epoch 174/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1522 - val_loss: 11.5322\n",
      "Epoch 175/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.3899 - val_loss: 10.4776\n",
      "Epoch 176/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.6818 - val_loss: 11.2095\n",
      "Epoch 177/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2940 - val_loss: 13.4278\n",
      "Epoch 178/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.7975 - val_loss: 10.4721\n",
      "Epoch 179/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5467 - val_loss: 11.5637\n",
      "Epoch 180/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.5805 - val_loss: 10.5747\n",
      "Epoch 181/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8087 - val_loss: 10.9660\n",
      "Epoch 182/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4052 - val_loss: 11.9076\n",
      "Epoch 183/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3777 - val_loss: 10.3199\n",
      "Epoch 184/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1296 - val_loss: 9.5274\n",
      "Epoch 185/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3180 - val_loss: 9.2826\n",
      "Epoch 186/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0498 - val_loss: 9.1393\n",
      "Epoch 187/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.7759 - val_loss: 10.9059\n",
      "Epoch 188/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.9802 - val_loss: 10.1958\n",
      "Epoch 189/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0834 - val_loss: 10.1338\n",
      "Epoch 190/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.1137 - val_loss: 9.7639\n",
      "Epoch 191/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.8982 - val_loss: 9.3206\n",
      "Epoch 192/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.8480 - val_loss: 9.3652\n",
      "Epoch 193/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3272 - val_loss: 9.0734\n",
      "Epoch 194/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.8391 - val_loss: 10.0653\n",
      "Epoch 195/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3259 - val_loss: 9.6469\n",
      "Epoch 196/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.5876 - val_loss: 9.9090\n",
      "Epoch 197/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.4976 - val_loss: 8.4751\n",
      "Epoch 198/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.8268 - val_loss: 8.6413\n",
      "Epoch 199/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.8963 - val_loss: 9.2217\n",
      "Epoch 200/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.3738 - val_loss: 9.2506\n",
      "Epoch 201/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1567 - val_loss: 10.8262\n",
      "Epoch 202/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.9549 - val_loss: 8.3182\n",
      "Epoch 203/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.3160 - val_loss: 8.3990\n",
      "Epoch 204/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.5719 - val_loss: 8.8666\n",
      "Epoch 205/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.1901 - val_loss: 9.2765\n",
      "Epoch 206/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.2012 - val_loss: 7.8813\n",
      "Epoch 207/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.5928 - val_loss: 8.0495\n",
      "Epoch 208/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.5934 - val_loss: 9.5899\n",
      "Epoch 209/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.2160 - val_loss: 8.5133\n",
      "Epoch 210/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9271 - val_loss: 8.2727\n",
      "Epoch 211/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.1269 - val_loss: 8.4513\n",
      "Epoch 212/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.9571 - val_loss: 8.0885\n",
      "Epoch 213/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.3791 - val_loss: 8.0837\n",
      "Epoch 214/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.0309 - val_loss: 8.0813\n",
      "Epoch 215/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.3610 - val_loss: 8.4947\n",
      "Epoch 216/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.2720 - val_loss: 7.8333\n",
      "Epoch 217/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.9972 - val_loss: 8.1048\n",
      "Epoch 218/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.0128 - val_loss: 7.9258\n",
      "Epoch 219/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.3763 - val_loss: 7.7777\n",
      "Epoch 220/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.0415 - val_loss: 8.4868\n",
      "Epoch 221/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.1190 - val_loss: 7.8084\n",
      "Epoch 222/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.1612 - val_loss: 8.1938\n",
      "Epoch 223/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.8969 - val_loss: 7.6031\n",
      "Epoch 224/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.8842 - val_loss: 7.9029\n",
      "Epoch 225/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.2790 - val_loss: 8.6460\n",
      "Epoch 226/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.2284 - val_loss: 8.4486\n",
      "Epoch 227/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.0975 - val_loss: 7.9688\n",
      "Epoch 228/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.0968 - val_loss: 7.5099\n",
      "Epoch 229/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.1145 - val_loss: 8.9373\n",
      "Epoch 230/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.9690 - val_loss: 7.5707\n",
      "Epoch 231/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.8410 - val_loss: 9.3876\n",
      "Epoch 232/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.9528 - val_loss: 8.3154\n",
      "Epoch 233/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.2594 - val_loss: 7.8662\n",
      "Epoch 234/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.2656 - val_loss: 8.4742\n",
      "Epoch 235/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.6699 - val_loss: 8.7956\n",
      "Epoch 236/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.3832 - val_loss: 8.1818\n",
      "Epoch 237/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.3217 - val_loss: 9.4157\n",
      "Epoch 238/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.6037 - val_loss: 8.0280\n",
      "Epoch 239/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.2999 - val_loss: 8.3051\n",
      "Epoch 240/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.3537 - val_loss: 7.5355\n",
      "Epoch 241/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.1880 - val_loss: 7.8384\n",
      "Epoch 242/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.9004 - val_loss: 7.6394\n",
      "Epoch 243/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.7948 - val_loss: 7.8203\n",
      "Epoch 244/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.1837 - val_loss: 7.5965\n",
      "Epoch 245/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.6440 - val_loss: 7.6391\n",
      "Epoch 246/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.8772 - val_loss: 7.2082\n",
      "Epoch 247/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.0023 - val_loss: 7.9771\n",
      "Epoch 248/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.0345 - val_loss: 9.1172\n",
      "Epoch 249/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.1326 - val_loss: 9.3397\n",
      "Epoch 250/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.0097 - val_loss: 8.8072\n",
      "Epoch 251/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.7427 - val_loss: 7.4362\n",
      "Epoch 252/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.8767 - val_loss: 7.6036\n",
      "Epoch 253/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.0057 - val_loss: 7.2034\n",
      "Epoch 254/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.7708 - val_loss: 9.6358\n",
      "Epoch 255/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.3019 - val_loss: 8.9654\n",
      "Epoch 256/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.7020 - val_loss: 8.3811\n",
      "Epoch 257/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.0021 - val_loss: 7.5328\n",
      "Epoch 258/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.7029 - val_loss: 7.3490\n",
      "Epoch 259/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.8282 - val_loss: 7.2445\n",
      "Epoch 260/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 6.8447 - val_loss: 8.5467\n",
      "Epoch 261/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 6.8365 - val_loss: 7.6287\n",
      "Epoch 262/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 6.7819 - val_loss: 9.0418\n",
      "Epoch 263/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 6.8190 - val_loss: 8.2805\n",
      "Epoch 264/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 7.3582 - val_loss: 7.1295\n",
      "Epoch 265/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 6.8334 - val_loss: 7.3671\n",
      "Epoch 266/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.0369 - val_loss: 8.9920\n",
      "Epoch 267/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 6.7324 - val_loss: 7.8444\n",
      "Epoch 268/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.0791 - val_loss: 8.9470\n",
      "Epoch 269/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.8595 - val_loss: 7.1146\n",
      "Epoch 270/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.6504 - val_loss: 8.4395\n",
      "Epoch 271/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.9143 - val_loss: 9.9586\n",
      "Epoch 272/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.9911 - val_loss: 9.8075\n",
      "Epoch 273/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.8297 - val_loss: 9.8716\n",
      "Epoch 274/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.1629 - val_loss: 7.7315\n",
      "Epoch 275/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.9854 - val_loss: 7.6208\n",
      "Epoch 276/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.3154 - val_loss: 7.9937\n",
      "Epoch 277/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.1907 - val_loss: 7.2249\n",
      "Epoch 278/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.5695 - val_loss: 7.6029\n",
      "Epoch 279/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.9001 - val_loss: 7.6593\n",
      "Epoch 280/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.5697 - val_loss: 7.8058\n",
      "Epoch 281/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.7343 - val_loss: 6.9503\n",
      "Epoch 282/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.6750 - val_loss: 8.2389\n",
      "Epoch 283/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.7429 - val_loss: 7.7803\n",
      "Epoch 284/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.6501 - val_loss: 10.4013\n",
      "Epoch 285/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0326 - val_loss: 7.7772\n",
      "Epoch 286/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.1887 - val_loss: 8.0568\n",
      "Epoch 287/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.4542 - val_loss: 6.9746\n",
      "Epoch 288/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.5236 - val_loss: 7.1843\n",
      "Epoch 289/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.2172 - val_loss: 8.6093\n",
      "Epoch 290/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.6981 - val_loss: 7.0149\n",
      "Epoch 291/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.6189 - val_loss: 7.2110\n",
      "Epoch 292/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.7258 - val_loss: 7.4351\n",
      "Epoch 293/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 6.5668 - val_loss: 6.9707\n",
      "Epoch 294/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 83us/step - loss: 6.9879 - val_loss: 8.2530\n",
      "Epoch 295/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.8406 - val_loss: 7.7823\n",
      "Epoch 296/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.4206 - val_loss: 6.9004\n",
      "Epoch 297/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.6300 - val_loss: 7.8603\n",
      "Epoch 298/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.9752 - val_loss: 8.9583\n",
      "Epoch 299/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.6680 - val_loss: 7.1145\n",
      "Epoch 300/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.6456 - val_loss: 7.7971\n",
      "Epoch 301/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.5879 - val_loss: 8.1470\n",
      "Epoch 302/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.6828 - val_loss: 7.3947\n",
      "Epoch 303/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.8693 - val_loss: 9.5566\n",
      "Epoch 304/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.7949 - val_loss: 7.0515\n",
      "Epoch 305/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.5606 - val_loss: 7.1818\n",
      "Epoch 306/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.5475 - val_loss: 8.5808\n",
      "Epoch 307/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.7387 - val_loss: 8.4708\n",
      "Epoch 308/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.5345 - val_loss: 7.3129\n",
      "Epoch 309/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.9499 - val_loss: 6.7918\n",
      "Epoch 310/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.5316 - val_loss: 7.6656\n",
      "Epoch 311/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.6188 - val_loss: 7.1056\n",
      "Epoch 312/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.5675 - val_loss: 7.6349\n",
      "Epoch 313/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.8253 - val_loss: 7.6514\n",
      "Epoch 314/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 6.7525 - val_loss: 7.4427\n",
      "Epoch 315/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.5436 - val_loss: 6.9608\n",
      "Epoch 316/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.4842 - val_loss: 7.6197\n",
      "Epoch 317/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.8176 - val_loss: 6.8786\n",
      "Epoch 318/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.6171 - val_loss: 6.6350\n",
      "Epoch 319/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.9423 - val_loss: 7.0625\n",
      "Epoch 320/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.3813 - val_loss: 7.0591\n",
      "Epoch 321/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.5697 - val_loss: 7.8467\n",
      "Epoch 322/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 6.5637 - val_loss: 7.3916\n",
      "Epoch 323/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.3937 - val_loss: 7.6834\n",
      "Epoch 324/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.1308 - val_loss: 7.0324\n",
      "Epoch 325/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.6760 - val_loss: 8.0767\n",
      "Epoch 326/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.7482 - val_loss: 8.2936\n",
      "Epoch 327/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.4768 - val_loss: 7.9134\n",
      "Epoch 328/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.7148 - val_loss: 8.0672\n",
      "Epoch 329/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.6899 - val_loss: 7.3968\n",
      "Epoch 330/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.4617 - val_loss: 7.6183\n",
      "Epoch 331/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.8785 - val_loss: 8.8699\n",
      "Epoch 332/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.3129 - val_loss: 6.8523\n",
      "Epoch 333/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.5610 - val_loss: 7.4856\n",
      "Epoch 334/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.6631 - val_loss: 10.0787\n",
      "Epoch 335/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.9235 - val_loss: 6.7284\n",
      "Epoch 336/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.4611 - val_loss: 7.2398\n",
      "Epoch 337/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.5349 - val_loss: 6.8256\n",
      "Epoch 338/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.3821 - val_loss: 6.8312\n",
      "Epoch 339/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 6.9796 - val_loss: 8.7205\n",
      "Epoch 340/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.9540 - val_loss: 7.5454\n",
      "Epoch 341/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.7790 - val_loss: 7.5816\n",
      "Epoch 342/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.9613 - val_loss: 7.2008\n",
      "Epoch 343/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.4104 - val_loss: 7.9712\n",
      "Epoch 344/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.7132 - val_loss: 7.4104\n",
      "Epoch 345/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.6675 - val_loss: 7.4736\n",
      "Epoch 346/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.5683 - val_loss: 7.5625\n",
      "Epoch 347/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.4399 - val_loss: 6.6567\n",
      "Epoch 348/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.5319 - val_loss: 7.4771\n",
      "Epoch 349/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.1018 - val_loss: 7.2504\n",
      "Epoch 350/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.9036 - val_loss: 7.9155\n",
      "Epoch 351/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.7314 - val_loss: 6.9607\n",
      "Epoch 352/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.5019 - val_loss: 7.4288\n",
      "Epoch 353/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.3752 - val_loss: 6.8829\n",
      "Epoch 354/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.5266 - val_loss: 6.8191\n",
      "Epoch 355/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.3400 - val_loss: 7.8431\n",
      "Epoch 356/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.2910 - val_loss: 7.1656\n",
      "Epoch 357/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.1008 - val_loss: 6.6274\n",
      "Epoch 358/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.7860 - val_loss: 6.5685\n",
      "Epoch 359/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.7869 - val_loss: 6.7776\n",
      "Epoch 360/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.2176 - val_loss: 6.7713\n",
      "Epoch 361/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.1167 - val_loss: 7.1279\n",
      "Epoch 362/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.2397 - val_loss: 7.4975\n",
      "Epoch 363/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.6881 - val_loss: 9.1327\n",
      "Epoch 364/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.6642 - val_loss: 8.0812\n",
      "Epoch 365/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.3616 - val_loss: 6.3678\n",
      "Epoch 366/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.9913 - val_loss: 6.8695\n",
      "Epoch 367/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 6.001 - 0s 82us/step - loss: 6.2883 - val_loss: 6.7691\n",
      "Epoch 368/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.3132 - val_loss: 7.9474\n",
      "Epoch 369/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.5927 - val_loss: 6.7061\n",
      "Epoch 370/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.4744 - val_loss: 7.6068\n",
      "Epoch 371/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.4332 - val_loss: 7.6391\n",
      "Epoch 372/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.2335 - val_loss: 7.6631\n",
      "Epoch 373/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.0827 - val_loss: 7.1397\n",
      "Epoch 374/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.0527 - val_loss: 6.7772\n",
      "Epoch 375/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.3976 - val_loss: 6.7999\n",
      "Epoch 376/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.1413 - val_loss: 7.0362\n",
      "Epoch 377/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.4903 - val_loss: 7.1728\n",
      "Epoch 378/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 6.0855 - val_loss: 6.8414\n",
      "Epoch 379/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.2884 - val_loss: 6.6995\n",
      "Epoch 380/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.2681 - val_loss: 6.6929\n",
      "Epoch 381/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.2876 - val_loss: 7.1994\n",
      "Epoch 382/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.6699 - val_loss: 6.6929\n",
      "Epoch 383/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.7806 - val_loss: 6.3379\n",
      "Epoch 384/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.5374 - val_loss: 6.7003\n",
      "Epoch 385/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.3192 - val_loss: 6.8060\n",
      "Epoch 386/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.7132 - val_loss: 7.2699\n",
      "Epoch 387/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.6089 - val_loss: 7.9408\n",
      "Epoch 388/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.3438 - val_loss: 7.2134\n",
      "Epoch 389/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.3829 - val_loss: 8.2677\n",
      "Epoch 390/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.5531 - val_loss: 7.6462\n",
      "Epoch 391/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.5967 - val_loss: 6.8563\n",
      "Epoch 392/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.3065 - val_loss: 8.8725\n",
      "Epoch 393/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.6730 - val_loss: 8.1620\n",
      "Epoch 394/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.5102 - val_loss: 6.8258\n",
      "Epoch 395/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.2084 - val_loss: 7.3160\n",
      "Epoch 396/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.1186 - val_loss: 7.8956\n",
      "Epoch 397/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.4632 - val_loss: 6.4099\n",
      "Epoch 398/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.9951 - val_loss: 7.1400\n",
      "Epoch 399/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.2538 - val_loss: 6.7819\n",
      "Epoch 400/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.0775 - val_loss: 6.8238\n",
      "Epoch 401/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.1117 - val_loss: 7.3886\n",
      "Epoch 402/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.0551 - val_loss: 6.5393\n",
      "Epoch 403/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.1353 - val_loss: 8.9876\n",
      "Epoch 404/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.4140 - val_loss: 6.4226\n",
      "Epoch 405/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.0352 - val_loss: 6.4025\n",
      "Epoch 406/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.2334 - val_loss: 6.6273\n",
      "Epoch 407/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.6852 - val_loss: 7.5576\n",
      "Epoch 408/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.3910 - val_loss: 6.5120\n",
      "Epoch 409/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.3193 - val_loss: 6.6285\n",
      "Epoch 410/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.1287 - val_loss: 6.9647\n",
      "Epoch 411/1000\n",
      "1052/1052 [==============================] - 0s 134us/step - loss: 6.5536 - val_loss: 7.5517\n",
      "Epoch 412/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 6.1094 - val_loss: 6.2654\n",
      "Epoch 413/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 6.3652 - val_loss: 6.8460\n",
      "Epoch 414/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 6.2138 - val_loss: 6.5576\n",
      "Epoch 415/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.5812 - val_loss: 6.8025\n",
      "Epoch 416/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.3544 - val_loss: 7.0883\n",
      "Epoch 417/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 6.2551 - val_loss: 7.2291\n",
      "Epoch 418/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.3817 - val_loss: 6.3401\n",
      "Epoch 419/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.3670 - val_loss: 7.2204\n",
      "Epoch 420/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.2972 - val_loss: 7.2722\n",
      "Epoch 421/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 6.3407 - val_loss: 8.0256\n",
      "Epoch 422/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.1335 - val_loss: 7.1679\n",
      "Epoch 423/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.2928 - val_loss: 7.5971\n",
      "Epoch 424/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 6.190 - 0s 85us/step - loss: 6.3549 - val_loss: 6.1848\n",
      "Epoch 425/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 6.3512 - val_loss: 7.6338\n",
      "Epoch 426/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.3770 - val_loss: 6.1859\n",
      "Epoch 427/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.9831 - val_loss: 6.5450\n",
      "Epoch 428/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.1959 - val_loss: 7.2563\n",
      "Epoch 429/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.3987 - val_loss: 7.3083\n",
      "Epoch 430/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.1084 - val_loss: 6.3309\n",
      "Epoch 431/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.4679 - val_loss: 7.4441\n",
      "Epoch 432/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 6.0596 - val_loss: 7.2550\n",
      "Epoch 433/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 6.1707 - val_loss: 6.8666\n",
      "Epoch 434/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 6.0212 - val_loss: 6.1974\n",
      "Epoch 435/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.8976 - val_loss: 7.6132\n",
      "Epoch 436/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 6.2572 - val_loss: 7.2329\n",
      "Epoch 437/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 6.5076 - val_loss: 7.0576\n",
      "Epoch 438/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.5157 - val_loss: 6.4990\n",
      "Epoch 439/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.1911 - val_loss: 6.8314\n",
      "Epoch 440/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.9731 - val_loss: 6.6355\n",
      "Epoch 441/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.1315 - val_loss: 7.9453\n",
      "Epoch 442/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.9829 - val_loss: 6.2629\n",
      "Epoch 443/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.0978 - val_loss: 6.9180\n",
      "Epoch 444/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 6.3085 - val_loss: 6.0850\n",
      "Epoch 445/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.9706 - val_loss: 6.7721\n",
      "Epoch 446/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.1748 - val_loss: 6.0456\n",
      "Epoch 447/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.9892 - val_loss: 6.1050\n",
      "Epoch 448/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.0007 - val_loss: 7.3879\n",
      "Epoch 449/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.5841 - val_loss: 7.5776\n",
      "Epoch 450/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.6505 - val_loss: 6.7259\n",
      "Epoch 451/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.2573 - val_loss: 7.7120\n",
      "Epoch 452/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.3016 - val_loss: 8.4263\n",
      "Epoch 453/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.5676 - val_loss: 8.7463\n",
      "Epoch 454/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.7415 - val_loss: 7.5500\n",
      "Epoch 455/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.4715 - val_loss: 7.5346\n",
      "Epoch 456/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.5633 - val_loss: 8.5019\n",
      "Epoch 457/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.3361 - val_loss: 7.0092\n",
      "Epoch 458/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.3194 - val_loss: 7.3118\n",
      "Epoch 459/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.1787 - val_loss: 6.1141\n",
      "Epoch 460/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.9252 - val_loss: 6.1749\n",
      "Epoch 461/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 5.8483 - val_loss: 6.7335\n",
      "Epoch 462/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.4735 - val_loss: 6.5118\n",
      "Epoch 463/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.6905 - val_loss: 6.9307\n",
      "Epoch 464/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.0104 - val_loss: 6.5008\n",
      "Epoch 465/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.8885 - val_loss: 6.3853\n",
      "Epoch 466/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.9295 - val_loss: 6.3226\n",
      "Epoch 467/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.2096 - val_loss: 6.5698\n",
      "Epoch 468/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.9246 - val_loss: 6.5342\n",
      "Epoch 469/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.1012 - val_loss: 6.9057\n",
      "Epoch 470/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.2967 - val_loss: 7.5861\n",
      "Epoch 471/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.8571 - val_loss: 7.0957\n",
      "Epoch 472/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.7886 - val_loss: 6.7703\n",
      "Epoch 473/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.8025 - val_loss: 6.3253\n",
      "Epoch 474/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.0947 - val_loss: 6.3365\n",
      "Epoch 475/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.2191 - val_loss: 6.9753\n",
      "Epoch 476/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.0118 - val_loss: 6.0996\n",
      "Epoch 477/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.0262 - val_loss: 6.1624\n",
      "Epoch 478/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.7642 - val_loss: 6.9426\n",
      "Epoch 479/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.9068 - val_loss: 6.1999\n",
      "Epoch 480/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.1748 - val_loss: 6.5678\n",
      "Epoch 481/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.3156 - val_loss: 6.1864\n",
      "Epoch 482/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.5653 - val_loss: 6.4387\n",
      "Epoch 483/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 6.4121 - val_loss: 7.3379\n",
      "Epoch 484/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.1332 - val_loss: 6.5253\n",
      "Epoch 485/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.0997 - val_loss: 6.0243\n",
      "Epoch 486/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.1211 - val_loss: 6.8171\n",
      "Epoch 487/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 6.2560 - val_loss: 6.0361\n",
      "Epoch 488/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.9613 - val_loss: 7.2117\n",
      "Epoch 489/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.1918 - val_loss: 6.7008\n",
      "Epoch 490/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.1192 - val_loss: 6.7147\n",
      "Epoch 491/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.9170 - val_loss: 6.5544\n",
      "Epoch 492/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.9002 - val_loss: 6.3911\n",
      "Epoch 493/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.2750 - val_loss: 6.6138\n",
      "Epoch 494/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6840 - val_loss: 6.5558\n",
      "Epoch 495/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.9311 - val_loss: 6.3407\n",
      "Epoch 496/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.8030 - val_loss: 6.2665\n",
      "Epoch 497/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.4152 - val_loss: 6.2542\n",
      "Epoch 498/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.3187 - val_loss: 6.9051\n",
      "Epoch 499/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.8095 - val_loss: 6.3095\n",
      "Epoch 500/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.9903 - val_loss: 6.0721\n",
      "Epoch 501/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.2540 - val_loss: 7.5969\n",
      "Epoch 502/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.0464 - val_loss: 6.6570\n",
      "Epoch 503/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.9049 - val_loss: 6.4760\n",
      "Epoch 504/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.2041 - val_loss: 7.2431\n",
      "Epoch 505/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.0111 - val_loss: 6.8252\n",
      "Epoch 506/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.1166 - val_loss: 6.3764\n",
      "Epoch 507/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.4413 - val_loss: 5.8475\n",
      "Epoch 508/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.9607 - val_loss: 6.2325\n",
      "Epoch 509/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.8554 - val_loss: 6.1086\n",
      "Epoch 510/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.8270 - val_loss: 6.7981\n",
      "Epoch 511/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.0309 - val_loss: 5.9241\n",
      "Epoch 512/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.0766 - val_loss: 5.8083\n",
      "Epoch 513/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.7264 - val_loss: 6.8487\n",
      "Epoch 514/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.0901 - val_loss: 7.9036\n",
      "Epoch 515/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.9519 - val_loss: 6.8626\n",
      "Epoch 516/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.9349 - val_loss: 6.8150\n",
      "Epoch 517/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.0938 - val_loss: 6.4312\n",
      "Epoch 518/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6795 - val_loss: 5.9574\n",
      "Epoch 519/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6080 - val_loss: 6.0658\n",
      "Epoch 520/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.9087 - val_loss: 6.8221\n",
      "Epoch 521/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.9691 - val_loss: 5.8477\n",
      "Epoch 522/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.7475 - val_loss: 6.3843\n",
      "Epoch 523/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.7113 - val_loss: 6.4284\n",
      "Epoch 524/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.7507 - val_loss: 6.2582\n",
      "Epoch 525/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.8596 - val_loss: 7.5696\n",
      "Epoch 526/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.9735 - val_loss: 6.0973\n",
      "Epoch 527/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.6514 - val_loss: 6.4306\n",
      "Epoch 528/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.9932 - val_loss: 7.0128\n",
      "Epoch 529/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 6.4710 - val_loss: 5.8721\n",
      "Epoch 530/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.7967 - val_loss: 7.1703\n",
      "Epoch 531/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.0063 - val_loss: 7.6487\n",
      "Epoch 532/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.1081 - val_loss: 7.2109\n",
      "Epoch 533/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.0753 - val_loss: 6.1519\n",
      "Epoch 534/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.7637 - val_loss: 5.8465\n",
      "Epoch 535/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.9338 - val_loss: 6.5570\n",
      "Epoch 536/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.3152 - val_loss: 7.6102\n",
      "Epoch 537/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.1959 - val_loss: 9.0119\n",
      "Epoch 538/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.1188 - val_loss: 6.8410\n",
      "Epoch 539/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.5524 - val_loss: 5.8898\n",
      "Epoch 540/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 6.3375 - val_loss: 6.0748\n",
      "Epoch 541/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 6.0100 - val_loss: 6.0882\n",
      "Epoch 542/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.8379 - val_loss: 6.1666\n",
      "Epoch 543/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6999 - val_loss: 6.5575\n",
      "Epoch 544/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.3416 - val_loss: 6.5465\n",
      "Epoch 545/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.0181 - val_loss: 6.8673\n",
      "Epoch 546/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.0078 - val_loss: 6.5041\n",
      "Epoch 547/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.7329 - val_loss: 5.9489\n",
      "Epoch 548/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.7629 - val_loss: 6.7187\n",
      "Epoch 549/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.7952 - val_loss: 6.5981\n",
      "Epoch 550/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.7924 - val_loss: 6.2402\n",
      "Epoch 551/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.7736 - val_loss: 6.6921\n",
      "Epoch 552/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.2818 - val_loss: 6.3698\n",
      "Epoch 553/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.6951 - val_loss: 6.1170\n",
      "Epoch 554/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.8543 - val_loss: 6.0484\n",
      "Epoch 555/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6919 - val_loss: 5.8280\n",
      "Epoch 556/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.6541 - val_loss: 6.5801\n",
      "Epoch 557/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.8416 - val_loss: 6.6016\n",
      "Epoch 558/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.9870 - val_loss: 5.7364\n",
      "Epoch 559/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.2585 - val_loss: 5.7295\n",
      "Epoch 560/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.7089 - val_loss: 5.6880\n",
      "Epoch 561/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6662 - val_loss: 6.2428\n",
      "Epoch 562/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.7727 - val_loss: 5.6975\n",
      "Epoch 563/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.0789 - val_loss: 6.1286\n",
      "Epoch 564/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.8780 - val_loss: 7.0789\n",
      "Epoch 565/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.9161 - val_loss: 5.9979\n",
      "Epoch 566/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.6610 - val_loss: 7.1049\n",
      "Epoch 567/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.0456 - val_loss: 6.6362\n",
      "Epoch 568/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.0592 - val_loss: 6.3761\n",
      "Epoch 569/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.9458 - val_loss: 5.9534\n",
      "Epoch 570/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.0376 - val_loss: 6.2028\n",
      "Epoch 571/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 6.6111 - val_loss: 6.0712\n",
      "Epoch 572/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.8761 - val_loss: 6.2613\n",
      "Epoch 573/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6225 - val_loss: 7.3860\n",
      "Epoch 574/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.7925 - val_loss: 5.9357\n",
      "Epoch 575/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.8735 - val_loss: 5.9092\n",
      "Epoch 576/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.5819 - val_loss: 6.4887\n",
      "Epoch 577/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.6799 - val_loss: 6.8256\n",
      "Epoch 578/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.7161 - val_loss: 5.9133\n",
      "Epoch 579/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.8115 - val_loss: 6.0465\n",
      "Epoch 580/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.7985 - val_loss: 5.9172\n",
      "Epoch 581/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.8669 - val_loss: 6.1760\n",
      "Epoch 582/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.9805 - val_loss: 5.8880\n",
      "Epoch 583/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.8252 - val_loss: 8.1176\n",
      "Epoch 584/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.7721 - val_loss: 5.9661\n",
      "Epoch 585/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.7689 - val_loss: 6.6323\n",
      "Epoch 586/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 5.6073 - val_loss: 5.6870\n",
      "Epoch 587/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.2473 - val_loss: 6.5269\n",
      "Epoch 588/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.9595 - val_loss: 6.4718\n",
      "Epoch 589/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 5.9134 - val_loss: 5.8127\n",
      "Epoch 590/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.0541 - val_loss: 5.7264\n",
      "Epoch 591/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.3865 - val_loss: 7.7208\n",
      "Epoch 592/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.0350 - val_loss: 5.8169\n",
      "Epoch 593/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.8229 - val_loss: 6.1250\n",
      "Epoch 594/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.2719 - val_loss: 6.3534\n",
      "Epoch 595/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.8676 - val_loss: 6.8577\n",
      "Epoch 596/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.8174 - val_loss: 6.1429\n",
      "Epoch 597/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6509 - val_loss: 6.7721\n",
      "Epoch 598/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.8782 - val_loss: 6.3165\n",
      "Epoch 599/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.9025 - val_loss: 6.6556\n",
      "Epoch 600/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.7202 - val_loss: 5.6485\n",
      "Epoch 601/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.7330 - val_loss: 7.0168\n",
      "Epoch 602/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.8966 - val_loss: 5.8115\n",
      "Epoch 603/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.0275 - val_loss: 8.0487\n",
      "Epoch 604/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.5004 - val_loss: 6.1902\n",
      "Epoch 605/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 5.8269 - val_loss: 6.2607\n",
      "Epoch 606/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 5.9335 - val_loss: 6.2291\n",
      "Epoch 607/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 5.8762 - val_loss: 7.6423\n",
      "Epoch 608/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 6.2723 - val_loss: 7.4970\n",
      "Epoch 609/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.0111 - val_loss: 6.6691\n",
      "Epoch 610/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.8616 - val_loss: 6.9720\n",
      "Epoch 611/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 6.0155 - val_loss: 6.3433\n",
      "Epoch 612/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 5.7007 - val_loss: 7.6903\n",
      "Epoch 613/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.7085 - val_loss: 6.1288\n",
      "Epoch 614/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.7312 - val_loss: 6.0600\n",
      "Epoch 615/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.6386 - val_loss: 7.1467\n",
      "Epoch 616/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.1019 - val_loss: 6.7722\n",
      "Epoch 617/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.8501 - val_loss: 7.9570\n",
      "Epoch 618/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.3243 - val_loss: 5.8051\n",
      "Epoch 619/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.8061 - val_loss: 6.6952\n",
      "Epoch 620/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.6437 - val_loss: 6.1689\n",
      "Epoch 621/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.9415 - val_loss: 5.9105\n",
      "Epoch 622/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.7132 - val_loss: 6.3536\n",
      "Epoch 623/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.8783 - val_loss: 5.6227\n",
      "Epoch 624/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.4101 - val_loss: 5.9214\n",
      "Epoch 625/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.0833 - val_loss: 7.9410\n",
      "Epoch 626/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.0738 - val_loss: 5.5992\n",
      "Epoch 627/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.7107 - val_loss: 5.6962\n",
      "Epoch 628/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.9348 - val_loss: 5.6712\n",
      "Epoch 629/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.1581 - val_loss: 5.5415\n",
      "Epoch 630/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.0383 - val_loss: 6.1641\n",
      "Epoch 631/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.2099 - val_loss: 6.1295\n",
      "Epoch 632/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.0809 - val_loss: 5.7299\n",
      "Epoch 633/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.0665 - val_loss: 5.5764\n",
      "Epoch 634/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.7726 - val_loss: 5.9334\n",
      "Epoch 635/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.7771 - val_loss: 5.5877\n",
      "Epoch 636/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6760 - val_loss: 5.5788\n",
      "Epoch 637/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.6888 - val_loss: 6.2876\n",
      "Epoch 638/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.0334 - val_loss: 8.7093\n",
      "Epoch 639/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.9557 - val_loss: 6.3610\n",
      "Epoch 640/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.6870 - val_loss: 5.7731\n",
      "Epoch 641/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.5331 - val_loss: 6.3941\n",
      "Epoch 642/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.6590 - val_loss: 6.5540\n",
      "Epoch 643/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.7787 - val_loss: 5.8322\n",
      "Epoch 644/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.5425 - val_loss: 5.7327\n",
      "Epoch 645/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.0978 - val_loss: 6.3577\n",
      "Epoch 646/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.8476 - val_loss: 6.6869\n",
      "Epoch 647/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.7427 - val_loss: 7.2458\n",
      "Epoch 648/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.8454 - val_loss: 5.9568\n",
      "Epoch 649/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.8053 - val_loss: 5.9866\n",
      "Epoch 650/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.8723 - val_loss: 5.9392\n",
      "Epoch 651/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.5024 - val_loss: 5.8612\n",
      "Epoch 652/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.6184 - val_loss: 6.1409\n",
      "Epoch 653/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.0844 - val_loss: 6.0444\n",
      "Epoch 654/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.4933 - val_loss: 5.5619\n",
      "Epoch 655/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6062 - val_loss: 6.6585\n",
      "Epoch 656/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.8405 - val_loss: 5.4658\n",
      "Epoch 657/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.7207 - val_loss: 6.6254\n",
      "Epoch 658/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.4777 - val_loss: 6.4199\n",
      "Epoch 659/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.9770 - val_loss: 5.9488\n",
      "Epoch 660/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.5896 - val_loss: 5.8186\n",
      "Epoch 661/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6348 - val_loss: 7.3614\n",
      "Epoch 662/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.5392 - val_loss: 5.6481\n",
      "Epoch 663/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.4794 - val_loss: 5.8783\n",
      "Epoch 664/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.6967 - val_loss: 5.7978\n",
      "Epoch 665/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.5202 - val_loss: 5.6032\n",
      "Epoch 666/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.9817 - val_loss: 8.1127\n",
      "Epoch 667/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.4518 - val_loss: 7.0422\n",
      "Epoch 668/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.7756 - val_loss: 5.9983\n",
      "Epoch 669/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6736 - val_loss: 6.8512\n",
      "Epoch 670/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.2258 - val_loss: 5.7085\n",
      "Epoch 671/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6659 - val_loss: 6.0751\n",
      "Epoch 672/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.8920 - val_loss: 6.5459\n",
      "Epoch 673/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.7871 - val_loss: 6.9938\n",
      "Epoch 674/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.2862 - val_loss: 7.4043\n",
      "Epoch 675/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.3009 - val_loss: 6.0266\n",
      "Epoch 676/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.5381 - val_loss: 5.9236\n",
      "Epoch 677/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.8374 - val_loss: 5.7237\n",
      "Epoch 678/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.7551 - val_loss: 6.5457\n",
      "Epoch 679/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.5507 - val_loss: 5.6882\n",
      "Epoch 680/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.6851 - val_loss: 5.5936\n",
      "Epoch 681/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.8442 - val_loss: 7.8887\n",
      "Epoch 682/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.4205 - val_loss: 6.0092\n",
      "Epoch 683/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.7376 - val_loss: 6.1172\n",
      "Epoch 684/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.2126 - val_loss: 5.9471\n",
      "Epoch 685/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.5615 - val_loss: 6.2109\n",
      "Epoch 686/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.5834 - val_loss: 5.8682\n",
      "Epoch 687/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.7239 - val_loss: 5.8157\n",
      "Epoch 688/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6741 - val_loss: 5.5591\n",
      "Epoch 689/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6587 - val_loss: 5.7235\n",
      "Epoch 690/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.1395 - val_loss: 6.6530\n",
      "Epoch 691/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.7246 - val_loss: 6.0561\n",
      "Epoch 692/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.7452 - val_loss: 5.9296\n",
      "Epoch 693/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.7430 - val_loss: 6.7565\n",
      "Epoch 694/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.9451 - val_loss: 6.1543\n",
      "Epoch 695/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6737 - val_loss: 5.5357\n",
      "Epoch 696/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.5057 - val_loss: 5.7748\n",
      "Epoch 697/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.5051 - val_loss: 5.5490\n",
      "Epoch 698/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.7749 - val_loss: 6.4683\n",
      "Epoch 699/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.6263 - val_loss: 6.1854\n",
      "Epoch 700/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.7413 - val_loss: 6.2672\n",
      "Epoch 701/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.9821 - val_loss: 8.0846\n",
      "Epoch 702/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.6893 - val_loss: 6.1029\n",
      "Epoch 703/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.6207 - val_loss: 6.0235\n",
      "Epoch 704/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 6.1046 - val_loss: 5.9271\n",
      "Epoch 705/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.0005 - val_loss: 7.4814\n",
      "Epoch 706/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.0691 - val_loss: 5.8450\n",
      "Epoch 707/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.0741 - val_loss: 6.4024\n",
      "Epoch 708/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6081 - val_loss: 5.4519\n",
      "Epoch 709/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.9384 - val_loss: 5.4898\n",
      "Epoch 710/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.8938 - val_loss: 6.3547\n",
      "Epoch 711/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.9581 - val_loss: 7.8020\n",
      "Epoch 712/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.8067 - val_loss: 6.7115\n",
      "Epoch 713/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.6689 - val_loss: 5.8944\n",
      "Epoch 714/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 6.0353 - val_loss: 5.5294\n",
      "Epoch 715/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.7673 - val_loss: 6.2863\n",
      "Epoch 716/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.7127 - val_loss: 5.8396\n",
      "Epoch 717/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.7920 - val_loss: 5.6816\n",
      "Epoch 718/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.8600 - val_loss: 5.6304\n",
      "Epoch 719/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6782 - val_loss: 5.4254\n",
      "Epoch 720/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.6401 - val_loss: 5.3975\n",
      "Epoch 721/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.4261 - val_loss: 5.9347\n",
      "Epoch 722/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.5646 - val_loss: 7.0290\n",
      "Epoch 723/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.7858 - val_loss: 6.2491\n",
      "Epoch 724/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.8693 - val_loss: 6.5264\n",
      "Epoch 725/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.3368 - val_loss: 5.5508\n",
      "Epoch 726/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.6450 - val_loss: 5.9507\n",
      "Epoch 727/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.7691 - val_loss: 5.8474\n",
      "Epoch 728/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.4215 - val_loss: 6.1002\n",
      "Epoch 729/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6907 - val_loss: 6.1596\n",
      "Epoch 730/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.9492 - val_loss: 5.4376\n",
      "Epoch 731/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.5719 - val_loss: 7.6313\n",
      "Epoch 732/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.5965 - val_loss: 5.7099\n",
      "Epoch 733/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.7849 - val_loss: 6.7428\n",
      "Epoch 734/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6513 - val_loss: 6.1722\n",
      "Epoch 735/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.6958 - val_loss: 6.7848\n",
      "Epoch 736/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.4748 - val_loss: 5.5193\n",
      "Epoch 737/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.6936 - val_loss: 5.5045\n",
      "Epoch 738/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.4872 - val_loss: 5.9965\n",
      "Epoch 739/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.4151 - val_loss: 6.0331\n",
      "Epoch 740/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.5221 - val_loss: 6.2984\n",
      "Epoch 741/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.5586 - val_loss: 5.2782\n",
      "Epoch 742/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.4551 - val_loss: 6.3319\n",
      "Epoch 743/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.6158 - val_loss: 5.5123\n",
      "Epoch 744/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.8394 - val_loss: 6.4034\n",
      "Epoch 745/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.4443 - val_loss: 5.7107\n",
      "Epoch 746/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.4874 - val_loss: 7.1162\n",
      "Epoch 747/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.8436 - val_loss: 6.1607\n",
      "Epoch 748/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.7686 - val_loss: 5.7587\n",
      "Epoch 749/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.8084 - val_loss: 7.7258\n",
      "Epoch 750/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.7621 - val_loss: 6.5836\n",
      "Epoch 751/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.7169 - val_loss: 5.5566\n",
      "Epoch 752/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.4148 - val_loss: 6.1020\n",
      "Epoch 753/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.6297 - val_loss: 6.2499\n",
      "Epoch 754/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.5292 - val_loss: 5.7107\n",
      "Epoch 755/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.5140 - val_loss: 5.3735\n",
      "Epoch 756/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.9415 - val_loss: 6.0973\n",
      "Epoch 757/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.4891 - val_loss: 5.7571\n",
      "Epoch 758/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.7357 - val_loss: 5.7425\n",
      "Epoch 759/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.5542 - val_loss: 5.6537\n",
      "Epoch 760/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.8553 - val_loss: 5.8478\n",
      "Epoch 761/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.3613 - val_loss: 5.5712\n",
      "Epoch 762/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.4335 - val_loss: 5.8533\n",
      "Epoch 763/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.6361 - val_loss: 5.9134\n",
      "Epoch 764/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.4791 - val_loss: 5.5872\n",
      "Epoch 765/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.4848 - val_loss: 6.3673\n",
      "Epoch 766/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6740 - val_loss: 5.6142\n",
      "Epoch 767/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.5819 - val_loss: 8.6602\n",
      "Epoch 768/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.0215 - val_loss: 5.9511\n",
      "Epoch 769/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.4255 - val_loss: 5.9639\n",
      "Epoch 770/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.7490 - val_loss: 5.6217\n",
      "Epoch 771/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.7447 - val_loss: 6.4165\n",
      "Epoch 772/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6196 - val_loss: 6.6354\n",
      "Epoch 773/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.6938 - val_loss: 7.2701\n",
      "Epoch 774/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.0654 - val_loss: 7.1930\n",
      "Epoch 775/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.8147 - val_loss: 6.6952\n",
      "Epoch 776/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.7812 - val_loss: 6.2148\n",
      "Epoch 777/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 5.5370 - val_loss: 5.4978\n",
      "Epoch 778/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 5.3082 - val_loss: 5.9818\n",
      "Epoch 779/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 5.4057 - val_loss: 5.3833\n",
      "Epoch 780/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 5.9522 - val_loss: 6.2579\n",
      "Epoch 781/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 5.7193 - val_loss: 5.8632\n",
      "Epoch 782/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.7224 - val_loss: 6.5138\n",
      "Epoch 783/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.8582 - val_loss: 6.3168\n",
      "Epoch 784/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 5.7612 - val_loss: 5.5079\n",
      "Epoch 785/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 6.1032 - val_loss: 6.4791\n",
      "Epoch 786/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.7690 - val_loss: 6.9294\n",
      "Epoch 787/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6211 - val_loss: 5.7069\n",
      "Epoch 788/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.7915 - val_loss: 6.6609\n",
      "Epoch 789/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.3382 - val_loss: 6.4081\n",
      "Epoch 790/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.9128 - val_loss: 5.9372\n",
      "Epoch 791/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.9583 - val_loss: 5.8294\n",
      "Epoch 792/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.6839 - val_loss: 5.4895\n",
      "Epoch 793/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6660 - val_loss: 5.9647\n",
      "Epoch 794/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6911 - val_loss: 5.7799\n",
      "Epoch 795/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.5791 - val_loss: 6.1255\n",
      "Epoch 796/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.3949 - val_loss: 5.3844\n",
      "Epoch 797/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.6159 - val_loss: 5.6020\n",
      "Epoch 798/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.7445 - val_loss: 6.5183\n",
      "Epoch 799/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.3554 - val_loss: 5.5057\n",
      "Epoch 800/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6519 - val_loss: 5.8627\n",
      "Epoch 801/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.7327 - val_loss: 5.7707\n",
      "Epoch 802/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.5667 - val_loss: 5.5912\n",
      "Epoch 803/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.3438 - val_loss: 5.4602\n",
      "Epoch 804/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.4157 - val_loss: 6.1840\n",
      "Epoch 805/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.5251 - val_loss: 6.9250\n",
      "Epoch 806/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.7088 - val_loss: 5.4561\n",
      "Epoch 807/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.1974 - val_loss: 5.8795\n",
      "Epoch 808/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.5027 - val_loss: 6.6009\n",
      "Epoch 809/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.5529 - val_loss: 7.4892\n",
      "Epoch 810/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6533 - val_loss: 5.9194\n",
      "Epoch 811/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.7074 - val_loss: 6.1260\n",
      "Epoch 812/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.7948 - val_loss: 5.8844\n",
      "Epoch 813/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.9400 - val_loss: 5.6054\n",
      "Epoch 814/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.5313 - val_loss: 7.3196\n",
      "Epoch 815/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.4708 - val_loss: 6.0023\n",
      "Epoch 816/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.2691 - val_loss: 5.2815\n",
      "Epoch 817/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.4241 - val_loss: 5.9681\n",
      "Epoch 818/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.6176 - val_loss: 6.3928\n",
      "Epoch 819/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.3676 - val_loss: 5.6580\n",
      "Epoch 820/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.2973 - val_loss: 6.3460\n",
      "Epoch 821/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.8734 - val_loss: 6.6428\n",
      "Epoch 822/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.7093 - val_loss: 6.3601\n",
      "Epoch 823/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.6510 - val_loss: 5.7347\n",
      "Epoch 824/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.5799 - val_loss: 5.7895\n",
      "Epoch 825/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.6973 - val_loss: 5.4866\n",
      "Epoch 826/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.7859 - val_loss: 5.6140\n",
      "Epoch 827/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.5006 - val_loss: 5.7151\n",
      "Epoch 828/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.3442 - val_loss: 6.0456\n",
      "Epoch 829/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 5.3493 - val_loss: 5.6390\n",
      "Epoch 830/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.4390 - val_loss: 6.2320\n",
      "Epoch 831/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6865 - val_loss: 5.9355\n",
      "Epoch 832/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.7933 - val_loss: 6.8134\n",
      "Epoch 833/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.8161 - val_loss: 5.5316\n",
      "Epoch 834/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.9052 - val_loss: 6.5604\n",
      "Epoch 835/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.5619 - val_loss: 5.7805\n",
      "Epoch 836/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.5498 - val_loss: 6.1198\n",
      "Epoch 837/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6280 - val_loss: 6.8792\n",
      "Epoch 838/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.4789 - val_loss: 6.1520\n",
      "Epoch 839/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.5604 - val_loss: 5.5124\n",
      "Epoch 840/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.6280 - val_loss: 6.2904\n",
      "Epoch 841/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.4013 - val_loss: 5.7449\n",
      "Epoch 842/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.3795 - val_loss: 5.5886\n",
      "Epoch 843/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.8710 - val_loss: 5.3261\n",
      "Epoch 844/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.3515 - val_loss: 5.4380\n",
      "Epoch 845/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.3721 - val_loss: 6.7250\n",
      "Epoch 846/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.3136 - val_loss: 5.4462\n",
      "Epoch 847/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6564 - val_loss: 5.6112\n",
      "Epoch 848/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.6095 - val_loss: 5.3446\n",
      "Epoch 849/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.8000 - val_loss: 5.2827\n",
      "Epoch 850/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.3083 - val_loss: 6.4895\n",
      "Epoch 851/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.4527 - val_loss: 5.4015\n",
      "Epoch 852/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.5874 - val_loss: 7.7186\n",
      "Epoch 853/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.7979 - val_loss: 5.6451\n",
      "Epoch 854/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.3472 - val_loss: 5.7978\n",
      "Epoch 855/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.0633 - val_loss: 6.2471\n",
      "Epoch 856/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.5551 - val_loss: 5.7205\n",
      "Epoch 857/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.3951 - val_loss: 5.8370\n",
      "Epoch 858/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.3963 - val_loss: 5.7474\n",
      "Epoch 859/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.5838 - val_loss: 5.6798\n",
      "Epoch 860/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.7293 - val_loss: 6.8455\n",
      "Epoch 861/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.6493 - val_loss: 6.0148\n",
      "Epoch 862/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.5685 - val_loss: 6.4676\n",
      "Epoch 863/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.9335 - val_loss: 6.8941\n",
      "Epoch 864/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.5598 - val_loss: 5.5776\n",
      "Epoch 865/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.4311 - val_loss: 6.4340\n",
      "Epoch 866/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.5229 - val_loss: 5.5348\n",
      "Epoch 867/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.2692 - val_loss: 6.1009\n",
      "Epoch 868/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.2472 - val_loss: 5.7545\n",
      "Epoch 869/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.3954 - val_loss: 6.1144\n",
      "Epoch 870/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.8782 - val_loss: 6.5311\n",
      "Epoch 871/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.4959 - val_loss: 6.1608\n",
      "Epoch 872/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6089 - val_loss: 5.3494\n",
      "Epoch 873/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 5.3507 - val_loss: 5.8421\n",
      "Epoch 874/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.3743 - val_loss: 6.0642\n",
      "Epoch 875/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.5102 - val_loss: 5.3647\n",
      "Epoch 876/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 5.2870 - val_loss: 5.3378\n",
      "Epoch 877/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.4851 - val_loss: 5.3119\n",
      "Epoch 878/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.1375 - val_loss: 8.2424\n",
      "Epoch 879/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.5485 - val_loss: 5.4812\n",
      "Epoch 880/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.4467 - val_loss: 5.4177\n",
      "Epoch 881/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.4259 - val_loss: 6.4995\n",
      "Epoch 882/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.4827 - val_loss: 5.9276\n",
      "Epoch 883/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.4788 - val_loss: 5.5658\n",
      "Epoch 884/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.0306 - val_loss: 5.4757\n",
      "Epoch 885/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.5058 - val_loss: 5.5530\n",
      "Epoch 886/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.5944 - val_loss: 5.9391\n",
      "Epoch 887/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.8204 - val_loss: 5.9294\n",
      "Epoch 888/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.3937 - val_loss: 6.3063\n",
      "Epoch 889/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.5508 - val_loss: 5.5069\n",
      "Epoch 890/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.4588 - val_loss: 6.2589\n",
      "Epoch 891/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.5362 - val_loss: 6.4078\n",
      "Epoch 892/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.5478 - val_loss: 5.6838\n",
      "Epoch 893/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.4402 - val_loss: 6.0110\n",
      "Epoch 894/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.8595 - val_loss: 6.2602\n",
      "Epoch 895/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.5332 - val_loss: 6.1098\n",
      "Epoch 896/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.4426 - val_loss: 5.4378\n",
      "Epoch 897/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.9505 - val_loss: 6.0506\n",
      "Epoch 898/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.4844 - val_loss: 6.3689\n",
      "Epoch 899/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 5.1407 - val_loss: 5.4886\n",
      "Epoch 900/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.5209 - val_loss: 6.9668\n",
      "Epoch 901/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.4993 - val_loss: 5.5718\n",
      "Epoch 902/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.4515 - val_loss: 5.1469\n",
      "Epoch 903/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.0916 - val_loss: 9.0703\n",
      "Epoch 904/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.9416 - val_loss: 5.5557\n",
      "Epoch 905/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.5921 - val_loss: 8.2294\n",
      "Epoch 906/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.4832 - val_loss: 5.4020\n",
      "Epoch 907/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.5261 - val_loss: 5.3874\n",
      "Epoch 908/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.5563 - val_loss: 6.2923\n",
      "Epoch 909/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.3843 - val_loss: 5.4476\n",
      "Epoch 910/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.5273 - val_loss: 5.0579\n",
      "Epoch 911/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.3445 - val_loss: 5.5012\n",
      "Epoch 912/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.4457 - val_loss: 5.7737\n",
      "Epoch 913/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.5158 - val_loss: 5.4145\n",
      "Epoch 914/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.4188 - val_loss: 6.2946\n",
      "Epoch 915/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.2303 - val_loss: 5.3667\n",
      "Epoch 916/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.2503 - val_loss: 5.6579\n",
      "Epoch 917/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.5118 - val_loss: 5.6007\n",
      "Epoch 918/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.2506 - val_loss: 6.5473\n",
      "Epoch 919/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.7624 - val_loss: 7.8203\n",
      "Epoch 920/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.3776 - val_loss: 6.2877\n",
      "Epoch 921/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.3463 - val_loss: 5.5943\n",
      "Epoch 922/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.1561 - val_loss: 5.8550\n",
      "Epoch 923/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.5746 - val_loss: 5.5876\n",
      "Epoch 924/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.4114 - val_loss: 5.8281\n",
      "Epoch 925/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.6004 - val_loss: 5.3230\n",
      "Epoch 926/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.5210 - val_loss: 5.4212\n",
      "Epoch 927/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 5.2428 - val_loss: 5.2237\n",
      "Epoch 928/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.3261 - val_loss: 5.5062\n",
      "Epoch 929/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.5369 - val_loss: 5.2456\n",
      "Epoch 930/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.4152 - val_loss: 7.3134\n",
      "Epoch 931/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.6827 - val_loss: 5.5833\n",
      "Epoch 932/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.3427 - val_loss: 5.4827\n",
      "Epoch 933/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.3421 - val_loss: 6.4339\n",
      "Epoch 934/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.7349 - val_loss: 8.1467\n",
      "Epoch 935/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.2522 - val_loss: 7.2296\n",
      "Epoch 936/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6040 - val_loss: 5.7182\n",
      "Epoch 937/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.3963 - val_loss: 5.6388\n",
      "Epoch 938/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.3952 - val_loss: 5.4982\n",
      "Epoch 939/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.4985 - val_loss: 5.5804\n",
      "Epoch 940/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.3868 - val_loss: 6.5192\n",
      "Epoch 941/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.5716 - val_loss: 5.5331\n",
      "Epoch 942/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.4960 - val_loss: 6.1016\n",
      "Epoch 943/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.7913 - val_loss: 5.4776\n",
      "Epoch 944/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.4933 - val_loss: 5.9634\n",
      "Epoch 945/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.4407 - val_loss: 5.8669\n",
      "Epoch 946/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.4533 - val_loss: 6.4974\n",
      "Epoch 947/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.3563 - val_loss: 5.5011\n",
      "Epoch 948/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.2679 - val_loss: 6.0323\n",
      "Epoch 949/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.6017 - val_loss: 5.3387\n",
      "Epoch 950/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 5.4819 - val_loss: 5.3734\n",
      "Epoch 951/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 5.2794 - val_loss: 5.2486\n",
      "Epoch 952/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 5.3038 - val_loss: 6.0242\n",
      "Epoch 953/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 5.4076 - val_loss: 5.3143\n",
      "Epoch 954/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.4074 - val_loss: 6.3740\n",
      "Epoch 955/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 5.2981 - val_loss: 6.0925\n",
      "Epoch 956/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.4574 - val_loss: 5.8497\n",
      "Epoch 957/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 5.4022 - val_loss: 5.4598\n",
      "Epoch 958/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.2652 - val_loss: 6.1033\n",
      "Epoch 959/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.6102 - val_loss: 5.8954\n",
      "Epoch 960/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.4572 - val_loss: 6.8994\n",
      "Epoch 961/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.9923 - val_loss: 7.1050\n",
      "Epoch 962/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.7074 - val_loss: 5.6689\n",
      "Epoch 963/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.5253 - val_loss: 6.0024\n",
      "Epoch 964/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.4483 - val_loss: 6.1191\n",
      "Epoch 965/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.7744 - val_loss: 6.3166\n",
      "Epoch 966/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.1903 - val_loss: 6.1930\n",
      "Epoch 967/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.3237 - val_loss: 5.2338\n",
      "Epoch 968/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.4820 - val_loss: 5.3693\n",
      "Epoch 969/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.1831 - val_loss: 6.0856\n",
      "Epoch 970/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.6438 - val_loss: 5.2405\n",
      "Epoch 971/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.2104 - val_loss: 7.1579\n",
      "Epoch 972/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.2471 - val_loss: 5.6375\n",
      "Epoch 973/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.8039 - val_loss: 5.1115\n",
      "Epoch 974/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.3701 - val_loss: 5.9104\n",
      "Epoch 975/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.4485 - val_loss: 6.4425\n",
      "Epoch 976/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.6326 - val_loss: 5.3536\n",
      "Epoch 977/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 5.2790 - val_loss: 5.3839\n",
      "Epoch 978/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.3338 - val_loss: 5.3611\n",
      "Epoch 979/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.4318 - val_loss: 5.6135\n",
      "Epoch 980/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.3466 - val_loss: 7.0420\n",
      "Epoch 981/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6480 - val_loss: 5.1613\n",
      "Epoch 982/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.2483 - val_loss: 5.3211\n",
      "Epoch 983/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.2846 - val_loss: 5.3949\n",
      "Epoch 984/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.5894 - val_loss: 6.7025\n",
      "Epoch 985/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.3927 - val_loss: 5.6683\n",
      "Epoch 986/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.1098 - val_loss: 6.2871\n",
      "Epoch 987/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.2234 - val_loss: 5.5038\n",
      "Epoch 988/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.2889 - val_loss: 5.5762\n",
      "Epoch 989/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.5610 - val_loss: 5.9047\n",
      "Epoch 990/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.4361 - val_loss: 5.4805\n",
      "Epoch 991/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.4788 - val_loss: 5.7403\n",
      "Epoch 992/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.3588 - val_loss: 6.7132\n",
      "Epoch 993/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.5986 - val_loss: 6.3864\n",
      "Epoch 994/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.2656 - val_loss: 5.2964\n",
      "Epoch 995/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.4759 - val_loss: 5.6589\n",
      "Epoch 996/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.3943 - val_loss: 7.8382\n",
      "Epoch 997/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.5080 - val_loss: 5.2920\n",
      "Epoch 998/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.3611 - val_loss: 5.7799\n",
      "Epoch 999/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.3661 - val_loss: 5.8534\n",
      "Epoch 1000/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.2548 - val_loss: 5.6439\n",
      "5.272662808409835\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.5735489 ,  2.965721  , -0.12788029, -4.030838  ,  0.38863236,\n",
       "          0.53005296, -0.8340661 , -4.231711  , -0.14026332, -4.5569715 ],\n",
       "        [-0.9878199 , -0.20671615, -0.5639114 ,  0.15339808, -0.00732744,\n",
       "          0.43364933, -0.850827  , -0.70490915, -0.02871592,  0.30813155],\n",
       "        [-2.0070765 ,  0.07018906, -1.9282663 ,  0.10152616, -1.1426042 ,\n",
       "          0.622675  , -0.35386506, -3.002482  ,  0.45451096, -0.7743051 ],\n",
       "        [-0.36451626, -0.05606051,  0.05223145,  0.03935704, -0.21410394,\n",
       "         -0.9803505 ,  0.31089288,  0.20114294,  0.6233615 ,  0.17570533],\n",
       "        [-0.62470955,  0.27751294,  0.8519549 , -2.4516122 ,  1.4873048 ,\n",
       "          0.46882743, -0.95781964, -0.2426019 , -1.6410679 , -0.253217  ]],\n",
       "       dtype=float32),\n",
       " array([ 5.7879066,  1.7180561, -1.093419 , -4.966212 , -3.1972873,\n",
       "        -3.5514178, -0.2515836, -4.9571686, -4.7201605, -5.7335043],\n",
       "       dtype=float32),\n",
       " array([[-1.4016353 ,  1.1094826 , -1.4397999 , -1.6250628 ,  1.8238206 ,\n",
       "         -0.61938566, -0.7504599 ,  1.6638932 ,  1.4040884 ,  0.3103458 ],\n",
       "        [ 0.67823696, -0.2965719 ,  0.7172463 ,  0.9376535 , -0.93419844,\n",
       "          1.0043402 ,  0.9593006 , -1.1695788 , -0.29203817, -0.93156195],\n",
       "        [-0.42650214,  0.22057045, -0.40574253, -0.42987007,  1.1141615 ,\n",
       "         -0.04814871, -0.76793045,  0.6761749 ,  0.7318687 ,  0.5950225 ],\n",
       "        [ 1.5280871 , -2.062102  ,  1.5319912 ,  2.1633313 , -2.1100082 ,\n",
       "          1.9467221 ,  1.9443551 , -1.8391527 , -1.8976849 , -1.4360967 ],\n",
       "        [ 0.74403447, -0.25794342,  0.39034092,  0.5657348 , -0.8951392 ,\n",
       "          0.12938774,  0.312264  , -0.8889422 , -0.15790163,  0.12566157],\n",
       "        [ 0.6850326 , -0.8396973 ,  1.3191825 ,  1.4672664 , -1.3447146 ,\n",
       "          0.90347874,  1.0436071 , -0.9117373 , -0.62459624, -0.5570676 ],\n",
       "        [-0.5306617 ,  0.8235995 , -0.7613418 , -0.03546904,  0.85349184,\n",
       "         -0.51355594,  0.10284619,  0.9183817 , -0.07323944,  0.05088506],\n",
       "        [ 0.6701548 , -0.2573543 ,  0.19145337,  0.6399363 , -0.890394  ,\n",
       "          0.4543761 ,  0.54846233, -0.8836309 , -0.5500345 ,  0.22888933],\n",
       "        [ 1.469363  , -1.3942603 ,  1.7784145 ,  1.4155437 , -1.5691352 ,\n",
       "          0.7979646 ,  1.2043215 , -1.9047956 , -1.6046364 , -0.6343983 ],\n",
       "        [ 1.6087018 , -2.3747609 ,  2.4751291 ,  1.9355835 , -2.4976296 ,\n",
       "          1.6167027 ,  1.7835585 , -2.440246  , -1.1786486 , -0.8727551 ]],\n",
       "       dtype=float32),\n",
       " array([-1.7730695 ,  1.767826  , -1.832753  , -1.8280209 ,  1.8813046 ,\n",
       "        -1.6361265 , -1.6385113 ,  1.8724964 ,  1.4892379 ,  0.80159616],\n",
       "       dtype=float32),\n",
       " array([[-1.2699622 ],\n",
       "        [ 1.3165675 ],\n",
       "        [-1.5436219 ],\n",
       "        [-1.6566802 ],\n",
       "        [ 1.8302298 ],\n",
       "        [-0.93330467],\n",
       "        [-1.0049285 ],\n",
       "        [ 1.7537912 ],\n",
       "        [ 0.9452325 ],\n",
       "        [ 0.3523106 ]], dtype=float32),\n",
       " array([2.0948145], dtype=float32)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_airfoil, history_airfoil, evaluate_airfoil=NN_model_structure_regression_5(X_train_airfoil, X_val_airfoil, Y_train_airfoil, Y_val_airfoil, adam2, 32, 1000, x_test_airfoil, y_test_airfoil)\n",
    "model_airfoil.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_airfoil.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_airfoil_structure5_4th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 15)                165       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 241\n",
      "Trainable params: 241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1052 samples, validate on 225 samples\n",
      "Epoch 1/1000\n",
      "1052/1052 [==============================] - 0s 256us/step - loss: 6342.7520 - val_loss: 629.4477\n",
      "Epoch 2/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 157.8213 - val_loss: 43.6885\n",
      "Epoch 3/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 39.7096 - val_loss: 30.8275\n",
      "Epoch 4/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 30.3097 - val_loss: 29.6645\n",
      "Epoch 5/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 27.2534 - val_loss: 28.0074\n",
      "Epoch 6/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 25.8312 - val_loss: 27.4208\n",
      "Epoch 7/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 24.7187 - val_loss: 26.3975\n",
      "Epoch 8/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 24.0329 - val_loss: 26.0713\n",
      "Epoch 9/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 23.1503 - val_loss: 25.6224\n",
      "Epoch 10/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.5337 - val_loss: 25.3409\n",
      "Epoch 11/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.0662 - val_loss: 29.2542\n",
      "Epoch 12/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 21.8425 - val_loss: 25.7082\n",
      "Epoch 13/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.8894 - val_loss: 26.3395\n",
      "Epoch 14/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 20.9789 - val_loss: 25.7535\n",
      "Epoch 15/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 20.4836 - val_loss: 24.3991\n",
      "Epoch 16/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 20.0101 - val_loss: 24.9488\n",
      "Epoch 17/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 19.9032 - val_loss: 26.4179\n",
      "Epoch 18/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 20.3238 - val_loss: 24.2849\n",
      "Epoch 19/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 19.2769 - val_loss: 23.9798\n",
      "Epoch 20/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.9002 - val_loss: 23.9021\n",
      "Epoch 21/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.3901 - val_loss: 23.2837\n",
      "Epoch 22/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.2555 - val_loss: 23.4802\n",
      "Epoch 23/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.2720 - val_loss: 24.0712\n",
      "Epoch 24/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.9742 - val_loss: 23.3410\n",
      "Epoch 25/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.6393 - val_loss: 22.1906\n",
      "Epoch 26/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.3128 - val_loss: 22.1481\n",
      "Epoch 27/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.0955 - val_loss: 21.3668\n",
      "Epoch 28/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 16.9653 - val_loss: 21.6886\n",
      "Epoch 29/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 16.8908 - val_loss: 21.5399\n",
      "Epoch 30/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 16.6952 - val_loss: 21.6617\n",
      "Epoch 31/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 16.2099 - val_loss: 20.4172\n",
      "Epoch 32/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 15.9755 - val_loss: 19.7515\n",
      "Epoch 33/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 16.0657 - val_loss: 20.4886\n",
      "Epoch 34/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 15.9807 - val_loss: 19.6073\n",
      "Epoch 35/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 15.5585 - val_loss: 19.3669\n",
      "Epoch 36/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 15.1479 - val_loss: 19.3895\n",
      "Epoch 37/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 15.4807 - val_loss: 19.0843\n",
      "Epoch 38/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 15.2209 - val_loss: 18.7094\n",
      "Epoch 39/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 15.3855 - val_loss: 18.6280\n",
      "Epoch 40/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.9169 - val_loss: 18.1864\n",
      "Epoch 41/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 14.4344 - val_loss: 17.8244\n",
      "Epoch 42/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.6714 - val_loss: 18.1146\n",
      "Epoch 43/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.5299 - val_loss: 18.5195\n",
      "Epoch 44/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 14.3849 - val_loss: 17.7817\n",
      "Epoch 45/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.2480 - val_loss: 17.9259\n",
      "Epoch 46/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.8259 - val_loss: 17.3408\n",
      "Epoch 47/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.8894 - val_loss: 17.6470\n",
      "Epoch 48/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.4143 - val_loss: 16.8099\n",
      "Epoch 49/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.3177 - val_loss: 16.9222\n",
      "Epoch 50/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.5201 - val_loss: 16.0486\n",
      "Epoch 51/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.2452 - val_loss: 16.9555\n",
      "Epoch 52/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.2578 - val_loss: 15.8657\n",
      "Epoch 53/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.7575 - val_loss: 15.6284\n",
      "Epoch 54/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.7563 - val_loss: 16.2261\n",
      "Epoch 55/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.5546 - val_loss: 15.8437\n",
      "Epoch 56/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.7503 - val_loss: 15.3332\n",
      "Epoch 57/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.8605 - val_loss: 15.8006\n",
      "Epoch 58/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.7655 - val_loss: 15.4397\n",
      "Epoch 59/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.1530 - val_loss: 15.6745\n",
      "Epoch 60/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.4866 - val_loss: 17.2975\n",
      "Epoch 61/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.9085 - val_loss: 15.1819\n",
      "Epoch 62/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.3538 - val_loss: 14.7862\n",
      "Epoch 63/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.6860 - val_loss: 15.4950\n",
      "Epoch 64/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.5997 - val_loss: 14.7197\n",
      "Epoch 65/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.1239 - val_loss: 14.4550\n",
      "Epoch 66/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.5844 - val_loss: 14.3021\n",
      "Epoch 67/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.1898 - val_loss: 16.0176\n",
      "Epoch 68/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.3662 - val_loss: 15.2408\n",
      "Epoch 69/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.2059 - val_loss: 13.2690\n",
      "Epoch 70/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.7631 - val_loss: 13.3476\n",
      "Epoch 71/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.8465 - val_loss: 13.1071\n",
      "Epoch 72/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.9374 - val_loss: 12.8270\n",
      "Epoch 73/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.2135 - val_loss: 16.0735\n",
      "Epoch 74/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.1794 - val_loss: 12.8483\n",
      "Epoch 75/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.5621 - val_loss: 12.6496\n",
      "Epoch 76/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.2207 - val_loss: 12.0882\n",
      "Epoch 77/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 10.0834 - val_loss: 12.3261\n",
      "Epoch 78/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.9192 - val_loss: 12.6126\n",
      "Epoch 79/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.7781 - val_loss: 12.9175\n",
      "Epoch 80/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.8982 - val_loss: 11.5969\n",
      "Epoch 81/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.9679 - val_loss: 11.9395\n",
      "Epoch 82/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.6341 - val_loss: 11.5803\n",
      "Epoch 83/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.9262 - val_loss: 11.4774\n",
      "Epoch 84/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.6838 - val_loss: 11.5815\n",
      "Epoch 85/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.5994 - val_loss: 11.0264\n",
      "Epoch 86/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.3502 - val_loss: 10.9497\n",
      "Epoch 87/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.6806 - val_loss: 11.3780\n",
      "Epoch 88/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.4841 - val_loss: 11.2060\n",
      "Epoch 89/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.8789 - val_loss: 10.3721\n",
      "Epoch 90/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.5040 - val_loss: 11.0057\n",
      "Epoch 91/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.2778 - val_loss: 10.2496\n",
      "Epoch 92/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1088 - val_loss: 10.1508\n",
      "Epoch 93/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8216 - val_loss: 10.6090\n",
      "Epoch 94/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.3439 - val_loss: 10.5443\n",
      "Epoch 95/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1312 - val_loss: 10.2244\n",
      "Epoch 96/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.2638 - val_loss: 11.8046\n",
      "Epoch 97/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.1231 - val_loss: 11.1005\n",
      "Epoch 98/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.8654 - val_loss: 9.9328\n",
      "Epoch 99/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.6027 - val_loss: 10.1896\n",
      "Epoch 100/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1895 - val_loss: 10.2133\n",
      "Epoch 101/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.2845 - val_loss: 10.3706\n",
      "Epoch 102/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7784 - val_loss: 11.7739\n",
      "Epoch 103/1000\n",
      "1052/1052 [==============================] - 0s 112us/step - loss: 8.9477 - val_loss: 10.7825\n",
      "Epoch 104/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 8.9833 - val_loss: 9.9889\n",
      "Epoch 105/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.3122 - val_loss: 12.3152\n",
      "Epoch 106/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.5028 - val_loss: 10.3858\n",
      "Epoch 107/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 9.1344 - val_loss: 10.0288\n",
      "Epoch 108/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.9459 - val_loss: 11.4169\n",
      "Epoch 109/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.5533 - val_loss: 9.3338\n",
      "Epoch 110/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 8.4992 - val_loss: 9.9272\n",
      "Epoch 111/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 8.5766 - val_loss: 10.8471\n",
      "Epoch 112/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.5942 - val_loss: 10.1753\n",
      "Epoch 113/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 8.6275 - val_loss: 10.1418\n",
      "Epoch 114/1000\n",
      "1052/1052 [==============================] - 0s 114us/step - loss: 8.7604 - val_loss: 9.4027\n",
      "Epoch 115/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.3449 - val_loss: 9.7954\n",
      "Epoch 116/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.0164 - val_loss: 9.1691\n",
      "Epoch 117/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 8.4196 - val_loss: 9.2171\n",
      "Epoch 118/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.7195 - val_loss: 9.7249\n",
      "Epoch 119/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.6225 - val_loss: 10.8964\n",
      "Epoch 120/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.4333 - val_loss: 9.6550\n",
      "Epoch 121/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3556 - val_loss: 8.9795\n",
      "Epoch 122/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.1397 - val_loss: 9.1685\n",
      "Epoch 123/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5687 - val_loss: 9.4485\n",
      "Epoch 124/1000\n",
      "1052/1052 [==============================] - 0s 112us/step - loss: 8.3889 - val_loss: 9.4943\n",
      "Epoch 125/1000\n",
      "1052/1052 [==============================] - 0s 114us/step - loss: 8.2783 - val_loss: 12.6948\n",
      "Epoch 126/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 9.2910 - val_loss: 12.4986\n",
      "Epoch 127/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 9.1755 - val_loss: 12.2306\n",
      "Epoch 128/1000\n",
      "1052/1052 [==============================] - 0s 115us/step - loss: 9.2008 - val_loss: 9.3425\n",
      "Epoch 129/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 8.7549 - val_loss: 9.2913\n",
      "Epoch 130/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 8.2512 - val_loss: 9.5401\n",
      "Epoch 131/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.2443 - val_loss: 10.0400\n",
      "Epoch 132/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1147 - val_loss: 9.8303\n",
      "Epoch 133/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.1118 - val_loss: 8.8885\n",
      "Epoch 134/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.4769 - val_loss: 9.1934\n",
      "Epoch 135/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.0130 - val_loss: 8.9339\n",
      "Epoch 136/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.3832 - val_loss: 9.8330\n",
      "Epoch 137/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.4277 - val_loss: 9.7833\n",
      "Epoch 138/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.9378 - val_loss: 10.4138\n",
      "Epoch 139/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.1376 - val_loss: 9.0379\n",
      "Epoch 140/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.5329 - val_loss: 9.8201\n",
      "Epoch 141/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.4200 - val_loss: 9.0629\n",
      "Epoch 142/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.0420 - val_loss: 9.6123\n",
      "Epoch 143/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0136 - val_loss: 9.2172\n",
      "Epoch 144/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.7524 - val_loss: 8.7178\n",
      "Epoch 145/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.5963 - val_loss: 8.6064\n",
      "Epoch 146/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5237 - val_loss: 9.0972\n",
      "Epoch 147/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.6133 - val_loss: 8.9716\n",
      "Epoch 148/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.4202 - val_loss: 10.5295\n",
      "Epoch 149/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3931 - val_loss: 10.0248\n",
      "Epoch 150/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.9738 - val_loss: 10.0304\n",
      "Epoch 151/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1008 - val_loss: 8.6502\n",
      "Epoch 152/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.1715 - val_loss: 9.4090\n",
      "Epoch 153/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.0869 - val_loss: 8.5884\n",
      "Epoch 154/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.4640 - val_loss: 8.6522\n",
      "Epoch 155/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.1961 - val_loss: 9.4973\n",
      "Epoch 156/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.3909 - val_loss: 11.2719\n",
      "Epoch 157/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1396 - val_loss: 8.7928\n",
      "Epoch 158/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4942 - val_loss: 9.7266\n",
      "Epoch 159/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4854 - val_loss: 8.6718\n",
      "Epoch 160/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 8.798 - 0s 89us/step - loss: 8.5472 - val_loss: 10.0355\n",
      "Epoch 161/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4968 - val_loss: 10.9010\n",
      "Epoch 162/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.5696 - val_loss: 8.6836\n",
      "Epoch 163/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0383 - val_loss: 9.0107\n",
      "Epoch 164/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0925 - val_loss: 10.0119\n",
      "Epoch 165/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7263 - val_loss: 9.1116\n",
      "Epoch 166/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.7645 - val_loss: 8.7376\n",
      "Epoch 167/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0852 - val_loss: 11.7273\n",
      "Epoch 168/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2613 - val_loss: 9.8558\n",
      "Epoch 169/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0076 - val_loss: 8.5787\n",
      "Epoch 170/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6380 - val_loss: 8.3109\n",
      "Epoch 171/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7247 - val_loss: 10.0591\n",
      "Epoch 172/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3292 - val_loss: 10.6317\n",
      "Epoch 173/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4567 - val_loss: 9.8323\n",
      "Epoch 174/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4632 - val_loss: 13.3700\n",
      "Epoch 175/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1418 - val_loss: 10.5697\n",
      "Epoch 176/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.9434 - val_loss: 9.6215\n",
      "Epoch 177/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.6154 - val_loss: 11.9606\n",
      "Epoch 178/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.0533 - val_loss: 10.6794\n",
      "Epoch 179/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9806 - val_loss: 9.0459\n",
      "Epoch 180/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.9725 - val_loss: 9.1147\n",
      "Epoch 181/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9423 - val_loss: 9.2953\n",
      "Epoch 182/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.6373 - val_loss: 9.1395\n",
      "Epoch 183/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.6168 - val_loss: 8.4482\n",
      "Epoch 184/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6268 - val_loss: 12.9784\n",
      "Epoch 185/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5474 - val_loss: 9.9652\n",
      "Epoch 186/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.8233 - val_loss: 10.8246\n",
      "Epoch 187/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6571 - val_loss: 8.7077\n",
      "Epoch 188/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.8819 - val_loss: 8.4354\n",
      "Epoch 189/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1006 - val_loss: 8.6080\n",
      "Epoch 190/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3306 - val_loss: 8.7667\n",
      "Epoch 191/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0831 - val_loss: 9.4156\n",
      "Epoch 192/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.5212 - val_loss: 9.3018\n",
      "Epoch 193/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.7430 - val_loss: 10.4673\n",
      "Epoch 194/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0787 - val_loss: 9.3553\n",
      "Epoch 195/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.4812 - val_loss: 8.4213\n",
      "Epoch 196/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.3659 - val_loss: 10.1231\n",
      "Epoch 197/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.7363 - val_loss: 9.2292\n",
      "Epoch 198/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.6168 - val_loss: 9.0817\n",
      "Epoch 199/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.5533 - val_loss: 9.1617\n",
      "Epoch 200/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.7784 - val_loss: 9.3394\n",
      "Epoch 201/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.2709 - val_loss: 8.6896\n",
      "Epoch 202/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4830 - val_loss: 11.2776\n",
      "Epoch 203/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3538 - val_loss: 8.6304\n",
      "Epoch 204/1000\n",
      "1052/1052 [==============================] - 0s 128us/step - loss: 8.3762 - val_loss: 10.6280\n",
      "Epoch 205/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.6780 - val_loss: 8.3171\n",
      "Epoch 206/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.4573 - val_loss: 8.4689\n",
      "Epoch 207/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.6531 - val_loss: 8.7358\n",
      "Epoch 208/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.3859 - val_loss: 9.7517\n",
      "Epoch 209/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.7353 - val_loss: 8.6193\n",
      "Epoch 210/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.6110 - val_loss: 10.9059\n",
      "Epoch 211/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.3716 - val_loss: 8.3417\n",
      "Epoch 212/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.3507 - val_loss: 9.2307\n",
      "Epoch 213/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.6463 - val_loss: 9.0183\n",
      "Epoch 214/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.2449 - val_loss: 10.0046\n",
      "Epoch 215/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0435 - val_loss: 8.3571\n",
      "Epoch 216/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.6268 - val_loss: 8.1791\n",
      "Epoch 217/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.3585 - val_loss: 13.3663\n",
      "Epoch 218/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6240 - val_loss: 10.0105\n",
      "Epoch 219/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.0281 - val_loss: 10.7462\n",
      "Epoch 220/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5684 - val_loss: 12.2906\n",
      "Epoch 221/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.4513 - val_loss: 11.0042\n",
      "Epoch 222/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6937 - val_loss: 10.4389\n",
      "Epoch 223/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8737 - val_loss: 9.7026\n",
      "Epoch 224/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.4545 - val_loss: 9.3784\n",
      "Epoch 225/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.6092 - val_loss: 8.3260\n",
      "Epoch 226/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.8157 - val_loss: 8.2658\n",
      "Epoch 227/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.1118 - val_loss: 8.5990\n",
      "Epoch 228/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1197 - val_loss: 9.1628\n",
      "Epoch 229/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.6922 - val_loss: 8.3649\n",
      "Epoch 230/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9624 - val_loss: 11.6709\n",
      "Epoch 231/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.7412 - val_loss: 8.1954\n",
      "Epoch 232/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.6713 - val_loss: 9.1053\n",
      "Epoch 233/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.2900 - val_loss: 9.0018\n",
      "Epoch 234/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.5713 - val_loss: 8.9055\n",
      "Epoch 235/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5959 - val_loss: 8.7158\n",
      "Epoch 236/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.2244 - val_loss: 9.9531\n",
      "Epoch 237/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.7116 - val_loss: 8.6919\n",
      "Epoch 238/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.6414 - val_loss: 9.9501\n",
      "Epoch 239/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.4910 - val_loss: 8.2692\n",
      "Epoch 240/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.6702 - val_loss: 8.2986\n",
      "Epoch 241/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9020 - val_loss: 8.4842\n",
      "Epoch 242/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.3511 - val_loss: 9.5090\n",
      "Epoch 243/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.6656 - val_loss: 9.7042\n",
      "Epoch 244/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3478 - val_loss: 8.4013\n",
      "Epoch 245/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.3165 - val_loss: 8.2185\n",
      "Epoch 246/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.1910 - val_loss: 8.5622\n",
      "Epoch 247/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.2027 - val_loss: 9.1844\n",
      "Epoch 248/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.6084 - val_loss: 8.6570\n",
      "Epoch 249/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.7904 - val_loss: 8.2780\n",
      "Epoch 250/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.5892 - val_loss: 9.0147\n",
      "Epoch 251/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.5130 - val_loss: 9.5649\n",
      "Epoch 252/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.3250 - val_loss: 8.1370\n",
      "Epoch 253/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.4678 - val_loss: 8.7417\n",
      "Epoch 254/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.5589 - val_loss: 9.3825\n",
      "Epoch 255/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.6372 - val_loss: 8.0353\n",
      "Epoch 256/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.2916 - val_loss: 8.6085\n",
      "Epoch 257/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.1967 - val_loss: 7.9442\n",
      "Epoch 258/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.3531 - val_loss: 8.1010\n",
      "Epoch 259/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.8635 - val_loss: 8.2218\n",
      "Epoch 260/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.7934 - val_loss: 8.1061\n",
      "Epoch 261/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.7623 - val_loss: 10.3625\n",
      "Epoch 262/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9977 - val_loss: 8.0062\n",
      "Epoch 263/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.2204 - val_loss: 11.1848\n",
      "Epoch 264/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.4426 - val_loss: 8.4889\n",
      "Epoch 265/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.2838 - val_loss: 8.0989\n",
      "Epoch 266/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.1519 - val_loss: 7.9152\n",
      "Epoch 267/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.7405 - val_loss: 10.3988\n",
      "Epoch 268/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.5458 - val_loss: 8.9526\n",
      "Epoch 269/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.5398 - val_loss: 8.0604\n",
      "Epoch 270/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.6088 - val_loss: 7.8105\n",
      "Epoch 271/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.2945 - val_loss: 10.0950\n",
      "Epoch 272/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.7465 - val_loss: 8.5099\n",
      "Epoch 273/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.6979 - val_loss: 8.9829\n",
      "Epoch 274/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.3635 - val_loss: 8.2305\n",
      "Epoch 275/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.6089 - val_loss: 8.0838\n",
      "Epoch 276/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.6755 - val_loss: 8.5874\n",
      "Epoch 277/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.3048 - val_loss: 7.9868\n",
      "Epoch 278/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.3996 - val_loss: 7.8947\n",
      "Epoch 279/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.1677 - val_loss: 7.8107\n",
      "Epoch 280/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 7.2225 - val_loss: 8.3209\n",
      "Epoch 281/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 7.4041 - val_loss: 9.3905\n",
      "Epoch 282/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 7.7018 - val_loss: 9.6687\n",
      "Epoch 283/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 7.4104 - val_loss: 9.5806\n",
      "Epoch 284/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 7.7211 - val_loss: 8.6131\n",
      "Epoch 285/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 7.8327 - val_loss: 8.5412\n",
      "Epoch 286/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.1229 - val_loss: 9.7875\n",
      "Epoch 287/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 7.9904 - val_loss: 8.3311\n",
      "Epoch 288/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.2963 - val_loss: 7.7514\n",
      "Epoch 289/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.0965 - val_loss: 8.6569\n",
      "Epoch 290/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.2822 - val_loss: 7.8194\n",
      "Epoch 291/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.4425 - val_loss: 10.4138\n",
      "Epoch 292/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.8849 - val_loss: 8.0033\n",
      "Epoch 293/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.5512 - val_loss: 8.1393\n",
      "Epoch 294/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.4570 - val_loss: 10.3441\n",
      "Epoch 295/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.1795 - val_loss: 8.8613\n",
      "Epoch 296/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.1791 - val_loss: 12.2739\n",
      "Epoch 297/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.1501 - val_loss: 7.9690\n",
      "Epoch 298/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.4746 - val_loss: 7.8373\n",
      "Epoch 299/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.8752 - val_loss: 11.1005\n",
      "Epoch 300/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.4684 - val_loss: 7.9791\n",
      "Epoch 301/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.6009 - val_loss: 8.2668\n",
      "Epoch 302/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.4629 - val_loss: 8.0285\n",
      "Epoch 303/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.0137 - val_loss: 10.5026\n",
      "Epoch 304/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.0896 - val_loss: 8.3812\n",
      "Epoch 305/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.5940 - val_loss: 8.3718\n",
      "Epoch 306/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.4920 - val_loss: 8.2295\n",
      "Epoch 307/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.6024 - val_loss: 8.1287\n",
      "Epoch 308/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.3799 - val_loss: 7.8634\n",
      "Epoch 309/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0236 - val_loss: 7.6526\n",
      "Epoch 310/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.3165 - val_loss: 8.3536\n",
      "Epoch 311/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.3073 - val_loss: 8.4543\n",
      "Epoch 312/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.2740 - val_loss: 8.2943\n",
      "Epoch 313/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.0598 - val_loss: 8.4464\n",
      "Epoch 314/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.9574 - val_loss: 8.7944\n",
      "Epoch 315/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0287 - val_loss: 7.7271\n",
      "Epoch 316/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.4744 - val_loss: 8.1483\n",
      "Epoch 317/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.2468 - val_loss: 9.0608\n",
      "Epoch 318/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.7223 - val_loss: 8.1272\n",
      "Epoch 319/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 7.4631 - val_loss: 8.0486\n",
      "Epoch 320/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.0215 - val_loss: 8.0350\n",
      "Epoch 321/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.1010 - val_loss: 9.3421\n",
      "Epoch 322/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 7.4154 - val_loss: 9.1608\n",
      "Epoch 323/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.6903 - val_loss: 7.9392\n",
      "Epoch 324/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.3000 - val_loss: 8.2105\n",
      "Epoch 325/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2204 - val_loss: 9.1940\n",
      "Epoch 326/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.0688 - val_loss: 7.7938\n",
      "Epoch 327/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 7.0665 - val_loss: 8.5885\n",
      "Epoch 328/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 7.4819 - val_loss: 11.9961\n",
      "Epoch 329/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.3076 - val_loss: 7.8078\n",
      "Epoch 330/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.0704 - val_loss: 9.5606\n",
      "Epoch 331/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.9789 - val_loss: 7.6597\n",
      "Epoch 332/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.0581 - val_loss: 8.5964\n",
      "Epoch 333/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.9721 - val_loss: 7.7997\n",
      "Epoch 334/1000\n",
      "1052/1052 [==============================] - 0s 109us/step - loss: 7.2672 - val_loss: 7.7514\n",
      "Epoch 335/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 7.2481 - val_loss: 8.7538\n",
      "Epoch 336/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.0186 - val_loss: 7.8427\n",
      "Epoch 337/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.0725 - val_loss: 10.1206\n",
      "Epoch 338/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 7.1691 - val_loss: 7.8100\n",
      "Epoch 339/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.8852 - val_loss: 7.6016\n",
      "Epoch 340/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.5130 - val_loss: 8.3299\n",
      "Epoch 341/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 7.3890 - val_loss: 9.0707\n",
      "Epoch 342/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.2145 - val_loss: 8.1412\n",
      "Epoch 343/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.6245 - val_loss: 8.4357\n",
      "Epoch 344/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.1918 - val_loss: 8.4011\n",
      "Epoch 345/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.6267 - val_loss: 9.7321\n",
      "Epoch 346/1000\n",
      "1052/1052 [==============================] - 0s 123us/step - loss: 7.4968 - val_loss: 7.9868\n",
      "Epoch 347/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.3435 - val_loss: 9.6590\n",
      "Epoch 348/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.3134 - val_loss: 9.5350\n",
      "Epoch 349/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.3384 - val_loss: 9.0913\n",
      "Epoch 350/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.3251 - val_loss: 9.0039\n",
      "Epoch 351/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.8089 - val_loss: 9.2307\n",
      "Epoch 352/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.5614 - val_loss: 8.5680\n",
      "Epoch 353/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.5369 - val_loss: 8.5404\n",
      "Epoch 354/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.5837 - val_loss: 10.0996\n",
      "Epoch 355/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 7.6855 - 0s 82us/step - loss: 7.3500 - val_loss: 7.9932\n",
      "Epoch 356/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.1946 - val_loss: 8.3351\n",
      "Epoch 357/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.8073 - val_loss: 8.8053\n",
      "Epoch 358/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.1074 - val_loss: 8.4841\n",
      "Epoch 359/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.9863 - val_loss: 7.9877\n",
      "Epoch 360/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.4911 - val_loss: 9.1377\n",
      "Epoch 361/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.4729 - val_loss: 8.5052\n",
      "Epoch 362/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.4820 - val_loss: 8.3084\n",
      "Epoch 363/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.1674 - val_loss: 7.9223\n",
      "Epoch 364/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.2296 - val_loss: 8.1785\n",
      "Epoch 365/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.1165 - val_loss: 7.6766\n",
      "Epoch 366/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.9731 - val_loss: 8.0354\n",
      "Epoch 367/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.2998 - val_loss: 8.1776\n",
      "Epoch 368/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.3419 - val_loss: 9.9165\n",
      "Epoch 369/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.7369 - val_loss: 8.7220\n",
      "Epoch 370/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.9994 - val_loss: 8.0465\n",
      "Epoch 371/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.9368 - val_loss: 8.8969\n",
      "Epoch 372/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.3711 - val_loss: 7.4265\n",
      "Epoch 373/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.9727 - val_loss: 8.0088\n",
      "Epoch 374/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.2389 - val_loss: 12.7268\n",
      "Epoch 375/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.7030 - val_loss: 8.0204\n",
      "Epoch 376/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.2665 - val_loss: 7.7942\n",
      "Epoch 377/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.0782 - val_loss: 8.6925\n",
      "Epoch 378/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.2553 - val_loss: 9.0208\n",
      "Epoch 379/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.4616 - val_loss: 7.9394\n",
      "Epoch 380/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.3437 - val_loss: 9.1318\n",
      "Epoch 381/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.9552 - val_loss: 7.9478\n",
      "Epoch 382/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.2293 - val_loss: 8.0180\n",
      "Epoch 383/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 6.8304 - val_loss: 8.3034\n",
      "Epoch 384/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.1916 - val_loss: 9.3967\n",
      "Epoch 385/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.1998 - val_loss: 8.4939\n",
      "Epoch 386/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.1322 - val_loss: 8.0329\n",
      "Epoch 387/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.6161 - val_loss: 8.8889\n",
      "Epoch 388/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.1984 - val_loss: 7.9156\n",
      "Epoch 389/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.5690 - val_loss: 7.8910\n",
      "Epoch 390/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 6.9685 - val_loss: 7.5542\n",
      "Epoch 391/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.3196 - val_loss: 7.6210\n",
      "Epoch 392/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 6.8528 - val_loss: 9.6987\n",
      "Epoch 393/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 6.9226 - val_loss: 7.9906\n",
      "Epoch 394/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.4408 - val_loss: 15.5816\n",
      "Epoch 395/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.5111 - val_loss: 8.1722\n",
      "Epoch 396/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.2306 - val_loss: 9.6356\n",
      "Epoch 397/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.7908 - val_loss: 8.8638\n",
      "Epoch 398/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.1363 - val_loss: 9.2275\n",
      "Epoch 399/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.3410 - val_loss: 8.0928\n",
      "Epoch 400/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.0167 - val_loss: 10.3580\n",
      "Epoch 401/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.0763 - val_loss: 7.6655\n",
      "Epoch 402/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.0739 - val_loss: 7.8462\n",
      "Epoch 403/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.1013 - val_loss: 8.7185\n",
      "Epoch 404/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.5090 - val_loss: 7.4146\n",
      "Epoch 405/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.0931 - val_loss: 8.3898\n",
      "Epoch 406/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.7821 - val_loss: 7.6626\n",
      "Epoch 407/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.9315 - val_loss: 8.7559\n",
      "Epoch 408/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.0024 - val_loss: 8.1338\n",
      "Epoch 409/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.9570 - val_loss: 9.0777\n",
      "Epoch 410/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.2613 - val_loss: 9.7638\n",
      "Epoch 411/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.5795 - val_loss: 7.5022\n",
      "Epoch 412/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9820 - val_loss: 7.7720\n",
      "Epoch 413/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9988 - val_loss: 7.7720\n",
      "Epoch 414/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.4156 - val_loss: 7.3165\n",
      "Epoch 415/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.2735 - val_loss: 9.8856\n",
      "Epoch 416/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.0240 - val_loss: 8.8632\n",
      "Epoch 417/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.8602 - val_loss: 8.1895\n",
      "Epoch 418/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.1002 - val_loss: 7.6738\n",
      "Epoch 419/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.9259 - val_loss: 7.5394\n",
      "Epoch 420/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.8319 - val_loss: 8.0648\n",
      "Epoch 421/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.2645 - val_loss: 7.6383\n",
      "Epoch 422/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.6300 - val_loss: 11.0352\n",
      "Epoch 423/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.5567 - val_loss: 8.6700\n",
      "Epoch 424/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 6.8377 - val_loss: 7.6469\n",
      "Epoch 425/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8506 - val_loss: 7.9712\n",
      "Epoch 426/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.5079 - val_loss: 8.3232\n",
      "Epoch 427/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.8650 - val_loss: 7.5622\n",
      "Epoch 428/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.0086 - val_loss: 8.8963\n",
      "Epoch 429/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.3038 - val_loss: 7.8389\n",
      "Epoch 430/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.0064 - val_loss: 8.4883\n",
      "Epoch 431/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.3215 - val_loss: 8.0038\n",
      "Epoch 432/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.8401 - val_loss: 8.1289\n",
      "Epoch 433/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.9128 - val_loss: 8.7743\n",
      "Epoch 434/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.0932 - val_loss: 7.5544\n",
      "Epoch 435/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.6428 - val_loss: 7.8364\n",
      "Epoch 436/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.0209 - val_loss: 8.2509\n",
      "Epoch 437/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.2687 - val_loss: 11.5008\n",
      "Epoch 438/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.7660 - val_loss: 7.8023\n",
      "Epoch 439/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.8656 - val_loss: 7.5540\n",
      "Epoch 440/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.7117 - val_loss: 7.9854\n",
      "Epoch 441/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.1332 - val_loss: 7.8131\n",
      "Epoch 442/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.0601 - val_loss: 8.1331\n",
      "Epoch 443/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.9146 - val_loss: 7.7839\n",
      "Epoch 444/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9373 - val_loss: 7.4633\n",
      "Epoch 445/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.6216 - val_loss: 7.7184\n",
      "Epoch 446/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.9864 - val_loss: 10.2845\n",
      "Epoch 447/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.3431 - val_loss: 8.5928\n",
      "Epoch 448/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.9735 - val_loss: 7.8422\n",
      "Epoch 449/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.8435 - val_loss: 7.5038\n",
      "Epoch 450/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 7.4843 - val_loss: 10.8364\n",
      "Epoch 451/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 7.3382 - val_loss: 8.1147\n",
      "Epoch 452/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.1824 - val_loss: 9.0451\n",
      "Epoch 453/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 7.5651 - val_loss: 10.9796\n",
      "Epoch 454/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.0847 - val_loss: 8.8521\n",
      "Epoch 455/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 7.7118 - val_loss: 9.0966\n",
      "Epoch 456/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.9763 - val_loss: 8.5303\n",
      "Epoch 457/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.9525 - val_loss: 7.4363\n",
      "Epoch 458/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.0527 - val_loss: 8.6458\n",
      "Epoch 459/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.1828 - val_loss: 8.6696\n",
      "Epoch 460/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.3015 - val_loss: 8.4085\n",
      "Epoch 461/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.8730 - val_loss: 10.4799\n",
      "Epoch 462/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0630 - val_loss: 8.4211\n",
      "Epoch 463/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.7915 - val_loss: 7.8048\n",
      "Epoch 464/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.4131 - val_loss: 7.3191\n",
      "Epoch 465/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.2988 - val_loss: 8.2929\n",
      "Epoch 466/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.7713 - val_loss: 7.8302\n",
      "Epoch 467/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.6971 - val_loss: 7.9534\n",
      "Epoch 468/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.3384 - val_loss: 8.0345\n",
      "Epoch 469/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.0775 - val_loss: 7.8968\n",
      "Epoch 470/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.0936 - val_loss: 7.8074\n",
      "Epoch 471/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.6147 - val_loss: 8.4037\n",
      "Epoch 472/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.6961 - val_loss: 8.9241\n",
      "Epoch 473/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.6301 - val_loss: 9.6188\n",
      "Epoch 474/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.1305 - val_loss: 8.9228\n",
      "Epoch 475/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.7369 - val_loss: 8.9710\n",
      "Epoch 476/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.9921 - val_loss: 8.1254\n",
      "Epoch 477/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.8385 - val_loss: 7.4880\n",
      "Epoch 478/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.8914 - val_loss: 8.4184\n",
      "Epoch 479/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.7582 - val_loss: 8.3396\n",
      "Epoch 480/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.8606 - val_loss: 7.9200\n",
      "Epoch 481/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.5184 - val_loss: 8.0200\n",
      "Epoch 482/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.7955 - val_loss: 7.8247\n",
      "Epoch 483/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.9543 - val_loss: 8.5947\n",
      "Epoch 484/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.6202 - val_loss: 7.6190\n",
      "Epoch 485/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.7989 - val_loss: 7.9938\n",
      "Epoch 486/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.4447 - val_loss: 7.0532\n",
      "Epoch 487/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.8235 - val_loss: 8.3396\n",
      "Epoch 488/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.8762 - val_loss: 7.2223\n",
      "Epoch 489/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.5224 - val_loss: 8.0472\n",
      "Epoch 490/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 6.6169 - val_loss: 8.3426\n",
      "Epoch 491/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.4129 - val_loss: 7.2611\n",
      "Epoch 492/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.2138 - val_loss: 7.8716\n",
      "Epoch 493/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.4051 - val_loss: 7.4358\n",
      "Epoch 494/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.6110 - val_loss: 7.3155\n",
      "Epoch 495/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 6.6689 - val_loss: 8.7775\n",
      "Epoch 496/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.6855 - val_loss: 8.7453\n",
      "Epoch 497/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.4542 - val_loss: 7.4745\n",
      "Epoch 498/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.0439 - val_loss: 9.1963\n",
      "Epoch 499/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.4923 - val_loss: 9.6147\n",
      "Epoch 500/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.8198 - val_loss: 8.7420\n",
      "Epoch 501/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.4106 - val_loss: 8.1465\n",
      "Epoch 502/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.6112 - val_loss: 8.5051\n",
      "Epoch 503/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.6890 - val_loss: 6.9168\n",
      "Epoch 504/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.0502 - val_loss: 9.5108\n",
      "Epoch 505/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.7338 - val_loss: 7.5210\n",
      "Epoch 506/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.4480 - val_loss: 8.9954\n",
      "Epoch 507/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.8221 - val_loss: 8.3850\n",
      "Epoch 508/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.3630 - val_loss: 7.5107\n",
      "Epoch 509/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.5271 - val_loss: 7.3798\n",
      "Epoch 510/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 6.2836 - val_loss: 9.4978\n",
      "Epoch 511/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.7357 - val_loss: 7.3577\n",
      "Epoch 512/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.4317 - val_loss: 7.5869\n",
      "Epoch 513/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.4898 - val_loss: 9.0623\n",
      "Epoch 514/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.8751 - val_loss: 7.0231\n",
      "Epoch 515/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.4514 - val_loss: 7.7729\n",
      "Epoch 516/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.8395 - val_loss: 7.4538\n",
      "Epoch 517/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.6264 - val_loss: 9.0125\n",
      "Epoch 518/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.7241 - val_loss: 7.6702\n",
      "Epoch 519/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.3421 - val_loss: 7.2330\n",
      "Epoch 520/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.8303 - val_loss: 8.8182\n",
      "Epoch 521/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.6032 - val_loss: 7.8394\n",
      "Epoch 522/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.1015 - val_loss: 7.5610\n",
      "Epoch 523/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.1020 - val_loss: 7.0423\n",
      "Epoch 524/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.2237 - val_loss: 6.9395\n",
      "Epoch 525/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.2848 - val_loss: 7.9194\n",
      "Epoch 526/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 6.9287 - val_loss: 7.4773\n",
      "Epoch 527/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.5768 - val_loss: 6.8995\n",
      "Epoch 528/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 6.1147 - val_loss: 7.4431\n",
      "Epoch 529/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.1941 - val_loss: 7.4660\n",
      "Epoch 530/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.6210 - val_loss: 7.0673\n",
      "Epoch 531/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.4673 - val_loss: 7.5078\n",
      "Epoch 532/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.7791 - val_loss: 8.8785\n",
      "Epoch 533/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.3513 - val_loss: 8.5773\n",
      "Epoch 534/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.9068 - val_loss: 7.7195\n",
      "Epoch 535/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.9327 - val_loss: 7.1337\n",
      "Epoch 536/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.1934 - val_loss: 6.8866\n",
      "Epoch 537/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.0517 - val_loss: 7.1800\n",
      "Epoch 538/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.5137 - val_loss: 8.1962\n",
      "Epoch 539/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.0796 - val_loss: 7.1679\n",
      "Epoch 540/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.1110 - val_loss: 7.5118\n",
      "Epoch 541/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.8191 - val_loss: 9.4129\n",
      "Epoch 542/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9230 - val_loss: 6.8525\n",
      "Epoch 543/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.4567 - val_loss: 7.0834\n",
      "Epoch 544/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.9373 - val_loss: 7.2199\n",
      "Epoch 545/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.3719 - val_loss: 7.2572\n",
      "Epoch 546/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.1249 - val_loss: 7.1791\n",
      "Epoch 547/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.1215 - val_loss: 7.8380\n",
      "Epoch 548/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.2462 - val_loss: 6.8326\n",
      "Epoch 549/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.5820 - val_loss: 12.6203\n",
      "Epoch 550/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.1061 - val_loss: 6.7349\n",
      "Epoch 551/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.2780 - val_loss: 7.3299\n",
      "Epoch 552/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.2919 - val_loss: 7.9588\n",
      "Epoch 553/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.4205 - val_loss: 7.5155\n",
      "Epoch 554/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.9106 - val_loss: 9.0594\n",
      "Epoch 555/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.1499 - val_loss: 6.9546\n",
      "Epoch 556/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.2571 - val_loss: 7.0210\n",
      "Epoch 557/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.1356 - val_loss: 8.0130\n",
      "Epoch 558/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.2365 - val_loss: 8.0811\n",
      "Epoch 559/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.7239 - val_loss: 8.7606\n",
      "Epoch 560/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.0931 - val_loss: 6.7549\n",
      "Epoch 561/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.2681 - val_loss: 9.4336\n",
      "Epoch 562/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.5755 - val_loss: 7.5182\n",
      "Epoch 563/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.2453 - val_loss: 6.6870\n",
      "Epoch 564/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.8837 - val_loss: 6.8879\n",
      "Epoch 565/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.4062 - val_loss: 6.8695\n",
      "Epoch 566/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.5577 - val_loss: 7.2381\n",
      "Epoch 567/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.3441 - val_loss: 6.9121\n",
      "Epoch 568/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.5095 - val_loss: 8.8635\n",
      "Epoch 569/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.5858 - val_loss: 6.9296\n",
      "Epoch 570/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.8005 - val_loss: 7.9843\n",
      "Epoch 571/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.5178 - val_loss: 6.7962\n",
      "Epoch 572/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.9219 - val_loss: 7.1789\n",
      "Epoch 573/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.2475 - val_loss: 7.5017\n",
      "Epoch 574/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.3384 - val_loss: 7.8571\n",
      "Epoch 575/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.3789 - val_loss: 6.6348\n",
      "Epoch 576/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.3789 - val_loss: 6.5073\n",
      "Epoch 577/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.1751 - val_loss: 9.2899\n",
      "Epoch 578/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.4301 - val_loss: 6.5559\n",
      "Epoch 579/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.0659 - val_loss: 7.7621\n",
      "Epoch 580/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.0637 - val_loss: 7.4022\n",
      "Epoch 581/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.9553 - val_loss: 7.9996\n",
      "Epoch 582/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.0876 - val_loss: 6.6036\n",
      "Epoch 583/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.0202 - val_loss: 7.4364\n",
      "Epoch 584/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.8338 - val_loss: 6.9510\n",
      "Epoch 585/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.3092 - val_loss: 7.0759\n",
      "Epoch 586/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.9867 - val_loss: 7.5183\n",
      "Epoch 587/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.4283 - val_loss: 7.2873\n",
      "Epoch 588/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.8155 - val_loss: 7.4989\n",
      "Epoch 589/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.7812 - val_loss: 8.7798\n",
      "Epoch 590/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.2408 - val_loss: 7.1378\n",
      "Epoch 591/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.1606 - val_loss: 7.1091\n",
      "Epoch 592/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.3501 - val_loss: 8.9042\n",
      "Epoch 593/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.9939 - val_loss: 6.5339\n",
      "Epoch 594/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.0945 - val_loss: 6.4189\n",
      "Epoch 595/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 6.3711 - val_loss: 6.6614\n",
      "Epoch 596/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.2226 - val_loss: 6.6296\n",
      "Epoch 597/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.9810 - val_loss: 7.5157\n",
      "Epoch 598/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.1414 - val_loss: 8.7084\n",
      "Epoch 599/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.8004 - val_loss: 8.0214\n",
      "Epoch 600/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.0679 - val_loss: 7.6050\n",
      "Epoch 601/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.0145 - val_loss: 6.9440\n",
      "Epoch 602/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.0729 - val_loss: 7.2683\n",
      "Epoch 603/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.1556 - val_loss: 7.3229\n",
      "Epoch 604/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.9550 - val_loss: 6.6176\n",
      "Epoch 605/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.1880 - val_loss: 6.8264\n",
      "Epoch 606/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 6.0176 - val_loss: 7.2389\n",
      "Epoch 607/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.7045 - val_loss: 6.7784\n",
      "Epoch 608/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.8415 - val_loss: 6.8632\n",
      "Epoch 609/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.9440 - val_loss: 6.7291\n",
      "Epoch 610/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.2337 - val_loss: 6.8195\n",
      "Epoch 611/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.8600 - val_loss: 6.4214\n",
      "Epoch 612/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.0545 - val_loss: 7.5851\n",
      "Epoch 613/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.3548 - val_loss: 7.7208\n",
      "Epoch 614/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.1623 - val_loss: 6.4737\n",
      "Epoch 615/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.9220 - val_loss: 7.0951\n",
      "Epoch 616/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 6.0280 - val_loss: 6.7763\n",
      "Epoch 617/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.4393 - val_loss: 6.7162\n",
      "Epoch 618/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.4708 - val_loss: 10.4121\n",
      "Epoch 619/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.8861 - val_loss: 6.6659\n",
      "Epoch 620/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.8029 - val_loss: 7.3666\n",
      "Epoch 621/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.2949 - val_loss: 6.7921\n",
      "Epoch 622/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.0962 - val_loss: 6.8985\n",
      "Epoch 623/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.8005 - val_loss: 6.7087\n",
      "Epoch 624/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 6.3936 - val_loss: 6.5976\n",
      "Epoch 625/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 6.0467 - val_loss: 7.4569\n",
      "Epoch 626/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 6.5418 - val_loss: 7.4019\n",
      "Epoch 627/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 6.4729 - val_loss: 7.6363\n",
      "Epoch 628/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 5.9938 - val_loss: 6.6707\n",
      "Epoch 629/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 5.7095 - val_loss: 6.8067\n",
      "Epoch 630/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 6.2210 - val_loss: 6.2504\n",
      "Epoch 631/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 6.4769 - val_loss: 9.8747\n",
      "Epoch 632/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.8148 - val_loss: 7.0850\n",
      "Epoch 633/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.7946 - val_loss: 6.3794\n",
      "Epoch 634/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.8373 - val_loss: 6.2608\n",
      "Epoch 635/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.0214 - val_loss: 6.4429\n",
      "Epoch 636/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.4349 - val_loss: 7.3694\n",
      "Epoch 637/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.2640 - val_loss: 9.5976\n",
      "Epoch 638/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.4689 - val_loss: 6.6250\n",
      "Epoch 639/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.1672 - val_loss: 7.3119\n",
      "Epoch 640/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.4406 - val_loss: 7.5098\n",
      "Epoch 641/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.0253 - val_loss: 7.0232\n",
      "Epoch 642/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.9218 - val_loss: 9.1542\n",
      "Epoch 643/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.3129 - val_loss: 6.8438\n",
      "Epoch 644/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.1994 - val_loss: 7.0339\n",
      "Epoch 645/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.8144 - val_loss: 7.7831\n",
      "Epoch 646/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.1510 - val_loss: 8.2416\n",
      "Epoch 647/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.9232 - val_loss: 7.0839\n",
      "Epoch 648/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.0666 - val_loss: 6.2916\n",
      "Epoch 649/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.9381 - val_loss: 6.6302\n",
      "Epoch 650/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.9638 - val_loss: 6.7647\n",
      "Epoch 651/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.7996 - val_loss: 6.8436\n",
      "Epoch 652/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.1257 - val_loss: 6.2776\n",
      "Epoch 653/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.8290 - val_loss: 6.3049\n",
      "Epoch 654/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.8498 - val_loss: 6.3875\n",
      "Epoch 655/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 6.0833 - val_loss: 6.4972\n",
      "Epoch 656/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.6821 - val_loss: 7.2844\n",
      "Epoch 657/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.1586 - val_loss: 6.3264\n",
      "Epoch 658/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.6447 - val_loss: 6.9796\n",
      "Epoch 659/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.5802 - val_loss: 6.9894\n",
      "Epoch 660/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.3739 - val_loss: 6.3309\n",
      "Epoch 661/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.7355 - val_loss: 6.4453\n",
      "Epoch 662/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.0010 - val_loss: 6.5638\n",
      "Epoch 663/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.0186 - val_loss: 7.1864\n",
      "Epoch 664/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.2005 - val_loss: 6.1574\n",
      "Epoch 665/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 6.4203 - val_loss: 8.2621\n",
      "Epoch 666/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.7977 - val_loss: 6.8926\n",
      "Epoch 667/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.7289 - val_loss: 6.9070\n",
      "Epoch 668/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.4184 - val_loss: 7.0045\n",
      "Epoch 669/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.3917 - val_loss: 8.6553\n",
      "Epoch 670/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.9106 - val_loss: 7.1730\n",
      "Epoch 671/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.7320 - val_loss: 6.6419\n",
      "Epoch 672/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6710 - val_loss: 7.5855\n",
      "Epoch 673/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.9543 - val_loss: 9.0376\n",
      "Epoch 674/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.1165 - val_loss: 7.2647\n",
      "Epoch 675/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.9897 - val_loss: 6.3509\n",
      "Epoch 676/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.9556 - val_loss: 6.0883\n",
      "Epoch 677/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.2458 - val_loss: 7.8596\n",
      "Epoch 678/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.0580 - val_loss: 6.4725\n",
      "Epoch 679/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.9675 - val_loss: 7.1990\n",
      "Epoch 680/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.9631 - val_loss: 6.3814\n",
      "Epoch 681/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.8276 - val_loss: 6.6770\n",
      "Epoch 682/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.8367 - val_loss: 6.7777\n",
      "Epoch 683/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.7904 - val_loss: 6.5679\n",
      "Epoch 684/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.2802 - val_loss: 6.5152\n",
      "Epoch 685/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 6.0369 - val_loss: 6.7571\n",
      "Epoch 686/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.9397 - val_loss: 7.3765\n",
      "Epoch 687/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6019 - val_loss: 7.3386\n",
      "Epoch 688/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.9322 - val_loss: 6.4944\n",
      "Epoch 689/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.7159 - val_loss: 6.8159\n",
      "Epoch 690/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.1517 - val_loss: 6.4661\n",
      "Epoch 691/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.9085 - val_loss: 7.5141\n",
      "Epoch 692/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.9562 - val_loss: 6.1698\n",
      "Epoch 693/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.7693 - val_loss: 6.9742\n",
      "Epoch 694/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.8531 - val_loss: 6.2202\n",
      "Epoch 695/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.1749 - val_loss: 7.2595\n",
      "Epoch 696/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.6864 - val_loss: 7.1528\n",
      "Epoch 697/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.9290 - val_loss: 6.4952\n",
      "Epoch 698/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 6.0517 - val_loss: 7.2639\n",
      "Epoch 699/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 6.3308 - val_loss: 8.2652\n",
      "Epoch 700/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 6.0775 - val_loss: 8.7286\n",
      "Epoch 701/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.0633 - val_loss: 7.1332\n",
      "Epoch 702/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.8427 - val_loss: 6.1319\n",
      "Epoch 703/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.5324 - val_loss: 8.7883\n",
      "Epoch 704/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.8112 - val_loss: 6.8310\n",
      "Epoch 705/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.6627 - val_loss: 6.1266\n",
      "Epoch 706/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.7542 - val_loss: 6.2000\n",
      "Epoch 707/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.6470 - val_loss: 7.4281\n",
      "Epoch 708/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.8133 - val_loss: 6.7753\n",
      "Epoch 709/1000\n",
      "1052/1052 [==============================] - 0s 116us/step - loss: 6.6034 - val_loss: 7.0555\n",
      "Epoch 710/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 5.6154 - val_loss: 6.8575\n",
      "Epoch 711/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.7737 - val_loss: 7.8576\n",
      "Epoch 712/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.6057 - val_loss: 6.8141\n",
      "Epoch 713/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.5249 - val_loss: 7.6914\n",
      "Epoch 714/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.9230 - val_loss: 6.6279\n",
      "Epoch 715/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 6.1371 - val_loss: 6.3039\n",
      "Epoch 716/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.9262 - val_loss: 6.5301\n",
      "Epoch 717/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.5671 - val_loss: 6.4196\n",
      "Epoch 718/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.8093 - val_loss: 6.0287\n",
      "Epoch 719/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.1691 - val_loss: 6.3738\n",
      "Epoch 720/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.6457 - val_loss: 6.0401\n",
      "Epoch 721/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.8869 - val_loss: 6.0703\n",
      "Epoch 722/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 5.9164 - val_loss: 6.4535\n",
      "Epoch 723/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.9467 - val_loss: 6.5555\n",
      "Epoch 724/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.2695 - val_loss: 6.1520\n",
      "Epoch 725/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.0491 - val_loss: 7.5350\n",
      "Epoch 726/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.5979 - val_loss: 6.3169\n",
      "Epoch 727/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.8359 - val_loss: 6.0800\n",
      "Epoch 728/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.1455 - val_loss: 9.6082\n",
      "Epoch 729/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.4668 - val_loss: 6.8912\n",
      "Epoch 730/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 6.5724 - val_loss: 6.7150\n",
      "Epoch 731/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.2520 - val_loss: 6.3103\n",
      "Epoch 732/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.0195 - val_loss: 6.8047\n",
      "Epoch 733/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.0448 - val_loss: 6.2833\n",
      "Epoch 734/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.3129 - val_loss: 10.0259\n",
      "Epoch 735/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.6988 - val_loss: 6.7024\n",
      "Epoch 736/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6774 - val_loss: 7.0179\n",
      "Epoch 737/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.8787 - val_loss: 6.7552\n",
      "Epoch 738/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.4852 - val_loss: 6.7078\n",
      "Epoch 739/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.5507 - val_loss: 6.1164\n",
      "Epoch 740/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.4766 - val_loss: 5.8713\n",
      "Epoch 741/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.5994 - val_loss: 6.3009\n",
      "Epoch 742/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.9567 - val_loss: 5.9127\n",
      "Epoch 743/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 6.2096 - val_loss: 6.8950\n",
      "Epoch 744/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.7571 - val_loss: 6.5522\n",
      "Epoch 745/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.7444 - val_loss: 6.5120\n",
      "Epoch 746/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.6331 - val_loss: 6.5290\n",
      "Epoch 747/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.8202 - val_loss: 6.8402\n",
      "Epoch 748/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.7134 - val_loss: 6.8272\n",
      "Epoch 749/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.9351 - val_loss: 6.8313\n",
      "Epoch 750/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.6143 - val_loss: 7.6199\n",
      "Epoch 751/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.7841 - val_loss: 6.1116\n",
      "Epoch 752/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.1817 - val_loss: 6.3830\n",
      "Epoch 753/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.0167 - val_loss: 6.1880\n",
      "Epoch 754/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.4249 - val_loss: 6.0416\n",
      "Epoch 755/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.5756 - val_loss: 6.4084\n",
      "Epoch 756/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.4680 - val_loss: 6.4909\n",
      "Epoch 757/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.7587 - val_loss: 6.1925\n",
      "Epoch 758/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.7022 - val_loss: 5.8386\n",
      "Epoch 759/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.3134 - val_loss: 6.3136\n",
      "Epoch 760/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.5582 - val_loss: 6.2625\n",
      "Epoch 761/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.6416 - val_loss: 6.4058\n",
      "Epoch 762/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.5107 - val_loss: 6.3337\n",
      "Epoch 763/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.7601 - val_loss: 5.9332\n",
      "Epoch 764/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.0792 - val_loss: 6.6520\n",
      "Epoch 765/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.5401 - val_loss: 6.1902\n",
      "Epoch 766/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.4260 - val_loss: 5.7738\n",
      "Epoch 767/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.8311 - val_loss: 6.5971\n",
      "Epoch 768/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.9184 - val_loss: 6.0816\n",
      "Epoch 769/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.0636 - val_loss: 7.4227\n",
      "Epoch 770/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6298 - val_loss: 5.9266\n",
      "Epoch 771/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.5005 - val_loss: 6.4602\n",
      "Epoch 772/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6523 - val_loss: 8.5551\n",
      "Epoch 773/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.8860 - val_loss: 6.0076\n",
      "Epoch 774/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.4910 - val_loss: 6.0842\n",
      "Epoch 775/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.5842 - val_loss: 6.1700\n",
      "Epoch 776/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.4113 - val_loss: 6.7499\n",
      "Epoch 777/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.9677 - val_loss: 6.7587\n",
      "Epoch 778/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6878 - val_loss: 6.5673\n",
      "Epoch 779/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 5.6679 - val_loss: 5.7604\n",
      "Epoch 780/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.4715 - val_loss: 5.9370\n",
      "Epoch 781/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.5581 - val_loss: 6.7234\n",
      "Epoch 782/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.8470 - val_loss: 6.1435\n",
      "Epoch 783/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.2504 - val_loss: 6.8550\n",
      "Epoch 784/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.0360 - val_loss: 6.2099\n",
      "Epoch 785/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.5075 - val_loss: 6.4809\n",
      "Epoch 786/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6177 - val_loss: 5.9437\n",
      "Epoch 787/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.3016 - val_loss: 6.2334\n",
      "Epoch 788/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.8686 - val_loss: 7.4286\n",
      "Epoch 789/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.9836 - val_loss: 6.4590\n",
      "Epoch 790/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6081 - val_loss: 6.8430\n",
      "Epoch 791/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.7650 - val_loss: 5.8393\n",
      "Epoch 792/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.8156 - val_loss: 5.9049\n",
      "Epoch 793/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.6794 - val_loss: 5.6824\n",
      "Epoch 794/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.5589 - val_loss: 7.3088\n",
      "Epoch 795/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 5.8974 - val_loss: 6.4633\n",
      "Epoch 796/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.7159 - val_loss: 7.2185\n",
      "Epoch 797/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 5.4493 - val_loss: 5.8132\n",
      "Epoch 798/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 5.3735 - val_loss: 5.9780\n",
      "Epoch 799/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 5.6034 - val_loss: 5.8936\n",
      "Epoch 800/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 6.1869 - val_loss: 5.5239\n",
      "Epoch 801/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.4215 - val_loss: 5.9284\n",
      "Epoch 802/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.5981 - val_loss: 6.1880\n",
      "Epoch 803/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 5.5113 - val_loss: 6.3357\n",
      "Epoch 804/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.5973 - val_loss: 7.9328\n",
      "Epoch 805/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 5.8308 - val_loss: 5.6318\n",
      "Epoch 806/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 6.1411 - val_loss: 7.5347\n",
      "Epoch 807/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.6293 - val_loss: 7.0960\n",
      "Epoch 808/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 5.6214 - val_loss: 5.9085\n",
      "Epoch 809/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 5.5120 - val_loss: 5.8874\n",
      "Epoch 810/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.3307 - val_loss: 6.9496\n",
      "Epoch 811/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.3037 - val_loss: 6.4716\n",
      "Epoch 812/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.1146 - val_loss: 5.6530\n",
      "Epoch 813/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.8154 - val_loss: 5.7569\n",
      "Epoch 814/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.5288 - val_loss: 5.7736\n",
      "Epoch 815/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.2375 - val_loss: 6.4629\n",
      "Epoch 816/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.4195 - val_loss: 5.7065\n",
      "Epoch 817/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.4673 - val_loss: 6.9273\n",
      "Epoch 818/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.8853 - val_loss: 5.6962\n",
      "Epoch 819/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.5781 - val_loss: 6.5274\n",
      "Epoch 820/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 5.6492 - val_loss: 7.0255\n",
      "Epoch 821/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.4119 - val_loss: 6.9557\n",
      "Epoch 822/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.5864 - val_loss: 6.3991\n",
      "Epoch 823/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.5569 - val_loss: 6.6355\n",
      "Epoch 824/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.9813 - val_loss: 5.6809\n",
      "Epoch 825/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.6999 - val_loss: 5.5709\n",
      "Epoch 826/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.4974 - val_loss: 5.9543\n",
      "Epoch 827/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.4625 - val_loss: 6.3317\n",
      "Epoch 828/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.7192 - val_loss: 5.8895\n",
      "Epoch 829/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.8727 - val_loss: 6.1063\n",
      "Epoch 830/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.2766 - val_loss: 6.0297\n",
      "Epoch 831/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.4270 - val_loss: 6.3621\n",
      "Epoch 832/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.5143 - val_loss: 6.4283\n",
      "Epoch 833/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.3205 - val_loss: 7.4873\n",
      "Epoch 834/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.5001 - val_loss: 6.3951\n",
      "Epoch 835/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.5837 - val_loss: 6.1317\n",
      "Epoch 836/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.4301 - val_loss: 5.5689\n",
      "Epoch 837/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.7686 - val_loss: 7.0515\n",
      "Epoch 838/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.4126 - val_loss: 6.3379\n",
      "Epoch 839/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.0985 - val_loss: 6.3083\n",
      "Epoch 840/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.1140 - val_loss: 5.9848\n",
      "Epoch 841/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.4826 - val_loss: 6.8537\n",
      "Epoch 842/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.7005 - val_loss: 5.4763\n",
      "Epoch 843/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6481 - val_loss: 6.1314\n",
      "Epoch 844/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.1636 - val_loss: 5.7628\n",
      "Epoch 845/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.3391 - val_loss: 6.3543\n",
      "Epoch 846/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.3564 - val_loss: 5.8663\n",
      "Epoch 847/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.1831 - val_loss: 5.6973\n",
      "Epoch 848/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.3206 - val_loss: 5.7362\n",
      "Epoch 849/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.7162 - val_loss: 5.7400\n",
      "Epoch 850/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.2671 - val_loss: 6.2186\n",
      "Epoch 851/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.4902 - val_loss: 6.4299\n",
      "Epoch 852/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.5356 - val_loss: 7.3751\n",
      "Epoch 853/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.3474 - val_loss: 7.1170\n",
      "Epoch 854/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.8450 - val_loss: 7.6178\n",
      "Epoch 855/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.0674 - val_loss: 5.6673\n",
      "Epoch 856/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.4823 - val_loss: 5.9115\n",
      "Epoch 857/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.4152 - val_loss: 5.9246\n",
      "Epoch 858/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.2134 - val_loss: 6.4292\n",
      "Epoch 859/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.6137 - val_loss: 6.2871\n",
      "Epoch 860/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.4689 - val_loss: 5.9046\n",
      "Epoch 861/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.2843 - val_loss: 5.5854\n",
      "Epoch 862/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.4630 - val_loss: 6.7384\n",
      "Epoch 863/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 6.0049 - val_loss: 5.5564\n",
      "Epoch 864/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.3652 - val_loss: 6.3168\n",
      "Epoch 865/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.5787 - val_loss: 8.2079\n",
      "Epoch 866/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6962 - val_loss: 6.2397\n",
      "Epoch 867/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.5234 - val_loss: 6.0252\n",
      "Epoch 868/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.0471 - val_loss: 8.3245\n",
      "Epoch 869/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.5946 - val_loss: 6.5378\n",
      "Epoch 870/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.5076 - val_loss: 5.5547\n",
      "Epoch 871/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.0668 - val_loss: 11.5070\n",
      "Epoch 872/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.4900 - val_loss: 6.8288\n",
      "Epoch 873/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.3450 - val_loss: 5.7216\n",
      "Epoch 874/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.2046 - val_loss: 5.4069\n",
      "Epoch 875/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.1329 - val_loss: 6.4318\n",
      "Epoch 876/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.3021 - val_loss: 7.3846\n",
      "Epoch 877/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.6242 - val_loss: 6.0678\n",
      "Epoch 878/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.3532 - val_loss: 5.7944\n",
      "Epoch 879/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.3559 - val_loss: 6.2039\n",
      "Epoch 880/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.2797 - val_loss: 7.8120\n",
      "Epoch 881/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.8304 - val_loss: 5.6051\n",
      "Epoch 882/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.7590 - val_loss: 5.8318\n",
      "Epoch 883/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.5870 - val_loss: 6.3258\n",
      "Epoch 884/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.3909 - val_loss: 5.6933\n",
      "Epoch 885/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.8410 - val_loss: 6.3987\n",
      "Epoch 886/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.5177 - val_loss: 6.2754\n",
      "Epoch 887/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.7605 - val_loss: 7.3658\n",
      "Epoch 888/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.9354 - val_loss: 6.0627\n",
      "Epoch 889/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.1797 - val_loss: 5.9743\n",
      "Epoch 890/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.0220 - val_loss: 6.2457\n",
      "Epoch 891/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.2315 - val_loss: 5.6946\n",
      "Epoch 892/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.2316 - val_loss: 6.2495\n",
      "Epoch 893/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.2464 - val_loss: 6.2089\n",
      "Epoch 894/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.5613 - val_loss: 6.0233\n",
      "Epoch 895/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.4518 - val_loss: 5.9664\n",
      "Epoch 896/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.5825 - val_loss: 6.3816\n",
      "Epoch 897/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.6604 - val_loss: 5.4978\n",
      "Epoch 898/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.7743 - val_loss: 6.0358\n",
      "Epoch 899/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.6167 - val_loss: 6.7272\n",
      "Epoch 900/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.3673 - val_loss: 5.7785\n",
      "Epoch 901/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.5579 - val_loss: 5.6377\n",
      "Epoch 902/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.4848 - val_loss: 5.6971\n",
      "Epoch 903/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.8186 - val_loss: 5.8938\n",
      "Epoch 904/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.4854 - val_loss: 5.8610\n",
      "Epoch 905/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.6816 - val_loss: 5.5527\n",
      "Epoch 906/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.5047 - val_loss: 6.3429\n",
      "Epoch 907/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.3692 - val_loss: 5.6984\n",
      "Epoch 908/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.2897 - val_loss: 5.9540\n",
      "Epoch 909/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.7534 - val_loss: 5.7520\n",
      "Epoch 910/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.3318 - val_loss: 5.3187\n",
      "Epoch 911/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.3390 - val_loss: 5.6154\n",
      "Epoch 912/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.7973 - val_loss: 5.3319\n",
      "Epoch 913/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.4999 - val_loss: 5.7291\n",
      "Epoch 914/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.3290 - val_loss: 7.5097\n",
      "Epoch 915/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.6123 - val_loss: 5.5577\n",
      "Epoch 916/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.5918 - val_loss: 6.5460\n",
      "Epoch 917/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.8605 - val_loss: 6.2288\n",
      "Epoch 918/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.4856 - val_loss: 7.1735\n",
      "Epoch 919/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.2073 - val_loss: 5.6796\n",
      "Epoch 920/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.9682 - val_loss: 6.8663\n",
      "Epoch 921/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.5187 - val_loss: 7.3215\n",
      "Epoch 922/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.4633 - val_loss: 6.3698\n",
      "Epoch 923/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.6517 - val_loss: 5.8822\n",
      "Epoch 924/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.1299 - val_loss: 5.6928\n",
      "Epoch 925/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.2558 - val_loss: 5.7985\n",
      "Epoch 926/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6665 - val_loss: 6.4288\n",
      "Epoch 927/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.7735 - val_loss: 5.5436\n",
      "Epoch 928/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.3586 - val_loss: 5.6524\n",
      "Epoch 929/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.1705 - val_loss: 6.0189\n",
      "Epoch 930/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.2571 - val_loss: 7.4608\n",
      "Epoch 931/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.5022 - val_loss: 5.8828\n",
      "Epoch 932/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.6018 - val_loss: 9.1859\n",
      "Epoch 933/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.4653 - val_loss: 6.1587\n",
      "Epoch 934/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.7489 - val_loss: 7.0006\n",
      "Epoch 935/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.2978 - val_loss: 6.2536\n",
      "Epoch 936/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.2974 - val_loss: 6.5465\n",
      "Epoch 937/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.4725 - val_loss: 6.5911\n",
      "Epoch 938/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.4001 - val_loss: 5.7729\n",
      "Epoch 939/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.2439 - val_loss: 6.4502\n",
      "Epoch 940/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.4238 - val_loss: 6.2837\n",
      "Epoch 941/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.2629 - val_loss: 5.5049\n",
      "Epoch 942/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.5902 - val_loss: 6.4258\n",
      "Epoch 943/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.5654 - val_loss: 6.0778\n",
      "Epoch 944/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.4382 - val_loss: 5.7890\n",
      "Epoch 945/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.1140 - val_loss: 5.6079\n",
      "Epoch 946/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.3811 - val_loss: 5.5450\n",
      "Epoch 947/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.6753 - val_loss: 5.8333\n",
      "Epoch 948/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.1881 - val_loss: 6.2232\n",
      "Epoch 949/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.3427 - val_loss: 6.0752\n",
      "Epoch 950/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.3887 - val_loss: 6.5408\n",
      "Epoch 951/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.4288 - val_loss: 5.8576\n",
      "Epoch 952/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.5764 - val_loss: 5.6766\n",
      "Epoch 953/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.3929 - val_loss: 6.7674\n",
      "Epoch 954/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 6.1195 - val_loss: 5.8560\n",
      "Epoch 955/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 5.5830 - val_loss: 5.3009\n",
      "Epoch 956/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.2182 - val_loss: 6.9838\n",
      "Epoch 957/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.3761 - val_loss: 6.2524\n",
      "Epoch 958/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.5085 - val_loss: 6.4796\n",
      "Epoch 959/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.8672 - val_loss: 6.0932\n",
      "Epoch 960/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.6763 - val_loss: 5.7575\n",
      "Epoch 961/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.4684 - val_loss: 5.4906\n",
      "Epoch 962/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.5156 - val_loss: 6.5903\n",
      "Epoch 963/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.4729 - val_loss: 6.3436\n",
      "Epoch 964/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.3741 - val_loss: 5.6663\n",
      "Epoch 965/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.3149 - val_loss: 5.4533\n",
      "Epoch 966/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.2187 - val_loss: 5.3704\n",
      "Epoch 967/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.8702 - val_loss: 7.3291\n",
      "Epoch 968/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.4396 - val_loss: 7.1183\n",
      "Epoch 969/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.5740 - val_loss: 5.9307\n",
      "Epoch 970/1000\n",
      "1052/1052 [==============================] - 0s 109us/step - loss: 6.0527 - val_loss: 6.9583\n",
      "Epoch 971/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 5.7229 - val_loss: 6.1081\n",
      "Epoch 972/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 5.3986 - val_loss: 5.3404\n",
      "Epoch 973/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 5.4068 - val_loss: 5.5283\n",
      "Epoch 974/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 5.2655 - val_loss: 5.6562\n",
      "Epoch 975/1000\n",
      "1052/1052 [==============================] - 0s 111us/step - loss: 5.2171 - val_loss: 5.7204\n",
      "Epoch 976/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.4329 - val_loss: 9.0260\n",
      "Epoch 977/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.4128 - val_loss: 5.6695\n",
      "Epoch 978/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.2644 - val_loss: 5.8090\n",
      "Epoch 979/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.2411 - val_loss: 5.7295\n",
      "Epoch 980/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.4308 - val_loss: 5.7677\n",
      "Epoch 981/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.2620 - val_loss: 6.2845\n",
      "Epoch 982/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.3045 - val_loss: 6.1528\n",
      "Epoch 983/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.1329 - val_loss: 5.8869\n",
      "Epoch 984/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.2807 - val_loss: 5.9828\n",
      "Epoch 985/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.0417 - val_loss: 6.1328\n",
      "Epoch 986/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.1630 - val_loss: 5.9303\n",
      "Epoch 987/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.4964 - val_loss: 6.1638\n",
      "Epoch 988/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.5606 - val_loss: 5.6617\n",
      "Epoch 989/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.3629 - val_loss: 5.3617\n",
      "Epoch 990/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.4691 - val_loss: 5.9141\n",
      "Epoch 991/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.6713 - val_loss: 7.6491\n",
      "Epoch 992/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.6822 - val_loss: 6.0021\n",
      "Epoch 993/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.7435 - val_loss: 5.6769\n",
      "Epoch 994/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.3032 - val_loss: 5.5204\n",
      "Epoch 995/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.2536 - val_loss: 5.3669\n",
      "Epoch 996/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6181 - val_loss: 7.7459\n",
      "Epoch 997/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.8361 - val_loss: 7.7032\n",
      "Epoch 998/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.2170 - val_loss: 5.5318\n",
      "Epoch 999/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.1966 - val_loss: 5.4842\n",
      "Epoch 1000/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.7194 - val_loss: 6.6748\n",
      "7.520083601495861\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 0.9664121 , -0.71439797,  3.457057  , -3.869236  ,  3.1601624 ,\n",
       "         -0.5665238 , -0.29038548,  1.3507513 ,  3.8137453 , -0.1498905 ],\n",
       "        [ 0.67139256, -0.32646775, -0.03267581,  0.15531106, -0.20973071,\n",
       "         -1.3679898 , -0.5755995 ,  1.2874985 ,  0.453728  , -0.08349421],\n",
       "        [-0.06338986, -0.83258474,  1.6046946 ,  0.09304156,  0.06345822,\n",
       "         -1.7463905 , -1.3970995 ,  1.772311  ,  1.979807  , -1.1843576 ],\n",
       "        [-0.2985319 ,  1.1293962 , -0.15580216,  0.00516685, -0.06806385,\n",
       "          0.01829284,  0.16563173, -0.7386769 , -0.15881743, -0.25415915],\n",
       "        [ 1.1360056 , -1.141263  , -0.18083592, -2.048034  ,  0.26113388,\n",
       "         -0.5319344 ,  0.11053264,  2.934145  ,  0.5286733 ,  0.14794125]],\n",
       "       dtype=float32),\n",
       " array([ 0.80044097,  2.9348962 ,  5.4104166 , -4.6731615 ,  1.818548  ,\n",
       "         5.0096025 , -1.0973121 ,  4.5200706 ,  3.8615472 ,  4.695368  ],\n",
       "       dtype=float32),\n",
       " array([[-0.54518306,  0.1050121 ,  0.6320416 , -0.02741606, -0.03393076,\n",
       "         -0.34513047, -0.4602043 ,  0.6457827 ,  0.40945628, -0.11431203,\n",
       "         -0.6007562 ,  0.24546348, -0.02260334,  0.7350534 ,  0.43944687],\n",
       "        [ 0.36895952, -0.46100473, -0.647151  ,  0.41781613, -0.7475067 ,\n",
       "         -0.29912543, -0.31037104, -0.20037684, -0.21094677, -0.42110103,\n",
       "         -0.30241707,  0.20638302,  0.22766487, -0.03682358,  0.52271694],\n",
       "        [ 1.4851321 , -1.6691998 , -1.4558039 ,  1.2608948 , -2.1905737 ,\n",
       "          1.3334484 ,  1.1951318 , -1.6787714 , -1.3773601 ,  1.6148617 ,\n",
       "          1.4306195 , -0.71249926,  2.207246  , -2.2127805 , -1.028271  ],\n",
       "        [-1.2767041 ,  1.301447  ,  1.7816825 , -1.5461206 ,  1.4076093 ,\n",
       "         -1.0238714 , -1.4631802 ,  1.8292712 ,  0.93545336, -0.8490264 ,\n",
       "         -1.4209819 ,  0.70823   , -1.6882268 ,  2.0714836 ,  1.3722495 ],\n",
       "        [-0.6755885 ,  0.684294  ,  0.21211125, -0.35163242,  0.99052036,\n",
       "         -0.89883685, -0.8360574 ,  0.7402367 ,  0.48424348, -0.48384628,\n",
       "         -0.53123343,  0.31210434, -0.92363584,  0.440035  ,  0.5992698 ],\n",
       "        [ 0.77469265, -1.1252567 , -0.8505697 ,  1.3724966 , -1.0419164 ,\n",
       "          0.9503638 ,  1.1160902 , -1.5564431 , -0.7157122 ,  0.6740991 ,\n",
       "          1.014114  , -0.22509038,  1.6191242 , -1.4205722 , -1.2588141 ],\n",
       "        [ 0.94606286, -0.39240453, -0.3041586 ,  1.0646228 , -0.40800676,\n",
       "          1.0027654 ,  0.9970817 , -0.75874436, -0.9704293 ,  1.2716272 ,\n",
       "          1.0455711 , -1.2302462 ,  0.9993892 , -0.22269757, -0.9664991 ],\n",
       "        [ 0.08435005, -0.05346079, -0.51957446,  0.8632685 , -0.27154526,\n",
       "         -0.4876438 , -0.33010304,  0.12302201, -0.04709545, -0.12168356,\n",
       "          0.45610762, -0.2795468 ,  0.81159544, -0.50448203,  0.05208613],\n",
       "        [ 0.8405903 , -0.26208317, -0.2306552 ,  0.5454728 , -0.64002067,\n",
       "         -0.24989623,  0.5118453 , -0.24354523, -0.7296971 ,  0.4271305 ,\n",
       "          0.2958085 , -0.09092518,  0.7485784 , -0.8697375 , -0.5549759 ],\n",
       "        [ 1.572178  , -2.0366666 , -1.4124168 ,  1.9288262 , -1.4695135 ,\n",
       "          0.78661394,  1.1621152 , -1.2514805 , -1.400385  ,  1.5984039 ,\n",
       "          1.6678482 , -0.63937336,  1.8350165 , -1.993241  , -0.9702199 ]],\n",
       "       dtype=float32),\n",
       " array([ 1.8191789, -1.8850513, -1.8770583,  1.898466 , -1.933182 ,\n",
       "         1.445755 ,  1.6254748, -1.843302 , -1.7200626,  1.5673653,\n",
       "         1.7921501, -1.4087335,  1.9566215, -1.9456323, -1.5742273],\n",
       "       dtype=float32),\n",
       " array([[ 1.0890586 ],\n",
       "        [-1.3450232 ],\n",
       "        [-1.3294342 ],\n",
       "        [ 1.4250367 ],\n",
       "        [-1.5475271 ],\n",
       "        [ 0.53520185],\n",
       "        [ 0.7962104 ],\n",
       "        [-1.2705163 ],\n",
       "        [-0.8705767 ],\n",
       "        [ 0.738251  ],\n",
       "        [ 1.05291   ],\n",
       "        [-0.36075804],\n",
       "        [ 1.6764339 ],\n",
       "        [-1.6682079 ],\n",
       "        [-0.7215157 ]], dtype=float32),\n",
       " array([2.192012], dtype=float32)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_airfoil, history_airfoil, evaluate_airfoil=NN_model_structure_regression_6(X_train_airfoil, X_val_airfoil, Y_train_airfoil, Y_val_airfoil, adam2, 32, 1000, x_test_airfoil, y_test_airfoil)\n",
    "model_airfoil.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_airfoil.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_airfoil_structure6_4th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_19 (Dense)             (None, 5)                 40        \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 76\n",
      "Trainable params: 76\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 274 samples, validate on 59 samples\n",
      "Epoch 1/1000\n",
      "274/274 [==============================] - 0s 799us/step - loss: 504.2260 - val_loss: 318.2313\n",
      "Epoch 2/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 235.2374 - val_loss: 103.9855\n",
      "Epoch 3/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 63.3557 - val_loss: 48.8885\n",
      "Epoch 4/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 33.5616 - val_loss: 28.9203\n",
      "Epoch 5/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 25.8883 - val_loss: 23.8108\n",
      "Epoch 6/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 21.9491 - val_loss: 21.7242\n",
      "Epoch 7/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 19.9904 - val_loss: 19.6241\n",
      "Epoch 8/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 18.1812 - val_loss: 18.2349\n",
      "Epoch 9/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 16.9328 - val_loss: 17.8332\n",
      "Epoch 10/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 16.0787 - val_loss: 18.0936\n",
      "Epoch 11/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 14.9187 - val_loss: 17.4015\n",
      "Epoch 12/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 14.0724 - val_loss: 17.8057\n",
      "Epoch 13/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 13.1820 - val_loss: 17.4573\n",
      "Epoch 14/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 12.7023 - val_loss: 17.4625\n",
      "Epoch 15/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 12.2188 - val_loss: 17.2505\n",
      "Epoch 16/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 12.3216 - val_loss: 17.1514\n",
      "Epoch 17/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 11.8759 - val_loss: 17.4080\n",
      "Epoch 18/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 11.7001 - val_loss: 16.8600\n",
      "Epoch 19/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 11.4377 - val_loss: 16.7213\n",
      "Epoch 20/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 11.1777 - val_loss: 16.0666\n",
      "Epoch 21/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 10.9423 - val_loss: 15.6481\n",
      "Epoch 22/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 10.9176 - val_loss: 15.6007\n",
      "Epoch 23/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 10.7645 - val_loss: 15.3315\n",
      "Epoch 24/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 10.9253 - val_loss: 15.0958\n",
      "Epoch 25/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 10.8137 - val_loss: 14.8588\n",
      "Epoch 26/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 10.3745 - val_loss: 14.5400\n",
      "Epoch 27/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 10.4561 - val_loss: 13.7138\n",
      "Epoch 28/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 10.3314 - val_loss: 13.3751\n",
      "Epoch 29/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 10.2407 - val_loss: 13.4632\n",
      "Epoch 30/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 10.0188 - val_loss: 13.0273\n",
      "Epoch 31/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 9.9042 - val_loss: 12.9841\n",
      "Epoch 32/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 9.8072 - val_loss: 12.6979\n",
      "Epoch 33/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 9.8081 - val_loss: 12.5030\n",
      "Epoch 34/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 9.9468 - val_loss: 12.2312\n",
      "Epoch 35/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 9.8185 - val_loss: 12.0896\n",
      "Epoch 36/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 9.7093 - val_loss: 11.8796\n",
      "Epoch 37/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 9.4361 - val_loss: 11.6112\n",
      "Epoch 38/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 9.4691 - val_loss: 11.8494\n",
      "Epoch 39/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 9.4596 - val_loss: 11.5972\n",
      "Epoch 40/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 9.3029 - val_loss: 11.3971\n",
      "Epoch 41/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 9.3038 - val_loss: 11.2737\n",
      "Epoch 42/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 9.2378 - val_loss: 11.2845\n",
      "Epoch 43/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 9.1948 - val_loss: 11.0348\n",
      "Epoch 44/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 9.2010 - val_loss: 10.7596\n",
      "Epoch 45/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 9.2498 - val_loss: 10.7470\n",
      "Epoch 46/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 9.2275 - val_loss: 10.9761\n",
      "Epoch 47/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 9.0291 - val_loss: 10.9390\n",
      "Epoch 48/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 9.1801 - val_loss: 10.9468\n",
      "Epoch 49/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.9437 - val_loss: 10.7261\n",
      "Epoch 50/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 8.9810 - val_loss: 10.4853\n",
      "Epoch 51/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 8.8908 - val_loss: 10.6722\n",
      "Epoch 52/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.9153 - val_loss: 10.4589\n",
      "Epoch 53/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 9.2105 - val_loss: 10.3913\n",
      "Epoch 54/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.9051 - val_loss: 10.4755\n",
      "Epoch 55/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.7679 - val_loss: 10.5266\n",
      "Epoch 56/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.7727 - val_loss: 10.6196\n",
      "Epoch 57/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 8.8201 - val_loss: 10.1920\n",
      "Epoch 58/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.8568 - val_loss: 10.4471\n",
      "Epoch 59/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.7084 - val_loss: 10.2821\n",
      "Epoch 60/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.7761 - val_loss: 10.1746\n",
      "Epoch 61/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 14.11 - 0s 95us/step - loss: 9.0098 - val_loss: 10.0633\n",
      "Epoch 62/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 9.1814 - val_loss: 10.2703\n",
      "Epoch 63/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 8.6680 - val_loss: 10.8503\n",
      "Epoch 64/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.5953 - val_loss: 10.2922\n",
      "Epoch 65/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.4899 - val_loss: 10.4572\n",
      "Epoch 66/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.6398 - val_loss: 10.0905\n",
      "Epoch 67/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 8.5049 - val_loss: 9.8680\n",
      "Epoch 68/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 98us/step - loss: 8.3593 - val_loss: 10.0390\n",
      "Epoch 69/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.3811 - val_loss: 10.0354\n",
      "Epoch 70/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.2641 - val_loss: 9.8600\n",
      "Epoch 71/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.3064 - val_loss: 9.7282\n",
      "Epoch 72/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 8.1957 - val_loss: 9.9753\n",
      "Epoch 73/1000\n",
      "274/274 [==============================] - 0s 117us/step - loss: 8.1497 - val_loss: 9.8319\n",
      "Epoch 74/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 8.1458 - val_loss: 9.7401\n",
      "Epoch 75/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.1063 - val_loss: 9.9375\n",
      "Epoch 76/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.0672 - val_loss: 9.7403\n",
      "Epoch 77/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.1073 - val_loss: 9.7807\n",
      "Epoch 78/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 8.1071 - val_loss: 9.8397\n",
      "Epoch 79/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 8.0544 - val_loss: 9.7987\n",
      "Epoch 80/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 8.2380 - val_loss: 9.8034\n",
      "Epoch 81/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.2429 - val_loss: 9.7367\n",
      "Epoch 82/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 8.2470 - val_loss: 9.6412\n",
      "Epoch 83/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.0194 - val_loss: 9.9243\n",
      "Epoch 84/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 8.2298 - val_loss: 9.6667\n",
      "Epoch 85/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.1320 - val_loss: 9.7154\n",
      "Epoch 86/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.0676 - val_loss: 9.8021\n",
      "Epoch 87/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.2330 - val_loss: 9.8132\n",
      "Epoch 88/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 7.9681 - val_loss: 9.6917\n",
      "Epoch 89/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 7.7445 - val_loss: 9.5820\n",
      "Epoch 90/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.6859 - val_loss: 9.6367\n",
      "Epoch 91/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.7420 - val_loss: 9.7810\n",
      "Epoch 92/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.7684 - val_loss: 9.5729\n",
      "Epoch 93/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 7.6936 - val_loss: 9.7016\n",
      "Epoch 94/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 7.6076 - val_loss: 9.8058\n",
      "Epoch 95/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 7.6775 - val_loss: 9.5912\n",
      "Epoch 96/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 7.7068 - val_loss: 9.5281\n",
      "Epoch 97/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.7171 - val_loss: 9.8374\n",
      "Epoch 98/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 8.0243 - val_loss: 9.6461\n",
      "Epoch 99/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.1725 - val_loss: 9.8694\n",
      "Epoch 100/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.6806 - val_loss: 9.9034\n",
      "Epoch 101/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 7.5883 - val_loss: 9.6517\n",
      "Epoch 102/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.5328 - val_loss: 9.6515\n",
      "Epoch 103/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.4218 - val_loss: 9.5778\n",
      "Epoch 104/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.5211 - val_loss: 9.6788\n",
      "Epoch 105/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 7.5370 - val_loss: 9.4451\n",
      "Epoch 106/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 7.4175 - val_loss: 9.3573\n",
      "Epoch 107/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 7.4097 - val_loss: 9.5147\n",
      "Epoch 108/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.4507 - val_loss: 9.5917\n",
      "Epoch 109/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.4029 - val_loss: 9.4070\n",
      "Epoch 110/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3543 - val_loss: 9.7038\n",
      "Epoch 111/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.3854 - val_loss: 9.6766\n",
      "Epoch 112/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3677 - val_loss: 9.2065\n",
      "Epoch 113/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 7.5107 - val_loss: 9.4503\n",
      "Epoch 114/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 7.4262 - val_loss: 9.5650\n",
      "Epoch 115/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 7.3376 - val_loss: 9.7388\n",
      "Epoch 116/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.2999 - val_loss: 9.5724\n",
      "Epoch 117/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 7.2407 - val_loss: 9.5541\n",
      "Epoch 118/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.2079 - val_loss: 9.5257\n",
      "Epoch 119/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 7.2476 - val_loss: 9.7006\n",
      "Epoch 120/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2359 - val_loss: 9.3140\n",
      "Epoch 121/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.2758 - val_loss: 9.6746\n",
      "Epoch 122/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.3206 - val_loss: 9.5272\n",
      "Epoch 123/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 7.4934 - val_loss: 9.5027\n",
      "Epoch 124/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.4828 - val_loss: 9.4991\n",
      "Epoch 125/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3410 - val_loss: 9.6900\n",
      "Epoch 126/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1177 - val_loss: 9.2247\n",
      "Epoch 127/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2518 - val_loss: 9.5287\n",
      "Epoch 128/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.3009 - val_loss: 9.4957\n",
      "Epoch 129/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1287 - val_loss: 9.6561\n",
      "Epoch 130/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 7.0730 - val_loss: 9.5942\n",
      "Epoch 131/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1432 - val_loss: 9.2888\n",
      "Epoch 132/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1133 - val_loss: 9.6552\n",
      "Epoch 133/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.1182 - val_loss: 9.4936\n",
      "Epoch 134/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0586 - val_loss: 9.6627\n",
      "Epoch 135/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1182 - val_loss: 9.4079\n",
      "Epoch 136/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0951 - val_loss: 9.4382\n",
      "Epoch 137/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.0281 - val_loss: 9.6110\n",
      "Epoch 138/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.0497 - val_loss: 9.4967\n",
      "Epoch 139/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1052 - val_loss: 9.5385\n",
      "Epoch 140/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.0250 - val_loss: 9.5170\n",
      "Epoch 141/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.0544 - val_loss: 9.7156\n",
      "Epoch 142/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.3247 - val_loss: 9.5715\n",
      "Epoch 143/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1553 - val_loss: 9.6885\n",
      "Epoch 144/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 7.1242 - val_loss: 9.3335\n",
      "Epoch 145/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9952 - val_loss: 9.5063\n",
      "Epoch 146/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 91us/step - loss: 7.1296 - val_loss: 9.4564\n",
      "Epoch 147/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 7.3791 - val_loss: 9.5641\n",
      "Epoch 148/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0573 - val_loss: 9.7220\n",
      "Epoch 149/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1622 - val_loss: 9.0841\n",
      "Epoch 150/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 7.0081 - val_loss: 9.3651\n",
      "Epoch 151/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.9063 - val_loss: 9.5225\n",
      "Epoch 152/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 7.1337 - val_loss: 9.5243\n",
      "Epoch 153/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3424 - val_loss: 9.5632\n",
      "Epoch 154/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9469 - val_loss: 9.3175\n",
      "Epoch 155/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9104 - val_loss: 9.4790\n",
      "Epoch 156/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8931 - val_loss: 9.4973\n",
      "Epoch 157/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9494 - val_loss: 9.1838\n",
      "Epoch 158/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.9102 - val_loss: 9.1308\n",
      "Epoch 159/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.3235 - val_loss: 9.4583\n",
      "Epoch 160/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.9437 - val_loss: 9.5283\n",
      "Epoch 161/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9983 - val_loss: 9.3551\n",
      "Epoch 162/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1162 - val_loss: 9.2917\n",
      "Epoch 163/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.8681 - val_loss: 9.3595\n",
      "Epoch 164/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.9411 - val_loss: 9.4211\n",
      "Epoch 165/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.9939 - val_loss: 9.2101\n",
      "Epoch 166/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.8658 - val_loss: 9.2835\n",
      "Epoch 167/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7792 - val_loss: 9.0979\n",
      "Epoch 168/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7586 - val_loss: 9.3257\n",
      "Epoch 169/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8276 - val_loss: 9.0046\n",
      "Epoch 170/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7436 - val_loss: 9.0725\n",
      "Epoch 171/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8914 - val_loss: 9.1079\n",
      "Epoch 172/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7697 - val_loss: 9.2260\n",
      "Epoch 173/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.8031 - val_loss: 9.0957\n",
      "Epoch 174/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.7718 - val_loss: 9.2838\n",
      "Epoch 175/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.8378 - val_loss: 8.9249\n",
      "Epoch 176/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.0170 - val_loss: 9.3108\n",
      "Epoch 177/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.7612 - val_loss: 8.8350\n",
      "Epoch 178/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.8329 - val_loss: 9.4368\n",
      "Epoch 179/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.7382 - val_loss: 9.0765\n",
      "Epoch 180/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9133 - val_loss: 9.1298\n",
      "Epoch 181/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8219 - val_loss: 8.8847\n",
      "Epoch 182/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7211 - val_loss: 9.0305\n",
      "Epoch 183/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8142 - val_loss: 9.1314\n",
      "Epoch 184/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8582 - val_loss: 9.0728\n",
      "Epoch 185/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.6935 - val_loss: 8.8798\n",
      "Epoch 186/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.0093 - val_loss: 9.1712\n",
      "Epoch 187/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9895 - val_loss: 9.0672\n",
      "Epoch 188/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1502 - val_loss: 8.9826\n",
      "Epoch 189/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.8898 - val_loss: 9.3949\n",
      "Epoch 190/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7507 - val_loss: 9.0549\n",
      "Epoch 191/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.1725 - val_loss: 9.1455\n",
      "Epoch 192/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.7137 - val_loss: 8.6509\n",
      "Epoch 193/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6211 - val_loss: 8.8228\n",
      "Epoch 194/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6987 - val_loss: 8.9829\n",
      "Epoch 195/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6821 - val_loss: 8.8783\n",
      "Epoch 196/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7428 - val_loss: 8.9043\n",
      "Epoch 197/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.7066 - val_loss: 8.7675\n",
      "Epoch 198/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6538 - val_loss: 8.9783\n",
      "Epoch 199/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.6619 - val_loss: 8.8294\n",
      "Epoch 200/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.8065 - val_loss: 8.7015\n",
      "Epoch 201/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.7266 - val_loss: 9.0526\n",
      "Epoch 202/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 6.7766 - val_loss: 8.9071\n",
      "Epoch 203/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5572 - val_loss: 9.0029\n",
      "Epoch 204/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.6291 - val_loss: 8.7670\n",
      "Epoch 205/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7237 - val_loss: 8.8462\n",
      "Epoch 206/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7343 - val_loss: 8.8884\n",
      "Epoch 207/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.6755 - val_loss: 8.8603\n",
      "Epoch 208/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.5393 - val_loss: 8.8678\n",
      "Epoch 209/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.6203 - val_loss: 8.8365\n",
      "Epoch 210/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6085 - val_loss: 8.9495\n",
      "Epoch 211/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7032 - val_loss: 8.8178\n",
      "Epoch 212/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5689 - val_loss: 8.6085\n",
      "Epoch 213/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.6072 - val_loss: 8.6036\n",
      "Epoch 214/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.6874 - val_loss: 8.6942\n",
      "Epoch 215/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.8207 - val_loss: 8.7883\n",
      "Epoch 216/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6488 - val_loss: 8.7191\n",
      "Epoch 217/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5662 - val_loss: 8.7093\n",
      "Epoch 218/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5525 - val_loss: 8.6065\n",
      "Epoch 219/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.5952 - val_loss: 8.8398\n",
      "Epoch 220/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5657 - val_loss: 8.5915\n",
      "Epoch 221/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.5861 - val_loss: 8.8548\n",
      "Epoch 222/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7197 - val_loss: 8.7246\n",
      "Epoch 223/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.6090 - val_loss: 8.9870\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 224/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5470 - val_loss: 8.5305\n",
      "Epoch 225/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.5551 - val_loss: 8.7662\n",
      "Epoch 226/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.5910 - val_loss: 8.5941\n",
      "Epoch 227/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.7838 - val_loss: 8.9780\n",
      "Epoch 228/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.6608 - val_loss: 8.6840\n",
      "Epoch 229/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6862 - val_loss: 8.7233\n",
      "Epoch 230/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6228 - val_loss: 8.5478\n",
      "Epoch 231/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.5313 - val_loss: 8.6643\n",
      "Epoch 232/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5365 - val_loss: 8.5802\n",
      "Epoch 233/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.6123 - val_loss: 8.8348\n",
      "Epoch 234/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5572 - val_loss: 8.5095\n",
      "Epoch 235/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5954 - val_loss: 8.5811\n",
      "Epoch 236/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5844 - val_loss: 8.5845\n",
      "Epoch 237/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5173 - val_loss: 8.7886\n",
      "Epoch 238/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6716 - val_loss: 8.6427\n",
      "Epoch 239/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5555 - val_loss: 8.6593\n",
      "Epoch 240/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5311 - val_loss: 8.5372\n",
      "Epoch 241/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.5132 - val_loss: 8.6865\n",
      "Epoch 242/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5669 - val_loss: 8.5362\n",
      "Epoch 243/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.8462 - val_loss: 8.6473\n",
      "Epoch 244/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.8857 - val_loss: 8.7015\n",
      "Epoch 245/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.6084 - val_loss: 8.5504\n",
      "Epoch 246/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.6627 - val_loss: 8.8206\n",
      "Epoch 247/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4661 - val_loss: 8.6744\n",
      "Epoch 248/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.4849 - val_loss: 8.6594\n",
      "Epoch 249/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5278 - val_loss: 8.6451\n",
      "Epoch 250/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5225 - val_loss: 8.5941\n",
      "Epoch 251/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.6042 - val_loss: 8.8021\n",
      "Epoch 252/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.5306 - val_loss: 8.5143\n",
      "Epoch 253/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.5235 - val_loss: 8.8492\n",
      "Epoch 254/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.5293 - val_loss: 8.3801\n",
      "Epoch 255/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.4949 - val_loss: 8.6289\n",
      "Epoch 256/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.5562 - val_loss: 8.5744\n",
      "Epoch 257/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4932 - val_loss: 8.6796\n",
      "Epoch 258/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6225 - val_loss: 8.4797\n",
      "Epoch 259/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5702 - val_loss: 8.5204\n",
      "Epoch 260/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4387 - val_loss: 8.5058\n",
      "Epoch 261/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4807 - val_loss: 8.5890\n",
      "Epoch 262/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4416 - val_loss: 8.5716\n",
      "Epoch 263/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4649 - val_loss: 8.6932\n",
      "Epoch 264/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5176 - val_loss: 8.5222\n",
      "Epoch 265/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4905 - val_loss: 8.6363\n",
      "Epoch 266/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4286 - val_loss: 8.7418\n",
      "Epoch 267/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4439 - val_loss: 8.3929\n",
      "Epoch 268/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4750 - val_loss: 8.6394\n",
      "Epoch 269/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5126 - val_loss: 8.5165\n",
      "Epoch 270/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4660 - val_loss: 8.5901\n",
      "Epoch 271/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.5739 - val_loss: 8.4942\n",
      "Epoch 272/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1653 - val_loss: 8.6250\n",
      "Epoch 273/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.9411 - val_loss: 8.3823\n",
      "Epoch 274/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.5773 - val_loss: 8.7835\n",
      "Epoch 275/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5971 - val_loss: 8.4778\n",
      "Epoch 276/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6127 - val_loss: 8.5707\n",
      "Epoch 277/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.5120 - val_loss: 8.3493\n",
      "Epoch 278/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5370 - val_loss: 8.9017\n",
      "Epoch 279/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5534 - val_loss: 8.4590\n",
      "Epoch 280/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.4273 - val_loss: 8.8784\n",
      "Epoch 281/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.5876 - val_loss: 8.5574\n",
      "Epoch 282/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.5474 - val_loss: 8.7822\n",
      "Epoch 283/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.9260 - val_loss: 8.5254\n",
      "Epoch 284/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4778 - val_loss: 8.6943\n",
      "Epoch 285/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3637 - val_loss: 8.4547\n",
      "Epoch 286/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4938 - val_loss: 8.8429\n",
      "Epoch 287/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.6434 - val_loss: 8.3422\n",
      "Epoch 288/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.6359 - val_loss: 8.7681\n",
      "Epoch 289/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4877 - val_loss: 8.4072\n",
      "Epoch 290/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.4540 - val_loss: 8.4259\n",
      "Epoch 291/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5306 - val_loss: 8.5986\n",
      "Epoch 292/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4505 - val_loss: 8.4511\n",
      "Epoch 293/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.3800 - val_loss: 8.7919\n",
      "Epoch 294/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.3830 - val_loss: 8.4142\n",
      "Epoch 295/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5851 - val_loss: 8.4383\n",
      "Epoch 296/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3778 - val_loss: 8.6069\n",
      "Epoch 297/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4656 - val_loss: 8.6367\n",
      "Epoch 298/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.4266 - val_loss: 8.4779\n",
      "Epoch 299/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4472 - val_loss: 8.3838\n",
      "Epoch 300/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3095 - val_loss: 8.4240\n",
      "Epoch 301/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3312 - val_loss: 8.4828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 302/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4485 - val_loss: 8.4361\n",
      "Epoch 303/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4118 - val_loss: 8.3030\n",
      "Epoch 304/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3871 - val_loss: 8.4860\n",
      "Epoch 305/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.3407 - val_loss: 8.4982\n",
      "Epoch 306/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.3131 - val_loss: 8.4524\n",
      "Epoch 307/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5969 - val_loss: 8.3018\n",
      "Epoch 308/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.4396 - val_loss: 8.3584\n",
      "Epoch 309/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3647 - val_loss: 8.3152\n",
      "Epoch 310/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.3975 - val_loss: 8.3396\n",
      "Epoch 311/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.4252 - val_loss: 8.3484\n",
      "Epoch 312/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3548 - val_loss: 8.3764\n",
      "Epoch 313/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.4799 - val_loss: 8.1986\n",
      "Epoch 314/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.3972 - val_loss: 8.4781\n",
      "Epoch 315/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2897 - val_loss: 8.3183\n",
      "Epoch 316/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.3648 - val_loss: 8.5311\n",
      "Epoch 317/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.4844 - val_loss: 8.2067\n",
      "Epoch 318/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.5075 - val_loss: 8.4994\n",
      "Epoch 319/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3139 - val_loss: 8.4029\n",
      "Epoch 320/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.2862 - val_loss: 8.4478\n",
      "Epoch 321/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.9096 - val_loss: 8.4383\n",
      "Epoch 322/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.7088 - val_loss: 8.3589\n",
      "Epoch 323/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6072 - val_loss: 8.3263\n",
      "Epoch 324/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2495 - val_loss: 8.0576\n",
      "Epoch 325/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4233 - val_loss: 8.2733\n",
      "Epoch 326/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4596 - val_loss: 8.1899\n",
      "Epoch 327/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.4265 - val_loss: 8.1207\n",
      "Epoch 328/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5856 - val_loss: 8.2439\n",
      "Epoch 329/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.3387 - val_loss: 8.6713\n",
      "Epoch 330/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3238 - val_loss: 8.4709\n",
      "Epoch 331/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.3546 - val_loss: 8.3249\n",
      "Epoch 332/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.3055 - val_loss: 8.0870\n",
      "Epoch 333/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.3264 - val_loss: 8.0355\n",
      "Epoch 334/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.4810 - val_loss: 8.2047\n",
      "Epoch 335/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.4195 - val_loss: 8.3790\n",
      "Epoch 336/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.2612 - val_loss: 8.1800\n",
      "Epoch 337/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2881 - val_loss: 8.0126\n",
      "Epoch 338/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2519 - val_loss: 8.1594\n",
      "Epoch 339/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.2874 - val_loss: 8.5390\n",
      "Epoch 340/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2729 - val_loss: 8.1865\n",
      "Epoch 341/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.2396 - val_loss: 8.1936\n",
      "Epoch 342/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2553 - val_loss: 8.2956\n",
      "Epoch 343/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.4144 - val_loss: 8.1890\n",
      "Epoch 344/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.4002 - val_loss: 8.1184\n",
      "Epoch 345/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2929 - val_loss: 8.3329\n",
      "Epoch 346/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2496 - val_loss: 8.3385\n",
      "Epoch 347/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.2193 - val_loss: 8.2859\n",
      "Epoch 348/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.4269 - val_loss: 8.2905\n",
      "Epoch 349/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5145 - val_loss: 7.9886\n",
      "Epoch 350/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.4458 - val_loss: 8.0489\n",
      "Epoch 351/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2884 - val_loss: 8.2521\n",
      "Epoch 352/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4109 - val_loss: 8.0200\n",
      "Epoch 353/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.3353 - val_loss: 8.3450\n",
      "Epoch 354/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.3463 - val_loss: 7.9336\n",
      "Epoch 355/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2320 - val_loss: 8.3877\n",
      "Epoch 356/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2748 - val_loss: 8.0535\n",
      "Epoch 357/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1886 - val_loss: 8.1693\n",
      "Epoch 358/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.2669 - val_loss: 8.1431\n",
      "Epoch 359/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1744 - val_loss: 8.0350\n",
      "Epoch 360/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2600 - val_loss: 7.9041\n",
      "Epoch 361/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1888 - val_loss: 8.0598\n",
      "Epoch 362/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2912 - val_loss: 7.9647\n",
      "Epoch 363/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.2907 - val_loss: 8.4864\n",
      "Epoch 364/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.2719 - val_loss: 7.9714\n",
      "Epoch 365/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2426 - val_loss: 8.0347\n",
      "Epoch 366/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2402 - val_loss: 8.0196\n",
      "Epoch 367/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.2509 - val_loss: 8.0111\n",
      "Epoch 368/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.3302 - val_loss: 8.0350\n",
      "Epoch 369/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3592 - val_loss: 8.1687\n",
      "Epoch 370/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1422 - val_loss: 8.1094\n",
      "Epoch 371/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.1575 - val_loss: 7.8926\n",
      "Epoch 372/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2179 - val_loss: 7.9622\n",
      "Epoch 373/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.2675 - val_loss: 8.1656\n",
      "Epoch 374/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3693 - val_loss: 7.7724\n",
      "Epoch 375/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2334 - val_loss: 7.9730\n",
      "Epoch 376/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3141 - val_loss: 8.0369\n",
      "Epoch 377/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.3212 - val_loss: 8.1283\n",
      "Epoch 378/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1037 - val_loss: 8.1401\n",
      "Epoch 379/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.2219 - val_loss: 8.2606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 380/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.4720 - val_loss: 8.0919\n",
      "Epoch 381/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5769 - val_loss: 8.1957\n",
      "Epoch 382/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2616 - val_loss: 8.0742\n",
      "Epoch 383/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3310 - val_loss: 8.0363\n",
      "Epoch 384/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3741 - val_loss: 7.7519\n",
      "Epoch 385/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.2582 - val_loss: 7.7595\n",
      "Epoch 386/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2916 - val_loss: 8.0389\n",
      "Epoch 387/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3382 - val_loss: 8.1162\n",
      "Epoch 388/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.1853 - val_loss: 8.0805\n",
      "Epoch 389/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1539 - val_loss: 7.9420\n",
      "Epoch 390/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.2501 - val_loss: 8.1471\n",
      "Epoch 391/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.1204 - val_loss: 7.8186\n",
      "Epoch 392/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.1271 - val_loss: 7.9596\n",
      "Epoch 393/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1153 - val_loss: 8.0829\n",
      "Epoch 394/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1605 - val_loss: 7.8918\n",
      "Epoch 395/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.0858 - val_loss: 7.9532\n",
      "Epoch 396/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1709 - val_loss: 7.9811\n",
      "Epoch 397/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.2661 - val_loss: 7.8496\n",
      "Epoch 398/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3292 - val_loss: 7.9441\n",
      "Epoch 399/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.1679 - val_loss: 7.8982\n",
      "Epoch 400/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1918 - val_loss: 8.0855\n",
      "Epoch 401/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.2053 - val_loss: 7.8554\n",
      "Epoch 402/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2481 - val_loss: 7.7584\n",
      "Epoch 403/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2710 - val_loss: 7.7315\n",
      "Epoch 404/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3673 - val_loss: 8.0418\n",
      "Epoch 405/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.0786 - val_loss: 7.9737\n",
      "Epoch 406/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1146 - val_loss: 7.9280\n",
      "Epoch 407/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.1854 - val_loss: 8.0273\n",
      "Epoch 408/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2205 - val_loss: 7.8579\n",
      "Epoch 409/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1760 - val_loss: 7.7487\n",
      "Epoch 410/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2925 - val_loss: 7.8505\n",
      "Epoch 411/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2133 - val_loss: 8.0163\n",
      "Epoch 412/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0839 - val_loss: 7.7934\n",
      "Epoch 413/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2108 - val_loss: 7.9481\n",
      "Epoch 414/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1679 - val_loss: 7.7006\n",
      "Epoch 415/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.3689 - val_loss: 7.9951\n",
      "Epoch 416/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2452 - val_loss: 7.8212\n",
      "Epoch 417/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.1935 - val_loss: 7.7314\n",
      "Epoch 418/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1276 - val_loss: 7.8305\n",
      "Epoch 419/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.1720 - val_loss: 8.0265\n",
      "Epoch 420/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3603 - val_loss: 8.1507\n",
      "Epoch 421/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.2555 - val_loss: 7.9783\n",
      "Epoch 422/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0949 - val_loss: 7.9099\n",
      "Epoch 423/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0937 - val_loss: 7.8060\n",
      "Epoch 424/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.1043 - val_loss: 7.8712\n",
      "Epoch 425/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.1307 - val_loss: 7.7827\n",
      "Epoch 426/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.2352 - val_loss: 7.7698\n",
      "Epoch 427/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1614 - val_loss: 7.9864\n",
      "Epoch 428/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9040 - val_loss: 8.2992\n",
      "Epoch 429/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.6550 - val_loss: 7.9117\n",
      "Epoch 430/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.4789 - val_loss: 7.9196\n",
      "Epoch 431/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4355 - val_loss: 8.0718\n",
      "Epoch 432/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3296 - val_loss: 8.4511\n",
      "Epoch 433/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2380 - val_loss: 7.8049\n",
      "Epoch 434/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0784 - val_loss: 7.8660\n",
      "Epoch 435/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2563 - val_loss: 7.7508\n",
      "Epoch 436/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1437 - val_loss: 7.9079\n",
      "Epoch 437/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.2275 - val_loss: 7.8589\n",
      "Epoch 438/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.1334 - val_loss: 7.9414\n",
      "Epoch 439/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1792 - val_loss: 7.7649\n",
      "Epoch 440/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1267 - val_loss: 7.9711\n",
      "Epoch 441/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.3690 - val_loss: 7.9581\n",
      "Epoch 442/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.5560 - val_loss: 7.9446\n",
      "Epoch 443/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.3744 - val_loss: 8.1140\n",
      "Epoch 444/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.4487 - val_loss: 7.9963\n",
      "Epoch 445/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.4219 - val_loss: 8.1531\n",
      "Epoch 446/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.2235 - val_loss: 8.0228\n",
      "Epoch 447/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.1387 - val_loss: 8.1184\n",
      "Epoch 448/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.0810 - val_loss: 8.0640\n",
      "Epoch 449/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.1369 - val_loss: 7.7376\n",
      "Epoch 450/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.2083 - val_loss: 8.0998\n",
      "Epoch 451/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.2220 - val_loss: 7.8613\n",
      "Epoch 452/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 3.000 - 0s 113us/step - loss: 6.3995 - val_loss: 8.0602\n",
      "Epoch 453/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.3900 - val_loss: 8.0056\n",
      "Epoch 454/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.1517 - val_loss: 8.0599\n",
      "Epoch 455/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0791 - val_loss: 8.1242\n",
      "Epoch 456/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.1289 - val_loss: 7.8353\n",
      "Epoch 457/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 109us/step - loss: 6.2015 - val_loss: 7.8220\n",
      "Epoch 458/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.2767 - val_loss: 8.1032\n",
      "Epoch 459/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.1413 - val_loss: 8.0989\n",
      "Epoch 460/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1592 - val_loss: 7.9343\n",
      "Epoch 461/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1784 - val_loss: 7.6372\n",
      "Epoch 462/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.0626 - val_loss: 7.9492\n",
      "Epoch 463/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.1794 - val_loss: 7.7431\n",
      "Epoch 464/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.1695 - val_loss: 8.1182\n",
      "Epoch 465/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0980 - val_loss: 8.0240\n",
      "Epoch 466/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.0744 - val_loss: 7.9495\n",
      "Epoch 467/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.0209 - val_loss: 7.6373\n",
      "Epoch 468/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.1097 - val_loss: 8.0666\n",
      "Epoch 469/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0686 - val_loss: 7.8165\n",
      "Epoch 470/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1755 - val_loss: 8.0119\n",
      "Epoch 471/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.0530 - val_loss: 7.7938\n",
      "Epoch 472/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1198 - val_loss: 7.8303\n",
      "Epoch 473/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.0856 - val_loss: 7.9791\n",
      "Epoch 474/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.2824 - val_loss: 7.9329\n",
      "Epoch 475/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3622 - val_loss: 7.6309\n",
      "Epoch 476/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 6.6245 - val_loss: 7.7518\n",
      "Epoch 477/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.6901 - val_loss: 7.8996\n",
      "Epoch 478/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.1748 - val_loss: 7.8057\n",
      "Epoch 479/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.2625 - val_loss: 8.0444\n",
      "Epoch 480/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1682 - val_loss: 7.8315\n",
      "Epoch 481/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1152 - val_loss: 8.1745\n",
      "Epoch 482/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.0462 - val_loss: 7.9520\n",
      "Epoch 483/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2064 - val_loss: 7.8751\n",
      "Epoch 484/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2335 - val_loss: 7.8494\n",
      "Epoch 485/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1195 - val_loss: 7.8704\n",
      "Epoch 486/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.0514 - val_loss: 7.9461\n",
      "Epoch 487/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0082 - val_loss: 7.8896\n",
      "Epoch 488/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.1191 - val_loss: 7.7549\n",
      "Epoch 489/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4433 - val_loss: 8.0625\n",
      "Epoch 490/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.0906 - val_loss: 7.8584\n",
      "Epoch 491/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1509 - val_loss: 7.9784\n",
      "Epoch 492/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0384 - val_loss: 7.7712\n",
      "Epoch 493/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1597 - val_loss: 8.0422\n",
      "Epoch 494/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1213 - val_loss: 7.9631\n",
      "Epoch 495/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.0889 - val_loss: 7.7438\n",
      "Epoch 496/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.0034 - val_loss: 7.6488\n",
      "Epoch 497/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1288 - val_loss: 7.8777\n",
      "Epoch 498/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.2164 - val_loss: 7.8347\n",
      "Epoch 499/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3580 - val_loss: 7.8009\n",
      "Epoch 500/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2015 - val_loss: 7.8013\n",
      "Epoch 501/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1292 - val_loss: 8.2838\n",
      "Epoch 502/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.0396 - val_loss: 7.7519\n",
      "Epoch 503/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1835 - val_loss: 7.8190\n",
      "Epoch 504/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2001 - val_loss: 7.5661\n",
      "Epoch 505/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.9823 - val_loss: 8.0103\n",
      "Epoch 506/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.0439 - val_loss: 7.7241\n",
      "Epoch 507/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1009 - val_loss: 7.8707\n",
      "Epoch 508/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0621 - val_loss: 8.0212\n",
      "Epoch 509/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0949 - val_loss: 7.9544\n",
      "Epoch 510/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0506 - val_loss: 7.6570\n",
      "Epoch 511/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9485 - val_loss: 7.8409\n",
      "Epoch 512/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3481 - val_loss: 7.8572\n",
      "Epoch 513/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.2634 - val_loss: 7.7914\n",
      "Epoch 514/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9915 - val_loss: 7.7523\n",
      "Epoch 515/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0322 - val_loss: 7.9474\n",
      "Epoch 516/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0853 - val_loss: 7.8458\n",
      "Epoch 517/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9874 - val_loss: 7.8141\n",
      "Epoch 518/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.0317 - val_loss: 7.8130\n",
      "Epoch 519/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9817 - val_loss: 7.8323\n",
      "Epoch 520/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1253 - val_loss: 7.8765\n",
      "Epoch 521/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9980 - val_loss: 7.6760\n",
      "Epoch 522/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1609 - val_loss: 7.6275\n",
      "Epoch 523/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.9966 - val_loss: 7.7207\n",
      "Epoch 524/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1112 - val_loss: 7.8164\n",
      "Epoch 525/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.4460 - val_loss: 7.9647\n",
      "Epoch 526/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2969 - val_loss: 7.8127\n",
      "Epoch 527/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3822 - val_loss: 8.0218\n",
      "Epoch 528/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2786 - val_loss: 7.7613\n",
      "Epoch 529/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9306 - val_loss: 7.9250\n",
      "Epoch 530/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.9863 - val_loss: 7.8666\n",
      "Epoch 531/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0636 - val_loss: 7.8833\n",
      "Epoch 532/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9685 - val_loss: 7.9169\n",
      "Epoch 533/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1127 - val_loss: 7.8241\n",
      "Epoch 534/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0093 - val_loss: 7.7989\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 535/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9570 - val_loss: 7.7953\n",
      "Epoch 536/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0377 - val_loss: 7.9474\n",
      "Epoch 537/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0770 - val_loss: 7.8950\n",
      "Epoch 538/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.2285 - val_loss: 8.0775\n",
      "Epoch 539/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1461 - val_loss: 7.7398\n",
      "Epoch 540/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.0473 - val_loss: 7.7516\n",
      "Epoch 541/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.9802 - val_loss: 7.8346\n",
      "Epoch 542/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1130 - val_loss: 7.5438\n",
      "Epoch 543/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9906 - val_loss: 7.6266\n",
      "Epoch 544/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0154 - val_loss: 7.9276\n",
      "Epoch 545/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.0012 - val_loss: 7.7434\n",
      "Epoch 546/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.9923 - val_loss: 8.0217\n",
      "Epoch 547/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0347 - val_loss: 7.6698\n",
      "Epoch 548/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1275 - val_loss: 7.9014\n",
      "Epoch 549/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1958 - val_loss: 7.6108\n",
      "Epoch 550/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4836 - val_loss: 7.9859\n",
      "Epoch 551/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3439 - val_loss: 7.7969\n",
      "Epoch 552/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.4723 - val_loss: 7.8537\n",
      "Epoch 553/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.2009 - val_loss: 7.8425\n",
      "Epoch 554/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.0705 - val_loss: 7.7552\n",
      "Epoch 555/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0814 - val_loss: 7.7205\n",
      "Epoch 556/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.0817 - val_loss: 7.8483\n",
      "Epoch 557/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9871 - val_loss: 7.9833\n",
      "Epoch 558/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1729 - val_loss: 7.7375\n",
      "Epoch 559/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0452 - val_loss: 7.7745\n",
      "Epoch 560/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.8948 - val_loss: 7.6950\n",
      "Epoch 561/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3169 - val_loss: 8.0787\n",
      "Epoch 562/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0957 - val_loss: 7.9857\n",
      "Epoch 563/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9317 - val_loss: 8.0045\n",
      "Epoch 564/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9582 - val_loss: 7.8188\n",
      "Epoch 565/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0229 - val_loss: 7.8722\n",
      "Epoch 566/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.0019 - val_loss: 7.9005\n",
      "Epoch 567/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.0951 - val_loss: 7.8198\n",
      "Epoch 568/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.0286 - val_loss: 7.7285\n",
      "Epoch 569/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0475 - val_loss: 7.7131\n",
      "Epoch 570/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1937 - val_loss: 7.8793\n",
      "Epoch 571/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1118 - val_loss: 7.7497\n",
      "Epoch 572/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0914 - val_loss: 7.7622\n",
      "Epoch 573/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0124 - val_loss: 7.9359\n",
      "Epoch 574/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9576 - val_loss: 7.7462\n",
      "Epoch 575/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9789 - val_loss: 7.9258\n",
      "Epoch 576/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.9516 - val_loss: 7.6278\n",
      "Epoch 577/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8986 - val_loss: 7.8069\n",
      "Epoch 578/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1636 - val_loss: 7.8190\n",
      "Epoch 579/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0913 - val_loss: 7.7219\n",
      "Epoch 580/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1227 - val_loss: 7.9679\n",
      "Epoch 581/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9999 - val_loss: 7.8885\n",
      "Epoch 582/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1025 - val_loss: 7.7624\n",
      "Epoch 583/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0093 - val_loss: 7.6361\n",
      "Epoch 584/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9059 - val_loss: 7.6676\n",
      "Epoch 585/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.9815 - val_loss: 7.7567\n",
      "Epoch 586/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.0537 - val_loss: 7.6643\n",
      "Epoch 587/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.9664 - val_loss: 7.8806\n",
      "Epoch 588/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0218 - val_loss: 7.6987\n",
      "Epoch 589/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.9049 - val_loss: 7.7290\n",
      "Epoch 590/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.0229 - val_loss: 7.6129\n",
      "Epoch 591/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.0213 - val_loss: 7.5620\n",
      "Epoch 592/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.8800 - val_loss: 7.6001\n",
      "Epoch 593/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9490 - val_loss: 7.7054\n",
      "Epoch 594/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1124 - val_loss: 7.7609\n",
      "Epoch 595/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.0483 - val_loss: 7.9829\n",
      "Epoch 596/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8881 - val_loss: 7.7820\n",
      "Epoch 597/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.9314 - val_loss: 7.9997\n",
      "Epoch 598/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.0387 - val_loss: 7.8484\n",
      "Epoch 599/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.2219 - val_loss: 7.4838\n",
      "Epoch 600/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2912 - val_loss: 7.6221\n",
      "Epoch 601/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1654 - val_loss: 7.5398\n",
      "Epoch 602/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0099 - val_loss: 8.1175\n",
      "Epoch 603/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9297 - val_loss: 8.1022\n",
      "Epoch 604/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9517 - val_loss: 7.6835\n",
      "Epoch 605/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.1061 - val_loss: 7.8590\n",
      "Epoch 606/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9349 - val_loss: 7.6027\n",
      "Epoch 607/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0245 - val_loss: 7.8771\n",
      "Epoch 608/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.9067 - val_loss: 7.7146\n",
      "Epoch 609/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9733 - val_loss: 7.9743\n",
      "Epoch 610/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9687 - val_loss: 7.8657\n",
      "Epoch 611/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9793 - val_loss: 8.0156\n",
      "Epoch 612/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8624 - val_loss: 7.8545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 613/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.0172 - val_loss: 7.7543\n",
      "Epoch 614/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.1312 - val_loss: 7.6365\n",
      "Epoch 615/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.0482 - val_loss: 7.8818\n",
      "Epoch 616/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.9883 - val_loss: 7.6805\n",
      "Epoch 617/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.2058 - val_loss: 7.6549\n",
      "Epoch 618/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.2336 - val_loss: 7.8038\n",
      "Epoch 619/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3571 - val_loss: 7.8748\n",
      "Epoch 620/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.9674 - val_loss: 7.9448\n",
      "Epoch 621/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1303 - val_loss: 7.5769\n",
      "Epoch 622/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0226 - val_loss: 7.8302\n",
      "Epoch 623/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8896 - val_loss: 7.7911\n",
      "Epoch 624/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.9511 - val_loss: 7.9697\n",
      "Epoch 625/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.0546 - val_loss: 7.8974\n",
      "Epoch 626/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.9271 - val_loss: 8.0855\n",
      "Epoch 627/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9593 - val_loss: 7.8942\n",
      "Epoch 628/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.1397 - val_loss: 8.0697\n",
      "Epoch 629/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9507 - val_loss: 7.7544\n",
      "Epoch 630/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.0584 - val_loss: 8.0817\n",
      "Epoch 631/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1075 - val_loss: 7.9792\n",
      "Epoch 632/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1723 - val_loss: 7.8273\n",
      "Epoch 633/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.2236 - val_loss: 7.7674\n",
      "Epoch 634/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.9806 - val_loss: 7.7144\n",
      "Epoch 635/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9532 - val_loss: 8.0693\n",
      "Epoch 636/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0512 - val_loss: 7.6934\n",
      "Epoch 637/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9406 - val_loss: 7.8247\n",
      "Epoch 638/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.9833 - val_loss: 7.7957\n",
      "Epoch 639/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.8645 - val_loss: 7.8210\n",
      "Epoch 640/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9971 - val_loss: 7.6942\n",
      "Epoch 641/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.9370 - val_loss: 7.7703\n",
      "Epoch 642/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8830 - val_loss: 7.8029\n",
      "Epoch 643/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.9249 - val_loss: 7.6661\n",
      "Epoch 644/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9052 - val_loss: 7.8686\n",
      "Epoch 645/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9994 - val_loss: 8.0234\n",
      "Epoch 646/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.9864 - val_loss: 7.6824\n",
      "Epoch 647/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 5.8623 - val_loss: 7.7307\n",
      "Epoch 648/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8783 - val_loss: 7.7215\n",
      "Epoch 649/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9961 - val_loss: 7.9899\n",
      "Epoch 650/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.9410 - val_loss: 7.7355\n",
      "Epoch 651/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 5.8445 - val_loss: 7.7982\n",
      "Epoch 652/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9633 - val_loss: 7.6095\n",
      "Epoch 653/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0539 - val_loss: 7.7863\n",
      "Epoch 654/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9238 - val_loss: 7.7941\n",
      "Epoch 655/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9061 - val_loss: 7.9634\n",
      "Epoch 656/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.9943 - val_loss: 7.8657\n",
      "Epoch 657/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1022 - val_loss: 8.0530\n",
      "Epoch 658/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9497 - val_loss: 7.9473\n",
      "Epoch 659/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.9412 - val_loss: 7.6339\n",
      "Epoch 660/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0214 - val_loss: 7.8463\n",
      "Epoch 661/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8600 - val_loss: 7.8240\n",
      "Epoch 662/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9471 - val_loss: 7.7680\n",
      "Epoch 663/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.1953 - val_loss: 8.1143\n",
      "Epoch 664/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.1859 - val_loss: 8.0379\n",
      "Epoch 665/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.1391 - val_loss: 8.1801\n",
      "Epoch 666/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9953 - val_loss: 8.1372\n",
      "Epoch 667/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.0566 - val_loss: 7.9857\n",
      "Epoch 668/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2020 - val_loss: 7.7400\n",
      "Epoch 669/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8875 - val_loss: 7.9036\n",
      "Epoch 670/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9054 - val_loss: 7.9311\n",
      "Epoch 671/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8281 - val_loss: 7.9358\n",
      "Epoch 672/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0221 - val_loss: 7.9876\n",
      "Epoch 673/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.3673 - val_loss: 7.7244\n",
      "Epoch 674/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.9506 - val_loss: 7.8026\n",
      "Epoch 675/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.8827 - val_loss: 8.0915\n",
      "Epoch 676/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0002 - val_loss: 7.9032\n",
      "Epoch 677/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.1463 - val_loss: 7.8256\n",
      "Epoch 678/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9180 - val_loss: 8.1073\n",
      "Epoch 679/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.9128 - val_loss: 7.8654\n",
      "Epoch 680/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9495 - val_loss: 7.9179\n",
      "Epoch 681/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0204 - val_loss: 7.9989\n",
      "Epoch 682/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.8500 - val_loss: 8.1590\n",
      "Epoch 683/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.8782 - val_loss: 7.9512\n",
      "Epoch 684/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9408 - val_loss: 7.8380\n",
      "Epoch 685/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8572 - val_loss: 7.9635\n",
      "Epoch 686/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8582 - val_loss: 7.8955\n",
      "Epoch 687/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.9914 - val_loss: 8.1392\n",
      "Epoch 688/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.8348 - val_loss: 8.1112\n",
      "Epoch 689/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0711 - val_loss: 7.8932\n",
      "Epoch 690/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.9023 - val_loss: 8.2374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 691/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.8684 - val_loss: 7.9091\n",
      "Epoch 692/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.0092 - val_loss: 8.0326\n",
      "Epoch 693/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9331 - val_loss: 7.9985\n",
      "Epoch 694/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8066 - val_loss: 8.2895\n",
      "Epoch 695/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.8991 - val_loss: 7.9303\n",
      "Epoch 696/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8777 - val_loss: 8.1737\n",
      "Epoch 697/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8860 - val_loss: 7.7431\n",
      "Epoch 698/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.0770 - val_loss: 8.0983\n",
      "Epoch 699/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0422 - val_loss: 7.9779\n",
      "Epoch 700/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8969 - val_loss: 8.1594\n",
      "Epoch 701/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.9100 - val_loss: 8.1777\n",
      "Epoch 702/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9428 - val_loss: 7.8915\n",
      "Epoch 703/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9707 - val_loss: 8.1831\n",
      "Epoch 704/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.9044 - val_loss: 7.9026\n",
      "Epoch 705/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1354 - val_loss: 8.3240\n",
      "Epoch 706/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.9973 - val_loss: 7.9478\n",
      "Epoch 707/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9526 - val_loss: 8.2874\n",
      "Epoch 708/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.8827 - val_loss: 8.1186\n",
      "Epoch 709/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.8613 - val_loss: 8.0382\n",
      "Epoch 710/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.7950 - val_loss: 8.0095\n",
      "Epoch 711/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8491 - val_loss: 8.1165\n",
      "Epoch 712/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9362 - val_loss: 7.8638\n",
      "Epoch 713/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.9770 - val_loss: 8.3472\n",
      "Epoch 714/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.0242 - val_loss: 8.0584\n",
      "Epoch 715/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.9167 - val_loss: 8.0408\n",
      "Epoch 716/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.8228 - val_loss: 7.8404\n",
      "Epoch 717/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.9633 - val_loss: 8.3061\n",
      "Epoch 718/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.8779 - val_loss: 8.1471\n",
      "Epoch 719/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.9006 - val_loss: 8.1512\n",
      "Epoch 720/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8860 - val_loss: 8.4195\n",
      "Epoch 721/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.9268 - val_loss: 8.1768\n",
      "Epoch 722/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7673 - val_loss: 8.4289\n",
      "Epoch 723/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.9089 - val_loss: 8.2077\n",
      "Epoch 724/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8194 - val_loss: 8.2943\n",
      "Epoch 725/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8539 - val_loss: 8.1689\n",
      "Epoch 726/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0739 - val_loss: 7.9473\n",
      "Epoch 727/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9412 - val_loss: 8.3817\n",
      "Epoch 728/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8095 - val_loss: 8.1875\n",
      "Epoch 729/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8513 - val_loss: 8.2313\n",
      "Epoch 730/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9275 - val_loss: 8.3674\n",
      "Epoch 731/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1119 - val_loss: 8.0949\n",
      "Epoch 732/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0233 - val_loss: 8.2591\n",
      "Epoch 733/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8456 - val_loss: 8.2954\n",
      "Epoch 734/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.9236 - val_loss: 8.1508\n",
      "Epoch 735/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.8058 - val_loss: 8.2493\n",
      "Epoch 736/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9769 - val_loss: 8.1259\n",
      "Epoch 737/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9261 - val_loss: 8.4064\n",
      "Epoch 738/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.8132 - val_loss: 8.3618\n",
      "Epoch 739/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7636 - val_loss: 8.3936\n",
      "Epoch 740/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8592 - val_loss: 8.2421\n",
      "Epoch 741/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8641 - val_loss: 8.3177\n",
      "Epoch 742/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8217 - val_loss: 8.1549\n",
      "Epoch 743/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8750 - val_loss: 8.3064\n",
      "Epoch 744/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7781 - val_loss: 8.2027\n",
      "Epoch 745/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7533 - val_loss: 8.0466\n",
      "Epoch 746/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8013 - val_loss: 8.1668\n",
      "Epoch 747/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7738 - val_loss: 8.1704\n",
      "Epoch 748/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8510 - val_loss: 8.2410\n",
      "Epoch 749/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.8842 - val_loss: 8.7171\n",
      "Epoch 750/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9900 - val_loss: 8.2716\n",
      "Epoch 751/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9589 - val_loss: 8.3221\n",
      "Epoch 752/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7700 - val_loss: 8.2254\n",
      "Epoch 753/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.7780 - val_loss: 8.4403\n",
      "Epoch 754/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.7974 - val_loss: 8.4135\n",
      "Epoch 755/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.8203 - val_loss: 8.1926\n",
      "Epoch 756/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.1020 - val_loss: 8.3645\n",
      "Epoch 757/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7992 - val_loss: 8.1376\n",
      "Epoch 758/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8507 - val_loss: 8.2515\n",
      "Epoch 759/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8147 - val_loss: 8.3230\n",
      "Epoch 760/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8888 - val_loss: 8.2548\n",
      "Epoch 761/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.0458 - val_loss: 8.4135\n",
      "Epoch 762/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9992 - val_loss: 8.4133\n",
      "Epoch 763/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9890 - val_loss: 8.4641\n",
      "Epoch 764/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0181 - val_loss: 8.4358\n",
      "Epoch 765/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.9774 - val_loss: 8.4609\n",
      "Epoch 766/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6649 - val_loss: 8.4153\n",
      "Epoch 767/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8049 - val_loss: 8.4264\n",
      "Epoch 768/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8384 - val_loss: 8.4659\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 769/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.8033 - val_loss: 8.4192\n",
      "Epoch 770/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.7773 - val_loss: 8.4985\n",
      "Epoch 771/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7444 - val_loss: 8.4372\n",
      "Epoch 772/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.8784 - val_loss: 8.3337\n",
      "Epoch 773/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9133 - val_loss: 8.3535\n",
      "Epoch 774/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.7732 - val_loss: 8.5429\n",
      "Epoch 775/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7371 - val_loss: 8.3392\n",
      "Epoch 776/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7468 - val_loss: 8.4229\n",
      "Epoch 777/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7964 - val_loss: 8.5094\n",
      "Epoch 778/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7488 - val_loss: 8.3954\n",
      "Epoch 779/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8144 - val_loss: 8.2735\n",
      "Epoch 780/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 5.8158 - val_loss: 8.3697\n",
      "Epoch 781/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.6932 - val_loss: 8.2728\n",
      "Epoch 782/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.8994 - val_loss: 8.3744\n",
      "Epoch 783/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.9271 - val_loss: 8.5785\n",
      "Epoch 784/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9642 - val_loss: 8.6501\n",
      "Epoch 785/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7561 - val_loss: 8.2496\n",
      "Epoch 786/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.7441 - val_loss: 8.2473\n",
      "Epoch 787/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.7096 - val_loss: 8.3849\n",
      "Epoch 788/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7405 - val_loss: 8.5659\n",
      "Epoch 789/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8902 - val_loss: 8.5159\n",
      "Epoch 790/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0086 - val_loss: 8.1564\n",
      "Epoch 791/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8273 - val_loss: 8.4895\n",
      "Epoch 792/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.7238 - val_loss: 8.4610\n",
      "Epoch 793/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7371 - val_loss: 8.7505\n",
      "Epoch 794/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7179 - val_loss: 8.3523\n",
      "Epoch 795/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8796 - val_loss: 8.4467\n",
      "Epoch 796/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0315 - val_loss: 8.0714\n",
      "Epoch 797/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8782 - val_loss: 8.4939\n",
      "Epoch 798/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8402 - val_loss: 8.4233\n",
      "Epoch 799/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7014 - val_loss: 8.9768\n",
      "Epoch 800/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7271 - val_loss: 8.5432\n",
      "Epoch 801/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8547 - val_loss: 8.3826\n",
      "Epoch 802/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8827 - val_loss: 8.4471\n",
      "Epoch 803/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8222 - val_loss: 8.5605\n",
      "Epoch 804/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.9062 - val_loss: 8.6408\n",
      "Epoch 805/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.7270 - val_loss: 8.6967\n",
      "Epoch 806/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6114 - val_loss: 8.4019\n",
      "Epoch 807/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8437 - val_loss: 8.7378\n",
      "Epoch 808/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.9101 - val_loss: 8.5302\n",
      "Epoch 809/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6930 - val_loss: 8.7672\n",
      "Epoch 810/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6432 - val_loss: 8.5148\n",
      "Epoch 811/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7181 - val_loss: 8.5760\n",
      "Epoch 812/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6495 - val_loss: 8.6814\n",
      "Epoch 813/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6837 - val_loss: 8.4587\n",
      "Epoch 814/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7188 - val_loss: 8.6602\n",
      "Epoch 815/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6265 - val_loss: 8.4302\n",
      "Epoch 816/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7429 - val_loss: 8.4582\n",
      "Epoch 817/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7253 - val_loss: 8.6370\n",
      "Epoch 818/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6895 - val_loss: 8.4445\n",
      "Epoch 819/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6910 - val_loss: 8.5700\n",
      "Epoch 820/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.7376 - val_loss: 8.5098\n",
      "Epoch 821/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6703 - val_loss: 8.7214\n",
      "Epoch 822/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7212 - val_loss: 8.6002\n",
      "Epoch 823/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6591 - val_loss: 8.6303\n",
      "Epoch 824/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.6875 - val_loss: 8.7838\n",
      "Epoch 825/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6819 - val_loss: 8.3984\n",
      "Epoch 826/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6639 - val_loss: 8.6551\n",
      "Epoch 827/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.6652 - val_loss: 8.6415\n",
      "Epoch 828/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8088 - val_loss: 8.7571\n",
      "Epoch 829/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.6437 - val_loss: 8.7719\n",
      "Epoch 830/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.7702 - val_loss: 8.6844\n",
      "Epoch 831/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.7800 - val_loss: 8.6893\n",
      "Epoch 832/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7077 - val_loss: 9.1965\n",
      "Epoch 833/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.7856 - val_loss: 8.6916\n",
      "Epoch 834/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.7354 - val_loss: 8.6983\n",
      "Epoch 835/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1942 - val_loss: 8.5555\n",
      "Epoch 836/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0900 - val_loss: 8.8803\n",
      "Epoch 837/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7271 - val_loss: 8.8627\n",
      "Epoch 838/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6552 - val_loss: 8.9581\n",
      "Epoch 839/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.6343 - val_loss: 8.6109\n",
      "Epoch 840/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6404 - val_loss: 8.8215\n",
      "Epoch 841/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.6813 - val_loss: 8.6388\n",
      "Epoch 842/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6125 - val_loss: 8.7453\n",
      "Epoch 843/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6755 - val_loss: 8.6422\n",
      "Epoch 844/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6322 - val_loss: 8.7502\n",
      "Epoch 845/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.6491 - val_loss: 8.9608\n",
      "Epoch 846/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6490 - val_loss: 8.7775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 847/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.6736 - val_loss: 8.4619\n",
      "Epoch 848/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7306 - val_loss: 8.5237\n",
      "Epoch 849/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.6517 - val_loss: 9.0393\n",
      "Epoch 850/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6600 - val_loss: 8.6476\n",
      "Epoch 851/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.6283 - val_loss: 8.8474\n",
      "Epoch 852/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.5946 - val_loss: 8.4139\n",
      "Epoch 853/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.6836 - val_loss: 8.7678\n",
      "Epoch 854/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.6179 - val_loss: 8.8623\n",
      "Epoch 855/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7976 - val_loss: 9.0387\n",
      "Epoch 856/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5656 - val_loss: 8.7888\n",
      "Epoch 857/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.6354 - val_loss: 8.6721\n",
      "Epoch 858/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6664 - val_loss: 8.7019\n",
      "Epoch 859/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7654 - val_loss: 8.7530\n",
      "Epoch 860/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6288 - val_loss: 8.7379\n",
      "Epoch 861/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6047 - val_loss: 8.9129\n",
      "Epoch 862/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.7254 - val_loss: 8.7606\n",
      "Epoch 863/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.6814 - val_loss: 8.4772\n",
      "Epoch 864/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.6972 - val_loss: 8.9292\n",
      "Epoch 865/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6897 - val_loss: 8.7668\n",
      "Epoch 866/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8248 - val_loss: 8.8684\n",
      "Epoch 867/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1279 - val_loss: 8.8099\n",
      "Epoch 868/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.0149 - val_loss: 8.7664\n",
      "Epoch 869/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6664 - val_loss: 8.9868\n",
      "Epoch 870/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.5692 - val_loss: 8.8514\n",
      "Epoch 871/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6334 - val_loss: 8.7559\n",
      "Epoch 872/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6825 - val_loss: 8.6388\n",
      "Epoch 873/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.5874 - val_loss: 8.8566\n",
      "Epoch 874/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.5603 - val_loss: 9.1012\n",
      "Epoch 875/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5271 - val_loss: 8.7862\n",
      "Epoch 876/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6635 - val_loss: 8.7312\n",
      "Epoch 877/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6509 - val_loss: 8.6778\n",
      "Epoch 878/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6914 - val_loss: 8.8198\n",
      "Epoch 879/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.5732 - val_loss: 8.9241\n",
      "Epoch 880/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6719 - val_loss: 9.2634\n",
      "Epoch 881/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6640 - val_loss: 8.8716\n",
      "Epoch 882/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7214 - val_loss: 8.6905\n",
      "Epoch 883/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6314 - val_loss: 8.9569\n",
      "Epoch 884/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8377 - val_loss: 9.3859\n",
      "Epoch 885/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.9726 - val_loss: 9.3128\n",
      "Epoch 886/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6418 - val_loss: 8.8221\n",
      "Epoch 887/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6578 - val_loss: 8.8781\n",
      "Epoch 888/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6477 - val_loss: 8.9761\n",
      "Epoch 889/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.6085 - val_loss: 8.9393\n",
      "Epoch 890/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7067 - val_loss: 8.6433\n",
      "Epoch 891/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7461 - val_loss: 9.0278\n",
      "Epoch 892/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6098 - val_loss: 8.6217\n",
      "Epoch 893/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7589 - val_loss: 8.8718\n",
      "Epoch 894/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6245 - val_loss: 8.9611\n",
      "Epoch 895/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6039 - val_loss: 8.9388\n",
      "Epoch 896/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6372 - val_loss: 8.7746\n",
      "Epoch 897/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6790 - val_loss: 8.9190\n",
      "Epoch 898/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7673 - val_loss: 8.8101\n",
      "Epoch 899/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.1497 - val_loss: 8.8888\n",
      "Epoch 900/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8345 - val_loss: 8.8582\n",
      "Epoch 901/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.9889 - val_loss: 9.1064\n",
      "Epoch 902/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5352 - val_loss: 8.9351\n",
      "Epoch 903/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5787 - val_loss: 8.6270\n",
      "Epoch 904/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.5386 - val_loss: 8.8483\n",
      "Epoch 905/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6299 - val_loss: 8.8048\n",
      "Epoch 906/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5690 - val_loss: 9.1660\n",
      "Epoch 907/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7158 - val_loss: 8.9129\n",
      "Epoch 908/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7226 - val_loss: 9.0707\n",
      "Epoch 909/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6610 - val_loss: 8.6412\n",
      "Epoch 910/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7185 - val_loss: 9.0709\n",
      "Epoch 911/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.6415 - val_loss: 9.0392\n",
      "Epoch 912/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.5771 - val_loss: 8.9454\n",
      "Epoch 913/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.7173 - val_loss: 8.8908\n",
      "Epoch 914/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5790 - val_loss: 8.9954\n",
      "Epoch 915/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5551 - val_loss: 8.9800\n",
      "Epoch 916/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5263 - val_loss: 8.9700\n",
      "Epoch 917/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6468 - val_loss: 8.7996\n",
      "Epoch 918/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6268 - val_loss: 9.1429\n",
      "Epoch 919/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.5483 - val_loss: 8.8115\n",
      "Epoch 920/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6311 - val_loss: 9.0394\n",
      "Epoch 921/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.6495 - val_loss: 9.1140\n",
      "Epoch 922/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.6252 - val_loss: 9.1359\n",
      "Epoch 923/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.5019 - val_loss: 9.0878\n",
      "Epoch 924/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.5394 - val_loss: 8.9403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 925/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6056 - val_loss: 8.9691\n",
      "Epoch 926/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5224 - val_loss: 9.2373\n",
      "Epoch 927/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6366 - val_loss: 9.1995\n",
      "Epoch 928/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7723 - val_loss: 9.0028\n",
      "Epoch 929/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8541 - val_loss: 9.5680\n",
      "Epoch 930/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.5758 - val_loss: 9.0502\n",
      "Epoch 931/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5988 - val_loss: 9.1018\n",
      "Epoch 932/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5822 - val_loss: 9.1624\n",
      "Epoch 933/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.5369 - val_loss: 9.2814\n",
      "Epoch 934/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6921 - val_loss: 8.9976\n",
      "Epoch 935/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6578 - val_loss: 9.1769\n",
      "Epoch 936/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5884 - val_loss: 8.9772\n",
      "Epoch 937/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5347 - val_loss: 8.9911\n",
      "Epoch 938/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5417 - val_loss: 9.0096\n",
      "Epoch 939/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5319 - val_loss: 9.1173\n",
      "Epoch 940/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.6004 - val_loss: 9.1444\n",
      "Epoch 941/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.4751 - val_loss: 9.0476\n",
      "Epoch 942/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6392 - val_loss: 9.1871\n",
      "Epoch 943/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.6018 - val_loss: 9.0885\n",
      "Epoch 944/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.5821 - val_loss: 8.9613\n",
      "Epoch 945/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.6220 - val_loss: 9.3078\n",
      "Epoch 946/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6069 - val_loss: 9.0805\n",
      "Epoch 947/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5420 - val_loss: 9.2301\n",
      "Epoch 948/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4982 - val_loss: 9.2630\n",
      "Epoch 949/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5578 - val_loss: 9.1526\n",
      "Epoch 950/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5259 - val_loss: 8.9388\n",
      "Epoch 951/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6107 - val_loss: 8.8025\n",
      "Epoch 952/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.6205 - val_loss: 9.4322\n",
      "Epoch 953/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5607 - val_loss: 9.1575\n",
      "Epoch 954/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5395 - val_loss: 9.1357\n",
      "Epoch 955/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.5350 - val_loss: 9.0856\n",
      "Epoch 956/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5270 - val_loss: 8.9048\n",
      "Epoch 957/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5496 - val_loss: 8.8947\n",
      "Epoch 958/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5176 - val_loss: 9.3546\n",
      "Epoch 959/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6109 - val_loss: 9.4748\n",
      "Epoch 960/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6364 - val_loss: 8.9023\n",
      "Epoch 961/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 5.6022 - val_loss: 9.0096\n",
      "Epoch 962/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.5170 - val_loss: 9.3824\n",
      "Epoch 963/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6543 - val_loss: 9.5390\n",
      "Epoch 964/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4840 - val_loss: 9.0391\n",
      "Epoch 965/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.6001 - val_loss: 9.0216\n",
      "Epoch 966/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.5723 - val_loss: 8.8463\n",
      "Epoch 967/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6584 - val_loss: 9.2753\n",
      "Epoch 968/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4979 - val_loss: 9.3891\n",
      "Epoch 969/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.5860 - val_loss: 8.9136\n",
      "Epoch 970/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7151 - val_loss: 9.1921\n",
      "Epoch 971/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.6695 - val_loss: 9.3370\n",
      "Epoch 972/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8343 - val_loss: 8.7166\n",
      "Epoch 973/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.9474 - val_loss: 8.9711\n",
      "Epoch 974/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.7333 - val_loss: 9.5016\n",
      "Epoch 975/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7863 - val_loss: 8.9852\n",
      "Epoch 976/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.8124 - val_loss: 9.3090\n",
      "Epoch 977/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.9982 - val_loss: 9.3209\n",
      "Epoch 978/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7620 - val_loss: 9.2574\n",
      "Epoch 979/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5593 - val_loss: 9.0198\n",
      "Epoch 980/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4951 - val_loss: 9.0036\n",
      "Epoch 981/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4786 - val_loss: 9.2176\n",
      "Epoch 982/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.7063 - val_loss: 9.3299\n",
      "Epoch 983/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6141 - val_loss: 9.3349\n",
      "Epoch 984/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8262 - val_loss: 9.2128\n",
      "Epoch 985/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8224 - val_loss: 9.2679\n",
      "Epoch 986/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9336 - val_loss: 9.6791\n",
      "Epoch 987/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9460 - val_loss: 9.5341\n",
      "Epoch 988/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.8122 - val_loss: 9.1764\n",
      "Epoch 989/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.6379 - val_loss: 8.7605\n",
      "Epoch 990/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.5459 - val_loss: 9.2774\n",
      "Epoch 991/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5056 - val_loss: 8.9112\n",
      "Epoch 992/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7452 - val_loss: 9.5590\n",
      "Epoch 993/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5916 - val_loss: 9.2564\n",
      "Epoch 994/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9722 - val_loss: 9.1154\n",
      "Epoch 995/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7122 - val_loss: 9.2225\n",
      "Epoch 996/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4356 - val_loss: 9.1366\n",
      "Epoch 997/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.5913 - val_loss: 9.3809\n",
      "Epoch 998/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.6556 - val_loss: 9.2581\n",
      "Epoch 999/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4877 - val_loss: 9.4288\n",
      "Epoch 1000/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5735 - val_loss: 9.0290\n",
      "6.360255200984114\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.10562204,  2.8462915 ,  0.06768758, -0.48668215, -0.38481486],\n",
       "        [-0.21877885,  2.0239153 , -0.18069106, -1.9512062 ,  0.14269303],\n",
       "        [ 0.03960619, -2.2883415 , -0.0959382 , -0.16708072, -1.1829926 ],\n",
       "        [-0.3483899 ,  0.32392612,  0.3502195 ,  1.9845966 , -0.7364791 ],\n",
       "        [ 0.11636996, -0.40747002, -0.5260901 , -1.0818738 , -0.18904634],\n",
       "        [ 0.02194943,  2.488261  ,  0.4300397 , -1.1068547 , -0.08296724],\n",
       "        [-0.6891439 , -0.66830826,  1.1318254 , -1.257284  ,  0.70168424]],\n",
       "       dtype=float32),\n",
       " array([-0.17728676,  2.583921  ,  1.4803219 ,  1.9890238 , -0.82225513],\n",
       "       dtype=float32),\n",
       " array([[ 0.4354432 ,  0.9998085 , -0.9778736 ,  0.8812299 , -0.83315015],\n",
       "        [ 0.02905946, -0.4391056 , -0.8196396 , -0.25135794, -0.6697966 ],\n",
       "        [ 1.0777968 ,  0.6602865 , -0.3570659 , -0.19244252, -1.3653127 ],\n",
       "        [-0.31723157, -0.92571056,  0.65161484, -0.1550049 ,  0.44247785],\n",
       "        [-0.14506157,  0.80129147, -0.47198144,  0.5749189 , -1.1257446 ]],\n",
       "       dtype=float32),\n",
       " array([ 2.3796902,  2.3203413, -2.2859623,  2.5246878, -2.3513353],\n",
       "       dtype=float32),\n",
       " array([[ 1.3612984],\n",
       "        [ 2.2411206],\n",
       "        [-2.1169558],\n",
       "        [ 1.4557691],\n",
       "        [-1.7762839]], dtype=float32),\n",
       " array([2.1617737], dtype=float32)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_autompg, history_autompg, evaluate_autompg=NN_model_structure_regression_1(X_train_autompg, X_val_autompg, Y_train_autompg, Y_val_autompg, adam2, 32, 1000, x_test_autompg, y_test_autompg)\n",
    "model_autompg.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_autompg.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_autompg_structure1_4th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_22 (Dense)             (None, 5)                 40        \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 111\n",
      "Trainable params: 111\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 274 samples, validate on 59 samples\n",
      "Epoch 1/1000\n",
      "274/274 [==============================] - 0s 972us/step - loss: 537.7889 - val_loss: 335.8427\n",
      "Epoch 2/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 198.2361 - val_loss: 74.2234\n",
      "Epoch 3/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 50.1232 - val_loss: 47.1121\n",
      "Epoch 4/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 32.5760 - val_loss: 28.0496\n",
      "Epoch 5/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 28.3966 - val_loss: 21.8646\n",
      "Epoch 6/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 20.1057 - val_loss: 21.5608\n",
      "Epoch 7/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 19.4453 - val_loss: 20.8665\n",
      "Epoch 8/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 18.0588 - val_loss: 20.1450\n",
      "Epoch 9/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 17.4473 - val_loss: 19.0330\n",
      "Epoch 10/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 16.4563 - val_loss: 18.5172\n",
      "Epoch 11/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 15.0692 - val_loss: 18.6730\n",
      "Epoch 12/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 14.3197 - val_loss: 18.7829\n",
      "Epoch 13/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 13.6184 - val_loss: 18.5938\n",
      "Epoch 14/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 13.3231 - val_loss: 18.3679\n",
      "Epoch 15/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 12.7733 - val_loss: 17.8808\n",
      "Epoch 16/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 12.2213 - val_loss: 17.2890\n",
      "Epoch 17/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 12.0484 - val_loss: 17.1656\n",
      "Epoch 18/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 11.5192 - val_loss: 15.8795\n",
      "Epoch 19/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 11.0100 - val_loss: 16.3435\n",
      "Epoch 20/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 10.6048 - val_loss: 15.5228\n",
      "Epoch 21/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 10.1869 - val_loss: 15.1192\n",
      "Epoch 22/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 9.8100 - val_loss: 14.4247\n",
      "Epoch 23/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 9.3800 - val_loss: 14.2478\n",
      "Epoch 24/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 9.1965 - val_loss: 13.2911\n",
      "Epoch 25/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 9.1093 - val_loss: 12.9892\n",
      "Epoch 26/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 8.9630 - val_loss: 12.9616\n",
      "Epoch 27/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.7137 - val_loss: 13.0377\n",
      "Epoch 28/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.5605 - val_loss: 12.8293\n",
      "Epoch 29/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 8.4257 - val_loss: 12.5474\n",
      "Epoch 30/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.3463 - val_loss: 12.3893\n",
      "Epoch 31/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 8.3591 - val_loss: 12.3143\n",
      "Epoch 32/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.2078 - val_loss: 12.4638\n",
      "Epoch 33/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.2304 - val_loss: 12.3437\n",
      "Epoch 34/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.0254 - val_loss: 12.2558\n",
      "Epoch 35/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.0023 - val_loss: 12.3927\n",
      "Epoch 36/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.0399 - val_loss: 12.2331\n",
      "Epoch 37/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.9052 - val_loss: 12.4262\n",
      "Epoch 38/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.7542 - val_loss: 12.0546\n",
      "Epoch 39/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.6904 - val_loss: 12.3592\n",
      "Epoch 40/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.9271 - val_loss: 11.8264\n",
      "Epoch 41/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.6892 - val_loss: 12.5570\n",
      "Epoch 42/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.7556 - val_loss: 11.7694\n",
      "Epoch 43/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.4580 - val_loss: 11.9263\n",
      "Epoch 44/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 7.5149 - val_loss: 11.9092\n",
      "Epoch 45/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.5087 - val_loss: 11.3856\n",
      "Epoch 46/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3713 - val_loss: 11.8324\n",
      "Epoch 47/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.4134 - val_loss: 11.6010\n",
      "Epoch 48/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.2464 - val_loss: 11.5407\n",
      "Epoch 49/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.2726 - val_loss: 11.4470\n",
      "Epoch 50/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2414 - val_loss: 11.2026\n",
      "Epoch 51/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 7.3713 - val_loss: 11.2223\n",
      "Epoch 52/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.5742 - val_loss: 12.0583\n",
      "Epoch 53/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1865 - val_loss: 11.7406\n",
      "Epoch 54/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.5200 - val_loss: 11.9547\n",
      "Epoch 55/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.2477 - val_loss: 11.1600\n",
      "Epoch 56/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.9856 - val_loss: 10.9464\n",
      "Epoch 57/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 7.3900 - val_loss: 11.7318\n",
      "Epoch 58/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.5606 - val_loss: 11.4860\n",
      "Epoch 59/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 7.1444 - val_loss: 11.1445\n",
      "Epoch 60/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 7.2832 - val_loss: 11.1340\n",
      "Epoch 61/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.1250 - val_loss: 11.5166\n",
      "Epoch 62/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1043 - val_loss: 11.8927\n",
      "Epoch 63/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 8.0990 - val_loss: 11.6232\n",
      "Epoch 64/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1681 - val_loss: 10.9677\n",
      "Epoch 65/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0549 - val_loss: 10.6035\n",
      "Epoch 66/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 7.2423 - val_loss: 11.1226\n",
      "Epoch 67/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.9768 - val_loss: 11.1975\n",
      "Epoch 68/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 91us/step - loss: 7.1868 - val_loss: 11.1097\n",
      "Epoch 69/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1026 - val_loss: 11.4111\n",
      "Epoch 70/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.2778 - val_loss: 11.4580\n",
      "Epoch 71/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 7.2002 - val_loss: 11.2563\n",
      "Epoch 72/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9542 - val_loss: 10.6771\n",
      "Epoch 73/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.8473 - val_loss: 10.8607\n",
      "Epoch 74/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.8754 - val_loss: 11.1219\n",
      "Epoch 75/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 7.0337 - val_loss: 10.8417\n",
      "Epoch 76/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 7.1379 - val_loss: 10.9070\n",
      "Epoch 77/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0650 - val_loss: 10.8639\n",
      "Epoch 78/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.9090 - val_loss: 11.3752\n",
      "Epoch 79/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.8454 - val_loss: 10.9989\n",
      "Epoch 80/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8032 - val_loss: 10.8960\n",
      "Epoch 81/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.9042 - val_loss: 11.1845\n",
      "Epoch 82/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.8376 - val_loss: 11.1463\n",
      "Epoch 83/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1898 - val_loss: 11.8992\n",
      "Epoch 84/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.2492 - val_loss: 10.7491\n",
      "Epoch 85/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.8315 - val_loss: 10.7958\n",
      "Epoch 86/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.8054 - val_loss: 10.8450\n",
      "Epoch 87/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9748 - val_loss: 11.2741\n",
      "Epoch 88/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7664 - val_loss: 10.7922\n",
      "Epoch 89/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.7366 - val_loss: 10.6547\n",
      "Epoch 90/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.7985 - val_loss: 10.7247\n",
      "Epoch 91/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.6615 - val_loss: 11.0857\n",
      "Epoch 92/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7024 - val_loss: 11.0308\n",
      "Epoch 93/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6195 - val_loss: 10.6899\n",
      "Epoch 94/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.6598 - val_loss: 10.5576\n",
      "Epoch 95/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6092 - val_loss: 10.7278\n",
      "Epoch 96/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6864 - val_loss: 10.8399\n",
      "Epoch 97/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.7890 - val_loss: 10.8050\n",
      "Epoch 98/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9134 - val_loss: 10.8403\n",
      "Epoch 99/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0179 - val_loss: 11.0539\n",
      "Epoch 100/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.4276 - val_loss: 11.6228\n",
      "Epoch 101/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 7.0603 - val_loss: 10.9005\n",
      "Epoch 102/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 7.1027 - val_loss: 11.2850\n",
      "Epoch 103/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.8631 - val_loss: 10.8920\n",
      "Epoch 104/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.6177 - val_loss: 10.9083\n",
      "Epoch 105/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0163 - val_loss: 10.6597\n",
      "Epoch 106/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6765 - val_loss: 11.2098\n",
      "Epoch 107/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8304 - val_loss: 11.2386\n",
      "Epoch 108/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.2714 - val_loss: 11.7859\n",
      "Epoch 109/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.0887 - val_loss: 11.0828\n",
      "Epoch 110/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.2283 - val_loss: 10.5421\n",
      "Epoch 111/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9421 - val_loss: 10.5906\n",
      "Epoch 112/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.7241 - val_loss: 11.0222\n",
      "Epoch 113/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6216 - val_loss: 10.4853\n",
      "Epoch 114/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6211 - val_loss: 10.2615\n",
      "Epoch 115/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.5812 - val_loss: 10.4970\n",
      "Epoch 116/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5823 - val_loss: 10.4259\n",
      "Epoch 117/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.4584 - val_loss: 10.5609\n",
      "Epoch 118/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.6189 - val_loss: 10.6235\n",
      "Epoch 119/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9031 - val_loss: 10.6681\n",
      "Epoch 120/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9867 - val_loss: 10.4341\n",
      "Epoch 121/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.5250 - val_loss: 10.3764\n",
      "Epoch 122/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.4242 - val_loss: 10.3695\n",
      "Epoch 123/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4177 - val_loss: 10.1841\n",
      "Epoch 124/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.3936 - val_loss: 10.3182\n",
      "Epoch 125/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.4515 - val_loss: 10.3362\n",
      "Epoch 126/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.5038 - val_loss: 10.2325\n",
      "Epoch 127/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.4729 - val_loss: 10.1696\n",
      "Epoch 128/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5752 - val_loss: 10.1517\n",
      "Epoch 129/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.6429 - val_loss: 10.2075\n",
      "Epoch 130/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4908 - val_loss: 10.0938\n",
      "Epoch 131/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.4702 - val_loss: 9.9376\n",
      "Epoch 132/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.3946 - val_loss: 10.0675\n",
      "Epoch 133/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.4731 - val_loss: 10.2644\n",
      "Epoch 134/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6180 - val_loss: 10.2530\n",
      "Epoch 135/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.6545 - val_loss: 10.0429\n",
      "Epoch 136/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.5578 - val_loss: 10.0598\n",
      "Epoch 137/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.3992 - val_loss: 10.0868\n",
      "Epoch 138/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4035 - val_loss: 10.1128\n",
      "Epoch 139/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 7.0030 - val_loss: 10.4015\n",
      "Epoch 140/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.4656 - val_loss: 10.0440\n",
      "Epoch 141/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5306 - val_loss: 10.0397\n",
      "Epoch 142/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4087 - val_loss: 10.1428\n",
      "Epoch 143/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5469 - val_loss: 10.1833\n",
      "Epoch 144/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6777 - val_loss: 10.0463\n",
      "Epoch 145/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 95us/step - loss: 6.5858 - val_loss: 10.0775\n",
      "Epoch 146/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3887 - val_loss: 9.9220\n",
      "Epoch 147/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4115 - val_loss: 9.8632\n",
      "Epoch 148/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3935 - val_loss: 10.3176\n",
      "Epoch 149/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3435 - val_loss: 10.1075\n",
      "Epoch 150/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.5235 - val_loss: 9.9206\n",
      "Epoch 151/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.3529 - val_loss: 9.9616\n",
      "Epoch 152/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3363 - val_loss: 10.0511\n",
      "Epoch 153/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5382 - val_loss: 10.3379\n",
      "Epoch 154/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5662 - val_loss: 9.9180\n",
      "Epoch 155/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.4347 - val_loss: 10.4440\n",
      "Epoch 156/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6024 - val_loss: 9.9422\n",
      "Epoch 157/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.8067 - val_loss: 10.1969\n",
      "Epoch 158/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.4879 - val_loss: 10.0335\n",
      "Epoch 159/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4154 - val_loss: 9.8639\n",
      "Epoch 160/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.4145 - val_loss: 9.8340\n",
      "Epoch 161/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3572 - val_loss: 10.0546\n",
      "Epoch 162/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.3863 - val_loss: 9.8897\n",
      "Epoch 163/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.3095 - val_loss: 10.0217\n",
      "Epoch 164/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.2842 - val_loss: 10.0050\n",
      "Epoch 165/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.2247 - val_loss: 9.9731\n",
      "Epoch 166/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2970 - val_loss: 9.9110\n",
      "Epoch 167/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4415 - val_loss: 10.0661\n",
      "Epoch 168/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.5386 - val_loss: 10.0730\n",
      "Epoch 169/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.3920 - val_loss: 10.0969\n",
      "Epoch 170/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3917 - val_loss: 10.0119\n",
      "Epoch 171/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3308 - val_loss: 9.8771\n",
      "Epoch 172/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2402 - val_loss: 9.7861\n",
      "Epoch 173/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2093 - val_loss: 9.9911\n",
      "Epoch 174/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4462 - val_loss: 9.9710\n",
      "Epoch 175/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5138 - val_loss: 9.7718\n",
      "Epoch 176/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.3809 - val_loss: 9.8301\n",
      "Epoch 177/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4956 - val_loss: 9.7662\n",
      "Epoch 178/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.2936 - val_loss: 10.0841\n",
      "Epoch 179/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5020 - val_loss: 9.9998\n",
      "Epoch 180/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6473 - val_loss: 10.0094\n",
      "Epoch 181/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.7439 - val_loss: 9.9618\n",
      "Epoch 182/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3252 - val_loss: 10.0355\n",
      "Epoch 183/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.2597 - val_loss: 9.8506\n",
      "Epoch 184/1000\n",
      "274/274 [==============================] - 0s 115us/step - loss: 6.4614 - val_loss: 9.8612\n",
      "Epoch 185/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.3173 - val_loss: 9.9729\n",
      "Epoch 186/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2621 - val_loss: 9.8686\n",
      "Epoch 187/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2687 - val_loss: 9.9813\n",
      "Epoch 188/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2224 - val_loss: 9.9271\n",
      "Epoch 189/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.3300 - val_loss: 9.9127\n",
      "Epoch 190/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.2916 - val_loss: 9.8142\n",
      "Epoch 191/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 6.2262 - val_loss: 9.9585\n",
      "Epoch 192/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2374 - val_loss: 10.0716\n",
      "Epoch 193/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.2960 - val_loss: 9.9434\n",
      "Epoch 194/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3441 - val_loss: 9.8543\n",
      "Epoch 195/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2965 - val_loss: 9.5829\n",
      "Epoch 196/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3370 - val_loss: 9.7346\n",
      "Epoch 197/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3805 - val_loss: 9.7673\n",
      "Epoch 198/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.2763 - val_loss: 9.9863\n",
      "Epoch 199/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3204 - val_loss: 9.7580\n",
      "Epoch 200/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7056 - val_loss: 10.0753\n",
      "Epoch 201/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.2325 - val_loss: 9.7670\n",
      "Epoch 202/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.2519 - val_loss: 9.8817\n",
      "Epoch 203/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3507 - val_loss: 9.6489\n",
      "Epoch 204/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2968 - val_loss: 9.9583\n",
      "Epoch 205/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.4576 - val_loss: 9.8636\n",
      "Epoch 206/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1403 - val_loss: 9.8484\n",
      "Epoch 207/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2784 - val_loss: 9.6744\n",
      "Epoch 208/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.4601 - val_loss: 10.0369\n",
      "Epoch 209/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2031 - val_loss: 9.8983\n",
      "Epoch 210/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3671 - val_loss: 9.8262\n",
      "Epoch 211/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3591 - val_loss: 9.8864\n",
      "Epoch 212/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.5292 - val_loss: 9.8026\n",
      "Epoch 213/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.6373 - val_loss: 10.0004\n",
      "Epoch 214/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7494 - val_loss: 9.8805\n",
      "Epoch 215/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.2722 - val_loss: 9.6389\n",
      "Epoch 216/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.4055 - val_loss: 9.8983\n",
      "Epoch 217/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.1827 - val_loss: 9.8104\n",
      "Epoch 218/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.1719 - val_loss: 9.7962\n",
      "Epoch 219/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2981 - val_loss: 9.9428\n",
      "Epoch 220/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3076 - val_loss: 9.7270\n",
      "Epoch 221/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2519 - val_loss: 9.5756\n",
      "Epoch 222/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.1803 - val_loss: 9.6596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 223/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2175 - val_loss: 9.8832\n",
      "Epoch 224/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3357 - val_loss: 9.8756\n",
      "Epoch 225/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.3047 - val_loss: 9.8609\n",
      "Epoch 226/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2641 - val_loss: 9.8304\n",
      "Epoch 227/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2375 - val_loss: 9.6648\n",
      "Epoch 228/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2522 - val_loss: 9.6102\n",
      "Epoch 229/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.1921 - val_loss: 9.6997\n",
      "Epoch 230/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.2057 - val_loss: 10.0311\n",
      "Epoch 231/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3452 - val_loss: 9.7252\n",
      "Epoch 232/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.1778 - val_loss: 9.8042\n",
      "Epoch 233/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.3208 - val_loss: 9.7968\n",
      "Epoch 234/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2925 - val_loss: 9.6667\n",
      "Epoch 235/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1085 - val_loss: 10.2535\n",
      "Epoch 236/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2409 - val_loss: 9.8508\n",
      "Epoch 237/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2363 - val_loss: 9.7967\n",
      "Epoch 238/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.2752 - val_loss: 9.8086\n",
      "Epoch 239/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.3253 - val_loss: 9.9088\n",
      "Epoch 240/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.1997 - val_loss: 9.6872\n",
      "Epoch 241/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.2171 - val_loss: 9.6939\n",
      "Epoch 242/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3062 - val_loss: 9.8493\n",
      "Epoch 243/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2906 - val_loss: 9.9763\n",
      "Epoch 244/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1839 - val_loss: 9.9239\n",
      "Epoch 245/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2499 - val_loss: 9.7024\n",
      "Epoch 246/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1998 - val_loss: 9.7477\n",
      "Epoch 247/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3446 - val_loss: 9.7418\n",
      "Epoch 248/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.3711 - val_loss: 9.9542\n",
      "Epoch 249/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.2656 - val_loss: 9.8274\n",
      "Epoch 250/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.7358 - val_loss: 10.0597\n",
      "Epoch 251/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4382 - val_loss: 9.8099\n",
      "Epoch 252/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1505 - val_loss: 9.8097\n",
      "Epoch 253/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2670 - val_loss: 9.7277\n",
      "Epoch 254/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1215 - val_loss: 9.7349\n",
      "Epoch 255/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.3455 - val_loss: 9.8130\n",
      "Epoch 256/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.2859 - val_loss: 9.7269\n",
      "Epoch 257/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.3109 - val_loss: 9.8006\n",
      "Epoch 258/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3780 - val_loss: 9.8729\n",
      "Epoch 259/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1963 - val_loss: 9.8057\n",
      "Epoch 260/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1206 - val_loss: 9.8210\n",
      "Epoch 261/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1563 - val_loss: 9.8942\n",
      "Epoch 262/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2167 - val_loss: 9.8593\n",
      "Epoch 263/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1528 - val_loss: 9.7567\n",
      "Epoch 264/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1670 - val_loss: 9.7076\n",
      "Epoch 265/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.1520 - val_loss: 9.7602\n",
      "Epoch 266/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.1050 - val_loss: 9.9216\n",
      "Epoch 267/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.1046 - val_loss: 9.7214\n",
      "Epoch 268/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1910 - val_loss: 9.6740\n",
      "Epoch 269/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 6.0852 - val_loss: 9.8584\n",
      "Epoch 270/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.1070 - val_loss: 9.7777\n",
      "Epoch 271/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2190 - val_loss: 9.8064\n",
      "Epoch 272/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1079 - val_loss: 9.7524\n",
      "Epoch 273/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3007 - val_loss: 9.7516\n",
      "Epoch 274/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3206 - val_loss: 9.7625\n",
      "Epoch 275/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0420 - val_loss: 9.7113\n",
      "Epoch 276/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3539 - val_loss: 9.7266\n",
      "Epoch 277/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3334 - val_loss: 9.6477\n",
      "Epoch 278/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2640 - val_loss: 9.7454\n",
      "Epoch 279/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0333 - val_loss: 9.9304\n",
      "Epoch 280/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.3088 - val_loss: 9.8413\n",
      "Epoch 281/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.0774 - val_loss: 9.6023\n",
      "Epoch 282/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.1696 - val_loss: 9.6624\n",
      "Epoch 283/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4245 - val_loss: 9.7372\n",
      "Epoch 284/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4223 - val_loss: 9.7727\n",
      "Epoch 285/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.4660 - val_loss: 9.5372\n",
      "Epoch 286/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3075 - val_loss: 9.7354\n",
      "Epoch 287/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1137 - val_loss: 9.8748\n",
      "Epoch 288/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2943 - val_loss: 9.8123\n",
      "Epoch 289/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.1519 - val_loss: 9.8665\n",
      "Epoch 290/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.1297 - val_loss: 9.6269\n",
      "Epoch 291/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 9.092 - 0s 102us/step - loss: 6.1478 - val_loss: 9.8559\n",
      "Epoch 292/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.0639 - val_loss: 9.6655\n",
      "Epoch 293/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.0976 - val_loss: 9.6685\n",
      "Epoch 294/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2081 - val_loss: 9.7938\n",
      "Epoch 295/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1638 - val_loss: 9.6300\n",
      "Epoch 296/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3486 - val_loss: 9.6859\n",
      "Epoch 297/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2731 - val_loss: 9.9172\n",
      "Epoch 298/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.1222 - val_loss: 9.7636\n",
      "Epoch 299/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.0997 - val_loss: 10.0190\n",
      "Epoch 300/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 98us/step - loss: 6.0588 - val_loss: 9.6562\n",
      "Epoch 301/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.1615 - val_loss: 9.7839\n",
      "Epoch 302/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.1308 - val_loss: 9.5383\n",
      "Epoch 303/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3741 - val_loss: 9.9843\n",
      "Epoch 304/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3879 - val_loss: 9.6381\n",
      "Epoch 305/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 6.1511 - val_loss: 9.5809\n",
      "Epoch 306/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.1346 - val_loss: 9.9919\n",
      "Epoch 307/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.4022 - val_loss: 9.7311\n",
      "Epoch 308/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2065 - val_loss: 9.7994\n",
      "Epoch 309/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1729 - val_loss: 9.7032\n",
      "Epoch 310/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1111 - val_loss: 9.7572\n",
      "Epoch 311/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.0663 - val_loss: 9.8266\n",
      "Epoch 312/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0570 - val_loss: 9.8972\n",
      "Epoch 313/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1793 - val_loss: 9.6616\n",
      "Epoch 314/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.3091 - val_loss: 9.6615\n",
      "Epoch 315/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.1814 - val_loss: 9.8551\n",
      "Epoch 316/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0996 - val_loss: 9.8894\n",
      "Epoch 317/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.1052 - val_loss: 9.9319\n",
      "Epoch 318/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.2515 - val_loss: 9.6194\n",
      "Epoch 319/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2604 - val_loss: 9.8193\n",
      "Epoch 320/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.2872 - val_loss: 9.9204\n",
      "Epoch 321/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2699 - val_loss: 9.7338\n",
      "Epoch 322/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5866 - val_loss: 9.6911\n",
      "Epoch 323/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.4218 - val_loss: 9.7772\n",
      "Epoch 324/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7524 - val_loss: 9.8870\n",
      "Epoch 325/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.1760 - val_loss: 9.9525\n",
      "Epoch 326/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.0402 - val_loss: 9.6925\n",
      "Epoch 327/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.9918 - val_loss: 9.6434\n",
      "Epoch 328/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.0983 - val_loss: 9.7946\n",
      "Epoch 329/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0255 - val_loss: 9.8214\n",
      "Epoch 330/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1319 - val_loss: 9.7108\n",
      "Epoch 331/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.2384 - val_loss: 9.9152\n",
      "Epoch 332/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.1648 - val_loss: 9.9918\n",
      "Epoch 333/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0085 - val_loss: 9.8160\n",
      "Epoch 334/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0787 - val_loss: 9.7324\n",
      "Epoch 335/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.1320 - val_loss: 9.8707\n",
      "Epoch 336/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9547 - val_loss: 10.1489\n",
      "Epoch 337/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.0923 - val_loss: 9.9039\n",
      "Epoch 338/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2128 - val_loss: 9.7543\n",
      "Epoch 339/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.9970 - val_loss: 9.7253\n",
      "Epoch 340/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0210 - val_loss: 9.5738\n",
      "Epoch 341/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.0436 - val_loss: 9.7012\n",
      "Epoch 342/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.9397 - val_loss: 9.9019\n",
      "Epoch 343/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0868 - val_loss: 9.8899\n",
      "Epoch 344/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.2707 - val_loss: 9.8036\n",
      "Epoch 345/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2402 - val_loss: 9.7563\n",
      "Epoch 346/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.9921 - val_loss: 9.9390\n",
      "Epoch 347/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0616 - val_loss: 9.7657\n",
      "Epoch 348/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.9768 - val_loss: 9.6462\n",
      "Epoch 349/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.9898 - val_loss: 9.9686\n",
      "Epoch 350/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.0077 - val_loss: 9.9053\n",
      "Epoch 351/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1335 - val_loss: 9.8668\n",
      "Epoch 352/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2203 - val_loss: 9.7883\n",
      "Epoch 353/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.4305 - val_loss: 10.0864\n",
      "Epoch 354/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0697 - val_loss: 9.7981\n",
      "Epoch 355/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9739 - val_loss: 9.6822\n",
      "Epoch 356/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1540 - val_loss: 9.5541\n",
      "Epoch 357/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0934 - val_loss: 9.6803\n",
      "Epoch 358/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0765 - val_loss: 9.7986\n",
      "Epoch 359/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9023 - val_loss: 9.7431\n",
      "Epoch 360/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9394 - val_loss: 9.9758\n",
      "Epoch 361/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1597 - val_loss: 9.8357\n",
      "Epoch 362/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0923 - val_loss: 9.8403\n",
      "Epoch 363/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.2773 - val_loss: 9.7813\n",
      "Epoch 364/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9081 - val_loss: 9.7752\n",
      "Epoch 365/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.9573 - val_loss: 9.7849\n",
      "Epoch 366/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0148 - val_loss: 9.6055\n",
      "Epoch 367/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.9647 - val_loss: 9.7258\n",
      "Epoch 368/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8947 - val_loss: 9.9221\n",
      "Epoch 369/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1198 - val_loss: 9.9259\n",
      "Epoch 370/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0115 - val_loss: 9.8425\n",
      "Epoch 371/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.9218 - val_loss: 9.8239\n",
      "Epoch 372/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.9394 - val_loss: 9.7710\n",
      "Epoch 373/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.9495 - val_loss: 9.7693\n",
      "Epoch 374/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9033 - val_loss: 9.8335\n",
      "Epoch 375/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.9332 - val_loss: 9.9162\n",
      "Epoch 376/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9312 - val_loss: 10.0274\n",
      "Epoch 377/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.9183 - val_loss: 9.9693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 378/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.0276 - val_loss: 9.9020\n",
      "Epoch 379/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.1091 - val_loss: 9.7055\n",
      "Epoch 380/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1245 - val_loss: 9.6017\n",
      "Epoch 381/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0685 - val_loss: 9.8798\n",
      "Epoch 382/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.9370 - val_loss: 9.9425\n",
      "Epoch 383/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8868 - val_loss: 9.9649\n",
      "Epoch 384/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9972 - val_loss: 10.0142\n",
      "Epoch 385/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9655 - val_loss: 9.8662\n",
      "Epoch 386/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9737 - val_loss: 9.9510\n",
      "Epoch 387/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.0086 - val_loss: 9.7195\n",
      "Epoch 388/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.9586 - val_loss: 10.0318\n",
      "Epoch 389/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.9091 - val_loss: 9.7382\n",
      "Epoch 390/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0058 - val_loss: 9.8415\n",
      "Epoch 391/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2168 - val_loss: 9.7079\n",
      "Epoch 392/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1041 - val_loss: 9.8942\n",
      "Epoch 393/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.0170 - val_loss: 10.0600\n",
      "Epoch 394/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.1018 - val_loss: 10.0042\n",
      "Epoch 395/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0363 - val_loss: 9.8651\n",
      "Epoch 396/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8937 - val_loss: 9.9168\n",
      "Epoch 397/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8653 - val_loss: 9.8953\n",
      "Epoch 398/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.9373 - val_loss: 9.7334\n",
      "Epoch 399/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.8876 - val_loss: 9.8531\n",
      "Epoch 400/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8590 - val_loss: 10.1929\n",
      "Epoch 401/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0103 - val_loss: 9.7936\n",
      "Epoch 402/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.8952 - val_loss: 9.8713\n",
      "Epoch 403/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.9499 - val_loss: 9.9517\n",
      "Epoch 404/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8410 - val_loss: 9.9557\n",
      "Epoch 405/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9689 - val_loss: 9.9326\n",
      "Epoch 406/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0377 - val_loss: 10.0789\n",
      "Epoch 407/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.9835 - val_loss: 9.9281\n",
      "Epoch 408/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.8442 - val_loss: 9.8082\n",
      "Epoch 409/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.8245 - val_loss: 9.8276\n",
      "Epoch 410/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.8542 - val_loss: 9.7682\n",
      "Epoch 411/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8727 - val_loss: 9.8605\n",
      "Epoch 412/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9144 - val_loss: 9.9769\n",
      "Epoch 413/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9992 - val_loss: 10.0800\n",
      "Epoch 414/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9217 - val_loss: 10.0664\n",
      "Epoch 415/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.9312 - val_loss: 10.0098\n",
      "Epoch 416/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9102 - val_loss: 10.0730\n",
      "Epoch 417/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8065 - val_loss: 9.9002\n",
      "Epoch 418/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.8035 - val_loss: 9.9832\n",
      "Epoch 419/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9204 - val_loss: 9.8195\n",
      "Epoch 420/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8623 - val_loss: 9.8705\n",
      "Epoch 421/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.7853 - val_loss: 9.9699\n",
      "Epoch 422/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9086 - val_loss: 10.1681\n",
      "Epoch 423/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8063 - val_loss: 9.7747\n",
      "Epoch 424/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9161 - val_loss: 9.8904\n",
      "Epoch 425/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8941 - val_loss: 10.0402\n",
      "Epoch 426/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0230 - val_loss: 10.1368\n",
      "Epoch 427/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8339 - val_loss: 10.0682\n",
      "Epoch 428/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.8723 - val_loss: 9.9794\n",
      "Epoch 429/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.9347 - val_loss: 9.9508\n",
      "Epoch 430/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.8552 - val_loss: 9.8099\n",
      "Epoch 431/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7839 - val_loss: 9.9938\n",
      "Epoch 432/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.8540 - val_loss: 10.0273\n",
      "Epoch 433/1000\n",
      "274/274 [==============================] - 0s 135us/step - loss: 5.9078 - val_loss: 10.1404\n",
      "Epoch 434/1000\n",
      "274/274 [==============================] - 0s 135us/step - loss: 5.7940 - val_loss: 10.1898\n",
      "Epoch 435/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 5.7855 - val_loss: 9.9351\n",
      "Epoch 436/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7505 - val_loss: 9.9501\n",
      "Epoch 437/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8172 - val_loss: 10.1252\n",
      "Epoch 438/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 5.8081 - val_loss: 10.0686\n",
      "Epoch 439/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8683 - val_loss: 10.0284\n",
      "Epoch 440/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8535 - val_loss: 9.8324\n",
      "Epoch 441/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8239 - val_loss: 9.9490\n",
      "Epoch 442/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.9789 - val_loss: 9.9332\n",
      "Epoch 443/1000\n",
      "274/274 [==============================] - 0s 135us/step - loss: 5.9202 - val_loss: 10.2175\n",
      "Epoch 444/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 5.8132 - val_loss: 10.0971\n",
      "Epoch 445/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 5.8263 - val_loss: 9.8842\n",
      "Epoch 446/1000\n",
      "274/274 [==============================] - 0s 157us/step - loss: 5.9724 - val_loss: 9.8993\n",
      "Epoch 447/1000\n",
      "274/274 [==============================] - 0s 149us/step - loss: 5.8235 - val_loss: 10.0955\n",
      "Epoch 448/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7938 - val_loss: 10.0712\n",
      "Epoch 449/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 5.8947 - val_loss: 10.0917\n",
      "Epoch 450/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9800 - val_loss: 10.0495\n",
      "Epoch 451/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1367 - val_loss: 10.0559\n",
      "Epoch 452/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8919 - val_loss: 10.0565\n",
      "Epoch 453/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0717 - val_loss: 9.9828\n",
      "Epoch 454/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.3755 - val_loss: 10.0553\n",
      "Epoch 455/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 98us/step - loss: 6.0585 - val_loss: 10.0601\n",
      "Epoch 456/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9890 - val_loss: 9.9723\n",
      "Epoch 457/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8622 - val_loss: 9.9137\n",
      "Epoch 458/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.9158 - val_loss: 10.0143\n",
      "Epoch 459/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 6.0511 - val_loss: 9.9702\n",
      "Epoch 460/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 6.2788 - val_loss: 10.0565\n",
      "Epoch 461/1000\n",
      "274/274 [==============================] - 0s 119us/step - loss: 6.2004 - val_loss: 10.0880\n",
      "Epoch 462/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 6.0677 - val_loss: 10.2558\n",
      "Epoch 463/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 5.6911 - val_loss: 10.2305\n",
      "Epoch 464/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.7971 - val_loss: 9.8921\n",
      "Epoch 465/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 5.8229 - val_loss: 10.0303\n",
      "Epoch 466/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.2025 - val_loss: 10.2308\n",
      "Epoch 467/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1630 - val_loss: 10.3817\n",
      "Epoch 468/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.8767 - val_loss: 10.2294\n",
      "Epoch 469/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.7919 - val_loss: 10.1293\n",
      "Epoch 470/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9157 - val_loss: 10.1360\n",
      "Epoch 471/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7111 - val_loss: 10.1080\n",
      "Epoch 472/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.8895 - val_loss: 10.2395\n",
      "Epoch 473/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.8261 - val_loss: 10.2052\n",
      "Epoch 474/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8554 - val_loss: 10.0924\n",
      "Epoch 475/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7334 - val_loss: 9.8442\n",
      "Epoch 476/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8056 - val_loss: 9.9928\n",
      "Epoch 477/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 5.8301 - val_loss: 10.1294\n",
      "Epoch 478/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.6946 - val_loss: 10.1202\n",
      "Epoch 479/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7833 - val_loss: 10.0814\n",
      "Epoch 480/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 5.9307 - val_loss: 9.8786\n",
      "Epoch 481/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7424 - val_loss: 9.8697\n",
      "Epoch 482/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.8164 - val_loss: 10.1454\n",
      "Epoch 483/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.7900 - val_loss: 10.3255\n",
      "Epoch 484/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 5.7363 - val_loss: 10.2338\n",
      "Epoch 485/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7508 - val_loss: 9.9434\n",
      "Epoch 486/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8320 - val_loss: 9.9237\n",
      "Epoch 487/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7596 - val_loss: 9.9676\n",
      "Epoch 488/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7236 - val_loss: 10.0622\n",
      "Epoch 489/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.7315 - val_loss: 10.2422\n",
      "Epoch 490/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.6934 - val_loss: 10.0883\n",
      "Epoch 491/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6858 - val_loss: 10.1894\n",
      "Epoch 492/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7809 - val_loss: 10.0529\n",
      "Epoch 493/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9813 - val_loss: 9.9382\n",
      "Epoch 494/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.9168 - val_loss: 9.9383\n",
      "Epoch 495/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.7950 - val_loss: 9.9519\n",
      "Epoch 496/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7107 - val_loss: 9.9918\n",
      "Epoch 497/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7650 - val_loss: 10.2094\n",
      "Epoch 498/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.7965 - val_loss: 9.9607\n",
      "Epoch 499/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7673 - val_loss: 9.8260\n",
      "Epoch 500/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8189 - val_loss: 10.1892\n",
      "Epoch 501/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7323 - val_loss: 10.1396\n",
      "Epoch 502/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9091 - val_loss: 9.9834\n",
      "Epoch 503/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7672 - val_loss: 10.1454\n",
      "Epoch 504/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6963 - val_loss: 10.2053\n",
      "Epoch 505/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8627 - val_loss: 10.0784\n",
      "Epoch 506/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.7897 - val_loss: 9.9543\n",
      "Epoch 507/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.7322 - val_loss: 9.8772\n",
      "Epoch 508/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7343 - val_loss: 10.0834\n",
      "Epoch 509/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9688 - val_loss: 9.8569\n",
      "Epoch 510/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8973 - val_loss: 9.8846\n",
      "Epoch 511/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7393 - val_loss: 9.9081\n",
      "Epoch 512/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6739 - val_loss: 9.9548\n",
      "Epoch 513/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6844 - val_loss: 9.9223\n",
      "Epoch 514/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.7463 - val_loss: 10.0244\n",
      "Epoch 515/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6954 - val_loss: 10.0039\n",
      "Epoch 516/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7395 - val_loss: 9.9165\n",
      "Epoch 517/1000\n",
      "274/274 [==============================] - 0s 117us/step - loss: 5.7834 - val_loss: 10.0619\n",
      "Epoch 518/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7129 - val_loss: 9.9145\n",
      "Epoch 519/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7464 - val_loss: 9.9717\n",
      "Epoch 520/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6515 - val_loss: 9.9049\n",
      "Epoch 521/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7169 - val_loss: 10.0471\n",
      "Epoch 522/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6707 - val_loss: 9.9823\n",
      "Epoch 523/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8663 - val_loss: 10.0369\n",
      "Epoch 524/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7530 - val_loss: 10.0235\n",
      "Epoch 525/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6634 - val_loss: 10.0016\n",
      "Epoch 526/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 9.672 - 0s 109us/step - loss: 5.8571 - val_loss: 10.1018\n",
      "Epoch 527/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.6959 - val_loss: 9.8603\n",
      "Epoch 528/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8105 - val_loss: 10.0007\n",
      "Epoch 529/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 6.0584 - val_loss: 9.8809\n",
      "Epoch 530/1000\n",
      "274/274 [==============================] - 0s 133us/step - loss: 5.8984 - val_loss: 9.9455\n",
      "Epoch 531/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.7452 - val_loss: 9.8726\n",
      "Epoch 532/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 109us/step - loss: 5.7225 - val_loss: 9.8117\n",
      "Epoch 533/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6156 - val_loss: 9.9622\n",
      "Epoch 534/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6989 - val_loss: 9.9383\n",
      "Epoch 535/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.7635 - val_loss: 9.9149\n",
      "Epoch 536/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7187 - val_loss: 9.9963\n",
      "Epoch 537/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8368 - val_loss: 9.8332\n",
      "Epoch 538/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1357 - val_loss: 9.9173\n",
      "Epoch 539/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8785 - val_loss: 10.0463\n",
      "Epoch 540/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.6791 - val_loss: 10.0670\n",
      "Epoch 541/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6681 - val_loss: 9.9555\n",
      "Epoch 542/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7585 - val_loss: 9.9568\n",
      "Epoch 543/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.8823 - val_loss: 10.1200\n",
      "Epoch 544/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8289 - val_loss: 9.8474\n",
      "Epoch 545/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6750 - val_loss: 9.8117\n",
      "Epoch 546/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6909 - val_loss: 9.8601\n",
      "Epoch 547/1000\n",
      "274/274 [==============================] - 0s 149us/step - loss: 5.8304 - val_loss: 9.9740\n",
      "Epoch 548/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 5.5963 - val_loss: 9.9893\n",
      "Epoch 549/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7710 - val_loss: 9.9033\n",
      "Epoch 550/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6883 - val_loss: 9.8503\n",
      "Epoch 551/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6880 - val_loss: 9.8847\n",
      "Epoch 552/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6892 - val_loss: 9.8331\n",
      "Epoch 553/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.7650 - val_loss: 10.0499\n",
      "Epoch 554/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 5.6360 - val_loss: 10.0197\n",
      "Epoch 555/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7311 - val_loss: 10.0031\n",
      "Epoch 556/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7242 - val_loss: 9.7708\n",
      "Epoch 557/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.6556 - val_loss: 9.7457\n",
      "Epoch 558/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6707 - val_loss: 9.9529\n",
      "Epoch 559/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6283 - val_loss: 9.7513\n",
      "Epoch 560/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.9801 - val_loss: 9.9010\n",
      "Epoch 561/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.7646 - val_loss: 9.8229\n",
      "Epoch 562/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.9708 - val_loss: 9.8085\n",
      "Epoch 563/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.7138 - val_loss: 9.7447\n",
      "Epoch 564/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.8033 - val_loss: 9.7753\n",
      "Epoch 565/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6558 - val_loss: 9.7968\n",
      "Epoch 566/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.9727 - val_loss: 9.7236\n",
      "Epoch 567/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7549 - val_loss: 10.1120\n",
      "Epoch 568/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7958 - val_loss: 9.8281\n",
      "Epoch 569/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1427 - val_loss: 9.9264\n",
      "Epoch 570/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7348 - val_loss: 9.6972\n",
      "Epoch 571/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6565 - val_loss: 9.7021\n",
      "Epoch 572/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5557 - val_loss: 9.6031\n",
      "Epoch 573/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6090 - val_loss: 9.6561\n",
      "Epoch 574/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5607 - val_loss: 9.7261\n",
      "Epoch 575/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8222 - val_loss: 9.6326\n",
      "Epoch 576/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6561 - val_loss: 9.6243\n",
      "Epoch 577/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6098 - val_loss: 9.7593\n",
      "Epoch 578/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.8151 - val_loss: 9.6331\n",
      "Epoch 579/1000\n",
      "274/274 [==============================] - 0s 148us/step - loss: 5.9629 - val_loss: 9.4447\n",
      "Epoch 580/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9025 - val_loss: 9.5150\n",
      "Epoch 581/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.8354 - val_loss: 9.6787\n",
      "Epoch 582/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5484 - val_loss: 9.6483\n",
      "Epoch 583/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.6012 - val_loss: 9.5571\n",
      "Epoch 584/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5513 - val_loss: 9.7627\n",
      "Epoch 585/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5325 - val_loss: 9.6477\n",
      "Epoch 586/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5977 - val_loss: 9.5153\n",
      "Epoch 587/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.5686 - val_loss: 9.5361\n",
      "Epoch 588/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.7286 - val_loss: 9.3254\n",
      "Epoch 589/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6838 - val_loss: 9.7134\n",
      "Epoch 590/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6011 - val_loss: 9.6002\n",
      "Epoch 591/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5739 - val_loss: 9.4114\n",
      "Epoch 592/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.5127 - val_loss: 9.3841\n",
      "Epoch 593/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5945 - val_loss: 9.4361\n",
      "Epoch 594/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4900 - val_loss: 9.4348\n",
      "Epoch 595/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.5059 - val_loss: 9.3752\n",
      "Epoch 596/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6816 - val_loss: 9.4265\n",
      "Epoch 597/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.5549 - val_loss: 9.1903\n",
      "Epoch 598/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.4726 - val_loss: 9.4619\n",
      "Epoch 599/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4650 - val_loss: 9.6248\n",
      "Epoch 600/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4829 - val_loss: 9.4249\n",
      "Epoch 601/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4869 - val_loss: 9.3895\n",
      "Epoch 602/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6655 - val_loss: 9.3745\n",
      "Epoch 603/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.7112 - val_loss: 9.4797\n",
      "Epoch 604/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.5614 - val_loss: 9.3109\n",
      "Epoch 605/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4388 - val_loss: 9.4050\n",
      "Epoch 606/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4417 - val_loss: 9.4039\n",
      "Epoch 607/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4688 - val_loss: 9.4396\n",
      "Epoch 608/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.5349 - val_loss: 9.3396\n",
      "Epoch 609/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 87us/step - loss: 5.3787 - val_loss: 9.2522\n",
      "Epoch 610/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.4262 - val_loss: 9.2777\n",
      "Epoch 611/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.4636 - val_loss: 9.4662\n",
      "Epoch 612/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5450 - val_loss: 9.2547\n",
      "Epoch 613/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.8912 - val_loss: 9.4642\n",
      "Epoch 614/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.7135 - val_loss: 9.4042\n",
      "Epoch 615/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6326 - val_loss: 9.4945\n",
      "Epoch 616/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5922 - val_loss: 9.3863\n",
      "Epoch 617/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5015 - val_loss: 9.4055\n",
      "Epoch 618/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6225 - val_loss: 9.3372\n",
      "Epoch 619/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4940 - val_loss: 9.3232\n",
      "Epoch 620/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.4625 - val_loss: 9.3712\n",
      "Epoch 621/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.5020 - val_loss: 9.2516\n",
      "Epoch 622/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4426 - val_loss: 9.2187\n",
      "Epoch 623/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4055 - val_loss: 9.3610\n",
      "Epoch 624/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.4613 - val_loss: 9.4162\n",
      "Epoch 625/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4881 - val_loss: 9.3830\n",
      "Epoch 626/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.3832 - val_loss: 9.4820\n",
      "Epoch 627/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4678 - val_loss: 9.3663\n",
      "Epoch 628/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4467 - val_loss: 9.2731\n",
      "Epoch 629/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6749 - val_loss: 9.3353\n",
      "Epoch 630/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.5711 - val_loss: 9.5803\n",
      "Epoch 631/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3862 - val_loss: 9.3543\n",
      "Epoch 632/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.5522 - val_loss: 9.4502\n",
      "Epoch 633/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9029 - val_loss: 9.5670\n",
      "Epoch 634/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5410 - val_loss: 9.3351\n",
      "Epoch 635/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4290 - val_loss: 9.3193\n",
      "Epoch 636/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4877 - val_loss: 9.3734\n",
      "Epoch 637/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3980 - val_loss: 9.4218\n",
      "Epoch 638/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3674 - val_loss: 9.4232\n",
      "Epoch 639/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.3567 - val_loss: 9.3901\n",
      "Epoch 640/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4027 - val_loss: 9.2203\n",
      "Epoch 641/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5162 - val_loss: 9.3915\n",
      "Epoch 642/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4184 - val_loss: 9.3920\n",
      "Epoch 643/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4001 - val_loss: 9.5807\n",
      "Epoch 644/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3728 - val_loss: 9.4490\n",
      "Epoch 645/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5906 - val_loss: 9.3695\n",
      "Epoch 646/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4248 - val_loss: 9.5055\n",
      "Epoch 647/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.3498 - val_loss: 9.3744\n",
      "Epoch 648/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4751 - val_loss: 9.3411\n",
      "Epoch 649/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4095 - val_loss: 9.4158\n",
      "Epoch 650/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.4227 - val_loss: 9.4071\n",
      "Epoch 651/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.3686 - val_loss: 9.4237\n",
      "Epoch 652/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3258 - val_loss: 9.4449\n",
      "Epoch 653/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5437 - val_loss: 9.4259\n",
      "Epoch 654/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.4370 - val_loss: 9.5105\n",
      "Epoch 655/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7423 - val_loss: 9.5866\n",
      "Epoch 656/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.5720 - val_loss: 9.4397\n",
      "Epoch 657/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7187 - val_loss: 9.4850\n",
      "Epoch 658/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4199 - val_loss: 9.2217\n",
      "Epoch 659/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.3211 - val_loss: 9.2228\n",
      "Epoch 660/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3671 - val_loss: 9.4945\n",
      "Epoch 661/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3572 - val_loss: 9.5752\n",
      "Epoch 662/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3798 - val_loss: 9.4263\n",
      "Epoch 663/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3842 - val_loss: 9.3736\n",
      "Epoch 664/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4008 - val_loss: 9.4601\n",
      "Epoch 665/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4972 - val_loss: 9.4781\n",
      "Epoch 666/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.2987 - val_loss: 9.3212\n",
      "Epoch 667/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3611 - val_loss: 9.3817\n",
      "Epoch 668/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3415 - val_loss: 9.4037\n",
      "Epoch 669/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.3965 - val_loss: 9.4474\n",
      "Epoch 670/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.3102 - val_loss: 9.4778\n",
      "Epoch 671/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.3064 - val_loss: 9.3812\n",
      "Epoch 672/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.2833 - val_loss: 9.3794\n",
      "Epoch 673/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3524 - val_loss: 9.3770\n",
      "Epoch 674/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.3376 - val_loss: 9.2939\n",
      "Epoch 675/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3406 - val_loss: 9.4101\n",
      "Epoch 676/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3905 - val_loss: 9.3202\n",
      "Epoch 677/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4334 - val_loss: 9.2685\n",
      "Epoch 678/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.3920 - val_loss: 9.3937\n",
      "Epoch 679/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.2617 - val_loss: 9.4133\n",
      "Epoch 680/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.4919 - val_loss: 9.5190\n",
      "Epoch 681/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3093 - val_loss: 9.7316\n",
      "Epoch 682/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5501 - val_loss: 9.3965\n",
      "Epoch 683/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3250 - val_loss: 9.4378\n",
      "Epoch 684/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3367 - val_loss: 9.5228\n",
      "Epoch 685/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.3174 - val_loss: 9.6339\n",
      "Epoch 686/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.3428 - val_loss: 9.4425\n",
      "Epoch 687/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 98us/step - loss: 5.2974 - val_loss: 9.3653\n",
      "Epoch 688/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.3180 - val_loss: 9.4164\n",
      "Epoch 689/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.3941 - val_loss: 9.3740\n",
      "Epoch 690/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.3078 - val_loss: 9.4346\n",
      "Epoch 691/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4710 - val_loss: 9.3721\n",
      "Epoch 692/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.6766 - val_loss: 9.6942\n",
      "Epoch 693/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6203 - val_loss: 9.5380\n",
      "Epoch 694/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.3368 - val_loss: 9.4737\n",
      "Epoch 695/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.3740 - val_loss: 9.4457\n",
      "Epoch 696/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4345 - val_loss: 9.3448\n",
      "Epoch 697/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3251 - val_loss: 9.2761\n",
      "Epoch 698/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.3387 - val_loss: 9.2530\n",
      "Epoch 699/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.4055 - val_loss: 9.4551\n",
      "Epoch 700/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4056 - val_loss: 9.3899\n",
      "Epoch 701/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3199 - val_loss: 9.3819\n",
      "Epoch 702/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2822 - val_loss: 9.5286\n",
      "Epoch 703/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2921 - val_loss: 9.5463\n",
      "Epoch 704/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2810 - val_loss: 9.2769\n",
      "Epoch 705/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3985 - val_loss: 9.2300\n",
      "Epoch 706/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4160 - val_loss: 9.6233\n",
      "Epoch 707/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.3744 - val_loss: 9.5833\n",
      "Epoch 708/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4025 - val_loss: 9.3783\n",
      "Epoch 709/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.3413 - val_loss: 9.4773\n",
      "Epoch 710/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3134 - val_loss: 9.4206\n",
      "Epoch 711/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3000 - val_loss: 9.4055\n",
      "Epoch 712/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3551 - val_loss: 9.5477\n",
      "Epoch 713/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3833 - val_loss: 9.4517\n",
      "Epoch 714/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4144 - val_loss: 9.4421\n",
      "Epoch 715/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.3421 - val_loss: 9.4775\n",
      "Epoch 716/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3466 - val_loss: 9.5322\n",
      "Epoch 717/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3718 - val_loss: 9.4970\n",
      "Epoch 718/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.4935 - val_loss: 9.4378\n",
      "Epoch 719/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4996 - val_loss: 9.4815\n",
      "Epoch 720/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3364 - val_loss: 9.6362\n",
      "Epoch 721/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4333 - val_loss: 9.3172\n",
      "Epoch 722/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3288 - val_loss: 9.3937\n",
      "Epoch 723/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.3382 - val_loss: 9.4820\n",
      "Epoch 724/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5719 - val_loss: 9.7073\n",
      "Epoch 725/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.8126 - val_loss: 9.8370\n",
      "Epoch 726/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.8468 - val_loss: 9.5303\n",
      "Epoch 727/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5417 - val_loss: 9.3942\n",
      "Epoch 728/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5876 - val_loss: 9.4880\n",
      "Epoch 729/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.4312 - val_loss: 9.5484\n",
      "Epoch 730/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.4031 - val_loss: 9.4381\n",
      "Epoch 731/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3110 - val_loss: 9.6431\n",
      "Epoch 732/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.3476 - val_loss: 9.5505\n",
      "Epoch 733/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3596 - val_loss: 9.5088\n",
      "Epoch 734/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3245 - val_loss: 9.3950\n",
      "Epoch 735/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3243 - val_loss: 9.4711\n",
      "Epoch 736/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4239 - val_loss: 9.7003\n",
      "Epoch 737/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5348 - val_loss: 9.5505\n",
      "Epoch 738/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5427 - val_loss: 9.2974\n",
      "Epoch 739/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4456 - val_loss: 9.3893\n",
      "Epoch 740/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.3921 - val_loss: 9.4368\n",
      "Epoch 741/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4325 - val_loss: 9.4869\n",
      "Epoch 742/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3201 - val_loss: 9.4827\n",
      "Epoch 743/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.5483 - val_loss: 9.6598\n",
      "Epoch 744/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2985 - val_loss: 9.6701\n",
      "Epoch 745/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3215 - val_loss: 9.4882\n",
      "Epoch 746/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2790 - val_loss: 9.5707\n",
      "Epoch 747/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3504 - val_loss: 9.4876\n",
      "Epoch 748/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4208 - val_loss: 9.4561\n",
      "Epoch 749/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.2732 - val_loss: 9.3677\n",
      "Epoch 750/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.3998 - val_loss: 9.5944\n",
      "Epoch 751/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.4261 - val_loss: 9.4801\n",
      "Epoch 752/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4325 - val_loss: 9.3652\n",
      "Epoch 753/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3645 - val_loss: 9.4412\n",
      "Epoch 754/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3689 - val_loss: 9.5125\n",
      "Epoch 755/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3201 - val_loss: 9.3759\n",
      "Epoch 756/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2647 - val_loss: 9.5622\n",
      "Epoch 757/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4523 - val_loss: 9.4771\n",
      "Epoch 758/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3905 - val_loss: 9.4123\n",
      "Epoch 759/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2390 - val_loss: 9.2984\n",
      "Epoch 760/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.3681 - val_loss: 9.4626\n",
      "Epoch 761/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.2285 - val_loss: 9.4902\n",
      "Epoch 762/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3444 - val_loss: 9.5786\n",
      "Epoch 763/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 4.151 - 0s 98us/step - loss: 5.5116 - val_loss: 9.4740\n",
      "Epoch 764/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 97us/step - loss: 5.3093 - val_loss: 9.3365\n",
      "Epoch 765/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.2962 - val_loss: 9.4069\n",
      "Epoch 766/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.3416 - val_loss: 9.4694\n",
      "Epoch 767/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.4432 - val_loss: 9.3867\n",
      "Epoch 768/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4266 - val_loss: 9.4315\n",
      "Epoch 769/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3547 - val_loss: 9.4568\n",
      "Epoch 770/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.3663 - val_loss: 9.4420\n",
      "Epoch 771/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3155 - val_loss: 9.4865\n",
      "Epoch 772/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.2577 - val_loss: 9.4057\n",
      "Epoch 773/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2802 - val_loss: 9.5027\n",
      "Epoch 774/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2150 - val_loss: 9.5309\n",
      "Epoch 775/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3193 - val_loss: 9.4201\n",
      "Epoch 776/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3433 - val_loss: 9.4608\n",
      "Epoch 777/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.2455 - val_loss: 9.3639\n",
      "Epoch 778/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.2771 - val_loss: 9.5363\n",
      "Epoch 779/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4473 - val_loss: 9.4662\n",
      "Epoch 780/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3751 - val_loss: 9.5869\n",
      "Epoch 781/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5372 - val_loss: 9.4764\n",
      "Epoch 782/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3403 - val_loss: 9.3603\n",
      "Epoch 783/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3653 - val_loss: 9.4474\n",
      "Epoch 784/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2583 - val_loss: 9.3228\n",
      "Epoch 785/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3445 - val_loss: 9.4093\n",
      "Epoch 786/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2834 - val_loss: 9.4492\n",
      "Epoch 787/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.3162 - val_loss: 9.5906\n",
      "Epoch 788/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3050 - val_loss: 9.4390\n",
      "Epoch 789/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.3937 - val_loss: 9.5137\n",
      "Epoch 790/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2932 - val_loss: 9.4340\n",
      "Epoch 791/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.2764 - val_loss: 9.4408\n",
      "Epoch 792/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4032 - val_loss: 9.5740\n",
      "Epoch 793/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.2753 - val_loss: 9.3486\n",
      "Epoch 794/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3887 - val_loss: 9.2701\n",
      "Epoch 795/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3407 - val_loss: 9.5265\n",
      "Epoch 796/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 5.3477 - val_loss: 9.5377\n",
      "Epoch 797/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5067 - val_loss: 9.3710\n",
      "Epoch 798/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.1499 - val_loss: 9.3810\n",
      "Epoch 799/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7443 - val_loss: 9.5021\n",
      "Epoch 800/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4485 - val_loss: 9.5175\n",
      "Epoch 801/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4976 - val_loss: 9.5506\n",
      "Epoch 802/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3852 - val_loss: 9.4177\n",
      "Epoch 803/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.3436 - val_loss: 9.3978\n",
      "Epoch 804/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.2926 - val_loss: 9.5421\n",
      "Epoch 805/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.4058 - val_loss: 9.6733\n",
      "Epoch 806/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3151 - val_loss: 9.5379\n",
      "Epoch 807/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.3625 - val_loss: 9.3917\n",
      "Epoch 808/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3551 - val_loss: 9.4066\n",
      "Epoch 809/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2999 - val_loss: 9.5493\n",
      "Epoch 810/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3067 - val_loss: 9.6286\n",
      "Epoch 811/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.3447 - val_loss: 9.6253\n",
      "Epoch 812/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2651 - val_loss: 9.5266\n",
      "Epoch 813/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3238 - val_loss: 9.3801\n",
      "Epoch 814/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2615 - val_loss: 9.5875\n",
      "Epoch 815/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4021 - val_loss: 9.5157\n",
      "Epoch 816/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3287 - val_loss: 9.5998\n",
      "Epoch 817/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.3201 - val_loss: 9.5685\n",
      "Epoch 818/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.3667 - val_loss: 9.5579\n",
      "Epoch 819/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4228 - val_loss: 9.4471\n",
      "Epoch 820/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.4240 - val_loss: 9.4052\n",
      "Epoch 821/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2455 - val_loss: 9.3169\n",
      "Epoch 822/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.3336 - val_loss: 9.5157\n",
      "Epoch 823/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7504 - val_loss: 9.6824\n",
      "Epoch 824/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4880 - val_loss: 9.7217\n",
      "Epoch 825/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.4862 - val_loss: 9.5547\n",
      "Epoch 826/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3884 - val_loss: 9.5007\n",
      "Epoch 827/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2999 - val_loss: 9.5489\n",
      "Epoch 828/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4295 - val_loss: 9.5716\n",
      "Epoch 829/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.5707 - val_loss: 9.5951\n",
      "Epoch 830/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.3565 - val_loss: 9.4677\n",
      "Epoch 831/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3475 - val_loss: 9.3636\n",
      "Epoch 832/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.3287 - val_loss: 9.5497\n",
      "Epoch 833/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5057 - val_loss: 9.5550\n",
      "Epoch 834/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.5091 - val_loss: 9.5731\n",
      "Epoch 835/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2784 - val_loss: 9.4051\n",
      "Epoch 836/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.2245 - val_loss: 9.4029\n",
      "Epoch 837/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2894 - val_loss: 9.3410\n",
      "Epoch 838/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.1853 - val_loss: 9.4089\n",
      "Epoch 839/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.2505 - val_loss: 9.5065\n",
      "Epoch 840/1000\n",
      "274/274 [==============================] - 0s 115us/step - loss: 5.2467 - val_loss: 9.4281\n",
      "Epoch 841/1000\n",
      "274/274 [==============================] - 0s 135us/step - loss: 5.3326 - val_loss: 9.3793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 842/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 5.3547 - val_loss: 9.4493\n",
      "Epoch 843/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3798 - val_loss: 9.5177\n",
      "Epoch 844/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.2350 - val_loss: 9.5164\n",
      "Epoch 845/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.2271 - val_loss: 9.6509\n",
      "Epoch 846/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.3234 - val_loss: 9.4770\n",
      "Epoch 847/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.3486 - val_loss: 9.4702\n",
      "Epoch 848/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.2564 - val_loss: 9.4882\n",
      "Epoch 849/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.4647 - val_loss: 9.4553\n",
      "Epoch 850/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.5771 - val_loss: 9.3801\n",
      "Epoch 851/1000\n",
      "274/274 [==============================] - 0s 129us/step - loss: 5.5004 - val_loss: 9.4399\n",
      "Epoch 852/1000\n",
      "274/274 [==============================] - 0s 122us/step - loss: 5.6475 - val_loss: 9.3879\n",
      "Epoch 853/1000\n",
      "274/274 [==============================] - 0s 117us/step - loss: 5.4130 - val_loss: 9.3881\n",
      "Epoch 854/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.3656 - val_loss: 9.3707\n",
      "Epoch 855/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2292 - val_loss: 9.3777\n",
      "Epoch 856/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.3271 - val_loss: 9.4512\n",
      "Epoch 857/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.2141 - val_loss: 9.6246\n",
      "Epoch 858/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.2590 - val_loss: 9.5880\n",
      "Epoch 859/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.2698 - val_loss: 9.4202\n",
      "Epoch 860/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.3310 - val_loss: 9.2682\n",
      "Epoch 861/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 5.3962 - val_loss: 9.5301\n",
      "Epoch 862/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.5755 - val_loss: 9.6091\n",
      "Epoch 863/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8927 - val_loss: 9.6012\n",
      "Epoch 864/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6167 - val_loss: 9.6098\n",
      "Epoch 865/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4934 - val_loss: 9.6325\n",
      "Epoch 866/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4821 - val_loss: 9.4306\n",
      "Epoch 867/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.3500 - val_loss: 9.5717\n",
      "Epoch 868/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.2688 - val_loss: 9.6822\n",
      "Epoch 869/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2662 - val_loss: 9.4635\n",
      "Epoch 870/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4330 - val_loss: 9.3669\n",
      "Epoch 871/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3867 - val_loss: 9.2546\n",
      "Epoch 872/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5308 - val_loss: 9.3518\n",
      "Epoch 873/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2808 - val_loss: 9.3238\n",
      "Epoch 874/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2518 - val_loss: 9.3373\n",
      "Epoch 875/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.2845 - val_loss: 9.4508\n",
      "Epoch 876/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4050 - val_loss: 9.4918\n",
      "Epoch 877/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3556 - val_loss: 9.4262\n",
      "Epoch 878/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.3166 - val_loss: 9.3222\n",
      "Epoch 879/1000\n",
      "274/274 [==============================] - 0s 146us/step - loss: 5.3156 - val_loss: 9.3415\n",
      "Epoch 880/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3281 - val_loss: 9.4235\n",
      "Epoch 881/1000\n",
      "274/274 [==============================] - 0s 115us/step - loss: 5.2650 - val_loss: 9.4513\n",
      "Epoch 882/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2650 - val_loss: 9.3786\n",
      "Epoch 883/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1833 - val_loss: 9.5246\n",
      "Epoch 884/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.2678 - val_loss: 9.3766\n",
      "Epoch 885/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3123 - val_loss: 9.4089\n",
      "Epoch 886/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3069 - val_loss: 9.3526\n",
      "Epoch 887/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3022 - val_loss: 9.3900\n",
      "Epoch 888/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 5.2975 - val_loss: 9.6897\n",
      "Epoch 889/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3236 - val_loss: 9.9374\n",
      "Epoch 890/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2416 - val_loss: 9.5874\n",
      "Epoch 891/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2638 - val_loss: 9.4858\n",
      "Epoch 892/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3492 - val_loss: 9.5522\n",
      "Epoch 893/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3841 - val_loss: 9.5171\n",
      "Epoch 894/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2177 - val_loss: 9.5218\n",
      "Epoch 895/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.3342 - val_loss: 9.3605\n",
      "Epoch 896/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3264 - val_loss: 9.4033\n",
      "Epoch 897/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4254 - val_loss: 9.5606\n",
      "Epoch 898/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2800 - val_loss: 9.4507\n",
      "Epoch 899/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.2628 - val_loss: 9.4386\n",
      "Epoch 900/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2939 - val_loss: 9.4063\n",
      "Epoch 901/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2552 - val_loss: 9.4379\n",
      "Epoch 902/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.4234 - val_loss: 9.5848\n",
      "Epoch 903/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2829 - val_loss: 9.5014\n",
      "Epoch 904/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2359 - val_loss: 9.5105\n",
      "Epoch 905/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.3749 - val_loss: 9.3755\n",
      "Epoch 906/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.2744 - val_loss: 9.3103\n",
      "Epoch 907/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.2236 - val_loss: 9.4113\n",
      "Epoch 908/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.4391 - val_loss: 9.4186\n",
      "Epoch 909/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4802 - val_loss: 9.5026\n",
      "Epoch 910/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.2627 - val_loss: 9.4823\n",
      "Epoch 911/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2398 - val_loss: 9.4685\n",
      "Epoch 912/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.2708 - val_loss: 9.5234\n",
      "Epoch 913/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3025 - val_loss: 9.4331\n",
      "Epoch 914/1000\n",
      "274/274 [==============================] - 0s 137us/step - loss: 5.2993 - val_loss: 9.4892\n",
      "Epoch 915/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.3489 - val_loss: 9.4954\n",
      "Epoch 916/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 5.4585 - val_loss: 9.4161\n",
      "Epoch 917/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2370 - val_loss: 9.4587\n",
      "Epoch 918/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5803 - val_loss: 9.4767\n",
      "Epoch 919/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 113us/step - loss: 5.4783 - val_loss: 9.4498\n",
      "Epoch 920/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4824 - val_loss: 9.5345\n",
      "Epoch 921/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.6740 - val_loss: 9.4325\n",
      "Epoch 922/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4046 - val_loss: 9.4583\n",
      "Epoch 923/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3298 - val_loss: 9.4977\n",
      "Epoch 924/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.1916 - val_loss: 9.3364\n",
      "Epoch 925/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.4055 - val_loss: 9.4774\n",
      "Epoch 926/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3617 - val_loss: 9.5912\n",
      "Epoch 927/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4920 - val_loss: 9.6128\n",
      "Epoch 928/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4567 - val_loss: 9.4884\n",
      "Epoch 929/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2758 - val_loss: 9.4810\n",
      "Epoch 930/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2913 - val_loss: 9.5362\n",
      "Epoch 931/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2383 - val_loss: 9.4955\n",
      "Epoch 932/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4447 - val_loss: 9.5189\n",
      "Epoch 933/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6594 - val_loss: 9.6521\n",
      "Epoch 934/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3292 - val_loss: 9.5877\n",
      "Epoch 935/1000\n",
      "274/274 [==============================] - 0s 149us/step - loss: 5.3669 - val_loss: 9.5555\n",
      "Epoch 936/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2759 - val_loss: 9.3880\n",
      "Epoch 937/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3624 - val_loss: 9.4220\n",
      "Epoch 938/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4157 - val_loss: 9.5381\n",
      "Epoch 939/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3266 - val_loss: 9.4933\n",
      "Epoch 940/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.3693 - val_loss: 9.4228\n",
      "Epoch 941/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.2908 - val_loss: 9.2287\n",
      "Epoch 942/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4336 - val_loss: 9.4613\n",
      "Epoch 943/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.4808 - val_loss: 9.4761\n",
      "Epoch 944/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 5.4033 - val_loss: 9.4920\n",
      "Epoch 945/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 5.5201 - val_loss: 9.4444\n",
      "Epoch 946/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.4665 - val_loss: 9.3200\n",
      "Epoch 947/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.4858 - val_loss: 9.4618\n",
      "Epoch 948/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2404 - val_loss: 9.4916\n",
      "Epoch 949/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3488 - val_loss: 9.5987\n",
      "Epoch 950/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3264 - val_loss: 9.6029\n",
      "Epoch 951/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5630 - val_loss: 9.6287\n",
      "Epoch 952/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7499 - val_loss: 9.5591\n",
      "Epoch 953/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2372 - val_loss: 9.4858\n",
      "Epoch 954/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.2609 - val_loss: 9.3540\n",
      "Epoch 955/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2407 - val_loss: 9.5334\n",
      "Epoch 956/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2655 - val_loss: 9.4865\n",
      "Epoch 957/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.3912 - val_loss: 9.5350\n",
      "Epoch 958/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.5163 - val_loss: 9.5274\n",
      "Epoch 959/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3150 - val_loss: 9.3713\n",
      "Epoch 960/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2636 - val_loss: 9.3366\n",
      "Epoch 961/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2716 - val_loss: 9.3731\n",
      "Epoch 962/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.2256 - val_loss: 9.6491\n",
      "Epoch 963/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4067 - val_loss: 9.4788\n",
      "Epoch 964/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.2989 - val_loss: 9.4239\n",
      "Epoch 965/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2439 - val_loss: 9.4242\n",
      "Epoch 966/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2749 - val_loss: 9.3367\n",
      "Epoch 967/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.3022 - val_loss: 9.4561\n",
      "Epoch 968/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 5.4126 - val_loss: 9.2632\n",
      "Epoch 969/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.2952 - val_loss: 9.3893\n",
      "Epoch 970/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4166 - val_loss: 9.5281\n",
      "Epoch 971/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5871 - val_loss: 9.4233\n",
      "Epoch 972/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 5.288 - 0s 113us/step - loss: 5.3974 - val_loss: 9.4445\n",
      "Epoch 973/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2896 - val_loss: 9.5733\n",
      "Epoch 974/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4086 - val_loss: 9.6643\n",
      "Epoch 975/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5418 - val_loss: 9.5924\n",
      "Epoch 976/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3281 - val_loss: 9.5486\n",
      "Epoch 977/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2077 - val_loss: 9.5157\n",
      "Epoch 978/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.2577 - val_loss: 9.4512\n",
      "Epoch 979/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.3153 - val_loss: 9.4193\n",
      "Epoch 980/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.3037 - val_loss: 9.4890\n",
      "Epoch 981/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2632 - val_loss: 9.5270\n",
      "Epoch 982/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2893 - val_loss: 9.5830\n",
      "Epoch 983/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4114 - val_loss: 9.3764\n",
      "Epoch 984/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1358 - val_loss: 9.4724\n",
      "Epoch 985/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.4407 - val_loss: 9.4043\n",
      "Epoch 986/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 5.1851 - val_loss: 9.6421\n",
      "Epoch 987/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.1829 - val_loss: 9.4593\n",
      "Epoch 988/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.2525 - val_loss: 9.4277\n",
      "Epoch 989/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4760 - val_loss: 9.5703\n",
      "Epoch 990/1000\n",
      "274/274 [==============================] - 0s 119us/step - loss: 5.3725 - val_loss: 9.5012\n",
      "Epoch 991/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.2230 - val_loss: 9.5616\n",
      "Epoch 992/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2028 - val_loss: 9.4381\n",
      "Epoch 993/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2196 - val_loss: 9.4401\n",
      "Epoch 994/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3381 - val_loss: 9.4417\n",
      "Epoch 995/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2680 - val_loss: 9.4701\n",
      "Epoch 996/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 113us/step - loss: 5.1974 - val_loss: 9.4533\n",
      "Epoch 997/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3337 - val_loss: 9.5281\n",
      "Epoch 998/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2879 - val_loss: 9.5611\n",
      "Epoch 999/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2315 - val_loss: 9.4299\n",
      "Epoch 1000/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.4139 - val_loss: 9.2819\n",
      "7.108653205936238\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-1.7350274 , -0.8693994 ,  0.92569983, -1.3920354 , -0.32666373],\n",
       "        [ 2.2008724 ,  2.5540974 , -0.12454545,  0.34559613, -1.1580389 ],\n",
       "        [-1.887371  , -2.2258608 , -0.24466757,  0.766277  ,  3.9484634 ],\n",
       "        [-1.8819337 , -2.105869  , -1.2389772 ,  0.44018263,  1.918372  ],\n",
       "        [-0.22819744,  1.1949954 ,  0.310088  ,  0.941166  ,  0.00507916],\n",
       "        [ 0.9311101 ,  0.58201647,  0.8559451 , -0.27702054, -1.7395903 ],\n",
       "        [ 2.0587733 , -0.3602795 , -0.00624899, -2.7764947 , -3.523835  ]],\n",
       "       dtype=float32),\n",
       " array([-0.7352176 ,  0.7305927 , -1.2269505 , -2.1953864 ,  0.73780715],\n",
       "       dtype=float32),\n",
       " array([[-0.3038303 , -0.49257088, -0.76411146, -0.81931883, -0.8029529 ,\n",
       "         -0.63740236,  0.5434296 ,  0.80913055,  0.5881579 ,  0.91990393],\n",
       "        [-0.37434456,  0.21276462,  0.37808648, -0.3640574 , -0.6874039 ,\n",
       "         -0.5364084 , -0.3435534 ,  0.667215  , -0.28354684,  0.5585642 ],\n",
       "        [-0.60731965, -0.31199494, -0.45507097, -0.9589845 , -0.4015797 ,\n",
       "         -0.6524607 ,  0.13134782,  0.30015656,  0.31091374,  0.6011441 ],\n",
       "        [ 0.03221568,  0.10214666, -0.35474432, -0.26457593,  0.6897155 ,\n",
       "          0.5712791 , -0.5000855 ,  0.3074809 , -0.3961305 , -0.70682925],\n",
       "        [-0.6119759 , -0.19103132, -0.90620476, -0.25336093, -0.7134454 ,\n",
       "         -0.5048362 ,  0.21557479,  0.73958564,  0.9669804 , -0.08747791]],\n",
       "       dtype=float32),\n",
       " array([-1.8986521, -1.8944483, -1.7366402, -1.8742414, -1.814208 ,\n",
       "        -1.8794512,  1.8021241,  1.7825965,  1.8201367,  1.8645729],\n",
       "       dtype=float32),\n",
       " array([[-1.4471879 ],\n",
       "        [-1.0404146 ],\n",
       "        [-0.76106703],\n",
       "        [-1.5944773 ],\n",
       "        [-1.3866572 ],\n",
       "        [-1.3690844 ],\n",
       "        [ 1.3064165 ],\n",
       "        [ 1.1728601 ],\n",
       "        [ 0.895524  ],\n",
       "        [ 1.1196936 ]], dtype=float32),\n",
       " array([1.7432859], dtype=float32)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_autompg, history_autompg, evaluate_autompg=NN_model_structure_regression_2(X_train_autompg, X_val_autompg, Y_train_autompg, Y_val_autompg, adam2, 32, 1000, x_test_autompg, y_test_autompg)\n",
    "model_autompg.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_autompg.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_autompg_structure2_4th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_25 (Dense)             (None, 5)                 40        \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 15)                90        \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 146\n",
      "Trainable params: 146\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 274 samples, validate on 59 samples\n",
      "Epoch 1/1000\n",
      "274/274 [==============================] - 0s 975us/step - loss: 460.1842 - val_loss: 244.9002\n",
      "Epoch 2/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 160.6956 - val_loss: 44.0405\n",
      "Epoch 3/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 32.3415 - val_loss: 24.5678\n",
      "Epoch 4/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 25.2950 - val_loss: 19.6478\n",
      "Epoch 5/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 19.5768 - val_loss: 16.7377\n",
      "Epoch 6/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 16.3270 - val_loss: 15.0199\n",
      "Epoch 7/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 13.9575 - val_loss: 14.0380\n",
      "Epoch 8/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 12.9160 - val_loss: 13.8354\n",
      "Epoch 9/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 12.0989 - val_loss: 13.1347\n",
      "Epoch 10/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 12.0608 - val_loss: 13.1722\n",
      "Epoch 11/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 11.0290 - val_loss: 12.7736\n",
      "Epoch 12/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 11.0848 - val_loss: 13.1282\n",
      "Epoch 13/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 10.7938 - val_loss: 11.9987\n",
      "Epoch 14/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 10.4011 - val_loss: 13.2011\n",
      "Epoch 15/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 10.5809 - val_loss: 12.0740\n",
      "Epoch 16/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 10.2076 - val_loss: 13.5804\n",
      "Epoch 17/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 9.9545 - val_loss: 11.9306\n",
      "Epoch 18/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 9.7875 - val_loss: 12.0550\n",
      "Epoch 19/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 9.6395 - val_loss: 11.4202\n",
      "Epoch 20/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 9.3976 - val_loss: 12.0185\n",
      "Epoch 21/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 9.4652 - val_loss: 11.2407\n",
      "Epoch 22/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 9.3146 - val_loss: 11.3919\n",
      "Epoch 23/1000\n",
      "274/274 [==============================] - 0s 119us/step - loss: 9.2880 - val_loss: 11.3203\n",
      "Epoch 24/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 9.2444 - val_loss: 11.2287\n",
      "Epoch 25/1000\n",
      "274/274 [==============================] - 0s 117us/step - loss: 8.9254 - val_loss: 11.0508\n",
      "Epoch 26/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 8.8692 - val_loss: 10.9878\n",
      "Epoch 27/1000\n",
      "274/274 [==============================] - 0s 119us/step - loss: 8.9396 - val_loss: 10.6743\n",
      "Epoch 28/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 9.0195 - val_loss: 10.7592\n",
      "Epoch 29/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 8.7968 - val_loss: 10.7250\n",
      "Epoch 30/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 8.7790 - val_loss: 10.8328\n",
      "Epoch 31/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 8.7566 - val_loss: 11.2273\n",
      "Epoch 32/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.7534 - val_loss: 11.0549\n",
      "Epoch 33/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.8276 - val_loss: 10.5398\n",
      "Epoch 34/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 8.7818 - val_loss: 10.1838\n",
      "Epoch 35/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 8.3631 - val_loss: 10.3402\n",
      "Epoch 36/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.5719 - val_loss: 10.3451\n",
      "Epoch 37/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.5796 - val_loss: 10.6979\n",
      "Epoch 38/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.5599 - val_loss: 10.1444\n",
      "Epoch 39/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.4400 - val_loss: 9.9927\n",
      "Epoch 40/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 8.986 - 0s 94us/step - loss: 8.2965 - val_loss: 10.1719\n",
      "Epoch 41/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.4208 - val_loss: 10.1230\n",
      "Epoch 42/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 8.4249 - val_loss: 9.8084\n",
      "Epoch 43/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.2536 - val_loss: 9.6789\n",
      "Epoch 44/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.2853 - val_loss: 9.6923\n",
      "Epoch 45/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.0310 - val_loss: 9.6056\n",
      "Epoch 46/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.0727 - val_loss: 9.6602\n",
      "Epoch 47/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.1275 - val_loss: 9.6624\n",
      "Epoch 48/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.8731 - val_loss: 9.6146\n",
      "Epoch 49/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 8.0397 - val_loss: 9.5891\n",
      "Epoch 50/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 8.2128 - val_loss: 9.3035\n",
      "Epoch 51/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 7.8855 - val_loss: 8.9323\n",
      "Epoch 52/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.7947 - val_loss: 9.2296\n",
      "Epoch 53/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.8403 - val_loss: 9.2994\n",
      "Epoch 54/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 8.0141 - val_loss: 9.3658\n",
      "Epoch 55/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.9811 - val_loss: 8.7847\n",
      "Epoch 56/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.9824 - val_loss: 9.1124\n",
      "Epoch 57/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 8.1314 - val_loss: 9.0149\n",
      "Epoch 58/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.8552 - val_loss: 8.9410\n",
      "Epoch 59/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.6686 - val_loss: 8.8366\n",
      "Epoch 60/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.6661 - val_loss: 8.6100\n",
      "Epoch 61/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 7.6723 - val_loss: 8.7209\n",
      "Epoch 62/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.7919 - val_loss: 9.2067\n",
      "Epoch 63/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 7.8253 - val_loss: 8.9870\n",
      "Epoch 64/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 8.0523 - val_loss: 8.6700\n",
      "Epoch 65/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.7576 - val_loss: 8.7427\n",
      "Epoch 66/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.7268 - val_loss: 8.5185\n",
      "Epoch 67/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.7069 - val_loss: 8.4048\n",
      "Epoch 68/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 101us/step - loss: 8.4689 - val_loss: 9.6043\n",
      "Epoch 69/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 8.4467 - val_loss: 9.2779\n",
      "Epoch 70/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 8.2216 - val_loss: 9.2966\n",
      "Epoch 71/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 8.1003 - val_loss: 8.8309\n",
      "Epoch 72/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 7.8168 - val_loss: 8.9561\n",
      "Epoch 73/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 7.5156 - val_loss: 8.5741\n",
      "Epoch 74/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.6966 - val_loss: 8.2728\n",
      "Epoch 75/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 7.6774 - val_loss: 8.2708\n",
      "Epoch 76/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.6060 - val_loss: 8.4678\n",
      "Epoch 77/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.5076 - val_loss: 8.5431\n",
      "Epoch 78/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.4939 - val_loss: 8.2660\n",
      "Epoch 79/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.4531 - val_loss: 8.5308\n",
      "Epoch 80/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 7.3284 - val_loss: 8.2953\n",
      "Epoch 81/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.3092 - val_loss: 8.2760\n",
      "Epoch 82/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 7.2853 - val_loss: 8.2836\n",
      "Epoch 83/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3906 - val_loss: 8.3710\n",
      "Epoch 84/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 7.2499 - val_loss: 8.1364\n",
      "Epoch 85/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 7.4140 - val_loss: 8.4403\n",
      "Epoch 86/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 7.5537 - val_loss: 8.3859\n",
      "Epoch 87/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 7.2290 - val_loss: 8.4003\n",
      "Epoch 88/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 7.4252 - val_loss: 8.2065\n",
      "Epoch 89/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 7.2797 - val_loss: 8.2853\n",
      "Epoch 90/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.1996 - val_loss: 8.3923\n",
      "Epoch 91/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.2695 - val_loss: 8.4354\n",
      "Epoch 92/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.3594 - val_loss: 8.5407\n",
      "Epoch 93/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.4977 - val_loss: 8.2307\n",
      "Epoch 94/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.3359 - val_loss: 8.2699\n",
      "Epoch 95/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 7.3818 - val_loss: 8.3005\n",
      "Epoch 96/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 7.2472 - val_loss: 8.2384\n",
      "Epoch 97/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 7.2307 - val_loss: 8.1805\n",
      "Epoch 98/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 7.4353 - val_loss: 8.3782\n",
      "Epoch 99/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 7.4175 - val_loss: 8.3388\n",
      "Epoch 100/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.2581 - val_loss: 8.3629\n",
      "Epoch 101/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1839 - val_loss: 8.4524\n",
      "Epoch 102/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.3486 - val_loss: 8.5434\n",
      "Epoch 103/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.2394 - val_loss: 8.4815\n",
      "Epoch 104/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.2475 - val_loss: 8.3894\n",
      "Epoch 105/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 7.1487 - val_loss: 8.2778\n",
      "Epoch 106/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.0078 - val_loss: 8.0697\n",
      "Epoch 107/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0557 - val_loss: 8.1107\n",
      "Epoch 108/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.1259 - val_loss: 8.2146\n",
      "Epoch 109/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1890 - val_loss: 8.3427\n",
      "Epoch 110/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.1946 - val_loss: 8.1130\n",
      "Epoch 111/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.1827 - val_loss: 8.1625\n",
      "Epoch 112/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.0773 - val_loss: 8.3002\n",
      "Epoch 113/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0923 - val_loss: 8.1914\n",
      "Epoch 114/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 7.0849 - val_loss: 8.4299\n",
      "Epoch 115/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 7.0033 - val_loss: 8.4806\n",
      "Epoch 116/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9981 - val_loss: 8.2032\n",
      "Epoch 117/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0340 - val_loss: 8.4172\n",
      "Epoch 118/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1390 - val_loss: 8.5352\n",
      "Epoch 119/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.9871 - val_loss: 8.2901\n",
      "Epoch 120/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9964 - val_loss: 8.3333\n",
      "Epoch 121/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9930 - val_loss: 8.3838\n",
      "Epoch 122/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0694 - val_loss: 8.7228\n",
      "Epoch 123/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1902 - val_loss: 8.5645\n",
      "Epoch 124/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.4624 - val_loss: 8.8097\n",
      "Epoch 125/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.2740 - val_loss: 8.1295\n",
      "Epoch 126/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0915 - val_loss: 8.6061\n",
      "Epoch 127/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.1520 - val_loss: 8.2667\n",
      "Epoch 128/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0195 - val_loss: 8.5131\n",
      "Epoch 129/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0082 - val_loss: 8.3893\n",
      "Epoch 130/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.9397 - val_loss: 8.3864\n",
      "Epoch 131/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8711 - val_loss: 8.6097\n",
      "Epoch 132/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.3531 - val_loss: 8.4962\n",
      "Epoch 133/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1103 - val_loss: 8.2097\n",
      "Epoch 134/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9505 - val_loss: 8.5293\n",
      "Epoch 135/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.1111 - val_loss: 8.2901\n",
      "Epoch 136/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0085 - val_loss: 8.4369\n",
      "Epoch 137/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9384 - val_loss: 8.4413\n",
      "Epoch 138/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 7.0632 - val_loss: 8.4406\n",
      "Epoch 139/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1118 - val_loss: 8.4755\n",
      "Epoch 140/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.9123 - val_loss: 8.4485\n",
      "Epoch 141/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 7.0820 - val_loss: 8.5202\n",
      "Epoch 142/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9964 - val_loss: 8.3091\n",
      "Epoch 143/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9393 - val_loss: 8.2900\n",
      "Epoch 144/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8316 - val_loss: 8.6540\n",
      "Epoch 145/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.0694 - val_loss: 8.7060\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 146/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1157 - val_loss: 8.6037\n",
      "Epoch 147/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9909 - val_loss: 8.4709\n",
      "Epoch 148/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 7.0222 - val_loss: 8.5409\n",
      "Epoch 149/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9586 - val_loss: 8.6266\n",
      "Epoch 150/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 7.0536 - val_loss: 8.4451\n",
      "Epoch 151/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.9981 - val_loss: 8.4790\n",
      "Epoch 152/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9580 - val_loss: 8.3536\n",
      "Epoch 153/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1358 - val_loss: 9.1408\n",
      "Epoch 154/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1556 - val_loss: 8.6246\n",
      "Epoch 155/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 6.8914 - val_loss: 8.5324\n",
      "Epoch 156/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 6.9429 - val_loss: 8.6145\n",
      "Epoch 157/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.9257 - val_loss: 8.5496\n",
      "Epoch 158/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.1227 - val_loss: 8.6636\n",
      "Epoch 159/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.2098 - val_loss: 8.6175\n",
      "Epoch 160/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.8397 - val_loss: 8.5702\n",
      "Epoch 161/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.7500 - val_loss: 8.5948\n",
      "Epoch 162/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.8893 - val_loss: 8.5625\n",
      "Epoch 163/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.9450 - val_loss: 8.5047\n",
      "Epoch 164/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 7.1884 - val_loss: 8.5539\n",
      "Epoch 165/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 7.0831 - val_loss: 8.6209\n",
      "Epoch 166/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9871 - val_loss: 8.7851\n",
      "Epoch 167/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 6.8309 - val_loss: 8.5771\n",
      "Epoch 168/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 7.1587 - val_loss: 8.8744\n",
      "Epoch 169/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.9770 - val_loss: 8.5845\n",
      "Epoch 170/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.8000 - val_loss: 8.6246\n",
      "Epoch 171/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.8159 - val_loss: 8.4676\n",
      "Epoch 172/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.7953 - val_loss: 8.6160\n",
      "Epoch 173/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.8364 - val_loss: 8.7774\n",
      "Epoch 174/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 6.9459 - val_loss: 8.9036\n",
      "Epoch 175/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9268 - val_loss: 8.6904\n",
      "Epoch 176/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1322 - val_loss: 8.7220\n",
      "Epoch 177/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 6.9551 - val_loss: 8.8925\n",
      "Epoch 178/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.7706 - val_loss: 8.7623\n",
      "Epoch 179/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 6.8503 - val_loss: 8.5239\n",
      "Epoch 180/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.7511 - val_loss: 8.8657\n",
      "Epoch 181/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.7855 - val_loss: 8.8357\n",
      "Epoch 182/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.7526 - val_loss: 8.6051\n",
      "Epoch 183/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.7087 - val_loss: 8.5109\n",
      "Epoch 184/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.8299 - val_loss: 8.8623\n",
      "Epoch 185/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.7156 - val_loss: 8.5678\n",
      "Epoch 186/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.7140 - val_loss: 9.1723\n",
      "Epoch 187/1000\n",
      "274/274 [==============================] - 0s 118us/step - loss: 6.9026 - val_loss: 9.0654\n",
      "Epoch 188/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.8307 - val_loss: 9.0417\n",
      "Epoch 189/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.8190 - val_loss: 8.5416\n",
      "Epoch 190/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.9722 - val_loss: 8.8705\n",
      "Epoch 191/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 6.7363 - val_loss: 8.6077\n",
      "Epoch 192/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.7979 - val_loss: 9.3257\n",
      "Epoch 193/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9826 - val_loss: 8.7295\n",
      "Epoch 194/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 6.8335 - val_loss: 9.2947\n",
      "Epoch 195/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7820 - val_loss: 8.7388\n",
      "Epoch 196/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.9378 - val_loss: 8.9686\n",
      "Epoch 197/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.6807 - val_loss: 8.5696\n",
      "Epoch 198/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.7857 - val_loss: 9.5876\n",
      "Epoch 199/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.1242 - val_loss: 9.1399\n",
      "Epoch 200/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 7.1328 - val_loss: 9.9453\n",
      "Epoch 201/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 7.1793 - val_loss: 8.9456\n",
      "Epoch 202/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.8616 - val_loss: 8.8583\n",
      "Epoch 203/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.7147 - val_loss: 8.8423\n",
      "Epoch 204/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7853 - val_loss: 8.8680\n",
      "Epoch 205/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9974 - val_loss: 9.1462\n",
      "Epoch 206/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.0158 - val_loss: 8.8002\n",
      "Epoch 207/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.7366 - val_loss: 9.1887\n",
      "Epoch 208/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 6.9901 - val_loss: 8.9214\n",
      "Epoch 209/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.7198 - val_loss: 8.8808\n",
      "Epoch 210/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.8952 - val_loss: 9.2780\n",
      "Epoch 211/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.7420 - val_loss: 8.7180\n",
      "Epoch 212/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 7.0056 - val_loss: 9.1685\n",
      "Epoch 213/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.6828 - val_loss: 9.0158\n",
      "Epoch 214/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6880 - val_loss: 9.0431\n",
      "Epoch 215/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.7294 - val_loss: 8.9577\n",
      "Epoch 216/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.7954 - val_loss: 9.0491\n",
      "Epoch 217/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6719 - val_loss: 9.2483\n",
      "Epoch 218/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7128 - val_loss: 9.2129\n",
      "Epoch 219/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6559 - val_loss: 9.1827\n",
      "Epoch 220/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8491 - val_loss: 9.2101\n",
      "Epoch 221/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.6626 - val_loss: 8.9482\n",
      "Epoch 222/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6600 - val_loss: 9.1627\n",
      "Epoch 223/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 97us/step - loss: 6.8588 - val_loss: 9.5371\n",
      "Epoch 224/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.9512 - val_loss: 9.3684\n",
      "Epoch 225/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.6528 - val_loss: 9.3135\n",
      "Epoch 226/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6051 - val_loss: 9.5144\n",
      "Epoch 227/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.7257 - val_loss: 9.0107\n",
      "Epoch 228/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.6502 - val_loss: 9.1345\n",
      "Epoch 229/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.5986 - val_loss: 8.9302\n",
      "Epoch 230/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5455 - val_loss: 9.1772\n",
      "Epoch 231/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5746 - val_loss: 9.3350\n",
      "Epoch 232/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7291 - val_loss: 9.5860\n",
      "Epoch 233/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.6167 - val_loss: 9.0686\n",
      "Epoch 234/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7561 - val_loss: 9.2006\n",
      "Epoch 235/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 9.666 - 0s 93us/step - loss: 6.5413 - val_loss: 9.0100\n",
      "Epoch 236/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6913 - val_loss: 9.5929\n",
      "Epoch 237/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9267 - val_loss: 9.5849\n",
      "Epoch 238/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 6.9632 - val_loss: 10.0845\n",
      "Epoch 239/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 7.2516 - val_loss: 9.2265\n",
      "Epoch 240/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.9874 - val_loss: 9.3253\n",
      "Epoch 241/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7054 - val_loss: 9.4237\n",
      "Epoch 242/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5635 - val_loss: 9.1663\n",
      "Epoch 243/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5744 - val_loss: 9.4447\n",
      "Epoch 244/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0599 - val_loss: 9.3928\n",
      "Epoch 245/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7608 - val_loss: 9.3328\n",
      "Epoch 246/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 6.6200 - val_loss: 9.3188\n",
      "Epoch 247/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.5850 - val_loss: 9.1290\n",
      "Epoch 248/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7567 - val_loss: 9.7596\n",
      "Epoch 249/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9457 - val_loss: 9.0731\n",
      "Epoch 250/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.8426 - val_loss: 9.7058\n",
      "Epoch 251/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 7.2028 - val_loss: 9.4879\n",
      "Epoch 252/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7493 - val_loss: 9.6969\n",
      "Epoch 253/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6643 - val_loss: 9.2219\n",
      "Epoch 254/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6467 - val_loss: 9.2580\n",
      "Epoch 255/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9463 - val_loss: 9.5625\n",
      "Epoch 256/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.5835 - val_loss: 9.2558\n",
      "Epoch 257/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.9721 - val_loss: 10.5504\n",
      "Epoch 258/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.1317 - val_loss: 9.7672\n",
      "Epoch 259/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6328 - val_loss: 10.6134\n",
      "Epoch 260/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9380 - val_loss: 9.5044\n",
      "Epoch 261/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8070 - val_loss: 10.0725\n",
      "Epoch 262/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7304 - val_loss: 9.2989\n",
      "Epoch 263/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.5133 - val_loss: 9.5916\n",
      "Epoch 264/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5543 - val_loss: 9.4463\n",
      "Epoch 265/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.1013 - val_loss: 10.2102\n",
      "Epoch 266/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7184 - val_loss: 9.2589\n",
      "Epoch 267/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.6077 - val_loss: 9.3588\n",
      "Epoch 268/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.7527 - val_loss: 9.4569\n",
      "Epoch 269/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.8865 - val_loss: 10.1415\n",
      "Epoch 270/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.8442 - val_loss: 9.2345\n",
      "Epoch 271/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.6837 - val_loss: 10.3401\n",
      "Epoch 272/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9385 - val_loss: 9.2004\n",
      "Epoch 273/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6783 - val_loss: 9.6243\n",
      "Epoch 274/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6043 - val_loss: 9.5654\n",
      "Epoch 275/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5804 - val_loss: 9.3228\n",
      "Epoch 276/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5860 - val_loss: 9.3486\n",
      "Epoch 277/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5938 - val_loss: 9.2247\n",
      "Epoch 278/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9492 - val_loss: 9.2801\n",
      "Epoch 279/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.5620 - val_loss: 9.6659\n",
      "Epoch 280/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.5201 - val_loss: 9.3652\n",
      "Epoch 281/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.8015 - val_loss: 9.4917\n",
      "Epoch 282/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5002 - val_loss: 9.2885\n",
      "Epoch 283/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.7810 - val_loss: 10.0512\n",
      "Epoch 284/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.7272 - val_loss: 9.2867\n",
      "Epoch 285/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6571 - val_loss: 9.4296\n",
      "Epoch 286/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.9366 - val_loss: 9.7342\n",
      "Epoch 287/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.8290 - val_loss: 9.1262\n",
      "Epoch 288/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7702 - val_loss: 9.7579\n",
      "Epoch 289/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.5636 - val_loss: 9.3002\n",
      "Epoch 290/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6799 - val_loss: 9.8705\n",
      "Epoch 291/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9547 - val_loss: 9.4180\n",
      "Epoch 292/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.8910 - val_loss: 9.7070\n",
      "Epoch 293/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.6527 - val_loss: 9.4599\n",
      "Epoch 294/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.4959 - val_loss: 9.6874\n",
      "Epoch 295/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5628 - val_loss: 9.3643\n",
      "Epoch 296/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5131 - val_loss: 9.4663\n",
      "Epoch 297/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7736 - val_loss: 9.1964\n",
      "Epoch 298/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5191 - val_loss: 9.4814\n",
      "Epoch 299/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.7318 - val_loss: 9.3321\n",
      "Epoch 300/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 95us/step - loss: 6.7252 - val_loss: 9.3898\n",
      "Epoch 301/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5092 - val_loss: 9.2662\n",
      "Epoch 302/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6482 - val_loss: 9.3011\n",
      "Epoch 303/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4904 - val_loss: 9.3084\n",
      "Epoch 304/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4912 - val_loss: 9.5832\n",
      "Epoch 305/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.6955 - val_loss: 9.4231\n",
      "Epoch 306/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.5753 - val_loss: 9.3702\n",
      "Epoch 307/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4566 - val_loss: 9.3648\n",
      "Epoch 308/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.6721 - val_loss: 9.5947\n",
      "Epoch 309/1000\n",
      "274/274 [==============================] - 0s 115us/step - loss: 6.4228 - val_loss: 9.4443\n",
      "Epoch 310/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.7013 - val_loss: 9.6105\n",
      "Epoch 311/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4800 - val_loss: 9.3621\n",
      "Epoch 312/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.5244 - val_loss: 9.3315\n",
      "Epoch 313/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6048 - val_loss: 9.2652\n",
      "Epoch 314/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.5179 - val_loss: 9.1893\n",
      "Epoch 315/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6168 - val_loss: 9.0601\n",
      "Epoch 316/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.8272 - val_loss: 9.1539\n",
      "Epoch 317/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.5573 - val_loss: 9.5445\n",
      "Epoch 318/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7254 - val_loss: 9.3962\n",
      "Epoch 319/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.7477 - val_loss: 9.7037\n",
      "Epoch 320/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.5574 - val_loss: 9.4952\n",
      "Epoch 321/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.6014 - val_loss: 9.7144\n",
      "Epoch 322/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.4254 - val_loss: 9.2872\n",
      "Epoch 323/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.6646 - val_loss: 9.2460\n",
      "Epoch 324/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4338 - val_loss: 9.3966\n",
      "Epoch 325/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4324 - val_loss: 9.1953\n",
      "Epoch 326/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.6085 - val_loss: 9.3114\n",
      "Epoch 327/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.4188 - val_loss: 9.2662\n",
      "Epoch 328/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 6.5835 - val_loss: 9.3195\n",
      "Epoch 329/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5267 - val_loss: 9.0047\n",
      "Epoch 330/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5616 - val_loss: 9.2764\n",
      "Epoch 331/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.5541 - val_loss: 9.0633\n",
      "Epoch 332/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.6634 - val_loss: 9.1847\n",
      "Epoch 333/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8960 - val_loss: 9.7118\n",
      "Epoch 334/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 6.7725 - val_loss: 9.3418\n",
      "Epoch 335/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.9945 - val_loss: 9.0752\n",
      "Epoch 336/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 6.9357 - val_loss: 8.9540\n",
      "Epoch 337/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.7227 - val_loss: 9.0855\n",
      "Epoch 338/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.6931 - val_loss: 9.3189\n",
      "Epoch 339/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.4584 - val_loss: 9.0146\n",
      "Epoch 340/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.5425 - val_loss: 9.0953\n",
      "Epoch 341/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9342 - val_loss: 9.6304\n",
      "Epoch 342/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9630 - val_loss: 9.2890\n",
      "Epoch 343/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7827 - val_loss: 9.1790\n",
      "Epoch 344/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.5628 - val_loss: 9.1359\n",
      "Epoch 345/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.6322 - val_loss: 9.4676\n",
      "Epoch 346/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.7352 - val_loss: 9.0083\n",
      "Epoch 347/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5664 - val_loss: 9.1613\n",
      "Epoch 348/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6043 - val_loss: 8.9896\n",
      "Epoch 349/1000\n",
      "274/274 [==============================] - 0s 134us/step - loss: 6.7648 - val_loss: 9.5395\n",
      "Epoch 350/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.6345 - val_loss: 9.0373\n",
      "Epoch 351/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.4493 - val_loss: 9.1988\n",
      "Epoch 352/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.5609 - val_loss: 8.9894\n",
      "Epoch 353/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3967 - val_loss: 8.9713\n",
      "Epoch 354/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4303 - val_loss: 9.0697\n",
      "Epoch 355/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.5251 - val_loss: 9.2030\n",
      "Epoch 356/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5055 - val_loss: 9.0927\n",
      "Epoch 357/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8527 - val_loss: 9.3016\n",
      "Epoch 358/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8886 - val_loss: 8.9186\n",
      "Epoch 359/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4033 - val_loss: 9.2691\n",
      "Epoch 360/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.6381 - val_loss: 8.8020\n",
      "Epoch 361/1000\n",
      "274/274 [==============================] - 0s 117us/step - loss: 6.6501 - val_loss: 8.8348\n",
      "Epoch 362/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.5356 - val_loss: 9.2292\n",
      "Epoch 363/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.4426 - val_loss: 9.1247\n",
      "Epoch 364/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.6714 - val_loss: 9.6533\n",
      "Epoch 365/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6085 - val_loss: 8.8573\n",
      "Epoch 366/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.7004 - val_loss: 8.9678\n",
      "Epoch 367/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4158 - val_loss: 8.7774\n",
      "Epoch 368/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4117 - val_loss: 8.8173\n",
      "Epoch 369/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.4538 - val_loss: 8.7298\n",
      "Epoch 370/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3807 - val_loss: 8.6205\n",
      "Epoch 371/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.3646 - val_loss: 8.7082\n",
      "Epoch 372/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.4173 - val_loss: 8.7815\n",
      "Epoch 373/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.3469 - val_loss: 8.5422\n",
      "Epoch 374/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5548 - val_loss: 8.6533\n",
      "Epoch 375/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4388 - val_loss: 8.5383\n",
      "Epoch 376/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.4446 - val_loss: 8.6860\n",
      "Epoch 377/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 98us/step - loss: 6.4658 - val_loss: 8.6528\n",
      "Epoch 378/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4188 - val_loss: 8.7852\n",
      "Epoch 379/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.3922 - val_loss: 8.7857\n",
      "Epoch 380/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4416 - val_loss: 8.5557\n",
      "Epoch 381/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.3855 - val_loss: 8.5512\n",
      "Epoch 382/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4941 - val_loss: 8.6044\n",
      "Epoch 383/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7121 - val_loss: 9.0154\n",
      "Epoch 384/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3352 - val_loss: 8.5144\n",
      "Epoch 385/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5285 - val_loss: 9.1617\n",
      "Epoch 386/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.4605 - val_loss: 8.4286\n",
      "Epoch 387/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3628 - val_loss: 8.5512\n",
      "Epoch 388/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5687 - val_loss: 8.3539\n",
      "Epoch 389/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4561 - val_loss: 8.5381\n",
      "Epoch 390/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3883 - val_loss: 8.5601\n",
      "Epoch 391/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.5260 - val_loss: 8.7113\n",
      "Epoch 392/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.5779 - val_loss: 8.9855\n",
      "Epoch 393/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4151 - val_loss: 8.5723\n",
      "Epoch 394/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.5957 - val_loss: 8.9419\n",
      "Epoch 395/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.4513 - val_loss: 8.4834\n",
      "Epoch 396/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.5599 - val_loss: 8.3201\n",
      "Epoch 397/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5805 - val_loss: 8.4243\n",
      "Epoch 398/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 6.3791 - val_loss: 8.7159\n",
      "Epoch 399/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.3953 - val_loss: 8.4803\n",
      "Epoch 400/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.5051 - val_loss: 8.9095\n",
      "Epoch 401/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6767 - val_loss: 8.5183\n",
      "Epoch 402/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.3430 - val_loss: 8.7591\n",
      "Epoch 403/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3579 - val_loss: 8.6069\n",
      "Epoch 404/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5070 - val_loss: 8.7267\n",
      "Epoch 405/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5891 - val_loss: 8.7839\n",
      "Epoch 406/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.4520 - val_loss: 8.7268\n",
      "Epoch 407/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4282 - val_loss: 8.6984\n",
      "Epoch 408/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.3519 - val_loss: 8.4850\n",
      "Epoch 409/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4545 - val_loss: 8.4587\n",
      "Epoch 410/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.3671 - val_loss: 8.6432\n",
      "Epoch 411/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5359 - val_loss: 8.6608\n",
      "Epoch 412/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4792 - val_loss: 8.1500\n",
      "Epoch 413/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.4764 - val_loss: 8.3038\n",
      "Epoch 414/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.3713 - val_loss: 8.4087\n",
      "Epoch 415/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3909 - val_loss: 8.7068\n",
      "Epoch 416/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.3970 - val_loss: 8.7184\n",
      "Epoch 417/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.4457 - val_loss: 8.6571\n",
      "Epoch 418/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.6346 - val_loss: 8.8686\n",
      "Epoch 419/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3617 - val_loss: 8.4236\n",
      "Epoch 420/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.5714 - val_loss: 8.4561\n",
      "Epoch 421/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.3582 - val_loss: 8.2479\n",
      "Epoch 422/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2951 - val_loss: 8.5167\n",
      "Epoch 423/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.4350 - val_loss: 8.2937\n",
      "Epoch 424/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3556 - val_loss: 8.1574\n",
      "Epoch 425/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4735 - val_loss: 8.6920\n",
      "Epoch 426/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7063 - val_loss: 8.2882\n",
      "Epoch 427/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5902 - val_loss: 8.2726\n",
      "Epoch 428/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.5496 - val_loss: 8.2433\n",
      "Epoch 429/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.9323 - val_loss: 8.7236\n",
      "Epoch 430/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7834 - val_loss: 8.3874\n",
      "Epoch 431/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.5797 - val_loss: 8.4544\n",
      "Epoch 432/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5592 - val_loss: 8.2981\n",
      "Epoch 433/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4482 - val_loss: 8.3100\n",
      "Epoch 434/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3401 - val_loss: 8.2053\n",
      "Epoch 435/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5049 - val_loss: 8.3583\n",
      "Epoch 436/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3883 - val_loss: 8.5603\n",
      "Epoch 437/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3818 - val_loss: 8.6723\n",
      "Epoch 438/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4374 - val_loss: 8.4065\n",
      "Epoch 439/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3136 - val_loss: 8.3305\n",
      "Epoch 440/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3356 - val_loss: 8.4550\n",
      "Epoch 441/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.4740 - val_loss: 8.4036\n",
      "Epoch 442/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.5870 - val_loss: 8.7682\n",
      "Epoch 443/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.3608 - val_loss: 8.1983\n",
      "Epoch 444/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5146 - val_loss: 8.1732\n",
      "Epoch 445/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.3482 - val_loss: 8.2129\n",
      "Epoch 446/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3921 - val_loss: 8.2375\n",
      "Epoch 447/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.3085 - val_loss: 8.4286\n",
      "Epoch 448/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.4142 - val_loss: 8.3883\n",
      "Epoch 449/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.5322 - val_loss: 8.9184\n",
      "Epoch 450/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.8216 - val_loss: 8.1427\n",
      "Epoch 451/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3927 - val_loss: 8.2369\n",
      "Epoch 452/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3559 - val_loss: 8.3879\n",
      "Epoch 453/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4993 - val_loss: 8.3426\n",
      "Epoch 454/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5824 - val_loss: 8.4144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 455/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3551 - val_loss: 8.2204\n",
      "Epoch 456/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.3007 - val_loss: 8.4232\n",
      "Epoch 457/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.4101 - val_loss: 8.3682\n",
      "Epoch 458/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3597 - val_loss: 8.2622\n",
      "Epoch 459/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4168 - val_loss: 8.4500\n",
      "Epoch 460/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4445 - val_loss: 8.1684\n",
      "Epoch 461/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3635 - val_loss: 8.3342\n",
      "Epoch 462/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.3333 - val_loss: 8.5165\n",
      "Epoch 463/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.4317 - val_loss: 8.2298\n",
      "Epoch 464/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 6.4313 - val_loss: 8.2573\n",
      "Epoch 465/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3850 - val_loss: 8.2396\n",
      "Epoch 466/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2681 - val_loss: 8.2056\n",
      "Epoch 467/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.4003 - val_loss: 8.4214\n",
      "Epoch 468/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6681 - val_loss: 8.3107\n",
      "Epoch 469/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.5441 - val_loss: 8.8711\n",
      "Epoch 470/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4862 - val_loss: 8.3065\n",
      "Epoch 471/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4956 - val_loss: 9.0985\n",
      "Epoch 472/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9960 - val_loss: 8.6158\n",
      "Epoch 473/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6442 - val_loss: 8.6211\n",
      "Epoch 474/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5084 - val_loss: 8.3178\n",
      "Epoch 475/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3542 - val_loss: 8.2641\n",
      "Epoch 476/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3689 - val_loss: 8.3784\n",
      "Epoch 477/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.3088 - val_loss: 8.2017\n",
      "Epoch 478/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3448 - val_loss: 8.3645\n",
      "Epoch 479/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.5042 - val_loss: 8.2975\n",
      "Epoch 480/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6832 - val_loss: 9.1098\n",
      "Epoch 481/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5844 - val_loss: 8.5994\n",
      "Epoch 482/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.4146 - val_loss: 8.4768\n",
      "Epoch 483/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.2614 - val_loss: 8.3597\n",
      "Epoch 484/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 6.4158 - val_loss: 8.2350\n",
      "Epoch 485/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3180 - val_loss: 8.3226\n",
      "Epoch 486/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4064 - val_loss: 8.2581\n",
      "Epoch 487/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3726 - val_loss: 8.6930\n",
      "Epoch 488/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.3843 - val_loss: 8.2202\n",
      "Epoch 489/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3896 - val_loss: 8.2286\n",
      "Epoch 490/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2445 - val_loss: 8.1127\n",
      "Epoch 491/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3208 - val_loss: 8.4587\n",
      "Epoch 492/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3383 - val_loss: 8.2693\n",
      "Epoch 493/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.3011 - val_loss: 8.2057\n",
      "Epoch 494/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3935 - val_loss: 8.1888\n",
      "Epoch 495/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 6.3169 - val_loss: 8.4429\n",
      "Epoch 496/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4024 - val_loss: 8.3911\n",
      "Epoch 497/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.3346 - val_loss: 8.4877\n",
      "Epoch 498/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.3648 - val_loss: 8.2204\n",
      "Epoch 499/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.5635 - val_loss: 8.2514\n",
      "Epoch 500/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4153 - val_loss: 8.3063\n",
      "Epoch 501/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.4865 - val_loss: 8.2489\n",
      "Epoch 502/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3897 - val_loss: 8.3712\n",
      "Epoch 503/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4647 - val_loss: 8.6901\n",
      "Epoch 504/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4118 - val_loss: 8.4250\n",
      "Epoch 505/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.2879 - val_loss: 8.2516\n",
      "Epoch 506/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.4258 - val_loss: 8.3145\n",
      "Epoch 507/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.4277 - val_loss: 8.3549\n",
      "Epoch 508/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.7168 - val_loss: 8.2108\n",
      "Epoch 509/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4110 - val_loss: 8.5989\n",
      "Epoch 510/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3377 - val_loss: 8.0379\n",
      "Epoch 511/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3771 - val_loss: 8.7583\n",
      "Epoch 512/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5622 - val_loss: 8.1548\n",
      "Epoch 513/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4625 - val_loss: 8.2278\n",
      "Epoch 514/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3897 - val_loss: 8.1098\n",
      "Epoch 515/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4055 - val_loss: 8.3387\n",
      "Epoch 516/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.5126 - val_loss: 8.3129\n",
      "Epoch 517/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.5652 - val_loss: 8.3101\n",
      "Epoch 518/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3052 - val_loss: 8.1042\n",
      "Epoch 519/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3267 - val_loss: 8.4537\n",
      "Epoch 520/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3090 - val_loss: 8.1249\n",
      "Epoch 521/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.5132 - val_loss: 8.6595\n",
      "Epoch 522/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7763 - val_loss: 8.4757\n",
      "Epoch 523/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.8486 - val_loss: 8.9951\n",
      "Epoch 524/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6121 - val_loss: 7.9769\n",
      "Epoch 525/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2761 - val_loss: 8.5334\n",
      "Epoch 526/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3465 - val_loss: 8.1797\n",
      "Epoch 527/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3870 - val_loss: 8.0643\n",
      "Epoch 528/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2959 - val_loss: 8.3405\n",
      "Epoch 529/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.3441 - val_loss: 8.4627\n",
      "Epoch 530/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4687 - val_loss: 8.2853\n",
      "Epoch 531/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.3515 - val_loss: 8.2598\n",
      "Epoch 532/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.5536 - val_loss: 8.8839\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 533/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5530 - val_loss: 8.4582\n",
      "Epoch 534/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 6.3929 - val_loss: 8.2621\n",
      "Epoch 535/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4013 - val_loss: 8.1747\n",
      "Epoch 536/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4283 - val_loss: 8.4119\n",
      "Epoch 537/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3635 - val_loss: 8.2994\n",
      "Epoch 538/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3351 - val_loss: 8.2035\n",
      "Epoch 539/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3870 - val_loss: 8.3858\n",
      "Epoch 540/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4672 - val_loss: 8.5254\n",
      "Epoch 541/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4135 - val_loss: 8.2875\n",
      "Epoch 542/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3203 - val_loss: 8.0372\n",
      "Epoch 543/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.3135 - val_loss: 8.0999\n",
      "Epoch 544/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.3360 - val_loss: 8.0219\n",
      "Epoch 545/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2954 - val_loss: 8.2288\n",
      "Epoch 546/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.2798 - val_loss: 8.2092\n",
      "Epoch 547/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3775 - val_loss: 8.0514\n",
      "Epoch 548/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3208 - val_loss: 8.0122\n",
      "Epoch 549/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4992 - val_loss: 8.6737\n",
      "Epoch 550/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.3327 - val_loss: 8.1240\n",
      "Epoch 551/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.5247 - val_loss: 8.2427\n",
      "Epoch 552/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2690 - val_loss: 8.6842\n",
      "Epoch 553/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.4644 - val_loss: 8.1491\n",
      "Epoch 554/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.6377 - val_loss: 9.0857\n",
      "Epoch 555/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.6684 - val_loss: 8.0595\n",
      "Epoch 556/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5726 - val_loss: 8.6033\n",
      "Epoch 557/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3030 - val_loss: 8.3010\n",
      "Epoch 558/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2727 - val_loss: 8.2938\n",
      "Epoch 559/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4898 - val_loss: 7.9312\n",
      "Epoch 560/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.5190 - val_loss: 8.0418\n",
      "Epoch 561/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7521 - val_loss: 8.5054\n",
      "Epoch 562/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5055 - val_loss: 7.9889\n",
      "Epoch 563/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 6.5174 - val_loss: 8.2728\n",
      "Epoch 564/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3996 - val_loss: 8.0712\n",
      "Epoch 565/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3060 - val_loss: 7.9136\n",
      "Epoch 566/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3498 - val_loss: 8.0408\n",
      "Epoch 567/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2984 - val_loss: 8.3200\n",
      "Epoch 568/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3688 - val_loss: 8.1299\n",
      "Epoch 569/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.4799 - val_loss: 8.6186\n",
      "Epoch 570/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3670 - val_loss: 8.1313\n",
      "Epoch 571/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2939 - val_loss: 8.5765\n",
      "Epoch 572/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4731 - val_loss: 8.0045\n",
      "Epoch 573/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.4271 - val_loss: 7.9383\n",
      "Epoch 574/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6233 - val_loss: 8.1639\n",
      "Epoch 575/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5213 - val_loss: 8.2750\n",
      "Epoch 576/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4807 - val_loss: 8.2012\n",
      "Epoch 577/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3649 - val_loss: 8.4534\n",
      "Epoch 578/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.3100 - val_loss: 8.1184\n",
      "Epoch 579/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.3456 - val_loss: 8.1461\n",
      "Epoch 580/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.4419 - val_loss: 8.1698\n",
      "Epoch 581/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4125 - val_loss: 8.1766\n",
      "Epoch 582/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.4774 - val_loss: 8.5867\n",
      "Epoch 583/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 6.3643 - val_loss: 8.3261\n",
      "Epoch 584/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3050 - val_loss: 8.1067\n",
      "Epoch 585/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.3079 - val_loss: 8.3717\n",
      "Epoch 586/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3792 - val_loss: 8.2922\n",
      "Epoch 587/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.2404 - val_loss: 8.1605\n",
      "Epoch 588/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3264 - val_loss: 8.2070\n",
      "Epoch 589/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2768 - val_loss: 8.4038\n",
      "Epoch 590/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.4746 - val_loss: 8.0887\n",
      "Epoch 591/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.3695 - val_loss: 8.6452\n",
      "Epoch 592/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.6220 - val_loss: 8.0854\n",
      "Epoch 593/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3528 - val_loss: 8.0229\n",
      "Epoch 594/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3361 - val_loss: 8.2769\n",
      "Epoch 595/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4535 - val_loss: 7.9022\n",
      "Epoch 596/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3039 - val_loss: 8.1138\n",
      "Epoch 597/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.4551 - val_loss: 8.1360\n",
      "Epoch 598/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.7378 - val_loss: 8.1638\n",
      "Epoch 599/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.8497 - val_loss: 8.6241\n",
      "Epoch 600/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3195 - val_loss: 7.9745\n",
      "Epoch 601/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.2508 - val_loss: 8.3315\n",
      "Epoch 602/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3907 - val_loss: 8.0931\n",
      "Epoch 603/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4913 - val_loss: 8.3001\n",
      "Epoch 604/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8367 - val_loss: 8.1487\n",
      "Epoch 605/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6135 - val_loss: 8.0087\n",
      "Epoch 606/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3154 - val_loss: 8.2991\n",
      "Epoch 607/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.3350 - val_loss: 8.3812\n",
      "Epoch 608/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.3345 - val_loss: 8.0673\n",
      "Epoch 609/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3242 - val_loss: 8.0158\n",
      "Epoch 610/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.3213 - val_loss: 7.9897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 611/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.3885 - val_loss: 8.4648\n",
      "Epoch 612/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.3308 - val_loss: 8.1735\n",
      "Epoch 613/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.4295 - val_loss: 8.4358\n",
      "Epoch 614/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.3856 - val_loss: 7.9658\n",
      "Epoch 615/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.2849 - val_loss: 8.5517\n",
      "Epoch 616/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7457 - val_loss: 8.0149\n",
      "Epoch 617/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.3750 - val_loss: 8.1057\n",
      "Epoch 618/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.3247 - val_loss: 7.9232\n",
      "Epoch 619/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5219 - val_loss: 8.0571\n",
      "Epoch 620/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4750 - val_loss: 8.7453\n",
      "Epoch 621/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.4324 - val_loss: 8.0978\n",
      "Epoch 622/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5271 - val_loss: 8.5892\n",
      "Epoch 623/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.3722 - val_loss: 8.0870\n",
      "Epoch 624/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.3503 - val_loss: 8.0520\n",
      "Epoch 625/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.3536 - val_loss: 8.2032\n",
      "Epoch 626/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.2819 - val_loss: 8.6578\n",
      "Epoch 627/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.6427 - val_loss: 8.2257\n",
      "Epoch 628/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6180 - val_loss: 8.9715\n",
      "Epoch 629/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8359 - val_loss: 8.0123\n",
      "Epoch 630/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3508 - val_loss: 8.5689\n",
      "Epoch 631/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3455 - val_loss: 8.2497\n",
      "Epoch 632/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4831 - val_loss: 8.4769\n",
      "Epoch 633/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.3691 - val_loss: 8.0559\n",
      "Epoch 634/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2963 - val_loss: 8.1490\n",
      "Epoch 635/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.3648 - val_loss: 8.4646\n",
      "Epoch 636/1000\n",
      "274/274 [==============================] - 0s 123us/step - loss: 6.3413 - val_loss: 8.2670\n",
      "Epoch 637/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.3413 - val_loss: 8.2868\n",
      "Epoch 638/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.2988 - val_loss: 8.0285\n",
      "Epoch 639/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.3992 - val_loss: 8.2648\n",
      "Epoch 640/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3151 - val_loss: 8.0782\n",
      "Epoch 641/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.3621 - val_loss: 8.2086\n",
      "Epoch 642/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3288 - val_loss: 8.1046\n",
      "Epoch 643/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3199 - val_loss: 8.3028\n",
      "Epoch 644/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.3236 - val_loss: 7.9597\n",
      "Epoch 645/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3464 - val_loss: 8.2692\n",
      "Epoch 646/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.2779 - val_loss: 8.2303\n",
      "Epoch 647/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.4996 - val_loss: 8.0790\n",
      "Epoch 648/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4589 - val_loss: 8.7722\n",
      "Epoch 649/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5486 - val_loss: 8.3475\n",
      "Epoch 650/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3166 - val_loss: 8.6094\n",
      "Epoch 651/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4190 - val_loss: 8.0137\n",
      "Epoch 652/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3045 - val_loss: 8.3226\n",
      "Epoch 653/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4050 - val_loss: 8.5820\n",
      "Epoch 654/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.4492 - val_loss: 8.1756\n",
      "Epoch 655/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2663 - val_loss: 8.4233\n",
      "Epoch 656/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4077 - val_loss: 8.1385\n",
      "Epoch 657/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3560 - val_loss: 8.5912\n",
      "Epoch 658/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5390 - val_loss: 8.1813\n",
      "Epoch 659/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5997 - val_loss: 8.7194\n",
      "Epoch 660/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3145 - val_loss: 8.0856\n",
      "Epoch 661/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3399 - val_loss: 8.4748\n",
      "Epoch 662/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3041 - val_loss: 7.9693\n",
      "Epoch 663/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4679 - val_loss: 8.3045\n",
      "Epoch 664/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3142 - val_loss: 7.9009\n",
      "Epoch 665/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.8533 - val_loss: 7.9467\n",
      "Epoch 666/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.3853 - val_loss: 8.1764\n",
      "Epoch 667/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.2691 - val_loss: 8.1348\n",
      "Epoch 668/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.4725 - val_loss: 8.3546\n",
      "Epoch 669/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4704 - val_loss: 8.1092\n",
      "Epoch 670/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4952 - val_loss: 8.1819\n",
      "Epoch 671/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3091 - val_loss: 8.2310\n",
      "Epoch 672/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3449 - val_loss: 8.0184\n",
      "Epoch 673/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4086 - val_loss: 8.3268\n",
      "Epoch 674/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6166 - val_loss: 8.0449\n",
      "Epoch 675/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6740 - val_loss: 8.6436\n",
      "Epoch 676/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9515 - val_loss: 7.9625\n",
      "Epoch 677/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4300 - val_loss: 8.0706\n",
      "Epoch 678/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.6668 - val_loss: 8.5695\n",
      "Epoch 679/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.8308 - val_loss: 7.9380\n",
      "Epoch 680/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2665 - val_loss: 8.2688\n",
      "Epoch 681/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2803 - val_loss: 8.0522\n",
      "Epoch 682/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3258 - val_loss: 8.0640\n",
      "Epoch 683/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3320 - val_loss: 7.9024\n",
      "Epoch 684/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.4131 - val_loss: 7.9379\n",
      "Epoch 685/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3125 - val_loss: 8.1340\n",
      "Epoch 686/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.2651 - val_loss: 8.2841\n",
      "Epoch 687/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.3142 - val_loss: 8.2674\n",
      "Epoch 688/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 98us/step - loss: 6.5518 - val_loss: 8.3835\n",
      "Epoch 689/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.7520 - val_loss: 7.9745\n",
      "Epoch 690/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.3227 - val_loss: 8.3739\n",
      "Epoch 691/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.4103 - val_loss: 8.0389\n",
      "Epoch 692/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4443 - val_loss: 8.1653\n",
      "Epoch 693/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.3236 - val_loss: 8.1440\n",
      "Epoch 694/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.6811 - val_loss: 8.0874\n",
      "Epoch 695/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4387 - val_loss: 8.5930\n",
      "Epoch 696/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.4423 - val_loss: 7.9391\n",
      "Epoch 697/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2935 - val_loss: 7.9976\n",
      "Epoch 698/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5962 - val_loss: 7.9044\n",
      "Epoch 699/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.5924 - val_loss: 7.9721\n",
      "Epoch 700/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.4878 - val_loss: 8.3645\n",
      "Epoch 701/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3468 - val_loss: 8.1137\n",
      "Epoch 702/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.4834 - val_loss: 8.2476\n",
      "Epoch 703/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4657 - val_loss: 8.2886\n",
      "Epoch 704/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.4315 - val_loss: 8.0119\n",
      "Epoch 705/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4160 - val_loss: 8.4461\n",
      "Epoch 706/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.3979 - val_loss: 8.2511\n",
      "Epoch 707/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.3417 - val_loss: 8.6471\n",
      "Epoch 708/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3442 - val_loss: 7.9876\n",
      "Epoch 709/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8241 - val_loss: 8.0078\n",
      "Epoch 710/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0795 - val_loss: 9.2466\n",
      "Epoch 711/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2636 - val_loss: 8.4830\n",
      "Epoch 712/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0157 - val_loss: 9.0829\n",
      "Epoch 713/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.6777 - val_loss: 8.2510\n",
      "Epoch 714/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.5174 - val_loss: 8.2427\n",
      "Epoch 715/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3797 - val_loss: 8.0865\n",
      "Epoch 716/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.3810 - val_loss: 8.1166\n",
      "Epoch 717/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7906 - val_loss: 8.6626\n",
      "Epoch 718/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7293 - val_loss: 8.1095\n",
      "Epoch 719/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3196 - val_loss: 8.2404\n",
      "Epoch 720/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2549 - val_loss: 8.2710\n",
      "Epoch 721/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.3767 - val_loss: 8.0797\n",
      "Epoch 722/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4473 - val_loss: 8.6036\n",
      "Epoch 723/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.3777 - val_loss: 8.0031\n",
      "Epoch 724/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2714 - val_loss: 8.0334\n",
      "Epoch 725/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.2829 - val_loss: 8.0159\n",
      "Epoch 726/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.7182 - val_loss: 8.0895\n",
      "Epoch 727/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7559 - val_loss: 8.5186\n",
      "Epoch 728/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3971 - val_loss: 8.1583\n",
      "Epoch 729/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.3202 - val_loss: 8.1542\n",
      "Epoch 730/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.5209 - val_loss: 8.0481\n",
      "Epoch 731/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.8048 - val_loss: 8.6437\n",
      "Epoch 732/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.9844 - val_loss: 7.9106\n",
      "Epoch 733/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.4031 - val_loss: 8.5512\n",
      "Epoch 734/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6326 - val_loss: 8.1891\n",
      "Epoch 735/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.3111 - val_loss: 8.3132\n",
      "Epoch 736/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3062 - val_loss: 8.2167\n",
      "Epoch 737/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3311 - val_loss: 8.1911\n",
      "Epoch 738/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.5554 - val_loss: 8.0365\n",
      "Epoch 739/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.6696 - val_loss: 8.3878\n",
      "Epoch 740/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3651 - val_loss: 8.2260\n",
      "Epoch 741/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2759 - val_loss: 8.2852\n",
      "Epoch 742/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3618 - val_loss: 8.2397\n",
      "Epoch 743/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2881 - val_loss: 8.0534\n",
      "Epoch 744/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3489 - val_loss: 7.8940\n",
      "Epoch 745/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3145 - val_loss: 8.2114\n",
      "Epoch 746/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3305 - val_loss: 8.2177\n",
      "Epoch 747/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2533 - val_loss: 8.0160\n",
      "Epoch 748/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2878 - val_loss: 7.9809\n",
      "Epoch 749/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.2649 - val_loss: 8.2616\n",
      "Epoch 750/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4815 - val_loss: 7.9387\n",
      "Epoch 751/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3184 - val_loss: 8.0406\n",
      "Epoch 752/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.5679 - val_loss: 8.3281\n",
      "Epoch 753/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3949 - val_loss: 7.8368\n",
      "Epoch 754/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.3344 - val_loss: 8.3261\n",
      "Epoch 755/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4200 - val_loss: 7.8964\n",
      "Epoch 756/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.2585 - val_loss: 8.1630\n",
      "Epoch 757/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.3375 - val_loss: 7.9780\n",
      "Epoch 758/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6834 - val_loss: 8.2920\n",
      "Epoch 759/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.4959 - val_loss: 8.3152\n",
      "Epoch 760/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4205 - val_loss: 8.0390\n",
      "Epoch 761/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4980 - val_loss: 8.1701\n",
      "Epoch 762/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3331 - val_loss: 8.1354\n",
      "Epoch 763/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.3400 - val_loss: 8.0834\n",
      "Epoch 764/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2814 - val_loss: 7.9641\n",
      "Epoch 765/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.2685 - val_loss: 8.5699\n",
      "Epoch 766/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 98us/step - loss: 6.3040 - val_loss: 8.2366\n",
      "Epoch 767/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2793 - val_loss: 8.0616\n",
      "Epoch 768/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.4029 - val_loss: 8.4920\n",
      "Epoch 769/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.5423 - val_loss: 7.8756\n",
      "Epoch 770/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.4759 - val_loss: 8.2562\n",
      "Epoch 771/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.6452 - val_loss: 8.8481\n",
      "Epoch 772/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.4353 - val_loss: 8.0599\n",
      "Epoch 773/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3108 - val_loss: 8.2518\n",
      "Epoch 774/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.8991 - val_loss: 8.4306\n",
      "Epoch 775/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5235 - val_loss: 9.0716\n",
      "Epoch 776/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.3622 - val_loss: 8.1380\n",
      "Epoch 777/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.3089 - val_loss: 8.3141\n",
      "Epoch 778/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.4563 - val_loss: 8.1286\n",
      "Epoch 779/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.2855 - val_loss: 8.4260\n",
      "Epoch 780/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.3993 - val_loss: 8.1239\n",
      "Epoch 781/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5900 - val_loss: 8.0654\n",
      "Epoch 782/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.7195 - val_loss: 8.4096\n",
      "Epoch 783/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6516 - val_loss: 8.5708\n",
      "Epoch 784/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 6.6190 - val_loss: 8.0522\n",
      "Epoch 785/1000\n",
      "274/274 [==============================] - 0s 122us/step - loss: 6.3077 - val_loss: 8.3900\n",
      "Epoch 786/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.6884 - val_loss: 8.3335\n",
      "Epoch 787/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.3960 - val_loss: 8.4052\n",
      "Epoch 788/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 6.6228 - val_loss: 8.1103\n",
      "Epoch 789/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.2731 - val_loss: 8.5982\n",
      "Epoch 790/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 6.5678 - val_loss: 7.9393\n",
      "Epoch 791/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 6.6119 - val_loss: 8.4125\n",
      "Epoch 792/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.4610 - val_loss: 8.2338\n",
      "Epoch 793/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.4718 - val_loss: 8.6481\n",
      "Epoch 794/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.3400 - val_loss: 8.3001\n",
      "Epoch 795/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4039 - val_loss: 8.5767\n",
      "Epoch 796/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3795 - val_loss: 8.4545\n",
      "Epoch 797/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.5325 - val_loss: 8.6424\n",
      "Epoch 798/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.5109 - val_loss: 8.3802\n",
      "Epoch 799/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4529 - val_loss: 8.2092\n",
      "Epoch 800/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.6172 - val_loss: 8.7403\n",
      "Epoch 801/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2909 - val_loss: 7.9451\n",
      "Epoch 802/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.5045 - val_loss: 7.9912\n",
      "Epoch 803/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.4211 - val_loss: 8.5292\n",
      "Epoch 804/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.3721 - val_loss: 8.3325\n",
      "Epoch 805/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.2427 - val_loss: 8.2229\n",
      "Epoch 806/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4211 - val_loss: 8.0859\n",
      "Epoch 807/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.2328 - val_loss: 8.2990\n",
      "Epoch 808/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2860 - val_loss: 8.1686\n",
      "Epoch 809/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.2504 - val_loss: 8.0770\n",
      "Epoch 810/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3024 - val_loss: 8.0579\n",
      "Epoch 811/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.4057 - val_loss: 8.0189\n",
      "Epoch 812/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4852 - val_loss: 8.1107\n",
      "Epoch 813/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.4017 - val_loss: 8.2388\n",
      "Epoch 814/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8489 - val_loss: 7.9243\n",
      "Epoch 815/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.4964 - val_loss: 8.8248\n",
      "Epoch 816/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.8152 - val_loss: 8.1919\n",
      "Epoch 817/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.4190 - val_loss: 8.1813\n",
      "Epoch 818/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2973 - val_loss: 7.9439\n",
      "Epoch 819/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3197 - val_loss: 8.3341\n",
      "Epoch 820/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4442 - val_loss: 7.8881\n",
      "Epoch 821/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4675 - val_loss: 8.0235\n",
      "Epoch 822/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3288 - val_loss: 8.1857\n",
      "Epoch 823/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.5404 - val_loss: 8.8612\n",
      "Epoch 824/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3075 - val_loss: 8.2231\n",
      "Epoch 825/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.3446 - val_loss: 8.1990\n",
      "Epoch 826/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.2843 - val_loss: 8.1185\n",
      "Epoch 827/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3343 - val_loss: 8.3840\n",
      "Epoch 828/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4466 - val_loss: 8.1015\n",
      "Epoch 829/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3042 - val_loss: 8.3435\n",
      "Epoch 830/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3574 - val_loss: 8.1512\n",
      "Epoch 831/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.3355 - val_loss: 8.3385\n",
      "Epoch 832/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.3309 - val_loss: 8.1422\n",
      "Epoch 833/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3532 - val_loss: 8.2455\n",
      "Epoch 834/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2817 - val_loss: 8.1479\n",
      "Epoch 835/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2491 - val_loss: 7.9927\n",
      "Epoch 836/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.2586 - val_loss: 7.8187\n",
      "Epoch 837/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2576 - val_loss: 8.0535\n",
      "Epoch 838/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2669 - val_loss: 7.9704\n",
      "Epoch 839/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5230 - val_loss: 8.6128\n",
      "Epoch 840/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9275 - val_loss: 8.1710\n",
      "Epoch 841/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6322 - val_loss: 9.4517\n",
      "Epoch 842/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6789 - val_loss: 8.2074\n",
      "Epoch 843/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3572 - val_loss: 8.5286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 844/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3617 - val_loss: 8.1594\n",
      "Epoch 845/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3965 - val_loss: 8.0323\n",
      "Epoch 846/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2847 - val_loss: 8.0415\n",
      "Epoch 847/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.2777 - val_loss: 8.1078\n",
      "Epoch 848/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2526 - val_loss: 8.1283\n",
      "Epoch 849/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3275 - val_loss: 8.0066\n",
      "Epoch 850/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3828 - val_loss: 8.4928\n",
      "Epoch 851/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3399 - val_loss: 8.0423\n",
      "Epoch 852/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3225 - val_loss: 8.1765\n",
      "Epoch 853/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2265 - val_loss: 8.0456\n",
      "Epoch 854/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2745 - val_loss: 8.2695\n",
      "Epoch 855/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3280 - val_loss: 8.2878\n",
      "Epoch 856/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.3470 - val_loss: 7.8784\n",
      "Epoch 857/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4154 - val_loss: 8.4535\n",
      "Epoch 858/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.5971 - val_loss: 8.1417\n",
      "Epoch 859/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.4526 - val_loss: 8.0222\n",
      "Epoch 860/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.2778 - val_loss: 8.1819\n",
      "Epoch 861/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4084 - val_loss: 8.0254\n",
      "Epoch 862/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.4790 - val_loss: 8.1679\n",
      "Epoch 863/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.4392 - val_loss: 7.8757\n",
      "Epoch 864/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3858 - val_loss: 8.2962\n",
      "Epoch 865/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.4605 - val_loss: 8.0694\n",
      "Epoch 866/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3588 - val_loss: 8.2050\n",
      "Epoch 867/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.6667 - val_loss: 8.4775\n",
      "Epoch 868/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.3238 - val_loss: 8.2405\n",
      "Epoch 869/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.3055 - val_loss: 8.0666\n",
      "Epoch 870/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3189 - val_loss: 8.0172\n",
      "Epoch 871/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.2924 - val_loss: 8.0332\n",
      "Epoch 872/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2822 - val_loss: 8.0224\n",
      "Epoch 873/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2544 - val_loss: 8.0808\n",
      "Epoch 874/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.3091 - val_loss: 8.0106\n",
      "Epoch 875/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.3492 - val_loss: 8.4054\n",
      "Epoch 876/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.3724 - val_loss: 8.2432\n",
      "Epoch 877/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.4809 - val_loss: 8.2850\n",
      "Epoch 878/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.4531 - val_loss: 8.6951\n",
      "Epoch 879/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.7047 - val_loss: 8.0170\n",
      "Epoch 880/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.4826 - val_loss: 8.0621\n",
      "Epoch 881/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.6973 - val_loss: 8.3101\n",
      "Epoch 882/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.4340 - val_loss: 8.1553\n",
      "Epoch 883/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.3043 - val_loss: 8.0529\n",
      "Epoch 884/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.3859 - val_loss: 8.3883\n",
      "Epoch 885/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4996 - val_loss: 8.0328\n",
      "Epoch 886/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7643 - val_loss: 8.2302\n",
      "Epoch 887/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.2706 - val_loss: 8.1922\n",
      "Epoch 888/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2750 - val_loss: 7.9961\n",
      "Epoch 889/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.2730 - val_loss: 8.5024\n",
      "Epoch 890/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.3602 - val_loss: 8.0729\n",
      "Epoch 891/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4835 - val_loss: 8.4697\n",
      "Epoch 892/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4998 - val_loss: 8.0886\n",
      "Epoch 893/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4941 - val_loss: 8.6612\n",
      "Epoch 894/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.5124 - val_loss: 8.0746\n",
      "Epoch 895/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3016 - val_loss: 8.2962\n",
      "Epoch 896/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.3811 - val_loss: 7.8482\n",
      "Epoch 897/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4018 - val_loss: 8.5122\n",
      "Epoch 898/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.4815 - val_loss: 8.1231\n",
      "Epoch 899/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.2688 - val_loss: 8.2256\n",
      "Epoch 900/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 6.2877 - val_loss: 8.3466\n",
      "Epoch 901/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 6.2676 - val_loss: 8.4065\n",
      "Epoch 902/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 6.4996 - val_loss: 8.2852\n",
      "Epoch 903/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 6.4009 - val_loss: 7.8880\n",
      "Epoch 904/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 6.3327 - val_loss: 8.4903\n",
      "Epoch 905/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 6.2491 - val_loss: 7.8400\n",
      "Epoch 906/1000\n",
      "274/274 [==============================] - 0s 117us/step - loss: 6.3416 - val_loss: 8.4326\n",
      "Epoch 907/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 6.2437 - val_loss: 8.0002\n",
      "Epoch 908/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.4788 - val_loss: 8.4387\n",
      "Epoch 909/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3219 - val_loss: 7.9366\n",
      "Epoch 910/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6074 - val_loss: 8.2574\n",
      "Epoch 911/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.3357 - val_loss: 8.0283\n",
      "Epoch 912/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.3400 - val_loss: 8.3275\n",
      "Epoch 913/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5098 - val_loss: 9.1503\n",
      "Epoch 914/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4467 - val_loss: 8.1028\n",
      "Epoch 915/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.3072 - val_loss: 8.1764\n",
      "Epoch 916/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3998 - val_loss: 8.0367\n",
      "Epoch 917/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3201 - val_loss: 8.0692\n",
      "Epoch 918/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.2205 - val_loss: 8.0209\n",
      "Epoch 919/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.3116 - val_loss: 8.1784\n",
      "Epoch 920/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.2482 - val_loss: 8.1169\n",
      "Epoch 921/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.3000 - val_loss: 7.9484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 922/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.3382 - val_loss: 8.2212\n",
      "Epoch 923/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.3516 - val_loss: 8.0036\n",
      "Epoch 924/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3796 - val_loss: 8.6253\n",
      "Epoch 925/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.6311 - val_loss: 7.8749\n",
      "Epoch 926/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.2679 - val_loss: 8.4466\n",
      "Epoch 927/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4134 - val_loss: 8.0700\n",
      "Epoch 928/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.3779 - val_loss: 8.4009\n",
      "Epoch 929/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.4677 - val_loss: 8.5535\n",
      "Epoch 930/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.7375 - val_loss: 8.1301\n",
      "Epoch 931/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.3100 - val_loss: 8.1542\n",
      "Epoch 932/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.4165 - val_loss: 8.7435\n",
      "Epoch 933/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.6932 - val_loss: 8.0288\n",
      "Epoch 934/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.2805 - val_loss: 8.3338\n",
      "Epoch 935/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.4714 - val_loss: 8.0199\n",
      "Epoch 936/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3163 - val_loss: 8.2540\n",
      "Epoch 937/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.2440 - val_loss: 8.1165\n",
      "Epoch 938/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.3948 - val_loss: 8.3317\n",
      "Epoch 939/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3834 - val_loss: 8.2037\n",
      "Epoch 940/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4379 - val_loss: 8.9105\n",
      "Epoch 941/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5156 - val_loss: 7.9950\n",
      "Epoch 942/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.2950 - val_loss: 8.1616\n",
      "Epoch 943/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.2859 - val_loss: 8.1982\n",
      "Epoch 944/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2457 - val_loss: 8.1274\n",
      "Epoch 945/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3762 - val_loss: 8.1557\n",
      "Epoch 946/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2918 - val_loss: 8.8174\n",
      "Epoch 947/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4229 - val_loss: 7.9563\n",
      "Epoch 948/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.4652 - val_loss: 9.0474\n",
      "Epoch 949/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.4501 - val_loss: 8.3636\n",
      "Epoch 950/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1855 - val_loss: 8.5822\n",
      "Epoch 951/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.4007 - val_loss: 8.1680\n",
      "Epoch 952/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2420 - val_loss: 8.2163\n",
      "Epoch 953/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.3296 - val_loss: 8.2234\n",
      "Epoch 954/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3811 - val_loss: 8.0367\n",
      "Epoch 955/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3047 - val_loss: 8.1574\n",
      "Epoch 956/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3300 - val_loss: 8.0394\n",
      "Epoch 957/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.2664 - val_loss: 8.3420\n",
      "Epoch 958/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.2662 - val_loss: 8.2085\n",
      "Epoch 959/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4238 - val_loss: 8.1156\n",
      "Epoch 960/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2845 - val_loss: 8.2372\n",
      "Epoch 961/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2035 - val_loss: 8.3304\n",
      "Epoch 962/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3392 - val_loss: 8.1935\n",
      "Epoch 963/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4638 - val_loss: 8.5737\n",
      "Epoch 964/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.4984 - val_loss: 8.0770\n",
      "Epoch 965/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7632 - val_loss: 8.1047\n",
      "Epoch 966/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.5439 - val_loss: 8.3517\n",
      "Epoch 967/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.3752 - val_loss: 7.9868\n",
      "Epoch 968/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4688 - val_loss: 8.4797\n",
      "Epoch 969/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.3695 - val_loss: 8.0936\n",
      "Epoch 970/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7090 - val_loss: 8.6292\n",
      "Epoch 971/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3119 - val_loss: 8.3204\n",
      "Epoch 972/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.2693 - val_loss: 8.5826\n",
      "Epoch 973/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4112 - val_loss: 7.9492\n",
      "Epoch 974/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.5152 - val_loss: 8.4347\n",
      "Epoch 975/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6252 - val_loss: 8.2655\n",
      "Epoch 976/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4426 - val_loss: 9.0916\n",
      "Epoch 977/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.3978 - val_loss: 8.1577\n",
      "Epoch 978/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5190 - val_loss: 9.1154\n",
      "Epoch 979/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7590 - val_loss: 8.3626\n",
      "Epoch 980/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6820 - val_loss: 8.6559\n",
      "Epoch 981/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4157 - val_loss: 8.2021\n",
      "Epoch 982/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2727 - val_loss: 8.7394\n",
      "Epoch 983/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3315 - val_loss: 8.0877\n",
      "Epoch 984/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3493 - val_loss: 8.1354\n",
      "Epoch 985/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2959 - val_loss: 7.9798\n",
      "Epoch 986/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3480 - val_loss: 8.4552\n",
      "Epoch 987/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.2609 - val_loss: 8.1620\n",
      "Epoch 988/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.2847 - val_loss: 8.3433\n",
      "Epoch 989/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5799 - val_loss: 8.0329\n",
      "Epoch 990/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.5267 - val_loss: 8.3405\n",
      "Epoch 991/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.2922 - val_loss: 8.0545\n",
      "Epoch 992/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.4351 - val_loss: 8.0780\n",
      "Epoch 993/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3057 - val_loss: 8.5050\n",
      "Epoch 994/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.5157 - val_loss: 8.1640\n",
      "Epoch 995/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.9932 - val_loss: 8.8010\n",
      "Epoch 996/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.6392 - val_loss: 8.0866\n",
      "Epoch 997/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.2887 - val_loss: 8.0636\n",
      "Epoch 998/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2884 - val_loss: 8.3070\n",
      "Epoch 999/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.2669 - val_loss: 8.2874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3252 - val_loss: 8.0212\n",
      "6.623743453268277\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 1.1519048 ,  1.9469985 ,  0.77748704, -1.8380169 ,  0.05035699],\n",
       "        [ 3.1053884 , -1.3874804 , -0.29227594, -2.2102985 ,  0.80721176],\n",
       "        [ 0.9040128 ,  0.57624876,  0.42768708,  1.273199  ,  0.35806745],\n",
       "        [-1.3171207 , -1.370385  ,  0.29683948,  0.435508  ,  0.18232079],\n",
       "        [-0.34628305, -0.09797841, -0.43961844, -0.00622515,  0.21127266],\n",
       "        [ 0.83773345, -1.1131687 , -0.19748867, -1.5479099 ,  0.04522674],\n",
       "        [ 0.166191  ,  0.6960804 ,  0.53037554,  0.01583136, -0.40520555]],\n",
       "       dtype=float32),\n",
       " array([-1.714827  , -3.360453  , -0.51732796, -1.9062803 ,  0.22170988],\n",
       "       dtype=float32),\n",
       " array([[-0.45725298, -0.4331758 , -0.87771916, -0.7171167 , -0.6989963 ,\n",
       "         -0.02871859, -0.36303493, -0.17308082,  0.06540415, -0.47010872,\n",
       "         -0.9601795 , -0.00834028,  0.01108593,  0.7847459 ,  0.0597272 ],\n",
       "        [-0.5235261 , -0.33539498, -0.10342056, -0.5632162 , -0.6217276 ,\n",
       "         -0.1726563 ,  0.13050693, -0.3157251 ,  0.35382324, -0.55361766,\n",
       "          0.0524671 ,  0.6400289 , -0.37364015,  0.7889523 ,  0.00189383],\n",
       "        [ 0.91637516,  0.39570647,  0.5733142 ,  0.58802396,  0.32045087,\n",
       "         -0.13273206,  0.9407015 ,  0.07813764, -0.61687875,  0.04199496,\n",
       "          0.96016526, -0.6369279 , -0.03481144, -0.92713267, -0.34707808],\n",
       "        [ 0.45964387,  0.5085355 , -0.25204557, -0.06556829,  0.20655803,\n",
       "         -0.4651045 ,  0.63381135,  0.30118427, -0.5425389 , -0.395641  ,\n",
       "          0.04617511, -0.6751094 ,  0.06514984, -0.72068036, -0.2144338 ],\n",
       "        [ 1.2189198 ,  0.8696033 ,  0.8804992 ,  0.14361213,  0.3308087 ,\n",
       "         -1.0909172 ,  0.7679588 ,  0.5408324 , -0.6971441 ,  0.2383754 ,\n",
       "          0.7424917 , -0.87235105,  0.1351515 , -1.0473067 , -0.41545004]],\n",
       "       dtype=float32),\n",
       " array([-1.8021384 , -1.7525048 , -1.8102417 , -1.5145278 , -1.5493093 ,\n",
       "         1.696296  , -1.685811  , -1.6653976 ,  1.6479017 , -1.421979  ,\n",
       "        -1.7611507 ,  1.7210946 , -0.36592445,  1.834756  ,  1.6289068 ],\n",
       "       dtype=float32),\n",
       " array([[-1.3637328 ],\n",
       "        [-1.4029274 ],\n",
       "        [-1.0549928 ],\n",
       "        [-0.71042395],\n",
       "        [-0.6181944 ],\n",
       "        [ 1.2001112 ],\n",
       "        [-1.1807728 ],\n",
       "        [-0.84779924],\n",
       "        [ 0.63549006],\n",
       "        [-0.21720864],\n",
       "        [-1.1734945 ],\n",
       "        [ 0.92494994],\n",
       "        [-0.02603455],\n",
       "        [ 1.4326383 ],\n",
       "        [ 0.741822  ]], dtype=float32),\n",
       " array([1.6978128], dtype=float32)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_autompg, history_autompg, evaluate_autompg=NN_model_structure_regression_3(X_train_autompg, X_val_autompg, Y_train_autompg, Y_val_autompg, adam2, 32, 1000, x_test_autompg, y_test_autompg)\n",
    "model_autompg.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_autompg.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_autompg_structure3_4th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_28 (Dense)             (None, 10)                80        \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 141\n",
      "Trainable params: 141\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 274 samples, validate on 59 samples\n",
      "Epoch 1/1000\n",
      "274/274 [==============================] - 0s 951us/step - loss: 471.2951 - val_loss: 269.6836\n",
      "Epoch 2/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 159.0305 - val_loss: 93.2334\n",
      "Epoch 3/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 63.8767 - val_loss: 35.4327\n",
      "Epoch 4/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 25.7781 - val_loss: 24.0830\n",
      "Epoch 5/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 17.4810 - val_loss: 23.3526\n",
      "Epoch 6/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 15.9018 - val_loss: 19.1961\n",
      "Epoch 7/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 14.5474 - val_loss: 18.9389\n",
      "Epoch 8/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 14.0890 - val_loss: 18.3112\n",
      "Epoch 9/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 13.1845 - val_loss: 17.4105\n",
      "Epoch 10/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 12.4444 - val_loss: 17.1689\n",
      "Epoch 11/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 11.8286 - val_loss: 16.5293\n",
      "Epoch 12/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 11.6341 - val_loss: 15.8713\n",
      "Epoch 13/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 11.3281 - val_loss: 15.5193\n",
      "Epoch 14/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 10.7399 - val_loss: 14.5551\n",
      "Epoch 15/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 10.1317 - val_loss: 14.4589\n",
      "Epoch 16/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 9.9818 - val_loss: 13.9833\n",
      "Epoch 17/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 9.7451 - val_loss: 13.7849\n",
      "Epoch 18/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 9.4663 - val_loss: 13.3868\n",
      "Epoch 19/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 9.4144 - val_loss: 12.6071\n",
      "Epoch 20/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 9.3115 - val_loss: 12.3476\n",
      "Epoch 21/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 8.8689 - val_loss: 12.4210\n",
      "Epoch 22/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 8.6175 - val_loss: 12.5185\n",
      "Epoch 23/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.5526 - val_loss: 12.1139\n",
      "Epoch 24/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 8.3562 - val_loss: 11.8838\n",
      "Epoch 25/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 8.3346 - val_loss: 11.6407\n",
      "Epoch 26/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 8.2320 - val_loss: 11.1725\n",
      "Epoch 27/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.1781 - val_loss: 11.4551\n",
      "Epoch 28/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.0960 - val_loss: 11.2942\n",
      "Epoch 29/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.2045 - val_loss: 11.1873\n",
      "Epoch 30/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.1961 - val_loss: 10.6794\n",
      "Epoch 31/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.0025 - val_loss: 10.9213\n",
      "Epoch 32/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.8668 - val_loss: 10.9851\n",
      "Epoch 33/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 7.8961 - val_loss: 11.0574\n",
      "Epoch 34/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.8469 - val_loss: 10.7193\n",
      "Epoch 35/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.8609 - val_loss: 10.9754\n",
      "Epoch 36/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 7.7327 - val_loss: 10.5583\n",
      "Epoch 37/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.9129 - val_loss: 10.5211\n",
      "Epoch 38/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 8.3297 - val_loss: 11.1515\n",
      "Epoch 39/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 8.0776 - val_loss: 11.3527\n",
      "Epoch 40/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.6735 - val_loss: 10.9036\n",
      "Epoch 41/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.0438 - val_loss: 11.0945\n",
      "Epoch 42/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 7.7148 - val_loss: 10.6245\n",
      "Epoch 43/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.5043 - val_loss: 10.8048\n",
      "Epoch 44/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.5558 - val_loss: 10.3779\n",
      "Epoch 45/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.5638 - val_loss: 10.2424\n",
      "Epoch 46/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.5504 - val_loss: 10.8909\n",
      "Epoch 47/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.4686 - val_loss: 10.7737\n",
      "Epoch 48/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 7.4408 - val_loss: 10.6768\n",
      "Epoch 49/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.5006 - val_loss: 10.3732\n",
      "Epoch 50/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.3459 - val_loss: 10.3514\n",
      "Epoch 51/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 7.4106 - val_loss: 10.6430\n",
      "Epoch 52/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.5672 - val_loss: 10.5860\n",
      "Epoch 53/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 7.3739 - val_loss: 10.5402\n",
      "Epoch 54/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.3024 - val_loss: 10.1419\n",
      "Epoch 55/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.2399 - val_loss: 10.2250\n",
      "Epoch 56/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 7.3331 - val_loss: 10.3404\n",
      "Epoch 57/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.2622 - val_loss: 10.0527\n",
      "Epoch 58/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3431 - val_loss: 10.2190\n",
      "Epoch 59/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.2357 - val_loss: 10.1526\n",
      "Epoch 60/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 7.2534 - val_loss: 10.2687\n",
      "Epoch 61/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.3700 - val_loss: 10.3418\n",
      "Epoch 62/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.3461 - val_loss: 10.0661\n",
      "Epoch 63/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1977 - val_loss: 10.1374\n",
      "Epoch 64/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.2281 - val_loss: 9.8384\n",
      "Epoch 65/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0916 - val_loss: 10.0846\n",
      "Epoch 66/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.1509 - val_loss: 9.8573\n",
      "Epoch 67/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 6.9788 - val_loss: 9.6932\n",
      "Epoch 68/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 97us/step - loss: 6.8895 - val_loss: 9.7422\n",
      "Epoch 69/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.8869 - val_loss: 9.5671\n",
      "Epoch 70/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8456 - val_loss: 9.8965\n",
      "Epoch 71/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7809 - val_loss: 9.8021\n",
      "Epoch 72/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 7.2599 - val_loss: 9.1589\n",
      "Epoch 73/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.6546 - val_loss: 9.5621\n",
      "Epoch 74/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.8843 - val_loss: 9.0955\n",
      "Epoch 75/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0345 - val_loss: 9.1296\n",
      "Epoch 76/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.6923 - val_loss: 8.8619\n",
      "Epoch 77/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6104 - val_loss: 9.4614\n",
      "Epoch 78/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5056 - val_loss: 8.9924\n",
      "Epoch 79/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.4742 - val_loss: 8.8358\n",
      "Epoch 80/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6814 - val_loss: 8.3682\n",
      "Epoch 81/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0967 - val_loss: 9.3054\n",
      "Epoch 82/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6655 - val_loss: 8.8317\n",
      "Epoch 83/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.5065 - val_loss: 8.6478\n",
      "Epoch 84/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3386 - val_loss: 8.5698\n",
      "Epoch 85/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.4082 - val_loss: 8.7278\n",
      "Epoch 86/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.3502 - val_loss: 8.6091\n",
      "Epoch 87/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.2571 - val_loss: 8.8605\n",
      "Epoch 88/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.2564 - val_loss: 8.4865\n",
      "Epoch 89/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2540 - val_loss: 8.7037\n",
      "Epoch 90/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.2900 - val_loss: 8.5193\n",
      "Epoch 91/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.1333 - val_loss: 8.5733\n",
      "Epoch 92/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.1455 - val_loss: 8.6752\n",
      "Epoch 93/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2152 - val_loss: 8.4158\n",
      "Epoch 94/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1140 - val_loss: 8.5247\n",
      "Epoch 95/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.1343 - val_loss: 8.3477\n",
      "Epoch 96/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.0609 - val_loss: 8.4974\n",
      "Epoch 97/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4173 - val_loss: 8.8939\n",
      "Epoch 98/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.3974 - val_loss: 8.7191\n",
      "Epoch 99/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0664 - val_loss: 8.4897\n",
      "Epoch 100/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0094 - val_loss: 8.5675\n",
      "Epoch 101/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.0184 - val_loss: 8.7933\n",
      "Epoch 102/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0512 - val_loss: 8.3241\n",
      "Epoch 103/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8763 - val_loss: 8.4503\n",
      "Epoch 104/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.0321 - val_loss: 8.3044\n",
      "Epoch 105/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9389 - val_loss: 8.4207\n",
      "Epoch 106/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8652 - val_loss: 8.1859\n",
      "Epoch 107/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0610 - val_loss: 8.4703\n",
      "Epoch 108/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.0926 - val_loss: 8.7315\n",
      "Epoch 109/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1801 - val_loss: 8.1832\n",
      "Epoch 110/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9160 - val_loss: 8.4606\n",
      "Epoch 111/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8848 - val_loss: 8.1628\n",
      "Epoch 112/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8753 - val_loss: 8.1339\n",
      "Epoch 113/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8185 - val_loss: 8.4563\n",
      "Epoch 114/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8918 - val_loss: 8.2947\n",
      "Epoch 115/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.8494 - val_loss: 8.2146\n",
      "Epoch 116/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6748 - val_loss: 8.2341\n",
      "Epoch 117/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.7768 - val_loss: 8.5573\n",
      "Epoch 118/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7122 - val_loss: 8.2482\n",
      "Epoch 119/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6104 - val_loss: 8.3023\n",
      "Epoch 120/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5980 - val_loss: 8.5206\n",
      "Epoch 121/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.7650 - val_loss: 8.7309\n",
      "Epoch 122/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.7639 - val_loss: 8.3909\n",
      "Epoch 123/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4880 - val_loss: 8.2592\n",
      "Epoch 124/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.5499 - val_loss: 8.3417\n",
      "Epoch 125/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5337 - val_loss: 9.0440\n",
      "Epoch 126/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.6264 - val_loss: 8.6826\n",
      "Epoch 127/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.5613 - val_loss: 8.5493\n",
      "Epoch 128/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.3973 - val_loss: 8.7849\n",
      "Epoch 129/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4011 - val_loss: 8.9322\n",
      "Epoch 130/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4420 - val_loss: 8.7495\n",
      "Epoch 131/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 5.5018 - val_loss: 8.7421\n",
      "Epoch 132/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4574 - val_loss: 8.9894\n",
      "Epoch 133/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 5.4354 - val_loss: 8.7143\n",
      "Epoch 134/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4756 - val_loss: 8.7010\n",
      "Epoch 135/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3408 - val_loss: 8.8235\n",
      "Epoch 136/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.3951 - val_loss: 8.9008\n",
      "Epoch 137/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5230 - val_loss: 9.0844\n",
      "Epoch 138/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.5831 - val_loss: 9.2041\n",
      "Epoch 139/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.3925 - val_loss: 9.5671\n",
      "Epoch 140/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2938 - val_loss: 8.9113\n",
      "Epoch 141/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2000 - val_loss: 9.4169\n",
      "Epoch 142/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3839 - val_loss: 8.9742\n",
      "Epoch 143/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.2096 - val_loss: 8.8518\n",
      "Epoch 144/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3371 - val_loss: 9.1838\n",
      "Epoch 145/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4035 - val_loss: 8.8531\n",
      "Epoch 146/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 5.2321 - val_loss: 9.0671\n",
      "Epoch 147/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3918 - val_loss: 8.7617\n",
      "Epoch 148/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5135 - val_loss: 8.9917\n",
      "Epoch 149/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.3617 - val_loss: 9.1182\n",
      "Epoch 150/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.3986 - val_loss: 8.9629\n",
      "Epoch 151/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.3621 - val_loss: 8.8400\n",
      "Epoch 152/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.0916 - val_loss: 9.0955\n",
      "Epoch 153/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6988 - val_loss: 9.3879\n",
      "Epoch 154/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4487 - val_loss: 9.6753\n",
      "Epoch 155/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3687 - val_loss: 9.1187\n",
      "Epoch 156/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3930 - val_loss: 9.5919\n",
      "Epoch 157/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2605 - val_loss: 8.9394\n",
      "Epoch 158/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2397 - val_loss: 8.9052\n",
      "Epoch 159/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.0965 - val_loss: 9.4262\n",
      "Epoch 160/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.1442 - val_loss: 9.2645\n",
      "Epoch 161/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.1072 - val_loss: 9.4775\n",
      "Epoch 162/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.1528 - val_loss: 9.3509\n",
      "Epoch 163/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.1614 - val_loss: 9.0038\n",
      "Epoch 164/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1512 - val_loss: 9.1228\n",
      "Epoch 165/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.1838 - val_loss: 9.2816\n",
      "Epoch 166/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.1986 - val_loss: 9.2733\n",
      "Epoch 167/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3529 - val_loss: 9.9692\n",
      "Epoch 168/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2478 - val_loss: 9.3890\n",
      "Epoch 169/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5192 - val_loss: 10.1400\n",
      "Epoch 170/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2535 - val_loss: 9.4555\n",
      "Epoch 171/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.4538 - val_loss: 9.6001\n",
      "Epoch 172/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1387 - val_loss: 9.3403\n",
      "Epoch 173/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.0951 - val_loss: 9.4622\n",
      "Epoch 174/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.0495 - val_loss: 8.9417\n",
      "Epoch 175/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.2388 - val_loss: 9.3044\n",
      "Epoch 176/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.0221 - val_loss: 9.3418\n",
      "Epoch 177/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.9930 - val_loss: 9.3792\n",
      "Epoch 178/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1901 - val_loss: 10.2838\n",
      "Epoch 179/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3337 - val_loss: 9.2003\n",
      "Epoch 180/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1247 - val_loss: 9.1858\n",
      "Epoch 181/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1548 - val_loss: 9.3331\n",
      "Epoch 182/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0665 - val_loss: 9.4273\n",
      "Epoch 183/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.0632 - val_loss: 9.3814\n",
      "Epoch 184/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0893 - val_loss: 9.2082\n",
      "Epoch 185/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9616 - val_loss: 9.4126\n",
      "Epoch 186/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.0810 - val_loss: 9.5533\n",
      "Epoch 187/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.9534 - val_loss: 9.7373\n",
      "Epoch 188/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.0944 - val_loss: 9.3134\n",
      "Epoch 189/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1384 - val_loss: 9.3010\n",
      "Epoch 190/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.2257 - val_loss: 9.8639\n",
      "Epoch 191/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5064 - val_loss: 9.6652\n",
      "Epoch 192/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3576 - val_loss: 9.8178\n",
      "Epoch 193/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.0216 - val_loss: 9.2411\n",
      "Epoch 194/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1298 - val_loss: 9.5468\n",
      "Epoch 195/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9319 - val_loss: 9.3503\n",
      "Epoch 196/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9579 - val_loss: 9.4715\n",
      "Epoch 197/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.9630 - val_loss: 9.4436\n",
      "Epoch 198/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0156 - val_loss: 9.6049\n",
      "Epoch 199/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0250 - val_loss: 9.4549\n",
      "Epoch 200/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9972 - val_loss: 9.3156\n",
      "Epoch 201/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.9991 - val_loss: 9.4821\n",
      "Epoch 202/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0871 - val_loss: 9.6322\n",
      "Epoch 203/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.0746 - val_loss: 9.5930\n",
      "Epoch 204/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.0437 - val_loss: 9.7801\n",
      "Epoch 205/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9051 - val_loss: 9.4303\n",
      "Epoch 206/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.0853 - val_loss: 9.1966\n",
      "Epoch 207/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0330 - val_loss: 9.5452\n",
      "Epoch 208/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.0408 - val_loss: 9.5428\n",
      "Epoch 209/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1368 - val_loss: 9.9390\n",
      "Epoch 210/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.9917 - val_loss: 9.2236\n",
      "Epoch 211/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9389 - val_loss: 9.5619\n",
      "Epoch 212/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 4.9670 - val_loss: 9.4923\n",
      "Epoch 213/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0944 - val_loss: 9.8461\n",
      "Epoch 214/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9097 - val_loss: 9.1452\n",
      "Epoch 215/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.0517 - val_loss: 9.7863\n",
      "Epoch 216/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1187 - val_loss: 9.5338\n",
      "Epoch 217/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0807 - val_loss: 9.5277\n",
      "Epoch 218/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.9956 - val_loss: 9.9831\n",
      "Epoch 219/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.2009 - val_loss: 9.5015\n",
      "Epoch 220/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.0396 - val_loss: 10.2364\n",
      "Epoch 221/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2434 - val_loss: 9.5074\n",
      "Epoch 222/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0675 - val_loss: 9.3787\n",
      "Epoch 223/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9746 - val_loss: 9.5396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 224/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1244 - val_loss: 9.2635\n",
      "Epoch 225/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0326 - val_loss: 9.7648\n",
      "Epoch 226/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0231 - val_loss: 9.5821\n",
      "Epoch 227/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 4.9599 - val_loss: 10.5638\n",
      "Epoch 228/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2746 - val_loss: 9.1502\n",
      "Epoch 229/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.9046 - val_loss: 9.5121\n",
      "Epoch 230/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.8507 - val_loss: 9.4076\n",
      "Epoch 231/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9777 - val_loss: 9.5430\n",
      "Epoch 232/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9539 - val_loss: 9.4797\n",
      "Epoch 233/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.0063 - val_loss: 9.5771\n",
      "Epoch 234/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.8688 - val_loss: 9.4685\n",
      "Epoch 235/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9389 - val_loss: 9.5545\n",
      "Epoch 236/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.8058 - val_loss: 9.7032\n",
      "Epoch 237/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9308 - val_loss: 9.4935\n",
      "Epoch 238/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8227 - val_loss: 9.2878\n",
      "Epoch 239/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.9444 - val_loss: 9.7358\n",
      "Epoch 240/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.9598 - val_loss: 9.4820\n",
      "Epoch 241/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.7992 - val_loss: 9.4356\n",
      "Epoch 242/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8142 - val_loss: 9.8001\n",
      "Epoch 243/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9240 - val_loss: 9.6841\n",
      "Epoch 244/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9651 - val_loss: 9.5308\n",
      "Epoch 245/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9323 - val_loss: 10.1713\n",
      "Epoch 246/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 4.9182 - val_loss: 9.6299\n",
      "Epoch 247/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.8719 - val_loss: 9.8344\n",
      "Epoch 248/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.8928 - val_loss: 9.1928\n",
      "Epoch 249/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9257 - val_loss: 10.1507\n",
      "Epoch 250/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9680 - val_loss: 9.3355\n",
      "Epoch 251/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.8506 - val_loss: 9.8447\n",
      "Epoch 252/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.8480 - val_loss: 9.5316\n",
      "Epoch 253/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8297 - val_loss: 9.8202\n",
      "Epoch 254/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 4.7822 - val_loss: 9.3737\n",
      "Epoch 255/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8919 - val_loss: 9.3006\n",
      "Epoch 256/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0270 - val_loss: 9.7283\n",
      "Epoch 257/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 4.9459 - val_loss: 9.4230\n",
      "Epoch 258/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.9410 - val_loss: 9.6499\n",
      "Epoch 259/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.0391 - val_loss: 9.4395\n",
      "Epoch 260/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8335 - val_loss: 10.0221\n",
      "Epoch 261/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.8214 - val_loss: 9.3116\n",
      "Epoch 262/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.9514 - val_loss: 9.1067\n",
      "Epoch 263/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9784 - val_loss: 9.7711\n",
      "Epoch 264/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9626 - val_loss: 9.3006\n",
      "Epoch 265/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9396 - val_loss: 9.9537\n",
      "Epoch 266/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8312 - val_loss: 9.4194\n",
      "Epoch 267/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8729 - val_loss: 9.6558\n",
      "Epoch 268/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.9949 - val_loss: 9.5020\n",
      "Epoch 269/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8102 - val_loss: 9.3685\n",
      "Epoch 270/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.7478 - val_loss: 9.3951\n",
      "Epoch 271/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.7674 - val_loss: 9.6031\n",
      "Epoch 272/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7354 - val_loss: 9.3604\n",
      "Epoch 273/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7639 - val_loss: 9.2949\n",
      "Epoch 274/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7298 - val_loss: 9.5931\n",
      "Epoch 275/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7373 - val_loss: 9.7199\n",
      "Epoch 276/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9665 - val_loss: 9.4104\n",
      "Epoch 277/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0513 - val_loss: 9.5605\n",
      "Epoch 278/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 4.9189 - val_loss: 9.7543\n",
      "Epoch 279/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0138 - val_loss: 9.3137\n",
      "Epoch 280/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0261 - val_loss: 10.0475\n",
      "Epoch 281/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3192 - val_loss: 9.5324\n",
      "Epoch 282/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.9393 - val_loss: 10.5278\n",
      "Epoch 283/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7812 - val_loss: 9.3166\n",
      "Epoch 284/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1259 - val_loss: 10.2883\n",
      "Epoch 285/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0848 - val_loss: 9.5263\n",
      "Epoch 286/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8003 - val_loss: 10.0872\n",
      "Epoch 287/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.0649 - val_loss: 9.5891\n",
      "Epoch 288/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.0879 - val_loss: 10.7974\n",
      "Epoch 289/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1585 - val_loss: 9.6371\n",
      "Epoch 290/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.8629 - val_loss: 10.3171\n",
      "Epoch 291/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0196 - val_loss: 9.5093\n",
      "Epoch 292/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.7965 - val_loss: 9.5758\n",
      "Epoch 293/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 4.7459 - val_loss: 9.3967\n",
      "Epoch 294/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.7639 - val_loss: 9.7105\n",
      "Epoch 295/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8466 - val_loss: 9.3746\n",
      "Epoch 296/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9360 - val_loss: 9.9214\n",
      "Epoch 297/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.8635 - val_loss: 9.4158\n",
      "Epoch 298/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7644 - val_loss: 9.2364\n",
      "Epoch 299/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8561 - val_loss: 9.2834\n",
      "Epoch 300/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.8090 - val_loss: 9.9021\n",
      "Epoch 301/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 116us/step - loss: 4.8916 - val_loss: 9.7342\n",
      "Epoch 302/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.9480 - val_loss: 9.3759\n",
      "Epoch 303/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.9368 - val_loss: 10.1469\n",
      "Epoch 304/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9560 - val_loss: 9.3335\n",
      "Epoch 305/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2206 - val_loss: 9.7968\n",
      "Epoch 306/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.8569 - val_loss: 9.1291\n",
      "Epoch 307/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.7607 - val_loss: 9.5131\n",
      "Epoch 308/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.8003 - val_loss: 9.9401\n",
      "Epoch 309/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.7533 - val_loss: 9.2640\n",
      "Epoch 310/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.4206 - val_loss: 10.1015\n",
      "Epoch 311/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.8440 - val_loss: 9.5300\n",
      "Epoch 312/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.7219 - val_loss: 9.9359\n",
      "Epoch 313/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.6385 - val_loss: 9.4583\n",
      "Epoch 314/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.8943 - val_loss: 9.7432\n",
      "Epoch 315/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.7445 - val_loss: 9.5813\n",
      "Epoch 316/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.7424 - val_loss: 9.5457\n",
      "Epoch 317/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6804 - val_loss: 9.4874\n",
      "Epoch 318/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.8203 - val_loss: 9.4966\n",
      "Epoch 319/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.6857 - val_loss: 9.5794\n",
      "Epoch 320/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.8074 - val_loss: 9.6189\n",
      "Epoch 321/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.8133 - val_loss: 9.5681\n",
      "Epoch 322/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.7133 - val_loss: 9.5789\n",
      "Epoch 323/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7611 - val_loss: 9.3657\n",
      "Epoch 324/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.8265 - val_loss: 9.7231\n",
      "Epoch 325/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.9954 - val_loss: 9.7896\n",
      "Epoch 326/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.7226 - val_loss: 9.3441\n",
      "Epoch 327/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.7840 - val_loss: 9.6662\n",
      "Epoch 328/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.7417 - val_loss: 9.2476\n",
      "Epoch 329/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.8406 - val_loss: 10.1262\n",
      "Epoch 330/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.9226 - val_loss: 9.3785\n",
      "Epoch 331/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.9925 - val_loss: 9.6065\n",
      "Epoch 332/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7451 - val_loss: 9.3085\n",
      "Epoch 333/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7833 - val_loss: 9.6101\n",
      "Epoch 334/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.9757 - val_loss: 9.9422\n",
      "Epoch 335/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9012 - val_loss: 9.4683\n",
      "Epoch 336/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.7746 - val_loss: 9.7752\n",
      "Epoch 337/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7718 - val_loss: 9.7453\n",
      "Epoch 338/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.6759 - val_loss: 9.3480\n",
      "Epoch 339/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6891 - val_loss: 9.4955\n",
      "Epoch 340/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8343 - val_loss: 9.4675\n",
      "Epoch 341/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.7725 - val_loss: 9.7689\n",
      "Epoch 342/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.9620 - val_loss: 9.3363\n",
      "Epoch 343/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.9322 - val_loss: 9.9525\n",
      "Epoch 344/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.0155 - val_loss: 9.5276\n",
      "Epoch 345/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9340 - val_loss: 10.4609\n",
      "Epoch 346/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.8375 - val_loss: 9.3456\n",
      "Epoch 347/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 4.7498 - val_loss: 9.4687\n",
      "Epoch 348/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.2118 - val_loss: 10.3805\n",
      "Epoch 349/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0155 - val_loss: 9.3598\n",
      "Epoch 350/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9988 - val_loss: 9.4101\n",
      "Epoch 351/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.6975 - val_loss: 9.2951\n",
      "Epoch 352/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6735 - val_loss: 10.2590\n",
      "Epoch 353/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0385 - val_loss: 9.4474\n",
      "Epoch 354/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8089 - val_loss: 9.3354\n",
      "Epoch 355/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6784 - val_loss: 9.5334\n",
      "Epoch 356/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7207 - val_loss: 9.1473\n",
      "Epoch 357/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7124 - val_loss: 9.4281\n",
      "Epoch 358/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.7168 - val_loss: 9.2834\n",
      "Epoch 359/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.9077 - val_loss: 10.1441\n",
      "Epoch 360/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.7416 - val_loss: 9.1940\n",
      "Epoch 361/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.7104 - val_loss: 9.7137\n",
      "Epoch 362/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6642 - val_loss: 9.1565\n",
      "Epoch 363/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.1681 - val_loss: 10.3188\n",
      "Epoch 364/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.3369 - val_loss: 9.4745\n",
      "Epoch 365/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.1775 - val_loss: 9.8445\n",
      "Epoch 366/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.6725 - val_loss: 9.2449\n",
      "Epoch 367/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0172 - val_loss: 9.3768\n",
      "Epoch 368/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.7512 - val_loss: 9.9816\n",
      "Epoch 369/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.9570 - val_loss: 9.3051\n",
      "Epoch 370/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7457 - val_loss: 9.3418\n",
      "Epoch 371/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5109 - val_loss: 9.2617\n",
      "Epoch 372/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.6521 - val_loss: 9.8685\n",
      "Epoch 373/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7728 - val_loss: 9.3122\n",
      "Epoch 374/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.5758 - val_loss: 9.3210\n",
      "Epoch 375/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.6541 - val_loss: 9.5441\n",
      "Epoch 376/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.6929 - val_loss: 9.6877\n",
      "Epoch 377/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.6769 - val_loss: 9.2753\n",
      "Epoch 378/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 109us/step - loss: 4.5809 - val_loss: 9.6781\n",
      "Epoch 379/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.0277 - val_loss: 9.6865\n",
      "Epoch 380/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4262 - val_loss: 9.2451\n",
      "Epoch 381/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0032 - val_loss: 9.6383\n",
      "Epoch 382/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.5408 - val_loss: 9.2667\n",
      "Epoch 383/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5502 - val_loss: 9.8919\n",
      "Epoch 384/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.9582 - val_loss: 9.2529\n",
      "Epoch 385/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.5988 - val_loss: 9.7192\n",
      "Epoch 386/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.7321 - val_loss: 9.7028\n",
      "Epoch 387/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.6593 - val_loss: 9.2614\n",
      "Epoch 388/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5300 - val_loss: 9.5659\n",
      "Epoch 389/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.6642 - val_loss: 9.2620\n",
      "Epoch 390/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5918 - val_loss: 9.8062\n",
      "Epoch 391/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.5627 - val_loss: 9.4115\n",
      "Epoch 392/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.6569 - val_loss: 9.6885\n",
      "Epoch 393/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5611 - val_loss: 9.1317\n",
      "Epoch 394/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7939 - val_loss: 9.9094\n",
      "Epoch 395/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.6563 - val_loss: 9.1962\n",
      "Epoch 396/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.4818 - val_loss: 9.7296\n",
      "Epoch 397/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.4978 - val_loss: 9.3977\n",
      "Epoch 398/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.4579 - val_loss: 9.8012\n",
      "Epoch 399/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.5942 - val_loss: 9.2503\n",
      "Epoch 400/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8008 - val_loss: 10.4059\n",
      "Epoch 401/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8748 - val_loss: 9.2048\n",
      "Epoch 402/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 4.9006 - val_loss: 9.9063\n",
      "Epoch 403/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.8266 - val_loss: 8.9671\n",
      "Epoch 404/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.7252 - val_loss: 9.0484\n",
      "Epoch 405/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7488 - val_loss: 9.7306\n",
      "Epoch 406/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5967 - val_loss: 9.6784\n",
      "Epoch 407/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.4125 - val_loss: 9.4301\n",
      "Epoch 408/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.5668 - val_loss: 9.0417\n",
      "Epoch 409/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4241 - val_loss: 9.2135\n",
      "Epoch 410/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.3704 - val_loss: 9.2713\n",
      "Epoch 411/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3734 - val_loss: 9.2504\n",
      "Epoch 412/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3502 - val_loss: 9.1592\n",
      "Epoch 413/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.4599 - val_loss: 9.3909\n",
      "Epoch 414/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.4622 - val_loss: 9.2939\n",
      "Epoch 415/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3574 - val_loss: 9.4239\n",
      "Epoch 416/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3840 - val_loss: 9.1253\n",
      "Epoch 417/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.5309 - val_loss: 10.2870\n",
      "Epoch 418/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.6620 - val_loss: 9.1318\n",
      "Epoch 419/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.2969 - val_loss: 9.3681\n",
      "Epoch 420/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3572 - val_loss: 9.3238\n",
      "Epoch 421/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.4311 - val_loss: 9.3223\n",
      "Epoch 422/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.5686 - val_loss: 9.3244\n",
      "Epoch 423/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.6382 - val_loss: 9.1387\n",
      "Epoch 424/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4365 - val_loss: 8.9916\n",
      "Epoch 425/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.4215 - val_loss: 9.4454\n",
      "Epoch 426/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3072 - val_loss: 8.9575\n",
      "Epoch 427/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.3958 - val_loss: 9.7000\n",
      "Epoch 428/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 4.3430 - val_loss: 9.3615\n",
      "Epoch 429/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.5620 - val_loss: 9.3859\n",
      "Epoch 430/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.5219 - val_loss: 9.6440\n",
      "Epoch 431/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3090 - val_loss: 9.2398\n",
      "Epoch 432/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.4892 - val_loss: 10.0342\n",
      "Epoch 433/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.8716 - val_loss: 9.3418\n",
      "Epoch 434/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.4399 - val_loss: 9.5850\n",
      "Epoch 435/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4817 - val_loss: 9.1478\n",
      "Epoch 436/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.4257 - val_loss: 9.5836\n",
      "Epoch 437/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3757 - val_loss: 9.5960\n",
      "Epoch 438/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.4693 - val_loss: 9.2638\n",
      "Epoch 439/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3468 - val_loss: 9.8550\n",
      "Epoch 440/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.2672 - val_loss: 9.0333\n",
      "Epoch 441/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.6220 - val_loss: 9.0782\n",
      "Epoch 442/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.6260 - val_loss: 9.9820\n",
      "Epoch 443/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.6228 - val_loss: 8.9767\n",
      "Epoch 444/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5369 - val_loss: 10.0557\n",
      "Epoch 445/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6510 - val_loss: 9.2796\n",
      "Epoch 446/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.5100 - val_loss: 9.1609\n",
      "Epoch 447/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2494 - val_loss: 9.6333\n",
      "Epoch 448/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.4836 - val_loss: 9.4841\n",
      "Epoch 449/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.5296 - val_loss: 9.2402\n",
      "Epoch 450/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9058 - val_loss: 10.2397\n",
      "Epoch 451/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4577 - val_loss: 9.0078\n",
      "Epoch 452/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.3203 - val_loss: 9.4663\n",
      "Epoch 453/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3982 - val_loss: 9.3606\n",
      "Epoch 454/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.2777 - val_loss: 9.4254\n",
      "Epoch 455/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 91us/step - loss: 4.2462 - val_loss: 9.0670\n",
      "Epoch 456/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2331 - val_loss: 9.4494\n",
      "Epoch 457/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.3959 - val_loss: 9.2438\n",
      "Epoch 458/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2424 - val_loss: 10.0252\n",
      "Epoch 459/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3661 - val_loss: 9.3787\n",
      "Epoch 460/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3133 - val_loss: 8.7412\n",
      "Epoch 461/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.4489 - val_loss: 9.3340\n",
      "Epoch 462/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4544 - val_loss: 9.4457\n",
      "Epoch 463/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 4.2901 - val_loss: 9.5993\n",
      "Epoch 464/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2567 - val_loss: 9.1030\n",
      "Epoch 465/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.3472 - val_loss: 9.4260\n",
      "Epoch 466/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3490 - val_loss: 9.2641\n",
      "Epoch 467/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4250 - val_loss: 9.1518\n",
      "Epoch 468/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.5983 - val_loss: 10.8066\n",
      "Epoch 469/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5865 - val_loss: 9.3347\n",
      "Epoch 470/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.5541 - val_loss: 10.8711\n",
      "Epoch 471/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0119 - val_loss: 9.2541\n",
      "Epoch 472/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3417 - val_loss: 10.7068\n",
      "Epoch 473/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.6257 - val_loss: 9.1291\n",
      "Epoch 474/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.7610 - val_loss: 9.3376\n",
      "Epoch 475/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3860 - val_loss: 9.1969\n",
      "Epoch 476/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4159 - val_loss: 9.1592\n",
      "Epoch 477/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2552 - val_loss: 9.2075\n",
      "Epoch 478/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.2761 - val_loss: 9.2943\n",
      "Epoch 479/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.2904 - val_loss: 8.9280\n",
      "Epoch 480/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3604 - val_loss: 10.1089\n",
      "Epoch 481/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3911 - val_loss: 9.2267\n",
      "Epoch 482/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5303 - val_loss: 10.4862\n",
      "Epoch 483/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.5534 - val_loss: 9.3606\n",
      "Epoch 484/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.2356 - val_loss: 9.6467\n",
      "Epoch 485/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1962 - val_loss: 9.2207\n",
      "Epoch 486/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 4.2898 - val_loss: 9.6540\n",
      "Epoch 487/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.2468 - val_loss: 9.3464\n",
      "Epoch 488/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2260 - val_loss: 8.9514\n",
      "Epoch 489/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2340 - val_loss: 9.7825\n",
      "Epoch 490/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3166 - val_loss: 9.0995\n",
      "Epoch 491/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.1549 - val_loss: 9.5591\n",
      "Epoch 492/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.2185 - val_loss: 9.6405\n",
      "Epoch 493/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.1848 - val_loss: 9.5091\n",
      "Epoch 494/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.3328 - val_loss: 9.0011\n",
      "Epoch 495/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4088 - val_loss: 9.8290\n",
      "Epoch 496/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3346 - val_loss: 9.8207\n",
      "Epoch 497/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.1952 - val_loss: 9.2050\n",
      "Epoch 498/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.4563 - val_loss: 9.4096\n",
      "Epoch 499/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.2972 - val_loss: 9.1773\n",
      "Epoch 500/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.2592 - val_loss: 10.1605\n",
      "Epoch 501/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4815 - val_loss: 9.2926\n",
      "Epoch 502/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2576 - val_loss: 9.9392\n",
      "Epoch 503/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3796 - val_loss: 8.9707\n",
      "Epoch 504/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2094 - val_loss: 10.0226\n",
      "Epoch 505/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.1784 - val_loss: 9.4827\n",
      "Epoch 506/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1795 - val_loss: 10.2541\n",
      "Epoch 507/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2446 - val_loss: 9.1326\n",
      "Epoch 508/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.2121 - val_loss: 9.9377\n",
      "Epoch 509/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2921 - val_loss: 9.3436\n",
      "Epoch 510/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2740 - val_loss: 9.8263\n",
      "Epoch 511/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 4.3513 - val_loss: 9.3547\n",
      "Epoch 512/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3866 - val_loss: 9.7580\n",
      "Epoch 513/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2143 - val_loss: 9.3036\n",
      "Epoch 514/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2430 - val_loss: 9.4151\n",
      "Epoch 515/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1534 - val_loss: 9.6387\n",
      "Epoch 516/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.2253 - val_loss: 9.3151\n",
      "Epoch 517/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0764 - val_loss: 9.5149\n",
      "Epoch 518/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1820 - val_loss: 9.2699\n",
      "Epoch 519/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2850 - val_loss: 9.2158\n",
      "Epoch 520/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.2817 - val_loss: 10.2188\n",
      "Epoch 521/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3159 - val_loss: 9.3875\n",
      "Epoch 522/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.3242 - val_loss: 9.5916\n",
      "Epoch 523/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1150 - val_loss: 9.4451\n",
      "Epoch 524/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2133 - val_loss: 9.2750\n",
      "Epoch 525/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3522 - val_loss: 9.6380\n",
      "Epoch 526/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2965 - val_loss: 9.1791\n",
      "Epoch 527/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1806 - val_loss: 9.7644\n",
      "Epoch 528/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.1589 - val_loss: 9.4536\n",
      "Epoch 529/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2868 - val_loss: 10.1482\n",
      "Epoch 530/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1856 - val_loss: 9.2574\n",
      "Epoch 531/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1545 - val_loss: 9.3415\n",
      "Epoch 532/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 98us/step - loss: 4.3206 - val_loss: 9.4156\n",
      "Epoch 533/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.5003 - val_loss: 10.4764\n",
      "Epoch 534/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 4.5604 - val_loss: 9.3595\n",
      "Epoch 535/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6261 - val_loss: 10.8340\n",
      "Epoch 536/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8419 - val_loss: 9.4569\n",
      "Epoch 537/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4531 - val_loss: 9.8514\n",
      "Epoch 538/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4320 - val_loss: 9.5988\n",
      "Epoch 539/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0264 - val_loss: 10.3436\n",
      "Epoch 540/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.2414 - val_loss: 9.4968\n",
      "Epoch 541/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1093 - val_loss: 9.6469\n",
      "Epoch 542/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.1210 - val_loss: 9.0568\n",
      "Epoch 543/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.1897 - val_loss: 9.2754\n",
      "Epoch 544/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.5267 - val_loss: 11.1143\n",
      "Epoch 545/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.7245 - val_loss: 10.0028\n",
      "Epoch 546/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.8101 - val_loss: 9.8240\n",
      "Epoch 547/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2595 - val_loss: 9.3887\n",
      "Epoch 548/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2095 - val_loss: 9.1304\n",
      "Epoch 549/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2285 - val_loss: 9.4601\n",
      "Epoch 550/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.0884 - val_loss: 9.0826\n",
      "Epoch 551/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0429 - val_loss: 9.5811\n",
      "Epoch 552/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1231 - val_loss: 9.5705\n",
      "Epoch 553/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.0941 - val_loss: 9.6571\n",
      "Epoch 554/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.1371 - val_loss: 9.5748\n",
      "Epoch 555/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.2801 - val_loss: 9.1602\n",
      "Epoch 556/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2809 - val_loss: 9.4568\n",
      "Epoch 557/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4813 - val_loss: 10.4027\n",
      "Epoch 558/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.3428 - val_loss: 9.1685\n",
      "Epoch 559/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1926 - val_loss: 9.5583\n",
      "Epoch 560/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.1203 - val_loss: 9.3108\n",
      "Epoch 561/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2241 - val_loss: 9.5776\n",
      "Epoch 562/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.4158 - val_loss: 10.9100\n",
      "Epoch 563/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.3783 - val_loss: 9.7348\n",
      "Epoch 564/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.1915 - val_loss: 9.1270\n",
      "Epoch 565/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.1986 - val_loss: 9.1266\n",
      "Epoch 566/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 4.0944 - val_loss: 9.8665\n",
      "Epoch 567/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1386 - val_loss: 9.6129\n",
      "Epoch 568/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0305 - val_loss: 9.4614\n",
      "Epoch 569/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1777 - val_loss: 9.2566\n",
      "Epoch 570/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.2511 - val_loss: 9.4945\n",
      "Epoch 571/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.1234 - val_loss: 10.3721\n",
      "Epoch 572/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1158 - val_loss: 9.5938\n",
      "Epoch 573/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1967 - val_loss: 10.2225\n",
      "Epoch 574/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1449 - val_loss: 9.2712\n",
      "Epoch 575/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.0718 - val_loss: 9.7845\n",
      "Epoch 576/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1099 - val_loss: 9.4149\n",
      "Epoch 577/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0570 - val_loss: 9.4419\n",
      "Epoch 578/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3579 - val_loss: 9.2608\n",
      "Epoch 579/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7247 - val_loss: 10.8696\n",
      "Epoch 580/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.4600 - val_loss: 9.5087\n",
      "Epoch 581/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0538 - val_loss: 10.0629\n",
      "Epoch 582/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.1047 - val_loss: 9.4493\n",
      "Epoch 583/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.1593 - val_loss: 9.8190\n",
      "Epoch 584/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0819 - val_loss: 9.0367\n",
      "Epoch 585/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.0336 - val_loss: 9.6024\n",
      "Epoch 586/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.1803 - val_loss: 10.4064\n",
      "Epoch 587/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2829 - val_loss: 9.5358\n",
      "Epoch 588/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0256 - val_loss: 10.0059\n",
      "Epoch 589/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0714 - val_loss: 9.4512\n",
      "Epoch 590/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.0907 - val_loss: 10.1956\n",
      "Epoch 591/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1414 - val_loss: 9.4064\n",
      "Epoch 592/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.0854 - val_loss: 9.8545\n",
      "Epoch 593/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1893 - val_loss: 9.6735\n",
      "Epoch 594/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3968 - val_loss: 9.1837\n",
      "Epoch 595/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2291 - val_loss: 10.1817\n",
      "Epoch 596/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1373 - val_loss: 9.1969\n",
      "Epoch 597/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4686 - val_loss: 9.2620\n",
      "Epoch 598/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.1301 - val_loss: 10.0980\n",
      "Epoch 599/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 4.0286 - val_loss: 9.7403\n",
      "Epoch 600/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2439 - val_loss: 9.2461\n",
      "Epoch 601/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2450 - val_loss: 12.1531\n",
      "Epoch 602/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2470 - val_loss: 9.4245\n",
      "Epoch 603/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5076 - val_loss: 9.6173\n",
      "Epoch 604/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.4007 - val_loss: 9.8503\n",
      "Epoch 605/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.1760 - val_loss: 9.8202\n",
      "Epoch 606/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1956 - val_loss: 9.2030\n",
      "Epoch 607/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.0278 - val_loss: 9.8049\n",
      "Epoch 608/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9775 - val_loss: 9.4963\n",
      "Epoch 609/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 95us/step - loss: 4.0431 - val_loss: 9.8560\n",
      "Epoch 610/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0321 - val_loss: 9.3757\n",
      "Epoch 611/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0114 - val_loss: 9.7105\n",
      "Epoch 612/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9966 - val_loss: 9.6795\n",
      "Epoch 613/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.0396 - val_loss: 9.4602\n",
      "Epoch 614/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2036 - val_loss: 10.5852\n",
      "Epoch 615/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.6106 - val_loss: 9.4884\n",
      "Epoch 616/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.5540 - val_loss: 11.4119\n",
      "Epoch 617/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3441 - val_loss: 9.8556\n",
      "Epoch 618/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0568 - val_loss: 11.7768\n",
      "Epoch 619/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.7173 - val_loss: 9.4826\n",
      "Epoch 620/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.4450 - val_loss: 9.8712\n",
      "Epoch 621/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2282 - val_loss: 9.8573\n",
      "Epoch 622/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0292 - val_loss: 9.5584\n",
      "Epoch 623/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 3.9538 - val_loss: 9.8578\n",
      "Epoch 624/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9989 - val_loss: 9.7161\n",
      "Epoch 625/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0302 - val_loss: 9.7666\n",
      "Epoch 626/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 3.9931 - val_loss: 9.5351\n",
      "Epoch 627/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0017 - val_loss: 9.7385\n",
      "Epoch 628/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0295 - val_loss: 9.3210\n",
      "Epoch 629/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.9749 - val_loss: 9.9367\n",
      "Epoch 630/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0784 - val_loss: 9.3111\n",
      "Epoch 631/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1064 - val_loss: 11.0931\n",
      "Epoch 632/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.2260 - val_loss: 9.4103\n",
      "Epoch 633/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0992 - val_loss: 10.4784\n",
      "Epoch 634/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1222 - val_loss: 9.6239\n",
      "Epoch 635/1000\n",
      "274/274 [==============================] - 0s 115us/step - loss: 4.0879 - val_loss: 9.9216\n",
      "Epoch 636/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.9994 - val_loss: 9.5508\n",
      "Epoch 637/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0684 - val_loss: 9.3158\n",
      "Epoch 638/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0238 - val_loss: 10.4637\n",
      "Epoch 639/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1254 - val_loss: 9.4370\n",
      "Epoch 640/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.9788 - val_loss: 9.7989\n",
      "Epoch 641/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.9679 - val_loss: 9.5630\n",
      "Epoch 642/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0692 - val_loss: 9.6548\n",
      "Epoch 643/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1503 - val_loss: 9.9090\n",
      "Epoch 644/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9472 - val_loss: 9.5432\n",
      "Epoch 645/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.9988 - val_loss: 9.4437\n",
      "Epoch 646/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 4.0723 - val_loss: 10.5376\n",
      "Epoch 647/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6089 - val_loss: 9.8004\n",
      "Epoch 648/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.2344 - val_loss: 10.6618\n",
      "Epoch 649/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4004 - val_loss: 9.2898\n",
      "Epoch 650/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1727 - val_loss: 9.5240\n",
      "Epoch 651/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1161 - val_loss: 10.1250\n",
      "Epoch 652/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.1387 - val_loss: 9.4255\n",
      "Epoch 653/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4887 - val_loss: 10.2178\n",
      "Epoch 654/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1496 - val_loss: 9.7062\n",
      "Epoch 655/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1213 - val_loss: 9.5674\n",
      "Epoch 656/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.0222 - val_loss: 9.8417\n",
      "Epoch 657/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.9883 - val_loss: 9.4747\n",
      "Epoch 658/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.0771 - val_loss: 9.5532\n",
      "Epoch 659/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.9137 - val_loss: 9.7060\n",
      "Epoch 660/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.3299 - val_loss: 11.2678\n",
      "Epoch 661/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3520 - val_loss: 10.0117\n",
      "Epoch 662/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9997 - val_loss: 9.5691\n",
      "Epoch 663/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.9320 - val_loss: 9.3432\n",
      "Epoch 664/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.9954 - val_loss: 9.9817\n",
      "Epoch 665/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 3.9603 - val_loss: 9.5838\n",
      "Epoch 666/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 4.0474 - val_loss: 9.9836\n",
      "Epoch 667/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9569 - val_loss: 9.5585\n",
      "Epoch 668/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9879 - val_loss: 9.8932\n",
      "Epoch 669/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 3.9810 - val_loss: 9.5757\n",
      "Epoch 670/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.9202 - val_loss: 9.9633\n",
      "Epoch 671/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 3.9534 - val_loss: 9.6685\n",
      "Epoch 672/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.0508 - val_loss: 9.7930\n",
      "Epoch 673/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0284 - val_loss: 9.6353\n",
      "Epoch 674/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 4.0076 - val_loss: 10.1234\n",
      "Epoch 675/1000\n",
      "274/274 [==============================] - 0s 237us/step - loss: 4.0123 - val_loss: 9.5853\n",
      "Epoch 676/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 4.0271 - val_loss: 9.6449\n",
      "Epoch 677/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 3.9818 - val_loss: 9.9118\n",
      "Epoch 678/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0228 - val_loss: 9.2971\n",
      "Epoch 679/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 4.0547 - val_loss: 10.9099\n",
      "Epoch 680/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0388 - val_loss: 9.9695\n",
      "Epoch 681/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 4.3372 - val_loss: 10.8748\n",
      "Epoch 682/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 4.0561 - val_loss: 9.5668\n",
      "Epoch 683/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0781 - val_loss: 9.6934\n",
      "Epoch 684/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 3.9582 - val_loss: 10.1276\n",
      "Epoch 685/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.0016 - val_loss: 9.2775\n",
      "Epoch 686/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 105us/step - loss: 3.9788 - val_loss: 10.2967\n",
      "Epoch 687/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1216 - val_loss: 9.7077\n",
      "Epoch 688/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.0419 - val_loss: 10.3625\n",
      "Epoch 689/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.2300 - val_loss: 9.5339\n",
      "Epoch 690/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0095 - val_loss: 9.4554\n",
      "Epoch 691/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1928 - val_loss: 11.0914\n",
      "Epoch 692/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.4053 - val_loss: 9.5198\n",
      "Epoch 693/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2432 - val_loss: 9.7513\n",
      "Epoch 694/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0903 - val_loss: 10.1685\n",
      "Epoch 695/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0424 - val_loss: 9.5365\n",
      "Epoch 696/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2515 - val_loss: 10.3360\n",
      "Epoch 697/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0881 - val_loss: 9.7184\n",
      "Epoch 698/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.0776 - val_loss: 10.0913\n",
      "Epoch 699/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1748 - val_loss: 9.3939\n",
      "Epoch 700/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1130 - val_loss: 10.7078\n",
      "Epoch 701/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2071 - val_loss: 9.6684\n",
      "Epoch 702/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.9666 - val_loss: 9.6515\n",
      "Epoch 703/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.9850 - val_loss: 9.7313\n",
      "Epoch 704/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 3.9940 - val_loss: 9.5251\n",
      "Epoch 705/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9207 - val_loss: 10.0306\n",
      "Epoch 706/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0223 - val_loss: 9.4703\n",
      "Epoch 707/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2053 - val_loss: 9.4149\n",
      "Epoch 708/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.1407 - val_loss: 10.6865\n",
      "Epoch 709/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2713 - val_loss: 10.2035\n",
      "Epoch 710/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.5227 - val_loss: 9.6011\n",
      "Epoch 711/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1357 - val_loss: 9.8800\n",
      "Epoch 712/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 3.9164 - val_loss: 9.7596\n",
      "Epoch 713/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0202 - val_loss: 9.2140\n",
      "Epoch 714/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0948 - val_loss: 9.9139\n",
      "Epoch 715/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 4.1318 - val_loss: 9.5315\n",
      "Epoch 716/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.2410 - val_loss: 10.9269\n",
      "Epoch 717/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 4.2415 - val_loss: 9.3856\n",
      "Epoch 718/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0141 - val_loss: 10.2830\n",
      "Epoch 719/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.9317 - val_loss: 9.3360\n",
      "Epoch 720/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4903 - val_loss: 11.0831\n",
      "Epoch 721/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.2596 - val_loss: 9.7722\n",
      "Epoch 722/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 3.8387 - val_loss: 10.0839\n",
      "Epoch 723/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.0610 - val_loss: 9.2847\n",
      "Epoch 724/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 4.4701 - val_loss: 11.4785\n",
      "Epoch 725/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.0040 - val_loss: 9.6796\n",
      "Epoch 726/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.2113 - val_loss: 11.0890\n",
      "Epoch 727/1000\n",
      "274/274 [==============================] - 0s 142us/step - loss: 4.1083 - val_loss: 9.7401\n",
      "Epoch 728/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 4.1303 - val_loss: 10.9780\n",
      "Epoch 729/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0896 - val_loss: 9.6949\n",
      "Epoch 730/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1486 - val_loss: 9.6766\n",
      "Epoch 731/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0970 - val_loss: 9.8207\n",
      "Epoch 732/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 3.890 - 0s 116us/step - loss: 3.8876 - val_loss: 9.6695\n",
      "Epoch 733/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.9247 - val_loss: 9.5171\n",
      "Epoch 734/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0153 - val_loss: 10.7352\n",
      "Epoch 735/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5292 - val_loss: 9.5539\n",
      "Epoch 736/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0593 - val_loss: 9.6293\n",
      "Epoch 737/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9595 - val_loss: 9.5270\n",
      "Epoch 738/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0297 - val_loss: 10.4822\n",
      "Epoch 739/1000\n",
      "274/274 [==============================] - 0s 138us/step - loss: 3.9652 - val_loss: 9.4683\n",
      "Epoch 740/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 3.9649 - val_loss: 9.6978\n",
      "Epoch 741/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.9597 - val_loss: 9.4961\n",
      "Epoch 742/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9328 - val_loss: 9.6678\n",
      "Epoch 743/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8877 - val_loss: 9.8789\n",
      "Epoch 744/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.8714 - val_loss: 9.4540\n",
      "Epoch 745/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.0779 - val_loss: 10.4094\n",
      "Epoch 746/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1223 - val_loss: 9.4251\n",
      "Epoch 747/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.0543 - val_loss: 9.9607\n",
      "Epoch 748/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 3.8731 - val_loss: 9.5919\n",
      "Epoch 749/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9940 - val_loss: 10.2184\n",
      "Epoch 750/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9477 - val_loss: 10.0137\n",
      "Epoch 751/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 3.9490 - val_loss: 9.6179\n",
      "Epoch 752/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1361 - val_loss: 10.4275\n",
      "Epoch 753/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0436 - val_loss: 9.5576\n",
      "Epoch 754/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.9127 - val_loss: 11.5022\n",
      "Epoch 755/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2608 - val_loss: 9.4170\n",
      "Epoch 756/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 3.8651 - val_loss: 9.6882\n",
      "Epoch 757/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9204 - val_loss: 9.4875\n",
      "Epoch 758/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9157 - val_loss: 10.1595\n",
      "Epoch 759/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 3.9220 - val_loss: 9.9303\n",
      "Epoch 760/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9462 - val_loss: 9.3558\n",
      "Epoch 761/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.0462 - val_loss: 10.1012\n",
      "Epoch 762/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9787 - val_loss: 9.7094\n",
      "Epoch 763/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 98us/step - loss: 4.0700 - val_loss: 10.3290\n",
      "Epoch 764/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.0006 - val_loss: 9.5257\n",
      "Epoch 765/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.9202 - val_loss: 10.1011\n",
      "Epoch 766/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 3.9978 - val_loss: 9.9854\n",
      "Epoch 767/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 3.9195 - val_loss: 9.5125\n",
      "Epoch 768/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9107 - val_loss: 10.3425\n",
      "Epoch 769/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 4.0812 - val_loss: 9.5420\n",
      "Epoch 770/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8478 - val_loss: 10.8176\n",
      "Epoch 771/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9734 - val_loss: 9.2237\n",
      "Epoch 772/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.1319 - val_loss: 9.9180\n",
      "Epoch 773/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9567 - val_loss: 10.0490\n",
      "Epoch 774/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0178 - val_loss: 9.5738\n",
      "Epoch 775/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.2594 - val_loss: 11.6595\n",
      "Epoch 776/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.5234 - val_loss: 9.4675\n",
      "Epoch 777/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9134 - val_loss: 10.6127\n",
      "Epoch 778/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2052 - val_loss: 9.9271\n",
      "Epoch 779/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.0114 - val_loss: 9.3589\n",
      "Epoch 780/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.1260 - val_loss: 10.6224\n",
      "Epoch 781/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5000 - val_loss: 9.6678\n",
      "Epoch 782/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8992 - val_loss: 10.3788\n",
      "Epoch 783/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 3.8926 - val_loss: 9.1755\n",
      "Epoch 784/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0093 - val_loss: 11.1653\n",
      "Epoch 785/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.2831 - val_loss: 9.2598\n",
      "Epoch 786/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0499 - val_loss: 10.3111\n",
      "Epoch 787/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2961 - val_loss: 10.0769\n",
      "Epoch 788/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.0980 - val_loss: 9.4138\n",
      "Epoch 789/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4886 - val_loss: 10.2330\n",
      "Epoch 790/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9365 - val_loss: 9.3921\n",
      "Epoch 791/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 3.7495 - val_loss: 10.2117\n",
      "Epoch 792/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 3.9859 - val_loss: 9.8337\n",
      "Epoch 793/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0760 - val_loss: 9.8389\n",
      "Epoch 794/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1163 - val_loss: 10.0034\n",
      "Epoch 795/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 3.8497 - val_loss: 9.4760\n",
      "Epoch 796/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8651 - val_loss: 9.8171\n",
      "Epoch 797/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9872 - val_loss: 9.7489\n",
      "Epoch 798/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9086 - val_loss: 9.6454\n",
      "Epoch 799/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9935 - val_loss: 10.1948\n",
      "Epoch 800/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8655 - val_loss: 9.3369\n",
      "Epoch 801/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9855 - val_loss: 9.4542\n",
      "Epoch 802/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 3.8890 - val_loss: 9.7383\n",
      "Epoch 803/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8159 - val_loss: 9.8817\n",
      "Epoch 804/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.9345 - val_loss: 9.3258\n",
      "Epoch 805/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.8828 - val_loss: 10.6476\n",
      "Epoch 806/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1845 - val_loss: 9.4765\n",
      "Epoch 807/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0212 - val_loss: 9.9097\n",
      "Epoch 808/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1499 - val_loss: 10.0624\n",
      "Epoch 809/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9070 - val_loss: 9.4771\n",
      "Epoch 810/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8755 - val_loss: 9.8692\n",
      "Epoch 811/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.9048 - val_loss: 10.5464\n",
      "Epoch 812/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9955 - val_loss: 9.5869\n",
      "Epoch 813/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0761 - val_loss: 9.5419\n",
      "Epoch 814/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0917 - val_loss: 10.1532\n",
      "Epoch 815/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0810 - val_loss: 9.6988\n",
      "Epoch 816/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.9237 - val_loss: 9.4784\n",
      "Epoch 817/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9214 - val_loss: 9.8337\n",
      "Epoch 818/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8769 - val_loss: 9.6544\n",
      "Epoch 819/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8087 - val_loss: 9.9713\n",
      "Epoch 820/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9696 - val_loss: 9.3526\n",
      "Epoch 821/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0518 - val_loss: 10.3494\n",
      "Epoch 822/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1151 - val_loss: 9.6109\n",
      "Epoch 823/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2004 - val_loss: 9.7469\n",
      "Epoch 824/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0279 - val_loss: 9.8027\n",
      "Epoch 825/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9490 - val_loss: 9.6763\n",
      "Epoch 826/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8713 - val_loss: 9.7654\n",
      "Epoch 827/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.9704 - val_loss: 11.0964\n",
      "Epoch 828/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1506 - val_loss: 9.4531\n",
      "Epoch 829/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.8587 - val_loss: 10.0985\n",
      "Epoch 830/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.0370 - val_loss: 10.2149\n",
      "Epoch 831/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.0386 - val_loss: 9.5204\n",
      "Epoch 832/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.9347 - val_loss: 9.5519\n",
      "Epoch 833/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.9819 - val_loss: 9.6989\n",
      "Epoch 834/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0126 - val_loss: 10.5047\n",
      "Epoch 835/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 3.9019 - val_loss: 9.4560\n",
      "Epoch 836/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1203 - val_loss: 11.8356\n",
      "Epoch 837/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.4312 - val_loss: 10.1333\n",
      "Epoch 838/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.0890 - val_loss: 10.6874\n",
      "Epoch 839/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0000 - val_loss: 9.6084\n",
      "Epoch 840/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 109us/step - loss: 3.9263 - val_loss: 10.0166\n",
      "Epoch 841/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8244 - val_loss: 9.7422\n",
      "Epoch 842/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9005 - val_loss: 9.7356\n",
      "Epoch 843/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.8436 - val_loss: 10.0716\n",
      "Epoch 844/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.8390 - val_loss: 9.9334\n",
      "Epoch 845/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9146 - val_loss: 9.5100\n",
      "Epoch 846/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.0883 - val_loss: 11.2128\n",
      "Epoch 847/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1647 - val_loss: 9.4809\n",
      "Epoch 848/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9739 - val_loss: 9.9317\n",
      "Epoch 849/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 3.8771 - val_loss: 9.7357\n",
      "Epoch 850/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8607 - val_loss: 9.4265\n",
      "Epoch 851/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8893 - val_loss: 10.6327\n",
      "Epoch 852/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 3.8598 - val_loss: 9.7845\n",
      "Epoch 853/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 3.8636 - val_loss: 9.5804\n",
      "Epoch 854/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 3.8877 - val_loss: 9.8708\n",
      "Epoch 855/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 3.7897 - val_loss: 9.6502\n",
      "Epoch 856/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 3.8703 - val_loss: 10.8861\n",
      "Epoch 857/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.2737 - val_loss: 9.2493\n",
      "Epoch 858/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9407 - val_loss: 9.6148\n",
      "Epoch 859/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1263 - val_loss: 10.5411\n",
      "Epoch 860/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 3.9714 - val_loss: 9.8797\n",
      "Epoch 861/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 3.8983 - val_loss: 9.7936\n",
      "Epoch 862/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9736 - val_loss: 9.8665\n",
      "Epoch 863/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 3.9407 - val_loss: 10.1796\n",
      "Epoch 864/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8529 - val_loss: 9.7488\n",
      "Epoch 865/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8827 - val_loss: 9.5940\n",
      "Epoch 866/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 3.9077 - val_loss: 10.9317\n",
      "Epoch 867/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.0188 - val_loss: 9.5380\n",
      "Epoch 868/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.1427 - val_loss: 11.1580\n",
      "Epoch 869/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.0296 - val_loss: 10.2818\n",
      "Epoch 870/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 3.9291 - val_loss: 10.4687\n",
      "Epoch 871/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 3.8196 - val_loss: 9.6323\n",
      "Epoch 872/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.4337 - val_loss: 10.9502\n",
      "Epoch 873/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 3.9287 - val_loss: 10.0287\n",
      "Epoch 874/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9612 - val_loss: 10.4245\n",
      "Epoch 875/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9634 - val_loss: 9.9256\n",
      "Epoch 876/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 3.8613 - val_loss: 9.5760\n",
      "Epoch 877/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 3.8482 - val_loss: 9.8614\n",
      "Epoch 878/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.9794 - val_loss: 9.6104\n",
      "Epoch 879/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 3.8185 - val_loss: 11.4062\n",
      "Epoch 880/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0656 - val_loss: 9.7535\n",
      "Epoch 881/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.8888 - val_loss: 9.8963\n",
      "Epoch 882/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8466 - val_loss: 9.8698\n",
      "Epoch 883/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 3.7102 - val_loss: 10.1020\n",
      "Epoch 884/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8342 - val_loss: 10.4923\n",
      "Epoch 885/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8158 - val_loss: 9.8840\n",
      "Epoch 886/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7695 - val_loss: 10.2047\n",
      "Epoch 887/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 3.7550 - val_loss: 10.0903\n",
      "Epoch 888/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.7530 - val_loss: 9.6716\n",
      "Epoch 889/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9169 - val_loss: 10.4991\n",
      "Epoch 890/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 3.7558 - val_loss: 9.7935\n",
      "Epoch 891/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9299 - val_loss: 11.2436\n",
      "Epoch 892/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1673 - val_loss: 9.3735\n",
      "Epoch 893/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 3.9358 - val_loss: 10.1370\n",
      "Epoch 894/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8702 - val_loss: 10.3475\n",
      "Epoch 895/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 3.9352 - val_loss: 10.3248\n",
      "Epoch 896/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8857 - val_loss: 9.9428\n",
      "Epoch 897/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 3.7789 - val_loss: 9.6295\n",
      "Epoch 898/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8167 - val_loss: 10.4988\n",
      "Epoch 899/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.8716 - val_loss: 10.0085\n",
      "Epoch 900/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 3.9439 - val_loss: 10.5372\n",
      "Epoch 901/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8558 - val_loss: 10.3315\n",
      "Epoch 902/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7896 - val_loss: 9.9182\n",
      "Epoch 903/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 3.7820 - val_loss: 10.3450\n",
      "Epoch 904/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.8214 - val_loss: 10.1024\n",
      "Epoch 905/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0657 - val_loss: 11.2014\n",
      "Epoch 906/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.9200 - val_loss: 9.5517\n",
      "Epoch 907/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.9764 - val_loss: 10.3813\n",
      "Epoch 908/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.9482 - val_loss: 10.9459\n",
      "Epoch 909/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9055 - val_loss: 9.6601\n",
      "Epoch 910/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.8755 - val_loss: 10.9949\n",
      "Epoch 911/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 3.7681 - val_loss: 9.6841\n",
      "Epoch 912/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.7864 - val_loss: 11.5649\n",
      "Epoch 913/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9950 - val_loss: 9.4808\n",
      "Epoch 914/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.7527 - val_loss: 12.2175\n",
      "Epoch 915/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.2184 - val_loss: 9.8569\n",
      "Epoch 916/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.8931 - val_loss: 10.3657\n",
      "Epoch 917/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 95us/step - loss: 3.8597 - val_loss: 10.1858\n",
      "Epoch 918/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 3.7987 - val_loss: 10.1094\n",
      "Epoch 919/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 3.8607 - val_loss: 9.6712\n",
      "Epoch 920/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9369 - val_loss: 9.9918\n",
      "Epoch 921/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8255 - val_loss: 11.2392\n",
      "Epoch 922/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9566 - val_loss: 9.8850\n",
      "Epoch 923/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8457 - val_loss: 9.8409\n",
      "Epoch 924/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9724 - val_loss: 10.0541\n",
      "Epoch 925/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9468 - val_loss: 9.6314\n",
      "Epoch 926/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.1367 - val_loss: 10.8229\n",
      "Epoch 927/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.6888 - val_loss: 9.7687\n",
      "Epoch 928/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0979 - val_loss: 11.6169\n",
      "Epoch 929/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0224 - val_loss: 9.9925\n",
      "Epoch 930/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0639 - val_loss: 9.6847\n",
      "Epoch 931/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8732 - val_loss: 10.2950\n",
      "Epoch 932/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8901 - val_loss: 10.8756\n",
      "Epoch 933/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1121 - val_loss: 9.9422\n",
      "Epoch 934/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.8271 - val_loss: 10.8399\n",
      "Epoch 935/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 3.8493 - val_loss: 9.6731\n",
      "Epoch 936/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3296 - val_loss: 11.8374\n",
      "Epoch 937/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.1574 - val_loss: 10.0718\n",
      "Epoch 938/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7929 - val_loss: 9.8574\n",
      "Epoch 939/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.2671 - val_loss: 10.7588\n",
      "Epoch 940/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 3.8568 - val_loss: 10.0886\n",
      "Epoch 941/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8546 - val_loss: 10.1086\n",
      "Epoch 942/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.7842 - val_loss: 10.4243\n",
      "Epoch 943/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 3.7817 - val_loss: 9.7603\n",
      "Epoch 944/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9103 - val_loss: 11.1234\n",
      "Epoch 945/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8684 - val_loss: 9.8419\n",
      "Epoch 946/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0861 - val_loss: 11.7816\n",
      "Epoch 947/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.8377 - val_loss: 9.8171\n",
      "Epoch 948/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1679 - val_loss: 11.3719\n",
      "Epoch 949/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 3.8612 - val_loss: 10.4238\n",
      "Epoch 950/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8205 - val_loss: 10.1329\n",
      "Epoch 951/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8659 - val_loss: 11.0289\n",
      "Epoch 952/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 3.7991 - val_loss: 9.7008\n",
      "Epoch 953/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 3.9645 - val_loss: 11.2928\n",
      "Epoch 954/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.6985 - val_loss: 9.8630\n",
      "Epoch 955/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8385 - val_loss: 10.5087\n",
      "Epoch 956/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 3.8290 - val_loss: 10.3543\n",
      "Epoch 957/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.7992 - val_loss: 9.4702\n",
      "Epoch 958/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9134 - val_loss: 10.4720\n",
      "Epoch 959/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.8164 - val_loss: 10.4562\n",
      "Epoch 960/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.7644 - val_loss: 10.2918\n",
      "Epoch 961/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.7801 - val_loss: 10.3341\n",
      "Epoch 962/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.6741 - val_loss: 10.2892\n",
      "Epoch 963/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 3.8779 - val_loss: 9.9455\n",
      "Epoch 964/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 3.9051 - val_loss: 10.5885\n",
      "Epoch 965/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 3.6954 - val_loss: 9.8009\n",
      "Epoch 966/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 3.8130 - val_loss: 11.2591\n",
      "Epoch 967/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 3.7755 - val_loss: 9.4137\n",
      "Epoch 968/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.1885 - val_loss: 10.9136\n",
      "Epoch 969/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8497 - val_loss: 10.4451\n",
      "Epoch 970/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.6823 - val_loss: 10.7525\n",
      "Epoch 971/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.0821 - val_loss: 11.5467\n",
      "Epoch 972/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1802 - val_loss: 9.6252\n",
      "Epoch 973/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2648 - val_loss: 10.3830\n",
      "Epoch 974/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.6992 - val_loss: 10.0625\n",
      "Epoch 975/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 3.7071 - val_loss: 10.3754\n",
      "Epoch 976/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.6638 - val_loss: 10.1721\n",
      "Epoch 977/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.6873 - val_loss: 10.0539\n",
      "Epoch 978/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.6944 - val_loss: 10.4473\n",
      "Epoch 979/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.7760 - val_loss: 10.2270\n",
      "Epoch 980/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 3.8010 - val_loss: 11.3213\n",
      "Epoch 981/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.6765 - val_loss: 9.7881\n",
      "Epoch 982/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 4.0016 - val_loss: 10.0590\n",
      "Epoch 983/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 3.8826 - val_loss: 11.2544\n",
      "Epoch 984/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1711 - val_loss: 9.8125\n",
      "Epoch 985/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0852 - val_loss: 10.8442\n",
      "Epoch 986/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.7368 - val_loss: 10.1326\n",
      "Epoch 987/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.7094 - val_loss: 10.1422\n",
      "Epoch 988/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.6899 - val_loss: 10.0671\n",
      "Epoch 989/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 3.7518 - val_loss: 10.3230\n",
      "Epoch 990/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.7654 - val_loss: 10.1959\n",
      "Epoch 991/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9989 - val_loss: 10.3056\n",
      "Epoch 992/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.7709 - val_loss: 9.8836\n",
      "Epoch 993/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 3.7280 - val_loss: 10.5039\n",
      "Epoch 994/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 3.6496 - val_loss: 10.1971\n",
      "Epoch 995/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.7108 - val_loss: 10.6330\n",
      "Epoch 996/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.7394 - val_loss: 10.0274\n",
      "Epoch 997/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 3.7341 - val_loss: 10.2301\n",
      "Epoch 998/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 3.7724 - val_loss: 10.1504\n",
      "Epoch 999/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 3.8608 - val_loss: 10.2773\n",
      "Epoch 1000/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8163 - val_loss: 10.3105\n",
      "9.321624642711575\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.01587684,  3.3961208 ,  0.9976807 , -1.8066075 ,  0.76832217,\n",
       "         -1.4006512 , -0.9553555 ,  1.5285815 ,  0.15097545, -1.5270396 ],\n",
       "        [ 0.54927874, -1.6584923 , -0.49496475,  0.56334066, -0.6029632 ,\n",
       "          0.5443326 , -1.3201429 , -3.9735973 , -0.21326391,  0.8425982 ],\n",
       "        [-0.28603598,  2.3327014 , -0.8422549 , -0.5274472 , -0.27047464,\n",
       "          0.5659955 ,  0.05911589, -2.7950149 , -0.93200237,  0.08850259],\n",
       "        [-1.2293054 ,  0.91389924,  0.8314568 ,  1.340507  ,  1.1333774 ,\n",
       "         -0.6399632 ,  1.3495536 ,  0.89416045, -0.05827907, -0.24505417],\n",
       "        [ 0.8172982 ,  0.05027466, -0.775708  , -0.11928917, -0.36958307,\n",
       "          0.16335952, -0.09156059,  0.48534945, -1.2946714 ,  0.57557124],\n",
       "        [-0.6450549 , -0.7623523 ,  0.60316765, -0.10105048, -1.77633   ,\n",
       "          0.4218894 ,  2.4833734 ,  1.112772  , -0.7942972 , -0.68007535],\n",
       "        [-1.1292084 , -1.2164863 , -0.11383384,  0.5946333 , -0.01031957,\n",
       "         -0.20427616,  2.2784922 ,  1.641462  ,  3.122334  , -0.8056768 ]],\n",
       "       dtype=float32),\n",
       " array([-1.0607986,  1.6156384, -2.2312999, -1.713341 ,  2.0464673,\n",
       "        -1.3720782,  2.6177523, -0.7776081,  2.4339175, -1.07163  ],\n",
       "       dtype=float32),\n",
       " array([[-0.9514    ,  1.0033108 ,  1.2339675 , -0.9074127 ,  0.20221564],\n",
       "        [ 1.247321  , -1.3707823 , -0.7162705 ,  1.2996049 , -0.5985591 ],\n",
       "        [ 0.17484878, -0.7002201 , -0.5984266 ,  0.9616409 , -0.64657336],\n",
       "        [-0.10576167, -0.15495035, -1.176948  ,  1.0709703 , -0.74711746],\n",
       "        [ 1.3973145 , -0.46557865, -1.5197355 ,  1.4931337 , -1.2110839 ],\n",
       "        [ 1.7076737 , -1.1380832 , -1.223377  ,  1.8710384 , -1.2265838 ],\n",
       "        [-0.9020502 ,  0.6160109 ,  0.86712754, -0.6973401 ,  0.61440694],\n",
       "        [ 0.73803496, -0.49240273, -0.250819  ,  0.55500776, -0.93008816],\n",
       "        [-0.63370395,  0.8548765 ,  0.5651096 ,  0.31194863,  0.6757043 ],\n",
       "        [ 0.24074961, -1.1060889 , -0.9828642 ,  0.9980006 ,  0.02477775]],\n",
       "       dtype=float32),\n",
       " array([-1.6912862,  1.6705456,  1.6982553, -1.7066039,  1.6715351],\n",
       "       dtype=float32),\n",
       " array([[-0.89872193],\n",
       "        [ 1.3395426 ],\n",
       "        [ 1.5143461 ],\n",
       "        [-1.4604832 ],\n",
       "        [ 0.8788681 ]], dtype=float32),\n",
       " array([1.7056701], dtype=float32)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_autompg, history_autompg, evaluate_autompg=NN_model_structure_regression_4(X_train_autompg, X_val_autompg, Y_train_autompg, Y_val_autompg, adam2, 32, 1000, x_test_autompg, y_test_autompg)\n",
    "model_autompg.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_autompg.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_autompg_structure4_4th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_31 (Dense)             (None, 10)                80        \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 201\n",
      "Trainable params: 201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 274 samples, validate on 59 samples\n",
      "Epoch 1/1000\n",
      "274/274 [==============================] - 0s 1ms/step - loss: 481.8177 - val_loss: 235.0124\n",
      "Epoch 2/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 139.8692 - val_loss: 95.2377\n",
      "Epoch 3/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 60.6499 - val_loss: 54.0498\n",
      "Epoch 4/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 31.0189 - val_loss: 24.0218\n",
      "Epoch 5/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 19.6673 - val_loss: 24.6265\n",
      "Epoch 6/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 15.4989 - val_loss: 17.4842\n",
      "Epoch 7/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 12.7300 - val_loss: 15.6727\n",
      "Epoch 8/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 10.4753 - val_loss: 13.5618\n",
      "Epoch 9/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 9.0159 - val_loss: 12.8162\n",
      "Epoch 10/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 8.8628 - val_loss: 11.9938\n",
      "Epoch 11/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 8.3639 - val_loss: 11.9417\n",
      "Epoch 12/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 8.3945 - val_loss: 11.9513\n",
      "Epoch 13/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 8.2847 - val_loss: 11.9104\n",
      "Epoch 14/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.9804 - val_loss: 11.0175\n",
      "Epoch 15/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 8.0280 - val_loss: 10.5091\n",
      "Epoch 16/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 7.7685 - val_loss: 10.0456\n",
      "Epoch 17/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 7.3023 - val_loss: 10.3344\n",
      "Epoch 18/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.1800 - val_loss: 9.9484\n",
      "Epoch 19/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1520 - val_loss: 9.6941\n",
      "Epoch 20/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 7.0205 - val_loss: 9.3937\n",
      "Epoch 21/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7976 - val_loss: 9.2152\n",
      "Epoch 22/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7430 - val_loss: 9.1894\n",
      "Epoch 23/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 6.6885 - val_loss: 9.3160\n",
      "Epoch 24/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6698 - val_loss: 9.2955\n",
      "Epoch 25/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 6.6361 - val_loss: 9.0649\n",
      "Epoch 26/1000\n",
      "274/274 [==============================] - 0s 117us/step - loss: 6.7145 - val_loss: 9.5864\n",
      "Epoch 27/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.5799 - val_loss: 9.3478\n",
      "Epoch 28/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.7552 - val_loss: 9.0311\n",
      "Epoch 29/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 7.2120 - val_loss: 9.8772\n",
      "Epoch 30/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.8713 - val_loss: 9.0109\n",
      "Epoch 31/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.6781 - val_loss: 9.4467\n",
      "Epoch 32/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5701 - val_loss: 9.1088\n",
      "Epoch 33/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5311 - val_loss: 9.2884\n",
      "Epoch 34/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.4194 - val_loss: 9.0925\n",
      "Epoch 35/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.3262 - val_loss: 9.3902\n",
      "Epoch 36/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5139 - val_loss: 9.2712\n",
      "Epoch 37/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.2749 - val_loss: 9.2116\n",
      "Epoch 38/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4043 - val_loss: 9.2800\n",
      "Epoch 39/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 6.3362 - val_loss: 9.0934\n",
      "Epoch 40/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.4313 - val_loss: 8.9933\n",
      "Epoch 41/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.4573 - val_loss: 9.7066\n",
      "Epoch 42/1000\n",
      "274/274 [==============================] - 0s 117us/step - loss: 6.3756 - val_loss: 9.0750\n",
      "Epoch 43/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.1809 - val_loss: 9.6824\n",
      "Epoch 44/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 6.4260 - val_loss: 9.2161\n",
      "Epoch 45/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 6.2217 - val_loss: 9.2996\n",
      "Epoch 46/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.3198 - val_loss: 9.2241\n",
      "Epoch 47/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.2873 - val_loss: 9.2522\n",
      "Epoch 48/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 6.2024 - val_loss: 9.0145\n",
      "Epoch 49/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 6.0560 - val_loss: 9.2359\n",
      "Epoch 50/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.0011 - val_loss: 9.4791\n",
      "Epoch 51/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.1338 - val_loss: 8.9845\n",
      "Epoch 52/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.0982 - val_loss: 9.3160\n",
      "Epoch 53/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.0457 - val_loss: 9.3782\n",
      "Epoch 54/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0879 - val_loss: 9.0836\n",
      "Epoch 55/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.0062 - val_loss: 9.2235\n",
      "Epoch 56/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 7.261 - 0s 109us/step - loss: 5.9819 - val_loss: 9.3519\n",
      "Epoch 57/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1538 - val_loss: 9.4876\n",
      "Epoch 58/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.0678 - val_loss: 9.3053\n",
      "Epoch 59/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.9541 - val_loss: 9.2491\n",
      "Epoch 60/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 6.0646 - val_loss: 9.0663\n",
      "Epoch 61/1000\n",
      "274/274 [==============================] - 0s 115us/step - loss: 6.0707 - val_loss: 9.4548\n",
      "Epoch 62/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.8509 - val_loss: 9.2633\n",
      "Epoch 63/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.0259 - val_loss: 9.4564\n",
      "Epoch 64/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2775 - val_loss: 9.2434\n",
      "Epoch 65/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 6.5355 - val_loss: 9.3217\n",
      "Epoch 66/1000\n",
      "274/274 [==============================] - 0s 119us/step - loss: 6.3060 - val_loss: 9.6992\n",
      "Epoch 67/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 6.1100 - val_loss: 9.0212\n",
      "Epoch 68/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 118us/step - loss: 5.8147 - val_loss: 9.2992\n",
      "Epoch 69/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9808 - val_loss: 9.2398\n",
      "Epoch 70/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.8437 - val_loss: 9.3566\n",
      "Epoch 71/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7687 - val_loss: 9.1267\n",
      "Epoch 72/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.7291 - val_loss: 9.4236\n",
      "Epoch 73/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 5.8106 - val_loss: 8.9994\n",
      "Epoch 74/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8137 - val_loss: 9.6131\n",
      "Epoch 75/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1210 - val_loss: 9.1065\n",
      "Epoch 76/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.0145 - val_loss: 9.4919\n",
      "Epoch 77/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 5.8370 - val_loss: 8.9029\n",
      "Epoch 78/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 5.7485 - val_loss: 9.1138\n",
      "Epoch 79/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6715 - val_loss: 8.9988\n",
      "Epoch 80/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 5.8742 - val_loss: 8.9454\n",
      "Epoch 81/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.9504 - val_loss: 9.4786\n",
      "Epoch 82/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.9649 - val_loss: 9.0023\n",
      "Epoch 83/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 5.7967 - val_loss: 8.9339\n",
      "Epoch 84/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6494 - val_loss: 9.0642\n",
      "Epoch 85/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 5.6346 - val_loss: 8.6900\n",
      "Epoch 86/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 5.8122 - val_loss: 8.6886\n",
      "Epoch 87/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 5.6355 - val_loss: 8.8693\n",
      "Epoch 88/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 5.5786 - val_loss: 8.7872\n",
      "Epoch 89/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7409 - val_loss: 9.4321\n",
      "Epoch 90/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.7153 - val_loss: 8.7500\n",
      "Epoch 91/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6409 - val_loss: 9.0534\n",
      "Epoch 92/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7230 - val_loss: 8.6275\n",
      "Epoch 93/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 5.8174 - val_loss: 9.1066\n",
      "Epoch 94/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 5.9630 - val_loss: 8.7475\n",
      "Epoch 95/1000\n",
      "274/274 [==============================] - 0s 115us/step - loss: 5.7674 - val_loss: 9.2522\n",
      "Epoch 96/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.6601 - val_loss: 8.7260\n",
      "Epoch 97/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5301 - val_loss: 8.8651\n",
      "Epoch 98/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.6264 - val_loss: 8.5954\n",
      "Epoch 99/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 5.7973 - val_loss: 9.9541\n",
      "Epoch 100/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6643 - val_loss: 8.9657\n",
      "Epoch 101/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 5.9008 - val_loss: 9.7328\n",
      "Epoch 102/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 5.5046 - val_loss: 9.0729\n",
      "Epoch 103/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.8119 - val_loss: 10.3314\n",
      "Epoch 104/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.9119 - val_loss: 8.8859\n",
      "Epoch 105/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8003 - val_loss: 9.6128\n",
      "Epoch 106/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 5.5510 - val_loss: 9.0483\n",
      "Epoch 107/1000\n",
      "274/274 [==============================] - 0s 115us/step - loss: 5.5146 - val_loss: 9.4833\n",
      "Epoch 108/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5498 - val_loss: 9.0021\n",
      "Epoch 109/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.4244 - val_loss: 8.9995\n",
      "Epoch 110/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.4023 - val_loss: 8.4998\n",
      "Epoch 111/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.4098 - val_loss: 8.9367\n",
      "Epoch 112/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.4114 - val_loss: 8.6384\n",
      "Epoch 113/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.3877 - val_loss: 8.8169\n",
      "Epoch 114/1000\n",
      "274/274 [==============================] - 0s 119us/step - loss: 5.3141 - val_loss: 8.8802\n",
      "Epoch 115/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.5049 - val_loss: 8.7082\n",
      "Epoch 116/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 5.4507 - val_loss: 8.5584\n",
      "Epoch 117/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3701 - val_loss: 8.7267\n",
      "Epoch 118/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4056 - val_loss: 8.5183\n",
      "Epoch 119/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.4041 - val_loss: 8.3449\n",
      "Epoch 120/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6075 - val_loss: 9.5064\n",
      "Epoch 121/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6410 - val_loss: 8.5595\n",
      "Epoch 122/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3939 - val_loss: 9.2195\n",
      "Epoch 123/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 5.2799 - val_loss: 8.7574\n",
      "Epoch 124/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 5.3383 - val_loss: 8.9010\n",
      "Epoch 125/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.4755 - val_loss: 8.4374\n",
      "Epoch 126/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.3783 - val_loss: 8.7564\n",
      "Epoch 127/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 5.3739 - val_loss: 8.8641\n",
      "Epoch 128/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2371 - val_loss: 8.6532\n",
      "Epoch 129/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.2341 - val_loss: 8.7067\n",
      "Epoch 130/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.3495 - val_loss: 8.5762\n",
      "Epoch 131/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.3052 - val_loss: 8.5897\n",
      "Epoch 132/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 5.2925 - val_loss: 8.5934\n",
      "Epoch 133/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2019 - val_loss: 8.5969\n",
      "Epoch 134/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.2355 - val_loss: 8.7904\n",
      "Epoch 135/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.2370 - val_loss: 8.8448\n",
      "Epoch 136/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.2677 - val_loss: 8.7857\n",
      "Epoch 137/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.2554 - val_loss: 8.5226\n",
      "Epoch 138/1000\n",
      "274/274 [==============================] - 0s 130us/step - loss: 5.3863 - val_loss: 9.5514\n",
      "Epoch 139/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.3146 - val_loss: 8.1829\n",
      "Epoch 140/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2564 - val_loss: 8.7016\n",
      "Epoch 141/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.1049 - val_loss: 8.4069\n",
      "Epoch 142/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1150 - val_loss: 8.6502\n",
      "Epoch 143/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1507 - val_loss: 8.5476\n",
      "Epoch 144/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5466 - val_loss: 8.5468\n",
      "Epoch 145/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 5.3073 - val_loss: 8.4900\n",
      "Epoch 146/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.0634 - val_loss: 8.4062\n",
      "Epoch 147/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0754 - val_loss: 8.9083\n",
      "Epoch 148/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.1349 - val_loss: 8.6007\n",
      "Epoch 149/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.2109 - val_loss: 9.0776\n",
      "Epoch 150/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2037 - val_loss: 8.8152\n",
      "Epoch 151/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1358 - val_loss: 8.6097\n",
      "Epoch 152/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.1873 - val_loss: 8.6003\n",
      "Epoch 153/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1493 - val_loss: 9.0920\n",
      "Epoch 154/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0429 - val_loss: 8.4131\n",
      "Epoch 155/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.2886 - val_loss: 9.2156\n",
      "Epoch 156/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.1260 - val_loss: 8.5674\n",
      "Epoch 157/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0176 - val_loss: 8.9948\n",
      "Epoch 158/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2086 - val_loss: 8.8068\n",
      "Epoch 159/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1170 - val_loss: 8.4401\n",
      "Epoch 160/1000\n",
      "274/274 [==============================] - 0s 466us/step - loss: 5.3805 - val_loss: 9.7571\n",
      "Epoch 161/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.4615 - val_loss: 8.4342\n",
      "Epoch 162/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.1314 - val_loss: 8.4333\n",
      "Epoch 163/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0636 - val_loss: 8.6637\n",
      "Epoch 164/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0941 - val_loss: 8.9970\n",
      "Epoch 165/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1845 - val_loss: 8.3815\n",
      "Epoch 166/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0714 - val_loss: 8.5116\n",
      "Epoch 167/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1143 - val_loss: 8.6584\n",
      "Epoch 168/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1630 - val_loss: 8.6658\n",
      "Epoch 169/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.1361 - val_loss: 8.9885\n",
      "Epoch 170/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1641 - val_loss: 8.8441\n",
      "Epoch 171/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1592 - val_loss: 9.7490\n",
      "Epoch 172/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.1055 - val_loss: 8.3793\n",
      "Epoch 173/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1540 - val_loss: 9.3620\n",
      "Epoch 174/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.1776 - val_loss: 8.2159\n",
      "Epoch 175/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3147 - val_loss: 8.4335\n",
      "Epoch 176/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.3164 - val_loss: 8.9972\n",
      "Epoch 177/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.9883 - val_loss: 8.6372\n",
      "Epoch 178/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.9009 - val_loss: 8.2949\n",
      "Epoch 179/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0449 - val_loss: 9.4286\n",
      "Epoch 180/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.0463 - val_loss: 8.4702\n",
      "Epoch 181/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.2474 - val_loss: 8.5650\n",
      "Epoch 182/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.9994 - val_loss: 8.7481\n",
      "Epoch 183/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.0300 - val_loss: 8.5129\n",
      "Epoch 184/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9820 - val_loss: 9.3666\n",
      "Epoch 185/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0070 - val_loss: 8.3448\n",
      "Epoch 186/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.0355 - val_loss: 9.2722\n",
      "Epoch 187/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.0572 - val_loss: 8.5258\n",
      "Epoch 188/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0066 - val_loss: 8.3639\n",
      "Epoch 189/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1611 - val_loss: 8.7630\n",
      "Epoch 190/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2003 - val_loss: 8.4407\n",
      "Epoch 191/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9716 - val_loss: 8.8051\n",
      "Epoch 192/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9937 - val_loss: 8.6094\n",
      "Epoch 193/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0050 - val_loss: 8.5521\n",
      "Epoch 194/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3705 - val_loss: 9.7967\n",
      "Epoch 195/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0214 - val_loss: 8.6913\n",
      "Epoch 196/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.9593 - val_loss: 9.5110\n",
      "Epoch 197/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0468 - val_loss: 8.2633\n",
      "Epoch 198/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5838 - val_loss: 9.6715\n",
      "Epoch 199/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.6514 - val_loss: 8.9621\n",
      "Epoch 200/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.1736 - val_loss: 8.2459\n",
      "Epoch 201/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0587 - val_loss: 9.1147\n",
      "Epoch 202/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.1435 - val_loss: 8.4198\n",
      "Epoch 203/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8884 - val_loss: 8.4849\n",
      "Epoch 204/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.9007 - val_loss: 8.7514\n",
      "Epoch 205/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.9056 - val_loss: 8.2821\n",
      "Epoch 206/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.2021 - val_loss: 9.3273\n",
      "Epoch 207/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0365 - val_loss: 8.3701\n",
      "Epoch 208/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8725 - val_loss: 8.4989\n",
      "Epoch 209/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8012 - val_loss: 8.7900\n",
      "Epoch 210/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.8591 - val_loss: 8.5710\n",
      "Epoch 211/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.0037 - val_loss: 8.7128\n",
      "Epoch 212/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.8314 - val_loss: 8.3647\n",
      "Epoch 213/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9320 - val_loss: 8.3765\n",
      "Epoch 214/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.8714 - val_loss: 8.8695\n",
      "Epoch 215/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.0040 - val_loss: 8.3158\n",
      "Epoch 216/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.9447 - val_loss: 8.7529\n",
      "Epoch 217/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 4.8365 - val_loss: 8.4340\n",
      "Epoch 218/1000\n",
      "274/274 [==============================] - 0s 146us/step - loss: 5.0020 - val_loss: 8.8950\n",
      "Epoch 219/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 4.9172 - val_loss: 8.2324\n",
      "Epoch 220/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.8492 - val_loss: 8.7194\n",
      "Epoch 221/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7880 - val_loss: 8.4248\n",
      "Epoch 222/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.9238 - val_loss: 8.1813\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 223/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.8543 - val_loss: 8.5253\n",
      "Epoch 224/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7975 - val_loss: 8.3115\n",
      "Epoch 225/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8260 - val_loss: 8.5696\n",
      "Epoch 226/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.8185 - val_loss: 8.6381\n",
      "Epoch 227/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.7797 - val_loss: 8.9012\n",
      "Epoch 228/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6780 - val_loss: 8.2314\n",
      "Epoch 229/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.9753 - val_loss: 8.6620\n",
      "Epoch 230/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.8620 - val_loss: 8.5398\n",
      "Epoch 231/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.7164 - val_loss: 8.5282\n",
      "Epoch 232/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.6960 - val_loss: 8.7777\n",
      "Epoch 233/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.7966 - val_loss: 8.4228\n",
      "Epoch 234/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.6783 - val_loss: 8.6796\n",
      "Epoch 235/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.7335 - val_loss: 8.3876\n",
      "Epoch 236/1000\n",
      "274/274 [==============================] - 0s 135us/step - loss: 4.7632 - val_loss: 8.4995\n",
      "Epoch 237/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 4.7815 - val_loss: 8.4663\n",
      "Epoch 238/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.8486 - val_loss: 8.7023\n",
      "Epoch 239/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.7211 - val_loss: 8.4324\n",
      "Epoch 240/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.7393 - val_loss: 8.6069\n",
      "Epoch 241/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6809 - val_loss: 8.6309\n",
      "Epoch 242/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7083 - val_loss: 8.5526\n",
      "Epoch 243/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.8885 - val_loss: 8.6086\n",
      "Epoch 244/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.7454 - val_loss: 8.3852\n",
      "Epoch 245/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9610 - val_loss: 9.2312\n",
      "Epoch 246/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9544 - val_loss: 8.1646\n",
      "Epoch 247/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7091 - val_loss: 8.9194\n",
      "Epoch 248/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7371 - val_loss: 8.6237\n",
      "Epoch 249/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6809 - val_loss: 9.0707\n",
      "Epoch 250/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7000 - val_loss: 8.4520\n",
      "Epoch 251/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 4.8099 - val_loss: 8.7448\n",
      "Epoch 252/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8074 - val_loss: 8.2402\n",
      "Epoch 253/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6850 - val_loss: 8.7520\n",
      "Epoch 254/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6847 - val_loss: 8.3999\n",
      "Epoch 255/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6477 - val_loss: 8.7659\n",
      "Epoch 256/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7396 - val_loss: 8.7117\n",
      "Epoch 257/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.7469 - val_loss: 8.2420\n",
      "Epoch 258/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6616 - val_loss: 9.0925\n",
      "Epoch 259/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6372 - val_loss: 8.5719\n",
      "Epoch 260/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7834 - val_loss: 8.4456\n",
      "Epoch 261/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6857 - val_loss: 8.5862\n",
      "Epoch 262/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.8245 - val_loss: 8.7379\n",
      "Epoch 263/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.9807 - val_loss: 8.3303\n",
      "Epoch 264/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8465 - val_loss: 9.3622\n",
      "Epoch 265/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8344 - val_loss: 8.2082\n",
      "Epoch 266/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.7062 - val_loss: 8.2937\n",
      "Epoch 267/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6648 - val_loss: 8.6722\n",
      "Epoch 268/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.6193 - val_loss: 8.2273\n",
      "Epoch 269/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6947 - val_loss: 8.7264\n",
      "Epoch 270/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4415 - val_loss: 8.5258\n",
      "Epoch 271/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.1117 - val_loss: 8.8446\n",
      "Epoch 272/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7284 - val_loss: 8.6132\n",
      "Epoch 273/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7549 - val_loss: 8.4881\n",
      "Epoch 274/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9698 - val_loss: 9.5519\n",
      "Epoch 275/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.8630 - val_loss: 8.4367\n",
      "Epoch 276/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.7379 - val_loss: 9.2459\n",
      "Epoch 277/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8060 - val_loss: 8.8143\n",
      "Epoch 278/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.7142 - val_loss: 8.6135\n",
      "Epoch 279/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6694 - val_loss: 8.4331\n",
      "Epoch 280/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.6798 - val_loss: 9.1296\n",
      "Epoch 281/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.6401 - val_loss: 8.1955\n",
      "Epoch 282/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.7770 - val_loss: 9.1166\n",
      "Epoch 283/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5413 - val_loss: 8.2636\n",
      "Epoch 284/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.6580 - val_loss: 8.4062\n",
      "Epoch 285/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.7545 - val_loss: 8.9956\n",
      "Epoch 286/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6258 - val_loss: 8.8022\n",
      "Epoch 287/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 4.6162 - val_loss: 8.5832\n",
      "Epoch 288/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.6660 - val_loss: 8.8158\n",
      "Epoch 289/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.9797 - val_loss: 8.5377\n",
      "Epoch 290/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8455 - val_loss: 9.2950\n",
      "Epoch 291/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0032 - val_loss: 8.8364\n",
      "Epoch 292/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1083 - val_loss: 8.5170\n",
      "Epoch 293/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7658 - val_loss: 9.8372\n",
      "Epoch 294/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.9677 - val_loss: 8.4534\n",
      "Epoch 295/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5408 - val_loss: 8.6406\n",
      "Epoch 296/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6725 - val_loss: 8.6031\n",
      "Epoch 297/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6365 - val_loss: 8.5141\n",
      "Epoch 298/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5462 - val_loss: 9.3697\n",
      "Epoch 299/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5722 - val_loss: 8.4384\n",
      "Epoch 300/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 98us/step - loss: 4.4590 - val_loss: 8.9107\n",
      "Epoch 301/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5704 - val_loss: 8.3863\n",
      "Epoch 302/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.6234 - val_loss: 8.2059\n",
      "Epoch 303/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5939 - val_loss: 8.3730\n",
      "Epoch 304/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.5878 - val_loss: 8.5477\n",
      "Epoch 305/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6229 - val_loss: 8.9638\n",
      "Epoch 306/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5238 - val_loss: 8.4984\n",
      "Epoch 307/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.5024 - val_loss: 8.7696\n",
      "Epoch 308/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.5429 - val_loss: 8.9251\n",
      "Epoch 309/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5481 - val_loss: 8.4707\n",
      "Epoch 310/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.4917 - val_loss: 8.8621\n",
      "Epoch 311/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4827 - val_loss: 8.5323\n",
      "Epoch 312/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.6203 - val_loss: 9.8423\n",
      "Epoch 313/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.8466 - val_loss: 8.3952\n",
      "Epoch 314/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 4.9248 - val_loss: 9.1147\n",
      "Epoch 315/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.5777 - val_loss: 8.6801\n",
      "Epoch 316/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7988 - val_loss: 8.6488\n",
      "Epoch 317/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7654 - val_loss: 8.9648\n",
      "Epoch 318/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6340 - val_loss: 8.7625\n",
      "Epoch 319/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.5706 - val_loss: 9.0603\n",
      "Epoch 320/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5447 - val_loss: 8.6600\n",
      "Epoch 321/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.5148 - val_loss: 8.4849\n",
      "Epoch 322/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.4687 - val_loss: 9.1719\n",
      "Epoch 323/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.5280 - val_loss: 8.6246\n",
      "Epoch 324/1000\n",
      "274/274 [==============================] - 0s 115us/step - loss: 4.5305 - val_loss: 8.7907\n",
      "Epoch 325/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.5157 - val_loss: 8.9467\n",
      "Epoch 326/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 4.5530 - val_loss: 8.7992\n",
      "Epoch 327/1000\n",
      "274/274 [==============================] - 0s 117us/step - loss: 4.6444 - val_loss: 8.6548\n",
      "Epoch 328/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.4476 - val_loss: 9.3046\n",
      "Epoch 329/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.6260 - val_loss: 8.5968\n",
      "Epoch 330/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 2.717 - 0s 106us/step - loss: 4.4315 - val_loss: 8.9066\n",
      "Epoch 331/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.4061 - val_loss: 8.6443\n",
      "Epoch 332/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4775 - val_loss: 9.4653\n",
      "Epoch 333/1000\n",
      "274/274 [==============================] - 0s 118us/step - loss: 4.7066 - val_loss: 8.3748\n",
      "Epoch 334/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.8364 - val_loss: 8.4799\n",
      "Epoch 335/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4416 - val_loss: 9.2376\n",
      "Epoch 336/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.5572 - val_loss: 8.4366\n",
      "Epoch 337/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.8767 - val_loss: 9.6632\n",
      "Epoch 338/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6613 - val_loss: 8.8350\n",
      "Epoch 339/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 4.5241 - val_loss: 8.8868\n",
      "Epoch 340/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.6164 - val_loss: 9.4155\n",
      "Epoch 341/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6433 - val_loss: 8.4813\n",
      "Epoch 342/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 4.4380 - val_loss: 9.3477\n",
      "Epoch 343/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 4.5962 - val_loss: 8.8553\n",
      "Epoch 344/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.4109 - val_loss: 8.6072\n",
      "Epoch 345/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 4.7239 - val_loss: 8.8413\n",
      "Epoch 346/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.5605 - val_loss: 9.0418\n",
      "Epoch 347/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 4.4878 - val_loss: 8.7888\n",
      "Epoch 348/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.5909 - val_loss: 9.1476\n",
      "Epoch 349/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.3113 - val_loss: 8.8953\n",
      "Epoch 350/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.3340 - val_loss: 10.5621\n",
      "Epoch 351/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.8379 - val_loss: 9.1323\n",
      "Epoch 352/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.5791 - val_loss: 8.7416\n",
      "Epoch 353/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.4349 - val_loss: 8.8110\n",
      "Epoch 354/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4243 - val_loss: 8.6758\n",
      "Epoch 355/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5228 - val_loss: 9.2809\n",
      "Epoch 356/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4540 - val_loss: 8.6488\n",
      "Epoch 357/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.5386 - val_loss: 9.2184\n",
      "Epoch 358/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.5710 - val_loss: 9.1129\n",
      "Epoch 359/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.4633 - val_loss: 8.6858\n",
      "Epoch 360/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.4427 - val_loss: 8.9612\n",
      "Epoch 361/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4893 - val_loss: 8.8840\n",
      "Epoch 362/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3788 - val_loss: 8.6166\n",
      "Epoch 363/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 4.3848 - val_loss: 9.1461\n",
      "Epoch 364/1000\n",
      "274/274 [==============================] - 0s 135us/step - loss: 4.6365 - val_loss: 8.5485\n",
      "Epoch 365/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.7602 - val_loss: 8.7501\n",
      "Epoch 366/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6642 - val_loss: 9.7171\n",
      "Epoch 367/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.6597 - val_loss: 8.4707\n",
      "Epoch 368/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.7461 - val_loss: 9.8328\n",
      "Epoch 369/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.5491 - val_loss: 9.2228\n",
      "Epoch 370/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.3294 - val_loss: 9.0900\n",
      "Epoch 371/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4522 - val_loss: 8.7401\n",
      "Epoch 372/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.3568 - val_loss: 9.0126\n",
      "Epoch 373/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4961 - val_loss: 9.2202\n",
      "Epoch 374/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3954 - val_loss: 9.0630\n",
      "Epoch 375/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3327 - val_loss: 8.6434\n",
      "Epoch 376/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.4559 - val_loss: 9.8942\n",
      "Epoch 377/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 106us/step - loss: 4.5255 - val_loss: 8.6298\n",
      "Epoch 378/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.5215 - val_loss: 8.6796\n",
      "Epoch 379/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6349 - val_loss: 10.2277\n",
      "Epoch 380/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.8100 - val_loss: 8.5393\n",
      "Epoch 381/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.8059 - val_loss: 8.6302\n",
      "Epoch 382/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4754 - val_loss: 9.5747\n",
      "Epoch 383/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5203 - val_loss: 8.7915\n",
      "Epoch 384/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4086 - val_loss: 9.4002\n",
      "Epoch 385/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5371 - val_loss: 9.1587\n",
      "Epoch 386/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4170 - val_loss: 8.7562\n",
      "Epoch 387/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3889 - val_loss: 9.0129\n",
      "Epoch 388/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 4.4111 - val_loss: 9.8090\n",
      "Epoch 389/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.4821 - val_loss: 8.8027\n",
      "Epoch 390/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.4923 - val_loss: 9.8364\n",
      "Epoch 391/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.5857 - val_loss: 9.2595\n",
      "Epoch 392/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6725 - val_loss: 8.8351\n",
      "Epoch 393/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4491 - val_loss: 8.9468\n",
      "Epoch 394/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.6723 - val_loss: 9.1534\n",
      "Epoch 395/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 4.7885 - val_loss: 9.9018\n",
      "Epoch 396/1000\n",
      "274/274 [==============================] - 0s 149us/step - loss: 4.6790 - val_loss: 9.0141\n",
      "Epoch 397/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 5.1789 - val_loss: 11.3622\n",
      "Epoch 398/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 5.1117 - val_loss: 8.6579\n",
      "Epoch 399/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3698 - val_loss: 8.9937\n",
      "Epoch 400/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.3321 - val_loss: 8.7578\n",
      "Epoch 401/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3210 - val_loss: 9.5636\n",
      "Epoch 402/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4177 - val_loss: 9.2401\n",
      "Epoch 403/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 4.3956 - val_loss: 8.7413\n",
      "Epoch 404/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.4168 - val_loss: 9.7195\n",
      "Epoch 405/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.6589 - val_loss: 8.7488\n",
      "Epoch 406/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 4.4075 - val_loss: 9.0406\n",
      "Epoch 407/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 4.3002 - val_loss: 9.5874\n",
      "Epoch 408/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 4.5619 - val_loss: 8.6703\n",
      "Epoch 409/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5175 - val_loss: 9.6776\n",
      "Epoch 410/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 4.2118 - val_loss: 8.8575\n",
      "Epoch 411/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4059 - val_loss: 9.2707\n",
      "Epoch 412/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.4256 - val_loss: 8.9485\n",
      "Epoch 413/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3350 - val_loss: 9.0309\n",
      "Epoch 414/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.4150 - val_loss: 10.6547\n",
      "Epoch 415/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7135 - val_loss: 9.0571\n",
      "Epoch 416/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3909 - val_loss: 9.0415\n",
      "Epoch 417/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.3973 - val_loss: 9.1114\n",
      "Epoch 418/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2023 - val_loss: 9.3021\n",
      "Epoch 419/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3954 - val_loss: 8.8664\n",
      "Epoch 420/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3101 - val_loss: 9.2133\n",
      "Epoch 421/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.4818 - val_loss: 9.6742\n",
      "Epoch 422/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.2964 - val_loss: 9.1397\n",
      "Epoch 423/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5584 - val_loss: 10.2634\n",
      "Epoch 424/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4303 - val_loss: 8.9534\n",
      "Epoch 425/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.5342 - val_loss: 9.0706\n",
      "Epoch 426/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.4890 - val_loss: 10.6457\n",
      "Epoch 427/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.4440 - val_loss: 9.0650\n",
      "Epoch 428/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.4360 - val_loss: 9.4575\n",
      "Epoch 429/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.3739 - val_loss: 9.3841\n",
      "Epoch 430/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.2997 - val_loss: 9.2163\n",
      "Epoch 431/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.2914 - val_loss: 9.1993\n",
      "Epoch 432/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3236 - val_loss: 8.7777\n",
      "Epoch 433/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5487 - val_loss: 10.0189\n",
      "Epoch 434/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.5555 - val_loss: 9.2110\n",
      "Epoch 435/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.4370 - val_loss: 9.3765\n",
      "Epoch 436/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.3325 - val_loss: 9.1230\n",
      "Epoch 437/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2798 - val_loss: 8.8909\n",
      "Epoch 438/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 4.2932 - val_loss: 9.7275\n",
      "Epoch 439/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3172 - val_loss: 9.3851\n",
      "Epoch 440/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.2876 - val_loss: 9.3652\n",
      "Epoch 441/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.2711 - val_loss: 9.2681\n",
      "Epoch 442/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.3391 - val_loss: 9.1983\n",
      "Epoch 443/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.3957 - val_loss: 9.9871\n",
      "Epoch 444/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4796 - val_loss: 9.1034\n",
      "Epoch 445/1000\n",
      "274/274 [==============================] - 0s 115us/step - loss: 4.8229 - val_loss: 9.2239\n",
      "Epoch 446/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3997 - val_loss: 9.4003\n",
      "Epoch 447/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3582 - val_loss: 9.4922\n",
      "Epoch 448/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6103 - val_loss: 9.1625\n",
      "Epoch 449/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.3870 - val_loss: 10.5556\n",
      "Epoch 450/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5555 - val_loss: 8.9700\n",
      "Epoch 451/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.2522 - val_loss: 9.3804\n",
      "Epoch 452/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.2645 - val_loss: 9.1518\n",
      "Epoch 453/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.2925 - val_loss: 9.0951\n",
      "Epoch 454/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 104us/step - loss: 4.2969 - val_loss: 9.1109\n",
      "Epoch 455/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3954 - val_loss: 10.2197\n",
      "Epoch 456/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3933 - val_loss: 9.0339\n",
      "Epoch 457/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.3722 - val_loss: 8.9467\n",
      "Epoch 458/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.8038 - val_loss: 10.5775\n",
      "Epoch 459/1000\n",
      "274/274 [==============================] - 0s 138us/step - loss: 4.5221 - val_loss: 9.1970\n",
      "Epoch 460/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.3435 - val_loss: 9.1702\n",
      "Epoch 461/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.3074 - val_loss: 9.4111\n",
      "Epoch 462/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3969 - val_loss: 10.0684\n",
      "Epoch 463/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3753 - val_loss: 9.0098\n",
      "Epoch 464/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3539 - val_loss: 9.2453\n",
      "Epoch 465/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2893 - val_loss: 9.6265\n",
      "Epoch 466/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6668 - val_loss: 9.3949\n",
      "Epoch 467/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8173 - val_loss: 10.6516\n",
      "Epoch 468/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5055 - val_loss: 9.3574\n",
      "Epoch 469/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4032 - val_loss: 9.1456\n",
      "Epoch 470/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2821 - val_loss: 9.3635\n",
      "Epoch 471/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2435 - val_loss: 9.3674\n",
      "Epoch 472/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5054 - val_loss: 10.5870\n",
      "Epoch 473/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2653 - val_loss: 9.1112\n",
      "Epoch 474/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3188 - val_loss: 9.2366\n",
      "Epoch 475/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2531 - val_loss: 9.8056\n",
      "Epoch 476/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3256 - val_loss: 9.1461\n",
      "Epoch 477/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.4071 - val_loss: 10.1256\n",
      "Epoch 478/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2709 - val_loss: 9.1100\n",
      "Epoch 479/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4492 - val_loss: 9.4143\n",
      "Epoch 480/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2209 - val_loss: 9.6156\n",
      "Epoch 481/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3259 - val_loss: 8.9968\n",
      "Epoch 482/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3835 - val_loss: 10.3674\n",
      "Epoch 483/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.4927 - val_loss: 9.7338\n",
      "Epoch 484/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2772 - val_loss: 9.2439\n",
      "Epoch 485/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.1763 - val_loss: 9.3668\n",
      "Epoch 486/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.1773 - val_loss: 9.8341\n",
      "Epoch 487/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3787 - val_loss: 9.2653\n",
      "Epoch 488/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2198 - val_loss: 9.2364\n",
      "Epoch 489/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2650 - val_loss: 9.2991\n",
      "Epoch 490/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1934 - val_loss: 9.6812\n",
      "Epoch 491/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2570 - val_loss: 9.3905\n",
      "Epoch 492/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3324 - val_loss: 9.6025\n",
      "Epoch 493/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 4.2941 - val_loss: 9.4883\n",
      "Epoch 494/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.1333 - val_loss: 9.3486\n",
      "Epoch 495/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3129 - val_loss: 10.1035\n",
      "Epoch 496/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3879 - val_loss: 9.3970\n",
      "Epoch 497/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7906 - val_loss: 10.9728\n",
      "Epoch 498/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.5136 - val_loss: 9.2336\n",
      "Epoch 499/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1223 - val_loss: 9.4107\n",
      "Epoch 500/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2126 - val_loss: 9.2432\n",
      "Epoch 501/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1803 - val_loss: 9.0122\n",
      "Epoch 502/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 4.2193 - val_loss: 9.3241\n",
      "Epoch 503/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.2763 - val_loss: 9.4082\n",
      "Epoch 504/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2438 - val_loss: 9.2735\n",
      "Epoch 505/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2546 - val_loss: 9.4161\n",
      "Epoch 506/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.4292 - val_loss: 11.0572\n",
      "Epoch 507/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.5235 - val_loss: 9.6571\n",
      "Epoch 508/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4511 - val_loss: 10.5286\n",
      "Epoch 509/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5265 - val_loss: 9.0975\n",
      "Epoch 510/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2754 - val_loss: 9.5009\n",
      "Epoch 511/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2395 - val_loss: 9.3977\n",
      "Epoch 512/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2840 - val_loss: 9.2066\n",
      "Epoch 513/1000\n",
      "274/274 [==============================] - 0s 135us/step - loss: 4.4232 - val_loss: 9.4811\n",
      "Epoch 514/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 4.1685 - val_loss: 9.6009\n",
      "Epoch 515/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3873 - val_loss: 9.7364\n",
      "Epoch 516/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.7566 - val_loss: 8.9706\n",
      "Epoch 517/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4852 - val_loss: 9.2422\n",
      "Epoch 518/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 4.3577 - val_loss: 9.7237\n",
      "Epoch 519/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 4.3057 - val_loss: 9.9055\n",
      "Epoch 520/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 4.2377 - val_loss: 9.2466\n",
      "Epoch 521/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2717 - val_loss: 9.5813\n",
      "Epoch 522/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.2485 - val_loss: 10.0077\n",
      "Epoch 523/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 4.2799 - val_loss: 10.1829\n",
      "Epoch 524/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3574 - val_loss: 9.5767\n",
      "Epoch 525/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.3026 - val_loss: 9.3502\n",
      "Epoch 526/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3517 - val_loss: 9.5952\n",
      "Epoch 527/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2968 - val_loss: 10.1376\n",
      "Epoch 528/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2083 - val_loss: 9.3600\n",
      "Epoch 529/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.2573 - val_loss: 9.7248\n",
      "Epoch 530/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1488 - val_loss: 9.5269\n",
      "Epoch 531/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 95us/step - loss: 4.2219 - val_loss: 9.4810\n",
      "Epoch 532/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2167 - val_loss: 10.1040\n",
      "Epoch 533/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.3320 - val_loss: 10.1112\n",
      "Epoch 534/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 4.8607 - val_loss: 9.3938\n",
      "Epoch 535/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3523 - val_loss: 10.4381\n",
      "Epoch 536/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3567 - val_loss: 9.5019\n",
      "Epoch 537/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2067 - val_loss: 9.7772\n",
      "Epoch 538/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.1895 - val_loss: 9.5854\n",
      "Epoch 539/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.2362 - val_loss: 9.8219\n",
      "Epoch 540/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.2714 - val_loss: 10.0216\n",
      "Epoch 541/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.2124 - val_loss: 9.3960\n",
      "Epoch 542/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3854 - val_loss: 9.7152\n",
      "Epoch 543/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.2424 - val_loss: 9.7559\n",
      "Epoch 544/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2601 - val_loss: 10.2145\n",
      "Epoch 545/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6502 - val_loss: 9.6895\n",
      "Epoch 546/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.0785 - val_loss: 12.7016\n",
      "Epoch 547/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 5.8303 - val_loss: 9.6510\n",
      "Epoch 548/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.1356 - val_loss: 9.4644\n",
      "Epoch 549/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.5823 - val_loss: 10.1525\n",
      "Epoch 550/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2905 - val_loss: 9.4151\n",
      "Epoch 551/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.2708 - val_loss: 9.5677\n",
      "Epoch 552/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1854 - val_loss: 10.9459\n",
      "Epoch 553/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3494 - val_loss: 9.6170\n",
      "Epoch 554/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.2857 - val_loss: 10.8676\n",
      "Epoch 555/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3829 - val_loss: 9.5506\n",
      "Epoch 556/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2899 - val_loss: 9.5746\n",
      "Epoch 557/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1747 - val_loss: 9.9560\n",
      "Epoch 558/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.3186 - val_loss: 9.7378\n",
      "Epoch 559/1000\n",
      "274/274 [==============================] - 0s 135us/step - loss: 4.1081 - val_loss: 10.0931\n",
      "Epoch 560/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.4336 - val_loss: 9.8424\n",
      "Epoch 561/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2645 - val_loss: 9.5064\n",
      "Epoch 562/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2994 - val_loss: 9.5265\n",
      "Epoch 563/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4305 - val_loss: 9.3604\n",
      "Epoch 564/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3356 - val_loss: 10.1074\n",
      "Epoch 565/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.3232 - val_loss: 10.2872\n",
      "Epoch 566/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 4.2226 - val_loss: 9.7101\n",
      "Epoch 567/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2882 - val_loss: 10.0305\n",
      "Epoch 568/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.2924 - val_loss: 10.2705\n",
      "Epoch 569/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4752 - val_loss: 9.6094\n",
      "Epoch 570/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2505 - val_loss: 9.9408\n",
      "Epoch 571/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2207 - val_loss: 10.0661\n",
      "Epoch 572/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.2561 - val_loss: 10.1691\n",
      "Epoch 573/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 4.1969 - val_loss: 9.6998\n",
      "Epoch 574/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2755 - val_loss: 10.7307\n",
      "Epoch 575/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3956 - val_loss: 9.6360\n",
      "Epoch 576/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4114 - val_loss: 9.4838\n",
      "Epoch 577/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.6537 - val_loss: 10.8051\n",
      "Epoch 578/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3097 - val_loss: 9.5040\n",
      "Epoch 579/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.1735 - val_loss: 9.7251\n",
      "Epoch 580/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.1938 - val_loss: 9.5982\n",
      "Epoch 581/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.1389 - val_loss: 10.0677\n",
      "Epoch 582/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2404 - val_loss: 10.0446\n",
      "Epoch 583/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1909 - val_loss: 9.6019\n",
      "Epoch 584/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1955 - val_loss: 10.2647\n",
      "Epoch 585/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 4.0831 - val_loss: 9.5626\n",
      "Epoch 586/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.2219 - val_loss: 10.3473\n",
      "Epoch 587/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1439 - val_loss: 9.8681\n",
      "Epoch 588/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.1748 - val_loss: 10.2476\n",
      "Epoch 589/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 4.3279 - val_loss: 9.5097\n",
      "Epoch 590/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 4.3162 - val_loss: 10.1918\n",
      "Epoch 591/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.3974 - val_loss: 10.0877\n",
      "Epoch 592/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4486 - val_loss: 9.5314\n",
      "Epoch 593/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5909 - val_loss: 10.4980\n",
      "Epoch 594/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 4.2109 - val_loss: 9.5265\n",
      "Epoch 595/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1322 - val_loss: 10.4220\n",
      "Epoch 596/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2383 - val_loss: 9.6149\n",
      "Epoch 597/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.0279 - val_loss: 10.1942\n",
      "Epoch 598/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.2647 - val_loss: 10.0170\n",
      "Epoch 599/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.2679 - val_loss: 9.7729\n",
      "Epoch 600/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1237 - val_loss: 10.1917\n",
      "Epoch 601/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.2367 - val_loss: 9.6865\n",
      "Epoch 602/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2269 - val_loss: 10.1451\n",
      "Epoch 603/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2783 - val_loss: 10.3351\n",
      "Epoch 604/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2400 - val_loss: 9.6826\n",
      "Epoch 605/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2608 - val_loss: 10.9449\n",
      "Epoch 606/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1950 - val_loss: 9.4379\n",
      "Epoch 607/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.1628 - val_loss: 10.9945\n",
      "Epoch 608/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 95us/step - loss: 4.6729 - val_loss: 10.1646\n",
      "Epoch 609/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5066 - val_loss: 10.8172\n",
      "Epoch 610/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 4.3398 - val_loss: 9.7255\n",
      "Epoch 611/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.1671 - val_loss: 9.9653\n",
      "Epoch 612/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1306 - val_loss: 10.2914\n",
      "Epoch 613/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1122 - val_loss: 9.7963\n",
      "Epoch 614/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2293 - val_loss: 10.8821\n",
      "Epoch 615/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4651 - val_loss: 9.9007\n",
      "Epoch 616/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3097 - val_loss: 9.6219\n",
      "Epoch 617/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.3963 - val_loss: 10.7988\n",
      "Epoch 618/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.2435 - val_loss: 10.1951\n",
      "Epoch 619/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.1164 - val_loss: 10.1152\n",
      "Epoch 620/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.2461 - val_loss: 11.1210\n",
      "Epoch 621/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 4.2903 - val_loss: 9.9055\n",
      "Epoch 622/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1327 - val_loss: 10.8672\n",
      "Epoch 623/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 4.2332 - val_loss: 9.7719\n",
      "Epoch 624/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.3209 - val_loss: 10.0205\n",
      "Epoch 625/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.0733 - val_loss: 10.2194\n",
      "Epoch 626/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4775 - val_loss: 9.6827\n",
      "Epoch 627/1000\n",
      "274/274 [==============================] - 0s 115us/step - loss: 4.5801 - val_loss: 10.4060\n",
      "Epoch 628/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2364 - val_loss: 10.2604\n",
      "Epoch 629/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.2539 - val_loss: 9.6772\n",
      "Epoch 630/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.2557 - val_loss: 10.7595\n",
      "Epoch 631/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4450 - val_loss: 9.8795\n",
      "Epoch 632/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.2336 - val_loss: 10.3679\n",
      "Epoch 633/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.2807 - val_loss: 10.0022\n",
      "Epoch 634/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2844 - val_loss: 10.1696\n",
      "Epoch 635/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1929 - val_loss: 10.5721\n",
      "Epoch 636/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1676 - val_loss: 9.8090\n",
      "Epoch 637/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3952 - val_loss: 10.5152\n",
      "Epoch 638/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2607 - val_loss: 10.4461\n",
      "Epoch 639/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.1543 - val_loss: 9.9633\n",
      "Epoch 640/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.3325 - val_loss: 9.7117\n",
      "Epoch 641/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1747 - val_loss: 10.3426\n",
      "Epoch 642/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2116 - val_loss: 9.9056\n",
      "Epoch 643/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2883 - val_loss: 9.9436\n",
      "Epoch 644/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.3128 - val_loss: 10.6968\n",
      "Epoch 645/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.1241 - val_loss: 10.0809\n",
      "Epoch 646/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1948 - val_loss: 10.4233\n",
      "Epoch 647/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.4018 - val_loss: 10.0488\n",
      "Epoch 648/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.2362 - val_loss: 10.1005\n",
      "Epoch 649/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4989 - val_loss: 10.1591\n",
      "Epoch 650/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3177 - val_loss: 10.1344\n",
      "Epoch 651/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 4.5255 - val_loss: 10.2944\n",
      "Epoch 652/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5434 - val_loss: 11.0031\n",
      "Epoch 653/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.5543 - val_loss: 9.9573\n",
      "Epoch 654/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 4.2817 - val_loss: 9.8108\n",
      "Epoch 655/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.1596 - val_loss: 10.0313\n",
      "Epoch 656/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2125 - val_loss: 10.7889\n",
      "Epoch 657/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2816 - val_loss: 9.8285\n",
      "Epoch 658/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4863 - val_loss: 10.6486\n",
      "Epoch 659/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 4.1387 - val_loss: 10.2323\n",
      "Epoch 660/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0648 - val_loss: 10.3682\n",
      "Epoch 661/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1542 - val_loss: 9.9965\n",
      "Epoch 662/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0960 - val_loss: 10.0054\n",
      "Epoch 663/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1495 - val_loss: 10.3972\n",
      "Epoch 664/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.1327 - val_loss: 9.9065\n",
      "Epoch 665/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.9036 - val_loss: 12.1866\n",
      "Epoch 666/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5493 - val_loss: 9.8872\n",
      "Epoch 667/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.3371 - val_loss: 10.5598\n",
      "Epoch 668/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1965 - val_loss: 10.1950\n",
      "Epoch 669/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1832 - val_loss: 9.8675\n",
      "Epoch 670/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6220 - val_loss: 10.3849\n",
      "Epoch 671/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.0777 - val_loss: 9.9508\n",
      "Epoch 672/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1234 - val_loss: 10.4029\n",
      "Epoch 673/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1208 - val_loss: 10.4142\n",
      "Epoch 674/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1562 - val_loss: 9.9898\n",
      "Epoch 675/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.1933 - val_loss: 11.2869\n",
      "Epoch 676/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.2803 - val_loss: 10.0905\n",
      "Epoch 677/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.3714 - val_loss: 10.4454\n",
      "Epoch 678/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.2874 - val_loss: 10.0863\n",
      "Epoch 679/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1462 - val_loss: 9.9897\n",
      "Epoch 680/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.1115 - val_loss: 10.4621\n",
      "Epoch 681/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.1473 - val_loss: 10.3504\n",
      "Epoch 682/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0380 - val_loss: 10.3625\n",
      "Epoch 683/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1584 - val_loss: 10.2658\n",
      "Epoch 684/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1773 - val_loss: 10.9351\n",
      "Epoch 685/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 92us/step - loss: 4.1792 - val_loss: 10.5408\n",
      "Epoch 686/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.1334 - val_loss: 10.4492\n",
      "Epoch 687/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.0765 - val_loss: 10.2519\n",
      "Epoch 688/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 4.3177 - val_loss: 10.5938\n",
      "Epoch 689/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.5422 - val_loss: 10.0819\n",
      "Epoch 690/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3527 - val_loss: 10.3182\n",
      "Epoch 691/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.1428 - val_loss: 10.2652\n",
      "Epoch 692/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 4.1332 - val_loss: 10.6366\n",
      "Epoch 693/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 4.2081 - val_loss: 10.3945\n",
      "Epoch 694/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 4.2350 - val_loss: 10.1348\n",
      "Epoch 695/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0959 - val_loss: 10.5439\n",
      "Epoch 696/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.0891 - val_loss: 10.4701\n",
      "Epoch 697/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0892 - val_loss: 10.9432\n",
      "Epoch 698/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 4.2925 - val_loss: 10.3358\n",
      "Epoch 699/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5395 - val_loss: 10.1378\n",
      "Epoch 700/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.4334 - val_loss: 10.5726\n",
      "Epoch 701/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 4.4491 - val_loss: 11.7105\n",
      "Epoch 702/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.5683 - val_loss: 10.6225\n",
      "Epoch 703/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5007 - val_loss: 11.9188\n",
      "Epoch 704/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.7163 - val_loss: 10.5674\n",
      "Epoch 705/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3230 - val_loss: 10.4129\n",
      "Epoch 706/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1023 - val_loss: 10.5216\n",
      "Epoch 707/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1747 - val_loss: 10.0754\n",
      "Epoch 708/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.4169 - val_loss: 11.7768\n",
      "Epoch 709/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2680 - val_loss: 10.3510\n",
      "Epoch 710/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.3676 - val_loss: 11.5218\n",
      "Epoch 711/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1969 - val_loss: 10.0802\n",
      "Epoch 712/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.2347 - val_loss: 10.2289\n",
      "Epoch 713/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2148 - val_loss: 10.8016\n",
      "Epoch 714/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.2136 - val_loss: 10.4365\n",
      "Epoch 715/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.0787 - val_loss: 10.6222\n",
      "Epoch 716/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0844 - val_loss: 10.5491\n",
      "Epoch 717/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.0713 - val_loss: 10.6114\n",
      "Epoch 718/1000\n",
      "274/274 [==============================] - 0s 135us/step - loss: 4.1452 - val_loss: 10.4238\n",
      "Epoch 719/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 4.0403 - val_loss: 10.3361\n",
      "Epoch 720/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.0484 - val_loss: 10.9399\n",
      "Epoch 721/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2012 - val_loss: 10.5152\n",
      "Epoch 722/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.4663 - val_loss: 10.4535\n",
      "Epoch 723/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.5184 - val_loss: 11.8482\n",
      "Epoch 724/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3385 - val_loss: 10.7521\n",
      "Epoch 725/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5148 - val_loss: 10.9680\n",
      "Epoch 726/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.3827 - val_loss: 11.1726\n",
      "Epoch 727/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.2529 - val_loss: 10.3395\n",
      "Epoch 728/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2900 - val_loss: 11.4603\n",
      "Epoch 729/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.5215 - val_loss: 10.4679\n",
      "Epoch 730/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6718 - val_loss: 10.0733\n",
      "Epoch 731/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3467 - val_loss: 11.0200\n",
      "Epoch 732/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2497 - val_loss: 10.4556\n",
      "Epoch 733/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.1455 - val_loss: 10.8118\n",
      "Epoch 734/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.1115 - val_loss: 10.1870\n",
      "Epoch 735/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.3566 - val_loss: 11.1885\n",
      "Epoch 736/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 4.3681 - val_loss: 11.0161\n",
      "Epoch 737/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.4510 - val_loss: 10.7868\n",
      "Epoch 738/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 4.4771 - val_loss: 12.4058\n",
      "Epoch 739/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 4.5976 - val_loss: 10.4310\n",
      "Epoch 740/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0767 - val_loss: 11.2906\n",
      "Epoch 741/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.1594 - val_loss: 10.5002\n",
      "Epoch 742/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1869 - val_loss: 10.4802\n",
      "Epoch 743/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0574 - val_loss: 10.9062\n",
      "Epoch 744/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2578 - val_loss: 10.2890\n",
      "Epoch 745/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.2688 - val_loss: 11.0919\n",
      "Epoch 746/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.1513 - val_loss: 10.4355\n",
      "Epoch 747/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.2804 - val_loss: 10.8263\n",
      "Epoch 748/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.5192 - val_loss: 11.3512\n",
      "Epoch 749/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4749 - val_loss: 10.6349\n",
      "Epoch 750/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.5466 - val_loss: 10.2966\n",
      "Epoch 751/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.1302 - val_loss: 10.9352\n",
      "Epoch 752/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2031 - val_loss: 10.3387\n",
      "Epoch 753/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 4.574 - 0s 102us/step - loss: 4.1251 - val_loss: 10.4856\n",
      "Epoch 754/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.0546 - val_loss: 10.3375\n",
      "Epoch 755/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.0432 - val_loss: 11.4849\n",
      "Epoch 756/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0986 - val_loss: 10.5176\n",
      "Epoch 757/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.2043 - val_loss: 10.3763\n",
      "Epoch 758/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.3197 - val_loss: 10.6025\n",
      "Epoch 759/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.2401 - val_loss: 10.9394\n",
      "Epoch 760/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.0536 - val_loss: 10.7568\n",
      "Epoch 761/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 4.1368 - val_loss: 10.4841\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 762/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.1360 - val_loss: 10.9585\n",
      "Epoch 763/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.9649 - val_loss: 10.6265\n",
      "Epoch 764/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0454 - val_loss: 10.9782\n",
      "Epoch 765/1000\n",
      "274/274 [==============================] - 0s 119us/step - loss: 4.0684 - val_loss: 10.7562\n",
      "Epoch 766/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0358 - val_loss: 11.0661\n",
      "Epoch 767/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1065 - val_loss: 11.0988\n",
      "Epoch 768/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2663 - val_loss: 10.7265\n",
      "Epoch 769/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 4.0301 - val_loss: 10.7514\n",
      "Epoch 770/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.1036 - val_loss: 10.9790\n",
      "Epoch 771/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0803 - val_loss: 10.7110\n",
      "Epoch 772/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.0432 - val_loss: 11.3344\n",
      "Epoch 773/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.3222 - val_loss: 11.0252\n",
      "Epoch 774/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.3095 - val_loss: 10.5839\n",
      "Epoch 775/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 3.794 - 0s 116us/step - loss: 4.4128 - val_loss: 11.5334\n",
      "Epoch 776/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.2625 - val_loss: 10.8315\n",
      "Epoch 777/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1480 - val_loss: 10.6656\n",
      "Epoch 778/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1223 - val_loss: 10.5002\n",
      "Epoch 779/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2324 - val_loss: 11.8343\n",
      "Epoch 780/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.2453 - val_loss: 10.6823\n",
      "Epoch 781/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.1336 - val_loss: 10.8704\n",
      "Epoch 782/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 4.244 - 0s 102us/step - loss: 4.0867 - val_loss: 11.0376\n",
      "Epoch 783/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.1763 - val_loss: 10.8608\n",
      "Epoch 784/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 4.0919 - val_loss: 11.3559\n",
      "Epoch 785/1000\n",
      "274/274 [==============================] - 0s 135us/step - loss: 4.1192 - val_loss: 10.6879\n",
      "Epoch 786/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 4.1736 - val_loss: 10.5826\n",
      "Epoch 787/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.2136 - val_loss: 11.2336\n",
      "Epoch 788/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3308 - val_loss: 10.9607\n",
      "Epoch 789/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1931 - val_loss: 10.9501\n",
      "Epoch 790/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4185 - val_loss: 11.9371\n",
      "Epoch 791/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.3839 - val_loss: 10.7606\n",
      "Epoch 792/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2289 - val_loss: 11.4456\n",
      "Epoch 793/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3363 - val_loss: 11.4591\n",
      "Epoch 794/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2742 - val_loss: 11.5645\n",
      "Epoch 795/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.2117 - val_loss: 10.8202\n",
      "Epoch 796/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 3.9809 - val_loss: 11.7453\n",
      "Epoch 797/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1223 - val_loss: 10.8980\n",
      "Epoch 798/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.3809 - val_loss: 11.7744\n",
      "Epoch 799/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2055 - val_loss: 10.7938\n",
      "Epoch 800/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1013 - val_loss: 11.4496\n",
      "Epoch 801/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 4.0828 - val_loss: 10.6882\n",
      "Epoch 802/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 4.0779 - val_loss: 10.8388\n",
      "Epoch 803/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.0192 - val_loss: 10.8531\n",
      "Epoch 804/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9944 - val_loss: 10.9362\n",
      "Epoch 805/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.0721 - val_loss: 10.8478\n",
      "Epoch 806/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3325 - val_loss: 11.3858\n",
      "Epoch 807/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0135 - val_loss: 11.2055\n",
      "Epoch 808/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0208 - val_loss: 11.1861\n",
      "Epoch 809/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9684 - val_loss: 10.8305\n",
      "Epoch 810/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9677 - val_loss: 11.6831\n",
      "Epoch 811/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0998 - val_loss: 11.2112\n",
      "Epoch 812/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.0793 - val_loss: 11.3441\n",
      "Epoch 813/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0635 - val_loss: 10.9570\n",
      "Epoch 814/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9958 - val_loss: 11.5784\n",
      "Epoch 815/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0400 - val_loss: 11.3792\n",
      "Epoch 816/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9612 - val_loss: 10.9844\n",
      "Epoch 817/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9500 - val_loss: 11.2119\n",
      "Epoch 818/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0277 - val_loss: 11.2875\n",
      "Epoch 819/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.9651 - val_loss: 11.1667\n",
      "Epoch 820/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9835 - val_loss: 11.3285\n",
      "Epoch 821/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0437 - val_loss: 11.0068\n",
      "Epoch 822/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 4.1578 - val_loss: 10.8175\n",
      "Epoch 823/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.1108 - val_loss: 11.2772\n",
      "Epoch 824/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 4.1977 - val_loss: 11.3505\n",
      "Epoch 825/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.0888 - val_loss: 11.1933\n",
      "Epoch 826/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 4.2036 - val_loss: 11.4916\n",
      "Epoch 827/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1327 - val_loss: 11.1652\n",
      "Epoch 828/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1175 - val_loss: 11.1246\n",
      "Epoch 829/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0413 - val_loss: 11.0357\n",
      "Epoch 830/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.0253 - val_loss: 11.4853\n",
      "Epoch 831/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.1489 - val_loss: 11.1227\n",
      "Epoch 832/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0008 - val_loss: 11.5195\n",
      "Epoch 833/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1970 - val_loss: 11.8627\n",
      "Epoch 834/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2202 - val_loss: 11.4270\n",
      "Epoch 835/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 4.0907 - val_loss: 11.1698\n",
      "Epoch 836/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0062 - val_loss: 11.3992\n",
      "Epoch 837/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.1841 - val_loss: 11.2252\n",
      "Epoch 838/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 106us/step - loss: 4.0765 - val_loss: 11.4587\n",
      "Epoch 839/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.1248 - val_loss: 11.3223\n",
      "Epoch 840/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1880 - val_loss: 10.9040\n",
      "Epoch 841/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.0739 - val_loss: 12.0142\n",
      "Epoch 842/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 4.0598 - val_loss: 11.0591\n",
      "Epoch 843/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.1192 - val_loss: 12.3421\n",
      "Epoch 844/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4988 - val_loss: 11.2449\n",
      "Epoch 845/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2671 - val_loss: 10.8294\n",
      "Epoch 846/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.2244 - val_loss: 12.3807\n",
      "Epoch 847/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.4171 - val_loss: 11.3115\n",
      "Epoch 848/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9544 - val_loss: 11.4614\n",
      "Epoch 849/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9992 - val_loss: 10.9987\n",
      "Epoch 850/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0071 - val_loss: 11.5041\n",
      "Epoch 851/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.0235 - val_loss: 11.1437\n",
      "Epoch 852/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1225 - val_loss: 10.9769\n",
      "Epoch 853/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0976 - val_loss: 11.6588\n",
      "Epoch 854/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.0867 - val_loss: 11.2105\n",
      "Epoch 855/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0127 - val_loss: 11.3580\n",
      "Epoch 856/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.0186 - val_loss: 11.3566\n",
      "Epoch 857/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0001 - val_loss: 11.8027\n",
      "Epoch 858/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.9304 - val_loss: 11.1966\n",
      "Epoch 859/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.0723 - val_loss: 11.6049\n",
      "Epoch 860/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.0652 - val_loss: 11.4043\n",
      "Epoch 861/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1573 - val_loss: 11.3378\n",
      "Epoch 862/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0387 - val_loss: 11.6427\n",
      "Epoch 863/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 3.9740 - val_loss: 11.2846\n",
      "Epoch 864/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 3.9738 - val_loss: 11.3345\n",
      "Epoch 865/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 4.0330 - val_loss: 11.1385\n",
      "Epoch 866/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1261 - val_loss: 11.0207\n",
      "Epoch 867/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.0068 - val_loss: 11.7458\n",
      "Epoch 868/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 4.2485 - val_loss: 11.2395\n",
      "Epoch 869/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.1707 - val_loss: 11.8882\n",
      "Epoch 870/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1573 - val_loss: 12.0341\n",
      "Epoch 871/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9574 - val_loss: 11.5701\n",
      "Epoch 872/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 3.9964 - val_loss: 12.0192\n",
      "Epoch 873/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.2149 - val_loss: 11.6793\n",
      "Epoch 874/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.9882 - val_loss: 11.3111\n",
      "Epoch 875/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 3.9721 - val_loss: 11.3321\n",
      "Epoch 876/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 3.9654 - val_loss: 11.4920\n",
      "Epoch 877/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.9672 - val_loss: 11.2803\n",
      "Epoch 878/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.9832 - val_loss: 11.2754\n",
      "Epoch 879/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0805 - val_loss: 11.5707\n",
      "Epoch 880/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.0767 - val_loss: 11.0612\n",
      "Epoch 881/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2007 - val_loss: 13.3961\n",
      "Epoch 882/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 4.4360 - val_loss: 11.4456\n",
      "Epoch 883/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.2251 - val_loss: 11.4152\n",
      "Epoch 884/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.1067 - val_loss: 11.4303\n",
      "Epoch 885/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0205 - val_loss: 11.1436\n",
      "Epoch 886/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 3.9728 - val_loss: 12.2198\n",
      "Epoch 887/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.2661 - val_loss: 11.2574\n",
      "Epoch 888/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0184 - val_loss: 12.1861\n",
      "Epoch 889/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3803 - val_loss: 11.0866\n",
      "Epoch 890/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 4.2274 - val_loss: 11.2242\n",
      "Epoch 891/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.9942 - val_loss: 11.1279\n",
      "Epoch 892/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.0470 - val_loss: 11.6930\n",
      "Epoch 893/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 4.2170 - val_loss: 11.2711\n",
      "Epoch 894/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0424 - val_loss: 12.0384\n",
      "Epoch 895/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0806 - val_loss: 11.8289\n",
      "Epoch 896/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3438 - val_loss: 11.2459\n",
      "Epoch 897/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.5884 - val_loss: 11.9172\n",
      "Epoch 898/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2327 - val_loss: 11.1975\n",
      "Epoch 899/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.2104 - val_loss: 11.8911\n",
      "Epoch 900/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.5239 - val_loss: 11.2653\n",
      "Epoch 901/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.7892 - val_loss: 13.0735\n",
      "Epoch 902/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.1713 - val_loss: 11.6108\n",
      "Epoch 903/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8691 - val_loss: 13.7243\n",
      "Epoch 904/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 4.5909 - val_loss: 11.6315\n",
      "Epoch 905/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.3280 - val_loss: 11.4057\n",
      "Epoch 906/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 4.0076 - val_loss: 11.7655\n",
      "Epoch 907/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0846 - val_loss: 11.6731\n",
      "Epoch 908/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.9894 - val_loss: 11.9279\n",
      "Epoch 909/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.9821 - val_loss: 11.2337\n",
      "Epoch 910/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 3.9958 - val_loss: 11.7102\n",
      "Epoch 911/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9792 - val_loss: 11.3553\n",
      "Epoch 912/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.4556 - val_loss: 12.6732\n",
      "Epoch 913/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1911 - val_loss: 11.4237\n",
      "Epoch 914/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 3.9980 - val_loss: 11.4663\n",
      "Epoch 915/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 96us/step - loss: 4.0119 - val_loss: 11.5810\n",
      "Epoch 916/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.9481 - val_loss: 11.9869\n",
      "Epoch 917/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.9457 - val_loss: 11.3802\n",
      "Epoch 918/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0641 - val_loss: 11.5832\n",
      "Epoch 919/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 3.9774 - val_loss: 11.4650\n",
      "Epoch 920/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.9394 - val_loss: 11.8471\n",
      "Epoch 921/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.0522 - val_loss: 12.1762\n",
      "Epoch 922/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 4.3450 - val_loss: 11.7618\n",
      "Epoch 923/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 4.4056 - val_loss: 12.3073\n",
      "Epoch 924/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.1457 - val_loss: 11.2267\n",
      "Epoch 925/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.1655 - val_loss: 11.6413\n",
      "Epoch 926/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.1450 - val_loss: 12.0708\n",
      "Epoch 927/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0543 - val_loss: 11.7735\n",
      "Epoch 928/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.1342 - val_loss: 11.3274\n",
      "Epoch 929/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 4.6074 - val_loss: 11.6717\n",
      "Epoch 930/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 4.1367 - val_loss: 11.6613\n",
      "Epoch 931/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2749 - val_loss: 11.4251\n",
      "Epoch 932/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 4.0915 - val_loss: 12.5698\n",
      "Epoch 933/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 4.2423 - val_loss: 11.4693\n",
      "Epoch 934/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.4141 - val_loss: 12.6336\n",
      "Epoch 935/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 4.2879 - val_loss: 11.8594\n",
      "Epoch 936/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 4.0780 - val_loss: 11.4903\n",
      "Epoch 937/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.1445 - val_loss: 12.0924\n",
      "Epoch 938/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 3.8749 - val_loss: 11.7238\n",
      "Epoch 939/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.0219 - val_loss: 11.9170\n",
      "Epoch 940/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 3.9445 - val_loss: 11.3185\n",
      "Epoch 941/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.1019 - val_loss: 11.6777\n",
      "Epoch 942/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.1503 - val_loss: 11.8083\n",
      "Epoch 943/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 4.2112 - val_loss: 12.3836\n",
      "Epoch 944/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 3.9900 - val_loss: 11.2363\n",
      "Epoch 945/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0562 - val_loss: 12.2594\n",
      "Epoch 946/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.1167 - val_loss: 12.2464\n",
      "Epoch 947/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1098 - val_loss: 11.5979\n",
      "Epoch 948/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.0458 - val_loss: 11.2960\n",
      "Epoch 949/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.1268 - val_loss: 12.1823\n",
      "Epoch 950/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.1823 - val_loss: 11.5519\n",
      "Epoch 951/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.0869 - val_loss: 11.9601\n",
      "Epoch 952/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9653 - val_loss: 11.9162\n",
      "Epoch 953/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.1127 - val_loss: 11.6324\n",
      "Epoch 954/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.3618 - val_loss: 12.9244\n",
      "Epoch 955/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4078 - val_loss: 11.8515\n",
      "Epoch 956/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2950 - val_loss: 11.6501\n",
      "Epoch 957/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 4.0073 - val_loss: 11.4401\n",
      "Epoch 958/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.9221 - val_loss: 11.5375\n",
      "Epoch 959/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0037 - val_loss: 11.8410\n",
      "Epoch 960/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.0276 - val_loss: 11.7086\n",
      "Epoch 961/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0161 - val_loss: 11.4276\n",
      "Epoch 962/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 3.9811 - val_loss: 12.0954\n",
      "Epoch 963/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 4.3714 - val_loss: 12.4931\n",
      "Epoch 964/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 4.1900 - val_loss: 11.5139\n",
      "Epoch 965/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.3836 - val_loss: 12.2931\n",
      "Epoch 966/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2193 - val_loss: 11.5753\n",
      "Epoch 967/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 3.9736 - val_loss: 11.5557\n",
      "Epoch 968/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.0178 - val_loss: 11.8312\n",
      "Epoch 969/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 4.1894 - val_loss: 11.8558\n",
      "Epoch 970/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 4.2419 - val_loss: 13.9165\n",
      "Epoch 971/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.7186 - val_loss: 11.3260\n",
      "Epoch 972/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3629 - val_loss: 11.7851\n",
      "Epoch 973/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1327 - val_loss: 11.8022\n",
      "Epoch 974/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0631 - val_loss: 11.7633\n",
      "Epoch 975/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8961 - val_loss: 12.0387\n",
      "Epoch 976/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.0138 - val_loss: 11.9521\n",
      "Epoch 977/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0291 - val_loss: 11.8454\n",
      "Epoch 978/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1475 - val_loss: 11.6386\n",
      "Epoch 979/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1434 - val_loss: 12.0165\n",
      "Epoch 980/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.1610 - val_loss: 11.6715\n",
      "Epoch 981/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0333 - val_loss: 11.7072\n",
      "Epoch 982/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0492 - val_loss: 12.0442\n",
      "Epoch 983/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2175 - val_loss: 11.6504\n",
      "Epoch 984/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2011 - val_loss: 13.0382\n",
      "Epoch 985/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 4.1004 - val_loss: 11.7596\n",
      "Epoch 986/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 3.9252 - val_loss: 12.0643\n",
      "Epoch 987/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.9721 - val_loss: 11.9391\n",
      "Epoch 988/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.0829 - val_loss: 11.3948\n",
      "Epoch 989/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.9401 - val_loss: 11.7078\n",
      "Epoch 990/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0106 - val_loss: 12.7506\n",
      "Epoch 991/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.0761 - val_loss: 11.4809\n",
      "Epoch 992/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 96us/step - loss: 4.6696 - val_loss: 13.1119\n",
      "Epoch 993/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4514 - val_loss: 11.6028\n",
      "Epoch 994/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2213 - val_loss: 11.7268\n",
      "Epoch 995/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 4.0077 - val_loss: 11.5874\n",
      "Epoch 996/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.9228 - val_loss: 11.7785\n",
      "Epoch 997/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1271 - val_loss: 11.9955\n",
      "Epoch 998/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 4.1130 - val_loss: 11.7044\n",
      "Epoch 999/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 3.9191 - val_loss: 11.9441\n",
      "Epoch 1000/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 3.8885 - val_loss: 11.9091\n",
      "10.610035621513754\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 1.1639695 ,  1.283826  , -1.6898532 , -2.0601327 , -1.626264  ,\n",
       "         -1.3830483 , -0.93661493,  0.41437373, -1.2904012 , -1.0984253 ],\n",
       "        [-1.2813449 , -0.8490455 , -0.23721956, -0.5582743 ,  0.30940345,\n",
       "          1.4459466 , -1.4134902 ,  1.3078264 ,  1.2726995 ,  4.1178393 ],\n",
       "        [-1.7363635 , -0.44613016, -0.04229394,  1.9745954 ,  0.16846931,\n",
       "         -0.83163345,  0.9209264 ,  1.0743065 ,  0.21251558,  2.4405181 ],\n",
       "        [ 1.0470659 ,  1.261406  ,  1.3089259 ,  4.2053304 ,  0.14426939,\n",
       "          0.44580382,  1.6901729 , -1.0119238 , -1.3332785 , -1.1992948 ],\n",
       "        [ 1.2032675 , -0.65293646, -1.2980282 , -0.14346465,  0.44082323,\n",
       "          0.71259   , -0.04488189,  0.3742145 ,  0.19019254, -0.55804586],\n",
       "        [-0.99392384, -1.7542171 ,  1.2657083 ,  0.4681495 ,  0.50954723,\n",
       "         -1.3582423 ,  0.01497945,  0.4688064 ,  1.7239367 , -0.4600185 ],\n",
       "        [ 0.5730523 , -0.5396366 ,  2.3695383 , -0.5783853 ,  0.15894355,\n",
       "         -0.23279822,  0.46295908, -0.5603541 ,  0.09050579, -0.7695989 ]],\n",
       "       dtype=float32),\n",
       " array([-2.1425028 , -1.1077063 , -1.1814907 , -1.6659657 , -1.6498259 ,\n",
       "        -2.333044  , -2.8066547 ,  0.35827926, -2.1883807 ,  0.3889368 ],\n",
       "       dtype=float32),\n",
       " array([[-0.35923523, -0.13213024,  1.0782981 ,  0.24193822,  1.0844904 ,\n",
       "          0.47177637, -0.3626422 ,  0.60622746,  0.79894716, -0.04099224],\n",
       "        [ 0.2583194 ,  0.5718423 , -0.4581128 , -0.5441857 ,  0.28646767,\n",
       "         -0.5638933 ,  0.13724507, -0.36410958, -0.04704278, -0.5722952 ],\n",
       "        [ 0.73251027,  0.06416298, -0.05316788, -0.46902493, -0.01847261,\n",
       "         -0.5372904 ,  0.20301847, -0.5990702 , -0.12259017, -0.39887595],\n",
       "        [ 0.17566696, -0.5446977 , -0.25265267,  0.40927058, -0.17419372,\n",
       "         -0.39719126,  0.40708888, -0.3266793 ,  0.13419054, -0.47813573],\n",
       "        [ 0.66661763,  0.7489448 ,  0.13639653, -0.49982032,  0.09979361,\n",
       "         -0.69350994,  0.31718123, -0.98261726, -0.12808903, -0.8171961 ],\n",
       "        [ 0.90049416,  0.8238163 , -0.79794586, -0.92455095, -0.33925784,\n",
       "         -0.45649314,  1.0228701 , -0.5793277 , -0.7764091 , -0.03340402],\n",
       "        [ 0.22703701,  0.3848625 , -1.227111  , -0.55429494, -0.16640493,\n",
       "         -1.406166  ,  1.5004799 , -1.0882158 , -0.94078565, -0.73851913],\n",
       "        [ 0.45236334,  1.2348746 , -0.71397275, -0.5091919 , -0.35546875,\n",
       "         -1.256385  ,  1.3830163 , -1.050876  , -0.9486762 , -0.38241795],\n",
       "        [-0.55059606, -0.86538285,  1.1224055 ,  1.4199364 ,  0.5449199 ,\n",
       "          0.46479344, -1.1917825 ,  1.024     ,  1.4140518 ,  0.75713897],\n",
       "        [-0.5871981 , -0.9125149 ,  0.52675724,  0.44570845,  0.77617276,\n",
       "          0.4049912 , -0.02492827,  0.54850185,  0.78040123, -0.18061484]],\n",
       "       dtype=float32),\n",
       " array([-1.3998439, -1.5150515,  1.547059 ,  1.5124367,  1.077051 ,\n",
       "         1.516601 , -1.5710591,  1.5710084,  1.5051106,  1.4759259],\n",
       "       dtype=float32),\n",
       " array([[-0.46063018],\n",
       "        [-0.74283695],\n",
       "        [ 0.9348401 ],\n",
       "        [ 0.7244442 ],\n",
       "        [ 0.05697441],\n",
       "        [ 0.96544147],\n",
       "        [-1.1640041 ],\n",
       "        [ 1.4980309 ],\n",
       "        [ 0.82992464],\n",
       "        [ 0.783738  ]], dtype=float32),\n",
       " array([1.6141224], dtype=float32)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_autompg, history_autompg, evaluate_autompg=NN_model_structure_regression_5(X_train_autompg, X_val_autompg, Y_train_autompg, Y_val_autompg, adam2, 32, 1000, x_test_autompg, y_test_autompg)\n",
    "model_autompg.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_autompg.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_autompg_structure5_4th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_34 (Dense)             (None, 10)                80        \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 15)                165       \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 261\n",
      "Trainable params: 261\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 274 samples, validate on 59 samples\n",
      "Epoch 1/1000\n",
      "274/274 [==============================] - 0s 1ms/step - loss: 445.6013 - val_loss: 174.1335\n",
      "Epoch 2/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 117.0520 - val_loss: 51.0621\n",
      "Epoch 3/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 33.3268 - val_loss: 33.3943\n",
      "Epoch 4/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 21.6809 - val_loss: 28.0274\n",
      "Epoch 5/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 17.1516 - val_loss: 22.8342\n",
      "Epoch 6/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 15.3944 - val_loss: 19.2642\n",
      "Epoch 7/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 12.6493 - val_loss: 17.9475\n",
      "Epoch 8/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 11.2484 - val_loss: 16.8594\n",
      "Epoch 9/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 10.9318 - val_loss: 16.1770\n",
      "Epoch 10/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 10.8680 - val_loss: 16.3427\n",
      "Epoch 11/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 10.0370 - val_loss: 15.3933\n",
      "Epoch 12/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 9.9945 - val_loss: 15.1716\n",
      "Epoch 13/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 10.2275 - val_loss: 16.3680\n",
      "Epoch 14/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 9.8105 - val_loss: 13.6730\n",
      "Epoch 15/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 9.3799 - val_loss: 14.5420\n",
      "Epoch 16/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 8.9364 - val_loss: 13.2225\n",
      "Epoch 17/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 9.0008 - val_loss: 14.0638\n",
      "Epoch 18/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 9.2894 - val_loss: 12.0410\n",
      "Epoch 19/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 8.7516 - val_loss: 11.9967\n",
      "Epoch 20/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.4102 - val_loss: 12.9355\n",
      "Epoch 21/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 8.3324 - val_loss: 11.6551\n",
      "Epoch 22/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 8.1297 - val_loss: 12.0566\n",
      "Epoch 23/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 8.0913 - val_loss: 11.5797\n",
      "Epoch 24/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.2736 - val_loss: 12.0374\n",
      "Epoch 25/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 7.9008 - val_loss: 11.9629\n",
      "Epoch 26/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.8959 - val_loss: 11.7910\n",
      "Epoch 27/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 8.2545 - val_loss: 11.6201\n",
      "Epoch 28/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.5559 - val_loss: 11.1989\n",
      "Epoch 29/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.4506 - val_loss: 11.2451\n",
      "Epoch 30/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.7325 - val_loss: 11.8155\n",
      "Epoch 31/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.8745 - val_loss: 11.4932\n",
      "Epoch 32/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.3442 - val_loss: 11.4482\n",
      "Epoch 33/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 7.3006 - val_loss: 10.5979\n",
      "Epoch 34/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 7.1167 - val_loss: 10.4100\n",
      "Epoch 35/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.9050 - val_loss: 10.7166\n",
      "Epoch 36/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2310 - val_loss: 10.6224\n",
      "Epoch 37/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.8541 - val_loss: 10.6020\n",
      "Epoch 38/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.0834 - val_loss: 9.8972\n",
      "Epoch 39/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7847 - val_loss: 9.7853\n",
      "Epoch 40/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 7.0564 - val_loss: 11.0543\n",
      "Epoch 41/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 7.0977 - val_loss: 10.2094\n",
      "Epoch 42/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8606 - val_loss: 9.7003\n",
      "Epoch 43/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.7809 - val_loss: 9.5187\n",
      "Epoch 44/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.8931 - val_loss: 10.3729\n",
      "Epoch 45/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.6821 - val_loss: 9.3670\n",
      "Epoch 46/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6117 - val_loss: 9.8775\n",
      "Epoch 47/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7397 - val_loss: 9.4373\n",
      "Epoch 48/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3787 - val_loss: 9.3277\n",
      "Epoch 49/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.4435 - val_loss: 8.9928\n",
      "Epoch 50/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.4660 - val_loss: 9.0015\n",
      "Epoch 51/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3656 - val_loss: 9.4186\n",
      "Epoch 52/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.6261 - val_loss: 8.9080\n",
      "Epoch 53/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.3059 - val_loss: 8.9571\n",
      "Epoch 54/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.2846 - val_loss: 9.1276\n",
      "Epoch 55/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.3645 - val_loss: 8.6964\n",
      "Epoch 56/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.2361 - val_loss: 8.8420\n",
      "Epoch 57/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1612 - val_loss: 9.4144\n",
      "Epoch 58/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2773 - val_loss: 8.5313\n",
      "Epoch 59/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1153 - val_loss: 8.9082\n",
      "Epoch 60/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7869 - val_loss: 8.8365\n",
      "Epoch 61/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0715 - val_loss: 8.4295\n",
      "Epoch 62/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.2084 - val_loss: 8.5387\n",
      "Epoch 63/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3434 - val_loss: 8.7861\n",
      "Epoch 64/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1615 - val_loss: 8.5308\n",
      "Epoch 65/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9681 - val_loss: 7.9286\n",
      "Epoch 66/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1277 - val_loss: 8.0670\n",
      "Epoch 67/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5421 - val_loss: 9.1155\n",
      "Epoch 68/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.6911 - val_loss: 8.0007\n",
      "Epoch 69/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 91us/step - loss: 6.1084 - val_loss: 8.4643\n",
      "Epoch 70/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.4549 - val_loss: 8.4438\n",
      "Epoch 71/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.4991 - val_loss: 8.1932\n",
      "Epoch 72/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0135 - val_loss: 9.0321\n",
      "Epoch 73/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3215 - val_loss: 8.8011\n",
      "Epoch 74/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.2612 - val_loss: 7.8989\n",
      "Epoch 75/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.9797 - val_loss: 8.0604\n",
      "Epoch 76/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8681 - val_loss: 7.9024\n",
      "Epoch 77/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 6.1052 - val_loss: 8.4838\n",
      "Epoch 78/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8517 - val_loss: 7.7803\n",
      "Epoch 79/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.8402 - val_loss: 7.9242\n",
      "Epoch 80/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.9150 - val_loss: 8.0143\n",
      "Epoch 81/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8410 - val_loss: 7.9603\n",
      "Epoch 82/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6800 - val_loss: 8.0329\n",
      "Epoch 83/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7787 - val_loss: 7.6588\n",
      "Epoch 84/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.8909 - val_loss: 8.4661\n",
      "Epoch 85/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.8580 - val_loss: 8.2957\n",
      "Epoch 86/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.1001 - val_loss: 8.2963\n",
      "Epoch 87/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0933 - val_loss: 8.8315\n",
      "Epoch 88/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.9562 - val_loss: 7.5777\n",
      "Epoch 89/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9553 - val_loss: 7.5389\n",
      "Epoch 90/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6600 - val_loss: 8.1599\n",
      "Epoch 91/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8509 - val_loss: 7.7764\n",
      "Epoch 92/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6541 - val_loss: 7.9833\n",
      "Epoch 93/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4994 - val_loss: 7.9546\n",
      "Epoch 94/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8279 - val_loss: 8.4113\n",
      "Epoch 95/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.8218 - val_loss: 7.9557\n",
      "Epoch 96/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.5445 - val_loss: 7.7860\n",
      "Epoch 97/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6038 - val_loss: 7.8642\n",
      "Epoch 98/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6529 - val_loss: 7.9972\n",
      "Epoch 99/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7239 - val_loss: 8.0106\n",
      "Epoch 100/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4792 - val_loss: 7.5623\n",
      "Epoch 101/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4276 - val_loss: 7.7063\n",
      "Epoch 102/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4555 - val_loss: 7.8343\n",
      "Epoch 103/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.4052 - val_loss: 8.2313\n",
      "Epoch 104/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7543 - val_loss: 7.6921\n",
      "Epoch 105/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.8001 - val_loss: 8.0136\n",
      "Epoch 106/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4622 - val_loss: 9.0338\n",
      "Epoch 107/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8859 - val_loss: 8.5864\n",
      "Epoch 108/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 5.5102 - val_loss: 7.6797\n",
      "Epoch 109/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.3162 - val_loss: 7.8726\n",
      "Epoch 110/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.4156 - val_loss: 8.0041\n",
      "Epoch 111/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 5.5642 - val_loss: 8.9560\n",
      "Epoch 112/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.8933 - val_loss: 7.9132\n",
      "Epoch 113/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.9627 - val_loss: 8.7787\n",
      "Epoch 114/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.9435 - val_loss: 10.3405\n",
      "Epoch 115/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5244 - val_loss: 8.3972\n",
      "Epoch 116/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8307 - val_loss: 8.9967\n",
      "Epoch 117/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2597 - val_loss: 11.2155\n",
      "Epoch 118/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.1261 - val_loss: 7.8165\n",
      "Epoch 119/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.7742 - val_loss: 8.4862\n",
      "Epoch 120/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7928 - val_loss: 8.5836\n",
      "Epoch 121/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4809 - val_loss: 8.8664\n",
      "Epoch 122/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7579 - val_loss: 8.4861\n",
      "Epoch 123/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5534 - val_loss: 8.2768\n",
      "Epoch 124/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4388 - val_loss: 8.4427\n",
      "Epoch 125/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6692 - val_loss: 8.2519\n",
      "Epoch 126/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6614 - val_loss: 8.5509\n",
      "Epoch 127/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4659 - val_loss: 8.0204\n",
      "Epoch 128/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 5.862 - 0s 94us/step - loss: 5.2719 - val_loss: 8.2136\n",
      "Epoch 129/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.5228 - val_loss: 8.0300\n",
      "Epoch 130/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.3085 - val_loss: 7.8821\n",
      "Epoch 131/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6374 - val_loss: 7.7396\n",
      "Epoch 132/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4465 - val_loss: 8.0986\n",
      "Epoch 133/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.3721 - val_loss: 8.4078\n",
      "Epoch 134/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.2778 - val_loss: 9.2748\n",
      "Epoch 135/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8551 - val_loss: 8.3789\n",
      "Epoch 136/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5421 - val_loss: 8.8662\n",
      "Epoch 137/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.2111 - val_loss: 8.8737\n",
      "Epoch 138/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.8262 - val_loss: 8.4608\n",
      "Epoch 139/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.5276 - val_loss: 8.5515\n",
      "Epoch 140/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4302 - val_loss: 8.5600\n",
      "Epoch 141/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.7249 - val_loss: 9.0186\n",
      "Epoch 142/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.2290 - val_loss: 8.2509\n",
      "Epoch 143/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.4819 - val_loss: 7.9791\n",
      "Epoch 144/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1663 - val_loss: 8.3907\n",
      "Epoch 145/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2457 - val_loss: 8.0525\n",
      "Epoch 146/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4386 - val_loss: 8.0810\n",
      "Epoch 147/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 95us/step - loss: 5.3076 - val_loss: 9.0301\n",
      "Epoch 148/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.3261 - val_loss: 8.4740\n",
      "Epoch 149/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.2774 - val_loss: 8.1230\n",
      "Epoch 150/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.3263 - val_loss: 8.0595\n",
      "Epoch 151/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.9487 - val_loss: 8.9467\n",
      "Epoch 152/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.2352 - val_loss: 8.5087\n",
      "Epoch 153/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3649 - val_loss: 8.7053\n",
      "Epoch 154/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.1606 - val_loss: 8.2323\n",
      "Epoch 155/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.3526 - val_loss: 8.1887\n",
      "Epoch 156/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.1027 - val_loss: 8.7546\n",
      "Epoch 157/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1720 - val_loss: 8.5289\n",
      "Epoch 158/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1546 - val_loss: 8.0653\n",
      "Epoch 159/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1236 - val_loss: 8.4007\n",
      "Epoch 160/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1767 - val_loss: 9.1073\n",
      "Epoch 161/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0726 - val_loss: 8.5872\n",
      "Epoch 162/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.0985 - val_loss: 8.4356\n",
      "Epoch 163/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2026 - val_loss: 8.4924\n",
      "Epoch 164/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.1019 - val_loss: 8.6635\n",
      "Epoch 165/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.2433 - val_loss: 9.4314\n",
      "Epoch 166/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 5.3997 - val_loss: 8.2852\n",
      "Epoch 167/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.1706 - val_loss: 8.2072\n",
      "Epoch 168/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1640 - val_loss: 9.0679\n",
      "Epoch 169/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.2395 - val_loss: 8.5959\n",
      "Epoch 170/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.3630 - val_loss: 8.9670\n",
      "Epoch 171/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.3547 - val_loss: 8.6075\n",
      "Epoch 172/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2018 - val_loss: 9.0393\n",
      "Epoch 173/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.0855 - val_loss: 8.7014\n",
      "Epoch 174/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.2245 - val_loss: 8.5413\n",
      "Epoch 175/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.7011 - val_loss: 10.1695\n",
      "Epoch 176/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3383 - val_loss: 9.1763\n",
      "Epoch 177/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.4513 - val_loss: 8.7869\n",
      "Epoch 178/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.0054 - val_loss: 9.2368\n",
      "Epoch 179/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4062 - val_loss: 9.4488\n",
      "Epoch 180/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1793 - val_loss: 8.0796\n",
      "Epoch 181/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3669 - val_loss: 9.3283\n",
      "Epoch 182/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4517 - val_loss: 9.1947\n",
      "Epoch 183/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4940 - val_loss: 10.2088\n",
      "Epoch 184/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6385 - val_loss: 9.3533\n",
      "Epoch 185/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.6827 - val_loss: 9.1264\n",
      "Epoch 186/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2476 - val_loss: 11.3415\n",
      "Epoch 187/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.0025 - val_loss: 8.3131\n",
      "Epoch 188/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.1977 - val_loss: 8.7397\n",
      "Epoch 189/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.0598 - val_loss: 9.3868\n",
      "Epoch 190/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.1410 - val_loss: 8.7319\n",
      "Epoch 191/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0878 - val_loss: 9.4652\n",
      "Epoch 192/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.0978 - val_loss: 9.9654\n",
      "Epoch 193/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2833 - val_loss: 9.0700\n",
      "Epoch 194/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0541 - val_loss: 10.0283\n",
      "Epoch 195/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.1726 - val_loss: 9.0337\n",
      "Epoch 196/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.0469 - val_loss: 9.3202\n",
      "Epoch 197/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0085 - val_loss: 9.0064\n",
      "Epoch 198/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9194 - val_loss: 9.4576\n",
      "Epoch 199/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5602 - val_loss: 8.7245\n",
      "Epoch 200/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0448 - val_loss: 9.9594\n",
      "Epoch 201/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0037 - val_loss: 8.9603\n",
      "Epoch 202/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4092 - val_loss: 9.2220\n",
      "Epoch 203/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1351 - val_loss: 9.5815\n",
      "Epoch 204/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2644 - val_loss: 9.3012\n",
      "Epoch 205/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5485 - val_loss: 9.5714\n",
      "Epoch 206/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.2927 - val_loss: 9.5670\n",
      "Epoch 207/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6355 - val_loss: 9.2918\n",
      "Epoch 208/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 5.5736 - val_loss: 8.5154\n",
      "Epoch 209/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0974 - val_loss: 9.7114\n",
      "Epoch 210/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.9538 - val_loss: 9.7117\n",
      "Epoch 211/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0584 - val_loss: 8.7634\n",
      "Epoch 212/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9837 - val_loss: 11.1388\n",
      "Epoch 213/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1842 - val_loss: 9.1035\n",
      "Epoch 214/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.9273 - val_loss: 9.7805\n",
      "Epoch 215/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.8301 - val_loss: 8.9704\n",
      "Epoch 216/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 4.9393 - val_loss: 8.6084\n",
      "Epoch 217/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.8414 - val_loss: 9.0879\n",
      "Epoch 218/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7799 - val_loss: 9.0275\n",
      "Epoch 219/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.0973 - val_loss: 9.0911\n",
      "Epoch 220/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2224 - val_loss: 10.1800\n",
      "Epoch 221/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2047 - val_loss: 9.0486\n",
      "Epoch 222/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5575 - val_loss: 9.4281\n",
      "Epoch 223/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8744 - val_loss: 10.8843\n",
      "Epoch 224/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5489 - val_loss: 9.0159\n",
      "Epoch 225/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 91us/step - loss: 4.9533 - val_loss: 9.4128\n",
      "Epoch 226/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4969 - val_loss: 8.8847\n",
      "Epoch 227/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.0008 - val_loss: 8.8489\n",
      "Epoch 228/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.1219 - val_loss: 9.1341\n",
      "Epoch 229/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 4.7739 - val_loss: 9.2499\n",
      "Epoch 230/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 4.8671 - val_loss: 8.7672\n",
      "Epoch 231/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.9766 - val_loss: 8.9252\n",
      "Epoch 232/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.8046 - val_loss: 8.9312\n",
      "Epoch 233/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.9320 - val_loss: 9.8623\n",
      "Epoch 234/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 5.1576 - val_loss: 9.0835\n",
      "Epoch 235/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9259 - val_loss: 8.8867\n",
      "Epoch 236/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.8963 - val_loss: 8.8208\n",
      "Epoch 237/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.8688 - val_loss: 9.4230\n",
      "Epoch 238/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.8549 - val_loss: 8.9059\n",
      "Epoch 239/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 4.7877 - val_loss: 9.5729\n",
      "Epoch 240/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.8745 - val_loss: 9.1946\n",
      "Epoch 241/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.8998 - val_loss: 9.0008\n",
      "Epoch 242/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.8223 - val_loss: 8.5817\n",
      "Epoch 243/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8173 - val_loss: 9.7118\n",
      "Epoch 244/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9268 - val_loss: 8.9963\n",
      "Epoch 245/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8530 - val_loss: 8.9338\n",
      "Epoch 246/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 4.9200 - val_loss: 9.2682\n",
      "Epoch 247/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.0424 - val_loss: 9.1368\n",
      "Epoch 248/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 4.6517 - val_loss: 8.9578\n",
      "Epoch 249/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.7983 - val_loss: 9.0574\n",
      "Epoch 250/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 4.8913 - val_loss: 9.3903\n",
      "Epoch 251/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.0908 - val_loss: 9.0421\n",
      "Epoch 252/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9264 - val_loss: 9.2292\n",
      "Epoch 253/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.6938 - val_loss: 9.1244\n",
      "Epoch 254/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.7286 - val_loss: 9.1818\n",
      "Epoch 255/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.7175 - val_loss: 9.5525\n",
      "Epoch 256/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4119 - val_loss: 10.3584\n",
      "Epoch 257/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.4473 - val_loss: 8.9490\n",
      "Epoch 258/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5480 - val_loss: 9.7322\n",
      "Epoch 259/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2236 - val_loss: 9.5266\n",
      "Epoch 260/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.1035 - val_loss: 9.5841\n",
      "Epoch 261/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.7841 - val_loss: 9.2736\n",
      "Epoch 262/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.3128 - val_loss: 8.7500\n",
      "Epoch 263/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 4.6966 - val_loss: 9.6080\n",
      "Epoch 264/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 4.269 - 0s 91us/step - loss: 4.9310 - val_loss: 9.0988\n",
      "Epoch 265/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.8127 - val_loss: 8.8101\n",
      "Epoch 266/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.7579 - val_loss: 8.7507\n",
      "Epoch 267/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 4.9336 - val_loss: 9.1891\n",
      "Epoch 268/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3192 - val_loss: 9.5329\n",
      "Epoch 269/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.8255 - val_loss: 8.9387\n",
      "Epoch 270/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0585 - val_loss: 9.1976\n",
      "Epoch 271/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.6913 - val_loss: 9.3273\n",
      "Epoch 272/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.9328 - val_loss: 8.8669\n",
      "Epoch 273/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 4.9620 - val_loss: 9.1402\n",
      "Epoch 274/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9889 - val_loss: 8.7089\n",
      "Epoch 275/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7774 - val_loss: 9.2834\n",
      "Epoch 276/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7006 - val_loss: 8.9381\n",
      "Epoch 277/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7008 - val_loss: 8.7204\n",
      "Epoch 278/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.5853 - val_loss: 9.1194\n",
      "Epoch 279/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7149 - val_loss: 9.0816\n",
      "Epoch 280/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.0471 - val_loss: 9.1272\n",
      "Epoch 281/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6445 - val_loss: 9.6702\n",
      "Epoch 282/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.8155 - val_loss: 9.3113\n",
      "Epoch 283/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7092 - val_loss: 9.0758\n",
      "Epoch 284/1000\n",
      "274/274 [==============================] - 0s 123us/step - loss: 4.8935 - val_loss: 8.6406\n",
      "Epoch 285/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.9161 - val_loss: 9.6607\n",
      "Epoch 286/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.9822 - val_loss: 9.3544\n",
      "Epoch 287/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4135 - val_loss: 8.8136\n",
      "Epoch 288/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.6622 - val_loss: 9.1860\n",
      "Epoch 289/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6227 - val_loss: 9.3558\n",
      "Epoch 290/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.9427 - val_loss: 9.9121\n",
      "Epoch 291/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.9217 - val_loss: 9.2818\n",
      "Epoch 292/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7919 - val_loss: 9.1748\n",
      "Epoch 293/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.5500 - val_loss: 8.9244\n",
      "Epoch 294/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7818 - val_loss: 8.8515\n",
      "Epoch 295/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 4.9585 - val_loss: 11.3596\n",
      "Epoch 296/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3383 - val_loss: 9.1587\n",
      "Epoch 297/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.0613 - val_loss: 8.6948\n",
      "Epoch 298/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.3507 - val_loss: 9.0879\n",
      "Epoch 299/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9307 - val_loss: 9.3987\n",
      "Epoch 300/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.9346 - val_loss: 8.9655\n",
      "Epoch 301/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7067 - val_loss: 8.7233\n",
      "Epoch 302/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 101us/step - loss: 4.5462 - val_loss: 8.7549\n",
      "Epoch 303/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7019 - val_loss: 9.3100\n",
      "Epoch 304/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7233 - val_loss: 8.6442\n",
      "Epoch 305/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.4909 - val_loss: 8.8078\n",
      "Epoch 306/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7037 - val_loss: 9.2799\n",
      "Epoch 307/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.5130 - val_loss: 8.8287\n",
      "Epoch 308/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.5358 - val_loss: 8.7474\n",
      "Epoch 309/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.6187 - val_loss: 9.4222\n",
      "Epoch 310/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7417 - val_loss: 8.8898\n",
      "Epoch 311/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6030 - val_loss: 8.7987\n",
      "Epoch 312/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.0206 - val_loss: 10.5020\n",
      "Epoch 313/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.1532 - val_loss: 8.9963\n",
      "Epoch 314/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 4.9665 - val_loss: 9.1543\n",
      "Epoch 315/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.8658 - val_loss: 9.5018\n",
      "Epoch 316/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.8565 - val_loss: 9.0997\n",
      "Epoch 317/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.6089 - val_loss: 8.9755\n",
      "Epoch 318/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5325 - val_loss: 9.2380\n",
      "Epoch 319/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.5764 - val_loss: 8.8919\n",
      "Epoch 320/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.7095 - val_loss: 8.5567\n",
      "Epoch 321/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.7424 - val_loss: 9.8274\n",
      "Epoch 322/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.0784 - val_loss: 9.5711\n",
      "Epoch 323/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3709 - val_loss: 8.7755\n",
      "Epoch 324/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 5.4777 - val_loss: 9.6979\n",
      "Epoch 325/1000\n",
      "274/274 [==============================] - 0s 138us/step - loss: 4.8963 - val_loss: 9.9565\n",
      "Epoch 326/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 4.8313 - val_loss: 9.8447\n",
      "Epoch 327/1000\n",
      "274/274 [==============================] - 0s 298us/step - loss: 4.8823 - val_loss: 8.7403\n",
      "Epoch 328/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 5.2876 - val_loss: 9.2505\n",
      "Epoch 329/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.2171 - val_loss: 9.0915\n",
      "Epoch 330/1000\n",
      "274/274 [==============================] - 0s 138us/step - loss: 4.9812 - val_loss: 9.5556\n",
      "Epoch 331/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9063 - val_loss: 9.3167\n",
      "Epoch 332/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.7914 - val_loss: 9.2819\n",
      "Epoch 333/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.5324 - val_loss: 9.1970\n",
      "Epoch 334/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4922 - val_loss: 8.4934\n",
      "Epoch 335/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.6292 - val_loss: 9.2378\n",
      "Epoch 336/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.7156 - val_loss: 8.8833\n",
      "Epoch 337/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.9011 - val_loss: 9.0891\n",
      "Epoch 338/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.8214 - val_loss: 9.1907\n",
      "Epoch 339/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 4.7122 - val_loss: 9.2654\n",
      "Epoch 340/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5900 - val_loss: 9.1124\n",
      "Epoch 341/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6742 - val_loss: 9.0786\n",
      "Epoch 342/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 4.9515 - val_loss: 9.1092\n",
      "Epoch 343/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6639 - val_loss: 8.8663\n",
      "Epoch 344/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6261 - val_loss: 9.2049\n",
      "Epoch 345/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6940 - val_loss: 8.6752\n",
      "Epoch 346/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 4.7608 - val_loss: 9.3385\n",
      "Epoch 347/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2886 - val_loss: 9.3549\n",
      "Epoch 348/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8562 - val_loss: 9.0069\n",
      "Epoch 349/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9351 - val_loss: 9.5417\n",
      "Epoch 350/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.9987 - val_loss: 9.0784\n",
      "Epoch 351/1000\n",
      "274/274 [==============================] - 0s 142us/step - loss: 4.6309 - val_loss: 9.0466\n",
      "Epoch 352/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.4545 - val_loss: 8.8252\n",
      "Epoch 353/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6594 - val_loss: 8.7641\n",
      "Epoch 354/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6479 - val_loss: 9.1400\n",
      "Epoch 355/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.5767 - val_loss: 9.1392\n",
      "Epoch 356/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.6539 - val_loss: 8.6758\n",
      "Epoch 357/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.4122 - val_loss: 9.4813\n",
      "Epoch 358/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.5635 - val_loss: 8.5941\n",
      "Epoch 359/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.8159 - val_loss: 9.2238\n",
      "Epoch 360/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.6230 - val_loss: 9.4026\n",
      "Epoch 361/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.8995 - val_loss: 8.8873\n",
      "Epoch 362/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3998 - val_loss: 9.2214\n",
      "Epoch 363/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5017 - val_loss: 8.6758\n",
      "Epoch 364/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.4802 - val_loss: 9.0156\n",
      "Epoch 365/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.6792 - val_loss: 9.1384\n",
      "Epoch 366/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5130 - val_loss: 8.4264\n",
      "Epoch 367/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3760 - val_loss: 9.7037\n",
      "Epoch 368/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.8024 - val_loss: 9.3885\n",
      "Epoch 369/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.6868 - val_loss: 8.9732\n",
      "Epoch 370/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5270 - val_loss: 9.7152\n",
      "Epoch 371/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.6410 - val_loss: 8.7397\n",
      "Epoch 372/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.8858 - val_loss: 8.8915\n",
      "Epoch 373/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.9493 - val_loss: 9.3927\n",
      "Epoch 374/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0974 - val_loss: 9.0435\n",
      "Epoch 375/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.7394 - val_loss: 8.6643\n",
      "Epoch 376/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.5379 - val_loss: 8.5421\n",
      "Epoch 377/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5291 - val_loss: 9.2102\n",
      "Epoch 378/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4431 - val_loss: 10.2757\n",
      "Epoch 379/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 105us/step - loss: 5.5951 - val_loss: 8.5888\n",
      "Epoch 380/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.5687 - val_loss: 8.8112\n",
      "Epoch 381/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.4816 - val_loss: 9.3500\n",
      "Epoch 382/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.4864 - val_loss: 8.5910\n",
      "Epoch 383/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.6425 - val_loss: 8.5250\n",
      "Epoch 384/1000\n",
      "274/274 [==============================] - 0s 117us/step - loss: 4.4859 - val_loss: 8.6931\n",
      "Epoch 385/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3998 - val_loss: 8.8566\n",
      "Epoch 386/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.5654 - val_loss: 8.8845\n",
      "Epoch 387/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.6275 - val_loss: 8.7954\n",
      "Epoch 388/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5238 - val_loss: 8.7509\n",
      "Epoch 389/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5116 - val_loss: 9.1098\n",
      "Epoch 390/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7818 - val_loss: 8.7980\n",
      "Epoch 391/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.4969 - val_loss: 9.0516\n",
      "Epoch 392/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4174 - val_loss: 8.4992\n",
      "Epoch 393/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.6463 - val_loss: 8.7131\n",
      "Epoch 394/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.5672 - val_loss: 9.0454\n",
      "Epoch 395/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.4338 - val_loss: 8.9536\n",
      "Epoch 396/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3651 - val_loss: 8.9418\n",
      "Epoch 397/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.5477 - val_loss: 8.8737\n",
      "Epoch 398/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.6704 - val_loss: 9.2158\n",
      "Epoch 399/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5373 - val_loss: 9.3162\n",
      "Epoch 400/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.4360 - val_loss: 8.6883\n",
      "Epoch 401/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5601 - val_loss: 8.9408\n",
      "Epoch 402/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.4745 - val_loss: 8.6986\n",
      "Epoch 403/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 4.4544 - val_loss: 9.2614\n",
      "Epoch 404/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3855 - val_loss: 8.6341\n",
      "Epoch 405/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.6369 - val_loss: 8.9637\n",
      "Epoch 406/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 4.8031 - val_loss: 10.6034\n",
      "Epoch 407/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4080 - val_loss: 9.2551\n",
      "Epoch 408/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.8322 - val_loss: 9.5486\n",
      "Epoch 409/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.1708 - val_loss: 9.7911\n",
      "Epoch 410/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.6729 - val_loss: 8.8913\n",
      "Epoch 411/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.5653 - val_loss: 9.3518\n",
      "Epoch 412/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9623 - val_loss: 9.5027\n",
      "Epoch 413/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5751 - val_loss: 9.7021\n",
      "Epoch 414/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8114 - val_loss: 9.2091\n",
      "Epoch 415/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3970 - val_loss: 8.9404\n",
      "Epoch 416/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7481 - val_loss: 8.8695\n",
      "Epoch 417/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.4855 - val_loss: 9.3392\n",
      "Epoch 418/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6108 - val_loss: 8.5492\n",
      "Epoch 419/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.4493 - val_loss: 9.4678\n",
      "Epoch 420/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.5038 - val_loss: 8.9495\n",
      "Epoch 421/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8567 - val_loss: 8.7881\n",
      "Epoch 422/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2280 - val_loss: 8.9461\n",
      "Epoch 423/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.5871 - val_loss: 8.5427\n",
      "Epoch 424/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.5968 - val_loss: 9.3816\n",
      "Epoch 425/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.7677 - val_loss: 8.9384\n",
      "Epoch 426/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5708 - val_loss: 9.3796\n",
      "Epoch 427/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4921 - val_loss: 8.4961\n",
      "Epoch 428/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2338 - val_loss: 9.1287\n",
      "Epoch 429/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.5044 - val_loss: 8.4688\n",
      "Epoch 430/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3825 - val_loss: 9.1865\n",
      "Epoch 431/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8205 - val_loss: 9.4372\n",
      "Epoch 432/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.7431 - val_loss: 8.3947\n",
      "Epoch 433/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5154 - val_loss: 9.8551\n",
      "Epoch 434/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.8382 - val_loss: 8.6128\n",
      "Epoch 435/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.6514 - val_loss: 8.6687\n",
      "Epoch 436/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.5753 - val_loss: 9.6481\n",
      "Epoch 437/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.6742 - val_loss: 8.6196\n",
      "Epoch 438/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3970 - val_loss: 8.8450\n",
      "Epoch 439/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.5016 - val_loss: 9.5619\n",
      "Epoch 440/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.4415 - val_loss: 8.4416\n",
      "Epoch 441/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.4732 - val_loss: 8.9572\n",
      "Epoch 442/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3772 - val_loss: 8.4922\n",
      "Epoch 443/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3976 - val_loss: 9.5198\n",
      "Epoch 444/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5747 - val_loss: 8.6615\n",
      "Epoch 445/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2618 - val_loss: 8.2567\n",
      "Epoch 446/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3645 - val_loss: 8.8281\n",
      "Epoch 447/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5319 - val_loss: 9.1057\n",
      "Epoch 448/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5815 - val_loss: 9.3818\n",
      "Epoch 449/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4818 - val_loss: 8.5731\n",
      "Epoch 450/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6488 - val_loss: 9.0780\n",
      "Epoch 451/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1237 - val_loss: 9.3352\n",
      "Epoch 452/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.4568 - val_loss: 8.7198\n",
      "Epoch 453/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3095 - val_loss: 9.0467\n",
      "Epoch 454/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.8735 - val_loss: 9.5248\n",
      "Epoch 455/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.8950 - val_loss: 9.0265\n",
      "Epoch 456/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 4.6139 - val_loss: 9.1734\n",
      "Epoch 457/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8276 - val_loss: 8.3361\n",
      "Epoch 458/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.8417 - val_loss: 9.5821\n",
      "Epoch 459/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7289 - val_loss: 9.0125\n",
      "Epoch 460/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6142 - val_loss: 8.7254\n",
      "Epoch 461/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.8392 - val_loss: 8.1212\n",
      "Epoch 462/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3630 - val_loss: 8.6489\n",
      "Epoch 463/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.2626 - val_loss: 8.5922\n",
      "Epoch 464/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3141 - val_loss: 8.5163\n",
      "Epoch 465/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3746 - val_loss: 9.9448\n",
      "Epoch 466/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.5651 - val_loss: 8.9018\n",
      "Epoch 467/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.2998 - val_loss: 8.7794\n",
      "Epoch 468/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2981 - val_loss: 8.4478\n",
      "Epoch 469/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2677 - val_loss: 8.3558\n",
      "Epoch 470/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3006 - val_loss: 8.4629\n",
      "Epoch 471/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3670 - val_loss: 9.3003\n",
      "Epoch 472/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1561 - val_loss: 8.3657\n",
      "Epoch 473/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3391 - val_loss: 8.9109\n",
      "Epoch 474/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3667 - val_loss: 8.5479\n",
      "Epoch 475/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.3049 - val_loss: 8.3635\n",
      "Epoch 476/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4063 - val_loss: 9.3539\n",
      "Epoch 477/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7789 - val_loss: 8.4234\n",
      "Epoch 478/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.5129 - val_loss: 8.5981\n",
      "Epoch 479/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4996 - val_loss: 8.9094\n",
      "Epoch 480/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3120 - val_loss: 8.5508\n",
      "Epoch 481/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.4534 - val_loss: 8.5711\n",
      "Epoch 482/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3748 - val_loss: 8.1822\n",
      "Epoch 483/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5094 - val_loss: 8.6314\n",
      "Epoch 484/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2918 - val_loss: 8.4695\n",
      "Epoch 485/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.2264 - val_loss: 8.4803\n",
      "Epoch 486/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1988 - val_loss: 8.3181\n",
      "Epoch 487/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3003 - val_loss: 8.4811\n",
      "Epoch 488/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.5324 - val_loss: 8.2921\n",
      "Epoch 489/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.5432 - val_loss: 8.2511\n",
      "Epoch 490/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3437 - val_loss: 8.5312\n",
      "Epoch 491/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.3549 - val_loss: 8.5738\n",
      "Epoch 492/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.1210 - val_loss: 9.6541\n",
      "Epoch 493/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.7814 - val_loss: 8.2080\n",
      "Epoch 494/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4468 - val_loss: 8.6031\n",
      "Epoch 495/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6828 - val_loss: 9.3600\n",
      "Epoch 496/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.9836 - val_loss: 10.2554\n",
      "Epoch 497/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2247 - val_loss: 8.6656\n",
      "Epoch 498/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9737 - val_loss: 8.9825\n",
      "Epoch 499/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.4057 - val_loss: 7.8873\n",
      "Epoch 500/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4903 - val_loss: 9.1816\n",
      "Epoch 501/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5442 - val_loss: 8.5541\n",
      "Epoch 502/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4870 - val_loss: 8.8214\n",
      "Epoch 503/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5204 - val_loss: 9.0354\n",
      "Epoch 504/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5221 - val_loss: 8.7815\n",
      "Epoch 505/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6596 - val_loss: 8.4158\n",
      "Epoch 506/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3231 - val_loss: 8.0392\n",
      "Epoch 507/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.3157 - val_loss: 8.2044\n",
      "Epoch 508/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1849 - val_loss: 8.3780\n",
      "Epoch 509/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.5455 - val_loss: 9.5214\n",
      "Epoch 510/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.9660 - val_loss: 9.1020\n",
      "Epoch 511/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3571 - val_loss: 7.8151\n",
      "Epoch 512/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.3431 - val_loss: 8.2403\n",
      "Epoch 513/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2696 - val_loss: 8.0764\n",
      "Epoch 514/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.2844 - val_loss: 8.8210\n",
      "Epoch 515/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2620 - val_loss: 8.3151\n",
      "Epoch 516/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5544 - val_loss: 8.5699\n",
      "Epoch 517/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.8085 - val_loss: 8.8850\n",
      "Epoch 518/1000\n",
      "274/274 [==============================] - 0s 138us/step - loss: 4.6234 - val_loss: 8.6435\n",
      "Epoch 519/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 4.3761 - val_loss: 8.0224\n",
      "Epoch 520/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 4.1869 - val_loss: 8.4594\n",
      "Epoch 521/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 4.4795 - val_loss: 8.6947\n",
      "Epoch 522/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 4.4334 - val_loss: 9.0732\n",
      "Epoch 523/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.4063 - val_loss: 8.4227\n",
      "Epoch 524/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.4104 - val_loss: 9.0715\n",
      "Epoch 525/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 4.3153 - val_loss: 8.4168\n",
      "Epoch 526/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.2974 - val_loss: 8.9098\n",
      "Epoch 527/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.2319 - val_loss: 8.1036\n",
      "Epoch 528/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 4.1923 - val_loss: 8.4975\n",
      "Epoch 529/1000\n",
      "274/274 [==============================] - 0s 135us/step - loss: 4.3364 - val_loss: 9.3143\n",
      "Epoch 530/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.9295 - val_loss: 8.3180\n",
      "Epoch 531/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 4.5022 - val_loss: 8.8020\n",
      "Epoch 532/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3954 - val_loss: 9.4410\n",
      "Epoch 533/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 95us/step - loss: 4.7815 - val_loss: 9.0970\n",
      "Epoch 534/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.3054 - val_loss: 8.3196\n",
      "Epoch 535/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9694 - val_loss: 9.7944\n",
      "Epoch 536/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9329 - val_loss: 8.8702\n",
      "Epoch 537/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 4.3294 - val_loss: 7.9309\n",
      "Epoch 538/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 4.7966 - val_loss: 9.3410\n",
      "Epoch 539/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.4557 - val_loss: 8.1635\n",
      "Epoch 540/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6456 - val_loss: 9.3976\n",
      "Epoch 541/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6342 - val_loss: 8.0395\n",
      "Epoch 542/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6863 - val_loss: 9.3904\n",
      "Epoch 543/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.6276 - val_loss: 8.3004\n",
      "Epoch 544/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.7149 - val_loss: 8.2983\n",
      "Epoch 545/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1391 - val_loss: 8.1446\n",
      "Epoch 546/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0652 - val_loss: 8.0886\n",
      "Epoch 547/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1601 - val_loss: 8.1747\n",
      "Epoch 548/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 4.4464 - val_loss: 8.3871\n",
      "Epoch 549/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.5331 - val_loss: 8.6504\n",
      "Epoch 550/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 4.3234 - val_loss: 8.1197\n",
      "Epoch 551/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2562 - val_loss: 7.6508\n",
      "Epoch 552/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.9041 - val_loss: 8.5832\n",
      "Epoch 553/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6328 - val_loss: 8.3955\n",
      "Epoch 554/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.5608 - val_loss: 8.1752\n",
      "Epoch 555/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.3010 - val_loss: 8.1592\n",
      "Epoch 556/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1452 - val_loss: 8.5851\n",
      "Epoch 557/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1056 - val_loss: 8.0214\n",
      "Epoch 558/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.6691 - val_loss: 9.4287\n",
      "Epoch 559/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7459 - val_loss: 8.6516\n",
      "Epoch 560/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.5078 - val_loss: 8.2605\n",
      "Epoch 561/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.2399 - val_loss: 7.8336\n",
      "Epoch 562/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4712 - val_loss: 8.6641\n",
      "Epoch 563/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4533 - val_loss: 8.7857\n",
      "Epoch 564/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3481 - val_loss: 8.3173\n",
      "Epoch 565/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.5376 - val_loss: 7.8735\n",
      "Epoch 566/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.2462 - val_loss: 8.7157\n",
      "Epoch 567/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.3806 - val_loss: 8.2710\n",
      "Epoch 568/1000\n",
      "274/274 [==============================] - 0s 146us/step - loss: 4.3384 - val_loss: 8.5989\n",
      "Epoch 569/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.1934 - val_loss: 7.7763\n",
      "Epoch 570/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.2307 - val_loss: 7.8007\n",
      "Epoch 571/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 4.0934 - val_loss: 8.7053\n",
      "Epoch 572/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.1465 - val_loss: 8.5266\n",
      "Epoch 573/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0890 - val_loss: 7.6513\n",
      "Epoch 574/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.0930 - val_loss: 8.0778\n",
      "Epoch 575/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.2257 - val_loss: 8.8155\n",
      "Epoch 576/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4577 - val_loss: 8.2220\n",
      "Epoch 577/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3087 - val_loss: 8.2841\n",
      "Epoch 578/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.2572 - val_loss: 8.0447\n",
      "Epoch 579/1000\n",
      "274/274 [==============================] - 0s 138us/step - loss: 4.3479 - val_loss: 8.3634\n",
      "Epoch 580/1000\n",
      "274/274 [==============================] - 0s 138us/step - loss: 4.2376 - val_loss: 8.6876\n",
      "Epoch 581/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2211 - val_loss: 8.1857\n",
      "Epoch 582/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3726 - val_loss: 8.2455\n",
      "Epoch 583/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 4.2383 - val_loss: 7.8616\n",
      "Epoch 584/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.1069 - val_loss: 8.5804\n",
      "Epoch 585/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 4.2949 - val_loss: 8.2481\n",
      "Epoch 586/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5106 - val_loss: 8.5335\n",
      "Epoch 587/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.7029 - val_loss: 9.5039\n",
      "Epoch 588/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 5.6059 - val_loss: 9.0993\n",
      "Epoch 589/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.9524 - val_loss: 9.5499\n",
      "Epoch 590/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.4514 - val_loss: 9.0545\n",
      "Epoch 591/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.5400 - val_loss: 8.7363\n",
      "Epoch 592/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.3400 - val_loss: 8.4356\n",
      "Epoch 593/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 4.1291 - val_loss: 8.0722\n",
      "Epoch 594/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 4.1218 - val_loss: 8.6435\n",
      "Epoch 595/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.5977 - val_loss: 8.0841\n",
      "Epoch 596/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.4387 - val_loss: 8.0313\n",
      "Epoch 597/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.2427 - val_loss: 8.1250\n",
      "Epoch 598/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1619 - val_loss: 8.2514\n",
      "Epoch 599/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3624 - val_loss: 8.3155\n",
      "Epoch 600/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1560 - val_loss: 8.3216\n",
      "Epoch 601/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9889 - val_loss: 8.3069\n",
      "Epoch 602/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.1480 - val_loss: 8.1354\n",
      "Epoch 603/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 4.1475 - val_loss: 7.7881\n",
      "Epoch 604/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2187 - val_loss: 8.9282\n",
      "Epoch 605/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 4.2440 - val_loss: 7.9015\n",
      "Epoch 606/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.1335 - val_loss: 8.7210\n",
      "Epoch 607/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 4.1842 - val_loss: 7.7865\n",
      "Epoch 608/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0146 - val_loss: 8.1317\n",
      "Epoch 609/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0347 - val_loss: 8.0628\n",
      "Epoch 610/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 91us/step - loss: 4.0410 - val_loss: 8.1844\n",
      "Epoch 611/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2896 - val_loss: 9.2442\n",
      "Epoch 612/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3245 - val_loss: 7.9134\n",
      "Epoch 613/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3806 - val_loss: 8.3796\n",
      "Epoch 614/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.2436 - val_loss: 8.8153\n",
      "Epoch 615/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.4210 - val_loss: 8.0767\n",
      "Epoch 616/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1186 - val_loss: 8.2008\n",
      "Epoch 617/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1764 - val_loss: 8.7117\n",
      "Epoch 618/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 4.2566 - val_loss: 8.0805\n",
      "Epoch 619/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 3.9943 - val_loss: 8.0236\n",
      "Epoch 620/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0497 - val_loss: 8.5040\n",
      "Epoch 621/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3153 - val_loss: 8.1619\n",
      "Epoch 622/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4454 - val_loss: 8.4424\n",
      "Epoch 623/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.1384 - val_loss: 8.1063\n",
      "Epoch 624/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 4.0916 - val_loss: 8.3359\n",
      "Epoch 625/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 4.0785 - val_loss: 8.1025\n",
      "Epoch 626/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2988 - val_loss: 7.9818\n",
      "Epoch 627/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.0016 - val_loss: 8.1165\n",
      "Epoch 628/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.9762 - val_loss: 8.1568\n",
      "Epoch 629/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.0312 - val_loss: 8.3067\n",
      "Epoch 630/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.2350 - val_loss: 7.9516\n",
      "Epoch 631/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.6237 - val_loss: 8.4230\n",
      "Epoch 632/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.2944 - val_loss: 7.9912\n",
      "Epoch 633/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.4731 - val_loss: 8.1846\n",
      "Epoch 634/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.9755 - val_loss: 7.6353\n",
      "Epoch 635/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2937 - val_loss: 8.7682\n",
      "Epoch 636/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.1257 - val_loss: 8.4712\n",
      "Epoch 637/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.2337 - val_loss: 8.3309\n",
      "Epoch 638/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 4.0037 - val_loss: 8.1772\n",
      "Epoch 639/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.3603 - val_loss: 8.4777\n",
      "Epoch 640/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1258 - val_loss: 8.4177\n",
      "Epoch 641/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.3235 - val_loss: 7.8905\n",
      "Epoch 642/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0930 - val_loss: 8.4391\n",
      "Epoch 643/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0296 - val_loss: 8.2655\n",
      "Epoch 644/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0170 - val_loss: 7.8254\n",
      "Epoch 645/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2246 - val_loss: 8.4587\n",
      "Epoch 646/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2669 - val_loss: 8.6887\n",
      "Epoch 647/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.3157 - val_loss: 8.5278\n",
      "Epoch 648/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 3.9708 - val_loss: 8.3278\n",
      "Epoch 649/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.0637 - val_loss: 7.6857\n",
      "Epoch 650/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.3416 - val_loss: 8.3001\n",
      "Epoch 651/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1203 - val_loss: 8.0218\n",
      "Epoch 652/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 4.3184 - val_loss: 9.1904\n",
      "Epoch 653/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.5543 - val_loss: 8.3498\n",
      "Epoch 654/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0791 - val_loss: 8.0129\n",
      "Epoch 655/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1246 - val_loss: 8.2330\n",
      "Epoch 656/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 3.9394 - val_loss: 8.2699\n",
      "Epoch 657/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1780 - val_loss: 8.5779\n",
      "Epoch 658/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 4.4188 - val_loss: 7.9760\n",
      "Epoch 659/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.1992 - val_loss: 8.6428\n",
      "Epoch 660/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.1176 - val_loss: 8.7418\n",
      "Epoch 661/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.2617 - val_loss: 7.6828\n",
      "Epoch 662/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0946 - val_loss: 7.7197\n",
      "Epoch 663/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 4.2808 - val_loss: 8.3067\n",
      "Epoch 664/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.0000 - val_loss: 8.4077\n",
      "Epoch 665/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.9942 - val_loss: 8.2790\n",
      "Epoch 666/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.0125 - val_loss: 7.8224\n",
      "Epoch 667/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1016 - val_loss: 8.3168\n",
      "Epoch 668/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0597 - val_loss: 8.1796\n",
      "Epoch 669/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.2390 - val_loss: 8.4426\n",
      "Epoch 670/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.0879 - val_loss: 8.1757\n",
      "Epoch 671/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.9505 - val_loss: 7.7794\n",
      "Epoch 672/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.0900 - val_loss: 8.2089\n",
      "Epoch 673/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4625 - val_loss: 8.1162\n",
      "Epoch 674/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2868 - val_loss: 9.6240\n",
      "Epoch 675/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.0041 - val_loss: 8.5059\n",
      "Epoch 676/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0091 - val_loss: 8.4194\n",
      "Epoch 677/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3112 - val_loss: 8.0564\n",
      "Epoch 678/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.2544 - val_loss: 8.1700\n",
      "Epoch 679/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1041 - val_loss: 8.1920\n",
      "Epoch 680/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.5128 - val_loss: 8.5193\n",
      "Epoch 681/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3011 - val_loss: 8.5417\n",
      "Epoch 682/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.2809 - val_loss: 8.5762\n",
      "Epoch 683/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2185 - val_loss: 7.8840\n",
      "Epoch 684/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1899 - val_loss: 7.9793\n",
      "Epoch 685/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.1639 - val_loss: 8.9780\n",
      "Epoch 686/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3666 - val_loss: 7.8213\n",
      "Epoch 687/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.1917 - val_loss: 8.6346\n",
      "Epoch 688/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 97us/step - loss: 4.1165 - val_loss: 7.7502\n",
      "Epoch 689/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.2146 - val_loss: 8.1677\n",
      "Epoch 690/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1586 - val_loss: 8.7748\n",
      "Epoch 691/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0611 - val_loss: 8.1184\n",
      "Epoch 692/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.1142 - val_loss: 8.6969\n",
      "Epoch 693/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0702 - val_loss: 8.0771\n",
      "Epoch 694/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.1688 - val_loss: 8.3677\n",
      "Epoch 695/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9973 - val_loss: 8.2919\n",
      "Epoch 696/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9830 - val_loss: 8.4094\n",
      "Epoch 697/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2636 - val_loss: 7.9776\n",
      "Epoch 698/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.9515 - val_loss: 8.6433\n",
      "Epoch 699/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0495 - val_loss: 8.2449\n",
      "Epoch 700/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 4.0809 - val_loss: 7.9271\n",
      "Epoch 701/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 3.9843 - val_loss: 8.2507\n",
      "Epoch 702/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.2395 - val_loss: 9.0750\n",
      "Epoch 703/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1921 - val_loss: 8.4715\n",
      "Epoch 704/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9974 - val_loss: 8.1916\n",
      "Epoch 705/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.9407 - val_loss: 8.1190\n",
      "Epoch 706/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.1561 - val_loss: 8.7463\n",
      "Epoch 707/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1826 - val_loss: 8.3380\n",
      "Epoch 708/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9736 - val_loss: 8.2505\n",
      "Epoch 709/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 3.9126 - val_loss: 8.2481\n",
      "Epoch 710/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0313 - val_loss: 9.2441\n",
      "Epoch 711/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.3881 - val_loss: 8.1454\n",
      "Epoch 712/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 4.6388 - val_loss: 8.8541\n",
      "Epoch 713/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.5782 - val_loss: 8.7001\n",
      "Epoch 714/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1675 - val_loss: 7.8680\n",
      "Epoch 715/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0511 - val_loss: 8.4337\n",
      "Epoch 716/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.0682 - val_loss: 7.8513\n",
      "Epoch 717/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 4.3107 - val_loss: 8.5619\n",
      "Epoch 718/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.9675 - val_loss: 7.8717\n",
      "Epoch 719/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.1476 - val_loss: 9.6999\n",
      "Epoch 720/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2339 - val_loss: 7.9566\n",
      "Epoch 721/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.0621 - val_loss: 7.8540\n",
      "Epoch 722/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.3418 - val_loss: 8.2273\n",
      "Epoch 723/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2275 - val_loss: 7.8617\n",
      "Epoch 724/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.3197 - val_loss: 9.4051\n",
      "Epoch 725/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5990 - val_loss: 9.3755\n",
      "Epoch 726/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3130 - val_loss: 8.4313\n",
      "Epoch 727/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0457 - val_loss: 7.8192\n",
      "Epoch 728/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.1371 - val_loss: 8.0839\n",
      "Epoch 729/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.1369 - val_loss: 8.2010\n",
      "Epoch 730/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0811 - val_loss: 8.8649\n",
      "Epoch 731/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.0039 - val_loss: 7.9099\n",
      "Epoch 732/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0273 - val_loss: 7.9161\n",
      "Epoch 733/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.9123 - val_loss: 8.1505\n",
      "Epoch 734/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 3.9665 - val_loss: 8.2710\n",
      "Epoch 735/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1882 - val_loss: 7.7526\n",
      "Epoch 736/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.2321 - val_loss: 9.2002\n",
      "Epoch 737/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.1722 - val_loss: 8.0989\n",
      "Epoch 738/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 4.0509 - val_loss: 8.0296\n",
      "Epoch 739/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 4.1009 - val_loss: 7.8722\n",
      "Epoch 740/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.8672 - val_loss: 8.0686\n",
      "Epoch 741/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 3.8980 - val_loss: 8.9074\n",
      "Epoch 742/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.2136 - val_loss: 7.9242\n",
      "Epoch 743/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3022 - val_loss: 8.4332\n",
      "Epoch 744/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2518 - val_loss: 8.0442\n",
      "Epoch 745/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 3.9203 - val_loss: 8.5871\n",
      "Epoch 746/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.9950 - val_loss: 8.0411\n",
      "Epoch 747/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.0900 - val_loss: 8.2443\n",
      "Epoch 748/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0019 - val_loss: 8.1424\n",
      "Epoch 749/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 4.0418 - val_loss: 8.1141\n",
      "Epoch 750/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0751 - val_loss: 8.4878\n",
      "Epoch 751/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.0551 - val_loss: 7.8868\n",
      "Epoch 752/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0609 - val_loss: 8.0004\n",
      "Epoch 753/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1540 - val_loss: 8.7151\n",
      "Epoch 754/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1199 - val_loss: 8.1591\n",
      "Epoch 755/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1785 - val_loss: 8.1120\n",
      "Epoch 756/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8772 - val_loss: 8.6974\n",
      "Epoch 757/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5316 - val_loss: 7.6764\n",
      "Epoch 758/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4406 - val_loss: 8.8779\n",
      "Epoch 759/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6307 - val_loss: 8.2846\n",
      "Epoch 760/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.0592 - val_loss: 8.7130\n",
      "Epoch 761/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0266 - val_loss: 7.9879\n",
      "Epoch 762/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.1693 - val_loss: 8.7181\n",
      "Epoch 763/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.0785 - val_loss: 8.1392\n",
      "Epoch 764/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0192 - val_loss: 7.8869\n",
      "Epoch 765/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 3.9420 - val_loss: 8.5099\n",
      "Epoch 766/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 97us/step - loss: 3.8110 - val_loss: 8.2081\n",
      "Epoch 767/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 3.9821 - val_loss: 9.2108\n",
      "Epoch 768/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 4.4691 - val_loss: 7.9309\n",
      "Epoch 769/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3192 - val_loss: 8.7376\n",
      "Epoch 770/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1748 - val_loss: 8.3286\n",
      "Epoch 771/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3454 - val_loss: 10.2837\n",
      "Epoch 772/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.4246 - val_loss: 8.3727\n",
      "Epoch 773/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 4.2293 - val_loss: 8.1020\n",
      "Epoch 774/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9988 - val_loss: 7.6522\n",
      "Epoch 775/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 4.0742 - val_loss: 7.6653\n",
      "Epoch 776/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 3.8913 - val_loss: 8.2095\n",
      "Epoch 777/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.9300 - val_loss: 8.6746\n",
      "Epoch 778/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9673 - val_loss: 7.8870\n",
      "Epoch 779/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 3.9669 - val_loss: 8.8907\n",
      "Epoch 780/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 3.9574 - val_loss: 8.0182\n",
      "Epoch 781/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9205 - val_loss: 8.5375\n",
      "Epoch 782/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0128 - val_loss: 8.1642\n",
      "Epoch 783/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.0705 - val_loss: 8.7504\n",
      "Epoch 784/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 3.8636 - val_loss: 7.8469\n",
      "Epoch 785/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.1262 - val_loss: 8.1616\n",
      "Epoch 786/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.9494 - val_loss: 7.9827\n",
      "Epoch 787/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.8729 - val_loss: 8.2788\n",
      "Epoch 788/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8993 - val_loss: 7.8824\n",
      "Epoch 789/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 3.9086 - val_loss: 8.8879\n",
      "Epoch 790/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1540 - val_loss: 8.2956\n",
      "Epoch 791/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1292 - val_loss: 8.9677\n",
      "Epoch 792/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.0934 - val_loss: 8.2482\n",
      "Epoch 793/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.9870 - val_loss: 8.4546\n",
      "Epoch 794/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.4688 - val_loss: 8.1531\n",
      "Epoch 795/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.1554 - val_loss: 10.2528\n",
      "Epoch 796/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.8747 - val_loss: 7.9624\n",
      "Epoch 797/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.2775 - val_loss: 8.6976\n",
      "Epoch 798/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3022 - val_loss: 9.0181\n",
      "Epoch 799/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4867 - val_loss: 8.5112\n",
      "Epoch 800/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0496 - val_loss: 8.2011\n",
      "Epoch 801/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.4076 - val_loss: 8.3803\n",
      "Epoch 802/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 4.4578 - val_loss: 9.0026\n",
      "Epoch 803/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9899 - val_loss: 8.6385\n",
      "Epoch 804/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6069 - val_loss: 8.5341\n",
      "Epoch 805/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.2810 - val_loss: 7.7270\n",
      "Epoch 806/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.0887 - val_loss: 8.1673\n",
      "Epoch 807/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1357 - val_loss: 9.6607\n",
      "Epoch 808/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.3585 - val_loss: 8.3716\n",
      "Epoch 809/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2309 - val_loss: 8.2047\n",
      "Epoch 810/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2888 - val_loss: 8.9354\n",
      "Epoch 811/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.3364 - val_loss: 9.0773\n",
      "Epoch 812/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2483 - val_loss: 7.8775\n",
      "Epoch 813/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 3.8075 - val_loss: 8.3527\n",
      "Epoch 814/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 3.9140 - val_loss: 8.0245\n",
      "Epoch 815/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 3.8198 - val_loss: 7.7929\n",
      "Epoch 816/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 3.8701 - val_loss: 7.9989\n",
      "Epoch 817/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 3.8479 - val_loss: 8.2522\n",
      "Epoch 818/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 3.9543 - val_loss: 8.0571\n",
      "Epoch 819/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 3.8964 - val_loss: 8.1875\n",
      "Epoch 820/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 3.8138 - val_loss: 7.6435\n",
      "Epoch 821/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 3.8653 - val_loss: 8.2123\n",
      "Epoch 822/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 3.9544 - val_loss: 8.2063\n",
      "Epoch 823/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.9904 - val_loss: 9.4292\n",
      "Epoch 824/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.4450 - val_loss: 8.0829\n",
      "Epoch 825/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.2208 - val_loss: 7.9551\n",
      "Epoch 826/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2102 - val_loss: 8.8316\n",
      "Epoch 827/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.1666 - val_loss: 8.2132\n",
      "Epoch 828/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 4.1159 - val_loss: 8.5982\n",
      "Epoch 829/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2120 - val_loss: 9.0657\n",
      "Epoch 830/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.4508 - val_loss: 8.1668\n",
      "Epoch 831/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1857 - val_loss: 8.3049\n",
      "Epoch 832/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 3.9386 - val_loss: 7.9568\n",
      "Epoch 833/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.2505 - val_loss: 9.3743\n",
      "Epoch 834/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 4.2853 - val_loss: 8.3367\n",
      "Epoch 835/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.1630 - val_loss: 8.2389\n",
      "Epoch 836/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.2011 - val_loss: 8.3360\n",
      "Epoch 837/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3047 - val_loss: 9.3266\n",
      "Epoch 838/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.1700 - val_loss: 8.2404\n",
      "Epoch 839/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0654 - val_loss: 9.8558\n",
      "Epoch 840/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.5756 - val_loss: 8.1623\n",
      "Epoch 841/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 4.0384 - val_loss: 7.9776\n",
      "Epoch 842/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.8067 - val_loss: 8.6335\n",
      "Epoch 843/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 3.9177 - val_loss: 7.9545\n",
      "Epoch 844/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 91us/step - loss: 3.9935 - val_loss: 7.9195\n",
      "Epoch 845/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 3.9723 - val_loss: 10.0763\n",
      "Epoch 846/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.7135 - val_loss: 8.0301\n",
      "Epoch 847/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 4.3445 - val_loss: 8.2083\n",
      "Epoch 848/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2806 - val_loss: 8.9216\n",
      "Epoch 849/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0214 - val_loss: 8.4577\n",
      "Epoch 850/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.9544 - val_loss: 8.3197\n",
      "Epoch 851/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 3.9744 - val_loss: 8.2019\n",
      "Epoch 852/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.0336 - val_loss: 8.6923\n",
      "Epoch 853/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.3924 - val_loss: 8.3283\n",
      "Epoch 854/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0194 - val_loss: 8.2700\n",
      "Epoch 855/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0484 - val_loss: 8.3480\n",
      "Epoch 856/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 3.8743 - val_loss: 8.2979\n",
      "Epoch 857/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 3.8160 - val_loss: 8.6102\n",
      "Epoch 858/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.1275 - val_loss: 8.9766\n",
      "Epoch 859/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 3.9865 - val_loss: 8.7924\n",
      "Epoch 860/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 4.1554 - val_loss: 8.7340\n",
      "Epoch 861/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 3.8493 - val_loss: 8.1354\n",
      "Epoch 862/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.8458 - val_loss: 8.1544\n",
      "Epoch 863/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0227 - val_loss: 8.1966\n",
      "Epoch 864/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 3.9402 - val_loss: 8.9262\n",
      "Epoch 865/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0315 - val_loss: 8.3846\n",
      "Epoch 866/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.0264 - val_loss: 8.7020\n",
      "Epoch 867/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.1386 - val_loss: 8.1604\n",
      "Epoch 868/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.0204 - val_loss: 8.4245\n",
      "Epoch 869/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.7483 - val_loss: 8.0500\n",
      "Epoch 870/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9624 - val_loss: 8.2389\n",
      "Epoch 871/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.0307 - val_loss: 8.1929\n",
      "Epoch 872/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.7940 - val_loss: 8.3449\n",
      "Epoch 873/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9854 - val_loss: 8.6298\n",
      "Epoch 874/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.8483 - val_loss: 8.3176\n",
      "Epoch 875/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5211 - val_loss: 10.0722\n",
      "Epoch 876/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.1348 - val_loss: 8.2974\n",
      "Epoch 877/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.1438 - val_loss: 8.3502\n",
      "Epoch 878/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 6.634 - 0s 106us/step - loss: 4.2785 - val_loss: 9.0411\n",
      "Epoch 879/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.0831 - val_loss: 8.6174\n",
      "Epoch 880/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.9644 - val_loss: 8.3928\n",
      "Epoch 881/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.1066 - val_loss: 9.6812\n",
      "Epoch 882/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0444 - val_loss: 8.4261\n",
      "Epoch 883/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8348 - val_loss: 8.4513\n",
      "Epoch 884/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.9154 - val_loss: 7.9527\n",
      "Epoch 885/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.9276 - val_loss: 8.7984\n",
      "Epoch 886/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.0057 - val_loss: 8.8976\n",
      "Epoch 887/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.1066 - val_loss: 8.6621\n",
      "Epoch 888/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 3.8438 - val_loss: 8.0027\n",
      "Epoch 889/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.7342 - val_loss: 8.7310\n",
      "Epoch 890/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9330 - val_loss: 8.1874\n",
      "Epoch 891/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 3.8905 - val_loss: 8.1352\n",
      "Epoch 892/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 3.9067 - val_loss: 8.4199\n",
      "Epoch 893/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.2366 - val_loss: 8.2335\n",
      "Epoch 894/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.2312 - val_loss: 10.2221\n",
      "Epoch 895/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7659 - val_loss: 8.9023\n",
      "Epoch 896/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.2083 - val_loss: 8.4058\n",
      "Epoch 897/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.2276 - val_loss: 9.2088\n",
      "Epoch 898/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.0341 - val_loss: 8.8914\n",
      "Epoch 899/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 3.8483 - val_loss: 8.4039\n",
      "Epoch 900/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 3.9455 - val_loss: 8.9935\n",
      "Epoch 901/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 3.8471 - val_loss: 8.1898\n",
      "Epoch 902/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 3.9226 - val_loss: 7.9948\n",
      "Epoch 903/1000\n",
      "274/274 [==============================] - 0s 85us/step - loss: 4.1853 - val_loss: 11.1565\n",
      "Epoch 904/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 4.6027 - val_loss: 8.8804\n",
      "Epoch 905/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5411 - val_loss: 9.6969\n",
      "Epoch 906/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 4.3129 - val_loss: 8.6652\n",
      "Epoch 907/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 3.8734 - val_loss: 8.6643\n",
      "Epoch 908/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.9361 - val_loss: 8.6877\n",
      "Epoch 909/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 3.9531 - val_loss: 8.0722\n",
      "Epoch 910/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 3.8624 - val_loss: 8.4699\n",
      "Epoch 911/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.8029 - val_loss: 9.7678\n",
      "Epoch 912/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.2405 - val_loss: 8.2600\n",
      "Epoch 913/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 3.9588 - val_loss: 9.1745\n",
      "Epoch 914/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9226 - val_loss: 8.8046\n",
      "Epoch 915/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.0701 - val_loss: 8.5704\n",
      "Epoch 916/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.0324 - val_loss: 8.7381\n",
      "Epoch 917/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 3.8227 - val_loss: 7.9319\n",
      "Epoch 918/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.8362 - val_loss: 8.8819\n",
      "Epoch 919/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0365 - val_loss: 8.6856\n",
      "Epoch 920/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 3.8984 - val_loss: 8.3558\n",
      "Epoch 921/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 92us/step - loss: 3.7760 - val_loss: 8.3142\n",
      "Epoch 922/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 3.8925 - val_loss: 8.4062\n",
      "Epoch 923/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 3.8197 - val_loss: 9.2279\n",
      "Epoch 924/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 3.8075 - val_loss: 8.0821\n",
      "Epoch 925/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.2057 - val_loss: 9.4456\n",
      "Epoch 926/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 4.0052 - val_loss: 8.3800\n",
      "Epoch 927/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3441 - val_loss: 9.2543\n",
      "Epoch 928/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 4.6643 - val_loss: 8.9844\n",
      "Epoch 929/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 3.9892 - val_loss: 9.2712\n",
      "Epoch 930/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 3.9479 - val_loss: 8.3447\n",
      "Epoch 931/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 3.8270 - val_loss: 8.6604\n",
      "Epoch 932/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 3.7625 - val_loss: 8.8683\n",
      "Epoch 933/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.9843 - val_loss: 9.1692\n",
      "Epoch 934/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 3.8790 - val_loss: 7.8863\n",
      "Epoch 935/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 3.9174 - val_loss: 8.3838\n",
      "Epoch 936/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.8461 - val_loss: 8.8361\n",
      "Epoch 937/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.8876 - val_loss: 8.5540\n",
      "Epoch 938/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8302 - val_loss: 8.7216\n",
      "Epoch 939/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 3.8405 - val_loss: 8.2492\n",
      "Epoch 940/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 3.8387 - val_loss: 9.8557\n",
      "Epoch 941/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 3.9396 - val_loss: 8.6508\n",
      "Epoch 942/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 3.8001 - val_loss: 9.7555\n",
      "Epoch 943/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 3.8783 - val_loss: 8.2254\n",
      "Epoch 944/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 3.7394 - val_loss: 8.6498\n",
      "Epoch 945/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 3.7772 - val_loss: 8.0112\n",
      "Epoch 946/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.7852 - val_loss: 9.4776\n",
      "Epoch 947/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.9786 - val_loss: 8.3908\n",
      "Epoch 948/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 3.9468 - val_loss: 8.7067\n",
      "Epoch 949/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.9027 - val_loss: 8.4162\n",
      "Epoch 950/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 5.216 - 0s 98us/step - loss: 3.8854 - val_loss: 9.2070\n",
      "Epoch 951/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.8823 - val_loss: 8.5707\n",
      "Epoch 952/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 3.8802 - val_loss: 8.9962\n",
      "Epoch 953/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 3.9650 - val_loss: 8.1614\n",
      "Epoch 954/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.1215 - val_loss: 8.8111\n",
      "Epoch 955/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 3.8876 - val_loss: 8.2489\n",
      "Epoch 956/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 3.7957 - val_loss: 8.3521\n",
      "Epoch 957/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.8204 - val_loss: 8.5332\n",
      "Epoch 958/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.8946 - val_loss: 8.7262\n",
      "Epoch 959/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 3.9840 - val_loss: 9.3107\n",
      "Epoch 960/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 3.8335 - val_loss: 8.7658\n",
      "Epoch 961/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 3.9823 - val_loss: 9.8974\n",
      "Epoch 962/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 4.4180 - val_loss: 8.1561\n",
      "Epoch 963/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 3.9535 - val_loss: 8.6176\n",
      "Epoch 964/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 3.9648 - val_loss: 9.4631\n",
      "Epoch 965/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 4.1790 - val_loss: 8.7755\n",
      "Epoch 966/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.1557 - val_loss: 9.1352\n",
      "Epoch 967/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.1095 - val_loss: 9.3667\n",
      "Epoch 968/1000\n",
      "274/274 [==============================] - 0s 123us/step - loss: 3.9499 - val_loss: 8.6285\n",
      "Epoch 969/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 4.1870 - val_loss: 8.7683\n",
      "Epoch 970/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 3.8819 - val_loss: 8.6681\n",
      "Epoch 971/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.7605 - val_loss: 9.2484\n",
      "Epoch 972/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.0505 - val_loss: 9.0210\n",
      "Epoch 973/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4804 - val_loss: 8.6379\n",
      "Epoch 974/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.8783 - val_loss: 9.2246\n",
      "Epoch 975/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.8385 - val_loss: 9.1833\n",
      "Epoch 976/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 3.8530 - val_loss: 9.3973\n",
      "Epoch 977/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 3.7190 - val_loss: 8.8704\n",
      "Epoch 978/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.7000 - val_loss: 8.8938\n",
      "Epoch 979/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.8646 - val_loss: 8.6077\n",
      "Epoch 980/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 3.8280 - val_loss: 9.1367\n",
      "Epoch 981/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.0474 - val_loss: 9.3827\n",
      "Epoch 982/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 3.7371 - val_loss: 8.3954\n",
      "Epoch 983/1000\n",
      "274/274 [==============================] - 0s 138us/step - loss: 3.9091 - val_loss: 8.7105\n",
      "Epoch 984/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 3.8041 - val_loss: 9.4310\n",
      "Epoch 985/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 3.9035 - val_loss: 8.5208\n",
      "Epoch 986/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 3.7583 - val_loss: 8.5018\n",
      "Epoch 987/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.0074 - val_loss: 8.6582\n",
      "Epoch 988/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 3.9719 - val_loss: 9.5364\n",
      "Epoch 989/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.0400 - val_loss: 8.8868\n",
      "Epoch 990/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.7438 - val_loss: 8.2698\n",
      "Epoch 991/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 3.8298 - val_loss: 8.5128\n",
      "Epoch 992/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 3.9708 - val_loss: 9.9072\n",
      "Epoch 993/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 3.8247 - val_loss: 8.8224\n",
      "Epoch 994/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 3.8086 - val_loss: 8.4220\n",
      "Epoch 995/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 3.9207 - val_loss: 8.4838\n",
      "Epoch 996/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 3.9066 - val_loss: 9.0575\n",
      "Epoch 997/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 3.8860 - val_loss: 9.0526\n",
      "Epoch 998/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 91us/step - loss: 3.9615 - val_loss: 8.5161\n",
      "Epoch 999/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 3.6941 - val_loss: 9.1120\n",
      "Epoch 1000/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 3.7523 - val_loss: 9.2952\n",
      "7.553562196634584\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.12028391, -1.1374549 ,  1.736599  , -1.7302289 ,  2.4218044 ,\n",
       "         -1.8547182 , -1.6800588 , -0.6686689 ,  0.28830576,  0.5316882 ],\n",
       "        [-0.75377953, -1.7412553 , -0.6585252 ,  0.08620577,  5.18228   ,\n",
       "          0.66336673,  2.0415156 , -1.789034  ,  1.263134  ,  0.05448996],\n",
       "        [-1.0817478 , -2.6584344 ,  0.10593318,  0.5400321 ,  2.0224674 ,\n",
       "         -0.9505978 , -0.27094358, -0.23341653, -0.9349026 , -0.66994953],\n",
       "        [ 1.5208857 , -0.8365863 , -0.19778126,  0.509167  ,  1.7467809 ,\n",
       "         -0.26585358, -1.4330475 ,  2.1550283 , -0.61239004,  2.5562274 ],\n",
       "        [-0.05223066,  2.2953107 ,  0.3800391 ,  0.31630427, -0.7647919 ,\n",
       "         -0.21774533,  1.0795949 , -0.33548716, -0.05881788, -0.97525305],\n",
       "        [-1.2680159 ,  1.3281231 , -0.31633088, -0.3938801 , -1.2302382 ,\n",
       "          0.33904576, -0.663743  , -1.531681  ,  1.9748439 , -0.827203  ],\n",
       "        [-1.6552871 ,  2.4402447 , -0.40009326, -0.5416761 , -1.1442833 ,\n",
       "          0.648384  ,  0.87197846, -1.7947104 , -0.3192405 , -0.68816483]],\n",
       "       dtype=float32),\n",
       " array([-0.44394884, -1.6689149 ,  0.90995574, -0.4217515 ,  0.87047374,\n",
       "        -1.0586255 ,  1.6827343 , -0.9496874 , -0.38698873,  0.00297284],\n",
       "       dtype=float32),\n",
       " array([[ 0.32964408, -0.38962683,  0.45297638,  0.1984487 ,  0.71126604,\n",
       "         -0.44073468, -0.5184969 ,  0.7420037 , -0.48124254,  0.656334  ,\n",
       "         -0.14309095, -0.18220972, -0.8194449 , -0.33380845,  0.15008229],\n",
       "        [ 0.23831938, -0.14991914,  0.1198635 ,  0.41144902,  0.6106932 ,\n",
       "         -0.22457975, -0.38246393,  0.56232977, -0.5233781 , -0.24467364,\n",
       "         -0.54754406,  0.30945733, -0.04631681, -0.09294706, -0.01451863],\n",
       "        [-0.8531926 ,  0.54835904, -0.86380166, -0.731325  , -0.6139011 ,\n",
       "          0.882772  ,  0.15464059, -0.53809166,  0.3894486 , -0.9687693 ,\n",
       "          0.6672931 ,  0.2179734 ,  0.8998094 ,  0.9142819 , -0.5149608 ],\n",
       "        [ 0.42371717, -0.16063398,  0.6841469 , -0.2224935 ,  0.5169115 ,\n",
       "         -0.14082737, -0.54059243,  0.17080513, -0.5375078 ,  0.34379897,\n",
       "         -0.54647535,  0.27084035, -0.70645165, -0.8729372 ,  0.22210293],\n",
       "        [-0.21343751,  0.8394544 , -0.07684902, -0.20449364, -0.17253013,\n",
       "          0.28679928,  0.7637588 , -0.49537683,  0.6286615 , -0.5941981 ,\n",
       "          0.56677145, -0.23335958,  0.1492709 ,  0.02578546, -0.44543856],\n",
       "        [-0.942342  ,  1.1555481 , -1.4147346 , -1.2265642 , -0.71552014,\n",
       "          1.2571152 ,  1.2585068 , -1.5090669 ,  0.6809728 , -0.82407635,\n",
       "          0.59534866, -0.5749345 ,  1.3736222 ,  0.8370963 , -0.69701505],\n",
       "        [-0.08227897,  0.6407623 ,  0.06632648, -0.542237  , -0.45689368,\n",
       "          0.23207906,  0.0029114 , -0.16358204,  0.21275765, -0.00935979,\n",
       "          0.6271751 , -0.25160804,  0.6677554 ,  0.51201993,  0.22570653],\n",
       "        [-0.49787214,  1.0744672 , -1.0065807 , -0.8056908 , -0.23622614,\n",
       "          0.69330335,  0.39437073, -0.84331506,  0.886167  , -1.0557255 ,\n",
       "          0.80882716, -0.5500927 ,  0.24801873,  0.6038297 , -0.4505637 ],\n",
       "        [ 0.15797606,  0.5036516 , -0.5998924 , -0.41956696, -0.27367502,\n",
       "          0.7249046 ,  0.23919022, -0.6810909 ,  0.72020596, -0.11010522,\n",
       "          0.73060673, -0.20017701, -0.09001614,  0.7072366 , -0.13690668],\n",
       "        [ 0.9059524 , -0.868871  ,  0.17652208, -0.08131143,  0.58175707,\n",
       "         -0.44815242,  0.07947527,  0.6358585 , -0.43964264,  0.69272286,\n",
       "         -0.9381056 , -0.24719244, -0.5187118 , -0.48086902,  0.07929724]],\n",
       "       dtype=float32),\n",
       " array([-1.555116 ,  1.6560483, -1.6105272, -1.4889705, -1.5637645,\n",
       "         1.5974519,  1.4014904, -1.6270154,  1.4718293, -1.5567198,\n",
       "         1.571271 , -0.6858524,  1.5975378,  1.580505 , -1.2393651],\n",
       "       dtype=float32),\n",
       " array([[-0.90905255],\n",
       "        [ 1.2497572 ],\n",
       "        [-0.92286134],\n",
       "        [-0.5752385 ],\n",
       "        [-0.88744676],\n",
       "        [ 0.7796554 ],\n",
       "        [ 0.44759944],\n",
       "        [-1.1595966 ],\n",
       "        [ 0.5117094 ],\n",
       "        [-0.9862866 ],\n",
       "        [ 1.0089467 ],\n",
       "        [-0.03345278],\n",
       "        [ 1.0970927 ],\n",
       "        [ 1.0528529 ],\n",
       "        [-0.18683417]], dtype=float32),\n",
       " array([1.6211566], dtype=float32)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_autompg, history_autompg, evaluate_autompg=NN_model_structure_regression_6(X_train_autompg, X_val_autompg, Y_train_autompg, Y_val_autompg, adam2, 32, 1000, x_test_autompg, y_test_autompg)\n",
    "model_autompg.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_autompg.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_autompg_structure6_4th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_37 (Dense)             (None, 5)                 115       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 151\n",
      "Trainable params: 151\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 143 samples, validate on 31 samples\n",
      "Epoch 1/1000\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0725 - val_loss: 0.0296\n",
      "Epoch 2/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0377 - val_loss: 0.0181\n",
      "Epoch 3/1000\n",
      "143/143 [==============================] - 0s 128us/step - loss: 0.0239 - val_loss: 0.0069\n",
      "Epoch 4/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0200 - val_loss: 0.0116\n",
      "Epoch 5/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0165 - val_loss: 0.0072\n",
      "Epoch 6/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0153 - val_loss: 0.0067\n",
      "Epoch 7/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0127 - val_loss: 0.0049\n",
      "Epoch 8/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0105 - val_loss: 0.0047\n",
      "Epoch 9/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0094 - val_loss: 0.0044\n",
      "Epoch 10/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0104 - val_loss: 0.0041\n",
      "Epoch 11/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0084 - val_loss: 0.0066\n",
      "Epoch 12/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0084 - val_loss: 0.0044\n",
      "Epoch 13/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0097 - val_loss: 0.0044\n",
      "Epoch 14/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0110 - val_loss: 0.0062\n",
      "Epoch 15/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0080 - val_loss: 0.0045\n",
      "Epoch 16/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0080 - val_loss: 0.0048\n",
      "Epoch 17/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0072 - val_loss: 0.0046\n",
      "Epoch 18/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0075 - val_loss: 0.0042\n",
      "Epoch 19/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0082 - val_loss: 0.0055\n",
      "Epoch 20/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0090 - val_loss: 0.0059\n",
      "Epoch 21/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0094 - val_loss: 0.0099\n",
      "Epoch 22/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0110 - val_loss: 0.0061\n",
      "Epoch 23/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0077 - val_loss: 0.0065\n",
      "Epoch 24/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0080 - val_loss: 0.0040\n",
      "Epoch 25/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0071 - val_loss: 0.0048\n",
      "Epoch 26/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0075 - val_loss: 0.0048\n",
      "Epoch 27/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0079 - val_loss: 0.0041\n",
      "Epoch 28/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0077 - val_loss: 0.0048\n",
      "Epoch 29/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0082 - val_loss: 0.0046\n",
      "Epoch 30/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0069 - val_loss: 0.0041\n",
      "Epoch 31/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0063 - val_loss: 0.0036\n",
      "Epoch 32/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0072 - val_loss: 0.0055\n",
      "Epoch 33/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0074 - val_loss: 0.0047\n",
      "Epoch 34/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0066 - val_loss: 0.0045\n",
      "Epoch 35/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0063 - val_loss: 0.0038\n",
      "Epoch 36/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0063 - val_loss: 0.0045\n",
      "Epoch 37/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0064 - val_loss: 0.0055\n",
      "Epoch 38/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0073 - val_loss: 0.0066\n",
      "Epoch 39/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0078 - val_loss: 0.0040\n",
      "Epoch 40/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0082 - val_loss: 0.0054\n",
      "Epoch 41/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0072 - val_loss: 0.0046\n",
      "Epoch 42/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0071 - val_loss: 0.0046\n",
      "Epoch 43/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0066 - val_loss: 0.0038\n",
      "Epoch 44/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0073 - val_loss: 0.0053\n",
      "Epoch 45/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0063 - val_loss: 0.0039\n",
      "Epoch 46/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0062 - val_loss: 0.0041\n",
      "Epoch 47/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0059 - val_loss: 0.0040\n",
      "Epoch 48/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0058 - val_loss: 0.0041\n",
      "Epoch 49/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0059 - val_loss: 0.0046\n",
      "Epoch 50/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0057 - val_loss: 0.0043\n",
      "Epoch 51/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0059 - val_loss: 0.0044\n",
      "Epoch 52/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0056 - val_loss: 0.0040\n",
      "Epoch 53/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0056 - val_loss: 0.0044\n",
      "Epoch 54/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0054 - val_loss: 0.0048\n",
      "Epoch 55/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0056 - val_loss: 0.0044\n",
      "Epoch 56/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0057 - val_loss: 0.0040\n",
      "Epoch 57/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0057 - val_loss: 0.0046\n",
      "Epoch 58/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0042\n",
      "Epoch 59/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0061 - val_loss: 0.0045\n",
      "Epoch 60/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0063 - val_loss: 0.0053\n",
      "Epoch 61/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0061 - val_loss: 0.0042\n",
      "Epoch 62/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0056 - val_loss: 0.0053\n",
      "Epoch 63/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0054 - val_loss: 0.0044\n",
      "Epoch 64/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0059 - val_loss: 0.0063\n",
      "Epoch 65/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0062 - val_loss: 0.0045\n",
      "Epoch 66/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0051\n",
      "Epoch 67/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0057 - val_loss: 0.0044\n",
      "Epoch 68/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0057 - val_loss: 0.0047\n",
      "Epoch 69/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 105us/step - loss: 0.0051 - val_loss: 0.0039\n",
      "Epoch 70/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 71/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0052 - val_loss: 0.0045\n",
      "Epoch 72/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0055 - val_loss: 0.0042\n",
      "Epoch 73/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0052 - val_loss: 0.0048\n",
      "Epoch 74/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0051 - val_loss: 0.0041\n",
      "Epoch 75/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0048 - val_loss: 0.0045\n",
      "Epoch 76/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0051 - val_loss: 0.0043\n",
      "Epoch 77/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0053 - val_loss: 0.0064\n",
      "Epoch 78/1000\n",
      "143/143 [==============================] - 0s 96us/step - loss: 0.0060 - val_loss: 0.0040\n",
      "Epoch 79/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0063 - val_loss: 0.0044\n",
      "Epoch 80/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0061 - val_loss: 0.0055\n",
      "Epoch 81/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0059 - val_loss: 0.0042\n",
      "Epoch 82/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 83/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0049 - val_loss: 0.0039\n",
      "Epoch 84/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0044\n",
      "Epoch 85/1000\n",
      "143/143 [==============================] - 0s 129us/step - loss: 0.0046 - val_loss: 0.0041\n",
      "Epoch 86/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 87/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0047 - val_loss: 0.0038\n",
      "Epoch 88/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0048 - val_loss: 0.0043\n",
      "Epoch 89/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0048 - val_loss: 0.0053\n",
      "Epoch 90/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 91/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0040\n",
      "Epoch 92/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 93/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 94/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0051 - val_loss: 0.0064\n",
      "Epoch 95/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0045 - val_loss: 0.0047\n",
      "Epoch 96/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0046 - val_loss: 0.0063\n",
      "Epoch 97/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 98/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 99/1000\n",
      "143/143 [==============================] - 0s 99us/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 100/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 101/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 102/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 103/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0043 - val_loss: 0.0054\n",
      "Epoch 104/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0050 - val_loss: 0.0042\n",
      "Epoch 105/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0041 - val_loss: 0.0054\n",
      "Epoch 106/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0047 - val_loss: 0.0054\n",
      "Epoch 107/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0062\n",
      "Epoch 108/1000\n",
      "143/143 [==============================] - 0s 100us/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 109/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0051 - val_loss: 0.0054\n",
      "Epoch 110/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 111/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0038 - val_loss: 0.0056\n",
      "Epoch 112/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 113/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 114/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0044 - val_loss: 0.0072\n",
      "Epoch 115/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0054 - val_loss: 0.0048\n",
      "Epoch 116/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 117/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0046 - val_loss: 0.0054\n",
      "Epoch 118/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0049 - val_loss: 0.0040\n",
      "Epoch 119/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0050 - val_loss: 0.0042\n",
      "Epoch 120/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 121/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 122/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0037 - val_loss: 0.0049\n",
      "Epoch 123/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0038 - val_loss: 0.0043\n",
      "Epoch 124/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0037 - val_loss: 0.0063\n",
      "Epoch 125/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 126/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 127/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0038 - val_loss: 0.0047\n",
      "Epoch 128/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0039 - val_loss: 0.0041\n",
      "Epoch 129/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 130/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0038 - val_loss: 0.0049\n",
      "Epoch 131/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0052\n",
      "Epoch 132/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0041 - val_loss: 0.0056\n",
      "Epoch 133/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 134/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0044 - val_loss: 0.0053\n",
      "Epoch 135/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0048 - val_loss: 0.0048\n",
      "Epoch 136/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0041 - val_loss: 0.0048\n",
      "Epoch 137/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0041 - val_loss: 0.0044\n",
      "Epoch 138/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0045 - val_loss: 0.0042\n",
      "Epoch 139/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 140/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0037 - val_loss: 0.0044\n",
      "Epoch 141/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0038 - val_loss: 0.0048\n",
      "Epoch 142/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 143/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 144/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0038 - val_loss: 0.0049\n",
      "Epoch 145/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Epoch 146/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0037 - val_loss: 0.0045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0037 - val_loss: 0.0048\n",
      "Epoch 148/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0047\n",
      "Epoch 149/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0039 - val_loss: 0.0048\n",
      "Epoch 150/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0039 - val_loss: 0.0044\n",
      "Epoch 151/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0044\n",
      "Epoch 152/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0050\n",
      "Epoch 153/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 154/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0041\n",
      "Epoch 155/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0038 - val_loss: 0.0068\n",
      "Epoch 156/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0036 - val_loss: 0.0054\n",
      "Epoch 157/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0055\n",
      "Epoch 158/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0035 - val_loss: 0.0040\n",
      "Epoch 159/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0038 - val_loss: 0.0043\n",
      "Epoch 160/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0038 - val_loss: 0.0050\n",
      "Epoch 161/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0034 - val_loss: 0.0040\n",
      "Epoch 162/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0043\n",
      "Epoch 163/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0051\n",
      "Epoch 164/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 165/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0040 - val_loss: 0.0045\n",
      "Epoch 166/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0052\n",
      "Epoch 167/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0035 - val_loss: 0.0047\n",
      "Epoch 168/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0034 - val_loss: 0.0051\n",
      "Epoch 169/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0032 - val_loss: 0.0043\n",
      "Epoch 170/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0033 - val_loss: 0.0045\n",
      "Epoch 171/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0031 - val_loss: 0.0046\n",
      "Epoch 172/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0035 - val_loss: 0.0052\n",
      "Epoch 173/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0031 - val_loss: 0.0047\n",
      "Epoch 174/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0054\n",
      "Epoch 175/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0035 - val_loss: 0.0043\n",
      "Epoch 176/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0048\n",
      "Epoch 177/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0032 - val_loss: 0.0053\n",
      "Epoch 178/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0032 - val_loss: 0.0040\n",
      "Epoch 179/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0044\n",
      "Epoch 180/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0063\n",
      "Epoch 181/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0041 - val_loss: 0.0044\n",
      "Epoch 182/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0053\n",
      "Epoch 183/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 184/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 185/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0040 - val_loss: 0.0069\n",
      "Epoch 186/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0043 - val_loss: 0.0053\n",
      "Epoch 187/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0040 - val_loss: 0.0059\n",
      "Epoch 188/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 189/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0035 - val_loss: 0.0042\n",
      "Epoch 190/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 191/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0030 - val_loss: 0.0043\n",
      "Epoch 192/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0043\n",
      "Epoch 193/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0029 - val_loss: 0.0042\n",
      "Epoch 194/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 195/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0055\n",
      "Epoch 196/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0046\n",
      "Epoch 197/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0064\n",
      "Epoch 198/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0037 - val_loss: 0.0047\n",
      "Epoch 199/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0031 - val_loss: 0.0050\n",
      "Epoch 200/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0028 - val_loss: 0.0045\n",
      "Epoch 201/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0046\n",
      "Epoch 202/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0029 - val_loss: 0.0041\n",
      "Epoch 203/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0029 - val_loss: 0.0043\n",
      "Epoch 204/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0034 - val_loss: 0.0052\n",
      "Epoch 205/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0041 - val_loss: 0.0042\n",
      "Epoch 206/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0032 - val_loss: 0.0045\n",
      "Epoch 207/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0030 - val_loss: 0.0046\n",
      "Epoch 208/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0048\n",
      "Epoch 209/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 210/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0029 - val_loss: 0.0047\n",
      "Epoch 211/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0041\n",
      "Epoch 212/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0044\n",
      "Epoch 213/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0044\n",
      "Epoch 214/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0028 - val_loss: 0.0043\n",
      "Epoch 215/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0050\n",
      "Epoch 216/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0031 - val_loss: 0.0044\n",
      "Epoch 217/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0029 - val_loss: 0.0048\n",
      "Epoch 218/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 219/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0053\n",
      "Epoch 220/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 221/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0027 - val_loss: 0.0049\n",
      "Epoch 222/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0030 - val_loss: 0.0044\n",
      "Epoch 223/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0048\n",
      "Epoch 224/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 101us/step - loss: 0.0030 - val_loss: 0.0043\n",
      "Epoch 225/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0048\n",
      "Epoch 226/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0028 - val_loss: 0.0044\n",
      "Epoch 227/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0028 - val_loss: 0.0041\n",
      "Epoch 228/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0033 - val_loss: 0.0048\n",
      "Epoch 229/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0030 - val_loss: 0.0043\n",
      "Epoch 230/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0029 - val_loss: 0.0042\n",
      "Epoch 231/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0030 - val_loss: 0.0060\n",
      "Epoch 232/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0045\n",
      "Epoch 233/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0033 - val_loss: 0.0041\n",
      "Epoch 234/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0029 - val_loss: 0.0048\n",
      "Epoch 235/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 236/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 237/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0028 - val_loss: 0.0045\n",
      "Epoch 238/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 239/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0027 - val_loss: 0.0043\n",
      "Epoch 240/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0027 - val_loss: 0.0039\n",
      "Epoch 241/1000\n",
      "143/143 [==============================] - 0s 100us/step - loss: 0.0027 - val_loss: 0.0043\n",
      "Epoch 242/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0027 - val_loss: 0.0047\n",
      "Epoch 243/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0026 - val_loss: 0.0042\n",
      "Epoch 244/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0026 - val_loss: 0.0044\n",
      "Epoch 245/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0026 - val_loss: 0.0042\n",
      "Epoch 246/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0067\n",
      "Epoch 247/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0041\n",
      "Epoch 248/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 249/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0061\n",
      "Epoch 250/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0036 - val_loss: 0.0042\n",
      "Epoch 251/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 252/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0034 - val_loss: 0.0050\n",
      "Epoch 253/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0031 - val_loss: 0.0041\n",
      "Epoch 254/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0028 - val_loss: 0.0044\n",
      "Epoch 255/1000\n",
      "143/143 [==============================] - 0s 100us/step - loss: 0.0028 - val_loss: 0.0039\n",
      "Epoch 256/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0026 - val_loss: 0.0040\n",
      "Epoch 257/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0026 - val_loss: 0.0042\n",
      "Epoch 258/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0029 - val_loss: 0.0041\n",
      "Epoch 259/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0046\n",
      "Epoch 260/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0042\n",
      "Epoch 261/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0043\n",
      "Epoch 262/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0042\n",
      "Epoch 263/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0026 - val_loss: 0.0044\n",
      "Epoch 264/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0051\n",
      "Epoch 265/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0027 - val_loss: 0.0045\n",
      "Epoch 266/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0046\n",
      "Epoch 267/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0039\n",
      "Epoch 268/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0026 - val_loss: 0.0041\n",
      "Epoch 269/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0029 - val_loss: 0.0052\n",
      "Epoch 270/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0042\n",
      "Epoch 271/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0030 - val_loss: 0.0040\n",
      "Epoch 272/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0043\n",
      "Epoch 273/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0025 - val_loss: 0.0041\n",
      "Epoch 274/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0026 - val_loss: 0.0042\n",
      "Epoch 275/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0044\n",
      "Epoch 276/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0025 - val_loss: 0.0041\n",
      "Epoch 277/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0025 - val_loss: 0.0045\n",
      "Epoch 278/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0042\n",
      "Epoch 279/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0026 - val_loss: 0.0045\n",
      "Epoch 280/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0025 - val_loss: 0.0043\n",
      "Epoch 281/1000\n",
      "143/143 [==============================] - 0s 129us/step - loss: 0.0024 - val_loss: 0.0041\n",
      "Epoch 282/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0024 - val_loss: 0.0040\n",
      "Epoch 283/1000\n",
      "143/143 [==============================] - 0s 136us/step - loss: 0.0026 - val_loss: 0.0049\n",
      "Epoch 284/1000\n",
      "143/143 [==============================] - 0s 134us/step - loss: 0.0024 - val_loss: 0.0042\n",
      "Epoch 285/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0046\n",
      "Epoch 286/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0040\n",
      "Epoch 287/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0023 - val_loss: 0.0045\n",
      "Epoch 288/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0024 - val_loss: 0.0047\n",
      "Epoch 289/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0025 - val_loss: 0.0043\n",
      "Epoch 290/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0025 - val_loss: 0.0045\n",
      "Epoch 291/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0024 - val_loss: 0.0041\n",
      "Epoch 292/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0027 - val_loss: 0.0043\n",
      "Epoch 293/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0024 - val_loss: 0.0044\n",
      "Epoch 294/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0024 - val_loss: 0.0049\n",
      "Epoch 295/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0043\n",
      "Epoch 296/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0023 - val_loss: 0.0044\n",
      "Epoch 297/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0024 - val_loss: 0.0042\n",
      "Epoch 298/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0026 - val_loss: 0.0043\n",
      "Epoch 299/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0027 - val_loss: 0.0051\n",
      "Epoch 300/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0024 - val_loss: 0.0041\n",
      "Epoch 301/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0041\n",
      "Epoch 302/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0023 - val_loss: 0.0048\n",
      "Epoch 303/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0025 - val_loss: 0.0043\n",
      "Epoch 304/1000\n",
      "143/143 [==============================] - 0s 99us/step - loss: 0.0023 - val_loss: 0.0046\n",
      "Epoch 305/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0045\n",
      "Epoch 306/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0027 - val_loss: 0.0043\n",
      "Epoch 307/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0052\n",
      "Epoch 308/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0027 - val_loss: 0.0045\n",
      "Epoch 309/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0030 - val_loss: 0.0044\n",
      "Epoch 310/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0049\n",
      "Epoch 311/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0022 - val_loss: 0.0044\n",
      "Epoch 312/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0027 - val_loss: 0.0057\n",
      "Epoch 313/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0023 - val_loss: 0.0053\n",
      "Epoch 314/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0032 - val_loss: 0.0049\n",
      "Epoch 315/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0046\n",
      "Epoch 316/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0024 - val_loss: 0.0041\n",
      "Epoch 317/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0049\n",
      "Epoch 318/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0023 - val_loss: 0.0043\n",
      "Epoch 319/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0047\n",
      "Epoch 320/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0044\n",
      "Epoch 321/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0043\n",
      "Epoch 322/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0023 - val_loss: 0.0041\n",
      "Epoch 323/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0023 - val_loss: 0.0047\n",
      "Epoch 324/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0043\n",
      "Epoch 325/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0021 - val_loss: 0.0045\n",
      "Epoch 326/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0052\n",
      "Epoch 327/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0049\n",
      "Epoch 328/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0050\n",
      "Epoch 329/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0043\n",
      "Epoch 330/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0025 - val_loss: 0.0042\n",
      "Epoch 331/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0024 - val_loss: 0.0044\n",
      "Epoch 332/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0023 - val_loss: 0.0047\n",
      "Epoch 333/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0023 - val_loss: 0.0041\n",
      "Epoch 334/1000\n",
      "143/143 [==============================] - 0s 99us/step - loss: 0.0025 - val_loss: 0.0044\n",
      "Epoch 335/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0023 - val_loss: 0.0043\n",
      "Epoch 336/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0045\n",
      "Epoch 337/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0021 - val_loss: 0.0042\n",
      "Epoch 338/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0021 - val_loss: 0.0044\n",
      "Epoch 339/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0023 - val_loss: 0.0041\n",
      "Epoch 340/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0023 - val_loss: 0.0046\n",
      "Epoch 341/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0042\n",
      "Epoch 342/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0041\n",
      "Epoch 343/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0020 - val_loss: 0.0047\n",
      "Epoch 344/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0040\n",
      "Epoch 345/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0040\n",
      "Epoch 346/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0024 - val_loss: 0.0051\n",
      "Epoch 347/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0043\n",
      "Epoch 348/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0048\n",
      "Epoch 349/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0045\n",
      "Epoch 350/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0042\n",
      "Epoch 351/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0025 - val_loss: 0.0047\n",
      "Epoch 352/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0022 - val_loss: 0.0047\n",
      "Epoch 353/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0040\n",
      "Epoch 354/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 355/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0021 - val_loss: 0.0044\n",
      "Epoch 356/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0020 - val_loss: 0.0040\n",
      "Epoch 357/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0022 - val_loss: 0.0048\n",
      "Epoch 358/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0021 - val_loss: 0.0047\n",
      "Epoch 359/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0020 - val_loss: 0.0052\n",
      "Epoch 360/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0053\n",
      "Epoch 361/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0020 - val_loss: 0.0043\n",
      "Epoch 362/1000\n",
      "143/143 [==============================] - 0s 99us/step - loss: 0.0021 - val_loss: 0.0048\n",
      "Epoch 363/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0021 - val_loss: 0.0043\n",
      "Epoch 364/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0041\n",
      "Epoch 365/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0024 - val_loss: 0.0057\n",
      "Epoch 366/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0027 - val_loss: 0.0043\n",
      "Epoch 367/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0021 - val_loss: 0.0043\n",
      "Epoch 368/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0020 - val_loss: 0.0043\n",
      "Epoch 369/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0048\n",
      "Epoch 370/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0042\n",
      "Epoch 371/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.001 - 0s 105us/step - loss: 0.0022 - val_loss: 0.0042\n",
      "Epoch 372/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Epoch 373/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0020 - val_loss: 0.0045\n",
      "Epoch 374/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0041\n",
      "Epoch 375/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0041\n",
      "Epoch 376/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0023 - val_loss: 0.0044\n",
      "Epoch 377/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0022 - val_loss: 0.0048\n",
      "Epoch 378/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 98us/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 379/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 380/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0021 - val_loss: 0.0051\n",
      "Epoch 381/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0025 - val_loss: 0.0044\n",
      "Epoch 382/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0023 - val_loss: 0.0046\n",
      "Epoch 383/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0023 - val_loss: 0.0047\n",
      "Epoch 384/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0021 - val_loss: 0.0043\n",
      "Epoch 385/1000\n",
      "143/143 [==============================] - 0s 100us/step - loss: 0.0021 - val_loss: 0.0043\n",
      "Epoch 386/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0020 - val_loss: 0.0047\n",
      "Epoch 387/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0021 - val_loss: 0.0041\n",
      "Epoch 388/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0045\n",
      "Epoch 389/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0060\n",
      "Epoch 390/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0025 - val_loss: 0.0043\n",
      "Epoch 391/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0025 - val_loss: 0.0044\n",
      "Epoch 392/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0023 - val_loss: 0.0043\n",
      "Epoch 393/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0048\n",
      "Epoch 394/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0045\n",
      "Epoch 395/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0040\n",
      "Epoch 396/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0053\n",
      "Epoch 397/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0024 - val_loss: 0.0046\n",
      "Epoch 398/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0044\n",
      "Epoch 399/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0021 - val_loss: 0.0054\n",
      "Epoch 400/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0043\n",
      "Epoch 401/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0024 - val_loss: 0.0045\n",
      "Epoch 402/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0020 - val_loss: 0.0050\n",
      "Epoch 403/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0024 - val_loss: 0.0044\n",
      "Epoch 404/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0053\n",
      "Epoch 405/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0047\n",
      "Epoch 406/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0020 - val_loss: 0.0041\n",
      "Epoch 407/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 408/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0053\n",
      "Epoch 409/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0021 - val_loss: 0.0044\n",
      "Epoch 410/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0047\n",
      "Epoch 411/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0022 - val_loss: 0.0052\n",
      "Epoch 412/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0031 - val_loss: 0.0043\n",
      "Epoch 413/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0022 - val_loss: 0.0056\n",
      "Epoch 414/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0029 - val_loss: 0.0046\n",
      "Epoch 415/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0043\n",
      "Epoch 416/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 417/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0022 - val_loss: 0.0043\n",
      "Epoch 418/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0042\n",
      "Epoch 419/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0044\n",
      "Epoch 420/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0044\n",
      "Epoch 421/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0021 - val_loss: 0.0056\n",
      "Epoch 422/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0044\n",
      "Epoch 423/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0045\n",
      "Epoch 424/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0044\n",
      "Epoch 425/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0021 - val_loss: 0.0051\n",
      "Epoch 426/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0042\n",
      "Epoch 427/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0018 - val_loss: 0.0042\n",
      "Epoch 428/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0044\n",
      "Epoch 429/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0042\n",
      "Epoch 430/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0048\n",
      "Epoch 431/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0046\n",
      "Epoch 432/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0021 - val_loss: 0.0049\n",
      "Epoch 433/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 434/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0042\n",
      "Epoch 435/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0018 - val_loss: 0.0046\n",
      "Epoch 436/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0042\n",
      "Epoch 437/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0017 - val_loss: 0.0047\n",
      "Epoch 438/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 439/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 440/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 441/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0019 - val_loss: 0.0049\n",
      "Epoch 442/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0023 - val_loss: 0.0047\n",
      "Epoch 443/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0020 - val_loss: 0.0058\n",
      "Epoch 444/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0025 - val_loss: 0.0044\n",
      "Epoch 445/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 446/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 447/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 448/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 449/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0051\n",
      "Epoch 450/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 451/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0048\n",
      "Epoch 452/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0050\n",
      "Epoch 453/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0018 - val_loss: 0.0045\n",
      "Epoch 454/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 455/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 456/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 457/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 458/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 459/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 460/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 461/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0019 - val_loss: 0.0050\n",
      "Epoch 462/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0020 - val_loss: 0.0043\n",
      "Epoch 463/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 464/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0044\n",
      "Epoch 465/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0018 - val_loss: 0.0046\n",
      "Epoch 466/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 467/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0018 - val_loss: 0.0046\n",
      "Epoch 468/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0057\n",
      "Epoch 469/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0024 - val_loss: 0.0044\n",
      "Epoch 470/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0047\n",
      "Epoch 471/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 472/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 473/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0049\n",
      "Epoch 474/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 475/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0045\n",
      "Epoch 476/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 477/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 478/1000\n",
      "143/143 [==============================] - 0s 99us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 479/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0020 - val_loss: 0.0045\n",
      "Epoch 480/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 481/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0017 - val_loss: 0.0047\n",
      "Epoch 482/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0049\n",
      "Epoch 483/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 484/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0017 - val_loss: 0.0057\n",
      "Epoch 485/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 486/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 487/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0016 - val_loss: 0.0054\n",
      "Epoch 488/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 489/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 490/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0050\n",
      "Epoch 491/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0020 - val_loss: 0.0057\n",
      "Epoch 492/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 493/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0047\n",
      "Epoch 494/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0017 - val_loss: 0.0047\n",
      "Epoch 495/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 496/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 497/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 498/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 499/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 500/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0049\n",
      "Epoch 501/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 502/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 503/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0016 - val_loss: 0.0048\n",
      "Epoch 504/1000\n",
      "143/143 [==============================] - 0s 99us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 505/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 506/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0017 - val_loss: 0.0049\n",
      "Epoch 507/1000\n",
      "143/143 [==============================] - 0s 100us/step - loss: 0.0017 - val_loss: 0.0047\n",
      "Epoch 508/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0049\n",
      "Epoch 509/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0053\n",
      "Epoch 510/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0019 - val_loss: 0.0053\n",
      "Epoch 511/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0020 - val_loss: 0.0045\n",
      "Epoch 512/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0048\n",
      "Epoch 513/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0016 - val_loss: 0.0051\n",
      "Epoch 514/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0020 - val_loss: 0.0045\n",
      "Epoch 515/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 516/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 517/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0054\n",
      "Epoch 518/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 519/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0021 - val_loss: 0.0046\n",
      "Epoch 520/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0061\n",
      "Epoch 521/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0047\n",
      "Epoch 522/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0051\n",
      "Epoch 523/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0024 - val_loss: 0.0064\n",
      "Epoch 524/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0024 - val_loss: 0.0047\n",
      "Epoch 525/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0019 - val_loss: 0.0047\n",
      "Epoch 526/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0016 - val_loss: 0.0047\n",
      "Epoch 527/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 528/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0049\n",
      "Epoch 529/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 530/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0057\n",
      "Epoch 531/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0019 - val_loss: 0.0042\n",
      "Epoch 532/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 107us/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 533/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0018 - val_loss: 0.0052\n",
      "Epoch 534/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0018 - val_loss: 0.0048\n",
      "Epoch 535/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0018 - val_loss: 0.0042\n",
      "Epoch 536/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0016 - val_loss: 0.0047\n",
      "Epoch 537/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 538/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0017 - val_loss: 0.0053\n",
      "Epoch 539/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0020 - val_loss: 0.0046\n",
      "Epoch 540/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0045\n",
      "Epoch 541/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0021 - val_loss: 0.0061\n",
      "Epoch 542/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0023 - val_loss: 0.0045\n",
      "Epoch 543/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 544/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0017 - val_loss: 0.0053\n",
      "Epoch 545/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 546/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 547/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0050\n",
      "Epoch 548/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 549/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 550/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0056\n",
      "Epoch 551/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 552/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0021 - val_loss: 0.0046\n",
      "Epoch 553/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0020 - val_loss: 0.0044\n",
      "Epoch 554/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0051\n",
      "Epoch 555/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 556/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 557/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 558/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 559/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 560/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0017 - val_loss: 0.0047\n",
      "Epoch 561/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0016 - val_loss: 0.0047\n",
      "Epoch 562/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 563/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 564/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 565/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0018 - val_loss: 0.0045\n",
      "Epoch 566/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 567/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0015 - val_loss: 0.0046\n",
      "Epoch 568/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0046\n",
      "Epoch 569/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0015 - val_loss: 0.0045\n",
      "Epoch 570/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 571/1000\n",
      "143/143 [==============================] - 0s 99us/step - loss: 0.0015 - val_loss: 0.0048\n",
      "Epoch 572/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0017 - val_loss: 0.0047\n",
      "Epoch 573/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 574/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0017 - val_loss: 0.0047\n",
      "Epoch 575/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0016 - val_loss: 0.0050\n",
      "Epoch 576/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0046\n",
      "Epoch 577/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 578/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0016 - val_loss: 0.0054\n",
      "Epoch 579/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 580/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 581/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0015 - val_loss: 0.0048\n",
      "Epoch 582/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0060\n",
      "Epoch 583/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0019 - val_loss: 0.0049\n",
      "Epoch 584/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0048\n",
      "Epoch 585/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0015 - val_loss: 0.0045\n",
      "Epoch 586/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 587/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 588/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 589/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 590/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0046\n",
      "Epoch 591/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0050\n",
      "Epoch 592/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 593/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0018 - val_loss: 0.0046\n",
      "Epoch 594/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0014 - val_loss: 0.0046\n",
      "Epoch 595/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0053\n",
      "Epoch 596/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 597/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 598/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0015 - val_loss: 0.0060\n",
      "Epoch 599/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0018 - val_loss: 0.0051\n",
      "Epoch 600/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0023 - val_loss: 0.0045\n",
      "Epoch 601/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0018 - val_loss: 0.0050\n",
      "Epoch 602/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0018 - val_loss: 0.0047\n",
      "Epoch 603/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 604/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 605/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0048\n",
      "Epoch 606/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0060\n",
      "Epoch 607/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0022 - val_loss: 0.0043\n",
      "Epoch 608/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0047\n",
      "Epoch 609/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0047\n",
      "Epoch 610/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 611/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 612/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 613/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 614/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0047\n",
      "Epoch 615/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0014 - val_loss: 0.0046\n",
      "Epoch 616/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0050\n",
      "Epoch 617/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0048\n",
      "Epoch 618/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 619/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0020 - val_loss: 0.0048\n",
      "Epoch 620/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0058\n",
      "Epoch 621/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0018 - val_loss: 0.0050\n",
      "Epoch 622/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0047\n",
      "Epoch 623/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0051\n",
      "Epoch 624/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 625/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 626/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 627/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0051\n",
      "Epoch 628/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 629/1000\n",
      "143/143 [==============================] - 0s 99us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 630/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0057\n",
      "Epoch 631/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0022 - val_loss: 0.0048\n",
      "Epoch 632/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0020 - val_loss: 0.0043\n",
      "Epoch 633/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0049\n",
      "Epoch 634/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 635/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 636/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0016 - val_loss: 0.0051\n",
      "Epoch 637/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0044\n",
      "Epoch 638/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 639/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0015 - val_loss: 0.0052\n",
      "Epoch 640/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 641/1000\n",
      "143/143 [==============================] - 0s 99us/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 642/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0016 - val_loss: 0.0052\n",
      "Epoch 643/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 644/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0015 - val_loss: 0.0047\n",
      "Epoch 645/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0014 - val_loss: 0.0049\n",
      "Epoch 646/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0014 - val_loss: 0.0047\n",
      "Epoch 647/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0014 - val_loss: 0.0046\n",
      "Epoch 648/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0015 - val_loss: 0.0047\n",
      "Epoch 649/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0015 - val_loss: 0.0045\n",
      "Epoch 650/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0050\n",
      "Epoch 651/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0047\n",
      "Epoch 652/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0048\n",
      "Epoch 653/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0049\n",
      "Epoch 654/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0048\n",
      "Epoch 655/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0054\n",
      "Epoch 656/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0047\n",
      "Epoch 657/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0014 - val_loss: 0.0049\n",
      "Epoch 658/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0068\n",
      "Epoch 659/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 660/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 661/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0016 - val_loss: 0.0070\n",
      "Epoch 662/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0057\n",
      "Epoch 663/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0025 - val_loss: 0.0050\n",
      "Epoch 664/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0018 - val_loss: 0.0048\n",
      "Epoch 665/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 666/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0048\n",
      "Epoch 667/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0014 - val_loss: 0.0046\n",
      "Epoch 668/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0014 - val_loss: 0.0046\n",
      "Epoch 669/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0014 - val_loss: 0.0049\n",
      "Epoch 670/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0051\n",
      "Epoch 671/1000\n",
      "143/143 [==============================] - 0s 100us/step - loss: 0.0014 - val_loss: 0.0047\n",
      "Epoch 672/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0046\n",
      "Epoch 673/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0014 - val_loss: 0.0048\n",
      "Epoch 674/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0046\n",
      "Epoch 675/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0014 - val_loss: 0.0047\n",
      "Epoch 676/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0015 - val_loss: 0.0055\n",
      "Epoch 677/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0019 - val_loss: 0.0052\n",
      "Epoch 678/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0020 - val_loss: 0.0051\n",
      "Epoch 679/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0064\n",
      "Epoch 680/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0019 - val_loss: 0.0052\n",
      "Epoch 681/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0022 - val_loss: 0.0053\n",
      "Epoch 682/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 683/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0015 - val_loss: 0.0045\n",
      "Epoch 684/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0060\n",
      "Epoch 685/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0047\n",
      "Epoch 686/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 133us/step - loss: 0.0017 - val_loss: 0.0048\n",
      "Epoch 687/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0014 - val_loss: 0.0048\n",
      "Epoch 688/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0047\n",
      "Epoch 689/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0047\n",
      "Epoch 690/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0047\n",
      "Epoch 691/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 692/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 0.0045\n",
      "Epoch 693/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0053\n",
      "Epoch 694/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0014 - val_loss: 0.0046\n",
      "Epoch 695/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0047\n",
      "Epoch 696/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0048\n",
      "Epoch 697/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0044\n",
      "Epoch 698/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0047\n",
      "Epoch 699/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0047\n",
      "Epoch 700/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0047\n",
      "Epoch 701/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0014 - val_loss: 0.0049\n",
      "Epoch 702/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0055\n",
      "Epoch 703/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0016 - val_loss: 0.0048\n",
      "Epoch 704/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0048\n",
      "Epoch 705/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0057\n",
      "Epoch 706/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0053\n",
      "Epoch 707/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 708/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 709/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0014 - val_loss: 0.0048\n",
      "Epoch 710/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0013 - val_loss: 0.0048\n",
      "Epoch 711/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0045\n",
      "Epoch 712/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0014 - val_loss: 0.0048\n",
      "Epoch 713/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 0.0049\n",
      "Epoch 714/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0047\n",
      "Epoch 715/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0049\n",
      "Epoch 716/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0049\n",
      "Epoch 717/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0013 - val_loss: 0.0047\n",
      "Epoch 718/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0052\n",
      "Epoch 719/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0051\n",
      "Epoch 720/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0016 - val_loss: 0.0048\n",
      "Epoch 721/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0053\n",
      "Epoch 722/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0052\n",
      "Epoch 723/1000\n",
      "143/143 [==============================] - 0s 127us/step - loss: 0.0015 - val_loss: 0.0047\n",
      "Epoch 724/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0052\n",
      "Epoch 725/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0052\n",
      "Epoch 726/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0047\n",
      "Epoch 727/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 728/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0014 - val_loss: 0.0049\n",
      "Epoch 729/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0049\n",
      "Epoch 730/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0013 - val_loss: 0.0052\n",
      "Epoch 731/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0050\n",
      "Epoch 732/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0048\n",
      "Epoch 733/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0014 - val_loss: 0.0049\n",
      "Epoch 734/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0014 - val_loss: 0.0063\n",
      "Epoch 735/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0046\n",
      "Epoch 736/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 737/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0017 - val_loss: 0.0050\n",
      "Epoch 738/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0051\n",
      "Epoch 739/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 740/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 741/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0057\n",
      "Epoch 742/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0017 - val_loss: 0.0047\n",
      "Epoch 743/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0047\n",
      "Epoch 744/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0054\n",
      "Epoch 745/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0047\n",
      "Epoch 746/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 747/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0014 - val_loss: 0.0053\n",
      "Epoch 748/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0017 - val_loss: 0.0048\n",
      "Epoch 749/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0046\n",
      "Epoch 750/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0047\n",
      "Epoch 751/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0049\n",
      "Epoch 752/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0051\n",
      "Epoch 753/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0047\n",
      "Epoch 754/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0014 - val_loss: 0.0047\n",
      "Epoch 755/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0049\n",
      "Epoch 756/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0014 - val_loss: 0.0048\n",
      "Epoch 757/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0014 - val_loss: 0.0048\n",
      "Epoch 758/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0012 - val_loss: 0.0051\n",
      "Epoch 759/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0016 - val_loss: 0.0052\n",
      "Epoch 760/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0049\n",
      "Epoch 761/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0047\n",
      "Epoch 762/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0047\n",
      "Epoch 763/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 109us/step - loss: 0.0014 - val_loss: 0.0050\n",
      "Epoch 764/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0053\n",
      "Epoch 765/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0049\n",
      "Epoch 766/1000\n",
      "143/143 [==============================] - 0s 92us/step - loss: 0.0013 - val_loss: 0.0049\n",
      "Epoch 767/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0048\n",
      "Epoch 768/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0013 - val_loss: 0.0052\n",
      "Epoch 769/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0014 - val_loss: 0.0050\n",
      "Epoch 770/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0013 - val_loss: 0.0050\n",
      "Epoch 771/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0013 - val_loss: 0.0052\n",
      "Epoch 772/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0051\n",
      "Epoch 773/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0014 - val_loss: 0.0050\n",
      "Epoch 774/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0052\n",
      "Epoch 775/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0051\n",
      "Epoch 776/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0013 - val_loss: 0.0049\n",
      "Epoch 777/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0016 - val_loss: 0.0050\n",
      "Epoch 778/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0012 - val_loss: 0.0049\n",
      "Epoch 779/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0048\n",
      "Epoch 780/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0052\n",
      "Epoch 781/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0014 - val_loss: 0.0062\n",
      "Epoch 782/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0020 - val_loss: 0.0048\n",
      "Epoch 783/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0014 - val_loss: 0.0050\n",
      "Epoch 784/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0049\n",
      "Epoch 785/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0015 - val_loss: 0.0053\n",
      "Epoch 786/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0050\n",
      "Epoch 787/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0046\n",
      "Epoch 788/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0015 - val_loss: 0.0054\n",
      "Epoch 789/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0013 - val_loss: 0.0049\n",
      "Epoch 790/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0014 - val_loss: 0.0046\n",
      "Epoch 791/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0016 - val_loss: 0.0053\n",
      "Epoch 792/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0058\n",
      "Epoch 793/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0049\n",
      "Epoch 794/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0050\n",
      "Epoch 795/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0013 - val_loss: 0.0055\n",
      "Epoch 796/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0048\n",
      "Epoch 797/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0049\n",
      "Epoch 798/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0012 - val_loss: 0.0051\n",
      "Epoch 799/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0050\n",
      "Epoch 800/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0054\n",
      "Epoch 801/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0014 - val_loss: 0.0050\n",
      "Epoch 802/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0049\n",
      "Epoch 803/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0013 - val_loss: 0.0051\n",
      "Epoch 804/1000\n",
      "143/143 [==============================] - 0s 100us/step - loss: 0.0013 - val_loss: 0.0051\n",
      "Epoch 805/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0013 - val_loss: 0.0049\n",
      "Epoch 806/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0049\n",
      "Epoch 807/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0012 - val_loss: 0.0052\n",
      "Epoch 808/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0052\n",
      "Epoch 809/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0013 - val_loss: 0.0052\n",
      "Epoch 810/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0012 - val_loss: 0.0052\n",
      "Epoch 811/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0012 - val_loss: 0.0050\n",
      "Epoch 812/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0013 - val_loss: 0.0057\n",
      "Epoch 813/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0014 - val_loss: 0.0052\n",
      "Epoch 814/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0014 - val_loss: 0.0049\n",
      "Epoch 815/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0051\n",
      "Epoch 816/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0051\n",
      "Epoch 817/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0012 - val_loss: 0.0049\n",
      "Epoch 818/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0012 - val_loss: 0.0050\n",
      "Epoch 819/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0049\n",
      "Epoch 820/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0014 - val_loss: 0.0053\n",
      "Epoch 821/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0012 - val_loss: 0.0049\n",
      "Epoch 822/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0013 - val_loss: 0.0050\n",
      "Epoch 823/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0053\n",
      "Epoch 824/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0012 - val_loss: 0.0050\n",
      "Epoch 825/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0049\n",
      "Epoch 826/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0014 - val_loss: 0.0056\n",
      "Epoch 827/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0014 - val_loss: 0.0051\n",
      "Epoch 828/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0012 - val_loss: 0.0050\n",
      "Epoch 829/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0055\n",
      "Epoch 830/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0016 - val_loss: 0.0051\n",
      "Epoch 831/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0013 - val_loss: 0.0049\n",
      "Epoch 832/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0015 - val_loss: 0.0054\n",
      "Epoch 833/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0014 - val_loss: 0.0053\n",
      "Epoch 834/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0051\n",
      "Epoch 835/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0012 - val_loss: 0.0050\n",
      "Epoch 836/1000\n",
      "143/143 [==============================] - 0s 100us/step - loss: 0.0014 - val_loss: 0.0054\n",
      "Epoch 837/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0057\n",
      "Epoch 838/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0053\n",
      "Epoch 839/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0017 - val_loss: 0.0051\n",
      "Epoch 840/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0065\n",
      "Epoch 841/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0016 - val_loss: 0.0051\n",
      "Epoch 842/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0015 - val_loss: 0.0051\n",
      "Epoch 843/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0013 - val_loss: 0.0052\n",
      "Epoch 844/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0014 - val_loss: 0.0055\n",
      "Epoch 845/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0018 - val_loss: 0.0053\n",
      "Epoch 846/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0014 - val_loss: 0.0054\n",
      "Epoch 847/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0012 - val_loss: 0.0047\n",
      "Epoch 848/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0013 - val_loss: 0.0050\n",
      "Epoch 849/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0055\n",
      "Epoch 850/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0014 - val_loss: 0.0055\n",
      "Epoch 851/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0015 - val_loss: 0.0053\n",
      "Epoch 852/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0054\n",
      "Epoch 853/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0016 - val_loss: 0.0057\n",
      "Epoch 854/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0049\n",
      "Epoch 855/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0051\n",
      "Epoch 856/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0056\n",
      "Epoch 857/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0046\n",
      "Epoch 858/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0049\n",
      "Epoch 859/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0048\n",
      "Epoch 860/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0013 - val_loss: 0.0064\n",
      "Epoch 861/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0053\n",
      "Epoch 862/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0014 - val_loss: 0.0049\n",
      "Epoch 863/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0013 - val_loss: 0.0052\n",
      "Epoch 864/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0013 - val_loss: 0.0050\n",
      "Epoch 865/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0049\n",
      "Epoch 866/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0015 - val_loss: 0.0051\n",
      "Epoch 867/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0061\n",
      "Epoch 868/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0049\n",
      "Epoch 869/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0012 - val_loss: 0.0052\n",
      "Epoch 870/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0012 - val_loss: 0.0051\n",
      "Epoch 871/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0051\n",
      "Epoch 872/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0013 - val_loss: 0.0046\n",
      "Epoch 873/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0012 - val_loss: 0.0052\n",
      "Epoch 874/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0013 - val_loss: 0.0051\n",
      "Epoch 875/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0013 - val_loss: 0.0050\n",
      "Epoch 876/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0054\n",
      "Epoch 877/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0012 - val_loss: 0.0050\n",
      "Epoch 878/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0047\n",
      "Epoch 879/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0014 - val_loss: 0.0057\n",
      "Epoch 880/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0013 - val_loss: 0.0047\n",
      "Epoch 881/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0012 - val_loss: 0.0049\n",
      "Epoch 882/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0013 - val_loss: 0.0061\n",
      "Epoch 883/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0052\n",
      "Epoch 884/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0016 - val_loss: 0.0056\n",
      "Epoch 885/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0020 - val_loss: 0.0064\n",
      "Epoch 886/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0020 - val_loss: 0.0052\n",
      "Epoch 887/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0050\n",
      "Epoch 888/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0013 - val_loss: 0.0050\n",
      "Epoch 889/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0013 - val_loss: 0.0051\n",
      "Epoch 890/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0051\n",
      "Epoch 891/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0013 - val_loss: 0.0050\n",
      "Epoch 892/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0013 - val_loss: 0.0050\n",
      "Epoch 893/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0059\n",
      "Epoch 894/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0051\n",
      "Epoch 895/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0016 - val_loss: 0.0050\n",
      "Epoch 896/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0054\n",
      "Epoch 897/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0012 - val_loss: 0.0049\n",
      "Epoch 898/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0012 - val_loss: 0.0051\n",
      "Epoch 899/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0012 - val_loss: 0.0052\n",
      "Epoch 900/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0051\n",
      "Epoch 901/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0013 - val_loss: 0.0051\n",
      "Epoch 902/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0012 - val_loss: 0.0061\n",
      "Epoch 903/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0014 - val_loss: 0.0053\n",
      "Epoch 904/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0053\n",
      "Epoch 905/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0057\n",
      "Epoch 906/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0050\n",
      "Epoch 907/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0050\n",
      "Epoch 908/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0053\n",
      "Epoch 909/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0055\n",
      "Epoch 910/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0013 - val_loss: 0.0049\n",
      "Epoch 911/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0054\n",
      "Epoch 912/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0012 - val_loss: 0.0051\n",
      "Epoch 913/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0012 - val_loss: 0.0050\n",
      "Epoch 914/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0013 - val_loss: 0.0051\n",
      "Epoch 915/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0053\n",
      "Epoch 916/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0059\n",
      "Epoch 917/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0054\n",
      "Epoch 918/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0015 - val_loss: 0.0051\n",
      "Epoch 919/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0014 - val_loss: 0.0062\n",
      "Epoch 920/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0051\n",
      "Epoch 921/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0049\n",
      "Epoch 922/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0015 - val_loss: 0.0056\n",
      "Epoch 923/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0012 - val_loss: 0.0052\n",
      "Epoch 924/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0013 - val_loss: 0.0053\n",
      "Epoch 925/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0052\n",
      "Epoch 926/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0012 - val_loss: 0.0055\n",
      "Epoch 927/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0053\n",
      "Epoch 928/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0013 - val_loss: 0.0053\n",
      "Epoch 929/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0015 - val_loss: 0.0052\n",
      "Epoch 930/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0014 - val_loss: 0.0055\n",
      "Epoch 931/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0012 - val_loss: 0.0052\n",
      "Epoch 932/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0014 - val_loss: 0.0048\n",
      "Epoch 933/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0056\n",
      "Epoch 934/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0013 - val_loss: 0.0055\n",
      "Epoch 935/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0014 - val_loss: 0.0051\n",
      "Epoch 936/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0053\n",
      "Epoch 937/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0011 - val_loss: 0.0054\n",
      "Epoch 938/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0011 - val_loss: 0.0052\n",
      "Epoch 939/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0050\n",
      "Epoch 940/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0052\n",
      "Epoch 941/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0053\n",
      "Epoch 942/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0012 - val_loss: 0.0051\n",
      "Epoch 943/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0012 - val_loss: 0.0057\n",
      "Epoch 944/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0013 - val_loss: 0.0052\n",
      "Epoch 945/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0050\n",
      "Epoch 946/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0012 - val_loss: 0.0052\n",
      "Epoch 947/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0054\n",
      "Epoch 948/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0012 - val_loss: 0.0051\n",
      "Epoch 949/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0013 - val_loss: 0.0054\n",
      "Epoch 950/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0012 - val_loss: 0.0055\n",
      "Epoch 951/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0012 - val_loss: 0.0051\n",
      "Epoch 952/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0012 - val_loss: 0.0054\n",
      "Epoch 953/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0013 - val_loss: 0.0058\n",
      "Epoch 954/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0056\n",
      "Epoch 955/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0018 - val_loss: 0.0053\n",
      "Epoch 956/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0066\n",
      "Epoch 957/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0022 - val_loss: 0.0050\n",
      "Epoch 958/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0017 - val_loss: 0.0049\n",
      "Epoch 959/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0015 - val_loss: 0.0058\n",
      "Epoch 960/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0016 - val_loss: 0.0053\n",
      "Epoch 961/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0055\n",
      "Epoch 962/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0017 - val_loss: 0.0061\n",
      "Epoch 963/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0018 - val_loss: 0.0050\n",
      "Epoch 964/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0049\n",
      "Epoch 965/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0056\n",
      "Epoch 966/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0051\n",
      "Epoch 967/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0051\n",
      "Epoch 968/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0015 - val_loss: 0.0062\n",
      "Epoch 969/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0017 - val_loss: 0.0050\n",
      "Epoch 970/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0052\n",
      "Epoch 971/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0013 - val_loss: 0.0052\n",
      "Epoch 972/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0013 - val_loss: 0.0051\n",
      "Epoch 973/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0052\n",
      "Epoch 974/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0013 - val_loss: 0.0054\n",
      "Epoch 975/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0012 - val_loss: 0.0052\n",
      "Epoch 976/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0012 - val_loss: 0.0053\n",
      "Epoch 977/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0012 - val_loss: 0.0051\n",
      "Epoch 978/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0054\n",
      "Epoch 979/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0012 - val_loss: 0.0051\n",
      "Epoch 980/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0011 - val_loss: 0.0051\n",
      "Epoch 981/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0012 - val_loss: 0.0053\n",
      "Epoch 982/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0012 - val_loss: 0.0051\n",
      "Epoch 983/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0012 - val_loss: 0.0051\n",
      "Epoch 984/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0011 - val_loss: 0.0051\n",
      "Epoch 985/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0012 - val_loss: 0.0053\n",
      "Epoch 986/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0049\n",
      "Epoch 987/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0012 - val_loss: 0.0052\n",
      "Epoch 988/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0053\n",
      "Epoch 989/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0013 - val_loss: 0.0058\n",
      "Epoch 990/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0052\n",
      "Epoch 991/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0014 - val_loss: 0.0053\n",
      "Epoch 992/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0062\n",
      "Epoch 993/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0016 - val_loss: 0.0062\n",
      "Epoch 994/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 133us/step - loss: 0.0023 - val_loss: 0.0056\n",
      "Epoch 995/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0061\n",
      "Epoch 996/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0022 - val_loss: 0.0056\n",
      "Epoch 997/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0020 - val_loss: 0.0064\n",
      "Epoch 998/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0018 - val_loss: 0.0053\n",
      "Epoch 999/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0015 - val_loss: 0.0052\n",
      "Epoch 1000/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0013 - val_loss: 0.0052\n",
      "0.008062931708991528\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 5.4572242e-01,  8.1395912e-01, -8.1829512e-01, -4.9526799e-01,\n",
       "         -7.1121371e-01],\n",
       "        [ 9.8678023e-02, -2.7170020e-01,  5.8043122e-01, -5.6454343e-01,\n",
       "          3.8592598e-01],\n",
       "        [ 1.8328462e-02,  1.4726886e-01,  7.2901225e-01, -6.4288139e-01,\n",
       "          3.0222836e-01],\n",
       "        [-1.0864085e-02,  4.6984279e-01,  2.7233416e-01, -6.9548005e-01,\n",
       "          1.0841838e+00],\n",
       "        [-2.9395930e-03, -1.9265683e-02,  4.0132487e-01, -1.4887788e+00,\n",
       "         -1.4735620e-02],\n",
       "        [-8.5325670e-01, -7.3470008e-01, -2.7525559e-01, -4.4424683e-01,\n",
       "         -8.6709291e-01],\n",
       "        [ 3.9613715e-01, -4.0190715e-01,  4.5254010e-01, -1.2290791e+00,\n",
       "         -8.7363046e-01],\n",
       "        [ 2.9471648e-01,  3.6090896e-01,  2.1694399e-01, -2.6279090e-02,\n",
       "         -2.6558207e-03],\n",
       "        [-3.0949569e-01, -7.9460688e-02, -3.4442896e-01, -9.0982372e-01,\n",
       "         -3.5798791e-01],\n",
       "        [ 2.0911319e+00,  8.7794930e-01,  3.3261800e-01, -3.4233910e-01,\n",
       "          6.6050701e-04],\n",
       "        [ 1.9919497e-01, -7.2951829e-01,  1.3556515e-01, -1.3901769e-01,\n",
       "          5.9781557e-01],\n",
       "        [ 8.1666894e-02,  1.0468969e+00, -3.8949144e-01,  1.6245697e+00,\n",
       "          1.2923284e+00],\n",
       "        [ 6.8687487e-01,  1.3723126e-01, -4.9633977e-01,  1.7160192e+00,\n",
       "         -6.3509867e-02],\n",
       "        [-7.8449136e-01, -4.9807444e-01, -2.2468112e+00,  8.3996433e-01,\n",
       "          8.5566628e-01],\n",
       "        [-2.7361360e-01, -2.4343020e-01, -3.3818898e-01,  4.5825571e-01,\n",
       "          2.6367509e-01],\n",
       "        [ 1.0204352e+00,  3.0616847e-01,  1.9261472e-01,  4.0628108e-01,\n",
       "         -2.1631248e-02],\n",
       "        [-8.4307438e-01,  3.3067232e-01, -4.8578335e-03,  3.1142139e-01,\n",
       "         -1.0339429e-01],\n",
       "        [ 5.4726440e-01, -5.8106609e-02, -5.1004636e-01, -1.4176485e-01,\n",
       "         -9.5881379e-01],\n",
       "        [-1.5297256e+00, -1.3665164e+00,  2.2103867e-01, -1.6016705e-01,\n",
       "          1.5327064e+00],\n",
       "        [-2.1284170e-01, -5.2801043e-01,  4.3780565e-01,  1.6191874e-01,\n",
       "          4.4428423e-01],\n",
       "        [-1.6862921e-01, -8.2589246e-02,  2.4885430e+00, -1.4587258e+00,\n",
       "         -6.3451248e-01],\n",
       "        [ 3.5518572e-01, -1.0360615e+00,  4.0608543e-01, -8.5313761e-01,\n",
       "          1.1256964e-02]], dtype=float32),\n",
       " array([ 0.2636588 ,  0.19271158,  0.33452907, -0.34885943, -0.11605458],\n",
       "       dtype=float32),\n",
       " array([[ 0.9884291 , -0.24351057,  0.34521413,  0.31451774,  0.29362398],\n",
       "        [ 0.01434669, -0.35937285,  0.05763306, -0.10538387, -0.34817633],\n",
       "        [-0.49424887,  0.8159353 , -0.3921752 ,  0.25725365, -0.7764347 ],\n",
       "        [ 0.15949045,  0.5668014 , -0.05754466,  0.41960135, -0.808739  ],\n",
       "        [ 0.0772112 , -0.33472028, -0.03876193,  0.47001925,  0.199003  ]],\n",
       "       dtype=float32),\n",
       " array([-0.12599598,  0.16402854, -0.00960915, -0.00646501, -0.05933734],\n",
       "       dtype=float32),\n",
       " array([[ 0.14037436],\n",
       "        [-0.0432646 ],\n",
       "        [ 0.02234672],\n",
       "        [ 0.04835502],\n",
       "        [ 0.52144206]], dtype=float32),\n",
       " array([0.0331239], dtype=float32)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_automobile, history_automobile, evaluate_automobile=NN_model_structure_regression_1(X_train_automobile, X_val_automobile, Y_train_automobile, Y_val_automobile, adam2, 32, 1000, x_test_automobile, y_test_automobile)\n",
    "model_automobile.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_automobile.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_automobile_structure1_4th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_40 (Dense)             (None, 5)                 115       \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 186\n",
      "Trainable params: 186\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 143 samples, validate on 31 samples\n",
      "Epoch 1/1000\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1213 - val_loss: 0.0194\n",
      "Epoch 2/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0260 - val_loss: 0.0075\n",
      "Epoch 3/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0178 - val_loss: 0.0128\n",
      "Epoch 4/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0167 - val_loss: 0.0087\n",
      "Epoch 5/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0148 - val_loss: 0.0116\n",
      "Epoch 6/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0123 - val_loss: 0.0084\n",
      "Epoch 7/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0104 - val_loss: 0.0056\n",
      "Epoch 8/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0113 - val_loss: 0.0083\n",
      "Epoch 9/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0098 - val_loss: 0.0048\n",
      "Epoch 10/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0088 - val_loss: 0.0069\n",
      "Epoch 11/1000\n",
      "143/143 [==============================] - 0s 100us/step - loss: 0.0113 - val_loss: 0.0057\n",
      "Epoch 12/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0098 - val_loss: 0.0044\n",
      "Epoch 13/1000\n",
      "143/143 [==============================] - 0s 99us/step - loss: 0.0091 - val_loss: 0.0065\n",
      "Epoch 14/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0086 - val_loss: 0.0108\n",
      "Epoch 15/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0097 - val_loss: 0.0074\n",
      "Epoch 16/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0108 - val_loss: 0.0055\n",
      "Epoch 17/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0090 - val_loss: 0.0048\n",
      "Epoch 18/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0086 - val_loss: 0.0069\n",
      "Epoch 19/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0080 - val_loss: 0.0055\n",
      "Epoch 20/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0075 - val_loss: 0.0044\n",
      "Epoch 21/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0073 - val_loss: 0.0057\n",
      "Epoch 22/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0073 - val_loss: 0.0046\n",
      "Epoch 23/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0077 - val_loss: 0.0052\n",
      "Epoch 24/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0085 - val_loss: 0.0052\n",
      "Epoch 25/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0078 - val_loss: 0.0062\n",
      "Epoch 26/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0074 - val_loss: 0.0043\n",
      "Epoch 27/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0077 - val_loss: 0.0049\n",
      "Epoch 28/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0083 - val_loss: 0.0050\n",
      "Epoch 29/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0075 - val_loss: 0.0047\n",
      "Epoch 30/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0073 - val_loss: 0.0062\n",
      "Epoch 31/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0077 - val_loss: 0.0078\n",
      "Epoch 32/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0085 - val_loss: 0.0074\n",
      "Epoch 33/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0085 - val_loss: 0.0045\n",
      "Epoch 34/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0074 - val_loss: 0.0056\n",
      "Epoch 35/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0075 - val_loss: 0.0051\n",
      "Epoch 36/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0074 - val_loss: 0.0065\n",
      "Epoch 37/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0087 - val_loss: 0.0039\n",
      "Epoch 38/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0074 - val_loss: 0.0072\n",
      "Epoch 39/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0073 - val_loss: 0.0049\n",
      "Epoch 40/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0074 - val_loss: 0.0046\n",
      "Epoch 41/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0073 - val_loss: 0.0059\n",
      "Epoch 42/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0076 - val_loss: 0.0074\n",
      "Epoch 43/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0072 - val_loss: 0.0046\n",
      "Epoch 44/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0067 - val_loss: 0.0056\n",
      "Epoch 45/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0066 - val_loss: 0.0046\n",
      "Epoch 46/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0064 - val_loss: 0.0046\n",
      "Epoch 47/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0065 - val_loss: 0.0062\n",
      "Epoch 48/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0066 - val_loss: 0.0055\n",
      "Epoch 49/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0066 - val_loss: 0.0051\n",
      "Epoch 50/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0065 - val_loss: 0.0042\n",
      "Epoch 51/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0069 - val_loss: 0.0040\n",
      "Epoch 52/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0064 - val_loss: 0.0056\n",
      "Epoch 53/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0062 - val_loss: 0.0050\n",
      "Epoch 54/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0058 - val_loss: 0.0051\n",
      "Epoch 55/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0058 - val_loss: 0.0049\n",
      "Epoch 56/1000\n",
      "143/143 [==============================] - 0s 100us/step - loss: 0.0058 - val_loss: 0.0053\n",
      "Epoch 57/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0059 - val_loss: 0.0043\n",
      "Epoch 58/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0055 - val_loss: 0.0044\n",
      "Epoch 59/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0056 - val_loss: 0.0044\n",
      "Epoch 60/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0057 - val_loss: 0.0044\n",
      "Epoch 61/1000\n",
      "143/143 [==============================] - 0s 130us/step - loss: 0.0053 - val_loss: 0.0068\n",
      "Epoch 62/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0064 - val_loss: 0.0051\n",
      "Epoch 63/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0057 - val_loss: 0.0044\n",
      "Epoch 64/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0055 - val_loss: 0.0043\n",
      "Epoch 65/1000\n",
      "143/143 [==============================] - 0s 135us/step - loss: 0.0061 - val_loss: 0.0050\n",
      "Epoch 66/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0052 - val_loss: 0.0047\n",
      "Epoch 67/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0061 - val_loss: 0.0047\n",
      "Epoch 68/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0060 - val_loss: 0.0050\n",
      "Epoch 69/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 110us/step - loss: 0.0061 - val_loss: 0.0087\n",
      "Epoch 70/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0069 - val_loss: 0.0052\n",
      "Epoch 71/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0066 - val_loss: 0.0044\n",
      "Epoch 72/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0070 - val_loss: 0.0060\n",
      "Epoch 73/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0057 - val_loss: 0.0052\n",
      "Epoch 74/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0045\n",
      "Epoch 75/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0063 - val_loss: 0.0062\n",
      "Epoch 76/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0054 - val_loss: 0.0043\n",
      "Epoch 77/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0053 - val_loss: 0.0051\n",
      "Epoch 78/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 79/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0047 - val_loss: 0.0044\n",
      "Epoch 80/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0053 - val_loss: 0.0043\n",
      "Epoch 81/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 82/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 83/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 84/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.006 - 0s 104us/step - loss: 0.0048 - val_loss: 0.0058\n",
      "Epoch 85/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 86/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0053\n",
      "Epoch 87/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0051 - val_loss: 0.0069\n",
      "Epoch 88/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0060 - val_loss: 0.0052\n",
      "Epoch 89/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0061 - val_loss: 0.0068\n",
      "Epoch 90/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0075 - val_loss: 0.0096\n",
      "Epoch 91/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0069 - val_loss: 0.0051\n",
      "Epoch 92/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0048 - val_loss: 0.0061\n",
      "Epoch 93/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0048 - val_loss: 0.0042\n",
      "Epoch 94/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 95/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0044 - val_loss: 0.0049\n",
      "Epoch 96/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0042 - val_loss: 0.0050\n",
      "Epoch 97/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0041 - val_loss: 0.0061\n",
      "Epoch 98/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0049\n",
      "Epoch 99/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0040 - val_loss: 0.0050\n",
      "Epoch 100/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0042 - val_loss: 0.0053\n",
      "Epoch 101/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0041 - val_loss: 0.0048\n",
      "Epoch 102/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0039 - val_loss: 0.0047\n",
      "Epoch 103/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0052\n",
      "Epoch 104/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0055\n",
      "Epoch 105/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0047 - val_loss: 0.0050\n",
      "Epoch 106/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0037 - val_loss: 0.0048\n",
      "Epoch 107/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0037 - val_loss: 0.0047\n",
      "Epoch 108/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0048\n",
      "Epoch 109/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0040 - val_loss: 0.0052\n",
      "Epoch 110/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 111/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0038 - val_loss: 0.0050\n",
      "Epoch 112/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0036 - val_loss: 0.0049\n",
      "Epoch 113/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0036 - val_loss: 0.0049\n",
      "Epoch 114/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 115/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0036 - val_loss: 0.0058\n",
      "Epoch 116/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0037 - val_loss: 0.0049\n",
      "Epoch 117/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0038 - val_loss: 0.0049\n",
      "Epoch 118/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0036 - val_loss: 0.0049\n",
      "Epoch 119/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0035 - val_loss: 0.0052\n",
      "Epoch 120/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0035 - val_loss: 0.0050\n",
      "Epoch 121/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0036 - val_loss: 0.0049\n",
      "Epoch 122/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0036 - val_loss: 0.0049\n",
      "Epoch 123/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0034 - val_loss: 0.0055\n",
      "Epoch 124/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 125/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0034 - val_loss: 0.0046\n",
      "Epoch 126/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0036 - val_loss: 0.0057\n",
      "Epoch 127/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0036 - val_loss: 0.0048\n",
      "Epoch 128/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0038 - val_loss: 0.0049\n",
      "Epoch 129/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0037 - val_loss: 0.0055\n",
      "Epoch 130/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0037 - val_loss: 0.0047\n",
      "Epoch 131/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0036 - val_loss: 0.0049\n",
      "Epoch 132/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0039 - val_loss: 0.0047\n",
      "Epoch 133/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0032 - val_loss: 0.0055\n",
      "Epoch 134/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0037 - val_loss: 0.0047\n",
      "Epoch 135/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0047\n",
      "Epoch 136/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0054\n",
      "Epoch 137/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0043 - val_loss: 0.0066\n",
      "Epoch 138/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0043 - val_loss: 0.0069\n",
      "Epoch 139/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0052 - val_loss: 0.0060\n",
      "Epoch 140/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0041 - val_loss: 0.0048\n",
      "Epoch 141/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0042 - val_loss: 0.0045\n",
      "Epoch 142/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0036 - val_loss: 0.0050\n",
      "Epoch 143/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 144/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0039 - val_loss: 0.0062\n",
      "Epoch 145/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0069 - val_loss: 0.0095\n",
      "Epoch 146/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 107us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 147/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 148/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0043 - val_loss: 0.0051\n",
      "Epoch 149/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 150/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0051\n",
      "Epoch 151/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 152/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0039 - val_loss: 0.0045\n",
      "Epoch 153/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0057\n",
      "Epoch 154/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0047\n",
      "Epoch 155/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0034 - val_loss: 0.0060\n",
      "Epoch 156/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 157/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0033 - val_loss: 0.0050\n",
      "Epoch 158/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0049\n",
      "Epoch 159/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0047\n",
      "Epoch 160/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0034 - val_loss: 0.0051\n",
      "Epoch 161/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0052\n",
      "Epoch 162/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0044 - val_loss: 0.0056\n",
      "Epoch 163/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0035 - val_loss: 0.0047\n",
      "Epoch 164/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0035 - val_loss: 0.0048\n",
      "Epoch 165/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0033 - val_loss: 0.0049\n",
      "Epoch 166/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0031 - val_loss: 0.0044\n",
      "Epoch 167/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0048\n",
      "Epoch 168/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0032 - val_loss: 0.0045\n",
      "Epoch 169/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0035 - val_loss: 0.0050\n",
      "Epoch 170/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0039 - val_loss: 0.0064\n",
      "Epoch 171/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0047\n",
      "Epoch 172/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0035 - val_loss: 0.0053\n",
      "Epoch 173/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0031 - val_loss: 0.0043\n",
      "Epoch 174/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0031 - val_loss: 0.0050\n",
      "Epoch 175/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0032 - val_loss: 0.0046\n",
      "Epoch 176/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0032 - val_loss: 0.0045\n",
      "Epoch 177/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0049\n",
      "Epoch 178/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0034 - val_loss: 0.0051\n",
      "Epoch 179/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0046\n",
      "Epoch 180/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0032 - val_loss: 0.0053\n",
      "Epoch 181/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0031 - val_loss: 0.0045\n",
      "Epoch 182/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0031 - val_loss: 0.0049\n",
      "Epoch 183/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0031 - val_loss: 0.0047\n",
      "Epoch 184/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0047\n",
      "Epoch 185/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0030 - val_loss: 0.0048\n",
      "Epoch 186/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0031 - val_loss: 0.0043\n",
      "Epoch 187/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0031 - val_loss: 0.0047\n",
      "Epoch 188/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0031 - val_loss: 0.0045\n",
      "Epoch 189/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0031 - val_loss: 0.0046\n",
      "Epoch 190/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0043\n",
      "Epoch 191/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0030 - val_loss: 0.0061\n",
      "Epoch 192/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 193/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0032 - val_loss: 0.0046\n",
      "Epoch 194/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0045\n",
      "Epoch 195/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 196/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0030 - val_loss: 0.0046\n",
      "Epoch 197/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0033 - val_loss: 0.0052\n",
      "Epoch 198/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 199/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0036 - val_loss: 0.0043\n",
      "Epoch 200/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0031 - val_loss: 0.0049\n",
      "Epoch 201/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0045\n",
      "Epoch 202/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0030 - val_loss: 0.0043\n",
      "Epoch 203/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0050\n",
      "Epoch 204/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0044\n",
      "Epoch 205/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0030 - val_loss: 0.0051\n",
      "Epoch 206/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0033 - val_loss: 0.0045\n",
      "Epoch 207/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0034 - val_loss: 0.0049\n",
      "Epoch 208/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0037 - val_loss: 0.0060\n",
      "Epoch 209/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0037 - val_loss: 0.0043\n",
      "Epoch 210/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0046\n",
      "Epoch 211/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0032 - val_loss: 0.0051\n",
      "Epoch 212/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 213/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0046\n",
      "Epoch 214/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0032 - val_loss: 0.0048\n",
      "Epoch 215/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0029 - val_loss: 0.0044\n",
      "Epoch 216/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0044\n",
      "Epoch 217/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0033 - val_loss: 0.0054\n",
      "Epoch 218/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0031 - val_loss: 0.0046\n",
      "Epoch 219/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0030 - val_loss: 0.0050\n",
      "Epoch 220/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0029 - val_loss: 0.0044\n",
      "Epoch 221/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0029 - val_loss: 0.0050\n",
      "Epoch 222/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0029 - val_loss: 0.0046\n",
      "Epoch 223/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0054\n",
      "Epoch 224/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 225/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0032 - val_loss: 0.0047\n",
      "Epoch 226/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0034 - val_loss: 0.0052\n",
      "Epoch 227/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0031 - val_loss: 0.0045\n",
      "Epoch 228/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0029 - val_loss: 0.0044\n",
      "Epoch 229/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0031 - val_loss: 0.0055\n",
      "Epoch 230/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 231/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0031 - val_loss: 0.0044\n",
      "Epoch 232/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0049\n",
      "Epoch 233/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0030 - val_loss: 0.0043\n",
      "Epoch 234/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0032 - val_loss: 0.0045\n",
      "Epoch 235/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0033 - val_loss: 0.0060\n",
      "Epoch 236/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 237/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0032 - val_loss: 0.0064\n",
      "Epoch 238/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0038 - val_loss: 0.0044\n",
      "Epoch 239/1000\n",
      "143/143 [==============================] - 0s 99us/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 240/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0031 - val_loss: 0.0046\n",
      "Epoch 241/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0043\n",
      "Epoch 242/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0044\n",
      "Epoch 243/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 244/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 245/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0046\n",
      "Epoch 246/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 247/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0045\n",
      "Epoch 248/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0030 - val_loss: 0.0045\n",
      "Epoch 249/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0030 - val_loss: 0.0046\n",
      "Epoch 250/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0029 - val_loss: 0.0053\n",
      "Epoch 251/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0031 - val_loss: 0.0044\n",
      "Epoch 252/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0028 - val_loss: 0.0050\n",
      "Epoch 253/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0028 - val_loss: 0.0043\n",
      "Epoch 254/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0029 - val_loss: 0.0047\n",
      "Epoch 255/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0028 - val_loss: 0.0043\n",
      "Epoch 256/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0029 - val_loss: 0.0042\n",
      "Epoch 257/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0051\n",
      "Epoch 258/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 259/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0050\n",
      "Epoch 260/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0032 - val_loss: 0.0045\n",
      "Epoch 261/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0045\n",
      "Epoch 262/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0028 - val_loss: 0.0045\n",
      "Epoch 263/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0027 - val_loss: 0.0045\n",
      "Epoch 264/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0028 - val_loss: 0.0041\n",
      "Epoch 265/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0032 - val_loss: 0.0050\n",
      "Epoch 266/1000\n",
      "143/143 [==============================] - 0s 100us/step - loss: 0.0033 - val_loss: 0.0048\n",
      "Epoch 267/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0031 - val_loss: 0.0044\n",
      "Epoch 268/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 269/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0028 - val_loss: 0.0052\n",
      "Epoch 270/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0031 - val_loss: 0.0040\n",
      "Epoch 271/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0035 - val_loss: 0.0041\n",
      "Epoch 272/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0031 - val_loss: 0.0051\n",
      "Epoch 273/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 274/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0028 - val_loss: 0.0042\n",
      "Epoch 275/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0049\n",
      "Epoch 276/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0029 - val_loss: 0.0042\n",
      "Epoch 277/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0031 - val_loss: 0.0043\n",
      "Epoch 278/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0031 - val_loss: 0.0054\n",
      "Epoch 279/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0029 - val_loss: 0.0041\n",
      "Epoch 280/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0029 - val_loss: 0.0044\n",
      "Epoch 281/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0030 - val_loss: 0.0048\n",
      "Epoch 282/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0048\n",
      "Epoch 283/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0043\n",
      "Epoch 284/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0030 - val_loss: 0.0043\n",
      "Epoch 285/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 286/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0028 - val_loss: 0.0045\n",
      "Epoch 287/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0026 - val_loss: 0.0048\n",
      "Epoch 288/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0043\n",
      "Epoch 289/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0043\n",
      "Epoch 290/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0043\n",
      "Epoch 291/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0044\n",
      "Epoch 292/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0029 - val_loss: 0.0045\n",
      "Epoch 293/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0029 - val_loss: 0.0040\n",
      "Epoch 294/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0041\n",
      "Epoch 295/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0028 - val_loss: 0.0050\n",
      "Epoch 296/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0043\n",
      "Epoch 297/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0047\n",
      "Epoch 298/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0027 - val_loss: 0.0040\n",
      "Epoch 299/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0027 - val_loss: 0.0042\n",
      "Epoch 300/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 110us/step - loss: 0.0028 - val_loss: 0.0041\n",
      "Epoch 301/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0026 - val_loss: 0.0045\n",
      "Epoch 302/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0026 - val_loss: 0.0049\n",
      "Epoch 303/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0035 - val_loss: 0.0061\n",
      "Epoch 304/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0033 - val_loss: 0.0040\n",
      "Epoch 305/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0039\n",
      "Epoch 306/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0049\n",
      "Epoch 307/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0040\n",
      "Epoch 308/1000\n",
      "143/143 [==============================] - 0s 100us/step - loss: 0.0028 - val_loss: 0.0042\n",
      "Epoch 309/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0039\n",
      "Epoch 310/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0042\n",
      "Epoch 311/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0026 - val_loss: 0.0043\n",
      "Epoch 312/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0025 - val_loss: 0.0042\n",
      "Epoch 313/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0043\n",
      "Epoch 314/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0041\n",
      "Epoch 315/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0032 - val_loss: 0.0047\n",
      "Epoch 316/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0032 - val_loss: 0.0051\n",
      "Epoch 317/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0031 - val_loss: 0.0041\n",
      "Epoch 318/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0040\n",
      "Epoch 319/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0041\n",
      "Epoch 320/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0050\n",
      "Epoch 321/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0028 - val_loss: 0.0040\n",
      "Epoch 322/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0028 - val_loss: 0.0040\n",
      "Epoch 323/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0031 - val_loss: 0.0053\n",
      "Epoch 324/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 325/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0034 - val_loss: 0.0041\n",
      "Epoch 326/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0034 - val_loss: 0.0047\n",
      "Epoch 327/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0029 - val_loss: 0.0039\n",
      "Epoch 328/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0027 - val_loss: 0.0040\n",
      "Epoch 329/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0051\n",
      "Epoch 330/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0031 - val_loss: 0.0047\n",
      "Epoch 331/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0070\n",
      "Epoch 332/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0040 - val_loss: 0.0042\n",
      "Epoch 333/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0030 - val_loss: 0.0043\n",
      "Epoch 334/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0033 - val_loss: 0.0043\n",
      "Epoch 335/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0031 - val_loss: 0.0039\n",
      "Epoch 336/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0046\n",
      "Epoch 337/1000\n",
      "143/143 [==============================] - 0s 99us/step - loss: 0.0027 - val_loss: 0.0039\n",
      "Epoch 338/1000\n",
      "143/143 [==============================] - 0s 99us/step - loss: 0.0026 - val_loss: 0.0042\n",
      "Epoch 339/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0026 - val_loss: 0.0041\n",
      "Epoch 340/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0043\n",
      "Epoch 341/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0026 - val_loss: 0.0041\n",
      "Epoch 342/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0049\n",
      "Epoch 343/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0044\n",
      "Epoch 344/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 345/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0030 - val_loss: 0.0055\n",
      "Epoch 346/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0029 - val_loss: 0.0041\n",
      "Epoch 347/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0039\n",
      "Epoch 348/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0044\n",
      "Epoch 349/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0041\n",
      "Epoch 350/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0031 - val_loss: 0.0040\n",
      "Epoch 351/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0027 - val_loss: 0.0048\n",
      "Epoch 352/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0027 - val_loss: 0.0043\n",
      "Epoch 353/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0031 - val_loss: 0.0039\n",
      "Epoch 354/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0034 - val_loss: 0.0059\n",
      "Epoch 355/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0035 - val_loss: 0.0042\n",
      "Epoch 356/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 357/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 358/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0040\n",
      "Epoch 359/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0027 - val_loss: 0.0038\n",
      "Epoch 360/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0029 - val_loss: 0.0054\n",
      "Epoch 361/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0032 - val_loss: 0.0040\n",
      "Epoch 362/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0027 - val_loss: 0.0050\n",
      "Epoch 363/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0027 - val_loss: 0.0042\n",
      "Epoch 364/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0026 - val_loss: 0.0040\n",
      "Epoch 365/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0043\n",
      "Epoch 366/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0027 - val_loss: 0.0040\n",
      "Epoch 367/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0039\n",
      "Epoch 368/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0031 - val_loss: 0.0048\n",
      "Epoch 369/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0029 - val_loss: 0.0039\n",
      "Epoch 370/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0025 - val_loss: 0.0039\n",
      "Epoch 371/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0024 - val_loss: 0.0039\n",
      "Epoch 372/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0024 - val_loss: 0.0043\n",
      "Epoch 373/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0025 - val_loss: 0.0041\n",
      "Epoch 374/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0043\n",
      "Epoch 375/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0025 - val_loss: 0.0039\n",
      "Epoch 376/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0026 - val_loss: 0.0047\n",
      "Epoch 377/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0056\n",
      "Epoch 378/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 379/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0031 - val_loss: 0.0038\n",
      "Epoch 380/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0028 - val_loss: 0.0050\n",
      "Epoch 381/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0037\n",
      "Epoch 382/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0041\n",
      "Epoch 383/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 384/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0040\n",
      "Epoch 385/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0029 - val_loss: 0.0043\n",
      "Epoch 386/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0029 - val_loss: 0.0054\n",
      "Epoch 387/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0029 - val_loss: 0.0040\n",
      "Epoch 388/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0026 - val_loss: 0.0040\n",
      "Epoch 389/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0029 - val_loss: 0.0045\n",
      "Epoch 390/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 391/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0039\n",
      "Epoch 392/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0024 - val_loss: 0.0042\n",
      "Epoch 393/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0039\n",
      "Epoch 394/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 395/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0026 - val_loss: 0.0046\n",
      "Epoch 396/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0040\n",
      "Epoch 397/1000\n",
      "143/143 [==============================] - 0s 100us/step - loss: 0.0026 - val_loss: 0.0050\n",
      "Epoch 398/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0025 - val_loss: 0.0040\n",
      "Epoch 399/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0024 - val_loss: 0.0041\n",
      "Epoch 400/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0023 - val_loss: 0.0038\n",
      "Epoch 401/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0025 - val_loss: 0.0038\n",
      "Epoch 402/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0023 - val_loss: 0.0044\n",
      "Epoch 403/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0024 - val_loss: 0.0040\n",
      "Epoch 404/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0041\n",
      "Epoch 405/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0025 - val_loss: 0.0041\n",
      "Epoch 406/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0026 - val_loss: 0.0040\n",
      "Epoch 407/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0032 - val_loss: 0.0059\n",
      "Epoch 408/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0039\n",
      "Epoch 409/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 410/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0041\n",
      "Epoch 411/1000\n",
      "143/143 [==============================] - 0s 99us/step - loss: 0.0024 - val_loss: 0.0038\n",
      "Epoch 412/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0036\n",
      "Epoch 413/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0037\n",
      "Epoch 414/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0039\n",
      "Epoch 415/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0023 - val_loss: 0.0047\n",
      "Epoch 416/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0024 - val_loss: 0.0038\n",
      "Epoch 417/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0022 - val_loss: 0.0045\n",
      "Epoch 418/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0025 - val_loss: 0.0041\n",
      "Epoch 419/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0027 - val_loss: 0.0042\n",
      "Epoch 420/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0024 - val_loss: 0.0040\n",
      "Epoch 421/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0039\n",
      "Epoch 422/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0039\n",
      "Epoch 423/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0037\n",
      "Epoch 424/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0024 - val_loss: 0.0039\n",
      "Epoch 425/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0024 - val_loss: 0.0042\n",
      "Epoch 426/1000\n",
      "143/143 [==============================] - 0s 99us/step - loss: 0.0024 - val_loss: 0.0038\n",
      "Epoch 427/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0028 - val_loss: 0.0039\n",
      "Epoch 428/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0044\n",
      "Epoch 429/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0026 - val_loss: 0.0039\n",
      "Epoch 430/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0039\n",
      "Epoch 431/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0042\n",
      "Epoch 432/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0022 - val_loss: 0.0039\n",
      "Epoch 433/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0023 - val_loss: 0.0038\n",
      "Epoch 434/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0024 - val_loss: 0.0041\n",
      "Epoch 435/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0038\n",
      "Epoch 436/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0037\n",
      "Epoch 437/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0022 - val_loss: 0.0037\n",
      "Epoch 438/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0040\n",
      "Epoch 439/1000\n",
      "143/143 [==============================] - 0s 99us/step - loss: 0.0023 - val_loss: 0.0035\n",
      "Epoch 440/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0023 - val_loss: 0.0036\n",
      "Epoch 441/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0022 - val_loss: 0.0039\n",
      "Epoch 442/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0023 - val_loss: 0.0041\n",
      "Epoch 443/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0043\n",
      "Epoch 444/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0026 - val_loss: 0.0038\n",
      "Epoch 445/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0023 - val_loss: 0.0039\n",
      "Epoch 446/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0038\n",
      "Epoch 447/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0040\n",
      "Epoch 448/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0022 - val_loss: 0.0040\n",
      "Epoch 449/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0023 - val_loss: 0.0040\n",
      "Epoch 450/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0026 - val_loss: 0.0053\n",
      "Epoch 451/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0037\n",
      "Epoch 452/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0025 - val_loss: 0.0039\n",
      "Epoch 453/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0023 - val_loss: 0.0043\n",
      "Epoch 454/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 109us/step - loss: 0.0024 - val_loss: 0.0039\n",
      "Epoch 455/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0022 - val_loss: 0.0036\n",
      "Epoch 456/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0021 - val_loss: 0.0043\n",
      "Epoch 457/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0038\n",
      "Epoch 458/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 459/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0030 - val_loss: 0.0059\n",
      "Epoch 460/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0031 - val_loss: 0.0041\n",
      "Epoch 461/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 462/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.001 - 0s 107us/step - loss: 0.0025 - val_loss: 0.0039\n",
      "Epoch 463/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0025 - val_loss: 0.0036\n",
      "Epoch 464/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0042\n",
      "Epoch 465/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0022 - val_loss: 0.0040\n",
      "Epoch 466/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0036\n",
      "Epoch 467/1000\n",
      "143/143 [==============================] - 0s 99us/step - loss: 0.0023 - val_loss: 0.0040\n",
      "Epoch 468/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0022 - val_loss: 0.0042\n",
      "Epoch 469/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0021 - val_loss: 0.0042\n",
      "Epoch 470/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0025 - val_loss: 0.0048\n",
      "Epoch 471/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0024 - val_loss: 0.0041\n",
      "Epoch 472/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0045\n",
      "Epoch 473/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0053\n",
      "Epoch 474/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0031 - val_loss: 0.0051\n",
      "Epoch 475/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0036 - val_loss: 0.0054\n",
      "Epoch 476/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 477/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0032 - val_loss: 0.0043\n",
      "Epoch 478/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0029 - val_loss: 0.0038\n",
      "Epoch 479/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 480/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0025 - val_loss: 0.0035\n",
      "Epoch 481/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0034\n",
      "Epoch 482/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0047\n",
      "Epoch 483/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0026 - val_loss: 0.0038\n",
      "Epoch 484/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0022 - val_loss: 0.0039\n",
      "Epoch 485/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0036\n",
      "Epoch 486/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0024 - val_loss: 0.0052\n",
      "Epoch 487/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0027 - val_loss: 0.0041\n",
      "Epoch 488/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0037\n",
      "Epoch 489/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0028 - val_loss: 0.0040\n",
      "Epoch 490/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0024 - val_loss: 0.0039\n",
      "Epoch 491/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0022 - val_loss: 0.0036\n",
      "Epoch 492/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0021 - val_loss: 0.0043\n",
      "Epoch 493/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 494/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0037\n",
      "Epoch 495/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0046\n",
      "Epoch 496/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0037\n",
      "Epoch 497/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0023 - val_loss: 0.0041\n",
      "Epoch 498/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0037\n",
      "Epoch 499/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0022 - val_loss: 0.0036\n",
      "Epoch 500/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0045\n",
      "Epoch 501/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0037\n",
      "Epoch 502/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0038\n",
      "Epoch 503/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0022 - val_loss: 0.0039\n",
      "Epoch 504/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0037\n",
      "Epoch 505/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0022 - val_loss: 0.0043\n",
      "Epoch 506/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0022 - val_loss: 0.0037\n",
      "Epoch 507/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0036\n",
      "Epoch 508/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0025 - val_loss: 0.0036\n",
      "Epoch 509/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0037\n",
      "Epoch 510/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0023 - val_loss: 0.0035\n",
      "Epoch 511/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0026 - val_loss: 0.0037\n",
      "Epoch 512/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0025 - val_loss: 0.0044\n",
      "Epoch 513/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0025 - val_loss: 0.0040\n",
      "Epoch 514/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0022 - val_loss: 0.0034\n",
      "Epoch 515/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0023 - val_loss: 0.0040\n",
      "Epoch 516/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0021 - val_loss: 0.0037\n",
      "Epoch 517/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0022 - val_loss: 0.0036\n",
      "Epoch 518/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Epoch 519/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0020 - val_loss: 0.0038\n",
      "Epoch 520/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0036\n",
      "Epoch 521/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0022 - val_loss: 0.0037\n",
      "Epoch 522/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0038\n",
      "Epoch 523/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0020 - val_loss: 0.0036\n",
      "Epoch 524/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0022 - val_loss: 0.0042\n",
      "Epoch 525/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0033\n",
      "Epoch 526/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0036\n",
      "Epoch 527/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0037\n",
      "Epoch 528/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0037\n",
      "Epoch 529/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0038\n",
      "Epoch 530/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0026 - val_loss: 0.0041\n",
      "Epoch 531/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 104us/step - loss: 0.0022 - val_loss: 0.0039\n",
      "Epoch 532/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0022 - val_loss: 0.0039\n",
      "Epoch 533/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0024 - val_loss: 0.0041\n",
      "Epoch 534/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0036\n",
      "Epoch 535/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0021 - val_loss: 0.0037\n",
      "Epoch 536/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0022 - val_loss: 0.0039\n",
      "Epoch 537/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0032\n",
      "Epoch 538/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0024 - val_loss: 0.0035\n",
      "Epoch 539/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0040\n",
      "Epoch 540/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0050\n",
      "Epoch 541/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0037\n",
      "Epoch 542/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0043\n",
      "Epoch 543/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0030 - val_loss: 0.0043\n",
      "Epoch 544/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0035\n",
      "Epoch 545/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0034\n",
      "Epoch 546/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0019 - val_loss: 0.0039\n",
      "Epoch 547/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0033\n",
      "Epoch 548/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0035\n",
      "Epoch 549/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0019 - val_loss: 0.0036\n",
      "Epoch 550/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0021 - val_loss: 0.0047\n",
      "Epoch 551/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0035\n",
      "Epoch 552/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0038\n",
      "Epoch 553/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0026 - val_loss: 0.0040\n",
      "Epoch 554/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0021 - val_loss: 0.0038\n",
      "Epoch 555/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0022 - val_loss: 0.0034\n",
      "Epoch 556/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0038\n",
      "Epoch 557/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0035\n",
      "Epoch 558/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0036\n",
      "Epoch 559/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0020 - val_loss: 0.0036\n",
      "Epoch 560/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0020 - val_loss: 0.0034\n",
      "Epoch 561/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0047\n",
      "Epoch 562/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0039\n",
      "Epoch 563/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0039\n",
      "Epoch 564/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0047\n",
      "Epoch 565/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 566/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0036\n",
      "Epoch 567/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0038\n",
      "Epoch 568/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0026 - val_loss: 0.0038\n",
      "Epoch 569/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0021 - val_loss: 0.0039\n",
      "Epoch 570/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0021 - val_loss: 0.0035\n",
      "Epoch 571/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0020 - val_loss: 0.0045\n",
      "Epoch 572/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0019 - val_loss: 0.0036\n",
      "Epoch 573/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0024 - val_loss: 0.0041\n",
      "Epoch 574/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0021 - val_loss: 0.0039\n",
      "Epoch 575/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0022 - val_loss: 0.0036\n",
      "Epoch 576/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0035\n",
      "Epoch 577/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 578/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0037\n",
      "Epoch 579/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0040\n",
      "Epoch 580/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0034\n",
      "Epoch 581/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0035\n",
      "Epoch 582/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0019 - val_loss: 0.0037\n",
      "Epoch 583/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0019 - val_loss: 0.0038\n",
      "Epoch 584/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0036\n",
      "Epoch 585/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0034\n",
      "Epoch 586/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 587/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0021 - val_loss: 0.0043\n",
      "Epoch 588/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0033\n",
      "Epoch 589/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0020 - val_loss: 0.0036\n",
      "Epoch 590/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0044\n",
      "Epoch 591/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0038\n",
      "Epoch 592/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0019 - val_loss: 0.0035\n",
      "Epoch 593/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0019 - val_loss: 0.0041\n",
      "Epoch 594/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0020 - val_loss: 0.0038\n",
      "Epoch 595/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0036\n",
      "Epoch 596/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0042\n",
      "Epoch 597/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0038\n",
      "Epoch 598/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0042\n",
      "Epoch 599/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0038\n",
      "Epoch 600/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0038\n",
      "Epoch 601/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0035\n",
      "Epoch 602/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0039\n",
      "Epoch 603/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0037\n",
      "Epoch 604/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0037\n",
      "Epoch 605/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0019 - val_loss: 0.0036\n",
      "Epoch 606/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0041\n",
      "Epoch 607/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0020 - val_loss: 0.0036\n",
      "Epoch 608/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0044\n",
      "Epoch 609/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0036\n",
      "Epoch 610/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0036\n",
      "Epoch 611/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0037\n",
      "Epoch 612/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0022 - val_loss: 0.0040\n",
      "Epoch 613/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 614/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0022 - val_loss: 0.0037\n",
      "Epoch 615/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0042\n",
      "Epoch 616/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0035\n",
      "Epoch 617/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0034\n",
      "Epoch 618/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 619/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0020 - val_loss: 0.0037\n",
      "Epoch 620/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 621/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0034\n",
      "Epoch 622/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0056\n",
      "Epoch 623/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0038\n",
      "Epoch 624/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 625/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0053\n",
      "Epoch 626/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0029 - val_loss: 0.0032\n",
      "Epoch 627/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0035\n",
      "Epoch 628/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0037\n",
      "Epoch 629/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0037\n",
      "Epoch 630/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0034\n",
      "Epoch 631/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0019 - val_loss: 0.0036\n",
      "Epoch 632/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0038\n",
      "Epoch 633/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0018 - val_loss: 0.0036\n",
      "Epoch 634/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0018 - val_loss: 0.0040\n",
      "Epoch 635/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0037\n",
      "Epoch 636/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 637/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0039\n",
      "Epoch 638/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0024 - val_loss: 0.0039\n",
      "Epoch 639/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0046\n",
      "Epoch 640/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Epoch 641/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0026 - val_loss: 0.0047\n",
      "Epoch 642/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0025 - val_loss: 0.0039\n",
      "Epoch 643/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0038\n",
      "Epoch 644/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0044\n",
      "Epoch 645/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0035\n",
      "Epoch 646/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0021 - val_loss: 0.0034\n",
      "Epoch 647/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0037\n",
      "Epoch 648/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0035\n",
      "Epoch 649/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0019 - val_loss: 0.0035\n",
      "Epoch 650/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0039\n",
      "Epoch 651/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0019 - val_loss: 0.0036\n",
      "Epoch 652/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0018 - val_loss: 0.0037\n",
      "Epoch 653/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 654/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0037\n",
      "Epoch 655/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 656/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0019 - val_loss: 0.0038\n",
      "Epoch 657/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0034\n",
      "Epoch 658/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0035\n",
      "Epoch 659/1000\n",
      "143/143 [==============================] - 0s 100us/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 660/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0038\n",
      "Epoch 661/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0018 - val_loss: 0.0038\n",
      "Epoch 662/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0037\n",
      "Epoch 663/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0040\n",
      "Epoch 664/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0035\n",
      "Epoch 665/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0018 - val_loss: 0.0048\n",
      "Epoch 666/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0022 - val_loss: 0.0036\n",
      "Epoch 667/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0019 - val_loss: 0.0037\n",
      "Epoch 668/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0036\n",
      "Epoch 669/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0036\n",
      "Epoch 670/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 671/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 672/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0035\n",
      "Epoch 673/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0037\n",
      "Epoch 674/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0036\n",
      "Epoch 675/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0038\n",
      "Epoch 676/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0042\n",
      "Epoch 677/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0036\n",
      "Epoch 678/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0019 - val_loss: 0.0036\n",
      "Epoch 679/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0020 - val_loss: 0.0049\n",
      "Epoch 680/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0022 - val_loss: 0.0038\n",
      "Epoch 681/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0035\n",
      "Epoch 682/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0035\n",
      "Epoch 683/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0037\n",
      "Epoch 684/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0036\n",
      "Epoch 685/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 106us/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 686/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0019 - val_loss: 0.0038\n",
      "Epoch 687/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0018 - val_loss: 0.0038\n",
      "Epoch 688/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Epoch 689/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 690/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0019 - val_loss: 0.0037\n",
      "Epoch 691/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 692/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0017 - val_loss: 0.0034\n",
      "Epoch 693/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0036\n",
      "Epoch 694/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0018 - val_loss: 0.0040\n",
      "Epoch 695/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0037\n",
      "Epoch 696/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0018 - val_loss: 0.0038\n",
      "Epoch 697/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0018 - val_loss: 0.0036\n",
      "Epoch 698/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 699/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0018 - val_loss: 0.0037\n",
      "Epoch 700/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0036\n",
      "Epoch 701/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0017 - val_loss: 0.0038\n",
      "Epoch 702/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0018 - val_loss: 0.0037\n",
      "Epoch 703/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0036\n",
      "Epoch 704/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0018 - val_loss: 0.0038\n",
      "Epoch 705/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0018 - val_loss: 0.0039\n",
      "Epoch 706/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0020 - val_loss: 0.0060\n",
      "Epoch 707/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0031 - val_loss: 0.0037\n",
      "Epoch 708/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0021 - val_loss: 0.0038\n",
      "Epoch 709/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0022 - val_loss: 0.0038\n",
      "Epoch 710/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0018 - val_loss: 0.0036\n",
      "Epoch 711/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0019 - val_loss: 0.0038\n",
      "Epoch 712/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0020 - val_loss: 0.0046\n",
      "Epoch 713/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0022 - val_loss: 0.0042\n",
      "Epoch 714/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0023 - val_loss: 0.0047\n",
      "Epoch 715/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0045\n",
      "Epoch 716/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0035\n",
      "Epoch 717/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0020 - val_loss: 0.0033\n",
      "Epoch 718/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0019 - val_loss: 0.0038\n",
      "Epoch 719/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0017 - val_loss: 0.0034\n",
      "Epoch 720/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0018 - val_loss: 0.0036\n",
      "Epoch 721/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0022 - val_loss: 0.0044\n",
      "Epoch 722/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0035\n",
      "Epoch 723/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0037\n",
      "Epoch 724/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 725/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0020 - val_loss: 0.0037\n",
      "Epoch 726/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0035\n",
      "Epoch 727/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0019 - val_loss: 0.0039\n",
      "Epoch 728/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Epoch 729/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0019 - val_loss: 0.0035\n",
      "Epoch 730/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0035\n",
      "Epoch 731/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0016 - val_loss: 0.0037\n",
      "Epoch 732/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0036\n",
      "Epoch 733/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0016 - val_loss: 0.0037\n",
      "Epoch 734/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0017 - val_loss: 0.0036\n",
      "Epoch 735/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0017 - val_loss: 0.0036\n",
      "Epoch 736/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0016 - val_loss: 0.0038\n",
      "Epoch 737/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0016 - val_loss: 0.0034\n",
      "Epoch 738/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0019 - val_loss: 0.0034\n",
      "Epoch 739/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 740/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Epoch 741/1000\n",
      "143/143 [==============================] - 0s 99us/step - loss: 0.0023 - val_loss: 0.0039\n",
      "Epoch 742/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0050\n",
      "Epoch 743/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0037\n",
      "Epoch 744/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0019 - val_loss: 0.0039\n",
      "Epoch 745/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0018 - val_loss: 0.0044\n",
      "Epoch 746/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0020 - val_loss: 0.0046\n",
      "Epoch 747/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0041\n",
      "Epoch 748/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 749/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0022 - val_loss: 0.0047\n",
      "Epoch 750/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0035\n",
      "Epoch 751/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 752/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0035\n",
      "Epoch 753/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0035\n",
      "Epoch 754/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0023 - val_loss: 0.0043\n",
      "Epoch 755/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0035\n",
      "Epoch 756/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0018 - val_loss: 0.0037\n",
      "Epoch 757/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0022 - val_loss: 0.0036\n",
      "Epoch 758/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0039\n",
      "Epoch 759/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0042\n",
      "Epoch 760/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0017 - val_loss: 0.0037\n",
      "Epoch 761/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0018 - val_loss: 0.0038\n",
      "Epoch 762/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 113us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 763/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0016 - val_loss: 0.0036\n",
      "Epoch 764/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0019 - val_loss: 0.0036\n",
      "Epoch 765/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 766/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0018 - val_loss: 0.0036\n",
      "Epoch 767/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0016 - val_loss: 0.0040\n",
      "Epoch 768/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0036\n",
      "Epoch 769/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0017 - val_loss: 0.0037\n",
      "Epoch 770/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0017 - val_loss: 0.0038\n",
      "Epoch 771/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0016 - val_loss: 0.0035\n",
      "Epoch 772/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0017 - val_loss: 0.0036\n",
      "Epoch 773/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0018 - val_loss: 0.0045\n",
      "Epoch 774/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0019 - val_loss: 0.0036\n",
      "Epoch 775/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0020 - val_loss: 0.0035\n",
      "Epoch 776/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0020 - val_loss: 0.0053\n",
      "Epoch 777/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0026 - val_loss: 0.0037\n",
      "Epoch 778/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0020 - val_loss: 0.0036\n",
      "Epoch 779/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0019 - val_loss: 0.0041\n",
      "Epoch 780/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0019 - val_loss: 0.0035\n",
      "Epoch 781/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0018 - val_loss: 0.0032\n",
      "Epoch 782/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 783/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0037\n",
      "Epoch 784/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 785/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0016 - val_loss: 0.0035\n",
      "Epoch 786/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0016 - val_loss: 0.0035\n",
      "Epoch 787/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0038\n",
      "Epoch 788/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0016 - val_loss: 0.0037\n",
      "Epoch 789/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0018 - val_loss: 0.0049\n",
      "Epoch 790/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0018 - val_loss: 0.0033\n",
      "Epoch 791/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0018 - val_loss: 0.0035\n",
      "Epoch 792/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0044\n",
      "Epoch 793/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0033\n",
      "Epoch 794/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0015 - val_loss: 0.0035\n",
      "Epoch 795/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0037\n",
      "Epoch 796/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0015 - val_loss: 0.0035\n",
      "Epoch 797/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0018 - val_loss: 0.0037\n",
      "Epoch 798/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0016 - val_loss: 0.0040\n",
      "Epoch 799/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0016 - val_loss: 0.0036\n",
      "Epoch 800/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 801/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0036\n",
      "Epoch 802/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0017 - val_loss: 0.0038\n",
      "Epoch 803/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 804/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0038\n",
      "Epoch 805/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 806/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0034\n",
      "Epoch 807/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0015 - val_loss: 0.0039\n",
      "Epoch 808/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0016 - val_loss: 0.0037\n",
      "Epoch 809/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0015 - val_loss: 0.0037\n",
      "Epoch 810/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0015 - val_loss: 0.0035\n",
      "Epoch 811/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0037\n",
      "Epoch 812/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 813/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0038\n",
      "Epoch 814/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0017 - val_loss: 0.0036\n",
      "Epoch 815/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0016 - val_loss: 0.0034\n",
      "Epoch 816/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 817/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0018 - val_loss: 0.0037\n",
      "Epoch 818/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0018 - val_loss: 0.0036\n",
      "Epoch 819/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Epoch 820/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0022 - val_loss: 0.0049\n",
      "Epoch 821/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0024 - val_loss: 0.0041\n",
      "Epoch 822/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0022 - val_loss: 0.0038\n",
      "Epoch 823/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0023 - val_loss: 0.0056\n",
      "Epoch 824/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0042\n",
      "Epoch 825/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0027 - val_loss: 0.0037\n",
      "Epoch 826/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0038\n",
      "Epoch 827/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0017 - val_loss: 0.0035\n",
      "Epoch 828/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0037\n",
      "Epoch 829/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 830/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0016 - val_loss: 0.0037\n",
      "Epoch 831/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0016 - val_loss: 0.0040\n",
      "Epoch 832/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 833/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 834/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0016 - val_loss: 0.0035\n",
      "Epoch 835/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 836/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0015 - val_loss: 0.0036\n",
      "Epoch 837/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0037\n",
      "Epoch 838/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0017 - val_loss: 0.0038\n",
      "Epoch 839/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0036\n",
      "Epoch 840/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0017 - val_loss: 0.0037\n",
      "Epoch 841/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 842/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0015 - val_loss: 0.0036\n",
      "Epoch 843/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0037\n",
      "Epoch 844/1000\n",
      "143/143 [==============================] - 0s 99us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 845/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0036\n",
      "Epoch 846/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0037\n",
      "Epoch 847/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0019 - val_loss: 0.0037\n",
      "Epoch 848/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 849/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0035\n",
      "Epoch 850/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0016 - val_loss: 0.0035\n",
      "Epoch 851/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 852/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0039\n",
      "Epoch 853/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0038\n",
      "Epoch 854/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 855/1000\n",
      "143/143 [==============================] - 0s 99us/step - loss: 0.0015 - val_loss: 0.0035\n",
      "Epoch 856/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0037\n",
      "Epoch 857/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0016 - val_loss: 0.0037\n",
      "Epoch 858/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 859/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 860/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0022 - val_loss: 0.0043\n",
      "Epoch 861/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0040\n",
      "Epoch 862/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0015 - val_loss: 0.0034\n",
      "Epoch 863/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0036\n",
      "Epoch 864/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 865/1000\n",
      "143/143 [==============================] - 0s 99us/step - loss: 0.0014 - val_loss: 0.0036\n",
      "Epoch 866/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0014 - val_loss: 0.0037\n",
      "Epoch 867/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0014 - val_loss: 0.0037\n",
      "Epoch 868/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0036\n",
      "Epoch 869/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0038\n",
      "Epoch 870/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0017 - val_loss: 0.0038\n",
      "Epoch 871/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 872/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0016 - val_loss: 0.0036\n",
      "Epoch 873/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 874/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0016 - val_loss: 0.0035\n",
      "Epoch 875/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0035\n",
      "Epoch 876/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 877/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0017 - val_loss: 0.0039\n",
      "Epoch 878/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0015 - val_loss: 0.0035\n",
      "Epoch 879/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0015 - val_loss: 0.0039\n",
      "Epoch 880/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0014 - val_loss: 0.0038\n",
      "Epoch 881/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0019 - val_loss: 0.0039\n",
      "Epoch 882/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0016 - val_loss: 0.0049\n",
      "Epoch 883/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0019 - val_loss: 0.0041\n",
      "Epoch 884/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0037\n",
      "Epoch 885/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0035\n",
      "Epoch 886/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 887/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0016 - val_loss: 0.0036\n",
      "Epoch 888/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0037\n",
      "Epoch 889/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0017 - val_loss: 0.0051\n",
      "Epoch 890/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0037\n",
      "Epoch 891/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0035\n",
      "Epoch 892/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0014 - val_loss: 0.0038\n",
      "Epoch 893/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0014 - val_loss: 0.0039\n",
      "Epoch 894/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0037\n",
      "Epoch 895/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 896/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0049\n",
      "Epoch 897/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 898/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 899/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0014 - val_loss: 0.0037\n",
      "Epoch 900/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0015 - val_loss: 0.0039\n",
      "Epoch 901/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.001 - 0s 108us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 902/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 903/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 904/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 905/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0035\n",
      "Epoch 906/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0047\n",
      "Epoch 907/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0040\n",
      "Epoch 908/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0017 - val_loss: 0.0036\n",
      "Epoch 909/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0016 - val_loss: 0.0034\n",
      "Epoch 910/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0019 - val_loss: 0.0052\n",
      "Epoch 911/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0036\n",
      "Epoch 912/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0016 - val_loss: 0.0035\n",
      "Epoch 913/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0039\n",
      "Epoch 914/1000\n",
      "143/143 [==============================] - 0s 100us/step - loss: 0.0013 - val_loss: 0.0037\n",
      "Epoch 915/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 916/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0040\n",
      "Epoch 917/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0037\n",
      "Epoch 918/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0037\n",
      "Epoch 919/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0038\n",
      "Epoch 920/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0038\n",
      "Epoch 921/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 922/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 923/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0037\n",
      "Epoch 924/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0036\n",
      "Epoch 925/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 926/1000\n",
      "143/143 [==============================] - 0s 100us/step - loss: 0.0014 - val_loss: 0.0037\n",
      "Epoch 927/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0013 - val_loss: 0.0039\n",
      "Epoch 928/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0013 - val_loss: 0.0039\n",
      "Epoch 929/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0040\n",
      "Epoch 930/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0013 - val_loss: 0.0039\n",
      "Epoch 931/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0013 - val_loss: 0.0046\n",
      "Epoch 932/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0018 - val_loss: 0.0040\n",
      "Epoch 933/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0013 - val_loss: 0.0047\n",
      "Epoch 934/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0035\n",
      "Epoch 935/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0016 - val_loss: 0.0037\n",
      "Epoch 936/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0014 - val_loss: 0.0037\n",
      "Epoch 937/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0013 - val_loss: 0.0038\n",
      "Epoch 938/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0037\n",
      "Epoch 939/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0013 - val_loss: 0.0040\n",
      "Epoch 940/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0039\n",
      "Epoch 941/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0013 - val_loss: 0.0038\n",
      "Epoch 942/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0038\n",
      "Epoch 943/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 944/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0048\n",
      "Epoch 945/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0020 - val_loss: 0.0038\n",
      "Epoch 946/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0018 - val_loss: 0.0036\n",
      "Epoch 947/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 948/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 949/1000\n",
      "143/143 [==============================] - 0s 100us/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 950/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0042\n",
      "Epoch 951/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 952/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 953/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 954/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0014 - val_loss: 0.0038\n",
      "Epoch 955/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0014 - val_loss: 0.0047\n",
      "Epoch 956/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0038\n",
      "Epoch 957/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0040\n",
      "Epoch 958/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0045\n",
      "Epoch 959/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 960/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0036\n",
      "Epoch 961/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0039\n",
      "Epoch 962/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 963/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 964/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0013 - val_loss: 0.0038\n",
      "Epoch 965/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 966/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 967/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 968/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0039\n",
      "Epoch 969/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0012 - val_loss: 0.0047\n",
      "Epoch 970/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0039\n",
      "Epoch 971/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0014 - val_loss: 0.0038\n",
      "Epoch 972/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0013 - val_loss: 0.0040\n",
      "Epoch 973/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0040\n",
      "Epoch 974/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0014 - val_loss: 0.0036\n",
      "Epoch 975/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 976/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 977/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0013 - val_loss: 0.0039\n",
      "Epoch 978/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0012 - val_loss: 0.0039\n",
      "Epoch 979/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0012 - val_loss: 0.0039\n",
      "Epoch 980/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0039\n",
      "Epoch 981/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0012 - val_loss: 0.0039\n",
      "Epoch 982/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0013 - val_loss: 0.0044\n",
      "Epoch 983/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0015 - val_loss: 0.0045\n",
      "Epoch 984/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 985/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0015 - val_loss: 0.0045\n",
      "Epoch 986/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 987/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0039\n",
      "Epoch 988/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0039\n",
      "Epoch 989/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0015 - val_loss: 0.0037\n",
      "Epoch 990/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0038\n",
      "Epoch 991/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0040\n",
      "Epoch 992/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 993/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 994/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 995/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0017 - val_loss: 0.0039\n",
      "Epoch 996/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0012 - val_loss: 0.0046\n",
      "Epoch 997/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0015 - val_loss: 0.0040\n",
      "Epoch 998/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 999/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 1000/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0013 - val_loss: 0.0038\n",
      "0.004593052435666323\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.60619414,  0.53706574, -0.29817966,  0.9125664 , -0.17468823],\n",
       "        [ 0.7411126 , -0.9988812 , -0.44103047, -0.61917883,  0.43020818],\n",
       "        [ 0.39505866,  0.7254051 ,  0.14011933, -0.48404396,  0.02504235],\n",
       "        [ 0.06455621, -0.74727225, -0.52423483, -0.05501774,  0.3111043 ],\n",
       "        [ 0.00625989, -0.05894499, -0.05519401,  0.0470604 ,  0.07775923],\n",
       "        [-0.06032483, -1.1925793 , -0.6208793 ,  0.5000313 ,  1.0711833 ],\n",
       "        [ 0.54988116, -0.49205956, -0.39470723, -0.7497958 , -0.19201355],\n",
       "        [ 0.17021699,  0.60853815,  0.15311064, -0.10946495, -0.4143899 ],\n",
       "        [ 0.20631644, -0.07015824,  0.21240926,  0.9206695 ,  0.77650505],\n",
       "        [ 0.6470893 ,  0.83835155, -0.63250273, -0.65021753, -1.926586  ],\n",
       "        [ 0.9615244 , -0.45782664,  0.3860102 ,  0.2041019 , -0.7043702 ],\n",
       "        [-1.0853072 , -0.1553475 ,  1.0047957 , -0.9688398 , -0.9482677 ],\n",
       "        [-0.2315692 , -0.4934533 ,  0.37712714, -0.92120093, -0.8564395 ],\n",
       "        [ 0.22940499, -1.2471706 ,  0.52930355,  1.5535725 , -0.05838894],\n",
       "        [ 0.04812943,  0.16896433,  0.8911162 , -0.04809265, -0.0105091 ],\n",
       "        [-0.35200673,  0.22122078, -0.14267913,  0.3114641 , -0.10046463],\n",
       "        [-0.3147997 ,  0.1760498 ,  0.23563601, -0.25424984,  0.4902496 ],\n",
       "        [ 0.33822852,  0.80269456, -0.515444  ,  0.836703  ,  0.20020284],\n",
       "        [ 0.7854695 , -0.17154391,  0.56581587,  0.51787704,  1.8575608 ],\n",
       "        [ 1.0215065 ,  1.0028446 ,  0.3474333 ,  0.772714  , -0.7417181 ],\n",
       "        [-0.11110682, -0.20127735,  0.34989297, -2.075196  ,  0.1055224 ],\n",
       "        [-0.5292529 , -0.24391195,  1.1186907 , -0.28103545, -0.7712789 ]],\n",
       "       dtype=float32),\n",
       " array([-0.01757557,  0.4926751 ,  0.12922077, -0.44315803, -0.28473526],\n",
       "       dtype=float32),\n",
       " array([[ 0.10350978, -0.17046565, -0.0542241 ,  0.00501279,  0.03707804,\n",
       "         -0.3478735 ,  0.09427172, -0.15119742, -0.11822382,  0.03542261],\n",
       "        [ 0.32486242,  0.00218895,  0.02093214,  0.11301617, -0.33076987,\n",
       "         -0.03320821,  0.44562486,  0.6060833 , -0.04471809, -0.1076182 ],\n",
       "        [-0.3416904 ,  0.33935213,  0.08400171, -0.15008555,  0.62205404,\n",
       "         -0.03803008, -0.33172637, -0.4108204 , -0.20405748,  0.24801736],\n",
       "        [-0.05325467,  0.34671187, -0.2652779 , -0.02231333,  0.46856707,\n",
       "         -0.6372364 , -0.03842817, -0.7247575 ,  0.27791217, -0.0903497 ],\n",
       "        [ 0.2604493 , -0.15873791,  0.5286555 ,  0.12378189, -0.79399574,\n",
       "          0.55459446,  0.39061436,  0.6878356 , -0.43393192,  0.04155227]],\n",
       "       dtype=float32),\n",
       " array([ 0.20994079, -0.06932156,  0.1561907 ,  0.15274984, -0.18718979,\n",
       "         0.08125865,  0.25313318,  0.08691924,  0.11822721, -0.20373504],\n",
       "       dtype=float32),\n",
       " array([[-0.01694985],\n",
       "        [-0.00160562],\n",
       "        [-0.01231859],\n",
       "        [ 0.00147461],\n",
       "        [ 0.3087344 ],\n",
       "        [-0.16122761],\n",
       "        [-0.05403107],\n",
       "        [-0.28821415],\n",
       "        [-0.00276311],\n",
       "        [ 0.00314521]], dtype=float32),\n",
       " array([0.02963082], dtype=float32)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_automobile, history_automobile, evaluate_automobile=NN_model_structure_regression_2(X_train_automobile, X_val_automobile, Y_train_automobile, Y_val_automobile, adam2, 32, 1000, x_test_automobile, y_test_automobile)\n",
    "model_automobile.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_automobile.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_automobile_structure2_4th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_43 (Dense)             (None, 5)                 115       \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 15)                90        \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 221\n",
      "Trainable params: 221\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 143 samples, validate on 31 samples\n",
      "Epoch 1/1000\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2139 - val_loss: 0.0798\n",
      "Epoch 2/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0724 - val_loss: 0.0307\n",
      "Epoch 3/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0468 - val_loss: 0.0222\n",
      "Epoch 4/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0357 - val_loss: 0.0183\n",
      "Epoch 5/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0323 - val_loss: 0.0157\n",
      "Epoch 6/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0265 - val_loss: 0.0434\n",
      "Epoch 7/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0339 - val_loss: 0.0149\n",
      "Epoch 8/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0312 - val_loss: 0.0242\n",
      "Epoch 9/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0294 - val_loss: 0.0115\n",
      "Epoch 10/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0249 - val_loss: 0.0129\n",
      "Epoch 11/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0225 - val_loss: 0.0116\n",
      "Epoch 12/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0202 - val_loss: 0.0103\n",
      "Epoch 13/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0196 - val_loss: 0.0093\n",
      "Epoch 14/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0209 - val_loss: 0.0125\n",
      "Epoch 15/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0192 - val_loss: 0.0126\n",
      "Epoch 16/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0192 - val_loss: 0.0088\n",
      "Epoch 17/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0156 - val_loss: 0.0078\n",
      "Epoch 18/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0149 - val_loss: 0.0065\n",
      "Epoch 19/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0138 - val_loss: 0.0059\n",
      "Epoch 20/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0126 - val_loss: 0.0052\n",
      "Epoch 21/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0120 - val_loss: 0.0076\n",
      "Epoch 22/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0124 - val_loss: 0.0064\n",
      "Epoch 23/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0116 - val_loss: 0.0050\n",
      "Epoch 24/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0106 - val_loss: 0.0061\n",
      "Epoch 25/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0103 - val_loss: 0.0060\n",
      "Epoch 26/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0121 - val_loss: 0.0087\n",
      "Epoch 27/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0118 - val_loss: 0.0048\n",
      "Epoch 28/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0101 - val_loss: 0.0047\n",
      "Epoch 29/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0095 - val_loss: 0.0044\n",
      "Epoch 30/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0099 - val_loss: 0.0043\n",
      "Epoch 31/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0091 - val_loss: 0.0050\n",
      "Epoch 32/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0094 - val_loss: 0.0044\n",
      "Epoch 33/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0089 - val_loss: 0.0051\n",
      "Epoch 34/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0097 - val_loss: 0.0089\n",
      "Epoch 35/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0103 - val_loss: 0.0046\n",
      "Epoch 36/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0083 - val_loss: 0.0048\n",
      "Epoch 37/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0085 - val_loss: 0.0050\n",
      "Epoch 38/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0083 - val_loss: 0.0043\n",
      "Epoch 39/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0088 - val_loss: 0.0047\n",
      "Epoch 40/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0088 - val_loss: 0.0078\n",
      "Epoch 41/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0094 - val_loss: 0.0053\n",
      "Epoch 42/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0100 - val_loss: 0.0048\n",
      "Epoch 43/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0090 - val_loss: 0.0062\n",
      "Epoch 44/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0090 - val_loss: 0.0061\n",
      "Epoch 45/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0093 - val_loss: 0.0052\n",
      "Epoch 46/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0089 - val_loss: 0.0062\n",
      "Epoch 47/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0101 - val_loss: 0.0057\n",
      "Epoch 48/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0086 - val_loss: 0.0100\n",
      "Epoch 49/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0097 - val_loss: 0.0069\n",
      "Epoch 50/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0101 - val_loss: 0.0051\n",
      "Epoch 51/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0086 - val_loss: 0.0047\n",
      "Epoch 52/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0082 - val_loss: 0.0044\n",
      "Epoch 53/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0087 - val_loss: 0.0066\n",
      "Epoch 54/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0083 - val_loss: 0.0051\n",
      "Epoch 55/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0082 - val_loss: 0.0055\n",
      "Epoch 56/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0079 - val_loss: 0.0048\n",
      "Epoch 57/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0078 - val_loss: 0.0046\n",
      "Epoch 58/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0075 - val_loss: 0.0047\n",
      "Epoch 59/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0074 - val_loss: 0.0044\n",
      "Epoch 60/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0075 - val_loss: 0.0044\n",
      "Epoch 61/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0074 - val_loss: 0.0044\n",
      "Epoch 62/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0076 - val_loss: 0.0062\n",
      "Epoch 63/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0085 - val_loss: 0.0053\n",
      "Epoch 64/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0083 - val_loss: 0.0068\n",
      "Epoch 65/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0085 - val_loss: 0.0054\n",
      "Epoch 66/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0082 - val_loss: 0.0054\n",
      "Epoch 67/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0083 - val_loss: 0.0046\n",
      "Epoch 68/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0073 - val_loss: 0.0049\n",
      "Epoch 69/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 105us/step - loss: 0.0075 - val_loss: 0.0046\n",
      "Epoch 70/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0072 - val_loss: 0.0055\n",
      "Epoch 71/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0076 - val_loss: 0.0059\n",
      "Epoch 72/1000\n",
      "143/143 [==============================] - 0s 100us/step - loss: 0.0086 - val_loss: 0.0071\n",
      "Epoch 73/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0092 - val_loss: 0.0045\n",
      "Epoch 74/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0079 - val_loss: 0.0047\n",
      "Epoch 75/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0075 - val_loss: 0.0048\n",
      "Epoch 76/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0074 - val_loss: 0.0046\n",
      "Epoch 77/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0071 - val_loss: 0.0046\n",
      "Epoch 78/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0072 - val_loss: 0.0049\n",
      "Epoch 79/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0072 - val_loss: 0.0048\n",
      "Epoch 80/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0073 - val_loss: 0.0046\n",
      "Epoch 81/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0077 - val_loss: 0.0045\n",
      "Epoch 82/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0069 - val_loss: 0.0055\n",
      "Epoch 83/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0076 - val_loss: 0.0053\n",
      "Epoch 84/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0072 - val_loss: 0.0051\n",
      "Epoch 85/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0070 - val_loss: 0.0043\n",
      "Epoch 86/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0072 - val_loss: 0.0049\n",
      "Epoch 87/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0079 - val_loss: 0.0057\n",
      "Epoch 88/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0076 - val_loss: 0.0054\n",
      "Epoch 89/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0078 - val_loss: 0.0062\n",
      "Epoch 90/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0074 - val_loss: 0.0046\n",
      "Epoch 91/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0073 - val_loss: 0.0047\n",
      "Epoch 92/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0074 - val_loss: 0.0050\n",
      "Epoch 93/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0073 - val_loss: 0.0050\n",
      "Epoch 94/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0079 - val_loss: 0.0060\n",
      "Epoch 95/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0086 - val_loss: 0.0052\n",
      "Epoch 96/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0079 - val_loss: 0.0055\n",
      "Epoch 97/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0073 - val_loss: 0.0047\n",
      "Epoch 98/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0075 - val_loss: 0.0059\n",
      "Epoch 99/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0078 - val_loss: 0.0045\n",
      "Epoch 100/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0080 - val_loss: 0.0066\n",
      "Epoch 101/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0074 - val_loss: 0.0051\n",
      "Epoch 102/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0073 - val_loss: 0.0053\n",
      "Epoch 103/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0067 - val_loss: 0.0044\n",
      "Epoch 104/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0067 - val_loss: 0.0051\n",
      "Epoch 105/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0069 - val_loss: 0.0043\n",
      "Epoch 106/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0069 - val_loss: 0.0048\n",
      "Epoch 107/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0070 - val_loss: 0.0046\n",
      "Epoch 108/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0065 - val_loss: 0.0041\n",
      "Epoch 109/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.005 - 0s 98us/step - loss: 0.0066 - val_loss: 0.0048\n",
      "Epoch 110/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0066 - val_loss: 0.0042\n",
      "Epoch 111/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0066 - val_loss: 0.0047\n",
      "Epoch 112/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0065 - val_loss: 0.0047\n",
      "Epoch 113/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0067 - val_loss: 0.0049\n",
      "Epoch 114/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0072 - val_loss: 0.0045\n",
      "Epoch 115/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0068 - val_loss: 0.0047\n",
      "Epoch 116/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0063 - val_loss: 0.0043\n",
      "Epoch 117/1000\n",
      "143/143 [==============================] - 0s 99us/step - loss: 0.0070 - val_loss: 0.0050\n",
      "Epoch 118/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0063 - val_loss: 0.0043\n",
      "Epoch 119/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0066 - val_loss: 0.0046\n",
      "Epoch 120/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0065 - val_loss: 0.0042\n",
      "Epoch 121/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0072 - val_loss: 0.0041\n",
      "Epoch 122/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0064 - val_loss: 0.0046\n",
      "Epoch 123/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0068 - val_loss: 0.0049\n",
      "Epoch 124/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0071 - val_loss: 0.0043\n",
      "Epoch 125/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0067 - val_loss: 0.0048\n",
      "Epoch 126/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0063 - val_loss: 0.0043\n",
      "Epoch 127/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0065 - val_loss: 0.0057\n",
      "Epoch 128/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0067 - val_loss: 0.0047\n",
      "Epoch 129/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0069 - val_loss: 0.0055\n",
      "Epoch 130/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0068 - val_loss: 0.0049\n",
      "Epoch 131/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0069 - val_loss: 0.0048\n",
      "Epoch 132/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0080 - val_loss: 0.0062\n",
      "Epoch 133/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0067 - val_loss: 0.0048\n",
      "Epoch 134/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0069 - val_loss: 0.0051\n",
      "Epoch 135/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0061 - val_loss: 0.0045\n",
      "Epoch 136/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0062 - val_loss: 0.0050\n",
      "Epoch 137/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0062 - val_loss: 0.0042\n",
      "Epoch 138/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0061 - val_loss: 0.0047\n",
      "Epoch 139/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0061 - val_loss: 0.0047\n",
      "Epoch 140/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0064 - val_loss: 0.0058\n",
      "Epoch 141/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0074 - val_loss: 0.0049\n",
      "Epoch 142/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0077 - val_loss: 0.0065\n",
      "Epoch 143/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0071 - val_loss: 0.0041\n",
      "Epoch 144/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0063 - val_loss: 0.0055\n",
      "Epoch 145/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0065 - val_loss: 0.0044\n",
      "Epoch 146/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0065 - val_loss: 0.0054\n",
      "Epoch 147/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0062 - val_loss: 0.0039\n",
      "Epoch 148/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0067 - val_loss: 0.0056\n",
      "Epoch 149/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0067 - val_loss: 0.0044\n",
      "Epoch 150/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0058 - val_loss: 0.0052\n",
      "Epoch 151/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0062 - val_loss: 0.0046\n",
      "Epoch 152/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0060 - val_loss: 0.0045\n",
      "Epoch 153/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0063 - val_loss: 0.0049\n",
      "Epoch 154/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0059 - val_loss: 0.0042\n",
      "Epoch 155/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0059 - val_loss: 0.0048\n",
      "Epoch 156/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0059 - val_loss: 0.0040\n",
      "Epoch 157/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0060 - val_loss: 0.0047\n",
      "Epoch 158/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0059 - val_loss: 0.0044\n",
      "Epoch 159/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0058 - val_loss: 0.0044\n",
      "Epoch 160/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0058 - val_loss: 0.0041\n",
      "Epoch 161/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0057 - val_loss: 0.0042\n",
      "Epoch 162/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0057 - val_loss: 0.0046\n",
      "Epoch 163/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0057 - val_loss: 0.0043\n",
      "Epoch 164/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0059 - val_loss: 0.0048\n",
      "Epoch 165/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0058 - val_loss: 0.0043\n",
      "Epoch 166/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0058 - val_loss: 0.0044\n",
      "Epoch 167/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0057 - val_loss: 0.0044\n",
      "Epoch 168/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 169/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0057 - val_loss: 0.0043\n",
      "Epoch 170/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 171/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0056 - val_loss: 0.0043\n",
      "Epoch 172/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 173/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0059 - val_loss: 0.0046\n",
      "Epoch 174/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0056 - val_loss: 0.0045\n",
      "Epoch 175/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 176/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0058 - val_loss: 0.0048\n",
      "Epoch 177/1000\n",
      "143/143 [==============================] - 0s 100us/step - loss: 0.0058 - val_loss: 0.0049\n",
      "Epoch 178/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0055 - val_loss: 0.0041\n",
      "Epoch 179/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0055 - val_loss: 0.0042\n",
      "Epoch 180/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0057 - val_loss: 0.0047\n",
      "Epoch 181/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0056 - val_loss: 0.0046\n",
      "Epoch 182/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0057 - val_loss: 0.0043\n",
      "Epoch 183/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0054 - val_loss: 0.0053\n",
      "Epoch 184/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0060 - val_loss: 0.0049\n",
      "Epoch 185/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0068 - val_loss: 0.0091\n",
      "Epoch 186/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0083 - val_loss: 0.0052\n",
      "Epoch 187/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0072 - val_loss: 0.0063\n",
      "Epoch 188/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0059 - val_loss: 0.0040\n",
      "Epoch 189/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0060 - val_loss: 0.0046\n",
      "Epoch 190/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0057 - val_loss: 0.0047\n",
      "Epoch 191/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0060 - val_loss: 0.0045\n",
      "Epoch 192/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 193/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0054 - val_loss: 0.0044\n",
      "Epoch 194/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0053 - val_loss: 0.0045\n",
      "Epoch 195/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0044\n",
      "Epoch 196/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0043\n",
      "Epoch 197/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0055 - val_loss: 0.0045\n",
      "Epoch 198/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0056 - val_loss: 0.0043\n",
      "Epoch 199/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0056 - val_loss: 0.0041\n",
      "Epoch 200/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 201/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0040\n",
      "Epoch 202/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0053 - val_loss: 0.0051\n",
      "Epoch 203/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0053 - val_loss: 0.0043\n",
      "Epoch 204/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0055 - val_loss: 0.0044\n",
      "Epoch 205/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0056 - val_loss: 0.0053\n",
      "Epoch 206/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0059 - val_loss: 0.0039\n",
      "Epoch 207/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0057 - val_loss: 0.0043\n",
      "Epoch 208/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0057 - val_loss: 0.0047\n",
      "Epoch 209/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0054 - val_loss: 0.0040\n",
      "Epoch 210/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 211/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0055 - val_loss: 0.0043\n",
      "Epoch 212/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0052 - val_loss: 0.0041\n",
      "Epoch 213/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0052 - val_loss: 0.0043\n",
      "Epoch 214/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0052 - val_loss: 0.0040\n",
      "Epoch 215/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0052 - val_loss: 0.0039\n",
      "Epoch 216/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0054 - val_loss: 0.0039\n",
      "Epoch 217/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 218/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0052 - val_loss: 0.0040\n",
      "Epoch 219/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0054 - val_loss: 0.0054\n",
      "Epoch 220/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0056 - val_loss: 0.0041\n",
      "Epoch 221/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0050 - val_loss: 0.0063\n",
      "Epoch 222/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0059 - val_loss: 0.0052\n",
      "Epoch 223/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 106us/step - loss: 0.0063 - val_loss: 0.0054\n",
      "Epoch 224/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0053 - val_loss: 0.0036\n",
      "Epoch 225/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 226/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0040\n",
      "Epoch 227/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0046\n",
      "Epoch 228/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0050 - val_loss: 0.0042\n",
      "Epoch 229/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0051 - val_loss: 0.0041\n",
      "Epoch 230/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0051\n",
      "Epoch 231/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0051 - val_loss: 0.0041\n",
      "Epoch 232/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 233/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0050 - val_loss: 0.0038\n",
      "Epoch 234/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0051 - val_loss: 0.0041\n",
      "Epoch 235/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0039\n",
      "Epoch 236/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0051 - val_loss: 0.0039\n",
      "Epoch 237/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0044\n",
      "Epoch 238/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0052 - val_loss: 0.0042\n",
      "Epoch 239/1000\n",
      "143/143 [==============================] - 0s 100us/step - loss: 0.0051 - val_loss: 0.0046\n",
      "Epoch 240/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0051 - val_loss: 0.0048\n",
      "Epoch 241/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0055 - val_loss: 0.0041\n",
      "Epoch 242/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0052 - val_loss: 0.0049\n",
      "Epoch 243/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0054 - val_loss: 0.0040\n",
      "Epoch 244/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0051 - val_loss: 0.0046\n",
      "Epoch 245/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 246/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0055 - val_loss: 0.0040\n",
      "Epoch 247/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0054 - val_loss: 0.0049\n",
      "Epoch 248/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0053 - val_loss: 0.0039\n",
      "Epoch 249/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0058 - val_loss: 0.0059\n",
      "Epoch 250/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0055 - val_loss: 0.0043\n",
      "Epoch 251/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 252/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0052 - val_loss: 0.0038\n",
      "Epoch 253/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0040\n",
      "Epoch 254/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0052 - val_loss: 0.0038\n",
      "Epoch 255/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0050 - val_loss: 0.0039\n",
      "Epoch 256/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0049 - val_loss: 0.0039\n",
      "Epoch 257/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 258/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0050 - val_loss: 0.0040\n",
      "Epoch 259/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0047\n",
      "Epoch 260/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0038\n",
      "Epoch 261/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0058 - val_loss: 0.0040\n",
      "Epoch 262/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0060 - val_loss: 0.0060\n",
      "Epoch 263/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0062 - val_loss: 0.0036\n",
      "Epoch 264/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0063 - val_loss: 0.0082\n",
      "Epoch 265/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0066 - val_loss: 0.0052\n",
      "Epoch 266/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0060 - val_loss: 0.0073\n",
      "Epoch 267/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0064 - val_loss: 0.0041\n",
      "Epoch 268/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0054 - val_loss: 0.0052\n",
      "Epoch 269/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0035\n",
      "Epoch 270/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0045\n",
      "Epoch 271/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0039\n",
      "Epoch 272/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0050 - val_loss: 0.0038\n",
      "Epoch 273/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0052 - val_loss: 0.0045\n",
      "Epoch 274/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0049 - val_loss: 0.0038\n",
      "Epoch 275/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 276/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0041\n",
      "Epoch 277/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0055 - val_loss: 0.0045\n",
      "Epoch 278/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0050 - val_loss: 0.0039\n",
      "Epoch 279/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0049 - val_loss: 0.0040\n",
      "Epoch 280/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0048 - val_loss: 0.0039\n",
      "Epoch 281/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0047 - val_loss: 0.0041\n",
      "Epoch 282/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0042\n",
      "Epoch 283/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0048 - val_loss: 0.0040\n",
      "Epoch 284/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0047 - val_loss: 0.0037\n",
      "Epoch 285/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 286/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0051 - val_loss: 0.0039\n",
      "Epoch 287/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0056 - val_loss: 0.0060\n",
      "Epoch 288/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0053 - val_loss: 0.0039\n",
      "Epoch 289/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0050 - val_loss: 0.0059\n",
      "Epoch 290/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0055 - val_loss: 0.0036\n",
      "Epoch 291/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0047 - val_loss: 0.0051\n",
      "Epoch 292/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0052 - val_loss: 0.0037\n",
      "Epoch 293/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0051 - val_loss: 0.0047\n",
      "Epoch 294/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0051 - val_loss: 0.0038\n",
      "Epoch 295/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0047 - val_loss: 0.0043\n",
      "Epoch 296/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0047 - val_loss: 0.0038\n",
      "Epoch 297/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0046 - val_loss: 0.0041\n",
      "Epoch 298/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0047 - val_loss: 0.0036\n",
      "Epoch 299/1000\n",
      "143/143 [==============================] - 0s 99us/step - loss: 0.0047 - val_loss: 0.0036\n",
      "Epoch 300/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0044\n",
      "Epoch 301/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0037\n",
      "Epoch 302/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 303/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0048 - val_loss: 0.0040\n",
      "Epoch 304/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0045\n",
      "Epoch 305/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0043\n",
      "Epoch 306/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0043\n",
      "Epoch 307/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0045 - val_loss: 0.0038\n",
      "Epoch 308/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0040\n",
      "Epoch 309/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0047 - val_loss: 0.0043\n",
      "Epoch 310/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0048 - val_loss: 0.0040\n",
      "Epoch 311/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0046 - val_loss: 0.0042\n",
      "Epoch 312/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0041\n",
      "Epoch 313/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0046 - val_loss: 0.0039\n",
      "Epoch 314/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0046 - val_loss: 0.0055\n",
      "Epoch 315/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0060 - val_loss: 0.0047\n",
      "Epoch 316/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0055 - val_loss: 0.0065\n",
      "Epoch 317/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0061 - val_loss: 0.0040\n",
      "Epoch 318/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0064\n",
      "Epoch 319/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0049 - val_loss: 0.0040\n",
      "Epoch 320/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0058\n",
      "Epoch 321/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0039\n",
      "Epoch 322/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0047 - val_loss: 0.0050\n",
      "Epoch 323/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0047 - val_loss: 0.0036\n",
      "Epoch 324/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0051 - val_loss: 0.0038\n",
      "Epoch 325/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0055 - val_loss: 0.0041\n",
      "Epoch 326/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0049 - val_loss: 0.0037\n",
      "Epoch 327/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0052 - val_loss: 0.0044\n",
      "Epoch 328/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0037\n",
      "Epoch 329/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0046 - val_loss: 0.0041\n",
      "Epoch 330/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0038\n",
      "Epoch 331/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0038\n",
      "Epoch 332/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 333/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0038\n",
      "Epoch 334/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0048 - val_loss: 0.0043\n",
      "Epoch 335/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0036\n",
      "Epoch 336/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0039\n",
      "Epoch 337/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0041\n",
      "Epoch 338/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0038\n",
      "Epoch 339/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 340/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0048 - val_loss: 0.0036\n",
      "Epoch 341/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0048 - val_loss: 0.0055\n",
      "Epoch 342/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0056 - val_loss: 0.0042\n",
      "Epoch 343/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0060 - val_loss: 0.0053\n",
      "Epoch 344/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0048 - val_loss: 0.0037\n",
      "Epoch 345/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 346/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0047 - val_loss: 0.0035\n",
      "Epoch 347/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0048 - val_loss: 0.0040\n",
      "Epoch 348/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0048 - val_loss: 0.0038\n",
      "Epoch 349/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0036\n",
      "Epoch 350/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 351/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0048 - val_loss: 0.0037\n",
      "Epoch 352/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0038\n",
      "Epoch 353/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0051 - val_loss: 0.0048\n",
      "Epoch 354/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0054 - val_loss: 0.0041\n",
      "Epoch 355/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0053 - val_loss: 0.0040\n",
      "Epoch 356/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0048 - val_loss: 0.0045\n",
      "Epoch 357/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0049 - val_loss: 0.0040\n",
      "Epoch 358/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0044 - val_loss: 0.0038\n",
      "Epoch 359/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0039\n",
      "Epoch 360/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0045 - val_loss: 0.0036\n",
      "Epoch 361/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0043\n",
      "Epoch 362/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0044 - val_loss: 0.0038\n",
      "Epoch 363/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0044 - val_loss: 0.0039\n",
      "Epoch 364/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0038\n",
      "Epoch 365/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0036\n",
      "Epoch 366/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0051 - val_loss: 0.0043\n",
      "Epoch 367/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0041\n",
      "Epoch 368/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0048 - val_loss: 0.0041\n",
      "Epoch 369/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 370/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0047 - val_loss: 0.0038\n",
      "Epoch 371/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 372/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0037\n",
      "Epoch 373/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0050 - val_loss: 0.0066\n",
      "Epoch 374/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0070 - val_loss: 0.0054\n",
      "Epoch 375/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 376/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0068 - val_loss: 0.0041\n",
      "Epoch 377/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 98us/step - loss: 0.0053 - val_loss: 0.0059\n",
      "Epoch 378/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0048 - val_loss: 0.0036\n",
      "Epoch 379/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0057 - val_loss: 0.0051\n",
      "Epoch 380/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0034\n",
      "Epoch 381/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0052 - val_loss: 0.0048\n",
      "Epoch 382/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0037\n",
      "Epoch 383/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0045 - val_loss: 0.0038\n",
      "Epoch 384/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0046 - val_loss: 0.0037\n",
      "Epoch 385/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0044 - val_loss: 0.0040\n",
      "Epoch 386/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0056 - val_loss: 0.0037\n",
      "Epoch 387/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0041\n",
      "Epoch 388/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0047 - val_loss: 0.0035\n",
      "Epoch 389/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0048 - val_loss: 0.0039\n",
      "Epoch 390/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0038\n",
      "Epoch 391/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0039\n",
      "Epoch 392/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0044 - val_loss: 0.0039\n",
      "Epoch 393/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0037\n",
      "Epoch 394/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0061 - val_loss: 0.0057\n",
      "Epoch 395/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0064 - val_loss: 0.0043\n",
      "Epoch 396/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0062 - val_loss: 0.0047\n",
      "Epoch 397/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0054 - val_loss: 0.0037\n",
      "Epoch 398/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0047 - val_loss: 0.0038\n",
      "Epoch 399/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0041\n",
      "Epoch 400/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0046 - val_loss: 0.0039\n",
      "Epoch 401/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0038\n",
      "Epoch 402/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0044 - val_loss: 0.0034\n",
      "Epoch 403/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 404/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0036\n",
      "Epoch 405/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0038\n",
      "Epoch 406/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0036\n",
      "Epoch 407/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0044 - val_loss: 0.0038\n",
      "Epoch 408/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0044 - val_loss: 0.0041\n",
      "Epoch 409/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0036\n",
      "Epoch 410/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0044 - val_loss: 0.0041\n",
      "Epoch 411/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0045 - val_loss: 0.0040\n",
      "Epoch 412/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0044 - val_loss: 0.0036\n",
      "Epoch 413/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0044 - val_loss: 0.0042\n",
      "Epoch 414/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0039\n",
      "Epoch 415/1000\n",
      "143/143 [==============================] - 0s 99us/step - loss: 0.0043 - val_loss: 0.0037\n",
      "Epoch 416/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0042 - val_loss: 0.0038\n",
      "Epoch 417/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0043 - val_loss: 0.0037\n",
      "Epoch 418/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0043 - val_loss: 0.0037\n",
      "Epoch 419/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0038\n",
      "Epoch 420/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0037\n",
      "Epoch 421/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 422/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0044 - val_loss: 0.0036\n",
      "Epoch 423/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0050\n",
      "Epoch 424/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0045 - val_loss: 0.0036\n",
      "Epoch 425/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0046 - val_loss: 0.0037\n",
      "Epoch 426/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0044 - val_loss: 0.0036\n",
      "Epoch 427/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0044 - val_loss: 0.0040\n",
      "Epoch 428/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0047 - val_loss: 0.0035\n",
      "Epoch 429/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0043 - val_loss: 0.0045\n",
      "Epoch 430/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 431/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 432/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0035\n",
      "Epoch 433/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 434/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0043 - val_loss: 0.0036\n",
      "Epoch 435/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 436/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0036\n",
      "Epoch 437/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 438/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0044 - val_loss: 0.0035\n",
      "Epoch 439/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0046 - val_loss: 0.0041\n",
      "Epoch 440/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0042 - val_loss: 0.0038\n",
      "Epoch 441/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0045\n",
      "Epoch 442/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0042 - val_loss: 0.0038\n",
      "Epoch 443/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0040\n",
      "Epoch 444/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0041 - val_loss: 0.0033\n",
      "Epoch 445/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 446/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0037\n",
      "Epoch 447/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 448/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0039\n",
      "Epoch 449/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0045 - val_loss: 0.0056\n",
      "Epoch 450/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0050 - val_loss: 0.0036\n",
      "Epoch 451/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0045 - val_loss: 0.0042\n",
      "Epoch 452/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0047 - val_loss: 0.0042\n",
      "Epoch 453/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0047 - val_loss: 0.0034\n",
      "Epoch 454/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 108us/step - loss: 0.0047 - val_loss: 0.0050\n",
      "Epoch 455/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0043 - val_loss: 0.0033\n",
      "Epoch 456/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0040\n",
      "Epoch 457/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0041 - val_loss: 0.0035\n",
      "Epoch 458/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0044 - val_loss: 0.0038\n",
      "Epoch 459/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0041\n",
      "Epoch 460/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0044 - val_loss: 0.0033\n",
      "Epoch 461/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0042\n",
      "Epoch 462/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0042 - val_loss: 0.0038\n",
      "Epoch 463/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0045 - val_loss: 0.0059\n",
      "Epoch 464/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0033\n",
      "Epoch 465/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0046 - val_loss: 0.0061\n",
      "Epoch 466/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0049 - val_loss: 0.0042\n",
      "Epoch 467/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0053 - val_loss: 0.0059\n",
      "Epoch 468/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0048 - val_loss: 0.0035\n",
      "Epoch 469/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0040 - val_loss: 0.0059\n",
      "Epoch 470/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0047 - val_loss: 0.0037\n",
      "Epoch 471/1000\n",
      "143/143 [==============================] - 0s 100us/step - loss: 0.0042 - val_loss: 0.0048\n",
      "Epoch 472/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0040 - val_loss: 0.0034\n",
      "Epoch 473/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 474/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0042 - val_loss: 0.0034\n",
      "Epoch 475/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 476/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0044 - val_loss: 0.0037\n",
      "Epoch 477/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 478/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 479/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0035\n",
      "Epoch 480/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 481/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0043 - val_loss: 0.0034\n",
      "Epoch 482/1000\n",
      "143/143 [==============================] - 0s 99us/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 483/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0038 - val_loss: 0.0033\n",
      "Epoch 484/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0038\n",
      "Epoch 485/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 486/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 487/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 488/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0040 - val_loss: 0.0037\n",
      "Epoch 489/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 490/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 491/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0040 - val_loss: 0.0049\n",
      "Epoch 492/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0044 - val_loss: 0.0038\n",
      "Epoch 493/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 494/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0038 - val_loss: 0.0031\n",
      "Epoch 495/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0035\n",
      "Epoch 496/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0040 - val_loss: 0.0051\n",
      "Epoch 497/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0042 - val_loss: 0.0038\n",
      "Epoch 498/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0047 - val_loss: 0.0056\n",
      "Epoch 499/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 500/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 501/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0041 - val_loss: 0.0038\n",
      "Epoch 502/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0036\n",
      "Epoch 503/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 504/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0043 - val_loss: 0.0031\n",
      "Epoch 505/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 506/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 507/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0040 - val_loss: 0.0037\n",
      "Epoch 508/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0032\n",
      "Epoch 509/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0043 - val_loss: 0.0033\n",
      "Epoch 510/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0039 - val_loss: 0.0047\n",
      "Epoch 511/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 512/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0039 - val_loss: 0.0045\n",
      "Epoch 513/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0038 - val_loss: 0.0032\n",
      "Epoch 514/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0038 - val_loss: 0.0037\n",
      "Epoch 515/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 516/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0037 - val_loss: 0.0034\n",
      "Epoch 517/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0030\n",
      "Epoch 518/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0040 - val_loss: 0.0049\n",
      "Epoch 519/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0043 - val_loss: 0.0037\n",
      "Epoch 520/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0044 - val_loss: 0.0037\n",
      "Epoch 521/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 522/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0033\n",
      "Epoch 523/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 524/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 525/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0036 - val_loss: 0.0033\n",
      "Epoch 526/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0036 - val_loss: 0.0035\n",
      "Epoch 527/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0035 - val_loss: 0.0041\n",
      "Epoch 528/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0037 - val_loss: 0.0040\n",
      "Epoch 529/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0037 - val_loss: 0.0033\n",
      "Epoch 530/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0039 - val_loss: 0.0045\n",
      "Epoch 531/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 532/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0038\n",
      "Epoch 533/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 534/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0039 - val_loss: 0.0031\n",
      "Epoch 535/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0039 - val_loss: 0.0035\n",
      "Epoch 536/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0062\n",
      "Epoch 537/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0030\n",
      "Epoch 538/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0040\n",
      "Epoch 539/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 540/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 541/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 542/1000\n",
      "143/143 [==============================] - 0s 140us/step - loss: 0.0033 - val_loss: 0.0040\n",
      "Epoch 543/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0036 - val_loss: 0.0032\n",
      "Epoch 544/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 545/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 546/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0036 - val_loss: 0.0031\n",
      "Epoch 547/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0046 - val_loss: 0.0060\n",
      "Epoch 548/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0030\n",
      "Epoch 549/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0037 - val_loss: 0.0033\n",
      "Epoch 550/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0038 - val_loss: 0.0050\n",
      "Epoch 551/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0038\n",
      "Epoch 552/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0045 - val_loss: 0.0058\n",
      "Epoch 553/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0042 - val_loss: 0.0028\n",
      "Epoch 554/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 555/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0034 - val_loss: 0.0031\n",
      "Epoch 556/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0041\n",
      "Epoch 557/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 558/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 559/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 560/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 561/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0038 - val_loss: 0.0052\n",
      "Epoch 562/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0031\n",
      "Epoch 563/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0032 - val_loss: 0.0041\n",
      "Epoch 564/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0032 - val_loss: 0.0031\n",
      "Epoch 565/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 566/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0032 - val_loss: 0.0030\n",
      "Epoch 567/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 568/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0034 - val_loss: 0.0031\n",
      "Epoch 569/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0037 - val_loss: 0.0058\n",
      "Epoch 570/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0040 - val_loss: 0.0030\n",
      "Epoch 571/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0033 - val_loss: 0.0039\n",
      "Epoch 572/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 573/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0030\n",
      "Epoch 574/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0030 - val_loss: 0.0048\n",
      "Epoch 575/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0039 - val_loss: 0.0033\n",
      "Epoch 576/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 577/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0031 - val_loss: 0.0037\n",
      "Epoch 578/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 579/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0030\n",
      "Epoch 580/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0031 - val_loss: 0.0036\n",
      "Epoch 581/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0030\n",
      "Epoch 582/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0030 - val_loss: 0.0039\n",
      "Epoch 583/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0032 - val_loss: 0.0032\n",
      "Epoch 584/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0031 - val_loss: 0.0027\n",
      "Epoch 585/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0047\n",
      "Epoch 586/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0033\n",
      "Epoch 587/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0027\n",
      "Epoch 588/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0032 - val_loss: 0.0035\n",
      "Epoch 589/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0034\n",
      "Epoch 590/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0031 - val_loss: 0.0030\n",
      "Epoch 591/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0036 - val_loss: 0.0032\n",
      "Epoch 592/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 593/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0033 - val_loss: 0.0027\n",
      "Epoch 594/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0032\n",
      "Epoch 595/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0029 - val_loss: 0.0032\n",
      "Epoch 596/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0032 - val_loss: 0.0028\n",
      "Epoch 597/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 598/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0040\n",
      "Epoch 599/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0035 - val_loss: 0.0026\n",
      "Epoch 600/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0032\n",
      "Epoch 601/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0048\n",
      "Epoch 602/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0030\n",
      "Epoch 603/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0040\n",
      "Epoch 604/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0032\n",
      "Epoch 605/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0032 - val_loss: 0.0030\n",
      "Epoch 606/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0035 - val_loss: 0.0055\n",
      "Epoch 607/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 608/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 103us/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 609/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 610/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0031 - val_loss: 0.0030\n",
      "Epoch 611/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 612/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 613/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0038\n",
      "Epoch 614/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 615/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0028 - val_loss: 0.0033\n",
      "Epoch 616/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 617/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0032\n",
      "Epoch 618/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 619/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0045\n",
      "Epoch 620/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 621/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0029 - val_loss: 0.0041\n",
      "Epoch 622/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 623/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0033\n",
      "Epoch 624/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0032 - val_loss: 0.0045\n",
      "Epoch 625/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 626/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0026 - val_loss: 0.0040\n",
      "Epoch 627/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 628/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 629/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 630/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Epoch 631/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 632/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0026 - val_loss: 0.0044\n",
      "Epoch 633/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 634/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 635/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 636/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 637/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 638/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0048\n",
      "Epoch 639/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 640/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0060\n",
      "Epoch 641/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 642/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 643/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0027 - val_loss: 0.0039\n",
      "Epoch 644/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 645/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 646/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0040\n",
      "Epoch 647/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0027 - val_loss: 0.0031\n",
      "Epoch 648/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0025 - val_loss: 0.0035\n",
      "Epoch 649/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 650/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 651/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0033\n",
      "Epoch 652/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 653/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 654/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0025 - val_loss: 0.0034\n",
      "Epoch 655/1000\n",
      "143/143 [==============================] - 0s 100us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 656/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 657/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 658/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0024 - val_loss: 0.0035\n",
      "Epoch 659/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0032\n",
      "Epoch 660/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 661/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 662/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 663/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0039\n",
      "Epoch 664/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 665/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 666/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 667/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0051\n",
      "Epoch 668/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0027\n",
      "Epoch 669/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 670/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0024 - val_loss: 0.0034\n",
      "Epoch 671/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0035\n",
      "Epoch 672/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 673/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0024 - val_loss: 0.0044\n",
      "Epoch 674/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 675/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 676/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0027 - val_loss: 0.0037\n",
      "Epoch 677/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0022 - val_loss: 0.0029\n",
      "Epoch 678/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0022 - val_loss: 0.0033\n",
      "Epoch 679/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0031\n",
      "Epoch 680/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 681/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 682/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0039\n",
      "Epoch 683/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 684/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 685/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 108us/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 686/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0022 - val_loss: 0.0029\n",
      "Epoch 687/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0022 - val_loss: 0.0029\n",
      "Epoch 688/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0022 - val_loss: 0.0048\n",
      "Epoch 689/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 690/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0022 - val_loss: 0.0035\n",
      "Epoch 691/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0022 - val_loss: 0.0029\n",
      "Epoch 692/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0021 - val_loss: 0.0032\n",
      "Epoch 693/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 694/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0040 - val_loss: 0.0028\n",
      "Epoch 695/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0043 - val_loss: 0.0042\n",
      "Epoch 696/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 697/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0037\n",
      "Epoch 698/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 699/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0021 - val_loss: 0.0041\n",
      "Epoch 700/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 701/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0020 - val_loss: 0.0036\n",
      "Epoch 702/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 703/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 704/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0033 - val_loss: 0.0041\n",
      "Epoch 705/1000\n",
      "143/143 [==============================] - 0s 128us/step - loss: 0.0029 - val_loss: 0.0056\n",
      "Epoch 706/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0034 - val_loss: 0.0029\n",
      "Epoch 707/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0026 - val_loss: 0.0034\n",
      "Epoch 708/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0029 - val_loss: 0.0058\n",
      "Epoch 709/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0028\n",
      "Epoch 710/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 711/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0028 - val_loss: 0.0040\n",
      "Epoch 712/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 713/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0024 - val_loss: 0.0033\n",
      "Epoch 714/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0024 - val_loss: 0.0048\n",
      "Epoch 715/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 716/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0020 - val_loss: 0.0037\n",
      "Epoch 717/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0022 - val_loss: 0.0032\n",
      "Epoch 718/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 719/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0052\n",
      "Epoch 720/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 721/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0021 - val_loss: 0.0034\n",
      "Epoch 722/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0037\n",
      "Epoch 723/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 724/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0020 - val_loss: 0.0032\n",
      "Epoch 725/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0020 - val_loss: 0.0030\n",
      "Epoch 726/1000\n",
      "143/143 [==============================] - 0s 100us/step - loss: 0.0020 - val_loss: 0.0049\n",
      "Epoch 727/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 728/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0031\n",
      "Epoch 729/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0036\n",
      "Epoch 730/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0032\n",
      "Epoch 731/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 732/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0020 - val_loss: 0.0031\n",
      "Epoch 733/1000\n",
      "143/143 [==============================] - 0s 130us/step - loss: 0.0019 - val_loss: 0.0038\n",
      "Epoch 734/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 735/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 736/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0038\n",
      "Epoch 737/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0029\n",
      "Epoch 738/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0031\n",
      "Epoch 739/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0019 - val_loss: 0.0033\n",
      "Epoch 740/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 741/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 742/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 743/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0031\n",
      "Epoch 744/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 745/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 746/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 747/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 748/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0031\n",
      "Epoch 749/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 750/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0020 - val_loss: 0.0030\n",
      "Epoch 751/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 752/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0035\n",
      "Epoch 753/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 754/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0020 - val_loss: 0.0028\n",
      "Epoch 755/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0044\n",
      "Epoch 756/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0037\n",
      "Epoch 757/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 758/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 759/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0039\n",
      "Epoch 760/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 761/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0018 - val_loss: 0.0040\n",
      "Epoch 762/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0033\n",
      "Epoch 763/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 764/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 765/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0020 - val_loss: 0.0030\n",
      "Epoch 766/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0018 - val_loss: 0.0030\n",
      "Epoch 767/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 768/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0020 - val_loss: 0.0041\n",
      "Epoch 769/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0034\n",
      "Epoch 770/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0031\n",
      "Epoch 771/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 772/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 773/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 774/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0019 - val_loss: 0.0035\n",
      "Epoch 775/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0017 - val_loss: 0.0032\n",
      "Epoch 776/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0029\n",
      "Epoch 777/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 778/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0022 - val_loss: 0.0031\n",
      "Epoch 779/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0031\n",
      "Epoch 780/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 781/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0021 - val_loss: 0.0039\n",
      "Epoch 782/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 783/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 784/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0022 - val_loss: 0.0037\n",
      "Epoch 785/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0033\n",
      "Epoch 786/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0019 - val_loss: 0.0032\n",
      "Epoch 787/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0030\n",
      "Epoch 788/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0038\n",
      "Epoch 789/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0018 - val_loss: 0.0033\n",
      "Epoch 790/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 791/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0017 - val_loss: 0.0040\n",
      "Epoch 792/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0038\n",
      "Epoch 793/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0034\n",
      "Epoch 794/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0031\n",
      "Epoch 795/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0019 - val_loss: 0.0027\n",
      "Epoch 796/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0036\n",
      "Epoch 797/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0018 - val_loss: 0.0031\n",
      "Epoch 798/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0035\n",
      "Epoch 799/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0018 - val_loss: 0.0027\n",
      "Epoch 800/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0018 - val_loss: 0.0031\n",
      "Epoch 801/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0028\n",
      "Epoch 802/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 803/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0033\n",
      "Epoch 804/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0039\n",
      "Epoch 805/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 806/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 807/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0039\n",
      "Epoch 808/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0020 - val_loss: 0.0048\n",
      "Epoch 809/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 810/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0018 - val_loss: 0.0033\n",
      "Epoch 811/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0021 - val_loss: 0.0038\n",
      "Epoch 812/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0032\n",
      "Epoch 813/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0017 - val_loss: 0.0058\n",
      "Epoch 814/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 815/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 816/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0030\n",
      "Epoch 817/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 818/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0055\n",
      "Epoch 819/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 820/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 821/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0031\n",
      "Epoch 822/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0036\n",
      "Epoch 823/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 824/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0038\n",
      "Epoch 825/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0017 - val_loss: 0.0028\n",
      "Epoch 826/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 827/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0035\n",
      "Epoch 828/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0020 - val_loss: 0.0034\n",
      "Epoch 829/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0018 - val_loss: 0.0039\n",
      "Epoch 830/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 831/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 832/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0019 - val_loss: 0.0049\n",
      "Epoch 833/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 834/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 835/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 836/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0017 - val_loss: 0.0027\n",
      "Epoch 837/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 838/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0048\n",
      "Epoch 839/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 104us/step - loss: 0.0018 - val_loss: 0.0031\n",
      "Epoch 840/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 841/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0040\n",
      "Epoch 842/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0019 - val_loss: 0.0034\n",
      "Epoch 843/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0016 - val_loss: 0.0030\n",
      "Epoch 844/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0036\n",
      "Epoch 845/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0035\n",
      "Epoch 846/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0041\n",
      "Epoch 847/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0018 - val_loss: 0.0029\n",
      "Epoch 848/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0016 - val_loss: 0.0033\n",
      "Epoch 849/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0016 - val_loss: 0.0027\n",
      "Epoch 850/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0031\n",
      "Epoch 851/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0015 - val_loss: 0.0029\n",
      "Epoch 852/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0016 - val_loss: 0.0036\n",
      "Epoch 853/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0027\n",
      "Epoch 854/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0017 - val_loss: 0.0030\n",
      "Epoch 855/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0018 - val_loss: 0.0040\n",
      "Epoch 856/1000\n",
      "143/143 [==============================] - 0s 100us/step - loss: 0.0018 - val_loss: 0.0033\n",
      "Epoch 857/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 858/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0017 - val_loss: 0.0027\n",
      "Epoch 859/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0050\n",
      "Epoch 860/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0032\n",
      "Epoch 861/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 862/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 863/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0041\n",
      "Epoch 864/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0017 - val_loss: 0.0030\n",
      "Epoch 865/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0017 - val_loss: 0.0031\n",
      "Epoch 866/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0029\n",
      "Epoch 867/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 868/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0029\n",
      "Epoch 869/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0030\n",
      "Epoch 870/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0021 - val_loss: 0.0053\n",
      "Epoch 871/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 872/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 873/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0036\n",
      "Epoch 874/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0017 - val_loss: 0.0035\n",
      "Epoch 875/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0017 - val_loss: 0.0028\n",
      "Epoch 876/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0033\n",
      "Epoch 877/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0017 - val_loss: 0.0035\n",
      "Epoch 878/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0016 - val_loss: 0.0033\n",
      "Epoch 879/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0027\n",
      "Epoch 880/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0038\n",
      "Epoch 881/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0035\n",
      "Epoch 882/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 883/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 884/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0018 - val_loss: 0.0033\n",
      "Epoch 885/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0017 - val_loss: 0.0034\n",
      "Epoch 886/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0015 - val_loss: 0.0037\n",
      "Epoch 887/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0028\n",
      "Epoch 888/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0034\n",
      "Epoch 889/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0015 - val_loss: 0.0037\n",
      "Epoch 890/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0019 - val_loss: 0.0031\n",
      "Epoch 891/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 892/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0017 - val_loss: 0.0028\n",
      "Epoch 893/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0019 - val_loss: 0.0031\n",
      "Epoch 894/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 895/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 896/1000\n",
      "143/143 [==============================] - 0s 100us/step - loss: 0.0019 - val_loss: 0.0027\n",
      "Epoch 897/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0034\n",
      "Epoch 898/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0015 - val_loss: 0.0032\n",
      "Epoch 899/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0028\n",
      "Epoch 900/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0016 - val_loss: 0.0029\n",
      "Epoch 901/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 902/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0016 - val_loss: 0.0029\n",
      "Epoch 903/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0031\n",
      "Epoch 904/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 905/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 906/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0015 - val_loss: 0.0029\n",
      "Epoch 907/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0015 - val_loss: 0.0040\n",
      "Epoch 908/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0029\n",
      "Epoch 909/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0017 - val_loss: 0.0027\n",
      "Epoch 910/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0042\n",
      "Epoch 911/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0018 - val_loss: 0.0035\n",
      "Epoch 912/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0014 - val_loss: 0.0033\n",
      "Epoch 913/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0037\n",
      "Epoch 914/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0034\n",
      "Epoch 915/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0031\n",
      "Epoch 916/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0030\n",
      "Epoch 917/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0030\n",
      "Epoch 918/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0014 - val_loss: 0.0034\n",
      "Epoch 919/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0015 - val_loss: 0.0039\n",
      "Epoch 920/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0038\n",
      "Epoch 921/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0027\n",
      "Epoch 922/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 923/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0016 - val_loss: 0.0032\n",
      "Epoch 924/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 925/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 926/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0033\n",
      "Epoch 927/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0030\n",
      "Epoch 928/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0014 - val_loss: 0.0033\n",
      "Epoch 929/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0038\n",
      "Epoch 930/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0033\n",
      "Epoch 931/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0014 - val_loss: 0.0033\n",
      "Epoch 932/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0033\n",
      "Epoch 933/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 934/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0018 - val_loss: 0.0045\n",
      "Epoch 935/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0030\n",
      "Epoch 936/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0032\n",
      "Epoch 937/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0034\n",
      "Epoch 938/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0039\n",
      "Epoch 939/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0015 - val_loss: 0.0034\n",
      "Epoch 940/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0014 - val_loss: 0.0032\n",
      "Epoch 941/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0013 - val_loss: 0.0049\n",
      "Epoch 942/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0016 - val_loss: 0.0026\n",
      "Epoch 943/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0017 - val_loss: 0.0030\n",
      "Epoch 944/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 945/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0030\n",
      "Epoch 946/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0016 - val_loss: 0.0032\n",
      "Epoch 947/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0017 - val_loss: 0.0030\n",
      "Epoch 948/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0015 - val_loss: 0.0035\n",
      "Epoch 949/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0036\n",
      "Epoch 950/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0031\n",
      "Epoch 951/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 952/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 953/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0033\n",
      "Epoch 954/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0030\n",
      "Epoch 955/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0015 - val_loss: 0.0035\n",
      "Epoch 956/1000\n",
      "143/143 [==============================] - 0s 100us/step - loss: 0.0015 - val_loss: 0.0035\n",
      "Epoch 957/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0031\n",
      "Epoch 958/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0029\n",
      "Epoch 959/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0018 - val_loss: 0.0034\n",
      "Epoch 960/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0017 - val_loss: 0.0050\n",
      "Epoch 961/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0019 - val_loss: 0.0032\n",
      "Epoch 962/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0022 - val_loss: 0.0033\n",
      "Epoch 963/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0037\n",
      "Epoch 964/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 965/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0016 - val_loss: 0.0031\n",
      "Epoch 966/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0017 - val_loss: 0.0032\n",
      "Epoch 967/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0035\n",
      "Epoch 968/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0014 - val_loss: 0.0034\n",
      "Epoch 969/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0034\n",
      "Epoch 970/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0033\n",
      "Epoch 971/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0034\n",
      "Epoch 972/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0034\n",
      "Epoch 973/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 974/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0016 - val_loss: 0.0029\n",
      "Epoch 975/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0016 - val_loss: 0.0031\n",
      "Epoch 976/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 977/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0015 - val_loss: 0.0034\n",
      "Epoch 978/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0029\n",
      "Epoch 979/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0033\n",
      "Epoch 980/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0031\n",
      "Epoch 981/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0035\n",
      "Epoch 982/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0013 - val_loss: 0.0030\n",
      "Epoch 983/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0035\n",
      "Epoch 984/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0039\n",
      "Epoch 985/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0016 - val_loss: 0.0038\n",
      "Epoch 986/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0017 - val_loss: 0.0035\n",
      "Epoch 987/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0016 - val_loss: 0.0034\n",
      "Epoch 988/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0036\n",
      "Epoch 989/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0032\n",
      "Epoch 990/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0034\n",
      "Epoch 991/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0034\n",
      "Epoch 992/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0032\n",
      "Epoch 993/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 111us/step - loss: 0.0020 - val_loss: 0.0030\n",
      "Epoch 994/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0050\n",
      "Epoch 995/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0031\n",
      "Epoch 996/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0027\n",
      "Epoch 997/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 998/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0014 - val_loss: 0.0033\n",
      "Epoch 999/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0034\n",
      "Epoch 1000/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0029\n",
      "0.012176395393908024\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 0.71036226, -0.10302917, -0.9189991 ,  0.39777452,  0.19584052],\n",
       "        [ 0.22109173,  0.65664095, -0.44598335, -0.6136856 ,  0.08573424],\n",
       "        [-0.9590096 , -0.37375563,  0.20607613, -0.27657562, -0.19846945],\n",
       "        [-0.23571002, -0.65722716,  0.03596286,  0.185982  ,  0.01001965],\n",
       "        [-0.27159145, -0.06250049,  0.32582757, -0.05341841,  0.5017336 ],\n",
       "        [ 0.89097255,  1.0554409 , -1.0225809 , -0.5462747 ,  0.29750708],\n",
       "        [-0.1793804 , -0.7214401 , -0.65326005, -0.15002458, -0.3456803 ],\n",
       "        [-0.02749527, -0.17999767, -0.18576503,  0.12821677, -0.22089916],\n",
       "        [-0.557536  , -0.24457613,  0.7360202 , -0.42238715, -0.5669123 ],\n",
       "        [ 0.6126669 ,  0.17354855, -0.8219064 , -0.21962704, -0.16128862],\n",
       "        [-0.18131714, -0.2282063 ,  0.33201933, -0.3282481 ,  0.04786977],\n",
       "        [ 0.29796433,  0.6119303 ,  1.9135824 ,  1.581173  ,  0.13115884],\n",
       "        [ 0.24357021,  0.51009697,  0.2211002 ,  0.6264713 , -0.05434312],\n",
       "        [ 1.5793031 ,  0.34355977,  1.3440794 ,  0.36248678,  0.07627951],\n",
       "        [ 0.02235953, -0.07826736,  0.7839594 ,  0.23029056, -0.6111456 ],\n",
       "        [-0.22201166, -0.42255265, -0.33070946, -0.1739714 , -0.48703524],\n",
       "        [-0.08239371, -0.10113367, -0.4003706 ,  0.19980013, -0.3732864 ],\n",
       "        [ 0.11535653,  0.0489846 , -0.13784398, -0.11888022, -0.18691066],\n",
       "        [-0.56362945,  0.913434  ,  0.9918275 , -0.7198361 , -0.07059307],\n",
       "        [ 0.12808426,  0.3310456 ,  0.5786699 , -0.38576463,  0.05232732],\n",
       "        [-2.3501277 ,  0.41459224,  0.56699646, -0.34438923, -0.2891749 ],\n",
       "        [-0.53301406,  0.49522203,  1.9273094 , -0.72838575,  0.27489024]],\n",
       "       dtype=float32),\n",
       " array([-0.5736643 ,  0.2226602 ,  0.2669356 , -0.21871817, -0.07841725],\n",
       "       dtype=float32),\n",
       " array([[-0.0839734 , -0.2773214 , -0.70399874,  0.3254699 ,  0.6344458 ,\n",
       "         -0.3301292 ,  0.8561651 , -0.10733332,  0.6777345 , -0.37619025,\n",
       "          0.05812584,  0.16888985,  0.10981619,  0.46035472,  0.78137696],\n",
       "        [ 0.00631711,  0.20320186,  0.63011837,  0.15055217, -0.06511065,\n",
       "          0.00851036,  0.22131512,  0.33634567,  0.24219014,  0.21825898,\n",
       "          0.27891484,  0.2260866 , -0.22433212,  0.13680288, -0.29727724],\n",
       "        [ 0.16648868, -0.50213784, -0.6901031 , -0.3903882 ,  0.36522055,\n",
       "         -0.36149225,  0.21518965, -0.228854  , -0.1616811 , -0.6513159 ,\n",
       "          0.22524156, -0.22952463,  0.33822823, -0.05917383,  0.08349481],\n",
       "        [-0.1800433 ,  0.36072463,  0.44837546,  0.09306913,  0.11402322,\n",
       "          0.2765232 , -0.2855471 ,  0.11730864, -0.19878647,  0.37372944,\n",
       "         -0.03036777, -0.28097898, -0.17401238, -0.02631158, -0.05768072],\n",
       "        [ 0.2494342 , -0.0690607 , -0.17762512, -0.38014713, -0.21774174,\n",
       "         -0.13807863, -0.21635327,  0.12780565,  0.16211864, -0.28407115,\n",
       "         -0.03635944, -0.15765059,  0.06050297, -0.3372126 , -0.44187835]],\n",
       "       dtype=float32),\n",
       " array([-0.12795265,  0.23314294, -0.2521877 ,  0.23422705,  0.09100769,\n",
       "         0.12306502, -0.06967963,  0.03414902,  0.40005845,  0.13186003,\n",
       "        -0.38953656, -0.11917853, -0.10402285,  0.05931359,  0.33163628],\n",
       "       dtype=float32),\n",
       " array([[-0.00149639],\n",
       "        [-0.04751658],\n",
       "        [-0.4730973 ],\n",
       "        [ 0.00553043],\n",
       "        [ 0.10207297],\n",
       "        [-0.00790554],\n",
       "        [ 0.17252934],\n",
       "        [-0.00821752],\n",
       "        [ 0.07480666],\n",
       "        [-0.04330963],\n",
       "        [-0.00343648],\n",
       "        [-0.00261769],\n",
       "        [ 0.00710465],\n",
       "        [ 0.06794034],\n",
       "        [ 0.13332975]], dtype=float32),\n",
       " array([0.23757029], dtype=float32)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_automobile, history_automobile, evaluate_automobile=NN_model_structure_regression_3(X_train_automobile, X_val_automobile, Y_train_automobile, Y_val_automobile, adam2, 32, 1000, x_test_automobile, y_test_automobile)\n",
    "model_automobile.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_automobile.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_automobile_structure3_4th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_46 (Dense)             (None, 10)                230       \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 291\n",
      "Trainable params: 291\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 143 samples, validate on 31 samples\n",
      "Epoch 1/1000\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.4068 - val_loss: 0.0572\n",
      "Epoch 2/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.1563 - val_loss: 0.0260\n",
      "Epoch 3/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0402 - val_loss: 0.0386\n",
      "Epoch 4/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0459 - val_loss: 0.0330\n",
      "Epoch 5/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0304 - val_loss: 0.0214\n",
      "Epoch 6/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0244 - val_loss: 0.0181\n",
      "Epoch 7/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0235 - val_loss: 0.0117\n",
      "Epoch 8/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0215 - val_loss: 0.0078\n",
      "Epoch 9/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0150 - val_loss: 0.0086\n",
      "Epoch 10/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0143 - val_loss: 0.0087\n",
      "Epoch 11/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0130 - val_loss: 0.0091\n",
      "Epoch 12/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0138 - val_loss: 0.0075\n",
      "Epoch 13/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0120 - val_loss: 0.0074\n",
      "Epoch 14/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0116 - val_loss: 0.0073\n",
      "Epoch 15/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0113 - val_loss: 0.0075\n",
      "Epoch 16/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0108 - val_loss: 0.0072\n",
      "Epoch 17/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0112 - val_loss: 0.0072\n",
      "Epoch 18/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0110 - val_loss: 0.0069\n",
      "Epoch 19/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0102 - val_loss: 0.0068\n",
      "Epoch 20/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0099 - val_loss: 0.0071\n",
      "Epoch 21/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0101 - val_loss: 0.0067\n",
      "Epoch 22/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0093 - val_loss: 0.0068\n",
      "Epoch 23/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0093 - val_loss: 0.0063\n",
      "Epoch 24/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0090 - val_loss: 0.0065\n",
      "Epoch 25/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0090 - val_loss: 0.0063\n",
      "Epoch 26/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0087 - val_loss: 0.0067\n",
      "Epoch 27/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0086 - val_loss: 0.0060\n",
      "Epoch 28/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0086 - val_loss: 0.0066\n",
      "Epoch 29/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0091 - val_loss: 0.0060\n",
      "Epoch 30/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0085 - val_loss: 0.0068\n",
      "Epoch 31/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0089 - val_loss: 0.0059\n",
      "Epoch 32/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0091 - val_loss: 0.0077\n",
      "Epoch 33/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0103 - val_loss: 0.0061\n",
      "Epoch 34/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0123 - val_loss: 0.0070\n",
      "Epoch 35/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0128 - val_loss: 0.0055\n",
      "Epoch 36/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0126 - val_loss: 0.0052\n",
      "Epoch 37/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0094 - val_loss: 0.0071\n",
      "Epoch 38/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0090 - val_loss: 0.0057\n",
      "Epoch 39/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0081 - val_loss: 0.0068\n",
      "Epoch 40/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0078 - val_loss: 0.0054\n",
      "Epoch 41/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0081 - val_loss: 0.0055\n",
      "Epoch 42/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0079 - val_loss: 0.0053\n",
      "Epoch 43/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0073 - val_loss: 0.0053\n",
      "Epoch 44/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0073 - val_loss: 0.0056\n",
      "Epoch 45/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0073 - val_loss: 0.0052\n",
      "Epoch 46/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0078 - val_loss: 0.0054\n",
      "Epoch 47/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0074 - val_loss: 0.0054\n",
      "Epoch 48/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0074 - val_loss: 0.0051\n",
      "Epoch 49/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0071 - val_loss: 0.0050\n",
      "Epoch 50/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0069 - val_loss: 0.0047\n",
      "Epoch 51/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0073 - val_loss: 0.0050\n",
      "Epoch 52/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0072 - val_loss: 0.0045\n",
      "Epoch 53/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0070 - val_loss: 0.0050\n",
      "Epoch 54/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0071 - val_loss: 0.0047\n",
      "Epoch 55/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0075 - val_loss: 0.0046\n",
      "Epoch 56/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0067 - val_loss: 0.0050\n",
      "Epoch 57/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0068 - val_loss: 0.0044\n",
      "Epoch 58/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0067 - val_loss: 0.0051\n",
      "Epoch 59/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0070 - val_loss: 0.0047\n",
      "Epoch 60/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0065 - val_loss: 0.0054\n",
      "Epoch 61/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0068 - val_loss: 0.0043\n",
      "Epoch 62/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0066 - val_loss: 0.0056\n",
      "Epoch 63/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0070 - val_loss: 0.0046\n",
      "Epoch 64/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0075 - val_loss: 0.0054\n",
      "Epoch 65/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0073 - val_loss: 0.0045\n",
      "Epoch 66/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0067 - val_loss: 0.0046\n",
      "Epoch 67/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0063 - val_loss: 0.0046\n",
      "Epoch 68/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0064 - val_loss: 0.0045\n",
      "Epoch 69/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 105us/step - loss: 0.0070 - val_loss: 0.0041\n",
      "Epoch 70/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0067 - val_loss: 0.0043\n",
      "Epoch 71/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0064 - val_loss: 0.0042\n",
      "Epoch 72/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0065 - val_loss: 0.0044\n",
      "Epoch 73/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0069 - val_loss: 0.0042\n",
      "Epoch 74/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0062 - val_loss: 0.0042\n",
      "Epoch 75/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0075 - val_loss: 0.0042\n",
      "Epoch 76/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0065 - val_loss: 0.0042\n",
      "Epoch 77/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0061 - val_loss: 0.0045\n",
      "Epoch 78/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0068 - val_loss: 0.0041\n",
      "Epoch 79/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0072 - val_loss: 0.0059\n",
      "Epoch 80/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0085 - val_loss: 0.0044\n",
      "Epoch 81/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0076 - val_loss: 0.0044\n",
      "Epoch 82/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0063 - val_loss: 0.0041\n",
      "Epoch 83/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0062 - val_loss: 0.0045\n",
      "Epoch 84/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0065 - val_loss: 0.0041\n",
      "Epoch 85/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0059 - val_loss: 0.0042\n",
      "Epoch 86/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0058 - val_loss: 0.0041\n",
      "Epoch 87/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0057 - val_loss: 0.0039\n",
      "Epoch 88/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0056 - val_loss: 0.0045\n",
      "Epoch 89/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0060 - val_loss: 0.0042\n",
      "Epoch 90/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0058 - val_loss: 0.0042\n",
      "Epoch 91/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0056 - val_loss: 0.0037\n",
      "Epoch 92/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0060 - val_loss: 0.0038\n",
      "Epoch 93/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0062 - val_loss: 0.0043\n",
      "Epoch 94/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0055 - val_loss: 0.0046\n",
      "Epoch 95/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0056 - val_loss: 0.0044\n",
      "Epoch 96/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0057 - val_loss: 0.0042\n",
      "Epoch 97/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0054 - val_loss: 0.0046\n",
      "Epoch 98/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0056 - val_loss: 0.0041\n",
      "Epoch 99/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0055 - val_loss: 0.0045\n",
      "Epoch 100/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0054 - val_loss: 0.0039\n",
      "Epoch 101/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0055 - val_loss: 0.0044\n",
      "Epoch 102/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0052 - val_loss: 0.0046\n",
      "Epoch 103/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0055 - val_loss: 0.0043\n",
      "Epoch 104/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0055 - val_loss: 0.0042\n",
      "Epoch 105/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0055 - val_loss: 0.0043\n",
      "Epoch 106/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0053 - val_loss: 0.0038\n",
      "Epoch 107/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0050 - val_loss: 0.0040\n",
      "Epoch 108/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0049 - val_loss: 0.0044\n",
      "Epoch 109/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0049 - val_loss: 0.0040\n",
      "Epoch 110/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0049 - val_loss: 0.0044\n",
      "Epoch 111/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0042\n",
      "Epoch 112/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0038\n",
      "Epoch 113/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0052 - val_loss: 0.0047\n",
      "Epoch 114/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0054 - val_loss: 0.0040\n",
      "Epoch 115/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 116/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0039\n",
      "Epoch 117/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0048 - val_loss: 0.0043\n",
      "Epoch 118/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0048 - val_loss: 0.0036\n",
      "Epoch 119/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0041\n",
      "Epoch 120/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0047 - val_loss: 0.0041\n",
      "Epoch 121/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0046 - val_loss: 0.0038\n",
      "Epoch 122/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0046 - val_loss: 0.0036\n",
      "Epoch 123/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 124/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0048 - val_loss: 0.0039\n",
      "Epoch 125/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0049 - val_loss: 0.0039\n",
      "Epoch 126/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0050 - val_loss: 0.0061\n",
      "Epoch 127/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0059 - val_loss: 0.0039\n",
      "Epoch 128/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 129/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0045 - val_loss: 0.0036\n",
      "Epoch 130/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0046 - val_loss: 0.0050\n",
      "Epoch 131/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0046 - val_loss: 0.0037\n",
      "Epoch 132/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0044 - val_loss: 0.0051\n",
      "Epoch 133/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0046 - val_loss: 0.0039\n",
      "Epoch 134/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0051 - val_loss: 0.0039\n",
      "Epoch 135/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0042 - val_loss: 0.0033\n",
      "Epoch 136/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0036\n",
      "Epoch 137/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0038\n",
      "Epoch 138/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0041 - val_loss: 0.0035\n",
      "Epoch 139/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 140/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0041 - val_loss: 0.0035\n",
      "Epoch 141/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0042 - val_loss: 0.0044\n",
      "Epoch 142/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0045 - val_loss: 0.0037\n",
      "Epoch 143/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 144/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0037\n",
      "Epoch 145/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0041 - val_loss: 0.0035\n",
      "Epoch 146/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 115us/step - loss: 0.0044 - val_loss: 0.0037\n",
      "Epoch 147/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0033\n",
      "Epoch 148/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0040 - val_loss: 0.0035\n",
      "Epoch 149/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0040 - val_loss: 0.0034\n",
      "Epoch 150/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0046 - val_loss: 0.0065\n",
      "Epoch 151/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0059 - val_loss: 0.0039\n",
      "Epoch 152/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0046\n",
      "Epoch 153/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0040 - val_loss: 0.0033\n",
      "Epoch 154/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0037 - val_loss: 0.0048\n",
      "Epoch 155/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0042 - val_loss: 0.0034\n",
      "Epoch 156/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0046 - val_loss: 0.0040\n",
      "Epoch 157/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0040 - val_loss: 0.0032\n",
      "Epoch 158/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 159/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0039 - val_loss: 0.0038\n",
      "Epoch 160/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0039 - val_loss: 0.0033\n",
      "Epoch 161/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 162/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0041 - val_loss: 0.0032\n",
      "Epoch 163/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0042 - val_loss: 0.0055\n",
      "Epoch 164/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0048 - val_loss: 0.0033\n",
      "Epoch 165/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0047 - val_loss: 0.0035\n",
      "Epoch 166/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0042 - val_loss: 0.0039\n",
      "Epoch 167/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0037 - val_loss: 0.0033\n",
      "Epoch 168/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0039 - val_loss: 0.0029\n",
      "Epoch 169/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0040 - val_loss: 0.0033\n",
      "Epoch 170/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0039 - val_loss: 0.0033\n",
      "Epoch 171/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 172/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0031\n",
      "Epoch 173/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0043\n",
      "Epoch 174/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0031\n",
      "Epoch 175/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0044\n",
      "Epoch 176/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0040 - val_loss: 0.0030\n",
      "Epoch 177/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0029\n",
      "Epoch 178/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0035 - val_loss: 0.0031\n",
      "Epoch 179/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 180/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0034 - val_loss: 0.0031\n",
      "Epoch 181/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 182/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 183/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0031\n",
      "Epoch 184/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0037 - val_loss: 0.0049\n",
      "Epoch 185/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0041 - val_loss: 0.0032\n",
      "Epoch 186/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0031\n",
      "Epoch 187/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0038 - val_loss: 0.0047\n",
      "Epoch 188/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0049 - val_loss: 0.0032\n",
      "Epoch 189/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0038\n",
      "Epoch 190/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 191/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0036 - val_loss: 0.0032\n",
      "Epoch 192/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0031 - val_loss: 0.0028\n",
      "Epoch 193/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0032 - val_loss: 0.0036\n",
      "Epoch 194/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 195/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0033 - val_loss: 0.0040\n",
      "Epoch 196/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 197/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 198/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0036 - val_loss: 0.0032\n",
      "Epoch 199/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0033 - val_loss: 0.0029\n",
      "Epoch 200/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 201/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 202/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0032 - val_loss: 0.0043\n",
      "Epoch 203/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0035 - val_loss: 0.0028\n",
      "Epoch 204/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 205/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0032 - val_loss: 0.0030\n",
      "Epoch 206/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 207/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 208/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0030 - val_loss: 0.0033\n",
      "Epoch 209/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 210/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0032\n",
      "Epoch 211/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0035\n",
      "Epoch 212/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 213/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0030 - val_loss: 0.0033\n",
      "Epoch 214/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 215/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 216/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0031 - val_loss: 0.0028\n",
      "Epoch 217/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0030 - val_loss: 0.0032\n",
      "Epoch 218/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 219/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 220/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 221/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0030 - val_loss: 0.0041\n",
      "Epoch 222/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 223/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 110us/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 224/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0043\n",
      "Epoch 225/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0033 - val_loss: 0.0029\n",
      "Epoch 226/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 227/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 228/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0031 - val_loss: 0.0055\n",
      "Epoch 229/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0040 - val_loss: 0.0028\n",
      "Epoch 230/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0031 - val_loss: 0.0029\n",
      "Epoch 231/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0031 - val_loss: 0.0039\n",
      "Epoch 232/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0028\n",
      "Epoch 233/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 234/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0035 - val_loss: 0.0026\n",
      "Epoch 235/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 236/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 237/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 238/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0027\n",
      "Epoch 239/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0030 - val_loss: 0.0034\n",
      "Epoch 240/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 241/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0043\n",
      "Epoch 242/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 243/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 244/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0028 - val_loss: 0.0033\n",
      "Epoch 245/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0032 - val_loss: 0.0029\n",
      "Epoch 246/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0045\n",
      "Epoch 247/1000\n",
      "143/143 [==============================] - 0s 99us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 248/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0028\n",
      "Epoch 249/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0030 - val_loss: 0.0033\n",
      "Epoch 250/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 251/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 252/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0032 - val_loss: 0.0027\n",
      "Epoch 253/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0041\n",
      "Epoch 254/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0030 - val_loss: 0.0027\n",
      "Epoch 255/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 256/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 257/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0028 - val_loss: 0.0031\n",
      "Epoch 258/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0028 - val_loss: 0.0032\n",
      "Epoch 259/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 260/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0032 - val_loss: 0.0047\n",
      "Epoch 261/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0030\n",
      "Epoch 262/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0030 - val_loss: 0.0040\n",
      "Epoch 263/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 264/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0033 - val_loss: 0.0028\n",
      "Epoch 265/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0031 - val_loss: 0.0035\n",
      "Epoch 266/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0034\n",
      "Epoch 267/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0028 - val_loss: 0.0026\n",
      "Epoch 268/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 269/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0026\n",
      "Epoch 270/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0027\n",
      "Epoch 271/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0033 - val_loss: 0.0039\n",
      "Epoch 272/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0034\n",
      "Epoch 273/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0032 - val_loss: 0.0031\n",
      "Epoch 274/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0031 - val_loss: 0.0062\n",
      "Epoch 275/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0041 - val_loss: 0.0032\n",
      "Epoch 276/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0038\n",
      "Epoch 277/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 278/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0027\n",
      "Epoch 279/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 280/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 281/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 282/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 283/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 284/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0037\n",
      "Epoch 285/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 286/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0025 - val_loss: 0.0032\n",
      "Epoch 287/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 288/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0025 - val_loss: 0.0033\n",
      "Epoch 289/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 290/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0028 - val_loss: 0.0042\n",
      "Epoch 291/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 292/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 293/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0028 - val_loss: 0.0038\n",
      "Epoch 294/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0029 - val_loss: 0.0027\n",
      "Epoch 295/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 296/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0046\n",
      "Epoch 297/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 298/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0032\n",
      "Epoch 299/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0029 - val_loss: 0.0033\n",
      "Epoch 300/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 301/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0035\n",
      "Epoch 302/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 303/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 304/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0027 - val_loss: 0.0039\n",
      "Epoch 305/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 306/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 307/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0031 - val_loss: 0.0039\n",
      "Epoch 308/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 309/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0025 - val_loss: 0.0034\n",
      "Epoch 310/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0026 - val_loss: 0.0034\n",
      "Epoch 311/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 312/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 313/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 314/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 315/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 316/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0025 - val_loss: 0.0032\n",
      "Epoch 317/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 318/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0023 - val_loss: 0.0035\n",
      "Epoch 319/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 320/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 321/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0025 - val_loss: 0.0045\n",
      "Epoch 322/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 323/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0029 - val_loss: 0.0034\n",
      "Epoch 324/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0027 - val_loss: 0.0034\n",
      "Epoch 325/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 326/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0024 - val_loss: 0.0033\n",
      "Epoch 327/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 328/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 329/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 330/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 331/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 332/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0029 - val_loss: 0.0027\n",
      "Epoch 333/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0031\n",
      "Epoch 334/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 335/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 336/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0032\n",
      "Epoch 337/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 338/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 339/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 340/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 341/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 342/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 343/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 344/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0026 - val_loss: 0.0039\n",
      "Epoch 345/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 346/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 347/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0026 - val_loss: 0.0054\n",
      "Epoch 348/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0032 - val_loss: 0.0028\n",
      "Epoch 349/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 350/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0032\n",
      "Epoch 351/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 352/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0023 - val_loss: 0.0034\n",
      "Epoch 353/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 354/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0037\n",
      "Epoch 355/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 356/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 357/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 358/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 359/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0035\n",
      "Epoch 360/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 361/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 362/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 363/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 364/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 365/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 366/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 367/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 368/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0027 - val_loss: 0.0051\n",
      "Epoch 369/1000\n",
      "143/143 [==============================] - 0s 99us/step - loss: 0.0025 - val_loss: 0.0036\n",
      "Epoch 370/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0030\n",
      "Epoch 371/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 372/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 373/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 374/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 375/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0022 - val_loss: 0.0033\n",
      "Epoch 376/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0032\n",
      "Epoch 377/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 378/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 379/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 380/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0034\n",
      "Epoch 381/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 382/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0030 - val_loss: 0.0027\n",
      "Epoch 383/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0025 - val_loss: 0.0034\n",
      "Epoch 384/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 385/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 386/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 387/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0023 - val_loss: 0.0033\n",
      "Epoch 388/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 389/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 390/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 391/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0021 - val_loss: 0.0028\n",
      "Epoch 392/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0022 - val_loss: 0.0029\n",
      "Epoch 393/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 394/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0022 - val_loss: 0.0035\n",
      "Epoch 395/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 396/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0029\n",
      "Epoch 397/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 398/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 399/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0022 - val_loss: 0.0031\n",
      "Epoch 400/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0022 - val_loss: 0.0031\n",
      "Epoch 401/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 402/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 403/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 404/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0037\n",
      "Epoch 405/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 406/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 407/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0047\n",
      "Epoch 408/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 409/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0022 - val_loss: 0.0029\n",
      "Epoch 410/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0031\n",
      "Epoch 411/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 412/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0021 - val_loss: 0.0032\n",
      "Epoch 413/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0031\n",
      "Epoch 414/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0028\n",
      "Epoch 415/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 416/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 417/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0037\n",
      "Epoch 418/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 419/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 420/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 421/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 422/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 423/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0022 - val_loss: 0.0031\n",
      "Epoch 424/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0028\n",
      "Epoch 425/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0021 - val_loss: 0.0042\n",
      "Epoch 426/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 427/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0022 - val_loss: 0.0035\n",
      "Epoch 428/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0047\n",
      "Epoch 429/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 430/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 431/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0033\n",
      "Epoch 432/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0021 - val_loss: 0.0028\n",
      "Epoch 433/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0021 - val_loss: 0.0042\n",
      "Epoch 434/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 435/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 436/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0030 - val_loss: 0.0053\n",
      "Epoch 437/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0035\n",
      "Epoch 438/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 439/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0031 - val_loss: 0.0034\n",
      "Epoch 440/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 441/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0025 - val_loss: 0.0033\n",
      "Epoch 442/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0023 - val_loss: 0.0033\n",
      "Epoch 443/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 444/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 445/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0031\n",
      "Epoch 446/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 447/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0022 - val_loss: 0.0029\n",
      "Epoch 448/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0023 - val_loss: 0.0041\n",
      "Epoch 449/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 450/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 451/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0023 - val_loss: 0.0036\n",
      "Epoch 452/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 453/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 454/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0048\n",
      "Epoch 455/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 456/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 457/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 458/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0042\n",
      "Epoch 459/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 460/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0022 - val_loss: 0.0033\n",
      "Epoch 461/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0021 - val_loss: 0.0037\n",
      "Epoch 462/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 463/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 464/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0021 - val_loss: 0.0036\n",
      "Epoch 465/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0022 - val_loss: 0.0031\n",
      "Epoch 466/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 467/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0023 - val_loss: 0.0033\n",
      "Epoch 468/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0023 - val_loss: 0.0037\n",
      "Epoch 469/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 470/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 471/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0053\n",
      "Epoch 472/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 473/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 474/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0028\n",
      "Epoch 475/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0020 - val_loss: 0.0031\n",
      "Epoch 476/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0022 - val_loss: 0.0047\n",
      "Epoch 477/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 478/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 479/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0033\n",
      "Epoch 480/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0028\n",
      "Epoch 481/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0034\n",
      "Epoch 482/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0033\n",
      "Epoch 483/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0022 - val_loss: 0.0029\n",
      "Epoch 484/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0023 - val_loss: 0.0037\n",
      "Epoch 485/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 486/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0019 - val_loss: 0.0039\n",
      "Epoch 487/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0031\n",
      "Epoch 488/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0031\n",
      "Epoch 489/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0036\n",
      "Epoch 490/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0032\n",
      "Epoch 491/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0033\n",
      "Epoch 492/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 493/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0033\n",
      "Epoch 494/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 495/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 496/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0038\n",
      "Epoch 497/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 498/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0019 - val_loss: 0.0030\n",
      "Epoch 499/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0019 - val_loss: 0.0027\n",
      "Epoch 500/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0020 - val_loss: 0.0032\n",
      "Epoch 501/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0049\n",
      "Epoch 502/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 503/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0020 - val_loss: 0.0035\n",
      "Epoch 504/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0033\n",
      "Epoch 505/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 506/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 507/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0041\n",
      "Epoch 508/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 509/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0031\n",
      "Epoch 510/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0034\n",
      "Epoch 511/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 512/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0029\n",
      "Epoch 513/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0031\n",
      "Epoch 514/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0020 - val_loss: 0.0031\n",
      "Epoch 515/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 516/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.001 - 0s 105us/step - loss: 0.0020 - val_loss: 0.0034\n",
      "Epoch 517/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0020 - val_loss: 0.0032\n",
      "Epoch 518/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0020 - val_loss: 0.0028\n",
      "Epoch 519/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0020 - val_loss: 0.0035\n",
      "Epoch 520/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 521/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0019 - val_loss: 0.0034\n",
      "Epoch 522/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 523/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0032\n",
      "Epoch 524/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0020 - val_loss: 0.0028\n",
      "Epoch 525/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0019 - val_loss: 0.0031\n",
      "Epoch 526/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0036\n",
      "Epoch 527/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 528/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0033\n",
      "Epoch 529/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0034\n",
      "Epoch 530/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 531/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0031\n",
      "Epoch 532/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0027\n",
      "Epoch 533/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0033\n",
      "Epoch 534/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 535/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0020 - val_loss: 0.0028\n",
      "Epoch 536/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0021 - val_loss: 0.0046\n",
      "Epoch 537/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0025 - val_loss: 0.0033\n",
      "Epoch 538/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 539/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0018 - val_loss: 0.0039\n",
      "Epoch 540/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 541/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0027\n",
      "Epoch 542/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 543/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0020 - val_loss: 0.0034\n",
      "Epoch 544/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0019 - val_loss: 0.0034\n",
      "Epoch 545/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0031\n",
      "Epoch 546/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0031\n",
      "Epoch 547/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0030\n",
      "Epoch 548/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0019 - val_loss: 0.0038\n",
      "Epoch 549/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0020 - val_loss: 0.0028\n",
      "Epoch 550/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 551/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0027 - val_loss: 0.0038\n",
      "Epoch 552/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0023 - val_loss: 0.0040\n",
      "Epoch 553/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 554/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0027 - val_loss: 0.0033\n",
      "Epoch 555/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 556/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 557/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0019 - val_loss: 0.0036\n",
      "Epoch 558/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0028\n",
      "Epoch 559/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0030\n",
      "Epoch 560/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0019 - val_loss: 0.0031\n",
      "Epoch 561/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0019 - val_loss: 0.0033\n",
      "Epoch 562/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 563/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0040\n",
      "Epoch 564/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0035\n",
      "Epoch 565/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 566/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 567/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0019 - val_loss: 0.0033\n",
      "Epoch 568/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0030\n",
      "Epoch 569/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0021 - val_loss: 0.0028\n",
      "Epoch 570/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0027\n",
      "Epoch 571/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0031\n",
      "Epoch 572/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0020 - val_loss: 0.0033\n",
      "Epoch 573/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0018 - val_loss: 0.0027\n",
      "Epoch 574/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0048\n",
      "Epoch 575/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 576/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 577/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0036\n",
      "Epoch 578/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0028\n",
      "Epoch 579/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 580/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0018 - val_loss: 0.0037\n",
      "Epoch 581/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0018 - val_loss: 0.0029\n",
      "Epoch 582/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0018 - val_loss: 0.0028\n",
      "Epoch 583/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0034\n",
      "Epoch 584/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0030\n",
      "Epoch 585/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0028\n",
      "Epoch 586/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0035\n",
      "Epoch 587/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0028\n",
      "Epoch 588/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 589/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 590/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0021 - val_loss: 0.0042\n",
      "Epoch 591/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0020 - val_loss: 0.0028\n",
      "Epoch 592/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0019 - val_loss: 0.0031\n",
      "Epoch 593/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0031\n",
      "Epoch 594/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0020 - val_loss: 0.0045\n",
      "Epoch 595/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0020 - val_loss: 0.0030\n",
      "Epoch 596/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0034\n",
      "Epoch 597/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0034\n",
      "Epoch 598/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0030\n",
      "Epoch 599/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0018 - val_loss: 0.0033\n",
      "Epoch 600/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0019 - val_loss: 0.0038\n",
      "Epoch 601/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 602/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 603/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0032 - val_loss: 0.0049\n",
      "Epoch 604/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0030 - val_loss: 0.0034\n",
      "Epoch 605/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 606/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 607/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0028\n",
      "Epoch 608/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 609/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 610/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0033\n",
      "Epoch 611/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 612/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 613/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0020 - val_loss: 0.0044\n",
      "Epoch 614/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0028\n",
      "Epoch 615/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0026\n",
      "Epoch 616/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0028\n",
      "Epoch 617/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0018 - val_loss: 0.0032\n",
      "Epoch 618/1000\n",
      "143/143 [==============================] - 0s 100us/step - loss: 0.0018 - val_loss: 0.0037\n",
      "Epoch 619/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 620/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0017 - val_loss: 0.0036\n",
      "Epoch 621/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0028\n",
      "Epoch 622/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 623/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0026 - val_loss: 0.0047\n",
      "Epoch 624/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0035\n",
      "Epoch 625/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0020 - val_loss: 0.0028\n",
      "Epoch 626/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 627/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 628/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0024 - val_loss: 0.0048\n",
      "Epoch 629/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0029\n",
      "Epoch 630/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 631/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0019 - val_loss: 0.0033\n",
      "Epoch 632/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0019 - val_loss: 0.0033\n",
      "Epoch 633/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0027\n",
      "Epoch 634/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0031\n",
      "Epoch 635/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0020 - val_loss: 0.0040\n",
      "Epoch 636/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0022 - val_loss: 0.0029\n",
      "Epoch 637/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0018 - val_loss: 0.0028\n",
      "Epoch 638/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0018 - val_loss: 0.0032\n",
      "Epoch 639/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 640/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0018 - val_loss: 0.0028\n",
      "Epoch 641/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0031\n",
      "Epoch 642/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0017 - val_loss: 0.0028\n",
      "Epoch 643/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0019 - val_loss: 0.0034\n",
      "Epoch 644/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0037\n",
      "Epoch 645/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0018 - val_loss: 0.0031\n",
      "Epoch 646/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0018 - val_loss: 0.0030\n",
      "Epoch 647/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0032\n",
      "Epoch 648/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0038\n",
      "Epoch 649/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0017 - val_loss: 0.0027\n",
      "Epoch 650/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0034\n",
      "Epoch 651/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0041\n",
      "Epoch 652/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0029\n",
      "Epoch 653/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 654/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0036\n",
      "Epoch 655/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0028\n",
      "Epoch 656/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 657/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0018 - val_loss: 0.0032\n",
      "Epoch 658/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0017 - val_loss: 0.0036\n",
      "Epoch 659/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0030\n",
      "Epoch 660/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0018 - val_loss: 0.0030\n",
      "Epoch 661/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0018 - val_loss: 0.0037\n",
      "Epoch 662/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 663/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0019 - val_loss: 0.0031\n",
      "Epoch 664/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0033\n",
      "Epoch 665/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0040\n",
      "Epoch 666/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0033\n",
      "Epoch 667/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0017 - val_loss: 0.0030\n",
      "Epoch 668/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0038\n",
      "Epoch 669/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0019 - val_loss: 0.0042\n",
      "Epoch 670/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0029\n",
      "Epoch 671/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 672/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0018 - val_loss: 0.0045\n",
      "Epoch 673/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 674/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0018 - val_loss: 0.0032\n",
      "Epoch 675/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0017 - val_loss: 0.0031\n",
      "Epoch 676/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0017 - val_loss: 0.0033\n",
      "Epoch 677/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.001 - 0s 101us/step - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 678/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0019 - val_loss: 0.0034\n",
      "Epoch 679/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0017 - val_loss: 0.0030\n",
      "Epoch 680/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 681/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 682/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0018 - val_loss: 0.0029\n",
      "Epoch 683/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0040\n",
      "Epoch 684/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0031\n",
      "Epoch 685/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 107us/step - loss: 0.0021 - val_loss: 0.0033\n",
      "Epoch 686/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0032\n",
      "Epoch 687/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0052\n",
      "Epoch 688/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0040\n",
      "Epoch 689/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 690/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0016 - val_loss: 0.0035\n",
      "Epoch 691/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 692/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0029\n",
      "Epoch 693/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 694/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0017 - val_loss: 0.0034\n",
      "Epoch 695/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0035\n",
      "Epoch 696/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0017 - val_loss: 0.0036\n",
      "Epoch 697/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0038\n",
      "Epoch 698/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 699/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0017 - val_loss: 0.0035\n",
      "Epoch 700/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0018 - val_loss: 0.0053\n",
      "Epoch 701/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 702/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 703/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0022 - val_loss: 0.0032\n",
      "Epoch 704/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0018 - val_loss: 0.0039\n",
      "Epoch 705/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0018 - val_loss: 0.0032\n",
      "Epoch 706/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0031\n",
      "Epoch 707/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0049\n",
      "Epoch 708/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0035\n",
      "Epoch 709/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0034\n",
      "Epoch 710/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0031\n",
      "Epoch 711/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 712/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0019 - val_loss: 0.0034\n",
      "Epoch 713/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0033\n",
      "Epoch 714/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0020 - val_loss: 0.0037\n",
      "Epoch 715/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0029\n",
      "Epoch 716/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 717/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0034\n",
      "Epoch 718/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0019 - val_loss: 0.0047\n",
      "Epoch 719/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0031\n",
      "Epoch 720/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0030\n",
      "Epoch 721/1000\n",
      "143/143 [==============================] - 0s 174us/step - loss: 0.0024 - val_loss: 0.0059\n",
      "Epoch 722/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 723/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0031\n",
      "Epoch 724/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 725/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0022 - val_loss: 0.0031\n",
      "Epoch 726/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0034\n",
      "Epoch 727/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0019 - val_loss: 0.0032\n",
      "Epoch 728/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0018 - val_loss: 0.0047\n",
      "Epoch 729/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 730/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0031\n",
      "Epoch 731/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0017 - val_loss: 0.0037\n",
      "Epoch 732/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0031\n",
      "Epoch 733/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0034\n",
      "Epoch 734/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0040\n",
      "Epoch 735/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0036\n",
      "Epoch 736/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 737/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0040\n",
      "Epoch 738/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0022 - val_loss: 0.0033\n",
      "Epoch 739/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0017 - val_loss: 0.0031\n",
      "Epoch 740/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0020 - val_loss: 0.0033\n",
      "Epoch 741/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0019 - val_loss: 0.0039\n",
      "Epoch 742/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0018 - val_loss: 0.0034\n",
      "Epoch 743/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0018 - val_loss: 0.0030\n",
      "Epoch 744/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0035\n",
      "Epoch 745/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0018 - val_loss: 0.0040\n",
      "Epoch 746/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0034\n",
      "Epoch 747/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0033\n",
      "Epoch 748/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0034\n",
      "Epoch 749/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0016 - val_loss: 0.0035\n",
      "Epoch 750/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0015 - val_loss: 0.0035\n",
      "Epoch 751/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0039\n",
      "Epoch 752/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0032\n",
      "Epoch 753/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 754/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0018 - val_loss: 0.0034\n",
      "Epoch 755/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0035\n",
      "Epoch 756/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 757/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0017 - val_loss: 0.0034\n",
      "Epoch 758/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0019 - val_loss: 0.0033\n",
      "Epoch 759/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0034\n",
      "Epoch 760/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 761/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0017 - val_loss: 0.0033\n",
      "Epoch 762/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0033\n",
      "Epoch 763/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0015 - val_loss: 0.0036\n",
      "Epoch 764/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 765/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0034\n",
      "Epoch 766/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0035\n",
      "Epoch 767/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0035\n",
      "Epoch 768/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0037\n",
      "Epoch 769/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0015 - val_loss: 0.0052\n",
      "Epoch 770/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0019 - val_loss: 0.0035\n",
      "Epoch 771/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0035\n",
      "Epoch 772/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0017 - val_loss: 0.0040\n",
      "Epoch 773/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 774/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0037\n",
      "Epoch 775/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0035\n",
      "Epoch 776/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0033\n",
      "Epoch 777/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 778/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0037\n",
      "Epoch 779/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0034\n",
      "Epoch 780/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0037\n",
      "Epoch 781/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 782/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0035\n",
      "Epoch 783/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0018 - val_loss: 0.0033\n",
      "Epoch 784/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0015 - val_loss: 0.0036\n",
      "Epoch 785/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0033\n",
      "Epoch 786/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0016 - val_loss: 0.0038\n",
      "Epoch 787/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 788/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0036\n",
      "Epoch 789/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0038\n",
      "Epoch 790/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0016 - val_loss: 0.0038\n",
      "Epoch 791/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 792/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0038\n",
      "Epoch 793/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0035\n",
      "Epoch 794/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 795/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0070\n",
      "Epoch 796/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 797/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0017 - val_loss: 0.0037\n",
      "Epoch 798/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0015 - val_loss: 0.0034\n",
      "Epoch 799/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 800/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0017 - val_loss: 0.0038\n",
      "Epoch 801/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0035\n",
      "Epoch 802/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 803/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0014 - val_loss: 0.0034\n",
      "Epoch 804/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0015 - val_loss: 0.0035\n",
      "Epoch 805/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0053\n",
      "Epoch 806/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0020 - val_loss: 0.0039\n",
      "Epoch 807/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0035\n",
      "Epoch 808/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0032\n",
      "Epoch 809/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0017 - val_loss: 0.0038\n",
      "Epoch 810/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0015 - val_loss: 0.0034\n",
      "Epoch 811/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 812/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 813/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0016 - val_loss: 0.0036\n",
      "Epoch 814/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0035\n",
      "Epoch 815/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 816/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 817/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 818/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 819/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0015 - val_loss: 0.0035\n",
      "Epoch 820/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0016 - val_loss: 0.0034\n",
      "Epoch 821/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 822/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0015 - val_loss: 0.0037\n",
      "Epoch 823/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 824/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0016 - val_loss: 0.0034\n",
      "Epoch 825/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0036\n",
      "Epoch 826/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0036\n",
      "Epoch 827/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0040\n",
      "Epoch 828/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 829/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0014 - val_loss: 0.0039\n",
      "Epoch 830/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0015 - val_loss: 0.0034\n",
      "Epoch 831/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0036\n",
      "Epoch 832/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0035\n",
      "Epoch 833/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0048\n",
      "Epoch 834/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0016 - val_loss: 0.0035\n",
      "Epoch 835/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0016 - val_loss: 0.0032\n",
      "Epoch 836/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0016 - val_loss: 0.0035\n",
      "Epoch 837/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0013 - val_loss: 0.0036\n",
      "Epoch 838/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0014 - val_loss: 0.0046\n",
      "Epoch 839/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 840/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0014 - val_loss: 0.0034\n",
      "Epoch 841/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0034\n",
      "Epoch 842/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0016 - val_loss: 0.0054\n",
      "Epoch 843/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0052\n",
      "Epoch 844/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0017 - val_loss: 0.0037\n",
      "Epoch 845/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0013 - val_loss: 0.0040\n",
      "Epoch 846/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 847/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0038\n",
      "Epoch 848/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0050\n",
      "Epoch 849/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 850/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0015 - val_loss: 0.0035\n",
      "Epoch 851/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0015 - val_loss: 0.0037\n",
      "Epoch 852/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 853/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0018 - val_loss: 0.0054\n",
      "Epoch 854/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0037\n",
      "Epoch 855/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0016 - val_loss: 0.0036\n",
      "Epoch 856/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0014 - val_loss: 0.0039\n",
      "Epoch 857/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0017 - val_loss: 0.0040\n",
      "Epoch 858/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 859/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0037\n",
      "Epoch 860/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 861/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0015 - val_loss: 0.0047\n",
      "Epoch 862/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0038\n",
      "Epoch 863/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0038\n",
      "Epoch 864/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 865/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 866/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0039\n",
      "Epoch 867/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 868/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0039\n",
      "Epoch 869/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0014 - val_loss: 0.0039\n",
      "Epoch 870/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0014 - val_loss: 0.0045\n",
      "Epoch 871/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0048\n",
      "Epoch 872/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0015 - val_loss: 0.0053\n",
      "Epoch 873/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 874/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0017 - val_loss: 0.0036\n",
      "Epoch 875/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0018 - val_loss: 0.0045\n",
      "Epoch 876/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0043\n",
      "Epoch 877/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0047\n",
      "Epoch 878/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0016 - val_loss: 0.0033\n",
      "Epoch 879/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0013 - val_loss: 0.0038\n",
      "Epoch 880/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0014 - val_loss: 0.0049\n",
      "Epoch 881/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 882/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0013 - val_loss: 0.0036\n",
      "Epoch 883/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0013 - val_loss: 0.0040\n",
      "Epoch 884/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0013 - val_loss: 0.0044\n",
      "Epoch 885/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0045\n",
      "Epoch 886/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0015 - val_loss: 0.0035\n",
      "Epoch 887/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0019 - val_loss: 0.0038\n",
      "Epoch 888/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0020 - val_loss: 0.0040\n",
      "Epoch 889/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0046\n",
      "Epoch 890/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0039\n",
      "Epoch 891/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0039\n",
      "Epoch 892/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0047\n",
      "Epoch 893/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0056\n",
      "Epoch 894/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0020 - val_loss: 0.0039\n",
      "Epoch 895/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0020 - val_loss: 0.0033\n",
      "Epoch 896/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0023 - val_loss: 0.0050\n",
      "Epoch 897/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0021 - val_loss: 0.0053\n",
      "Epoch 898/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0025 - val_loss: 0.0032\n",
      "Epoch 899/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0038\n",
      "Epoch 900/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0047\n",
      "Epoch 901/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0035\n",
      "Epoch 902/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0023 - val_loss: 0.0034\n",
      "Epoch 903/1000\n",
      "143/143 [==============================] - 0s 100us/step - loss: 0.0013 - val_loss: 0.0036\n",
      "Epoch 904/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0014 - val_loss: 0.0035\n",
      "Epoch 905/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0040\n",
      "Epoch 906/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0012 - val_loss: 0.0042\n",
      "Epoch 907/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0038\n",
      "Epoch 908/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0061\n",
      "Epoch 909/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0039\n",
      "Epoch 910/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0014 - val_loss: 0.0035\n",
      "Epoch 911/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0020 - val_loss: 0.0050\n",
      "Epoch 912/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0015 - val_loss: 0.0035\n",
      "Epoch 913/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0035\n",
      "Epoch 914/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0013 - val_loss: 0.0038\n",
      "Epoch 915/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 916/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0036\n",
      "Epoch 917/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0039\n",
      "Epoch 918/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0048\n",
      "Epoch 919/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0015 - val_loss: 0.0045\n",
      "Epoch 920/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 921/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0012 - val_loss: 0.0047\n",
      "Epoch 922/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 923/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 924/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0036\n",
      "Epoch 925/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0017 - val_loss: 0.0039\n",
      "Epoch 926/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0049\n",
      "Epoch 927/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0048\n",
      "Epoch 928/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0040\n",
      "Epoch 929/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 930/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 931/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0014 - val_loss: 0.0046\n",
      "Epoch 932/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0037\n",
      "Epoch 933/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0039\n",
      "Epoch 934/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 935/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 936/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0013 - val_loss: 0.0039\n",
      "Epoch 937/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0014 - val_loss: 0.0039\n",
      "Epoch 938/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0051\n",
      "Epoch 939/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0060\n",
      "Epoch 940/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0034\n",
      "Epoch 941/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0018 - val_loss: 0.0033\n",
      "Epoch 942/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0035\n",
      "Epoch 943/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0061\n",
      "Epoch 944/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0018 - val_loss: 0.0040\n",
      "Epoch 945/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 946/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0040\n",
      "Epoch 947/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0035\n",
      "Epoch 948/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0014 - val_loss: 0.0034\n",
      "Epoch 949/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0014 - val_loss: 0.0039\n",
      "Epoch 950/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0013 - val_loss: 0.0038\n",
      "Epoch 951/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 952/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0037\n",
      "Epoch 953/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0039\n",
      "Epoch 954/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0044\n",
      "Epoch 955/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0012 - val_loss: 0.0035\n",
      "Epoch 956/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0012 - val_loss: 0.0045\n",
      "Epoch 957/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0012 - val_loss: 0.0039\n",
      "Epoch 958/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0040\n",
      "Epoch 959/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0051\n",
      "Epoch 960/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 961/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 962/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0049\n",
      "Epoch 963/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0048\n",
      "Epoch 964/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0046\n",
      "Epoch 965/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0016 - val_loss: 0.0040\n",
      "Epoch 966/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 967/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0015 - val_loss: 0.0051\n",
      "Epoch 968/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0049\n",
      "Epoch 969/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0038\n",
      "Epoch 970/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0044\n",
      "Epoch 971/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0040\n",
      "Epoch 972/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0044\n",
      "Epoch 973/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0012 - val_loss: 0.0040\n",
      "Epoch 974/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0012 - val_loss: 0.0042\n",
      "Epoch 975/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0011 - val_loss: 0.0039\n",
      "Epoch 976/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0012 - val_loss: 0.0048\n",
      "Epoch 977/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0013 - val_loss: 0.0044\n",
      "Epoch 978/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0041\n",
      "Epoch 979/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0011 - val_loss: 0.0038\n",
      "Epoch 980/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0012 - val_loss: 0.0049\n",
      "Epoch 981/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0012 - val_loss: 0.0046\n",
      "Epoch 982/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0039\n",
      "Epoch 983/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 984/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0046\n",
      "Epoch 985/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0047\n",
      "Epoch 986/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 987/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0012 - val_loss: 0.0052\n",
      "Epoch 988/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0048\n",
      "Epoch 989/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0052\n",
      "Epoch 990/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 991/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0013 - val_loss: 0.0040\n",
      "Epoch 992/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0012 - val_loss: 0.0038\n",
      "Epoch 993/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0044\n",
      "Epoch 994/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 995/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0012 - val_loss: 0.0044\n",
      "Epoch 996/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0012 - val_loss: 0.0045\n",
      "Epoch 997/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0012 - val_loss: 0.0042\n",
      "Epoch 998/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0011 - val_loss: 0.0043\n",
      "Epoch 999/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0012 - val_loss: 0.0060\n",
      "Epoch 1000/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0017 - val_loss: 0.0056\n",
      "0.0053664036095142365\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-1.04212761e-01, -1.54211313e-01, -1.17019132e-01,\n",
       "         -6.55142665e-01, -3.82029384e-01,  2.49525383e-01,\n",
       "         -1.02312326e+00, -1.21020891e-01, -1.64541692e-01,\n",
       "         -6.66790485e-01],\n",
       "        [ 2.94268757e-01, -3.35404098e-01, -2.19164327e-01,\n",
       "         -8.25215816e-01,  1.31606713e-01,  2.81991102e-02,\n",
       "         -4.01895463e-01,  4.62316006e-01, -3.67710501e-01,\n",
       "          2.19327837e-01],\n",
       "        [ 1.12858322e-02, -3.06483328e-01, -2.50414938e-01,\n",
       "         -6.53700531e-01,  2.95567751e-01, -3.19169968e-01,\n",
       "          2.66283661e-01, -1.51329115e-01,  3.18544686e-01,\n",
       "          1.91502199e-01],\n",
       "        [-5.20174623e-01, -7.16784120e-01,  1.40636647e+00,\n",
       "         -3.64394754e-01, -1.51088035e+00,  9.48521018e-01,\n",
       "          1.01856577e+00, -8.04215372e-01, -4.15553421e-01,\n",
       "         -2.67472625e-01],\n",
       "        [ 2.66922176e-01, -7.15288222e-02, -1.44352570e-01,\n",
       "          3.47454041e-01, -4.21235412e-01,  3.19446437e-02,\n",
       "          2.85900712e-01, -3.35828245e-01, -4.21666056e-02,\n",
       "         -1.80642251e-02],\n",
       "        [ 1.93536520e-01,  3.30835342e-01, -1.07281685e-01,\n",
       "          3.86860222e-01,  5.88129342e-01, -3.23544592e-02,\n",
       "         -4.64143157e-01,  3.90027255e-01,  1.70249835e-01,\n",
       "         -2.73210943e-01],\n",
       "        [ 1.29736006e-01, -4.09600645e-01, -4.76466447e-01,\n",
       "          4.94785875e-01,  3.78731817e-01,  5.72449148e-01,\n",
       "          6.81419194e-01, -3.75318110e-01, -1.64426178e-01,\n",
       "          4.47772175e-01],\n",
       "        [-1.61564410e-01,  3.46230626e-01, -4.06269491e-01,\n",
       "          3.35009336e-01, -1.01806879e-01,  1.67349458e-01,\n",
       "          8.91943797e-02, -1.36387259e-01, -2.17693076e-01,\n",
       "         -1.87221020e-01],\n",
       "        [-2.52351791e-01,  1.40228838e-01, -2.87706465e-01,\n",
       "          1.57454193e+00,  1.63583666e-01,  2.12338060e-01,\n",
       "          8.90116811e-01,  2.92819440e-01,  1.40606225e-01,\n",
       "          2.65420437e-01],\n",
       "        [ 1.34244442e-01,  2.06663460e-01,  1.82025707e+00,\n",
       "         -9.47514176e-01,  4.13016856e-01,  1.69547752e-01,\n",
       "         -4.62076724e-01, -1.34916715e-02, -3.36640209e-01,\n",
       "          3.46367992e-02],\n",
       "        [-2.65474468e-01,  2.08332837e-01,  1.58970281e-01,\n",
       "          2.34713420e-01,  4.09576774e-01,  2.51162738e-01,\n",
       "          6.13574646e-02,  3.69529724e-01,  5.51146984e-01,\n",
       "          1.20269525e+00],\n",
       "        [-3.97376090e-01, -9.70860384e-03,  2.03614807e+00,\n",
       "         -1.38086602e-01, -4.05598849e-01, -5.20247042e-01,\n",
       "          1.08476806e+00, -7.52701342e-01,  5.80323162e-04,\n",
       "          4.89380844e-02],\n",
       "        [ 7.12098703e-02, -4.62926179e-01,  3.20272058e-01,\n",
       "         -1.12885058e-01, -3.26239198e-01, -4.29148316e-01,\n",
       "         -4.01816010e-01,  1.16488673e-01, -1.31737366e-01,\n",
       "          7.48990536e-01],\n",
       "        [-3.62045437e-01,  1.13370173e-01,  1.11467175e-01,\n",
       "          8.71673584e-01, -1.65514362e+00,  3.83022279e-01,\n",
       "         -9.23354685e-01,  4.80360799e-02, -2.39886492e-02,\n",
       "          1.22664332e-01],\n",
       "        [-1.57110363e-01,  2.56747147e-03, -5.90962134e-02,\n",
       "          7.29013979e-02, -1.15090996e-01, -2.60559976e-01,\n",
       "         -3.86192739e-01,  1.33096263e-01,  5.48451185e-01,\n",
       "         -1.28355533e-01],\n",
       "        [-3.74563426e-01,  4.28087026e-01,  3.76677632e-01,\n",
       "         -4.63716388e-01, -1.96052611e-01,  1.34155750e-01,\n",
       "         -6.06529057e-01,  5.52663542e-02, -5.71219660e-02,\n",
       "         -1.07343905e-02],\n",
       "        [ 1.86937168e-01,  3.42930615e-01,  4.51016486e-01,\n",
       "          2.30667507e-03, -5.88501990e-01,  1.34518677e-02,\n",
       "          7.93583810e-01, -7.44649172e-01,  2.03747138e-01,\n",
       "         -4.91013117e-02],\n",
       "        [ 1.78906396e-01,  3.01701993e-01, -1.27765253e-01,\n",
       "         -6.50859416e-01, -1.21842265e+00,  2.65223086e-01,\n",
       "          1.05695200e+00,  2.62181491e-01, -2.84718215e-01,\n",
       "         -1.20190769e-01],\n",
       "        [-1.91819251e-01, -8.21185037e-02, -1.42357051e+00,\n",
       "         -4.81626421e-01, -9.18892443e-01, -9.55187529e-03,\n",
       "         -6.02627754e-01, -4.77550060e-01,  5.03010035e-01,\n",
       "          7.56870389e-01],\n",
       "        [-1.98545754e-01, -2.26799518e-01,  3.97384644e-01,\n",
       "         -7.60439932e-02, -3.61026943e-01, -4.95136648e-01,\n",
       "          1.74793750e-01,  1.40496686e-01, -1.33043602e-01,\n",
       "          5.24222612e-01],\n",
       "        [-7.31654614e-02,  2.22852886e-01, -2.86402792e-01,\n",
       "         -7.82514691e-01, -6.12890363e-01, -3.88193130e-01,\n",
       "          1.22295737e+00,  4.09490556e-01,  1.07010379e-01,\n",
       "         -1.10370375e-01],\n",
       "        [ 2.17604846e-01, -3.73727590e-01,  5.39878547e-01,\n",
       "         -3.48940827e-02, -1.05071425e+00,  8.75049159e-02,\n",
       "          1.17342234e+00,  5.14201701e-01,  2.93495208e-01,\n",
       "         -3.77883716e-03]], dtype=float32),\n",
       " array([-0.0039928 ,  0.02654814, -0.01455273, -0.43990457, -0.0290205 ,\n",
       "        -0.09223626,  0.52629465, -0.13350055, -0.05512702,  0.06422294],\n",
       "       dtype=float32),\n",
       " array([[ 0.25986362, -0.31111997,  0.26623997, -0.09116307, -0.34415475],\n",
       "        [ 0.3610294 ,  0.11812419, -0.18305078, -0.33978784,  0.6053225 ],\n",
       "        [ 0.53983706, -0.02258646, -0.02610383, -0.11768902, -1.2088848 ],\n",
       "        [ 0.5645839 ,  0.54783875,  0.34529302, -0.79428446, -0.29112715],\n",
       "        [-0.3769993 , -0.6572393 , -0.60994387, -0.01485359,  0.4001332 ],\n",
       "        [-0.46529362,  0.05286128,  0.15092655, -0.33986917, -0.489245  ],\n",
       "        [-0.37621546, -0.5302506 ,  0.25889897, -0.02911759,  1.0915598 ],\n",
       "        [ 0.56155765, -0.06332055,  0.22052279, -0.78152055, -0.0162289 ],\n",
       "        [-0.09639653, -0.1747309 , -0.44451842, -0.5634228 , -0.25362733],\n",
       "        [ 0.21120639, -0.06150661,  0.07065769, -0.9099515 , -0.479471  ]],\n",
       "       dtype=float32),\n",
       " array([ 0.1198687 ,  0.13787265, -0.07986759, -0.04834222,  0.25866735],\n",
       "       dtype=float32),\n",
       " array([[ 0.15077318],\n",
       "        [ 0.23871504],\n",
       "        [ 0.04312178],\n",
       "        [-0.10720536],\n",
       "        [-0.3229513 ]], dtype=float32),\n",
       " array([0.15928581], dtype=float32)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_automobile, history_automobile, evaluate_automobile=NN_model_structure_regression_4(X_train_automobile, X_val_automobile, Y_train_automobile, Y_val_automobile, adam2, 32, 1000, x_test_automobile, y_test_automobile)\n",
    "model_automobile.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_automobile.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_automobile_structure4_4th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_49 (Dense)             (None, 10)                230       \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 351\n",
      "Trainable params: 351\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 143 samples, validate on 31 samples\n",
      "Epoch 1/1000\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.3358 - val_loss: 0.2043\n",
      "Epoch 2/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.1634 - val_loss: 0.0893\n",
      "Epoch 3/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.1072 - val_loss: 0.0267\n",
      "Epoch 4/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0668 - val_loss: 0.0251\n",
      "Epoch 5/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0466 - val_loss: 0.0409\n",
      "Epoch 6/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0316 - val_loss: 0.0221\n",
      "Epoch 7/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0294 - val_loss: 0.0142\n",
      "Epoch 8/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0226 - val_loss: 0.0083\n",
      "Epoch 9/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0217 - val_loss: 0.0087\n",
      "Epoch 10/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0194 - val_loss: 0.0107\n",
      "Epoch 11/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0142 - val_loss: 0.0100\n",
      "Epoch 12/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0145 - val_loss: 0.0085\n",
      "Epoch 13/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0148 - val_loss: 0.0064\n",
      "Epoch 14/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0119 - val_loss: 0.0059\n",
      "Epoch 15/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0109 - val_loss: 0.0054\n",
      "Epoch 16/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0110 - val_loss: 0.0050\n",
      "Epoch 17/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0100 - val_loss: 0.0047\n",
      "Epoch 18/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0103 - val_loss: 0.0047\n",
      "Epoch 19/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0103 - val_loss: 0.0046\n",
      "Epoch 20/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0092 - val_loss: 0.0046\n",
      "Epoch 21/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0092 - val_loss: 0.0051\n",
      "Epoch 22/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0088 - val_loss: 0.0046\n",
      "Epoch 23/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0079 - val_loss: 0.0046\n",
      "Epoch 24/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0078 - val_loss: 0.0045\n",
      "Epoch 25/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0075 - val_loss: 0.0045\n",
      "Epoch 26/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0076 - val_loss: 0.0047\n",
      "Epoch 27/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0075 - val_loss: 0.0055\n",
      "Epoch 28/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0078 - val_loss: 0.0053\n",
      "Epoch 29/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0074 - val_loss: 0.0053\n",
      "Epoch 30/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0072 - val_loss: 0.0051\n",
      "Epoch 31/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0072 - val_loss: 0.0061\n",
      "Epoch 32/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0073 - val_loss: 0.0049\n",
      "Epoch 33/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0069 - val_loss: 0.0050\n",
      "Epoch 34/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0069 - val_loss: 0.0059\n",
      "Epoch 35/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0082 - val_loss: 0.0079\n",
      "Epoch 36/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0087 - val_loss: 0.0098\n",
      "Epoch 37/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0086 - val_loss: 0.0061\n",
      "Epoch 38/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0072 - val_loss: 0.0056\n",
      "Epoch 39/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0065 - val_loss: 0.0053\n",
      "Epoch 40/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0070 - val_loss: 0.0051\n",
      "Epoch 41/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0067 - val_loss: 0.0055\n",
      "Epoch 42/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0064 - val_loss: 0.0054\n",
      "Epoch 43/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0068 - val_loss: 0.0061\n",
      "Epoch 44/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0064 - val_loss: 0.0061\n",
      "Epoch 45/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0074 - val_loss: 0.0065\n",
      "Epoch 46/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0068 - val_loss: 0.0056\n",
      "Epoch 47/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0070 - val_loss: 0.0067\n",
      "Epoch 48/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0072 - val_loss: 0.0073\n",
      "Epoch 49/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0067 - val_loss: 0.0055\n",
      "Epoch 50/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0065 - val_loss: 0.0054\n",
      "Epoch 51/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0062 - val_loss: 0.0061\n",
      "Epoch 52/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0064 - val_loss: 0.0059\n",
      "Epoch 53/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0067 - val_loss: 0.0058\n",
      "Epoch 54/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0060 - val_loss: 0.0054\n",
      "Epoch 55/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0068 - val_loss: 0.0054\n",
      "Epoch 56/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0068 - val_loss: 0.0062\n",
      "Epoch 57/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0061 - val_loss: 0.0057\n",
      "Epoch 58/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0058 - val_loss: 0.0071\n",
      "Epoch 59/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0069 - val_loss: 0.0054\n",
      "Epoch 60/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0069 - val_loss: 0.0056\n",
      "Epoch 61/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0065 - val_loss: 0.0065\n",
      "Epoch 62/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0061 - val_loss: 0.0053\n",
      "Epoch 63/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0063 - val_loss: 0.0057\n",
      "Epoch 64/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0066 - val_loss: 0.0061\n",
      "Epoch 65/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0056 - val_loss: 0.0054\n",
      "Epoch 66/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0057 - val_loss: 0.0055\n",
      "Epoch 67/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0057 - val_loss: 0.0053\n",
      "Epoch 68/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0058 - val_loss: 0.0053\n",
      "Epoch 69/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 110us/step - loss: 0.0061 - val_loss: 0.0058\n",
      "Epoch 70/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0072 - val_loss: 0.0080\n",
      "Epoch 71/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0068 - val_loss: 0.0057\n",
      "Epoch 72/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0062 - val_loss: 0.0054\n",
      "Epoch 73/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0057 - val_loss: 0.0053\n",
      "Epoch 74/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0060 - val_loss: 0.0056\n",
      "Epoch 75/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0062 - val_loss: 0.0067\n",
      "Epoch 76/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0057 - val_loss: 0.0054\n",
      "Epoch 77/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0061 - val_loss: 0.0055\n",
      "Epoch 78/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0057 - val_loss: 0.0056\n",
      "Epoch 79/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0066 - val_loss: 0.0063\n",
      "Epoch 80/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0059 - val_loss: 0.0094\n",
      "Epoch 81/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0081 - val_loss: 0.0053\n",
      "Epoch 82/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0061 - val_loss: 0.0053\n",
      "Epoch 83/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 84/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 85/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0049\n",
      "Epoch 86/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0057 - val_loss: 0.0052\n",
      "Epoch 87/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0055 - val_loss: 0.0056\n",
      "Epoch 88/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0052 - val_loss: 0.0053\n",
      "Epoch 89/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0052 - val_loss: 0.0055\n",
      "Epoch 90/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0056 - val_loss: 0.0054\n",
      "Epoch 91/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0052 - val_loss: 0.0053\n",
      "Epoch 92/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0055\n",
      "Epoch 93/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0052 - val_loss: 0.0054\n",
      "Epoch 94/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0057 - val_loss: 0.0056\n",
      "Epoch 95/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0055\n",
      "Epoch 96/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0054 - val_loss: 0.0054\n",
      "Epoch 97/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0059 - val_loss: 0.0055\n",
      "Epoch 98/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0052 - val_loss: 0.0055\n",
      "Epoch 99/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0050 - val_loss: 0.0053\n",
      "Epoch 100/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0049 - val_loss: 0.0056\n",
      "Epoch 101/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0051 - val_loss: 0.0052\n",
      "Epoch 102/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0050 - val_loss: 0.0053\n",
      "Epoch 103/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0047 - val_loss: 0.0063\n",
      "Epoch 104/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0053 - val_loss: 0.0061\n",
      "Epoch 105/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0058 - val_loss: 0.0058\n",
      "Epoch 106/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0049 - val_loss: 0.0068\n",
      "Epoch 107/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0053 - val_loss: 0.0049\n",
      "Epoch 108/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 109/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0049 - val_loss: 0.0051\n",
      "Epoch 110/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0047 - val_loss: 0.0051\n",
      "Epoch 111/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0046 - val_loss: 0.0071\n",
      "Epoch 112/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0052 - val_loss: 0.0052\n",
      "Epoch 113/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0045 - val_loss: 0.0064\n",
      "Epoch 114/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0051\n",
      "Epoch 115/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 116/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 117/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0044 - val_loss: 0.0056\n",
      "Epoch 118/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0045 - val_loss: 0.0053\n",
      "Epoch 119/1000\n",
      "143/143 [==============================] - 0s 129us/step - loss: 0.0044 - val_loss: 0.0058\n",
      "Epoch 120/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0051 - val_loss: 0.0076\n",
      "Epoch 121/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0052\n",
      "Epoch 122/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0057\n",
      "Epoch 123/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0052 - val_loss: 0.0058\n",
      "Epoch 124/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0041 - val_loss: 0.0053\n",
      "Epoch 125/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0053\n",
      "Epoch 126/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0068\n",
      "Epoch 127/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0044 - val_loss: 0.0053\n",
      "Epoch 128/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0055\n",
      "Epoch 129/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0042 - val_loss: 0.0054\n",
      "Epoch 130/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0039 - val_loss: 0.0051\n",
      "Epoch 131/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0040 - val_loss: 0.0061\n",
      "Epoch 132/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0055\n",
      "Epoch 133/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0041 - val_loss: 0.0052\n",
      "Epoch 134/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0051\n",
      "Epoch 135/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0038 - val_loss: 0.0054\n",
      "Epoch 136/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0039 - val_loss: 0.0054\n",
      "Epoch 137/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 138/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0040 - val_loss: 0.0051\n",
      "Epoch 139/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0071\n",
      "Epoch 140/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0050\n",
      "Epoch 141/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0043 - val_loss: 0.0053\n",
      "Epoch 142/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0039 - val_loss: 0.0071\n",
      "Epoch 143/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 144/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0046 - val_loss: 0.0055\n",
      "Epoch 145/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 146/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0083\n",
      "Epoch 147/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0054 - val_loss: 0.0046\n",
      "Epoch 148/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0049 - val_loss: 0.0056\n",
      "Epoch 149/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0047 - val_loss: 0.0054\n",
      "Epoch 150/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0044 - val_loss: 0.0057\n",
      "Epoch 151/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 152/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0043 - val_loss: 0.0042\n",
      "Epoch 153/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0042 - val_loss: 0.0051\n",
      "Epoch 154/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0067\n",
      "Epoch 155/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0041 - val_loss: 0.0043\n",
      "Epoch 156/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 157/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0047\n",
      "Epoch 158/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0034 - val_loss: 0.0051\n",
      "Epoch 159/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0087\n",
      "Epoch 160/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0049 - val_loss: 0.0045\n",
      "Epoch 161/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 162/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0038 - val_loss: 0.0072\n",
      "Epoch 163/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0045 - val_loss: 0.0042\n",
      "Epoch 164/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0035 - val_loss: 0.0043\n",
      "Epoch 165/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0041 - val_loss: 0.0067\n",
      "Epoch 166/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0040 - val_loss: 0.0044\n",
      "Epoch 167/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0047\n",
      "Epoch 168/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0046\n",
      "Epoch 169/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0043\n",
      "Epoch 170/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0071\n",
      "Epoch 171/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 172/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0032 - val_loss: 0.0047\n",
      "Epoch 173/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0032 - val_loss: 0.0052\n",
      "Epoch 174/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 175/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0034 - val_loss: 0.0054\n",
      "Epoch 176/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0038 - val_loss: 0.0056\n",
      "Epoch 177/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0051\n",
      "Epoch 178/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0052\n",
      "Epoch 179/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0037 - val_loss: 0.0062\n",
      "Epoch 180/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0036 - val_loss: 0.0047\n",
      "Epoch 181/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0033 - val_loss: 0.0048\n",
      "Epoch 182/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0039 - val_loss: 0.0042\n",
      "Epoch 183/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0031 - val_loss: 0.0041\n",
      "Epoch 184/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0066\n",
      "Epoch 185/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0049\n",
      "Epoch 186/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0048 - val_loss: 0.0058\n",
      "Epoch 187/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0043 - val_loss: 0.0075\n",
      "Epoch 188/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0035 - val_loss: 0.0043\n",
      "Epoch 189/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0032 - val_loss: 0.0041\n",
      "Epoch 190/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0031 - val_loss: 0.0061\n",
      "Epoch 191/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0034 - val_loss: 0.0044\n",
      "Epoch 192/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0027 - val_loss: 0.0042\n",
      "Epoch 193/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0033 - val_loss: 0.0045\n",
      "Epoch 194/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0033 - val_loss: 0.0058\n",
      "Epoch 195/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 196/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0044\n",
      "Epoch 197/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0030 - val_loss: 0.0048\n",
      "Epoch 198/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0027 - val_loss: 0.0042\n",
      "Epoch 199/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0028 - val_loss: 0.0041\n",
      "Epoch 200/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0030 - val_loss: 0.0052\n",
      "Epoch 201/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0033 - val_loss: 0.0047\n",
      "Epoch 202/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0033 - val_loss: 0.0068\n",
      "Epoch 203/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0031 - val_loss: 0.0039\n",
      "Epoch 204/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0027 - val_loss: 0.0042\n",
      "Epoch 205/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0028 - val_loss: 0.0044\n",
      "Epoch 206/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0052\n",
      "Epoch 207/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0030 - val_loss: 0.0048\n",
      "Epoch 208/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0025 - val_loss: 0.0042\n",
      "Epoch 209/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0046\n",
      "Epoch 210/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0024 - val_loss: 0.0040\n",
      "Epoch 211/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0046\n",
      "Epoch 212/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0025 - val_loss: 0.0041\n",
      "Epoch 213/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0042\n",
      "Epoch 214/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0023 - val_loss: 0.0043\n",
      "Epoch 215/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0023 - val_loss: 0.0043\n",
      "Epoch 216/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0024 - val_loss: 0.0041\n",
      "Epoch 217/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0025 - val_loss: 0.0045\n",
      "Epoch 218/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0039\n",
      "Epoch 219/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0024 - val_loss: 0.0039\n",
      "Epoch 220/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0039\n",
      "Epoch 221/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0049\n",
      "Epoch 222/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0056\n",
      "Epoch 223/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0040\n",
      "Epoch 224/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0035 - val_loss: 0.0052\n",
      "Epoch 225/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0041\n",
      "Epoch 226/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0051\n",
      "Epoch 227/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0047\n",
      "Epoch 228/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0038\n",
      "Epoch 229/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0022 - val_loss: 0.0042\n",
      "Epoch 230/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0023 - val_loss: 0.0055\n",
      "Epoch 231/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0029 - val_loss: 0.0046\n",
      "Epoch 232/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0031 - val_loss: 0.0039\n",
      "Epoch 233/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0028 - val_loss: 0.0061\n",
      "Epoch 234/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0040\n",
      "Epoch 235/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0024 - val_loss: 0.0038\n",
      "Epoch 236/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0023 - val_loss: 0.0042\n",
      "Epoch 237/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0026 - val_loss: 0.0038\n",
      "Epoch 238/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0028 - val_loss: 0.0062\n",
      "Epoch 239/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0026 - val_loss: 0.0038\n",
      "Epoch 240/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0037\n",
      "Epoch 241/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0024 - val_loss: 0.0043\n",
      "Epoch 242/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0027 - val_loss: 0.0039\n",
      "Epoch 243/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0023 - val_loss: 0.0051\n",
      "Epoch 244/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0035\n",
      "Epoch 245/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0036\n",
      "Epoch 246/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0037\n",
      "Epoch 247/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0022 - val_loss: 0.0039\n",
      "Epoch 248/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0036\n",
      "Epoch 249/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0021 - val_loss: 0.0061\n",
      "Epoch 250/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0030 - val_loss: 0.0040\n",
      "Epoch 251/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0022 - val_loss: 0.0034\n",
      "Epoch 252/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0022 - val_loss: 0.0037\n",
      "Epoch 253/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0044\n",
      "Epoch 254/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0023 - val_loss: 0.0036\n",
      "Epoch 255/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0025 - val_loss: 0.0034\n",
      "Epoch 256/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Epoch 257/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0021 - val_loss: 0.0039\n",
      "Epoch 258/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 259/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0038\n",
      "Epoch 260/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0020 - val_loss: 0.0041\n",
      "Epoch 261/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0043\n",
      "Epoch 262/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0038\n",
      "Epoch 263/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0038\n",
      "Epoch 264/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0020 - val_loss: 0.0039\n",
      "Epoch 265/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0019 - val_loss: 0.0038\n",
      "Epoch 266/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0041\n",
      "Epoch 267/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0019 - val_loss: 0.0039\n",
      "Epoch 268/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0018 - val_loss: 0.0038\n",
      "Epoch 269/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0041\n",
      "Epoch 270/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0036\n",
      "Epoch 271/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0041\n",
      "Epoch 272/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0018 - val_loss: 0.0037\n",
      "Epoch 273/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0037\n",
      "Epoch 274/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0035\n",
      "Epoch 275/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0036\n",
      "Epoch 276/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0051\n",
      "Epoch 277/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.001 - 0s 119us/step - loss: 0.0026 - val_loss: 0.0054\n",
      "Epoch 278/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0029 - val_loss: 0.0039\n",
      "Epoch 279/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0020 - val_loss: 0.0036\n",
      "Epoch 280/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0023 - val_loss: 0.0034\n",
      "Epoch 281/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 282/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0021 - val_loss: 0.0036\n",
      "Epoch 283/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0019 - val_loss: 0.0035\n",
      "Epoch 284/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 285/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0035\n",
      "Epoch 286/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0038\n",
      "Epoch 287/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0060\n",
      "Epoch 288/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0023 - val_loss: 0.0037\n",
      "Epoch 289/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0020 - val_loss: 0.0037\n",
      "Epoch 290/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0020 - val_loss: 0.0039\n",
      "Epoch 291/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0049\n",
      "Epoch 292/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0037\n",
      "Epoch 293/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0036\n",
      "Epoch 294/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0021 - val_loss: 0.0037\n",
      "Epoch 295/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0022 - val_loss: 0.0033\n",
      "Epoch 296/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0035\n",
      "Epoch 297/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0048\n",
      "Epoch 298/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0041\n",
      "Epoch 299/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0036\n",
      "Epoch 300/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 301/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0038\n",
      "Epoch 302/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 303/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0064\n",
      "Epoch 304/1000\n",
      "143/143 [==============================] - 0s 140us/step - loss: 0.0025 - val_loss: 0.0038\n",
      "Epoch 305/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0033\n",
      "Epoch 306/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0018 - val_loss: 0.0033\n",
      "Epoch 307/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0035\n",
      "Epoch 308/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0035\n",
      "Epoch 309/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0037\n",
      "Epoch 310/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0041\n",
      "Epoch 311/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0039\n",
      "Epoch 312/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0040\n",
      "Epoch 313/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0047\n",
      "Epoch 314/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0035\n",
      "Epoch 315/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0035\n",
      "Epoch 316/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 317/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 318/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0044\n",
      "Epoch 319/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0041\n",
      "Epoch 320/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0019 - val_loss: 0.0038\n",
      "Epoch 321/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0062\n",
      "Epoch 322/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0037 - val_loss: 0.0042\n",
      "Epoch 323/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0040 - val_loss: 0.0037\n",
      "Epoch 324/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0021 - val_loss: 0.0050\n",
      "Epoch 325/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0034\n",
      "Epoch 326/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0018 - val_loss: 0.0034\n",
      "Epoch 327/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0021 - val_loss: 0.0035\n",
      "Epoch 328/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 329/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0041\n",
      "Epoch 330/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0033\n",
      "Epoch 331/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 332/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 333/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 334/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0020 - val_loss: 0.0039\n",
      "Epoch 335/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0042\n",
      "Epoch 336/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0034\n",
      "Epoch 337/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0036\n",
      "Epoch 338/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0041\n",
      "Epoch 339/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0039\n",
      "Epoch 340/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0017 - val_loss: 0.0065\n",
      "Epoch 341/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0032 - val_loss: 0.0072\n",
      "Epoch 342/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0046\n",
      "Epoch 343/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0029 - val_loss: 0.0038\n",
      "Epoch 344/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0046\n",
      "Epoch 345/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 346/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0021 - val_loss: 0.0065\n",
      "Epoch 347/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0034\n",
      "Epoch 348/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0025 - val_loss: 0.0055\n",
      "Epoch 349/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0037 - val_loss: 0.0075\n",
      "Epoch 350/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0041 - val_loss: 0.0057\n",
      "Epoch 351/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0037 - val_loss: 0.0049\n",
      "Epoch 352/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 353/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0022 - val_loss: 0.0044\n",
      "Epoch 354/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0019 - val_loss: 0.0035\n",
      "Epoch 355/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0040\n",
      "Epoch 356/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0034\n",
      "Epoch 357/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0033\n",
      "Epoch 358/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0040\n",
      "Epoch 359/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0033\n",
      "Epoch 360/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0040\n",
      "Epoch 361/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0034\n",
      "Epoch 362/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0035\n",
      "Epoch 363/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0035\n",
      "Epoch 364/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0016 - val_loss: 0.0040\n",
      "Epoch 365/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0034\n",
      "Epoch 366/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 367/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0019 - val_loss: 0.0036\n",
      "Epoch 368/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0017 - val_loss: 0.0033\n",
      "Epoch 369/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0017 - val_loss: 0.0033\n",
      "Epoch 370/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0038\n",
      "Epoch 371/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0034\n",
      "Epoch 372/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0033\n",
      "Epoch 373/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0035\n",
      "Epoch 374/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0034\n",
      "Epoch 375/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0040\n",
      "Epoch 376/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 377/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 108us/step - loss: 0.0017 - val_loss: 0.0033\n",
      "Epoch 378/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 379/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0033\n",
      "Epoch 380/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 381/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0016 - val_loss: 0.0035\n",
      "Epoch 382/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 383/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0020 - val_loss: 0.0038\n",
      "Epoch 384/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0043\n",
      "Epoch 385/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0024 - val_loss: 0.0032\n",
      "Epoch 386/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0019 - val_loss: 0.0034\n",
      "Epoch 387/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 388/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0017 - val_loss: 0.0037\n",
      "Epoch 389/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0016 - val_loss: 0.0033\n",
      "Epoch 390/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0034\n",
      "Epoch 391/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0019 - val_loss: 0.0061\n",
      "Epoch 392/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0024 - val_loss: 0.0038\n",
      "Epoch 393/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0017 - val_loss: 0.0038\n",
      "Epoch 394/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0022 - val_loss: 0.0032\n",
      "Epoch 395/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 396/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0037\n",
      "Epoch 397/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 398/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0018 - val_loss: 0.0034\n",
      "Epoch 399/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0015 - val_loss: 0.0036\n",
      "Epoch 400/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0034\n",
      "Epoch 401/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0016 - val_loss: 0.0033\n",
      "Epoch 402/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0014 - val_loss: 0.0038\n",
      "Epoch 403/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 404/1000\n",
      "143/143 [==============================] - 0s 99us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 405/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0018 - val_loss: 0.0036\n",
      "Epoch 406/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0037\n",
      "Epoch 407/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0035\n",
      "Epoch 408/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0034\n",
      "Epoch 409/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 410/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0037\n",
      "Epoch 411/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0014 - val_loss: 0.0036\n",
      "Epoch 412/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 413/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0015 - val_loss: 0.0035\n",
      "Epoch 414/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0038\n",
      "Epoch 415/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0024 - val_loss: 0.0039\n",
      "Epoch 416/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0020 - val_loss: 0.0039\n",
      "Epoch 417/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0017 - val_loss: 0.0035\n",
      "Epoch 418/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0036\n",
      "Epoch 419/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 420/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0021 - val_loss: 0.0032\n",
      "Epoch 421/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0035\n",
      "Epoch 422/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0016 - val_loss: 0.0050\n",
      "Epoch 423/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0021 - val_loss: 0.0046\n",
      "Epoch 424/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0018 - val_loss: 0.0036\n",
      "Epoch 425/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0032\n",
      "Epoch 426/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0037\n",
      "Epoch 427/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0014 - val_loss: 0.0037\n",
      "Epoch 428/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0015 - val_loss: 0.0036\n",
      "Epoch 429/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0035\n",
      "Epoch 430/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0014 - val_loss: 0.0049\n",
      "Epoch 431/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 432/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0036\n",
      "Epoch 433/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0038\n",
      "Epoch 434/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0035\n",
      "Epoch 435/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0018 - val_loss: 0.0040\n",
      "Epoch 436/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 437/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 438/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0037\n",
      "Epoch 439/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0034\n",
      "Epoch 440/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0035\n",
      "Epoch 441/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0034\n",
      "Epoch 442/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0037\n",
      "Epoch 443/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0036\n",
      "Epoch 444/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 445/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0036\n",
      "Epoch 446/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0017 - val_loss: 0.0039\n",
      "Epoch 447/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 448/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 449/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 450/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0016 - val_loss: 0.0040\n",
      "Epoch 451/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0036\n",
      "Epoch 452/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0036\n",
      "Epoch 453/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0014 - val_loss: 0.0034\n",
      "Epoch 454/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 110us/step - loss: 0.0018 - val_loss: 0.0038\n",
      "Epoch 455/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 456/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0014 - val_loss: 0.0036\n",
      "Epoch 457/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 458/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 459/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0035\n",
      "Epoch 460/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0035\n",
      "Epoch 461/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0016 - val_loss: 0.0036\n",
      "Epoch 462/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 463/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0036\n",
      "Epoch 464/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0014 - val_loss: 0.0045\n",
      "Epoch 465/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 466/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0035\n",
      "Epoch 467/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0017 - val_loss: 0.0040\n",
      "Epoch 468/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0050\n",
      "Epoch 469/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 470/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0018 - val_loss: 0.0036\n",
      "Epoch 471/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 472/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0022 - val_loss: 0.0048\n",
      "Epoch 473/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0038 - val_loss: 0.0044\n",
      "Epoch 474/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0023 - val_loss: 0.0058\n",
      "Epoch 475/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0034 - val_loss: 0.0031\n",
      "Epoch 476/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0035\n",
      "Epoch 477/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0037\n",
      "Epoch 478/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0034\n",
      "Epoch 479/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0017 - val_loss: 0.0039\n",
      "Epoch 480/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0055\n",
      "Epoch 481/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0032\n",
      "Epoch 482/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0036\n",
      "Epoch 483/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 484/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 485/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0014 - val_loss: 0.0033\n",
      "Epoch 486/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0013 - val_loss: 0.0038\n",
      "Epoch 487/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0013 - val_loss: 0.0039\n",
      "Epoch 488/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0047\n",
      "Epoch 489/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0038\n",
      "Epoch 490/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0037\n",
      "Epoch 491/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0018 - val_loss: 0.0048\n",
      "Epoch 492/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0037\n",
      "Epoch 493/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0025 - val_loss: 0.0064\n",
      "Epoch 494/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0026 - val_loss: 0.0047\n",
      "Epoch 495/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0022 - val_loss: 0.0034\n",
      "Epoch 496/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0018 - val_loss: 0.0038\n",
      "Epoch 497/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0018 - val_loss: 0.0040\n",
      "Epoch 498/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 499/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0016 - val_loss: 0.0032\n",
      "Epoch 500/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0019 - val_loss: 0.0034\n",
      "Epoch 501/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 502/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0039\n",
      "Epoch 503/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0034\n",
      "Epoch 504/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0037\n",
      "Epoch 505/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0014 - val_loss: 0.0036\n",
      "Epoch 506/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 507/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0037\n",
      "Epoch 508/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0040\n",
      "Epoch 509/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0036\n",
      "Epoch 510/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0013 - val_loss: 0.0035\n",
      "Epoch 511/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0013 - val_loss: 0.0037\n",
      "Epoch 512/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0014 - val_loss: 0.0037\n",
      "Epoch 513/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 514/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0013 - val_loss: 0.0034\n",
      "Epoch 515/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0012 - val_loss: 0.0039\n",
      "Epoch 516/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 517/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 518/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0036\n",
      "Epoch 519/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0013 - val_loss: 0.0038\n",
      "Epoch 520/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0013 - val_loss: 0.0045\n",
      "Epoch 521/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0042\n",
      "Epoch 522/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0018 - val_loss: 0.0056\n",
      "Epoch 523/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0050\n",
      "Epoch 524/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0037\n",
      "Epoch 525/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0014 - val_loss: 0.0034\n",
      "Epoch 526/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0018 - val_loss: 0.0034\n",
      "Epoch 527/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0016 - val_loss: 0.0053\n",
      "Epoch 528/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0018 - val_loss: 0.0036\n",
      "Epoch 529/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0021 - val_loss: 0.0043\n",
      "Epoch 530/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0022 - val_loss: 0.0039\n",
      "Epoch 531/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0036\n",
      "Epoch 532/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0038\n",
      "Epoch 533/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0016 - val_loss: 0.0037\n",
      "Epoch 534/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0035\n",
      "Epoch 535/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 536/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0022 - val_loss: 0.0036\n",
      "Epoch 537/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0013 - val_loss: 0.0037\n",
      "Epoch 538/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0013 - val_loss: 0.0035\n",
      "Epoch 539/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0035\n",
      "Epoch 540/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0013 - val_loss: 0.0036\n",
      "Epoch 541/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0013 - val_loss: 0.0037\n",
      "Epoch 542/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0044\n",
      "Epoch 543/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0035\n",
      "Epoch 544/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0012 - val_loss: 0.0036\n",
      "Epoch 545/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0012 - val_loss: 0.0037\n",
      "Epoch 546/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0037\n",
      "Epoch 547/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0037\n",
      "Epoch 548/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0012 - val_loss: 0.0038\n",
      "Epoch 549/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0012 - val_loss: 0.0038\n",
      "Epoch 550/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0012 - val_loss: 0.0036\n",
      "Epoch 551/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0011 - val_loss: 0.0037\n",
      "Epoch 552/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0012 - val_loss: 0.0037\n",
      "Epoch 553/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0038\n",
      "Epoch 554/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0011 - val_loss: 0.0036\n",
      "Epoch 555/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0038\n",
      "Epoch 556/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 557/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 558/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0037\n",
      "Epoch 559/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 560/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0023 - val_loss: 0.0049\n",
      "Epoch 561/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0037\n",
      "Epoch 562/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0058\n",
      "Epoch 563/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0044\n",
      "Epoch 564/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0013 - val_loss: 0.0035\n",
      "Epoch 565/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 566/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0013 - val_loss: 0.0035\n",
      "Epoch 567/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0013 - val_loss: 0.0040\n",
      "Epoch 568/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0036\n",
      "Epoch 569/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0013 - val_loss: 0.0035\n",
      "Epoch 570/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0038\n",
      "Epoch 571/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0012 - val_loss: 0.0033\n",
      "Epoch 572/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0014 - val_loss: 0.0035\n",
      "Epoch 573/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0013 - val_loss: 0.0047\n",
      "Epoch 574/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0013 - val_loss: 0.0037\n",
      "Epoch 575/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0014 - val_loss: 0.0034\n",
      "Epoch 576/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0014 - val_loss: 0.0037\n",
      "Epoch 577/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 578/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0037\n",
      "Epoch 579/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0039\n",
      "Epoch 580/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0013 - val_loss: 0.0036\n",
      "Epoch 581/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0036\n",
      "Epoch 582/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0012 - val_loss: 0.0043\n",
      "Epoch 583/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0037\n",
      "Epoch 584/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0015 - val_loss: 0.0055\n",
      "Epoch 585/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0018 - val_loss: 0.0038\n",
      "Epoch 586/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0037\n",
      "Epoch 587/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 588/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0037\n",
      "Epoch 589/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0034\n",
      "Epoch 590/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0013 - val_loss: 0.0035\n",
      "Epoch 591/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0044\n",
      "Epoch 592/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0040\n",
      "Epoch 593/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 594/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0021 - val_loss: 0.0035\n",
      "Epoch 595/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0016 - val_loss: 0.0047\n",
      "Epoch 596/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0016 - val_loss: 0.0036\n",
      "Epoch 597/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0017 - val_loss: 0.0035\n",
      "Epoch 598/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0018 - val_loss: 0.0036\n",
      "Epoch 599/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 600/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0016 - val_loss: 0.0034\n",
      "Epoch 601/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0012 - val_loss: 0.0038\n",
      "Epoch 602/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0013 - val_loss: 0.0039\n",
      "Epoch 603/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0013 - val_loss: 0.0035\n",
      "Epoch 604/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0016 - val_loss: 0.0037\n",
      "Epoch 605/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0019 - val_loss: 0.0056\n",
      "Epoch 606/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0020 - val_loss: 0.0047\n",
      "Epoch 607/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0017 - val_loss: 0.0039\n",
      "Epoch 608/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0039\n",
      "Epoch 609/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0013 - val_loss: 0.0034\n",
      "Epoch 610/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0013 - val_loss: 0.0050\n",
      "Epoch 611/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 612/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0020 - val_loss: 0.0038\n",
      "Epoch 613/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0017 - val_loss: 0.0037\n",
      "Epoch 614/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0016 - val_loss: 0.0040\n",
      "Epoch 615/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0013 - val_loss: 0.0037\n",
      "Epoch 616/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0015 - val_loss: 0.0036\n",
      "Epoch 617/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0012 - val_loss: 0.0039\n",
      "Epoch 618/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0035\n",
      "Epoch 619/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0012 - val_loss: 0.0037\n",
      "Epoch 620/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0040\n",
      "Epoch 621/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0016 - val_loss: 0.0035\n",
      "Epoch 622/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0013 - val_loss: 0.0039\n",
      "Epoch 623/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0039\n",
      "Epoch 624/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0012 - val_loss: 0.0034\n",
      "Epoch 625/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0012 - val_loss: 0.0046\n",
      "Epoch 626/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0014 - val_loss: 0.0035\n",
      "Epoch 627/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0036\n",
      "Epoch 628/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0013 - val_loss: 0.0048\n",
      "Epoch 629/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0017 - val_loss: 0.0035\n",
      "Epoch 630/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 631/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0015 - val_loss: 0.0056\n",
      "Epoch 632/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0016 - val_loss: 0.0037\n",
      "Epoch 633/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0013 - val_loss: 0.0048\n",
      "Epoch 634/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0025 - val_loss: 0.0044\n",
      "Epoch 635/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0016 - val_loss: 0.0035\n",
      "Epoch 636/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0013 - val_loss: 0.0046\n",
      "Epoch 637/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 638/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0014 - val_loss: 0.0038\n",
      "Epoch 639/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0035\n",
      "Epoch 640/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0011 - val_loss: 0.0036\n",
      "Epoch 641/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0012 - val_loss: 0.0040\n",
      "Epoch 642/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0011 - val_loss: 0.0038\n",
      "Epoch 643/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 644/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0012 - val_loss: 0.0042\n",
      "Epoch 645/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0034\n",
      "Epoch 646/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0012 - val_loss: 0.0036\n",
      "Epoch 647/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0012 - val_loss: 0.0037\n",
      "Epoch 648/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0011 - val_loss: 0.0036\n",
      "Epoch 649/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0013 - val_loss: 0.0036\n",
      "Epoch 650/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0039\n",
      "Epoch 651/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0011 - val_loss: 0.0036\n",
      "Epoch 652/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0037\n",
      "Epoch 653/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0034\n",
      "Epoch 654/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0011 - val_loss: 0.0039\n",
      "Epoch 655/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0011 - val_loss: 0.0043\n",
      "Epoch 656/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0017 - val_loss: 0.0037\n",
      "Epoch 657/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0014 - val_loss: 0.0050\n",
      "Epoch 658/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0019 - val_loss: 0.0053\n",
      "Epoch 659/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0039\n",
      "Epoch 660/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 661/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0015 - val_loss: 0.0037\n",
      "Epoch 662/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0041\n",
      "Epoch 663/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 664/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0037\n",
      "Epoch 665/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0038\n",
      "Epoch 666/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0011 - val_loss: 0.0037\n",
      "Epoch 667/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0039\n",
      "Epoch 668/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0038\n",
      "Epoch 669/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0012 - val_loss: 0.0039\n",
      "Epoch 670/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0014 - val_loss: 0.0038\n",
      "Epoch 671/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0012 - val_loss: 0.0047\n",
      "Epoch 672/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0055\n",
      "Epoch 673/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 674/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0034\n",
      "Epoch 675/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0037\n",
      "Epoch 676/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0014 - val_loss: 0.0038\n",
      "Epoch 677/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0013 - val_loss: 0.0038\n",
      "Epoch 678/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0012 - val_loss: 0.0036\n",
      "Epoch 679/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0012 - val_loss: 0.0035\n",
      "Epoch 680/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0012 - val_loss: 0.0040\n",
      "Epoch 681/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0012 - val_loss: 0.0046\n",
      "Epoch 682/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0047\n",
      "Epoch 683/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0039\n",
      "Epoch 684/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 685/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 115us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 686/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 687/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0013 - val_loss: 0.0038\n",
      "Epoch 688/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0014 - val_loss: 0.0039\n",
      "Epoch 689/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0037\n",
      "Epoch 690/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0017 - val_loss: 0.0036\n",
      "Epoch 691/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0014 - val_loss: 0.0052\n",
      "Epoch 692/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0015 - val_loss: 0.0037\n",
      "Epoch 693/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0015 - val_loss: 0.0035\n",
      "Epoch 694/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 695/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 696/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0013 - val_loss: 0.0040\n",
      "Epoch 697/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0011 - val_loss: 0.0037\n",
      "Epoch 698/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0037\n",
      "Epoch 699/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0011 - val_loss: 0.0041\n",
      "Epoch 700/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0012 - val_loss: 0.0042\n",
      "Epoch 701/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0012 - val_loss: 0.0036\n",
      "Epoch 702/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0012 - val_loss: 0.0041\n",
      "Epoch 703/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0040\n",
      "Epoch 704/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0039\n",
      "Epoch 705/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0012 - val_loss: 0.0044\n",
      "Epoch 706/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0013 - val_loss: 0.0047\n",
      "Epoch 707/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0039\n",
      "Epoch 708/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0012 - val_loss: 0.0037\n",
      "Epoch 709/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0039\n",
      "Epoch 710/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0011 - val_loss: 0.0039\n",
      "Epoch 711/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0010 - val_loss: 0.0039\n",
      "Epoch 712/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0010 - val_loss: 0.0039\n",
      "Epoch 713/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0012 - val_loss: 0.0035\n",
      "Epoch 714/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0011 - val_loss: 0.0041\n",
      "Epoch 715/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0011 - val_loss: 0.0040\n",
      "Epoch 716/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0042\n",
      "Epoch 717/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0014 - val_loss: 0.0046\n",
      "Epoch 718/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0013 - val_loss: 0.0044\n",
      "Epoch 719/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0039\n",
      "Epoch 720/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0042\n",
      "Epoch 721/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0020 - val_loss: 0.0039\n",
      "Epoch 722/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0015 - val_loss: 0.0040\n",
      "Epoch 723/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0013 - val_loss: 0.0045\n",
      "Epoch 724/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0046\n",
      "Epoch 725/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0018 - val_loss: 0.0039\n",
      "Epoch 726/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0015 - val_loss: 0.0037\n",
      "Epoch 727/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0013 - val_loss: 0.0036\n",
      "Epoch 728/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0013 - val_loss: 0.0044\n",
      "Epoch 729/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0034\n",
      "Epoch 730/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0011 - val_loss: 0.0045\n",
      "Epoch 731/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 732/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0011 - val_loss: 0.0040\n",
      "Epoch 733/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0011 - val_loss: 0.0036\n",
      "Epoch 734/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0012 - val_loss: 0.0039\n",
      "Epoch 735/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 736/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0047\n",
      "Epoch 737/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0015 - val_loss: 0.0051\n",
      "Epoch 738/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0047\n",
      "Epoch 739/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0014 - val_loss: 0.0038\n",
      "Epoch 740/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0017 - val_loss: 0.0042\n",
      "Epoch 741/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0016 - val_loss: 0.0040\n",
      "Epoch 742/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0014 - val_loss: 0.0047\n",
      "Epoch 743/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0011 - val_loss: 0.0033\n",
      "Epoch 744/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 745/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0012 - val_loss: 0.0038\n",
      "Epoch 746/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0011 - val_loss: 0.0041\n",
      "Epoch 747/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0011 - val_loss: 0.0046\n",
      "Epoch 748/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 749/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0037\n",
      "Epoch 750/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0013 - val_loss: 0.0039\n",
      "Epoch 751/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0011 - val_loss: 0.0040\n",
      "Epoch 752/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0010 - val_loss: 0.0041\n",
      "Epoch 753/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0011 - val_loss: 0.0040\n",
      "Epoch 754/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0012 - val_loss: 0.0041\n",
      "Epoch 755/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0010 - val_loss: 0.0040\n",
      "Epoch 756/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0010 - val_loss: 0.0041\n",
      "Epoch 757/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0011 - val_loss: 0.0040\n",
      "Epoch 758/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0039\n",
      "Epoch 759/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 760/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0010 - val_loss: 0.0047\n",
      "Epoch 761/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0011 - val_loss: 0.0042\n",
      "Epoch 762/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 118us/step - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 763/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0011 - val_loss: 0.0041\n",
      "Epoch 764/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0011 - val_loss: 0.0042\n",
      "Epoch 765/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0011 - val_loss: 0.0038\n",
      "Epoch 766/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0054\n",
      "Epoch 767/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 768/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0012 - val_loss: 0.0041\n",
      "Epoch 769/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0012 - val_loss: 0.0043\n",
      "Epoch 770/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 771/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0013 - val_loss: 0.0040\n",
      "Epoch 772/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 773/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 774/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0010 - val_loss: 0.0046\n",
      "Epoch 775/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0053\n",
      "Epoch 776/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0013 - val_loss: 0.0040\n",
      "Epoch 777/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0011 - val_loss: 0.0041\n",
      "Epoch 778/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0040\n",
      "Epoch 779/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0010 - val_loss: 0.0038\n",
      "Epoch 780/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0012 - val_loss: 0.0041\n",
      "Epoch 781/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0013 - val_loss: 0.0046\n",
      "Epoch 782/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0011 - val_loss: 0.0046\n",
      "Epoch 783/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0041\n",
      "Epoch 784/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0011 - val_loss: 0.0045\n",
      "Epoch 785/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0039\n",
      "Epoch 786/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0047\n",
      "Epoch 787/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0014 - val_loss: 0.0053\n",
      "Epoch 788/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 789/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0016 - val_loss: 0.0047\n",
      "Epoch 790/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0012 - val_loss: 0.0042\n",
      "Epoch 791/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 792/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0018 - val_loss: 0.0038\n",
      "Epoch 793/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0047\n",
      "Epoch 794/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0013 - val_loss: 0.0040\n",
      "Epoch 795/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0044\n",
      "Epoch 796/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0011 - val_loss: 0.0039\n",
      "Epoch 797/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0040\n",
      "Epoch 798/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0012 - val_loss: 0.0041\n",
      "Epoch 799/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0011 - val_loss: 0.0044\n",
      "Epoch 800/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0012 - val_loss: 0.0047\n",
      "Epoch 801/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0056\n",
      "Epoch 802/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0014 - val_loss: 0.0037\n",
      "Epoch 803/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0012 - val_loss: 0.0051\n",
      "Epoch 804/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0012 - val_loss: 0.0038\n",
      "Epoch 805/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0012 - val_loss: 0.0038\n",
      "Epoch 806/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0010 - val_loss: 0.0045\n",
      "Epoch 807/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0010 - val_loss: 0.0040\n",
      "Epoch 808/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0010 - val_loss: 0.0039\n",
      "Epoch 809/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0010 - val_loss: 0.0039\n",
      "Epoch 810/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 9.9266e-04 - val_loss: 0.0042\n",
      "Epoch 811/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0011 - val_loss: 0.0044\n",
      "Epoch 812/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0012 - val_loss: 0.0042\n",
      "Epoch 813/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0012 - val_loss: 0.0043\n",
      "Epoch 814/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0010 - val_loss: 0.0041\n",
      "Epoch 815/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 9.8195e-04 - val_loss: 0.0043\n",
      "Epoch 816/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0011 - val_loss: 0.0049\n",
      "Epoch 817/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0011 - val_loss: 0.0039\n",
      "Epoch 818/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0014 - val_loss: 0.0037\n",
      "Epoch 819/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0013 - val_loss: 0.0049\n",
      "Epoch 820/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0016 - val_loss: 0.0040\n",
      "Epoch 821/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0014 - val_loss: 0.0039\n",
      "Epoch 822/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0012 - val_loss: 0.0045\n",
      "Epoch 823/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0012 - val_loss: 0.0045\n",
      "Epoch 824/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 825/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 826/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0016 - val_loss: 0.0047\n",
      "Epoch 827/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 828/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0045\n",
      "Epoch 829/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0017 - val_loss: 0.0053\n",
      "Epoch 830/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0046\n",
      "Epoch 831/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0013 - val_loss: 0.0044\n",
      "Epoch 832/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 833/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0053\n",
      "Epoch 834/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0018 - val_loss: 0.0042\n",
      "Epoch 835/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0014 - val_loss: 0.0038\n",
      "Epoch 836/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0047\n",
      "Epoch 837/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0039\n",
      "Epoch 838/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0010 - val_loss: 0.0038\n",
      "Epoch 839/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 106us/step - loss: 9.8073e-04 - val_loss: 0.0044\n",
      "Epoch 840/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0050\n",
      "Epoch 841/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0014 - val_loss: 0.0046\n",
      "Epoch 842/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0043\n",
      "Epoch 843/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 844/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0039\n",
      "Epoch 845/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0011 - val_loss: 0.0041\n",
      "Epoch 846/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0011 - val_loss: 0.0048\n",
      "Epoch 847/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0039\n",
      "Epoch 848/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0011 - val_loss: 0.0041\n",
      "Epoch 849/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 850/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0010 - val_loss: 0.0040\n",
      "Epoch 851/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 9.9486e-04 - val_loss: 0.0042\n",
      "Epoch 852/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 9.9079e-04 - val_loss: 0.0048\n",
      "Epoch 853/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0046\n",
      "Epoch 854/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0012 - val_loss: 0.0041\n",
      "Epoch 855/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0012 - val_loss: 0.0043\n",
      "Epoch 856/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 9.7122e-04 - val_loss: 0.0042\n",
      "Epoch 857/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0012 - val_loss: 0.0042\n",
      "Epoch 858/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 9.9691e-04 - val_loss: 0.0041\n",
      "Epoch 859/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 9.9661e-04 - val_loss: 0.0044\n",
      "Epoch 860/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 9.6288e-04 - val_loss: 0.0048\n",
      "Epoch 861/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0011 - val_loss: 0.0049\n",
      "Epoch 862/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 863/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0045\n",
      "Epoch 864/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 865/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 866/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0015 - val_loss: 0.0057\n",
      "Epoch 867/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0042\n",
      "Epoch 868/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0014 - val_loss: 0.0045\n",
      "Epoch 869/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0013 - val_loss: 0.0039\n",
      "Epoch 870/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 871/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0049\n",
      "Epoch 872/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0040\n",
      "Epoch 873/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 9.9567e-04 - val_loss: 0.0039\n",
      "Epoch 874/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 9.8973e-04 - val_loss: 0.0050\n",
      "Epoch 875/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0012 - val_loss: 0.0049\n",
      "Epoch 876/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 877/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0012 - val_loss: 0.0044\n",
      "Epoch 878/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0042\n",
      "Epoch 879/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 9.8260e-04 - val_loss: 0.0040\n",
      "Epoch 880/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 9.5070e-04 - val_loss: 0.0041\n",
      "Epoch 881/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0011 - val_loss: 0.0047\n",
      "Epoch 882/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0044\n",
      "Epoch 883/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 884/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0017 - val_loss: 0.0051\n",
      "Epoch 885/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0056\n",
      "Epoch 886/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 887/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0040\n",
      "Epoch 888/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0012 - val_loss: 0.0042\n",
      "Epoch 889/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0011 - val_loss: 0.0047\n",
      "Epoch 890/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 9.8580e-04 - val_loss: 0.0039\n",
      "Epoch 891/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0011 - val_loss: 0.0043\n",
      "Epoch 892/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 9.5127e-04 - val_loss: 0.0045\n",
      "Epoch 893/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0010 - val_loss: 0.0043\n",
      "Epoch 894/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0011 - val_loss: 0.0043\n",
      "Epoch 895/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0040\n",
      "Epoch 896/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0011 - val_loss: 0.0040\n",
      "Epoch 897/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 9.4067e-04 - val_loss: 0.0046\n",
      "Epoch 898/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0012 - val_loss: 0.0047\n",
      "Epoch 899/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0044\n",
      "Epoch 900/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0043\n",
      "Epoch 901/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0011 - val_loss: 0.0042\n",
      "Epoch 902/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0010 - val_loss: 0.0042\n",
      "Epoch 903/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0011 - val_loss: 0.0042\n",
      "Epoch 904/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0011 - val_loss: 0.0044\n",
      "Epoch 905/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 9.3224e-04 - val_loss: 0.0040\n",
      "Epoch 906/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 9.1301e-04 - val_loss: 0.0046\n",
      "Epoch 907/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 9.3187e-04 - val_loss: 0.0047\n",
      "Epoch 908/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0042\n",
      "Epoch 909/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 9.9501e-04 - val_loss: 0.0043\n",
      "Epoch 910/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0011 - val_loss: 0.0048\n",
      "Epoch 911/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0012 - val_loss: 0.0045\n",
      "Epoch 912/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0010 - val_loss: 0.0045\n",
      "Epoch 913/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0011 - val_loss: 0.0045\n",
      "Epoch 914/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0010 - val_loss: 0.0039\n",
      "Epoch 915/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 105us/step - loss: 0.0010 - val_loss: 0.0047\n",
      "Epoch 916/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0011 - val_loss: 0.0047\n",
      "Epoch 917/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0011 - val_loss: 0.0043\n",
      "Epoch 918/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 9.1703e-04 - val_loss: 0.0048\n",
      "Epoch 919/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0010 - val_loss: 0.0045\n",
      "Epoch 920/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0044\n",
      "Epoch 921/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0011 - val_loss: 0.0042\n",
      "Epoch 922/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0010 - val_loss: 0.0042\n",
      "Epoch 923/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 9.3054e-04 - val_loss: 0.0049\n",
      "Epoch 924/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0012 - val_loss: 0.0048\n",
      "Epoch 925/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 926/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0013 - val_loss: 0.0044\n",
      "Epoch 927/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0046\n",
      "Epoch 928/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 9.7548e-04 - val_loss: 0.0042\n",
      "Epoch 929/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0045\n",
      "Epoch 930/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0050\n",
      "Epoch 931/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 932/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0053\n",
      "Epoch 933/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0011 - val_loss: 0.0050\n",
      "Epoch 934/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0012 - val_loss: 0.0041\n",
      "Epoch 935/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0011 - val_loss: 0.0047\n",
      "Epoch 936/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0010 - val_loss: 0.0043\n",
      "Epoch 937/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 938/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0045\n",
      "Epoch 939/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 940/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0012 - val_loss: 0.0047\n",
      "Epoch 941/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0010 - val_loss: 0.0048\n",
      "Epoch 942/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0011 - val_loss: 0.0043\n",
      "Epoch 943/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 9.6491e-04 - val_loss: 0.0050\n",
      "Epoch 944/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0047\n",
      "Epoch 945/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 946/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0012 - val_loss: 0.0054\n",
      "Epoch 947/1000\n",
      "143/143 [==============================] - 0s 99us/step - loss: 0.0010 - val_loss: 0.0043\n",
      "Epoch 948/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 9.1067e-04 - val_loss: 0.0045\n",
      "Epoch 949/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0049\n",
      "Epoch 950/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0012 - val_loss: 0.0060\n",
      "Epoch 951/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0016 - val_loss: 0.0051\n",
      "Epoch 952/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0050\n",
      "Epoch 953/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 954/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0012 - val_loss: 0.0046\n",
      "Epoch 955/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0011 - val_loss: 0.0056\n",
      "Epoch 956/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0012 - val_loss: 0.0041\n",
      "Epoch 957/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0010 - val_loss: 0.0045\n",
      "Epoch 958/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0048\n",
      "Epoch 959/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0048\n",
      "Epoch 960/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0011 - val_loss: 0.0045\n",
      "Epoch 961/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0010 - val_loss: 0.0042\n",
      "Epoch 962/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 9.8586e-04 - val_loss: 0.0041\n",
      "Epoch 963/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0011 - val_loss: 0.0042\n",
      "Epoch 964/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0010 - val_loss: 0.0044\n",
      "Epoch 965/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 9.8609e-04 - val_loss: 0.0045\n",
      "Epoch 966/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 967/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0047\n",
      "Epoch 968/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0012 - val_loss: 0.0039\n",
      "Epoch 969/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0011 - val_loss: 0.0046\n",
      "Epoch 970/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 9.5803e-04 - val_loss: 0.0041\n",
      "Epoch 971/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 9.1556e-04 - val_loss: 0.0048\n",
      "Epoch 972/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 9.7442e-04 - val_loss: 0.0044\n",
      "Epoch 973/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 8.9204e-04 - val_loss: 0.0050\n",
      "Epoch 974/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 9.3432e-04 - val_loss: 0.0049\n",
      "Epoch 975/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 9.5317e-04 - val_loss: 0.0044\n",
      "Epoch 976/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 8.7362e-04 - val_loss: 0.0042\n",
      "Epoch 977/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 8.7440e-04 - val_loss: 0.0051\n",
      "Epoch 978/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 9.8013e-04 - val_loss: 0.0048\n",
      "Epoch 979/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 9.3373e-04 - val_loss: 0.0043\n",
      "Epoch 980/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 9.8181e-04 - val_loss: 0.0051\n",
      "Epoch 981/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 9.8062e-04 - val_loss: 0.0047\n",
      "Epoch 982/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 9.8881e-04 - val_loss: 0.0044\n",
      "Epoch 983/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0011 - val_loss: 0.0047\n",
      "Epoch 984/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0011 - val_loss: 0.0047\n",
      "Epoch 985/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 9.4572e-04 - val_loss: 0.0042\n",
      "Epoch 986/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 9.8455e-04 - val_loss: 0.0048\n",
      "Epoch 987/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 9.5179e-04 - val_loss: 0.0050\n",
      "Epoch 988/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 9.9559e-04 - val_loss: 0.0050\n",
      "Epoch 989/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0011 - val_loss: 0.0048\n",
      "Epoch 990/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0049\n",
      "Epoch 991/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 8.9740e-04 - val_loss: 0.0040\n",
      "Epoch 992/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 9.9954e-04 - val_loss: 0.0050\n",
      "Epoch 993/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 9.9605e-04 - val_loss: 0.0046\n",
      "Epoch 994/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 9.6928e-04 - val_loss: 0.0043\n",
      "Epoch 995/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0010 - val_loss: 0.0045\n",
      "Epoch 996/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 9.2048e-04 - val_loss: 0.0054\n",
      "Epoch 997/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0010 - val_loss: 0.0048\n",
      "Epoch 998/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 9.1856e-04 - val_loss: 0.0051\n",
      "Epoch 999/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 8.6863e-04 - val_loss: 0.0042\n",
      "Epoch 1000/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 9.4500e-04 - val_loss: 0.0045\n",
      "0.007047600578516722\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-1.00431487e-01,  1.21067889e-01,  4.09593701e-01,\n",
       "          2.40309685e-01,  4.03337516e-02, -7.69879818e-01,\n",
       "          1.73465982e-01, -1.56160223e+00,  9.49560106e-02,\n",
       "          1.63260773e-01],\n",
       "        [ 4.40749466e-01, -1.25971520e+00,  2.63565928e-01,\n",
       "         -3.05983484e-01, -1.07567355e-01, -2.62014776e-01,\n",
       "          3.20910156e-01,  7.81092346e-01, -1.52180493e-01,\n",
       "          4.75504011e-01],\n",
       "        [ 5.03566384e-01,  3.82459313e-01,  1.12733006e-01,\n",
       "         -3.24534923e-01, -1.89240366e-01,  3.56999099e-01,\n",
       "          1.36057049e-01,  7.89302409e-01, -3.65474999e-01,\n",
       "          2.27050930e-01],\n",
       "        [ 1.15214497e-01, -2.54611325e+00,  7.75862396e-01,\n",
       "          2.33249158e-01, -2.16309384e-01, -7.78955460e-01,\n",
       "         -1.24643862e-01,  3.59998226e-01,  1.13832392e-02,\n",
       "          1.98465526e-01],\n",
       "        [ 2.11324230e-01, -3.31838056e-02,  4.37098324e-01,\n",
       "          2.49756649e-01,  6.44292012e-02, -1.24731712e-01,\n",
       "          5.26124895e-01,  2.32355878e-01,  1.51975349e-01,\n",
       "          4.45157260e-01],\n",
       "        [-2.50272840e-01, -6.01756573e-01,  4.21271801e-01,\n",
       "         -1.08699836e-01,  1.26420259e-02, -5.28960884e-01,\n",
       "          1.52970105e-01, -3.95269603e-01,  2.20963433e-01,\n",
       "          9.09530997e-01],\n",
       "        [ 5.84645092e-01, -7.41264671e-02,  5.58817126e-02,\n",
       "          5.70580244e-01, -5.39174497e-01,  7.70692527e-02,\n",
       "          4.59845275e-01,  6.06916606e-01,  7.53518566e-02,\n",
       "         -1.10950515e-01],\n",
       "        [ 1.27540007e-01,  5.25329053e-01,  2.25437701e-01,\n",
       "          2.98710346e-01,  8.20015594e-02, -1.91969827e-01,\n",
       "          3.02226156e-01,  1.38433322e-01, -1.20711550e-01,\n",
       "         -2.88579985e-02],\n",
       "        [ 5.95979095e-01,  8.68556440e-01,  8.04423273e-01,\n",
       "         -1.33769408e-01,  2.58393884e-02,  8.97027194e-01,\n",
       "          2.75604010e-01, -5.67344904e-01, -3.06931078e-01,\n",
       "          6.98887527e-01],\n",
       "        [ 9.05837957e-03, -1.51341438e-01, -2.81274945e-01,\n",
       "          1.07884550e+00,  4.90683969e-03,  8.30974638e-01,\n",
       "         -2.62791645e-02,  7.12800846e-02,  2.12945759e-01,\n",
       "         -1.03764832e+00],\n",
       "        [ 7.26806283e-01,  2.44646594e-01, -5.61133564e-01,\n",
       "         -2.81984150e-01,  3.13284129e-01,  1.13370419e+00,\n",
       "         -9.80826616e-02, -3.23983818e-01,  1.73582509e-02,\n",
       "         -2.77696818e-01],\n",
       "        [-8.30092192e-01,  1.81202903e-01, -1.79968333e+00,\n",
       "         -6.59571946e-01, -5.25412500e-01, -3.37698199e-02,\n",
       "          1.84285000e-01,  1.01827659e-01, -2.86881149e-01,\n",
       "         -8.80873144e-01],\n",
       "        [ 2.97109187e-01, -1.44589809e-04, -8.08574855e-01,\n",
       "          1.00798413e-01, -5.92826270e-02, -2.76783019e-01,\n",
       "         -4.70822379e-02,  4.10103679e-01, -1.19472064e-01,\n",
       "         -9.25351679e-01],\n",
       "        [-1.97135508e-01, -5.78868687e-01, -1.27299368e+00,\n",
       "         -3.44189644e-01,  1.11709721e-01,  2.37026662e-01,\n",
       "          3.27392630e-02, -1.46610236e+00, -3.13184142e-01,\n",
       "          9.59091127e-01],\n",
       "        [-2.62279719e-01, -1.15629002e-01,  3.47231269e-01,\n",
       "          2.30886862e-01,  2.42781341e-01,  5.64911902e-01,\n",
       "          5.49087524e-01,  3.42291266e-01, -3.56701940e-01,\n",
       "          4.23495919e-01],\n",
       "        [-5.58990061e-01,  7.77727515e-02, -2.16293056e-02,\n",
       "          3.50155950e-01, -2.29110166e-01, -3.46179545e-01,\n",
       "          3.57808977e-01, -5.00586808e-01,  4.54616427e-01,\n",
       "         -2.75091559e-01],\n",
       "        [-5.03380120e-01,  5.85584760e-01, -2.63317138e-01,\n",
       "          6.60062283e-02,  3.37440819e-01, -5.81615031e-01,\n",
       "          4.09334563e-02,  2.77506173e-01,  2.43884459e-01,\n",
       "         -4.95987013e-02],\n",
       "        [ 9.96338725e-01,  2.63284922e-01, -7.23934248e-02,\n",
       "          4.30447400e-01, -1.20321304e-01, -2.14164540e-01,\n",
       "          2.84541249e-01,  1.17633261e-01, -7.48845696e-01,\n",
       "         -1.86683819e-01],\n",
       "        [-5.99069335e-02,  4.95321602e-01,  7.13414848e-02,\n",
       "         -9.36094940e-01,  7.06048131e-01,  1.39382541e+00,\n",
       "         -1.93583339e-01,  3.93759042e-01,  4.47988898e-01,\n",
       "          8.81516039e-01],\n",
       "        [ 4.33106363e-01,  1.92507625e-01, -1.08203478e-01,\n",
       "         -4.78056408e-02, -5.19550331e-02,  8.20141196e-01,\n",
       "         -5.14955163e-01, -8.20660353e-01, -4.06106353e-01,\n",
       "         -4.42274719e-01],\n",
       "        [ 4.07343835e-01, -3.70942712e-01,  5.05302846e-01,\n",
       "          6.72260165e-01,  1.77431345e-01, -6.99544013e-01,\n",
       "         -4.83076453e-01,  1.84687161e+00,  1.79296248e-02,\n",
       "          1.48795098e-01],\n",
       "        [ 1.27111912e-01,  2.00123027e-01, -6.55401498e-02,\n",
       "          1.39234662e-01,  9.57625508e-02,  1.03007936e+00,\n",
       "         -1.51949346e-01,  1.22375214e+00, -5.08588970e-01,\n",
       "          2.39534765e-01]], dtype=float32),\n",
       " array([ 0.19166201,  0.13903554, -0.03244181,  0.180671  , -0.09568623,\n",
       "         0.24249287,  0.02706645,  0.35640544, -0.1206972 , -0.1490153 ],\n",
       "       dtype=float32),\n",
       " array([[ 0.22678727,  0.44458532,  0.3937924 ,  0.44003588, -0.31920543,\n",
       "         -0.21995911,  0.00449867, -0.09395269, -0.3120437 , -0.35814625],\n",
       "        [ 0.05561677, -0.30176318,  0.46189156, -0.3117799 ,  0.14931233,\n",
       "          0.35682088, -0.14442171, -0.29953596,  0.00354244, -0.08712019],\n",
       "        [ 0.08133499, -0.5183653 , -0.05698365, -0.73978925,  0.18176648,\n",
       "          0.64577776, -0.01577434, -0.15328322,  0.3788685 ,  0.1831841 ],\n",
       "        [ 0.00081245,  0.5684714 , -0.30351013,  0.69527584,  0.12830076,\n",
       "         -0.605523  ,  0.38060445,  0.16482536, -0.19630264, -0.14986956],\n",
       "        [ 0.29595512,  0.29180035,  0.15518071,  0.01362084, -0.06792969,\n",
       "          0.39145565, -0.45850077, -0.11082315,  0.18643738, -0.12398192],\n",
       "        [-0.5652043 ,  0.03830593, -0.38031238,  0.5594219 , -0.16348398,\n",
       "          0.22463797,  0.05644115,  0.32200372,  0.2320236 ,  0.52288955],\n",
       "        [ 0.43673062,  0.04139037, -0.05405327, -0.01970058,  0.19094343,\n",
       "          0.4375429 , -0.00278895, -0.360753  , -0.01604711, -0.13418685],\n",
       "        [ 0.18743981, -0.52968436, -0.1038717 , -0.53432024,  0.25058082,\n",
       "          0.25281385, -0.17337266, -0.556155  ,  0.55356354,  0.34190613],\n",
       "        [ 0.5292661 ,  0.14223877,  0.00960899, -0.00679409,  0.19549374,\n",
       "          0.22421435,  0.55480343, -0.7352927 ,  0.18261364,  0.06485435],\n",
       "        [-0.11401816, -0.10102632,  0.10150595,  0.5953712 , -0.01857084,\n",
       "         -0.36236578, -0.18302259,  0.42362404, -0.56456894,  0.20025745]],\n",
       "       dtype=float32),\n",
       " array([ 0.13861787, -0.14359719,  0.14180605, -0.153212  ,  0.03545209,\n",
       "         0.16697077,  0.17368042, -0.08143268,  0.1418231 , -0.11552152],\n",
       "       dtype=float32),\n",
       " array([[-0.01639237],\n",
       "        [ 0.10154468],\n",
       "        [-0.00527039],\n",
       "        [ 0.3072464 ],\n",
       "        [-0.07060292],\n",
       "        [-0.05086824],\n",
       "        [ 0.01526215],\n",
       "        [ 0.06186668],\n",
       "        [-0.17705338],\n",
       "        [-0.0096192 ]], dtype=float32),\n",
       " array([-0.02031852], dtype=float32)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_automobile, history_automobile, evaluate_automobile=NN_model_structure_regression_5(X_train_automobile, X_val_automobile, Y_train_automobile, Y_val_automobile, adam2, 32, 1000, x_test_automobile, y_test_automobile)\n",
    "model_automobile.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_automobile.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_automobile_structure5_4th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_52 (Dense)             (None, 10)                230       \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 15)                165       \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 411\n",
      "Trainable params: 411\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 143 samples, validate on 31 samples\n",
      "Epoch 1/1000\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.4699 - val_loss: 0.0212\n",
      "Epoch 2/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.1465 - val_loss: 0.1660\n",
      "Epoch 3/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0823 - val_loss: 0.0095\n",
      "Epoch 4/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0455 - val_loss: 0.0080\n",
      "Epoch 5/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0432 - val_loss: 0.0131\n",
      "Epoch 6/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0354 - val_loss: 0.0073\n",
      "Epoch 7/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0286 - val_loss: 0.0054\n",
      "Epoch 8/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0212 - val_loss: 0.0076\n",
      "Epoch 9/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0149 - val_loss: 0.0074\n",
      "Epoch 10/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0161 - val_loss: 0.0065\n",
      "Epoch 11/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0128 - val_loss: 0.0058\n",
      "Epoch 12/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0109 - val_loss: 0.0061\n",
      "Epoch 13/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0102 - val_loss: 0.0049\n",
      "Epoch 14/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0093 - val_loss: 0.0051\n",
      "Epoch 15/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0090 - val_loss: 0.0048\n",
      "Epoch 16/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0088 - val_loss: 0.0048\n",
      "Epoch 17/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0086 - val_loss: 0.0046\n",
      "Epoch 18/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0084 - val_loss: 0.0044\n",
      "Epoch 19/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0080 - val_loss: 0.0046\n",
      "Epoch 20/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0080 - val_loss: 0.0048\n",
      "Epoch 21/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0077 - val_loss: 0.0044\n",
      "Epoch 22/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0079 - val_loss: 0.0043\n",
      "Epoch 23/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0076 - val_loss: 0.0046\n",
      "Epoch 24/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0084 - val_loss: 0.0052\n",
      "Epoch 25/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0082 - val_loss: 0.0061\n",
      "Epoch 26/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0084 - val_loss: 0.0048\n",
      "Epoch 27/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0073 - val_loss: 0.0044\n",
      "Epoch 28/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0078 - val_loss: 0.0046\n",
      "Epoch 29/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0075 - val_loss: 0.0045\n",
      "Epoch 30/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0073 - val_loss: 0.0053\n",
      "Epoch 31/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0072 - val_loss: 0.0045\n",
      "Epoch 32/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0070 - val_loss: 0.0044\n",
      "Epoch 33/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0074 - val_loss: 0.0047\n",
      "Epoch 34/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0071 - val_loss: 0.0048\n",
      "Epoch 35/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0069 - val_loss: 0.0048\n",
      "Epoch 36/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0070 - val_loss: 0.0047\n",
      "Epoch 37/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0071 - val_loss: 0.0052\n",
      "Epoch 38/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0077 - val_loss: 0.0062\n",
      "Epoch 39/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0079 - val_loss: 0.0050\n",
      "Epoch 40/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0064 - val_loss: 0.0047\n",
      "Epoch 41/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0071 - val_loss: 0.0052\n",
      "Epoch 42/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0071 - val_loss: 0.0046\n",
      "Epoch 43/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0071 - val_loss: 0.0047\n",
      "Epoch 44/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0070 - val_loss: 0.0045\n",
      "Epoch 45/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0072 - val_loss: 0.0042\n",
      "Epoch 46/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0065 - val_loss: 0.0046\n",
      "Epoch 47/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0066 - val_loss: 0.0044\n",
      "Epoch 48/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0064 - val_loss: 0.0043\n",
      "Epoch 49/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0064 - val_loss: 0.0045\n",
      "Epoch 50/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0064 - val_loss: 0.0042\n",
      "Epoch 51/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0062 - val_loss: 0.0051\n",
      "Epoch 52/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0065 - val_loss: 0.0051\n",
      "Epoch 53/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0067 - val_loss: 0.0050\n",
      "Epoch 54/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0064 - val_loss: 0.0042\n",
      "Epoch 55/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0062 - val_loss: 0.0041\n",
      "Epoch 56/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0063 - val_loss: 0.0042\n",
      "Epoch 57/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0061 - val_loss: 0.0044\n",
      "Epoch 58/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0063 - val_loss: 0.0048\n",
      "Epoch 59/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0062 - val_loss: 0.0043\n",
      "Epoch 60/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0059 - val_loss: 0.0046\n",
      "Epoch 61/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0060 - val_loss: 0.0048\n",
      "Epoch 62/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0060 - val_loss: 0.0065\n",
      "Epoch 63/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0072 - val_loss: 0.0077\n",
      "Epoch 64/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0079 - val_loss: 0.0081\n",
      "Epoch 65/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0075 - val_loss: 0.0046\n",
      "Epoch 66/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0068 - val_loss: 0.0044\n",
      "Epoch 67/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0063 - val_loss: 0.0043\n",
      "Epoch 68/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0062 - val_loss: 0.0045\n",
      "Epoch 69/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 111us/step - loss: 0.0058 - val_loss: 0.0052\n",
      "Epoch 70/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0060 - val_loss: 0.0051\n",
      "Epoch 71/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0057 - val_loss: 0.0065\n",
      "Epoch 72/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0065 - val_loss: 0.0051\n",
      "Epoch 73/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0062 - val_loss: 0.0055\n",
      "Epoch 74/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0058 - val_loss: 0.0042\n",
      "Epoch 75/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0059 - val_loss: 0.0051\n",
      "Epoch 76/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0056 - val_loss: 0.0043\n",
      "Epoch 77/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0057 - val_loss: 0.0043\n",
      "Epoch 78/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0055 - val_loss: 0.0045\n",
      "Epoch 79/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0057 - val_loss: 0.0048\n",
      "Epoch 80/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0063 - val_loss: 0.0080\n",
      "Epoch 81/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0066 - val_loss: 0.0070\n",
      "Epoch 82/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0073 - val_loss: 0.0079\n",
      "Epoch 83/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0063 - val_loss: 0.0047\n",
      "Epoch 84/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0056 - val_loss: 0.0070\n",
      "Epoch 85/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0063 - val_loss: 0.0047\n",
      "Epoch 86/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0066 - val_loss: 0.0046\n",
      "Epoch 87/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0063 - val_loss: 0.0044\n",
      "Epoch 88/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0056 - val_loss: 0.0039\n",
      "Epoch 89/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0055 - val_loss: 0.0044\n",
      "Epoch 90/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0052 - val_loss: 0.0055\n",
      "Epoch 91/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0060 - val_loss: 0.0053\n",
      "Epoch 92/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0058 - val_loss: 0.0052\n",
      "Epoch 93/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0058 - val_loss: 0.0039\n",
      "Epoch 94/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0055 - val_loss: 0.0045\n",
      "Epoch 95/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0047\n",
      "Epoch 96/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0056 - val_loss: 0.0053\n",
      "Epoch 97/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0051 - val_loss: 0.0046\n",
      "Epoch 98/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0060 - val_loss: 0.0046\n",
      "Epoch 99/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0061 - val_loss: 0.0056\n",
      "Epoch 100/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0058 - val_loss: 0.0050\n",
      "Epoch 101/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0052 - val_loss: 0.0055\n",
      "Epoch 102/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0052 - val_loss: 0.0047\n",
      "Epoch 103/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0060 - val_loss: 0.0055\n",
      "Epoch 104/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0051 - val_loss: 0.0055\n",
      "Epoch 105/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0057 - val_loss: 0.0051\n",
      "Epoch 106/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0056 - val_loss: 0.0045\n",
      "Epoch 107/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0059 - val_loss: 0.0042\n",
      "Epoch 108/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0054 - val_loss: 0.0056\n",
      "Epoch 109/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0052 - val_loss: 0.0049\n",
      "Epoch 110/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0044\n",
      "Epoch 111/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0051 - val_loss: 0.0047\n",
      "Epoch 112/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0044\n",
      "Epoch 113/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0048 - val_loss: 0.0052\n",
      "Epoch 114/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0054 - val_loss: 0.0052\n",
      "Epoch 115/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0054 - val_loss: 0.0062\n",
      "Epoch 116/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0056 - val_loss: 0.0039\n",
      "Epoch 117/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0053 - val_loss: 0.0041\n",
      "Epoch 118/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0052\n",
      "Epoch 119/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0041\n",
      "Epoch 120/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0049 - val_loss: 0.0044\n",
      "Epoch 121/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0041\n",
      "Epoch 122/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 123/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0043\n",
      "Epoch 124/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 125/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0046 - val_loss: 0.0042\n",
      "Epoch 126/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0049 - val_loss: 0.0068\n",
      "Epoch 127/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0048\n",
      "Epoch 128/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0044\n",
      "Epoch 129/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0049 - val_loss: 0.0060\n",
      "Epoch 130/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0051 - val_loss: 0.0045\n",
      "Epoch 131/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0046 - val_loss: 0.0053\n",
      "Epoch 132/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 133/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 134/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0044 - val_loss: 0.0042\n",
      "Epoch 135/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 136/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0061\n",
      "Epoch 137/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0048 - val_loss: 0.0041\n",
      "Epoch 138/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0045 - val_loss: 0.0041\n",
      "Epoch 139/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0047 - val_loss: 0.0044\n",
      "Epoch 140/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0047 - val_loss: 0.0051\n",
      "Epoch 141/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0046 - val_loss: 0.0050\n",
      "Epoch 142/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 143/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 144/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0059 - val_loss: 0.0048\n",
      "Epoch 145/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0054\n",
      "Epoch 146/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 111us/step - loss: 0.0043 - val_loss: 0.0038\n",
      "Epoch 147/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 148/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 149/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0041 - val_loss: 0.0042\n",
      "Epoch 150/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0040 - val_loss: 0.0044\n",
      "Epoch 151/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0042\n",
      "Epoch 152/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0043 - val_loss: 0.0037\n",
      "Epoch 153/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0042 - val_loss: 0.0061\n",
      "Epoch 154/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 155/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 156/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0042 - val_loss: 0.0054\n",
      "Epoch 157/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0042 - val_loss: 0.0039\n",
      "Epoch 158/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0040 - val_loss: 0.0044\n",
      "Epoch 159/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 160/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 161/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0043 - val_loss: 0.0039\n",
      "Epoch 162/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0046 - val_loss: 0.0053\n",
      "Epoch 163/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0040 - val_loss: 0.0042\n",
      "Epoch 164/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0041 - val_loss: 0.0057\n",
      "Epoch 165/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0040 - val_loss: 0.0046\n",
      "Epoch 166/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0050\n",
      "Epoch 167/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 168/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0041 - val_loss: 0.0045\n",
      "Epoch 169/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0040 - val_loss: 0.0060\n",
      "Epoch 170/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0036 - val_loss: 0.0050\n",
      "Epoch 171/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0053 - val_loss: 0.0048\n",
      "Epoch 172/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 173/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 174/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0044\n",
      "Epoch 175/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0054\n",
      "Epoch 176/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0040 - val_loss: 0.0044\n",
      "Epoch 177/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 178/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0041\n",
      "Epoch 179/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0036 - val_loss: 0.0039\n",
      "Epoch 180/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0041\n",
      "Epoch 181/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0050\n",
      "Epoch 182/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0040 - val_loss: 0.0037\n",
      "Epoch 183/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.002 - 0s 119us/step - loss: 0.0037 - val_loss: 0.0039\n",
      "Epoch 184/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0036 - val_loss: 0.0052\n",
      "Epoch 185/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0037 - val_loss: 0.0043\n",
      "Epoch 186/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0049\n",
      "Epoch 187/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 188/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0042\n",
      "Epoch 189/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0035 - val_loss: 0.0042\n",
      "Epoch 190/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0033 - val_loss: 0.0041\n",
      "Epoch 191/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Epoch 192/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0036 - val_loss: 0.0061\n",
      "Epoch 193/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0039\n",
      "Epoch 194/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0041 - val_loss: 0.0045\n",
      "Epoch 195/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0048 - val_loss: 0.0079\n",
      "Epoch 196/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 197/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0037 - val_loss: 0.0040\n",
      "Epoch 198/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0066\n",
      "Epoch 199/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0042 - val_loss: 0.0040\n",
      "Epoch 200/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0051\n",
      "Epoch 201/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0042\n",
      "Epoch 202/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0036 - val_loss: 0.0042\n",
      "Epoch 203/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0039 - val_loss: 0.0052\n",
      "Epoch 204/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 205/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0031 - val_loss: 0.0074\n",
      "Epoch 206/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 207/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0031 - val_loss: 0.0046\n",
      "Epoch 208/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0032 - val_loss: 0.0047\n",
      "Epoch 209/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 210/1000\n",
      "143/143 [==============================] - 0s 99us/step - loss: 0.0034 - val_loss: 0.0043\n",
      "Epoch 211/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0055\n",
      "Epoch 212/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0047\n",
      "Epoch 213/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0038 - val_loss: 0.0043\n",
      "Epoch 214/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0034 - val_loss: 0.0056\n",
      "Epoch 215/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0041\n",
      "Epoch 216/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0043\n",
      "Epoch 217/1000\n",
      "143/143 [==============================] - 0s 100us/step - loss: 0.0030 - val_loss: 0.0044\n",
      "Epoch 218/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0029 - val_loss: 0.0042\n",
      "Epoch 219/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0030 - val_loss: 0.0046\n",
      "Epoch 220/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 221/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0030 - val_loss: 0.0047\n",
      "Epoch 222/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 223/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0043\n",
      "Epoch 224/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0031 - val_loss: 0.0049\n",
      "Epoch 225/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0035 - val_loss: 0.0060\n",
      "Epoch 226/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0037 - val_loss: 0.0053\n",
      "Epoch 227/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0040 - val_loss: 0.0053\n",
      "Epoch 228/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0038 - val_loss: 0.0049\n",
      "Epoch 229/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0044\n",
      "Epoch 230/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0052\n",
      "Epoch 231/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0041\n",
      "Epoch 232/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0028 - val_loss: 0.0043\n",
      "Epoch 233/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0042\n",
      "Epoch 234/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0049\n",
      "Epoch 235/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 236/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0044\n",
      "Epoch 237/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0027 - val_loss: 0.0042\n",
      "Epoch 238/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0031 - val_loss: 0.0056\n",
      "Epoch 239/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0040\n",
      "Epoch 240/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0030 - val_loss: 0.0052\n",
      "Epoch 241/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0029 - val_loss: 0.0041\n",
      "Epoch 242/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0031 - val_loss: 0.0044\n",
      "Epoch 243/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0035 - val_loss: 0.0052\n",
      "Epoch 244/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0030 - val_loss: 0.0041\n",
      "Epoch 245/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0028 - val_loss: 0.0042\n",
      "Epoch 246/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0030 - val_loss: 0.0048\n",
      "Epoch 247/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0029 - val_loss: 0.0043\n",
      "Epoch 248/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0027 - val_loss: 0.0042\n",
      "Epoch 249/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0042\n",
      "Epoch 250/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0026 - val_loss: 0.0043\n",
      "Epoch 251/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0029 - val_loss: 0.0051\n",
      "Epoch 252/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0029 - val_loss: 0.0043\n",
      "Epoch 253/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0028 - val_loss: 0.0044\n",
      "Epoch 254/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0047\n",
      "Epoch 255/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0029 - val_loss: 0.0051\n",
      "Epoch 256/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0058\n",
      "Epoch 257/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0077\n",
      "Epoch 258/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0045 - val_loss: 0.0069\n",
      "Epoch 259/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0044 - val_loss: 0.0056\n",
      "Epoch 260/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 261/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0033 - val_loss: 0.0061\n",
      "Epoch 262/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0034 - val_loss: 0.0046\n",
      "Epoch 263/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 264/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0041 - val_loss: 0.0075\n",
      "Epoch 265/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0037 - val_loss: 0.0048\n",
      "Epoch 266/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 267/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0031 - val_loss: 0.0048\n",
      "Epoch 268/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0031 - val_loss: 0.0044\n",
      "Epoch 269/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0053\n",
      "Epoch 270/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0048\n",
      "Epoch 271/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0030 - val_loss: 0.0041\n",
      "Epoch 272/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0027 - val_loss: 0.0047\n",
      "Epoch 273/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0026 - val_loss: 0.0044\n",
      "Epoch 274/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0029 - val_loss: 0.0050\n",
      "Epoch 275/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0047\n",
      "Epoch 276/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0028 - val_loss: 0.0039\n",
      "Epoch 277/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0027 - val_loss: 0.0045\n",
      "Epoch 278/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0025 - val_loss: 0.0043\n",
      "Epoch 279/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0024 - val_loss: 0.0040\n",
      "Epoch 280/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0024 - val_loss: 0.0044\n",
      "Epoch 281/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0024 - val_loss: 0.0041\n",
      "Epoch 282/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0024 - val_loss: 0.0059\n",
      "Epoch 283/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 284/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0027 - val_loss: 0.0042\n",
      "Epoch 285/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0040\n",
      "Epoch 286/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0025 - val_loss: 0.0045\n",
      "Epoch 287/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0043\n",
      "Epoch 288/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0023 - val_loss: 0.0041\n",
      "Epoch 289/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0041\n",
      "Epoch 290/1000\n",
      "143/143 [==============================] - 0s 100us/step - loss: 0.0024 - val_loss: 0.0067\n",
      "Epoch 291/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 292/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0039\n",
      "Epoch 293/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0040\n",
      "Epoch 294/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0033 - val_loss: 0.0047\n",
      "Epoch 295/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0050\n",
      "Epoch 296/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0027 - val_loss: 0.0040\n",
      "Epoch 297/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0040\n",
      "Epoch 298/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0044\n",
      "Epoch 299/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0023 - val_loss: 0.0052\n",
      "Epoch 300/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0045\n",
      "Epoch 301/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0049\n",
      "Epoch 302/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0049\n",
      "Epoch 303/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0023 - val_loss: 0.0045\n",
      "Epoch 304/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0046\n",
      "Epoch 305/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0025 - val_loss: 0.0061\n",
      "Epoch 306/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0026 - val_loss: 0.0041\n",
      "Epoch 307/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0042\n",
      "Epoch 308/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 309/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0023 - val_loss: 0.0045\n",
      "Epoch 310/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0021 - val_loss: 0.0046\n",
      "Epoch 311/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 312/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0055\n",
      "Epoch 313/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0044\n",
      "Epoch 314/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0041\n",
      "Epoch 315/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0022 - val_loss: 0.0042\n",
      "Epoch 316/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0022 - val_loss: 0.0044\n",
      "Epoch 317/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0021 - val_loss: 0.0042\n",
      "Epoch 318/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0045\n",
      "Epoch 319/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0039\n",
      "Epoch 320/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0050\n",
      "Epoch 321/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0022 - val_loss: 0.0045\n",
      "Epoch 322/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0021 - val_loss: 0.0047\n",
      "Epoch 323/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0043\n",
      "Epoch 324/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0046\n",
      "Epoch 325/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0052\n",
      "Epoch 326/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0023 - val_loss: 0.0040\n",
      "Epoch 327/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0081\n",
      "Epoch 328/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0029 - val_loss: 0.0045\n",
      "Epoch 329/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0043\n",
      "Epoch 330/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0026 - val_loss: 0.0044\n",
      "Epoch 331/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0024 - val_loss: 0.0044\n",
      "Epoch 332/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0022 - val_loss: 0.0056\n",
      "Epoch 333/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0025 - val_loss: 0.0043\n",
      "Epoch 334/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0043\n",
      "Epoch 335/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0053\n",
      "Epoch 336/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0045\n",
      "Epoch 337/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0020 - val_loss: 0.0046\n",
      "Epoch 338/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0023 - val_loss: 0.0048\n",
      "Epoch 339/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 340/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0021 - val_loss: 0.0047\n",
      "Epoch 341/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 342/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0019 - val_loss: 0.0051\n",
      "Epoch 343/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0043\n",
      "Epoch 344/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0043\n",
      "Epoch 345/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0052\n",
      "Epoch 346/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0027 - val_loss: 0.0065\n",
      "Epoch 347/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0031 - val_loss: 0.0051\n",
      "Epoch 348/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0050\n",
      "Epoch 349/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0026 - val_loss: 0.0044\n",
      "Epoch 350/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0025 - val_loss: 0.0067\n",
      "Epoch 351/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0044\n",
      "Epoch 352/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0042\n",
      "Epoch 353/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0042\n",
      "Epoch 354/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0059\n",
      "Epoch 355/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0046\n",
      "Epoch 356/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0021 - val_loss: 0.0057\n",
      "Epoch 357/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0053\n",
      "Epoch 358/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0041\n",
      "Epoch 359/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0046\n",
      "Epoch 360/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0060\n",
      "Epoch 361/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0048\n",
      "Epoch 362/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0043\n",
      "Epoch 363/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 364/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0041\n",
      "Epoch 365/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0020 - val_loss: 0.0051\n",
      "Epoch 366/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 367/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0019 - val_loss: 0.0047\n",
      "Epoch 368/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0020 - val_loss: 0.0051\n",
      "Epoch 369/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0041\n",
      "Epoch 370/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 371/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0025 - val_loss: 0.0052\n",
      "Epoch 372/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 373/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0019 - val_loss: 0.0047\n",
      "Epoch 374/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0019 - val_loss: 0.0048\n",
      "Epoch 375/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0041\n",
      "Epoch 376/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0022 - val_loss: 0.0050\n",
      "Epoch 377/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 378/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0044\n",
      "Epoch 379/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0052\n",
      "Epoch 380/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0024 - val_loss: 0.0062\n",
      "Epoch 381/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0021 - val_loss: 0.0047\n",
      "Epoch 382/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0048\n",
      "Epoch 383/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0023 - val_loss: 0.0043\n",
      "Epoch 384/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0049\n",
      "Epoch 385/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0021 - val_loss: 0.0048\n",
      "Epoch 386/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0021 - val_loss: 0.0057\n",
      "Epoch 387/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0020 - val_loss: 0.0045\n",
      "Epoch 388/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0019 - val_loss: 0.0047\n",
      "Epoch 389/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0024 - val_loss: 0.0046\n",
      "Epoch 390/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0019 - val_loss: 0.0048\n",
      "Epoch 391/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0020 - val_loss: 0.0053\n",
      "Epoch 392/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0041\n",
      "Epoch 393/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0017 - val_loss: 0.0047\n",
      "Epoch 394/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0021 - val_loss: 0.0051\n",
      "Epoch 395/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 396/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 397/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 398/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0020 - val_loss: 0.0046\n",
      "Epoch 399/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0019 - val_loss: 0.0062\n",
      "Epoch 400/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0022 - val_loss: 0.0044\n",
      "Epoch 401/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0023 - val_loss: 0.0053\n",
      "Epoch 402/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0025 - val_loss: 0.0043\n",
      "Epoch 403/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0028 - val_loss: 0.0067\n",
      "Epoch 404/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0043\n",
      "Epoch 405/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0057\n",
      "Epoch 406/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0046\n",
      "Epoch 407/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0024 - val_loss: 0.0050\n",
      "Epoch 408/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0022 - val_loss: 0.0065\n",
      "Epoch 409/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0022 - val_loss: 0.0049\n",
      "Epoch 410/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0025 - val_loss: 0.0044\n",
      "Epoch 411/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0058\n",
      "Epoch 412/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0019 - val_loss: 0.0041\n",
      "Epoch 413/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0042\n",
      "Epoch 414/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0048\n",
      "Epoch 415/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 416/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0055\n",
      "Epoch 417/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0019 - val_loss: 0.0047\n",
      "Epoch 418/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 419/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0050\n",
      "Epoch 420/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0027 - val_loss: 0.0051\n",
      "Epoch 421/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0020 - val_loss: 0.0058\n",
      "Epoch 422/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0018 - val_loss: 0.0045\n",
      "Epoch 423/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0021 - val_loss: 0.0044\n",
      "Epoch 424/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0019 - val_loss: 0.0052\n",
      "Epoch 425/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0057\n",
      "Epoch 426/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0018 - val_loss: 0.0045\n",
      "Epoch 427/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0047\n",
      "Epoch 428/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0050\n",
      "Epoch 429/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0049\n",
      "Epoch 430/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0017 - val_loss: 0.0050\n",
      "Epoch 431/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0018 - val_loss: 0.0044\n",
      "Epoch 432/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 433/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0049\n",
      "Epoch 434/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0017 - val_loss: 0.0047\n",
      "Epoch 435/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0047\n",
      "Epoch 436/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0045\n",
      "Epoch 437/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0022 - val_loss: 0.0045\n",
      "Epoch 438/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0046\n",
      "Epoch 439/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0019 - val_loss: 0.0056\n",
      "Epoch 440/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0048\n",
      "Epoch 441/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0045\n",
      "Epoch 442/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0040\n",
      "Epoch 443/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0045\n",
      "Epoch 444/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0018 - val_loss: 0.0061\n",
      "Epoch 445/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0019 - val_loss: 0.0052\n",
      "Epoch 446/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0051\n",
      "Epoch 447/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0025 - val_loss: 0.0042\n",
      "Epoch 448/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0020 - val_loss: 0.0055\n",
      "Epoch 449/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0051\n",
      "Epoch 450/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0018 - val_loss: 0.0044\n",
      "Epoch 451/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 452/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 453/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 454/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0050\n",
      "Epoch 455/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0047\n",
      "Epoch 456/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0045\n",
      "Epoch 457/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 458/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 459/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0059\n",
      "Epoch 460/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0049\n",
      "Epoch 461/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0018 - val_loss: 0.0042\n",
      "Epoch 462/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0047\n",
      "Epoch 463/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0015 - val_loss: 0.0060\n",
      "Epoch 464/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0018 - val_loss: 0.0044\n",
      "Epoch 465/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0019 - val_loss: 0.0047\n",
      "Epoch 466/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0059\n",
      "Epoch 467/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 468/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0062\n",
      "Epoch 469/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0048\n",
      "Epoch 470/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 471/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0042\n",
      "Epoch 472/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0018 - val_loss: 0.0050\n",
      "Epoch 473/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 474/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 475/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0016 - val_loss: 0.0055\n",
      "Epoch 476/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0024 - val_loss: 0.0053\n",
      "Epoch 477/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 478/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 479/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0018 - val_loss: 0.0045\n",
      "Epoch 480/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0018 - val_loss: 0.0059\n",
      "Epoch 481/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0046\n",
      "Epoch 482/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 483/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 484/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0015 - val_loss: 0.0045\n",
      "Epoch 485/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0047\n",
      "Epoch 486/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0050\n",
      "Epoch 487/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 488/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0015 - val_loss: 0.0047\n",
      "Epoch 489/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 490/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0018 - val_loss: 0.0051\n",
      "Epoch 491/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0016 - val_loss: 0.0048\n",
      "Epoch 492/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0015 - val_loss: 0.0049\n",
      "Epoch 493/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0052\n",
      "Epoch 494/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0015 - val_loss: 0.0050\n",
      "Epoch 495/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 496/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0046\n",
      "Epoch 497/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0017 - val_loss: 0.0051\n",
      "Epoch 498/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0056\n",
      "Epoch 499/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 500/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0047\n",
      "Epoch 501/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0059\n",
      "Epoch 502/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0021 - val_loss: 0.0047\n",
      "Epoch 503/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0016 - val_loss: 0.0054\n",
      "Epoch 504/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0046\n",
      "Epoch 505/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0015 - val_loss: 0.0051\n",
      "Epoch 506/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0056\n",
      "Epoch 507/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0047\n",
      "Epoch 508/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0058\n",
      "Epoch 509/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0017 - val_loss: 0.0062\n",
      "Epoch 510/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0020 - val_loss: 0.0047\n",
      "Epoch 511/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0045\n",
      "Epoch 512/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0017 - val_loss: 0.0050\n",
      "Epoch 513/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0053\n",
      "Epoch 514/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0023 - val_loss: 0.0063\n",
      "Epoch 515/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0019 - val_loss: 0.0051\n",
      "Epoch 516/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0048\n",
      "Epoch 517/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0046\n",
      "Epoch 518/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0049\n",
      "Epoch 519/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0056\n",
      "Epoch 520/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0048\n",
      "Epoch 521/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0015 - val_loss: 0.0048\n",
      "Epoch 522/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0015 - val_loss: 0.0045\n",
      "Epoch 523/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0045\n",
      "Epoch 524/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0014 - val_loss: 0.0062\n",
      "Epoch 525/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0019 - val_loss: 0.0049\n",
      "Epoch 526/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 527/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0014 - val_loss: 0.0047\n",
      "Epoch 528/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0015 - val_loss: 0.0055\n",
      "Epoch 529/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0057\n",
      "Epoch 530/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0051\n",
      "Epoch 531/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0062\n",
      "Epoch 532/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 533/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0046\n",
      "Epoch 534/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0024 - val_loss: 0.0062\n",
      "Epoch 535/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0026 - val_loss: 0.0049\n",
      "Epoch 536/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0021 - val_loss: 0.0048\n",
      "Epoch 537/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0043\n",
      "Epoch 538/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 539/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0014 - val_loss: 0.0046\n",
      "Epoch 540/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0049\n",
      "Epoch 541/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0014 - val_loss: 0.0045\n",
      "Epoch 542/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 543/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0015 - val_loss: 0.0049\n",
      "Epoch 544/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 545/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0051\n",
      "Epoch 546/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0062\n",
      "Epoch 547/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0020 - val_loss: 0.0046\n",
      "Epoch 548/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 549/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0047\n",
      "Epoch 550/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0065\n",
      "Epoch 551/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0048\n",
      "Epoch 552/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0015 - val_loss: 0.0045\n",
      "Epoch 553/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0047\n",
      "Epoch 554/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0063\n",
      "Epoch 555/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0045\n",
      "Epoch 556/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0013 - val_loss: 0.0046\n",
      "Epoch 557/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0014 - val_loss: 0.0051\n",
      "Epoch 558/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0016 - val_loss: 0.0053\n",
      "Epoch 559/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0017 - val_loss: 0.0058\n",
      "Epoch 560/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0017 - val_loss: 0.0061\n",
      "Epoch 561/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0056\n",
      "Epoch 562/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0019 - val_loss: 0.0051\n",
      "Epoch 563/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 564/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0051\n",
      "Epoch 565/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0014 - val_loss: 0.0050\n",
      "Epoch 566/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0046\n",
      "Epoch 567/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0013 - val_loss: 0.0047\n",
      "Epoch 568/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0050\n",
      "Epoch 569/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0014 - val_loss: 0.0048\n",
      "Epoch 570/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0049\n",
      "Epoch 571/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0047\n",
      "Epoch 572/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0022 - val_loss: 0.0051\n",
      "Epoch 573/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0053\n",
      "Epoch 574/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0014 - val_loss: 0.0048\n",
      "Epoch 575/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0015 - val_loss: 0.0045\n",
      "Epoch 576/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0016 - val_loss: 0.0049\n",
      "Epoch 577/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0046\n",
      "Epoch 578/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0052\n",
      "Epoch 579/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0013 - val_loss: 0.0050\n",
      "Epoch 580/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0047\n",
      "Epoch 581/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0013 - val_loss: 0.0049\n",
      "Epoch 582/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0049\n",
      "Epoch 583/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0047\n",
      "Epoch 584/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 0.0047\n",
      "Epoch 585/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0049\n",
      "Epoch 586/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0013 - val_loss: 0.0055\n",
      "Epoch 587/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0013 - val_loss: 0.0050\n",
      "Epoch 588/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0048\n",
      "Epoch 589/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0052\n",
      "Epoch 590/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0051\n",
      "Epoch 591/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0052\n",
      "Epoch 592/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0013 - val_loss: 0.0052\n",
      "Epoch 593/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0019 - val_loss: 0.0049\n",
      "Epoch 594/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0012 - val_loss: 0.0055\n",
      "Epoch 595/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0050\n",
      "Epoch 596/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0055\n",
      "Epoch 597/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0048\n",
      "Epoch 598/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0049\n",
      "Epoch 599/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0050\n",
      "Epoch 600/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0013 - val_loss: 0.0053\n",
      "Epoch 601/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0012 - val_loss: 0.0051\n",
      "Epoch 602/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0012 - val_loss: 0.0049\n",
      "Epoch 603/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0013 - val_loss: 0.0052\n",
      "Epoch 604/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0056\n",
      "Epoch 605/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0016 - val_loss: 0.0050\n",
      "Epoch 606/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0050\n",
      "Epoch 607/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0017 - val_loss: 0.0055\n",
      "Epoch 608/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0050\n",
      "Epoch 609/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0055\n",
      "Epoch 610/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0016 - val_loss: 0.0050\n",
      "Epoch 611/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0012 - val_loss: 0.0045\n",
      "Epoch 612/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0013 - val_loss: 0.0049\n",
      "Epoch 613/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0013 - val_loss: 0.0046\n",
      "Epoch 614/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0048\n",
      "Epoch 615/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0018 - val_loss: 0.0051\n",
      "Epoch 616/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0023 - val_loss: 0.0049\n",
      "Epoch 617/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0030 - val_loss: 0.0054\n",
      "Epoch 618/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0068\n",
      "Epoch 619/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0028 - val_loss: 0.0062\n",
      "Epoch 620/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0023 - val_loss: 0.0046\n",
      "Epoch 621/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0015 - val_loss: 0.0049\n",
      "Epoch 622/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0050\n",
      "Epoch 623/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0051\n",
      "Epoch 624/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 625/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0021 - val_loss: 0.0046\n",
      "Epoch 626/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 627/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0062\n",
      "Epoch 628/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0046\n",
      "Epoch 629/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0047\n",
      "Epoch 630/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 631/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0016 - val_loss: 0.0058\n",
      "Epoch 632/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0048\n",
      "Epoch 633/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0016 - val_loss: 0.0048\n",
      "Epoch 634/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0023 - val_loss: 0.0047\n",
      "Epoch 635/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 636/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0015 - val_loss: 0.0062\n",
      "Epoch 637/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0046\n",
      "Epoch 638/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0012 - val_loss: 0.0050\n",
      "Epoch 639/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0013 - val_loss: 0.0051\n",
      "Epoch 640/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0049\n",
      "Epoch 641/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0014 - val_loss: 0.0052\n",
      "Epoch 642/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0014 - val_loss: 0.0055\n",
      "Epoch 643/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0048\n",
      "Epoch 644/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0020 - val_loss: 0.0078\n",
      "Epoch 645/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0022 - val_loss: 0.0058\n",
      "Epoch 646/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0022 - val_loss: 0.0045\n",
      "Epoch 647/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0047\n",
      "Epoch 648/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0047\n",
      "Epoch 649/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0014 - val_loss: 0.0052\n",
      "Epoch 650/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0014 - val_loss: 0.0049\n",
      "Epoch 651/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0013 - val_loss: 0.0047\n",
      "Epoch 652/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0049\n",
      "Epoch 653/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0045\n",
      "Epoch 654/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0013 - val_loss: 0.0046\n",
      "Epoch 655/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0016 - val_loss: 0.0053\n",
      "Epoch 656/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0015 - val_loss: 0.0061\n",
      "Epoch 657/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0016 - val_loss: 0.0052\n",
      "Epoch 658/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0045\n",
      "Epoch 659/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0018 - val_loss: 0.0049\n",
      "Epoch 660/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0067\n",
      "Epoch 661/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 662/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0014 - val_loss: 0.0048\n",
      "Epoch 663/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0012 - val_loss: 0.0047\n",
      "Epoch 664/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0013 - val_loss: 0.0047\n",
      "Epoch 665/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0055\n",
      "Epoch 666/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0049\n",
      "Epoch 667/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0050\n",
      "Epoch 668/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0060\n",
      "Epoch 669/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0016 - val_loss: 0.0058\n",
      "Epoch 670/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0015 - val_loss: 0.0046\n",
      "Epoch 671/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0013 - val_loss: 0.0044\n",
      "Epoch 672/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0015 - val_loss: 0.0049\n",
      "Epoch 673/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0015 - val_loss: 0.0063\n",
      "Epoch 674/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0015 - val_loss: 0.0048\n",
      "Epoch 675/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0015 - val_loss: 0.0049\n",
      "Epoch 676/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0052\n",
      "Epoch 677/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0013 - val_loss: 0.0054\n",
      "Epoch 678/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0045\n",
      "Epoch 679/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0046\n",
      "Epoch 680/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0011 - val_loss: 0.0049\n",
      "Epoch 681/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0013 - val_loss: 0.0050\n",
      "Epoch 682/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0012 - val_loss: 0.0052\n",
      "Epoch 683/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0013 - val_loss: 0.0050\n",
      "Epoch 684/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0013 - val_loss: 0.0057\n",
      "Epoch 685/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0055\n",
      "Epoch 686/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0022 - val_loss: 0.0065\n",
      "Epoch 687/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0016 - val_loss: 0.0052\n",
      "Epoch 688/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0051\n",
      "Epoch 689/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0014 - val_loss: 0.0047\n",
      "Epoch 690/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0024 - val_loss: 0.0075\n",
      "Epoch 691/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0026 - val_loss: 0.0070\n",
      "Epoch 692/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0053\n",
      "Epoch 693/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0043\n",
      "Epoch 694/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0069\n",
      "Epoch 695/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0018 - val_loss: 0.0047\n",
      "Epoch 696/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0016 - val_loss: 0.0048\n",
      "Epoch 697/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0017 - val_loss: 0.0048\n",
      "Epoch 698/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0012 - val_loss: 0.0053\n",
      "Epoch 699/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0012 - val_loss: 0.0047\n",
      "Epoch 700/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0012 - val_loss: 0.0047\n",
      "Epoch 701/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0049\n",
      "Epoch 702/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0011 - val_loss: 0.0050\n",
      "Epoch 703/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0011 - val_loss: 0.0049\n",
      "Epoch 704/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0012 - val_loss: 0.0046\n",
      "Epoch 705/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0012 - val_loss: 0.0056\n",
      "Epoch 706/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0014 - val_loss: 0.0057\n",
      "Epoch 707/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0014 - val_loss: 0.0048\n",
      "Epoch 708/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0048\n",
      "Epoch 709/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0017 - val_loss: 0.0050\n",
      "Epoch 710/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0018 - val_loss: 0.0057\n",
      "Epoch 711/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0018 - val_loss: 0.0059\n",
      "Epoch 712/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0047\n",
      "Epoch 713/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0020 - val_loss: 0.0056\n",
      "Epoch 714/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0025 - val_loss: 0.0053\n",
      "Epoch 715/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0018 - val_loss: 0.0064\n",
      "Epoch 716/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0047\n",
      "Epoch 717/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0022 - val_loss: 0.0051\n",
      "Epoch 718/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0019 - val_loss: 0.0060\n",
      "Epoch 719/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0053\n",
      "Epoch 720/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 721/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 722/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0056\n",
      "Epoch 723/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0013 - val_loss: 0.0046\n",
      "Epoch 724/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0048\n",
      "Epoch 725/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0012 - val_loss: 0.0050\n",
      "Epoch 726/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0052\n",
      "Epoch 727/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0012 - val_loss: 0.0049\n",
      "Epoch 728/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0011 - val_loss: 0.0048\n",
      "Epoch 729/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0011 - val_loss: 0.0050\n",
      "Epoch 730/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0011 - val_loss: 0.0047\n",
      "Epoch 731/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0012 - val_loss: 0.0049\n",
      "Epoch 732/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0011 - val_loss: 0.0059\n",
      "Epoch 733/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0012 - val_loss: 0.0049\n",
      "Epoch 734/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0047\n",
      "Epoch 735/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0014 - val_loss: 0.0052\n",
      "Epoch 736/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0012 - val_loss: 0.0047\n",
      "Epoch 737/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0058\n",
      "Epoch 738/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0015 - val_loss: 0.0057\n",
      "Epoch 739/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0016 - val_loss: 0.0053\n",
      "Epoch 740/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0013 - val_loss: 0.0052\n",
      "Epoch 741/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0019 - val_loss: 0.0056\n",
      "Epoch 742/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0018 - val_loss: 0.0071\n",
      "Epoch 743/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0018 - val_loss: 0.0049\n",
      "Epoch 744/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0015 - val_loss: 0.0050\n",
      "Epoch 745/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0018 - val_loss: 0.0058\n",
      "Epoch 746/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0017 - val_loss: 0.0056\n",
      "Epoch 747/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0014 - val_loss: 0.0046\n",
      "Epoch 748/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0013 - val_loss: 0.0049\n",
      "Epoch 749/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0011 - val_loss: 0.0051\n",
      "Epoch 750/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0047\n",
      "Epoch 751/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0059\n",
      "Epoch 752/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0051\n",
      "Epoch 753/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0047\n",
      "Epoch 754/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0011 - val_loss: 0.0054\n",
      "Epoch 755/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0018 - val_loss: 0.0052\n",
      "Epoch 756/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0015 - val_loss: 0.0072\n",
      "Epoch 757/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0018 - val_loss: 0.0050\n",
      "Epoch 758/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0016 - val_loss: 0.0056\n",
      "Epoch 759/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0053\n",
      "Epoch 760/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0014 - val_loss: 0.0056\n",
      "Epoch 761/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0049\n",
      "Epoch 762/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0056\n",
      "Epoch 763/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0049\n",
      "Epoch 764/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0049\n",
      "Epoch 765/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0047\n",
      "Epoch 766/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0052\n",
      "Epoch 767/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0013 - val_loss: 0.0059\n",
      "Epoch 768/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0048\n",
      "Epoch 769/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0011 - val_loss: 0.0052\n",
      "Epoch 770/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0011 - val_loss: 0.0053\n",
      "Epoch 771/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0012 - val_loss: 0.0052\n",
      "Epoch 772/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0014 - val_loss: 0.0053\n",
      "Epoch 773/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0012 - val_loss: 0.0052\n",
      "Epoch 774/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0012 - val_loss: 0.0058\n",
      "Epoch 775/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0012 - val_loss: 0.0050\n",
      "Epoch 776/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0055\n",
      "Epoch 777/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0011 - val_loss: 0.0056\n",
      "Epoch 778/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0011 - val_loss: 0.0056\n",
      "Epoch 779/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0050\n",
      "Epoch 780/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0012 - val_loss: 0.0051\n",
      "Epoch 781/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0013 - val_loss: 0.0056\n",
      "Epoch 782/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0050\n",
      "Epoch 783/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0011 - val_loss: 0.0056\n",
      "Epoch 784/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0012 - val_loss: 0.0051\n",
      "Epoch 785/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0011 - val_loss: 0.0049\n",
      "Epoch 786/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0011 - val_loss: 0.0051\n",
      "Epoch 787/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0058\n",
      "Epoch 788/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0013 - val_loss: 0.0057\n",
      "Epoch 789/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0011 - val_loss: 0.0050\n",
      "Epoch 790/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0011 - val_loss: 0.0055\n",
      "Epoch 791/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0011 - val_loss: 0.0053\n",
      "Epoch 792/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0011 - val_loss: 0.0056\n",
      "Epoch 793/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0011 - val_loss: 0.0049\n",
      "Epoch 794/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0011 - val_loss: 0.0050\n",
      "Epoch 795/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0011 - val_loss: 0.0053\n",
      "Epoch 796/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0010 - val_loss: 0.0050\n",
      "Epoch 797/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0011 - val_loss: 0.0051\n",
      "Epoch 798/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0014 - val_loss: 0.0052\n",
      "Epoch 799/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0011 - val_loss: 0.0065\n",
      "Epoch 800/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0014 - val_loss: 0.0057\n",
      "Epoch 801/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0012 - val_loss: 0.0052\n",
      "Epoch 802/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0050\n",
      "Epoch 803/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0056\n",
      "Epoch 804/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0056\n",
      "Epoch 805/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0052\n",
      "Epoch 806/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0063\n",
      "Epoch 807/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0050\n",
      "Epoch 808/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0048\n",
      "Epoch 809/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0016 - val_loss: 0.0058\n",
      "Epoch 810/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0061\n",
      "Epoch 811/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0016 - val_loss: 0.0050\n",
      "Epoch 812/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0013 - val_loss: 0.0049\n",
      "Epoch 813/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0011 - val_loss: 0.0051\n",
      "Epoch 814/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0011 - val_loss: 0.0053\n",
      "Epoch 815/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0011 - val_loss: 0.0048\n",
      "Epoch 816/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0012 - val_loss: 0.0053\n",
      "Epoch 817/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0010 - val_loss: 0.0052\n",
      "Epoch 818/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0011 - val_loss: 0.0054\n",
      "Epoch 819/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0011 - val_loss: 0.0050\n",
      "Epoch 820/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0052\n",
      "Epoch 821/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0011 - val_loss: 0.0063\n",
      "Epoch 822/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0050\n",
      "Epoch 823/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0014 - val_loss: 0.0050\n",
      "Epoch 824/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0049\n",
      "Epoch 825/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0011 - val_loss: 0.0050\n",
      "Epoch 826/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0014 - val_loss: 0.0052\n",
      "Epoch 827/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0013 - val_loss: 0.0052\n",
      "Epoch 828/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0012 - val_loss: 0.0060\n",
      "Epoch 829/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0016 - val_loss: 0.0064\n",
      "Epoch 830/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0013 - val_loss: 0.0050\n",
      "Epoch 831/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0012 - val_loss: 0.0055\n",
      "Epoch 832/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0012 - val_loss: 0.0056\n",
      "Epoch 833/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0010 - val_loss: 0.0050\n",
      "Epoch 834/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0010 - val_loss: 0.0052\n",
      "Epoch 835/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0011 - val_loss: 0.0056\n",
      "Epoch 836/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0011 - val_loss: 0.0060\n",
      "Epoch 837/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0055\n",
      "Epoch 838/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0014 - val_loss: 0.0049\n",
      "Epoch 839/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 115us/step - loss: 0.0012 - val_loss: 0.0059\n",
      "Epoch 840/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0055\n",
      "Epoch 841/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0011 - val_loss: 0.0053\n",
      "Epoch 842/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0011 - val_loss: 0.0050\n",
      "Epoch 843/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0016 - val_loss: 0.0050\n",
      "Epoch 844/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0014 - val_loss: 0.0068\n",
      "Epoch 845/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0016 - val_loss: 0.0064\n",
      "Epoch 846/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0018 - val_loss: 0.0050\n",
      "Epoch 847/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0016 - val_loss: 0.0048\n",
      "Epoch 848/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0011 - val_loss: 0.0053\n",
      "Epoch 849/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0011 - val_loss: 0.0051\n",
      "Epoch 850/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0011 - val_loss: 0.0058\n",
      "Epoch 851/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0013 - val_loss: 0.0052\n",
      "Epoch 852/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0013 - val_loss: 0.0048\n",
      "Epoch 853/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0011 - val_loss: 0.0053\n",
      "Epoch 854/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0012 - val_loss: 0.0051\n",
      "Epoch 855/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0012 - val_loss: 0.0054\n",
      "Epoch 856/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0059\n",
      "Epoch 857/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0012 - val_loss: 0.0049\n",
      "Epoch 858/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0051\n",
      "Epoch 859/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0011 - val_loss: 0.0066\n",
      "Epoch 860/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0014 - val_loss: 0.0054\n",
      "Epoch 861/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0011 - val_loss: 0.0053\n",
      "Epoch 862/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0013 - val_loss: 0.0052\n",
      "Epoch 863/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0016 - val_loss: 0.0058\n",
      "Epoch 864/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0057\n",
      "Epoch 865/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0047\n",
      "Epoch 866/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0054\n",
      "Epoch 867/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0011 - val_loss: 0.0058\n",
      "Epoch 868/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0011 - val_loss: 0.0049\n",
      "Epoch 869/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0011 - val_loss: 0.0051\n",
      "Epoch 870/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0010 - val_loss: 0.0056\n",
      "Epoch 871/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0010 - val_loss: 0.0054\n",
      "Epoch 872/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0010 - val_loss: 0.0061\n",
      "Epoch 873/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0016 - val_loss: 0.0050\n",
      "Epoch 874/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0054\n",
      "Epoch 875/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0054\n",
      "Epoch 876/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0051\n",
      "Epoch 877/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0012 - val_loss: 0.0056\n",
      "Epoch 878/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0013 - val_loss: 0.0057\n",
      "Epoch 879/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0011 - val_loss: 0.0060\n",
      "Epoch 880/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0012 - val_loss: 0.0051\n",
      "Epoch 881/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0010 - val_loss: 0.0053\n",
      "Epoch 882/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0011 - val_loss: 0.0054\n",
      "Epoch 883/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0010 - val_loss: 0.0054\n",
      "Epoch 884/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0012 - val_loss: 0.0056\n",
      "Epoch 885/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0011 - val_loss: 0.0051\n",
      "Epoch 886/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0012 - val_loss: 0.0051\n",
      "Epoch 887/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0054\n",
      "Epoch 888/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 9.5359e-04 - val_loss: 0.0049\n",
      "Epoch 889/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0011 - val_loss: 0.0056\n",
      "Epoch 890/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0010 - val_loss: 0.0052\n",
      "Epoch 891/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 9.8901e-04 - val_loss: 0.0056\n",
      "Epoch 892/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0011 - val_loss: 0.0052\n",
      "Epoch 893/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0055\n",
      "Epoch 894/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0018 - val_loss: 0.0069\n",
      "Epoch 895/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0019 - val_loss: 0.0065\n",
      "Epoch 896/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 897/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0054\n",
      "Epoch 898/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0048\n",
      "Epoch 899/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0054\n",
      "Epoch 900/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0013 - val_loss: 0.0049\n",
      "Epoch 901/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0052\n",
      "Epoch 902/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 9.8239e-04 - val_loss: 0.0052\n",
      "Epoch 903/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0054\n",
      "Epoch 904/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0050\n",
      "Epoch 905/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0010 - val_loss: 0.0052\n",
      "Epoch 906/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0010 - val_loss: 0.0055\n",
      "Epoch 907/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 9.8586e-04 - val_loss: 0.0055\n",
      "Epoch 908/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 9.5964e-04 - val_loss: 0.0053\n",
      "Epoch 909/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0010 - val_loss: 0.0053\n",
      "Epoch 910/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0010 - val_loss: 0.0059\n",
      "Epoch 911/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0011 - val_loss: 0.0053\n",
      "Epoch 912/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0010 - val_loss: 0.0055\n",
      "Epoch 913/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0011 - val_loss: 0.0055\n",
      "Epoch 914/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 9.6998e-04 - val_loss: 0.0055\n",
      "Epoch 915/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 9.5019e-04 - val_loss: 0.0052\n",
      "Epoch 916/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0056\n",
      "Epoch 917/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 9.8272e-04 - val_loss: 0.0056\n",
      "Epoch 918/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0010 - val_loss: 0.0055\n",
      "Epoch 919/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0011 - val_loss: 0.0056\n",
      "Epoch 920/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 9.7225e-04 - val_loss: 0.0054\n",
      "Epoch 921/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 9.3801e-04 - val_loss: 0.0057\n",
      "Epoch 922/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0010 - val_loss: 0.0057\n",
      "Epoch 923/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0012 - val_loss: 0.0069\n",
      "Epoch 924/1000\n",
      "143/143 [==============================] - 0s 100us/step - loss: 0.0012 - val_loss: 0.0064\n",
      "Epoch 925/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0011 - val_loss: 0.0057\n",
      "Epoch 926/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0053\n",
      "Epoch 927/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0011 - val_loss: 0.0053\n",
      "Epoch 928/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0011 - val_loss: 0.0058\n",
      "Epoch 929/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 9.9474e-04 - val_loss: 0.0057\n",
      "Epoch 930/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0066\n",
      "Epoch 931/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0010 - val_loss: 0.0052\n",
      "Epoch 932/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0010 - val_loss: 0.0054\n",
      "Epoch 933/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0056\n",
      "Epoch 934/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0013 - val_loss: 0.0056\n",
      "Epoch 935/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0059\n",
      "Epoch 936/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0013 - val_loss: 0.0057\n",
      "Epoch 937/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0011 - val_loss: 0.0056\n",
      "Epoch 938/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0010 - val_loss: 0.0054\n",
      "Epoch 939/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0013 - val_loss: 0.0052\n",
      "Epoch 940/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 9.5378e-04 - val_loss: 0.0071\n",
      "Epoch 941/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0066\n",
      "Epoch 942/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0013 - val_loss: 0.0050\n",
      "Epoch 943/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0011 - val_loss: 0.0056\n",
      "Epoch 944/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 9.1365e-04 - val_loss: 0.0067\n",
      "Epoch 945/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0010 - val_loss: 0.0053\n",
      "Epoch 946/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0057\n",
      "Epoch 947/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0010 - val_loss: 0.0055\n",
      "Epoch 948/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 9.7302e-04 - val_loss: 0.0055\n",
      "Epoch 949/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 9.6477e-04 - val_loss: 0.0059\n",
      "Epoch 950/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 9.6849e-04 - val_loss: 0.0059\n",
      "Epoch 951/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0011 - val_loss: 0.0058\n",
      "Epoch 952/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 9.7303e-04 - val_loss: 0.0054\n",
      "Epoch 953/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 9.2778e-04 - val_loss: 0.0060\n",
      "Epoch 954/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 9.4609e-04 - val_loss: 0.0056\n",
      "Epoch 955/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0011 - val_loss: 0.0057\n",
      "Epoch 956/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0054\n",
      "Epoch 957/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0062\n",
      "Epoch 958/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0064\n",
      "Epoch 959/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0012 - val_loss: 0.0062\n",
      "Epoch 960/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0060\n",
      "Epoch 961/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0012 - val_loss: 0.0052\n",
      "Epoch 962/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0011 - val_loss: 0.0067\n",
      "Epoch 963/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0011 - val_loss: 0.0051\n",
      "Epoch 964/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0052\n",
      "Epoch 965/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0051\n",
      "Epoch 966/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 9.5733e-04 - val_loss: 0.0056\n",
      "Epoch 967/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0061\n",
      "Epoch 968/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0051\n",
      "Epoch 969/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0062\n",
      "Epoch 970/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0013 - val_loss: 0.0049\n",
      "Epoch 971/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0011 - val_loss: 0.0055\n",
      "Epoch 972/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 9.3680e-04 - val_loss: 0.0055\n",
      "Epoch 973/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 9.9814e-04 - val_loss: 0.0055\n",
      "Epoch 974/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0011 - val_loss: 0.0050\n",
      "Epoch 975/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0011 - val_loss: 0.0056\n",
      "Epoch 976/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0011 - val_loss: 0.0061\n",
      "Epoch 977/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0054\n",
      "Epoch 978/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0014 - val_loss: 0.0060\n",
      "Epoch 979/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0065\n",
      "Epoch 980/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0012 - val_loss: 0.0055\n",
      "Epoch 981/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 9.8057e-04 - val_loss: 0.0062\n",
      "Epoch 982/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0012 - val_loss: 0.0054\n",
      "Epoch 983/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0052\n",
      "Epoch 984/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 9.9235e-04 - val_loss: 0.0060\n",
      "Epoch 985/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 9.8869e-04 - val_loss: 0.0063\n",
      "Epoch 986/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0058\n",
      "Epoch 987/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0011 - val_loss: 0.0052\n",
      "Epoch 988/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 9.9301e-04 - val_loss: 0.0054\n",
      "Epoch 989/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0010 - val_loss: 0.0058\n",
      "Epoch 990/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0011 - val_loss: 0.0050\n",
      "Epoch 991/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0010 - val_loss: 0.0073\n",
      "Epoch 992/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 106us/step - loss: 0.0013 - val_loss: 0.0059\n",
      "Epoch 993/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0011 - val_loss: 0.0052\n",
      "Epoch 994/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 9.7538e-04 - val_loss: 0.0060\n",
      "Epoch 995/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0012 - val_loss: 0.0067\n",
      "Epoch 996/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0013 - val_loss: 0.0064\n",
      "Epoch 997/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0015 - val_loss: 0.0055\n",
      "Epoch 998/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0062\n",
      "Epoch 999/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0019 - val_loss: 0.0056\n",
      "Epoch 1000/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0067\n",
      "0.004818336572498083\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-9.04928327e-01,  5.18170118e-01, -1.55771365e-02,\n",
       "          2.80922651e-01,  8.63481998e-01,  8.31255317e-01,\n",
       "         -4.87107784e-01,  3.48561645e-01,  4.08805162e-01,\n",
       "         -1.61818862e-01],\n",
       "        [-5.41140556e-01,  2.73890823e-01, -2.36904368e-01,\n",
       "          9.03675407e-02, -6.92040741e-01,  5.78446507e-01,\n",
       "          7.34928489e-01,  2.72814534e-03, -7.65474141e-02,\n",
       "          1.16567202e-01],\n",
       "        [ 1.06496930e+00,  5.69713265e-02,  8.67590308e-02,\n",
       "         -3.16236109e-01, -5.60738205e-04,  2.24754378e-01,\n",
       "          2.02225015e-01, -2.42828846e-01,  4.09718186e-01,\n",
       "          7.56944567e-02],\n",
       "        [ 1.09439421e+00,  2.48776689e-01,  3.83852899e-01,\n",
       "         -1.11993238e-01,  8.93789887e-01, -2.98329797e-02,\n",
       "         -3.77590984e-01, -2.39643138e-02,  4.39037055e-01,\n",
       "         -2.91052669e-01],\n",
       "        [ 1.20551579e-01, -1.74420238e-01, -2.52269179e-01,\n",
       "          5.90089142e-01,  2.11817101e-01, -3.25537711e-01,\n",
       "         -4.08314496e-01, -3.05178523e-01,  2.18927234e-01,\n",
       "          2.16087867e-02],\n",
       "        [-1.01834536e+00,  9.12625790e-02, -7.44033933e-01,\n",
       "         -2.04576373e-01, -3.37794662e-01, -9.44743514e-01,\n",
       "         -4.44696844e-01,  2.26170689e-01, -1.68589473e-01,\n",
       "          4.31938231e-01],\n",
       "        [ 7.91542351e-01,  2.16793343e-01, -1.40373021e-01,\n",
       "          1.84175204e-02, -5.44602513e-01,  6.54425398e-02,\n",
       "          1.66428223e-01, -1.50170594e-01,  6.01705849e-01,\n",
       "         -6.58632219e-02],\n",
       "        [-2.91510373e-01,  2.73915410e-01,  9.02463347e-02,\n",
       "         -3.32176656e-01,  2.71195676e-02, -7.03393444e-02,\n",
       "          1.68487225e-02, -2.43187398e-01,  1.53529644e-01,\n",
       "          5.07630765e-01],\n",
       "        [ 6.79071486e-01, -7.33548522e-01, -6.15896463e-01,\n",
       "         -4.98770118e-01,  1.28557599e+00, -1.17478716e+00,\n",
       "          1.01486437e-01, -7.79579282e-02,  1.56115338e-01,\n",
       "          6.41345263e-01],\n",
       "        [-6.36561632e-01, -2.44919613e-01,  1.62503827e+00,\n",
       "          1.92602828e-01, -8.06527138e-01,  6.72558665e-01,\n",
       "         -3.27120692e-01,  8.80510062e-02, -1.26105875e-01,\n",
       "         -4.62997407e-02],\n",
       "        [ 4.40107912e-01,  2.04166397e-01,  4.31477845e-01,\n",
       "          3.27116251e-01,  4.39604998e-01, -3.12995195e-01,\n",
       "          1.26002157e+00,  2.68191159e-01,  5.52841485e-01,\n",
       "          1.14393324e-01],\n",
       "        [ 3.70082408e-01,  5.37727177e-01,  1.12830925e+00,\n",
       "         -2.05387637e-01, -7.10938036e-01, -3.09046954e-01,\n",
       "          2.72697657e-01, -1.19223818e-02,  7.02696443e-02,\n",
       "          9.05484557e-02],\n",
       "        [-2.29174837e-01,  5.36330879e-01,  8.61585438e-01,\n",
       "          1.33936018e-01, -5.12872458e-01, -3.89777809e-01,\n",
       "          4.62437093e-01,  5.63951954e-02,  4.95347321e-01,\n",
       "          6.34283796e-02],\n",
       "        [-1.28579986e+00,  1.43502876e-01, -4.45793599e-01,\n",
       "          1.09173506e-02,  1.09033668e+00, -1.42929494e+00,\n",
       "         -2.76106410e-02,  2.34116629e-01,  3.45593870e-01,\n",
       "         -1.02466688e-01],\n",
       "        [-4.37992007e-01,  3.24737757e-01, -2.37950206e-01,\n",
       "         -2.16286272e-01, -9.71514583e-02,  4.02665257e-01,\n",
       "          4.06773865e-01,  5.02334721e-02,  3.94855857e-01,\n",
       "         -2.90086985e-01],\n",
       "        [-3.77415478e-01,  1.44151658e-01,  3.15890223e-01,\n",
       "         -1.59842461e-01,  7.28911757e-01,  5.65569162e-01,\n",
       "          2.83073366e-01,  1.79419073e-03,  1.58719912e-01,\n",
       "          2.88240552e-01],\n",
       "        [ 5.38564920e-01,  1.19065475e-02,  1.72808558e-01,\n",
       "          1.84260055e-01, -3.66439223e-01, -3.72926384e-01,\n",
       "         -4.13329005e-01, -1.41755208e-01,  3.22641969e-01,\n",
       "          2.04188660e-01],\n",
       "        [ 1.16720927e+00, -5.65348268e-01, -2.45491341e-01,\n",
       "         -5.09988248e-01, -5.74687600e-01, -1.27537083e-02,\n",
       "         -3.30039531e-01,  8.31744596e-02,  7.34703541e-02,\n",
       "          8.12787097e-03],\n",
       "        [-2.07132727e-01, -6.72282726e-02, -7.91288972e-01,\n",
       "          6.72153234e-02,  4.96080518e-01,  5.81698477e-01,\n",
       "         -1.00567482e-01, -3.51948798e-01,  4.23175454e-01,\n",
       "          2.89956719e-01],\n",
       "        [ 3.10717165e-01, -1.63107371e+00,  1.80845737e-01,\n",
       "         -2.26240888e-01,  9.95957017e-01,  1.69929600e+00,\n",
       "          2.22742017e-02,  1.34351403e-01,  4.02475804e-01,\n",
       "         -1.14496261e-01],\n",
       "        [ 9.10648882e-01, -5.24542809e-01,  5.93542576e-01,\n",
       "         -1.34042099e-01, -1.82359695e+00,  6.55350447e-01,\n",
       "         -3.86899374e-02, -6.37253225e-02,  5.04703633e-02,\n",
       "         -2.44741365e-01],\n",
       "        [ 3.77226621e-01, -6.44422948e-01,  1.58685058e-01,\n",
       "          2.91301668e-01, -1.12208772e+00, -2.60313749e-02,\n",
       "          3.96231443e-01, -1.26404494e-01,  1.90698802e-01,\n",
       "         -5.96499071e-02]], dtype=float32),\n",
       " array([ 0.6983135 ,  0.06459986,  0.17048213, -0.10886261, -0.46302614,\n",
       "         0.5317274 , -0.02326193,  0.15910055,  0.13719794,  0.09186039],\n",
       "       dtype=float32),\n",
       " array([[-3.14258665e-01, -2.87229598e-01,  2.90636152e-01,\n",
       "         -2.47437656e-01, -5.16076624e-01,  2.24550098e-01,\n",
       "         -4.12187546e-01,  5.57257794e-02,  3.08003902e-01,\n",
       "          7.73120448e-02, -6.14214718e-01,  1.55131966e-01,\n",
       "         -2.44602978e-01, -2.90959179e-01, -3.32663447e-01],\n",
       "        [ 6.65374994e-02, -1.84677556e-01, -9.15875062e-02,\n",
       "          1.92569360e-01, -4.13800180e-01,  2.73486018e-01,\n",
       "         -4.08323437e-01,  1.06624693e-01,  1.26761384e-03,\n",
       "         -4.03890252e-01, -1.34186774e-01,  3.16957533e-02,\n",
       "         -1.01119488e-01, -1.83032127e-03,  6.08334504e-02],\n",
       "        [ 1.81864649e-01,  2.69632876e-01,  3.95361818e-02,\n",
       "          8.08692053e-02,  6.28185928e-01, -4.52959329e-01,\n",
       "          8.35662484e-02,  3.69360268e-01, -3.14129502e-01,\n",
       "          7.76437521e-02,  3.04989308e-01,  1.14982855e-03,\n",
       "         -3.77189666e-01,  2.82906532e-01,  1.28629446e-01],\n",
       "        [ 1.78371862e-01, -9.06885862e-02,  6.29637092e-02,\n",
       "         -4.34439868e-01, -1.96553007e-01, -2.91284233e-01,\n",
       "         -1.68883875e-01, -1.84926614e-01,  6.75193919e-03,\n",
       "          3.71501654e-01, -2.73390003e-02,  3.25638689e-02,\n",
       "          2.50980616e-01, -2.29654685e-01, -1.75665334e-01],\n",
       "        [ 4.07866478e-01, -1.06538171e-02,  2.02881679e-01,\n",
       "         -2.38711953e-01,  2.30170757e-01, -5.35913818e-02,\n",
       "         -2.09737808e-01,  2.29664311e-01,  3.23745757e-01,\n",
       "          4.43756372e-01,  8.51004496e-02, -4.66689974e-01,\n",
       "         -4.73590165e-01,  4.02407110e-01,  5.95536716e-02],\n",
       "        [-5.97914398e-01,  7.38892183e-02, -3.04943062e-02,\n",
       "         -1.49778381e-01, -4.14264888e-01,  1.63894966e-01,\n",
       "         -1.96759298e-01, -2.09759876e-01,  1.03137933e-01,\n",
       "         -8.40230808e-02,  1.20039694e-01,  1.61231175e-01,\n",
       "         -3.98029648e-02, -3.42019528e-01, -2.24321324e-04],\n",
       "        [ 1.03041887e-01, -1.50761575e-01,  3.11258078e-01,\n",
       "         -1.77650645e-01,  2.95526356e-01, -4.74103749e-01,\n",
       "         -1.98919475e-01, -9.49464440e-02,  2.51917690e-01,\n",
       "          1.02950200e-01, -2.89618760e-01, -7.78038204e-02,\n",
       "          1.92456871e-01, -1.14354722e-01,  3.64868760e-01],\n",
       "        [ 2.21058682e-01,  4.46225004e-03, -3.94556165e-01,\n",
       "         -3.32672924e-01,  2.57991046e-01,  3.54653895e-01,\n",
       "          5.07298447e-02,  3.66486073e-01,  2.55798846e-01,\n",
       "          2.68825859e-01,  3.38369250e-01,  4.31070834e-01,\n",
       "          4.61091697e-02, -3.73414457e-01,  1.26552820e-01],\n",
       "        [ 4.35331762e-01, -1.76487654e-01, -1.34447530e-01,\n",
       "         -2.39637017e-01,  4.18004930e-01, -3.17198992e-01,\n",
       "         -3.09292287e-01, -2.23038286e-01, -2.96461526e-02,\n",
       "          2.58547336e-01,  3.63353342e-01,  5.38200513e-02,\n",
       "          2.14714497e-01,  2.84839094e-01,  2.60334015e-01],\n",
       "        [ 8.92203003e-02,  2.55205423e-01, -2.12785080e-01,\n",
       "          4.09694016e-01, -6.14832044e-01, -1.27676651e-01,\n",
       "          4.06987160e-01,  1.95130244e-01, -1.44238710e-01,\n",
       "         -7.54614323e-02, -7.90952593e-02, -4.46306258e-01,\n",
       "          3.49291056e-01, -2.49202311e-01, -5.20015895e-01]], dtype=float32),\n",
       " array([ 0.11087865, -0.04625196,  0.05450163, -0.0613573 ,  0.06949648,\n",
       "         0.00465432,  0.1463228 , -0.02857038,  0.13750371,  0.0545251 ,\n",
       "         0.02167326, -0.10245369, -0.15690784,  0.16105257,  0.06467306],\n",
       "       dtype=float32),\n",
       " array([[ 0.24477829],\n",
       "        [ 0.01365729],\n",
       "        [-0.00776973],\n",
       "        [ 0.00482937],\n",
       "        [ 0.21804245],\n",
       "        [-0.30417436],\n",
       "        [ 0.07185323],\n",
       "        [ 0.02329944],\n",
       "        [-0.01493556],\n",
       "        [ 0.0157391 ],\n",
       "        [ 0.08279989],\n",
       "        [-0.03318001],\n",
       "        [-0.01338807],\n",
       "        [ 0.08142435],\n",
       "        [ 0.03204186]], dtype=float32),\n",
       " array([0.0721689], dtype=float32)]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_automobile, history_automobile, evaluate_automobile=NN_model_structure_regression_6(X_train_automobile, X_val_automobile, Y_train_automobile, Y_val_automobile, adam2, 32, 1000, x_test_automobile, y_test_automobile)\n",
    "model_automobile.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_automobile.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_automobile_structure6_4th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_55 (Dense)             (None, 5)                 20        \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 56\n",
      "Trainable params: 56\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 32 samples, validate on 7 samples\n",
      "Epoch 1/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 37.2572 - val_loss: 34.6341\n",
      "Epoch 2/1000\n",
      "32/32 [==============================] - 0s 130us/step - loss: 34.5809 - val_loss: 31.9102\n",
      "Epoch 3/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 31.7687 - val_loss: 28.6734\n",
      "Epoch 4/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 28.7285 - val_loss: 24.7461\n",
      "Epoch 5/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 25.1384 - val_loss: 20.2897\n",
      "Epoch 6/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 20.9084 - val_loss: 15.5344\n",
      "Epoch 7/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 16.1611 - val_loss: 10.7040\n",
      "Epoch 8/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 11.1788 - val_loss: 6.1855\n",
      "Epoch 9/1000\n",
      "32/32 [==============================] - 0s 131us/step - loss: 6.4162 - val_loss: 2.5714\n",
      "Epoch 10/1000\n",
      "32/32 [==============================] - 0s 131us/step - loss: 2.5452 - val_loss: 0.5857\n",
      "Epoch 11/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 0.4301 - val_loss: 0.7290\n",
      "Epoch 12/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.7792 - val_loss: 2.3221\n",
      "Epoch 13/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9538 - val_loss: 3.5426\n",
      "Epoch 14/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.7222 - val_loss: 3.6487\n",
      "Epoch 15/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9953 - val_loss: 2.9303\n",
      "Epoch 16/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0402 - val_loss: 1.9044\n",
      "Epoch 17/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.5704 - val_loss: 1.0434\n",
      "Epoch 18/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2564 - val_loss: 0.5878\n",
      "Epoch 19/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.4627 - val_loss: 0.5158\n",
      "Epoch 20/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 0.2218 - val_loss: 0.6671\n",
      "Epoch 21/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.3598 - val_loss: 0.8742\n",
      "Epoch 22/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.6573 - val_loss: 1.0241\n",
      "Epoch 23/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 0.9485 - val_loss: 1.0668\n",
      "Epoch 24/1000\n",
      "32/32 [==============================] - 0s 131us/step - loss: 1.1428 - val_loss: 1.0003\n",
      "Epoch 25/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2102 - val_loss: 0.8525\n",
      "Epoch 26/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 1.1593 - val_loss: 0.6641\n",
      "Epoch 27/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0192 - val_loss: 0.4752\n",
      "Epoch 28/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.8267 - val_loss: 0.3147\n",
      "Epoch 29/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.6174 - val_loss: 0.1988\n",
      "Epoch 30/1000\n",
      "32/32 [==============================] - 0s 110us/step - loss: 0.4225 - val_loss: 0.1339\n",
      "Epoch 31/1000\n",
      "32/32 [==============================] - 0s 138us/step - loss: 0.2663 - val_loss: 0.1207\n",
      "Epoch 32/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.1648 - val_loss: 0.1541\n",
      "Epoch 33/1000\n",
      "32/32 [==============================] - 0s 164us/step - loss: 0.1240 - val_loss: 0.2217\n",
      "Epoch 34/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1379 - val_loss: 0.3044\n",
      "Epoch 35/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.1899 - val_loss: 0.3807\n",
      "Epoch 36/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.2561 - val_loss: 0.4320\n",
      "Epoch 37/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.3124 - val_loss: 0.4479\n",
      "Epoch 38/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.3407 - val_loss: 0.4280\n",
      "Epoch 39/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 0.3341 - val_loss: 0.3799\n",
      "Epoch 40/1000\n",
      "32/32 [==============================] - 0s 137us/step - loss: 0.2964 - val_loss: 0.3152\n",
      "Epoch 41/1000\n",
      "32/32 [==============================] - 0s 131us/step - loss: 0.2392 - val_loss: 0.2457\n",
      "Epoch 42/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1765 - val_loss: 0.1811\n",
      "Epoch 43/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.1203 - val_loss: 0.1277\n",
      "Epoch 44/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0785 - val_loss: 0.0891\n",
      "Epoch 45/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0541 - val_loss: 0.0665\n",
      "Epoch 46/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0460 - val_loss: 0.0588\n",
      "Epoch 47/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0506 - val_loss: 0.0634\n",
      "Epoch 48/1000\n",
      "32/32 [==============================] - 0s 145us/step - loss: 0.0627 - val_loss: 0.0760\n",
      "Epoch 49/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 0.0771 - val_loss: 0.0915\n",
      "Epoch 50/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0893 - val_loss: 0.1047\n",
      "Epoch 51/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 0.0960 - val_loss: 0.1117\n",
      "Epoch 52/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0958 - val_loss: 0.1101\n",
      "Epoch 53/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0888 - val_loss: 0.1002\n",
      "Epoch 54/1000\n",
      "32/32 [==============================] - 0s 128us/step - loss: 0.0765 - val_loss: 0.0836\n",
      "Epoch 55/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0616 - val_loss: 0.0636\n",
      "Epoch 56/1000\n",
      "32/32 [==============================] - 0s 129us/step - loss: 0.0468 - val_loss: 0.0434\n",
      "Epoch 57/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 0.0347 - val_loss: 0.0262\n",
      "Epoch 58/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0268 - val_loss: 0.0136\n",
      "Epoch 59/1000\n",
      "32/32 [==============================] - 0s 121us/step - loss: 0.0235 - val_loss: 0.0064\n",
      "Epoch 60/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0242 - val_loss: 0.0040\n",
      "Epoch 61/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0275 - val_loss: 0.0049\n",
      "Epoch 62/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0316 - val_loss: 0.0075\n",
      "Epoch 63/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 0.0350 - val_loss: 0.0104\n",
      "Epoch 64/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 0.0367 - val_loss: 0.0125\n",
      "Epoch 65/1000\n",
      "32/32 [==============================] - 0s 132us/step - loss: 0.0363 - val_loss: 0.0134\n",
      "Epoch 66/1000\n",
      "32/32 [==============================] - 0s 127us/step - loss: 0.0341 - val_loss: 0.0131\n",
      "Epoch 67/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0306 - val_loss: 0.0120\n",
      "Epoch 68/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0266 - val_loss: 0.0105\n",
      "Epoch 69/1000\n",
      "32/32 [==============================] - 0s 130us/step - loss: 0.0228 - val_loss: 0.0090\n",
      "Epoch 70/1000\n",
      "32/32 [==============================] - 0s 129us/step - loss: 0.0198 - val_loss: 0.0080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 0.0179 - val_loss: 0.0077\n",
      "Epoch 72/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0172 - val_loss: 0.0079\n",
      "Epoch 73/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0175 - val_loss: 0.0085\n",
      "Epoch 74/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0183 - val_loss: 0.0092\n",
      "Epoch 75/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 0.0193 - val_loss: 0.0098\n",
      "Epoch 76/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0200 - val_loss: 0.0101\n",
      "Epoch 77/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0203 - val_loss: 0.0099\n",
      "Epoch 78/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 0.0200 - val_loss: 0.0094\n",
      "Epoch 79/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0191 - val_loss: 0.0085\n",
      "Epoch 80/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0180 - val_loss: 0.0074\n",
      "Epoch 81/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 0.0168 - val_loss: 0.0063\n",
      "Epoch 82/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0156 - val_loss: 0.0054\n",
      "Epoch 83/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 0.0147 - val_loss: 0.0047\n",
      "Epoch 84/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0142 - val_loss: 0.0042\n",
      "Epoch 85/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0139 - val_loss: 0.0040\n",
      "Epoch 86/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 0.0139 - val_loss: 0.0040\n",
      "Epoch 87/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0141 - val_loss: 0.0040\n",
      "Epoch 88/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0143 - val_loss: 0.0041\n",
      "Epoch 89/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0144 - val_loss: 0.0042\n",
      "Epoch 90/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0144 - val_loss: 0.0041\n",
      "Epoch 91/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0143 - val_loss: 0.0040\n",
      "Epoch 92/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0140 - val_loss: 0.0038\n",
      "Epoch 93/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0136 - val_loss: 0.0036\n",
      "Epoch 94/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0132 - val_loss: 0.0034\n",
      "Epoch 95/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0129 - val_loss: 0.0033\n",
      "Epoch 96/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0126 - val_loss: 0.0034\n",
      "Epoch 97/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0124 - val_loss: 0.0034\n",
      "Epoch 98/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0123 - val_loss: 0.0036\n",
      "Epoch 99/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0122 - val_loss: 0.0037\n",
      "Epoch 100/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0122 - val_loss: 0.0037\n",
      "Epoch 101/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0122 - val_loss: 0.0037\n",
      "Epoch 102/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0121 - val_loss: 0.0037\n",
      "Epoch 103/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0121 - val_loss: 0.0036\n",
      "Epoch 104/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0119 - val_loss: 0.0035\n",
      "Epoch 105/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0118 - val_loss: 0.0033\n",
      "Epoch 106/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0116 - val_loss: 0.0032\n",
      "Epoch 107/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0115 - val_loss: 0.0031\n",
      "Epoch 108/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0113 - val_loss: 0.0030\n",
      "Epoch 109/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0112 - val_loss: 0.0029\n",
      "Epoch 110/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0111 - val_loss: 0.0029\n",
      "Epoch 111/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0110 - val_loss: 0.0028\n",
      "Epoch 112/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0109 - val_loss: 0.0028\n",
      "Epoch 113/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0109 - val_loss: 0.0028\n",
      "Epoch 114/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0108 - val_loss: 0.0027\n",
      "Epoch 115/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0107 - val_loss: 0.0026\n",
      "Epoch 116/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0107 - val_loss: 0.0026\n",
      "Epoch 117/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0106 - val_loss: 0.0025\n",
      "Epoch 118/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0105 - val_loss: 0.0024\n",
      "Epoch 119/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0104 - val_loss: 0.0023\n",
      "Epoch 120/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0103 - val_loss: 0.0023\n",
      "Epoch 121/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0102 - val_loss: 0.0022\n",
      "Epoch 122/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0101 - val_loss: 0.0022\n",
      "Epoch 123/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0101 - val_loss: 0.0022\n",
      "Epoch 124/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0100 - val_loss: 0.0022\n",
      "Epoch 125/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0099 - val_loss: 0.0022\n",
      "Epoch 126/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0099 - val_loss: 0.0022\n",
      "Epoch 127/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0098 - val_loss: 0.0022\n",
      "Epoch 128/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0097 - val_loss: 0.0022\n",
      "Epoch 129/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0097 - val_loss: 0.0022\n",
      "Epoch 130/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0096 - val_loss: 0.0021\n",
      "Epoch 131/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0095 - val_loss: 0.0021\n",
      "Epoch 132/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0095 - val_loss: 0.0020\n",
      "Epoch 133/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0094 - val_loss: 0.0020\n",
      "Epoch 134/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0093 - val_loss: 0.0020\n",
      "Epoch 135/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0093 - val_loss: 0.0019\n",
      "Epoch 136/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0092 - val_loss: 0.0019\n",
      "Epoch 137/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0091 - val_loss: 0.0019\n",
      "Epoch 138/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0091 - val_loss: 0.0018\n",
      "Epoch 139/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0090 - val_loss: 0.0018\n",
      "Epoch 140/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0090 - val_loss: 0.0018\n",
      "Epoch 141/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0089 - val_loss: 0.0018\n",
      "Epoch 142/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0088 - val_loss: 0.0018\n",
      "Epoch 143/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0088 - val_loss: 0.0018\n",
      "Epoch 144/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0087 - val_loss: 0.0018\n",
      "Epoch 145/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0087 - val_loss: 0.0018\n",
      "Epoch 146/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0086 - val_loss: 0.0017\n",
      "Epoch 147/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0086 - val_loss: 0.0017\n",
      "Epoch 148/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0085 - val_loss: 0.0017\n",
      "Epoch 149/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0085 - val_loss: 0.0017\n",
      "Epoch 150/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0084 - val_loss: 0.0017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0084 - val_loss: 0.0017\n",
      "Epoch 152/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0083 - val_loss: 0.0017\n",
      "Epoch 153/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0083 - val_loss: 0.0017\n",
      "Epoch 154/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0082 - val_loss: 0.0017\n",
      "Epoch 155/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0082 - val_loss: 0.0017\n",
      "Epoch 156/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0081 - val_loss: 0.0016\n",
      "Epoch 157/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0081 - val_loss: 0.0016\n",
      "Epoch 158/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0080 - val_loss: 0.0016\n",
      "Epoch 159/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0080 - val_loss: 0.0016\n",
      "Epoch 160/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0079 - val_loss: 0.0016\n",
      "Epoch 161/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0079 - val_loss: 0.0015\n",
      "Epoch 162/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0078 - val_loss: 0.0015\n",
      "Epoch 163/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0078 - val_loss: 0.0015\n",
      "Epoch 164/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0077 - val_loss: 0.0015\n",
      "Epoch 165/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0077 - val_loss: 0.0015\n",
      "Epoch 166/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0076 - val_loss: 0.0015\n",
      "Epoch 167/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0076 - val_loss: 0.0014\n",
      "Epoch 168/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0076 - val_loss: 0.0014\n",
      "Epoch 169/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0075 - val_loss: 0.0014\n",
      "Epoch 170/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0075 - val_loss: 0.0014\n",
      "Epoch 171/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0074 - val_loss: 0.0014\n",
      "Epoch 172/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0074 - val_loss: 0.0014\n",
      "Epoch 173/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0073 - val_loss: 0.0014\n",
      "Epoch 174/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0073 - val_loss: 0.0014\n",
      "Epoch 175/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0073 - val_loss: 0.0013\n",
      "Epoch 176/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0072 - val_loss: 0.0013\n",
      "Epoch 177/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0072 - val_loss: 0.0013\n",
      "Epoch 178/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0071 - val_loss: 0.0013\n",
      "Epoch 179/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0071 - val_loss: 0.0013\n",
      "Epoch 180/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0071 - val_loss: 0.0013\n",
      "Epoch 181/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0070 - val_loss: 0.0013\n",
      "Epoch 182/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0070 - val_loss: 0.0013\n",
      "Epoch 183/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0070 - val_loss: 0.0013\n",
      "Epoch 184/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0069 - val_loss: 0.0012\n",
      "Epoch 185/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0069 - val_loss: 0.0012\n",
      "Epoch 186/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0068 - val_loss: 0.0012\n",
      "Epoch 187/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0068 - val_loss: 0.0012\n",
      "Epoch 188/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0068 - val_loss: 0.0012\n",
      "Epoch 189/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0067 - val_loss: 0.0012\n",
      "Epoch 190/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0067 - val_loss: 0.0012\n",
      "Epoch 191/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0067 - val_loss: 0.0012\n",
      "Epoch 192/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0066 - val_loss: 0.0012\n",
      "Epoch 193/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0066 - val_loss: 0.0011\n",
      "Epoch 194/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0066 - val_loss: 0.0011\n",
      "Epoch 195/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0065 - val_loss: 0.0011\n",
      "Epoch 196/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0065 - val_loss: 0.0011\n",
      "Epoch 197/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0065 - val_loss: 0.0011\n",
      "Epoch 198/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0064 - val_loss: 0.0011\n",
      "Epoch 199/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0064 - val_loss: 0.0011\n",
      "Epoch 200/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0064 - val_loss: 0.0011\n",
      "Epoch 201/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0063 - val_loss: 0.0011\n",
      "Epoch 202/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0063 - val_loss: 0.0011\n",
      "Epoch 203/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0063 - val_loss: 0.0011\n",
      "Epoch 204/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0062 - val_loss: 0.0011\n",
      "Epoch 205/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0062 - val_loss: 0.0010\n",
      "Epoch 206/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0062 - val_loss: 0.0010\n",
      "Epoch 207/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0062 - val_loss: 0.0010\n",
      "Epoch 208/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0061 - val_loss: 0.0010\n",
      "Epoch 209/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0061 - val_loss: 0.0010\n",
      "Epoch 210/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0061 - val_loss: 9.9883e-04\n",
      "Epoch 211/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0060 - val_loss: 9.9063e-04\n",
      "Epoch 212/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0060 - val_loss: 9.8261e-04\n",
      "Epoch 213/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0060 - val_loss: 9.7476e-04\n",
      "Epoch 214/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0059 - val_loss: 9.6708e-04\n",
      "Epoch 215/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0059 - val_loss: 9.5955e-04\n",
      "Epoch 216/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0059 - val_loss: 9.5214e-04\n",
      "Epoch 217/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0059 - val_loss: 9.4488e-04\n",
      "Epoch 218/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0058 - val_loss: 9.3771e-04\n",
      "Epoch 219/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0058 - val_loss: 9.3064e-04\n",
      "Epoch 220/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0058 - val_loss: 9.2360e-04\n",
      "Epoch 221/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0058 - val_loss: 9.1669e-04\n",
      "Epoch 222/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0057 - val_loss: 9.0980e-04\n",
      "Epoch 223/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0057 - val_loss: 9.0300e-04\n",
      "Epoch 224/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0057 - val_loss: 8.9624e-04\n",
      "Epoch 225/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0057 - val_loss: 8.8954e-04\n",
      "Epoch 226/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0056 - val_loss: 8.8289e-04\n",
      "Epoch 227/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0056 - val_loss: 8.7630e-04\n",
      "Epoch 228/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0056 - val_loss: 8.6976e-04\n",
      "Epoch 229/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0056 - val_loss: 8.6327e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 230/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0055 - val_loss: 8.5686e-04\n",
      "Epoch 231/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0055 - val_loss: 8.5049e-04\n",
      "Epoch 232/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0055 - val_loss: 8.4419e-04\n",
      "Epoch 233/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0055 - val_loss: 8.3795e-04\n",
      "Epoch 234/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 0.0054 - val_loss: 8.3181e-04\n",
      "Epoch 235/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0054 - val_loss: 8.2573e-04\n",
      "Epoch 236/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0054 - val_loss: 8.1972e-04\n",
      "Epoch 237/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0054 - val_loss: 8.1381e-04\n",
      "Epoch 238/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0053 - val_loss: 8.0798e-04\n",
      "Epoch 239/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0053 - val_loss: 8.0221e-04\n",
      "Epoch 240/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0053 - val_loss: 7.9652e-04\n",
      "Epoch 241/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0053 - val_loss: 7.9093e-04\n",
      "Epoch 242/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0052 - val_loss: 7.8538e-04\n",
      "Epoch 243/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0052 - val_loss: 7.7991e-04\n",
      "Epoch 244/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0052 - val_loss: 7.7450e-04\n",
      "Epoch 245/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0052 - val_loss: 7.6914e-04\n",
      "Epoch 246/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0051 - val_loss: 7.6385e-04\n",
      "Epoch 247/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0051 - val_loss: 7.5861e-04\n",
      "Epoch 248/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0051 - val_loss: 7.5341e-04\n",
      "Epoch 249/1000\n",
      "32/32 [==============================] - 0s 132us/step - loss: 0.0051 - val_loss: 7.4826e-04\n",
      "Epoch 250/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0051 - val_loss: 7.4316e-04\n",
      "Epoch 251/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0050 - val_loss: 7.3812e-04\n",
      "Epoch 252/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0050 - val_loss: 7.3312e-04\n",
      "Epoch 253/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0050 - val_loss: 7.2818e-04\n",
      "Epoch 254/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0050 - val_loss: 7.2331e-04\n",
      "Epoch 255/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0050 - val_loss: 7.1846e-04\n",
      "Epoch 256/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0049 - val_loss: 7.1368e-04\n",
      "Epoch 257/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0049 - val_loss: 7.0894e-04\n",
      "Epoch 258/1000\n",
      "32/32 [==============================] - 0s 138us/step - loss: 0.0049 - val_loss: 7.0425e-04\n",
      "Epoch 259/1000\n",
      "32/32 [==============================] - 0s 122us/step - loss: 0.0049 - val_loss: 6.9961e-04\n",
      "Epoch 260/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0049 - val_loss: 6.9503e-04\n",
      "Epoch 261/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0048 - val_loss: 6.9051e-04\n",
      "Epoch 262/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 0.0048 - val_loss: 6.8604e-04\n",
      "Epoch 263/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0048 - val_loss: 6.8161e-04\n",
      "Epoch 264/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0048 - val_loss: 6.7724e-04\n",
      "Epoch 265/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0048 - val_loss: 6.7292e-04\n",
      "Epoch 266/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0047 - val_loss: 6.6865e-04\n",
      "Epoch 267/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0047 - val_loss: 6.6443e-04\n",
      "Epoch 268/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0047 - val_loss: 6.6024e-04\n",
      "Epoch 269/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0047 - val_loss: 6.5612e-04\n",
      "Epoch 270/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0047 - val_loss: 6.5204e-04\n",
      "Epoch 271/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0046 - val_loss: 6.4798e-04\n",
      "Epoch 272/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0046 - val_loss: 6.4398e-04\n",
      "Epoch 273/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0046 - val_loss: 6.4001e-04\n",
      "Epoch 274/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0046 - val_loss: 6.3608e-04\n",
      "Epoch 275/1000\n",
      "32/32 [==============================] - 0s 130us/step - loss: 0.0046 - val_loss: 6.3220e-04\n",
      "Epoch 276/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0045 - val_loss: 6.2836e-04\n",
      "Epoch 277/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0045 - val_loss: 6.2455e-04\n",
      "Epoch 278/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0045 - val_loss: 6.2078e-04\n",
      "Epoch 279/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0045 - val_loss: 6.1705e-04\n",
      "Epoch 280/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0045 - val_loss: 6.1336e-04\n",
      "Epoch 281/1000\n",
      "32/32 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 6.0970e-04\n",
      "Epoch 282/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0044 - val_loss: 6.0609e-04\n",
      "Epoch 283/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0044 - val_loss: 6.0251e-04\n",
      "Epoch 284/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0044 - val_loss: 5.9898e-04\n",
      "Epoch 285/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0044 - val_loss: 5.9548e-04\n",
      "Epoch 286/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0044 - val_loss: 5.9201e-04\n",
      "Epoch 287/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0043 - val_loss: 5.8859e-04\n",
      "Epoch 288/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0043 - val_loss: 5.8519e-04\n",
      "Epoch 289/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0043 - val_loss: 5.8184e-04\n",
      "Epoch 290/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0043 - val_loss: 5.7851e-04\n",
      "Epoch 291/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0043 - val_loss: 5.7523e-04\n",
      "Epoch 292/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0043 - val_loss: 5.7197e-04\n",
      "Epoch 293/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0042 - val_loss: 5.6874e-04\n",
      "Epoch 294/1000\n",
      "32/32 [==============================] - 0s 166us/step - loss: 0.0042 - val_loss: 5.6557e-04\n",
      "Epoch 295/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0042 - val_loss: 5.6242e-04\n",
      "Epoch 296/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0042 - val_loss: 5.5930e-04\n",
      "Epoch 297/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0042 - val_loss: 5.5622e-04\n",
      "Epoch 298/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0042 - val_loss: 5.5316e-04\n",
      "Epoch 299/1000\n",
      "32/32 [==============================] - 0s 119us/step - loss: 0.0042 - val_loss: 5.5013e-04\n",
      "Epoch 300/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0041 - val_loss: 5.4713e-04\n",
      "Epoch 301/1000\n",
      "32/32 [==============================] - 0s 120us/step - loss: 0.0041 - val_loss: 5.4418e-04\n",
      "Epoch 302/1000\n",
      "32/32 [==============================] - 0s 121us/step - loss: 0.0041 - val_loss: 5.4124e-04\n",
      "Epoch 303/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0041 - val_loss: 5.3834e-04\n",
      "Epoch 304/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0041 - val_loss: 5.3547e-04\n",
      "Epoch 305/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0041 - val_loss: 5.3261e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 306/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0040 - val_loss: 5.2980e-04\n",
      "Epoch 307/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0040 - val_loss: 5.2699e-04\n",
      "Epoch 308/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0040 - val_loss: 5.2424e-04\n",
      "Epoch 309/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0040 - val_loss: 5.2151e-04\n",
      "Epoch 310/1000\n",
      "32/32 [==============================] - 0s 138us/step - loss: 0.0040 - val_loss: 5.1880e-04\n",
      "Epoch 311/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0040 - val_loss: 5.1613e-04\n",
      "Epoch 312/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0040 - val_loss: 5.1348e-04\n",
      "Epoch 313/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0039 - val_loss: 5.1085e-04\n",
      "Epoch 314/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0039 - val_loss: 5.0825e-04\n",
      "Epoch 315/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0039 - val_loss: 5.0568e-04\n",
      "Epoch 316/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 0.0039 - val_loss: 5.0314e-04\n",
      "Epoch 317/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0039 - val_loss: 5.0062e-04\n",
      "Epoch 318/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 0.0039 - val_loss: 4.9813e-04\n",
      "Epoch 319/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0038 - val_loss: 4.9566e-04\n",
      "Epoch 320/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0038 - val_loss: 4.9322e-04\n",
      "Epoch 321/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0038 - val_loss: 4.9079e-04\n",
      "Epoch 322/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 0.0038 - val_loss: 4.8838e-04\n",
      "Epoch 323/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0038 - val_loss: 4.8601e-04\n",
      "Epoch 324/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0038 - val_loss: 4.8365e-04\n",
      "Epoch 325/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0038 - val_loss: 4.8131e-04\n",
      "Epoch 326/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0037 - val_loss: 4.7900e-04\n",
      "Epoch 327/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0037 - val_loss: 4.7673e-04\n",
      "Epoch 328/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 0.0037 - val_loss: 4.7446e-04\n",
      "Epoch 329/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0037 - val_loss: 4.7223e-04\n",
      "Epoch 330/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0037 - val_loss: 4.7001e-04\n",
      "Epoch 331/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0037 - val_loss: 4.6782e-04\n",
      "Epoch 332/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0037 - val_loss: 4.6565e-04\n",
      "Epoch 333/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 0.0037 - val_loss: 4.6350e-04\n",
      "Epoch 334/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0036 - val_loss: 4.6136e-04\n",
      "Epoch 335/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0036 - val_loss: 4.5924e-04\n",
      "Epoch 336/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0036 - val_loss: 4.5714e-04\n",
      "Epoch 337/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0036 - val_loss: 4.5507e-04\n",
      "Epoch 338/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0036 - val_loss: 4.5302e-04\n",
      "Epoch 339/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0036 - val_loss: 4.5098e-04\n",
      "Epoch 340/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0036 - val_loss: 4.4896e-04\n",
      "Epoch 341/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0035 - val_loss: 4.4696e-04\n",
      "Epoch 342/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0035 - val_loss: 4.4498e-04\n",
      "Epoch 343/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0035 - val_loss: 4.4303e-04\n",
      "Epoch 344/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0035 - val_loss: 4.4108e-04\n",
      "Epoch 345/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0035 - val_loss: 4.3916e-04\n",
      "Epoch 346/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0035 - val_loss: 4.3726e-04\n",
      "Epoch 347/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0035 - val_loss: 4.3537e-04\n",
      "Epoch 348/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0035 - val_loss: 4.3351e-04\n",
      "Epoch 349/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0034 - val_loss: 4.3165e-04\n",
      "Epoch 350/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0034 - val_loss: 4.2982e-04\n",
      "Epoch 351/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0034 - val_loss: 4.2801e-04\n",
      "Epoch 352/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0034 - val_loss: 4.2620e-04\n",
      "Epoch 353/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0034 - val_loss: 4.2442e-04\n",
      "Epoch 354/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0034 - val_loss: 4.2265e-04\n",
      "Epoch 355/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0034 - val_loss: 4.2090e-04\n",
      "Epoch 356/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0034 - val_loss: 4.1916e-04\n",
      "Epoch 357/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0034 - val_loss: 4.1743e-04\n",
      "Epoch 358/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0033 - val_loss: 4.1574e-04\n",
      "Epoch 359/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0033 - val_loss: 4.1405e-04\n",
      "Epoch 360/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0033 - val_loss: 4.1237e-04\n",
      "Epoch 361/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0033 - val_loss: 4.1071e-04\n",
      "Epoch 362/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0033 - val_loss: 4.0907e-04\n",
      "Epoch 363/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0033 - val_loss: 4.0744e-04\n",
      "Epoch 364/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0033 - val_loss: 4.0583e-04\n",
      "Epoch 365/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0033 - val_loss: 4.0423e-04\n",
      "Epoch 366/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0032 - val_loss: 4.0263e-04\n",
      "Epoch 367/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0032 - val_loss: 4.0107e-04\n",
      "Epoch 368/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0032 - val_loss: 3.9951e-04\n",
      "Epoch 369/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 0.0032 - val_loss: 3.9797e-04\n",
      "Epoch 370/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 0.0032 - val_loss: 3.9644e-04\n",
      "Epoch 371/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 0.0032 - val_loss: 3.9492e-04\n",
      "Epoch 372/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 3.9341e-04\n",
      "Epoch 373/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0032 - val_loss: 3.9192e-04\n",
      "Epoch 374/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0032 - val_loss: 3.9043e-04\n",
      "Epoch 375/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0031 - val_loss: 3.8898e-04\n",
      "Epoch 376/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0031 - val_loss: 3.8752e-04\n",
      "Epoch 377/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0031 - val_loss: 3.8607e-04\n",
      "Epoch 378/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0031 - val_loss: 3.8464e-04\n",
      "Epoch 379/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0031 - val_loss: 3.8323e-04\n",
      "Epoch 380/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0031 - val_loss: 3.8182e-04\n",
      "Epoch 381/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0031 - val_loss: 3.8043e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 382/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0031 - val_loss: 3.7905e-04\n",
      "Epoch 383/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0031 - val_loss: 3.7768e-04\n",
      "Epoch 384/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0030 - val_loss: 3.7633e-04\n",
      "Epoch 385/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 3.7497e-04\n",
      "Epoch 386/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 3.7364e-04\n",
      "Epoch 387/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 3.7231e-04\n",
      "Epoch 388/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 0.0030 - val_loss: 3.7100e-04\n",
      "Epoch 389/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0030 - val_loss: 3.6970e-04\n",
      "Epoch 390/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 3.6841e-04\n",
      "Epoch 391/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 0.0030 - val_loss: 3.6711e-04\n",
      "Epoch 392/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 3.6584e-04\n",
      "Epoch 393/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 3.6458e-04\n",
      "Epoch 394/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0029 - val_loss: 3.6332e-04\n",
      "Epoch 395/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 3.6208e-04\n",
      "Epoch 396/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0029 - val_loss: 3.6085e-04\n",
      "Epoch 397/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 3.5962e-04\n",
      "Epoch 398/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 3.5842e-04\n",
      "Epoch 399/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0029 - val_loss: 3.5722e-04\n",
      "Epoch 400/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 0.0029 - val_loss: 3.5603e-04\n",
      "Epoch 401/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0029 - val_loss: 3.5484e-04\n",
      "Epoch 402/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0029 - val_loss: 3.5367e-04\n",
      "Epoch 403/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0029 - val_loss: 3.5250e-04\n",
      "Epoch 404/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 3.5134e-04\n",
      "Epoch 405/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 3.5019e-04\n",
      "Epoch 406/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0028 - val_loss: 3.4905e-04\n",
      "Epoch 407/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0028 - val_loss: 3.4792e-04\n",
      "Epoch 408/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 3.4680e-04\n",
      "Epoch 409/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 3.4568e-04\n",
      "Epoch 410/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 3.4458e-04\n",
      "Epoch 411/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0028 - val_loss: 3.4348e-04\n",
      "Epoch 412/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0028 - val_loss: 3.4238e-04\n",
      "Epoch 413/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 3.4130e-04\n",
      "Epoch 414/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 3.4022e-04\n",
      "Epoch 415/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 3.3917e-04\n",
      "Epoch 416/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0027 - val_loss: 3.3809e-04\n",
      "Epoch 417/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 3.3704e-04\n",
      "Epoch 418/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0027 - val_loss: 3.3599e-04\n",
      "Epoch 419/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0027 - val_loss: 3.3495e-04\n",
      "Epoch 420/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0027 - val_loss: 3.3392e-04\n",
      "Epoch 421/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0027 - val_loss: 3.3290e-04\n",
      "Epoch 422/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0027 - val_loss: 3.3188e-04\n",
      "Epoch 423/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0027 - val_loss: 3.3088e-04\n",
      "Epoch 424/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 3.2988e-04\n",
      "Epoch 425/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0027 - val_loss: 3.2889e-04\n",
      "Epoch 426/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0026 - val_loss: 3.2790e-04\n",
      "Epoch 427/1000\n",
      "32/32 [==============================] - 0s 130us/step - loss: 0.0026 - val_loss: 3.2691e-04\n",
      "Epoch 428/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0026 - val_loss: 3.2594e-04\n",
      "Epoch 429/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 0.0026 - val_loss: 3.2496e-04\n",
      "Epoch 430/1000\n",
      "32/32 [==============================] - 0s 160us/step - loss: 0.0026 - val_loss: 3.2399e-04\n",
      "Epoch 431/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0026 - val_loss: 3.2304e-04\n",
      "Epoch 432/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0026 - val_loss: 3.2209e-04\n",
      "Epoch 433/1000\n",
      "32/32 [==============================] - 0s 131us/step - loss: 0.0026 - val_loss: 3.2114e-04\n",
      "Epoch 434/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 0.0026 - val_loss: 3.2021e-04\n",
      "Epoch 435/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 3.1928e-04\n",
      "Epoch 436/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 3.1836e-04\n",
      "Epoch 437/1000\n",
      "32/32 [==============================] - 0s 165us/step - loss: 0.0026 - val_loss: 3.1743e-04\n",
      "Epoch 438/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 3.1652e-04\n",
      "Epoch 439/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0025 - val_loss: 3.1561e-04\n",
      "Epoch 440/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0025 - val_loss: 3.1471e-04\n",
      "Epoch 441/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 3.1381e-04\n",
      "Epoch 442/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0025 - val_loss: 3.1291e-04\n",
      "Epoch 443/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0025 - val_loss: 3.1202e-04\n",
      "Epoch 444/1000\n",
      "32/32 [==============================] - 0s 120us/step - loss: 0.0025 - val_loss: 3.1114e-04\n",
      "Epoch 445/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0025 - val_loss: 3.1027e-04\n",
      "Epoch 446/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0025 - val_loss: 3.0939e-04\n",
      "Epoch 447/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 3.0853e-04\n",
      "Epoch 448/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 3.0766e-04\n",
      "Epoch 449/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0025 - val_loss: 3.0681e-04\n",
      "Epoch 450/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0024 - val_loss: 3.0595e-04\n",
      "Epoch 451/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 3.0511e-04\n",
      "Epoch 452/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 3.0426e-04\n",
      "Epoch 453/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 3.0343e-04\n",
      "Epoch 454/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 3.0261e-04\n",
      "Epoch 455/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 3.0177e-04\n",
      "Epoch 456/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 3.0095e-04\n",
      "Epoch 457/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 0.0024 - val_loss: 3.0013e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 458/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 2.9931e-04\n",
      "Epoch 459/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 2.9850e-04\n",
      "Epoch 460/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 2.9768e-04\n",
      "Epoch 461/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0024 - val_loss: 2.9689e-04\n",
      "Epoch 462/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0024 - val_loss: 2.9609e-04\n",
      "Epoch 463/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 2.9530e-04\n",
      "Epoch 464/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 2.9452e-04\n",
      "Epoch 465/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0023 - val_loss: 2.9372e-04\n",
      "Epoch 466/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 2.9294e-04\n",
      "Epoch 467/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 2.9217e-04\n",
      "Epoch 468/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 2.9140e-04\n",
      "Epoch 469/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0023 - val_loss: 2.9063e-04\n",
      "Epoch 470/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 2.8986e-04\n",
      "Epoch 471/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 2.8909e-04\n",
      "Epoch 472/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0023 - val_loss: 2.8833e-04\n",
      "Epoch 473/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0023 - val_loss: 2.8757e-04\n",
      "Epoch 474/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0023 - val_loss: 2.8683e-04\n",
      "Epoch 475/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 0.0023 - val_loss: 2.8608e-04\n",
      "Epoch 476/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0022 - val_loss: 2.8533e-04\n",
      "Epoch 477/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 2.8459e-04\n",
      "Epoch 478/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0022 - val_loss: 2.8385e-04\n",
      "Epoch 479/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0022 - val_loss: 2.8311e-04\n",
      "Epoch 480/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0022 - val_loss: 2.8239e-04\n",
      "Epoch 481/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 0.0022 - val_loss: 2.8166e-04\n",
      "Epoch 482/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 2.8094e-04\n",
      "Epoch 483/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0022 - val_loss: 2.8021e-04\n",
      "Epoch 484/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 2.7949e-04\n",
      "Epoch 485/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0022 - val_loss: 2.7877e-04\n",
      "Epoch 486/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 2.7806e-04\n",
      "Epoch 487/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0022 - val_loss: 2.7735e-04\n",
      "Epoch 488/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 2.7664e-04\n",
      "Epoch 489/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 2.7594e-04\n",
      "Epoch 490/1000\n",
      "32/32 [==============================] - 0s 122us/step - loss: 0.0022 - val_loss: 2.7524e-04\n",
      "Epoch 491/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 0.0021 - val_loss: 2.7454e-04\n",
      "Epoch 492/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0021 - val_loss: 2.7384e-04\n",
      "Epoch 493/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 2.7316e-04\n",
      "Epoch 494/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 2.7246e-04\n",
      "Epoch 495/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0021 - val_loss: 2.7178e-04\n",
      "Epoch 496/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0021 - val_loss: 2.7109e-04\n",
      "Epoch 497/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 2.7041e-04\n",
      "Epoch 498/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0021 - val_loss: 2.6973e-04\n",
      "Epoch 499/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 2.6905e-04\n",
      "Epoch 500/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0021 - val_loss: 2.6838e-04\n",
      "Epoch 501/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 2.6771e-04\n",
      "Epoch 502/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 2.6704e-04\n",
      "Epoch 503/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 2.6637e-04\n",
      "Epoch 504/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0021 - val_loss: 2.6570e-04\n",
      "Epoch 505/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 2.6504e-04\n",
      "Epoch 506/1000\n",
      "32/32 [==============================] - 0s 160us/step - loss: 0.0020 - val_loss: 2.6438e-04\n",
      "Epoch 507/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 2.6372e-04\n",
      "Epoch 508/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0020 - val_loss: 2.6307e-04\n",
      "Epoch 509/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 0.0020 - val_loss: 2.6241e-04\n",
      "Epoch 510/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 0.0020 - val_loss: 2.6176e-04\n",
      "Epoch 511/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 2.6112e-04\n",
      "Epoch 512/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 0.0020 - val_loss: 2.6047e-04\n",
      "Epoch 513/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 0.0020 - val_loss: 2.5983e-04\n",
      "Epoch 514/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 0.0020 - val_loss: 2.5918e-04\n",
      "Epoch 515/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 2.5854e-04\n",
      "Epoch 516/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 2.5790e-04\n",
      "Epoch 517/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 2.5727e-04\n",
      "Epoch 518/1000\n",
      "32/32 [==============================] - 0s 129us/step - loss: 0.0020 - val_loss: 2.5663e-04\n",
      "Epoch 519/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0020 - val_loss: 2.5601e-04\n",
      "Epoch 520/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 0.0020 - val_loss: 2.5537e-04\n",
      "Epoch 521/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0020 - val_loss: 2.5475e-04\n",
      "Epoch 522/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 0.0019 - val_loss: 2.5412e-04\n",
      "Epoch 523/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 2.5350e-04\n",
      "Epoch 524/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 2.5288e-04\n",
      "Epoch 525/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 0.0019 - val_loss: 2.5226e-04\n",
      "Epoch 526/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0019 - val_loss: 2.5164e-04\n",
      "Epoch 527/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 2.5102e-04\n",
      "Epoch 528/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 2.5041e-04\n",
      "Epoch 529/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 2.4980e-04\n",
      "Epoch 530/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 2.4918e-04\n",
      "Epoch 531/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 2.4858e-04\n",
      "Epoch 532/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 2.4797e-04\n",
      "Epoch 533/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 2.4736e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 534/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 2.4675e-04\n",
      "Epoch 535/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 2.4615e-04\n",
      "Epoch 536/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 0.0019 - val_loss: 2.4555e-04\n",
      "Epoch 537/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 2.4496e-04\n",
      "Epoch 538/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0019 - val_loss: 2.4436e-04\n",
      "Epoch 539/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 2.4377e-04\n",
      "Epoch 540/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 0.0018 - val_loss: 2.4317e-04\n",
      "Epoch 541/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 2.4258e-04\n",
      "Epoch 542/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 2.4198e-04\n",
      "Epoch 543/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 0.0018 - val_loss: 2.4139e-04\n",
      "Epoch 544/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 2.4080e-04\n",
      "Epoch 545/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0018 - val_loss: 2.4022e-04\n",
      "Epoch 546/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 2.3963e-04\n",
      "Epoch 547/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 2.3905e-04\n",
      "Epoch 548/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 2.3847e-04\n",
      "Epoch 549/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 2.3789e-04\n",
      "Epoch 550/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 2.3731e-04\n",
      "Epoch 551/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 2.3673e-04\n",
      "Epoch 552/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 2.3616e-04\n",
      "Epoch 553/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0018 - val_loss: 2.3559e-04\n",
      "Epoch 554/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0018 - val_loss: 2.3501e-04\n",
      "Epoch 555/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 2.3444e-04\n",
      "Epoch 556/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 2.3387e-04\n",
      "Epoch 557/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 2.3330e-04\n",
      "Epoch 558/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 2.3273e-04\n",
      "Epoch 559/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 2.3217e-04\n",
      "Epoch 560/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 2.3161e-04\n",
      "Epoch 561/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 2.3104e-04\n",
      "Epoch 562/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 2.3048e-04\n",
      "Epoch 563/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0017 - val_loss: 2.2992e-04\n",
      "Epoch 564/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 2.2936e-04\n",
      "Epoch 565/1000\n",
      "32/32 [==============================] - 0s 131us/step - loss: 0.0017 - val_loss: 2.2880e-04\n",
      "Epoch 566/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 2.2824e-04\n",
      "Epoch 567/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0017 - val_loss: 2.2770e-04\n",
      "Epoch 568/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 2.2714e-04\n",
      "Epoch 569/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 0.0017 - val_loss: 2.2658e-04\n",
      "Epoch 570/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0017 - val_loss: 2.2603e-04\n",
      "Epoch 571/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 2.2547e-04\n",
      "Epoch 572/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 0.0017 - val_loss: 2.2493e-04\n",
      "Epoch 573/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 0.0017 - val_loss: 2.2438e-04\n",
      "Epoch 574/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 2.2383e-04\n",
      "Epoch 575/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 2.2329e-04\n",
      "Epoch 576/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0017 - val_loss: 2.2275e-04\n",
      "Epoch 577/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 0.0017 - val_loss: 2.2221e-04\n",
      "Epoch 578/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0016 - val_loss: 2.2168e-04\n",
      "Epoch 579/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 2.2113e-04\n",
      "Epoch 580/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 2.2059e-04\n",
      "Epoch 581/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 2.2005e-04\n",
      "Epoch 582/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 0.0016 - val_loss: 2.1952e-04\n",
      "Epoch 583/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 0.0016 - val_loss: 2.1898e-04\n",
      "Epoch 584/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 2.1844e-04\n",
      "Epoch 585/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0016 - val_loss: 2.1791e-04\n",
      "Epoch 586/1000\n",
      "32/32 [==============================] - 0s 122us/step - loss: 0.0016 - val_loss: 2.1738e-04\n",
      "Epoch 587/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 2.1685e-04\n",
      "Epoch 588/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0016 - val_loss: 2.1632e-04\n",
      "Epoch 589/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 0.0016 - val_loss: 2.1579e-04\n",
      "Epoch 590/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 2.1528e-04\n",
      "Epoch 591/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 2.1474e-04\n",
      "Epoch 592/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 0.0016 - val_loss: 2.1423e-04\n",
      "Epoch 593/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 2.1370e-04\n",
      "Epoch 594/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 2.1317e-04\n",
      "Epoch 595/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 2.1265e-04\n",
      "Epoch 596/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 0.0016 - val_loss: 2.1213e-04\n",
      "Epoch 597/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 2.1161e-04\n",
      "Epoch 598/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 0.0016 - val_loss: 2.1109e-04\n",
      "Epoch 599/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 2.1059e-04\n",
      "Epoch 600/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 2.1006e-04\n",
      "Epoch 601/1000\n",
      "32/32 [==============================] - 0s 145us/step - loss: 0.0015 - val_loss: 2.0955e-04\n",
      "Epoch 602/1000\n",
      "32/32 [==============================] - 0s 133us/step - loss: 0.0015 - val_loss: 2.0904e-04\n",
      "Epoch 603/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 0.0015 - val_loss: 2.0852e-04\n",
      "Epoch 604/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 0.0015 - val_loss: 2.0802e-04\n",
      "Epoch 605/1000\n",
      "32/32 [==============================] - 0s 160us/step - loss: 0.0015 - val_loss: 2.0751e-04\n",
      "Epoch 606/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 2.0700e-04\n",
      "Epoch 607/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 0.0015 - val_loss: 2.0650e-04\n",
      "Epoch 608/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 2.0599e-04\n",
      "Epoch 609/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 2.0548e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 610/1000\n",
      "32/32 [==============================] - 0s 174us/step - loss: 0.0015 - val_loss: 2.0498e-04\n",
      "Epoch 611/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 2.0447e-04\n",
      "Epoch 612/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 0.0015 - val_loss: 2.0397e-04\n",
      "Epoch 613/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 2.0347e-04\n",
      "Epoch 614/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0015 - val_loss: 2.0297e-04\n",
      "Epoch 615/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0015 - val_loss: 2.0247e-04\n",
      "Epoch 616/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 2.0198e-04\n",
      "Epoch 617/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 2.0148e-04\n",
      "Epoch 618/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 2.0099e-04\n",
      "Epoch 619/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 2.0049e-04\n",
      "Epoch 620/1000\n",
      "32/32 [==============================] - 0s 133us/step - loss: 0.0015 - val_loss: 2.0000e-04\n",
      "Epoch 621/1000\n",
      "32/32 [==============================] - 0s 133us/step - loss: 0.0015 - val_loss: 1.9951e-04\n",
      "Epoch 622/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 1.9902e-04\n",
      "Epoch 623/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 1.9854e-04\n",
      "Epoch 624/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0014 - val_loss: 1.9804e-04\n",
      "Epoch 625/1000\n",
      "32/32 [==============================] - 0s 121us/step - loss: 0.0014 - val_loss: 1.9755e-04\n",
      "Epoch 626/1000\n",
      "32/32 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 1.9706e-04\n",
      "Epoch 627/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0014 - val_loss: 1.9658e-04\n",
      "Epoch 628/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0014 - val_loss: 1.9609e-04\n",
      "Epoch 629/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 0.0014 - val_loss: 1.9561e-04\n",
      "Epoch 630/1000\n",
      "32/32 [==============================] - 0s 183us/step - loss: 0.0014 - val_loss: 1.9513e-04\n",
      "Epoch 631/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 1.9465e-04\n",
      "Epoch 632/1000\n",
      "32/32 [==============================] - 0s 128us/step - loss: 0.0014 - val_loss: 1.9417e-04\n",
      "Epoch 633/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 0.0014 - val_loss: 1.9369e-04\n",
      "Epoch 634/1000\n",
      "32/32 [==============================] - 0s 128us/step - loss: 0.0014 - val_loss: 1.9321e-04\n",
      "Epoch 635/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 1.9274e-04\n",
      "Epoch 636/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 1.9226e-04\n",
      "Epoch 637/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 1.9179e-04\n",
      "Epoch 638/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 0.0014 - val_loss: 1.9131e-04\n",
      "Epoch 639/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 1.9085e-04\n",
      "Epoch 640/1000\n",
      "32/32 [==============================] - 0s 145us/step - loss: 0.0014 - val_loss: 1.9037e-04\n",
      "Epoch 641/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 1.8991e-04\n",
      "Epoch 642/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0014 - val_loss: 1.8943e-04\n",
      "Epoch 643/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 1.8897e-04\n",
      "Epoch 644/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0014 - val_loss: 1.8850e-04\n",
      "Epoch 645/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 1.8804e-04\n",
      "Epoch 646/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 1.8757e-04\n",
      "Epoch 647/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 1.8710e-04\n",
      "Epoch 648/1000\n",
      "32/32 [==============================] - 0s 122us/step - loss: 0.0014 - val_loss: 1.8664e-04\n",
      "Epoch 649/1000\n",
      "32/32 [==============================] - 0s 161us/step - loss: 0.0013 - val_loss: 1.8618e-04\n",
      "Epoch 650/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 1.8572e-04\n",
      "Epoch 651/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0013 - val_loss: 1.8526e-04\n",
      "Epoch 652/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 1.8481e-04\n",
      "Epoch 653/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 1.8435e-04\n",
      "Epoch 654/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 1.8389e-04\n",
      "Epoch 655/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 1.8344e-04\n",
      "Epoch 656/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 1.8299e-04\n",
      "Epoch 657/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 1.8253e-04\n",
      "Epoch 658/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0013 - val_loss: 1.8208e-04\n",
      "Epoch 659/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0013 - val_loss: 1.8162e-04\n",
      "Epoch 660/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0013 - val_loss: 1.8117e-04\n",
      "Epoch 661/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 1.8072e-04\n",
      "Epoch 662/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 1.8027e-04\n",
      "Epoch 663/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 1.7984e-04\n",
      "Epoch 664/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 1.7939e-04\n",
      "Epoch 665/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 1.7895e-04\n",
      "Epoch 666/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 1.7851e-04\n",
      "Epoch 667/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0013 - val_loss: 1.7807e-04\n",
      "Epoch 668/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 1.7763e-04\n",
      "Epoch 669/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 1.7719e-04\n",
      "Epoch 670/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 1.7675e-04\n",
      "Epoch 671/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 0.0013 - val_loss: 1.7631e-04\n",
      "Epoch 672/1000\n",
      "32/32 [==============================] - 0s 161us/step - loss: 0.0013 - val_loss: 1.7587e-04\n",
      "Epoch 673/1000\n",
      "32/32 [==============================] - 0s 145us/step - loss: 0.0013 - val_loss: 1.7543e-04\n",
      "Epoch 674/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0013 - val_loss: 1.7500e-04\n",
      "Epoch 675/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 1.7456e-04\n",
      "Epoch 676/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 1.7413e-04\n",
      "Epoch 677/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 0.0012 - val_loss: 1.7370e-04\n",
      "Epoch 678/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 1.7327e-04\n",
      "Epoch 679/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0012 - val_loss: 1.7285e-04\n",
      "Epoch 680/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0012 - val_loss: 1.7242e-04\n",
      "Epoch 681/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 1.7198e-04\n",
      "Epoch 682/1000\n",
      "32/32 [==============================] - 0s 164us/step - loss: 0.0012 - val_loss: 1.7157e-04\n",
      "Epoch 683/1000\n",
      "32/32 [==============================] - 0s 163us/step - loss: 0.0012 - val_loss: 1.7113e-04\n",
      "Epoch 684/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 1.7071e-04\n",
      "Epoch 685/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0012 - val_loss: 1.7029e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 686/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 1.6987e-04\n",
      "Epoch 687/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 0.0012 - val_loss: 1.6945e-04\n",
      "Epoch 688/1000\n",
      "32/32 [==============================] - 0s 122us/step - loss: 0.0012 - val_loss: 1.6904e-04\n",
      "Epoch 689/1000\n",
      "32/32 [==============================] - 0s 138us/step - loss: 0.0012 - val_loss: 1.6861e-04\n",
      "Epoch 690/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 1.6820e-04\n",
      "Epoch 691/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 0.0012 - val_loss: 1.6778e-04\n",
      "Epoch 692/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0012 - val_loss: 1.6737e-04\n",
      "Epoch 693/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 0.0012 - val_loss: 1.6696e-04\n",
      "Epoch 694/1000\n",
      "32/32 [==============================] - 0s 138us/step - loss: 0.0012 - val_loss: 1.6654e-04\n",
      "Epoch 695/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 1.6612e-04\n",
      "Epoch 696/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 0.0012 - val_loss: 1.6571e-04\n",
      "Epoch 697/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 1.6530e-04\n",
      "Epoch 698/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0012 - val_loss: 1.6489e-04\n",
      "Epoch 699/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 1.6449e-04\n",
      "Epoch 700/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 1.6408e-04\n",
      "Epoch 701/1000\n",
      "32/32 [==============================] - 0s 145us/step - loss: 0.0012 - val_loss: 1.6367e-04\n",
      "Epoch 702/1000\n",
      "32/32 [==============================] - 0s 145us/step - loss: 0.0012 - val_loss: 1.6327e-04\n",
      "Epoch 703/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 1.6287e-04\n",
      "Epoch 704/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 1.6247e-04\n",
      "Epoch 705/1000\n",
      "32/32 [==============================] - 0s 130us/step - loss: 0.0012 - val_loss: 1.6207e-04\n",
      "Epoch 706/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0012 - val_loss: 1.6167e-04\n",
      "Epoch 707/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0012 - val_loss: 1.6127e-04\n",
      "Epoch 708/1000\n",
      "32/32 [==============================] - 0s 130us/step - loss: 0.0012 - val_loss: 1.6087e-04\n",
      "Epoch 709/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 1.6047e-04\n",
      "Epoch 710/1000\n",
      "32/32 [==============================] - 0s 137us/step - loss: 0.0011 - val_loss: 1.6007e-04\n",
      "Epoch 711/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 1.5968e-04\n",
      "Epoch 712/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 1.5928e-04\n",
      "Epoch 713/1000\n",
      "32/32 [==============================] - 0s 175us/step - loss: 0.0011 - val_loss: 1.5889e-04\n",
      "Epoch 714/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 0.0011 - val_loss: 1.5850e-04\n",
      "Epoch 715/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 1.5811e-04\n",
      "Epoch 716/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 1.5772e-04\n",
      "Epoch 717/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 1.5734e-04\n",
      "Epoch 718/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 1.5694e-04\n",
      "Epoch 719/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 1.5656e-04\n",
      "Epoch 720/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 0.0011 - val_loss: 1.5618e-04\n",
      "Epoch 721/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0011 - val_loss: 1.5579e-04\n",
      "Epoch 722/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 0.0011 - val_loss: 1.5540e-04\n",
      "Epoch 723/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 1.5502e-04\n",
      "Epoch 724/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 1.5463e-04\n",
      "Epoch 725/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 0.0011 - val_loss: 1.5426e-04\n",
      "Epoch 726/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 1.5387e-04\n",
      "Epoch 727/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 1.5350e-04\n",
      "Epoch 728/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0011 - val_loss: 1.5312e-04\n",
      "Epoch 729/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0011 - val_loss: 1.5274e-04\n",
      "Epoch 730/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 0.0011 - val_loss: 1.5236e-04\n",
      "Epoch 731/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 0.0011 - val_loss: 1.5200e-04\n",
      "Epoch 732/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0011 - val_loss: 1.5162e-04\n",
      "Epoch 733/1000\n",
      "32/32 [==============================] - 0s 169us/step - loss: 0.0011 - val_loss: 1.5126e-04\n",
      "Epoch 734/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 0.0011 - val_loss: 1.5088e-04\n",
      "Epoch 735/1000\n",
      "32/32 [==============================] - 0s 130us/step - loss: 0.0011 - val_loss: 1.5052e-04\n",
      "Epoch 736/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 0.0011 - val_loss: 1.5015e-04\n",
      "Epoch 737/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0011 - val_loss: 1.4977e-04\n",
      "Epoch 738/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 1.4940e-04\n",
      "Epoch 739/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 1.4904e-04\n",
      "Epoch 740/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 0.0011 - val_loss: 1.4867e-04\n",
      "Epoch 741/1000\n",
      "32/32 [==============================] - 0s 137us/step - loss: 0.0011 - val_loss: 1.4830e-04\n",
      "Epoch 742/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 1.4794e-04\n",
      "Epoch 743/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 1.4758e-04\n",
      "Epoch 744/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 1.4722e-04\n",
      "Epoch 745/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 1.4686e-04\n",
      "Epoch 746/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 1.4650e-04\n",
      "Epoch 747/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 1.4614e-04\n",
      "Epoch 748/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 1.4579e-04\n",
      "Epoch 749/1000\n",
      "32/32 [==============================] - 0s 117us/step - loss: 0.0010 - val_loss: 1.4543e-04\n",
      "Epoch 750/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0010 - val_loss: 1.4508e-04\n",
      "Epoch 751/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 1.4472e-04\n",
      "Epoch 752/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 0.0010 - val_loss: 1.4438e-04\n",
      "Epoch 753/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 1.4402e-04\n",
      "Epoch 754/1000\n",
      "32/32 [==============================] - 0s 128us/step - loss: 0.0010 - val_loss: 1.4367e-04\n",
      "Epoch 755/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 0.0010 - val_loss: 1.4333e-04\n",
      "Epoch 756/1000\n",
      "32/32 [==============================] - 0s 138us/step - loss: 0.0010 - val_loss: 1.4297e-04\n",
      "Epoch 757/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 1.4262e-04\n",
      "Epoch 758/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 1.4227e-04\n",
      "Epoch 759/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0010 - val_loss: 1.4192e-04\n",
      "Epoch 760/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 0.0010 - val_loss: 1.4158e-04\n",
      "Epoch 761/1000\n",
      "32/32 [==============================] - 0s 112us/step - loss: 0.0010 - val_loss: 1.4123e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 762/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 1.4089e-04\n",
      "Epoch 763/1000\n",
      "32/32 [==============================] - 0s 132us/step - loss: 0.0010 - val_loss: 1.4054e-04\n",
      "Epoch 764/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 9.9751e-04 - val_loss: 1.4021e-04\n",
      "Epoch 765/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 9.9502e-04 - val_loss: 1.3987e-04\n",
      "Epoch 766/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 9.9253e-04 - val_loss: 1.3953e-04\n",
      "Epoch 767/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.9006e-04 - val_loss: 1.3919e-04\n",
      "Epoch 768/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.8759e-04 - val_loss: 1.3886e-04\n",
      "Epoch 769/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.8512e-04 - val_loss: 1.3853e-04\n",
      "Epoch 770/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.8268e-04 - val_loss: 1.3819e-04\n",
      "Epoch 771/1000\n",
      "32/32 [==============================] - 0s 117us/step - loss: 9.8023e-04 - val_loss: 1.3786e-04\n",
      "Epoch 772/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 9.7780e-04 - val_loss: 1.3752e-04\n",
      "Epoch 773/1000\n",
      "32/32 [==============================] - 0s 132us/step - loss: 9.7536e-04 - val_loss: 1.3718e-04\n",
      "Epoch 774/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.7294e-04 - val_loss: 1.3685e-04\n",
      "Epoch 775/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 9.7053e-04 - val_loss: 1.3652e-04\n",
      "Epoch 776/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 9.6812e-04 - val_loss: 1.3618e-04\n",
      "Epoch 777/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 9.6572e-04 - val_loss: 1.3585e-04\n",
      "Epoch 778/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6333e-04 - val_loss: 1.3553e-04\n",
      "Epoch 779/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.6094e-04 - val_loss: 1.3520e-04\n",
      "Epoch 780/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 9.5856e-04 - val_loss: 1.3488e-04\n",
      "Epoch 781/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.5621e-04 - val_loss: 1.3456e-04\n",
      "Epoch 782/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.5384e-04 - val_loss: 1.3423e-04\n",
      "Epoch 783/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.5149e-04 - val_loss: 1.3390e-04\n",
      "Epoch 784/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 9.4914e-04 - val_loss: 1.3358e-04\n",
      "Epoch 785/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4680e-04 - val_loss: 1.3326e-04\n",
      "Epoch 786/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4447e-04 - val_loss: 1.3294e-04\n",
      "Epoch 787/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4215e-04 - val_loss: 1.3262e-04\n",
      "Epoch 788/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.3984e-04 - val_loss: 1.3230e-04\n",
      "Epoch 789/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3753e-04 - val_loss: 1.3199e-04\n",
      "Epoch 790/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3523e-04 - val_loss: 1.3167e-04\n",
      "Epoch 791/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3293e-04 - val_loss: 1.3136e-04\n",
      "Epoch 792/1000\n",
      "32/32 [==============================] - 0s 137us/step - loss: 9.3064e-04 - val_loss: 1.3104e-04\n",
      "Epoch 793/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 9.2836e-04 - val_loss: 1.3073e-04\n",
      "Epoch 794/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.2609e-04 - val_loss: 1.3042e-04\n",
      "Epoch 795/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 9.2383e-04 - val_loss: 1.3011e-04\n",
      "Epoch 796/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 9.2157e-04 - val_loss: 1.2978e-04\n",
      "Epoch 797/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1932e-04 - val_loss: 1.2948e-04\n",
      "Epoch 798/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1707e-04 - val_loss: 1.2917e-04\n",
      "Epoch 799/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 9.1484e-04 - val_loss: 1.2886e-04\n",
      "Epoch 800/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1261e-04 - val_loss: 1.2855e-04\n",
      "Epoch 801/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1038e-04 - val_loss: 1.2824e-04\n",
      "Epoch 802/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.0818e-04 - val_loss: 1.2793e-04\n",
      "Epoch 803/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 9.0596e-04 - val_loss: 1.2763e-04\n",
      "Epoch 804/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.0376e-04 - val_loss: 1.2733e-04\n",
      "Epoch 805/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.0157e-04 - val_loss: 1.2702e-04\n",
      "Epoch 806/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.9938e-04 - val_loss: 1.2672e-04\n",
      "Epoch 807/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.9720e-04 - val_loss: 1.2642e-04\n",
      "Epoch 808/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.9502e-04 - val_loss: 1.2613e-04\n",
      "Epoch 809/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9286e-04 - val_loss: 1.2582e-04\n",
      "Epoch 810/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9069e-04 - val_loss: 1.2552e-04\n",
      "Epoch 811/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.8854e-04 - val_loss: 1.2523e-04\n",
      "Epoch 812/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.8639e-04 - val_loss: 1.2493e-04\n",
      "Epoch 813/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 8.8425e-04 - val_loss: 1.2463e-04\n",
      "Epoch 814/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.8211e-04 - val_loss: 1.2433e-04\n",
      "Epoch 815/1000\n",
      "32/32 [==============================] - 0s 114us/step - loss: 8.8000e-04 - val_loss: 1.2404e-04\n",
      "Epoch 816/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 8.7787e-04 - val_loss: 1.2375e-04\n",
      "Epoch 817/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 8.7575e-04 - val_loss: 1.2345e-04\n",
      "Epoch 818/1000\n",
      "32/32 [==============================] - 0s 121us/step - loss: 8.7365e-04 - val_loss: 1.2317e-04\n",
      "Epoch 819/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7155e-04 - val_loss: 1.2287e-04\n",
      "Epoch 820/1000\n",
      "32/32 [==============================] - 0s 132us/step - loss: 8.6946e-04 - val_loss: 1.2258e-04\n",
      "Epoch 821/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 8.6737e-04 - val_loss: 1.2230e-04\n",
      "Epoch 822/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.6529e-04 - val_loss: 1.2201e-04\n",
      "Epoch 823/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.6321e-04 - val_loss: 1.2172e-04\n",
      "Epoch 824/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.6115e-04 - val_loss: 1.2143e-04\n",
      "Epoch 825/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5908e-04 - val_loss: 1.2114e-04\n",
      "Epoch 826/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 8.5703e-04 - val_loss: 1.2086e-04\n",
      "Epoch 827/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 8.5498e-04 - val_loss: 1.2057e-04\n",
      "Epoch 828/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5293e-04 - val_loss: 1.2029e-04\n",
      "Epoch 829/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.5090e-04 - val_loss: 1.2001e-04\n",
      "Epoch 830/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 8.4887e-04 - val_loss: 1.1972e-04\n",
      "Epoch 831/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 8.4685e-04 - val_loss: 1.1945e-04\n",
      "Epoch 832/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 8.4483e-04 - val_loss: 1.1916e-04\n",
      "Epoch 833/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 8.4282e-04 - val_loss: 1.1888e-04\n",
      "Epoch 834/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.4081e-04 - val_loss: 1.1860e-04\n",
      "Epoch 835/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 8.3881e-04 - val_loss: 1.1832e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 836/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 8.3681e-04 - val_loss: 1.1805e-04\n",
      "Epoch 837/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.3483e-04 - val_loss: 1.1777e-04\n",
      "Epoch 838/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3285e-04 - val_loss: 1.1749e-04\n",
      "Epoch 839/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3087e-04 - val_loss: 1.1722e-04\n",
      "Epoch 840/1000\n",
      "32/32 [==============================] - 0s 128us/step - loss: 8.2890e-04 - val_loss: 1.1695e-04\n",
      "Epoch 841/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 8.2694e-04 - val_loss: 1.1667e-04\n",
      "Epoch 842/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2498e-04 - val_loss: 1.1640e-04\n",
      "Epoch 843/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 8.2302e-04 - val_loss: 1.1613e-04\n",
      "Epoch 844/1000\n",
      "32/32 [==============================] - 0s 130us/step - loss: 8.2108e-04 - val_loss: 1.1586e-04\n",
      "Epoch 845/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.1915e-04 - val_loss: 1.1559e-04\n",
      "Epoch 846/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 8.1721e-04 - val_loss: 1.1532e-04\n",
      "Epoch 847/1000\n",
      "32/32 [==============================] - 0s 158us/step - loss: 8.1528e-04 - val_loss: 1.1505e-04\n",
      "Epoch 848/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.1336e-04 - val_loss: 1.1478e-04\n",
      "Epoch 849/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.1145e-04 - val_loss: 1.1452e-04\n",
      "Epoch 850/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.0953e-04 - val_loss: 1.1425e-04\n",
      "Epoch 851/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.0763e-04 - val_loss: 1.1399e-04\n",
      "Epoch 852/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.0574e-04 - val_loss: 1.1372e-04\n",
      "Epoch 853/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.0384e-04 - val_loss: 1.1346e-04\n",
      "Epoch 854/1000\n",
      "32/32 [==============================] - 0s 121us/step - loss: 8.0196e-04 - val_loss: 1.1320e-04\n",
      "Epoch 855/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 8.0007e-04 - val_loss: 1.1294e-04\n",
      "Epoch 856/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.9819e-04 - val_loss: 1.1268e-04\n",
      "Epoch 857/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9633e-04 - val_loss: 1.1241e-04\n",
      "Epoch 858/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 7.9446e-04 - val_loss: 1.1215e-04\n",
      "Epoch 859/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9261e-04 - val_loss: 1.1190e-04\n",
      "Epoch 860/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9076e-04 - val_loss: 1.1164e-04\n",
      "Epoch 861/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8891e-04 - val_loss: 1.1138e-04\n",
      "Epoch 862/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8706e-04 - val_loss: 1.1112e-04\n",
      "Epoch 863/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.8523e-04 - val_loss: 1.1086e-04\n",
      "Epoch 864/1000\n",
      "32/32 [==============================] - 0s 129us/step - loss: 7.8340e-04 - val_loss: 1.1060e-04\n",
      "Epoch 865/1000\n",
      "32/32 [==============================] - 0s 120us/step - loss: 7.8157e-04 - val_loss: 1.1035e-04\n",
      "Epoch 866/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7975e-04 - val_loss: 1.1010e-04\n",
      "Epoch 867/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 7.7793e-04 - val_loss: 1.0984e-04\n",
      "Epoch 868/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7613e-04 - val_loss: 1.0959e-04\n",
      "Epoch 869/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.7433e-04 - val_loss: 1.0934e-04\n",
      "Epoch 870/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 7.7252e-04 - val_loss: 1.0909e-04\n",
      "Epoch 871/1000\n",
      "32/32 [==============================] - 0s 177us/step - loss: 7.7074e-04 - val_loss: 1.0884e-04\n",
      "Epoch 872/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 7.6894e-04 - val_loss: 1.0859e-04\n",
      "Epoch 873/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 7.6716e-04 - val_loss: 1.0835e-04\n",
      "Epoch 874/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6539e-04 - val_loss: 1.0809e-04\n",
      "Epoch 875/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.6361e-04 - val_loss: 1.0784e-04\n",
      "Epoch 876/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.6185e-04 - val_loss: 1.0760e-04\n",
      "Epoch 877/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6008e-04 - val_loss: 1.0736e-04\n",
      "Epoch 878/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5834e-04 - val_loss: 1.0711e-04\n",
      "Epoch 879/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.5658e-04 - val_loss: 1.0687e-04\n",
      "Epoch 880/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.5484e-04 - val_loss: 1.0662e-04\n",
      "Epoch 881/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5310e-04 - val_loss: 1.0637e-04\n",
      "Epoch 882/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5136e-04 - val_loss: 1.0613e-04\n",
      "Epoch 883/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.4963e-04 - val_loss: 1.0589e-04\n",
      "Epoch 884/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4791e-04 - val_loss: 1.0565e-04\n",
      "Epoch 885/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.4618e-04 - val_loss: 1.0542e-04\n",
      "Epoch 886/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4447e-04 - val_loss: 1.0517e-04\n",
      "Epoch 887/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.4277e-04 - val_loss: 1.0493e-04\n",
      "Epoch 888/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4107e-04 - val_loss: 1.0469e-04\n",
      "Epoch 889/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3936e-04 - val_loss: 1.0445e-04\n",
      "Epoch 890/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 7.3767e-04 - val_loss: 1.0422e-04\n",
      "Epoch 891/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.3598e-04 - val_loss: 1.0398e-04\n",
      "Epoch 892/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 7.3429e-04 - val_loss: 1.0374e-04\n",
      "Epoch 893/1000\n",
      "32/32 [==============================] - 0s 130us/step - loss: 7.3262e-04 - val_loss: 1.0351e-04\n",
      "Epoch 894/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3093e-04 - val_loss: 1.0328e-04\n",
      "Epoch 895/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2928e-04 - val_loss: 1.0304e-04\n",
      "Epoch 896/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 7.2761e-04 - val_loss: 1.0281e-04\n",
      "Epoch 897/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 7.2595e-04 - val_loss: 1.0258e-04\n",
      "Epoch 898/1000\n",
      "32/32 [==============================] - 0s 166us/step - loss: 7.2429e-04 - val_loss: 1.0235e-04\n",
      "Epoch 899/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2264e-04 - val_loss: 1.0212e-04\n",
      "Epoch 900/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.2100e-04 - val_loss: 1.0189e-04\n",
      "Epoch 901/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1936e-04 - val_loss: 1.0166e-04\n",
      "Epoch 902/1000\n",
      "32/32 [==============================] - 0s 163us/step - loss: 7.1772e-04 - val_loss: 1.0143e-04\n",
      "Epoch 903/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1609e-04 - val_loss: 1.0120e-04\n",
      "Epoch 904/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1447e-04 - val_loss: 1.0097e-04\n",
      "Epoch 905/1000\n",
      "32/32 [==============================] - 0s 160us/step - loss: 7.1284e-04 - val_loss: 1.0074e-04\n",
      "Epoch 906/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.1123e-04 - val_loss: 1.0052e-04\n",
      "Epoch 907/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.0961e-04 - val_loss: 1.0029e-04\n",
      "Epoch 908/1000\n",
      "32/32 [==============================] - 0s 166us/step - loss: 7.0801e-04 - val_loss: 1.0006e-04\n",
      "Epoch 909/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 7.0641e-04 - val_loss: 9.9841e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 910/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0481e-04 - val_loss: 9.9617e-05\n",
      "Epoch 911/1000\n",
      "32/32 [==============================] - 0s 168us/step - loss: 7.0322e-04 - val_loss: 9.9397e-05\n",
      "Epoch 912/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0163e-04 - val_loss: 9.9172e-05\n",
      "Epoch 913/1000\n",
      "32/32 [==============================] - 0s 161us/step - loss: 7.0005e-04 - val_loss: 9.8955e-05\n",
      "Epoch 914/1000\n",
      "32/32 [==============================] - 0s 118us/step - loss: 6.9847e-04 - val_loss: 9.8730e-05\n",
      "Epoch 915/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9690e-04 - val_loss: 9.8510e-05\n",
      "Epoch 916/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 6.9533e-04 - val_loss: 9.8294e-05\n",
      "Epoch 917/1000\n",
      "32/32 [==============================] - 0s 133us/step - loss: 6.9376e-04 - val_loss: 9.8070e-05\n",
      "Epoch 918/1000\n",
      "32/32 [==============================] - 0s 131us/step - loss: 6.9220e-04 - val_loss: 9.7856e-05\n",
      "Epoch 919/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.9065e-04 - val_loss: 9.7637e-05\n",
      "Epoch 920/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 6.8909e-04 - val_loss: 9.7418e-05\n",
      "Epoch 921/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8754e-04 - val_loss: 9.7194e-05\n",
      "Epoch 922/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.8601e-04 - val_loss: 9.6989e-05\n",
      "Epoch 923/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.8447e-04 - val_loss: 9.6764e-05\n",
      "Epoch 924/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.8293e-04 - val_loss: 9.6549e-05\n",
      "Epoch 925/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 6.8140e-04 - val_loss: 9.6333e-05\n",
      "Epoch 926/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 6.7987e-04 - val_loss: 9.6121e-05\n",
      "Epoch 927/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7836e-04 - val_loss: 9.5904e-05\n",
      "Epoch 928/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 6.7684e-04 - val_loss: 9.5689e-05\n",
      "Epoch 929/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.7533e-04 - val_loss: 9.5481e-05\n",
      "Epoch 930/1000\n",
      "32/32 [==============================] - 0s 137us/step - loss: 6.7382e-04 - val_loss: 9.5270e-05\n",
      "Epoch 931/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.7231e-04 - val_loss: 9.5058e-05\n",
      "Epoch 932/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.7082e-04 - val_loss: 9.4854e-05\n",
      "Epoch 933/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 6.6932e-04 - val_loss: 9.4642e-05\n",
      "Epoch 934/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6784e-04 - val_loss: 9.4436e-05\n",
      "Epoch 935/1000\n",
      "32/32 [==============================] - 0s 176us/step - loss: 6.6635e-04 - val_loss: 9.4225e-05\n",
      "Epoch 936/1000\n",
      "32/32 [==============================] - 0s 161us/step - loss: 6.6487e-04 - val_loss: 9.4016e-05\n",
      "Epoch 937/1000\n",
      "32/32 [==============================] - 0s 169us/step - loss: 6.6339e-04 - val_loss: 9.3811e-05\n",
      "Epoch 938/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6192e-04 - val_loss: 9.3609e-05\n",
      "Epoch 939/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6045e-04 - val_loss: 9.3396e-05\n",
      "Epoch 940/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5898e-04 - val_loss: 9.3190e-05\n",
      "Epoch 941/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5753e-04 - val_loss: 9.2989e-05\n",
      "Epoch 942/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5607e-04 - val_loss: 9.2776e-05\n",
      "Epoch 943/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.5461e-04 - val_loss: 9.2571e-05\n",
      "Epoch 944/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5318e-04 - val_loss: 9.2369e-05\n",
      "Epoch 945/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.5172e-04 - val_loss: 9.2166e-05\n",
      "Epoch 946/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5029e-04 - val_loss: 9.1968e-05\n",
      "Epoch 947/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4885e-04 - val_loss: 9.1765e-05\n",
      "Epoch 948/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.4742e-04 - val_loss: 9.1564e-05\n",
      "Epoch 949/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 6.4599e-04 - val_loss: 9.1363e-05\n",
      "Epoch 950/1000\n",
      "32/32 [==============================] - 0s 117us/step - loss: 6.4457e-04 - val_loss: 9.1166e-05\n",
      "Epoch 951/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4315e-04 - val_loss: 9.0967e-05\n",
      "Epoch 952/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 6.4174e-04 - val_loss: 9.0771e-05\n",
      "Epoch 953/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4032e-04 - val_loss: 9.0571e-05\n",
      "Epoch 954/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.3892e-04 - val_loss: 9.0378e-05\n",
      "Epoch 955/1000\n",
      "32/32 [==============================] - 0s 133us/step - loss: 6.3751e-04 - val_loss: 9.0174e-05\n",
      "Epoch 956/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 6.3611e-04 - val_loss: 8.9979e-05\n",
      "Epoch 957/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.3472e-04 - val_loss: 8.9780e-05\n",
      "Epoch 958/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 6.3333e-04 - val_loss: 8.9586e-05\n",
      "Epoch 959/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 6.3194e-04 - val_loss: 8.9394e-05\n",
      "Epoch 960/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3056e-04 - val_loss: 8.9204e-05\n",
      "Epoch 961/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.2918e-04 - val_loss: 8.9005e-05\n",
      "Epoch 962/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2780e-04 - val_loss: 8.8808e-05\n",
      "Epoch 963/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 6.2643e-04 - val_loss: 8.8611e-05\n",
      "Epoch 964/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 6.2506e-04 - val_loss: 8.8423e-05\n",
      "Epoch 965/1000\n",
      "32/32 [==============================] - 0s 138us/step - loss: 6.2369e-04 - val_loss: 8.8234e-05\n",
      "Epoch 966/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.2233e-04 - val_loss: 8.8041e-05\n",
      "Epoch 967/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 6.2098e-04 - val_loss: 8.7852e-05\n",
      "Epoch 968/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.1963e-04 - val_loss: 8.7663e-05\n",
      "Epoch 969/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.1827e-04 - val_loss: 8.7475e-05\n",
      "Epoch 970/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 6.1694e-04 - val_loss: 8.7285e-05\n",
      "Epoch 971/1000\n",
      "32/32 [==============================] - 0s 130us/step - loss: 6.1560e-04 - val_loss: 8.7098e-05\n",
      "Epoch 972/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 6.1426e-04 - val_loss: 8.6912e-05\n",
      "Epoch 973/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 6.1293e-04 - val_loss: 8.6717e-05\n",
      "Epoch 974/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.1160e-04 - val_loss: 8.6527e-05\n",
      "Epoch 975/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.1027e-04 - val_loss: 8.6342e-05\n",
      "Epoch 976/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0895e-04 - val_loss: 8.6153e-05\n",
      "Epoch 977/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0763e-04 - val_loss: 8.5967e-05\n",
      "Epoch 978/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.0631e-04 - val_loss: 8.5787e-05\n",
      "Epoch 979/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 6.0500e-04 - val_loss: 8.5602e-05\n",
      "Epoch 980/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.0369e-04 - val_loss: 8.5415e-05\n",
      "Epoch 981/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0239e-04 - val_loss: 8.5234e-05\n",
      "Epoch 982/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 6.0109e-04 - val_loss: 8.5056e-05\n",
      "Epoch 983/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9980e-04 - val_loss: 8.4872e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 984/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 5.9850e-04 - val_loss: 8.4689e-05\n",
      "Epoch 985/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9721e-04 - val_loss: 8.4504e-05\n",
      "Epoch 986/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9592e-04 - val_loss: 8.4325e-05\n",
      "Epoch 987/1000\n",
      "32/32 [==============================] - 0s 118us/step - loss: 5.9465e-04 - val_loss: 8.4146e-05\n",
      "Epoch 988/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 5.9337e-04 - val_loss: 8.3970e-05\n",
      "Epoch 989/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 5.9209e-04 - val_loss: 8.3781e-05\n",
      "Epoch 990/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9082e-04 - val_loss: 8.3604e-05\n",
      "Epoch 991/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.8955e-04 - val_loss: 8.3429e-05\n",
      "Epoch 992/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.8829e-04 - val_loss: 8.3249e-05\n",
      "Epoch 993/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 5.8702e-04 - val_loss: 8.3076e-05\n",
      "Epoch 994/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.8577e-04 - val_loss: 8.2891e-05\n",
      "Epoch 995/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 5.8451e-04 - val_loss: 8.2717e-05\n",
      "Epoch 996/1000\n",
      "32/32 [==============================] - 0s 137us/step - loss: 5.8327e-04 - val_loss: 8.2534e-05\n",
      "Epoch 997/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.8201e-04 - val_loss: 8.2360e-05\n",
      "Epoch 998/1000\n",
      "32/32 [==============================] - 0s 131us/step - loss: 5.8078e-04 - val_loss: 8.2190e-05\n",
      "Epoch 999/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.7954e-04 - val_loss: 8.2011e-05\n",
      "Epoch 1000/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 5.7829e-04 - val_loss: 8.1840e-05\n",
      "7.356476999120787e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.9547809 , -0.70075583,  0.93348825, -1.0377702 ,  1.1184882 ],\n",
       "        [ 0.06112464, -0.0985145 , -0.6434552 ,  1.1727086 , -0.5420046 ],\n",
       "        [ 0.2241915 , -1.2524726 , -1.3355135 , -0.8867324 ,  0.45765135]],\n",
       "       dtype=float32),\n",
       " array([-0.82537836, -0.68842566,  0.67985415,  0.8553519 , -0.60817665],\n",
       "       dtype=float32),\n",
       " array([[-0.323142  ,  1.1352091 , -0.12353183, -0.2643727 ,  0.64439124],\n",
       "        [-0.46887562, -0.00236923,  0.74908805, -0.37208283,  0.2561972 ],\n",
       "        [ 0.79080075,  0.30135262, -0.48065734, -0.31345648,  0.00156789],\n",
       "        [-0.4564334 ,  0.14380543, -0.68713963, -0.5933642 , -0.21551353],\n",
       "        [-1.1562613 ,  0.17627661,  0.01170437,  0.01910819,  0.76695037]],\n",
       "       dtype=float32),\n",
       " array([ 0.8943569 ,  0.11826516, -0.8373644 ,  0.8464892 , -0.8707357 ],\n",
       "       dtype=float32),\n",
       " array([[ 1.2984133 ],\n",
       "        [-0.10585112],\n",
       "        [-0.6966867 ],\n",
       "        [ 0.6507614 ],\n",
       "        [-0.90641415]], dtype=float32),\n",
       " array([0.929705], dtype=float32)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_challenger, history_challenger, evaluate_challenger=NN_model_structure_regression_1(X_train_challenger, X_val_challenger, Y_train_challenger, Y_val_challenger, adam2, 32, 1000, x_test_challenger, y_test_challenger)\n",
    "model_challenger.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_challenger.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_challenger_structure1_4th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_58 (Dense)             (None, 5)                 20        \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 91\n",
      "Trainable params: 91\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 32 samples, validate on 7 samples\n",
      "Epoch 1/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 34.8236 - val_loss: 34.3798\n",
      "Epoch 2/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 32.1568 - val_loss: 30.2719\n",
      "Epoch 3/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 28.4133 - val_loss: 25.0591\n",
      "Epoch 4/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 23.5986 - val_loss: 18.6804\n",
      "Epoch 5/1000\n",
      "32/32 [==============================] - 0s 160us/step - loss: 17.8910 - val_loss: 11.7647\n",
      "Epoch 6/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 11.9325 - val_loss: 5.9305\n",
      "Epoch 7/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.7820 - val_loss: 2.4614\n",
      "Epoch 8/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 2.9915 - val_loss: 1.4815\n",
      "Epoch 9/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3037 - val_loss: 2.3107\n",
      "Epoch 10/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.1514 - val_loss: 3.7136\n",
      "Epoch 11/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.1119 - val_loss: 4.7022\n",
      "Epoch 12/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1831 - val_loss: 4.6158\n",
      "Epoch 13/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7360 - val_loss: 3.6500\n",
      "Epoch 14/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.4523 - val_loss: 2.4353\n",
      "Epoch 15/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1602 - val_loss: 1.5016\n",
      "Epoch 16/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3523 - val_loss: 1.0373\n",
      "Epoch 17/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.1083 - val_loss: 0.9450\n",
      "Epoch 18/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2377 - val_loss: 0.9828\n",
      "Epoch 19/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.4459 - val_loss: 0.9673\n",
      "Epoch 20/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.5186 - val_loss: 0.8657\n",
      "Epoch 21/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4088 - val_loss: 0.7322\n",
      "Epoch 22/1000\n",
      "32/32 [==============================] - 0s 130us/step - loss: 1.1725 - val_loss: 0.6339\n",
      "Epoch 23/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.8945 - val_loss: 0.6101\n",
      "Epoch 24/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.6472 - val_loss: 0.6577\n",
      "Epoch 25/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.4707 - val_loss: 0.7367\n",
      "Epoch 26/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.3712 - val_loss: 0.7947\n",
      "Epoch 27/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 0.3314 - val_loss: 0.7952\n",
      "Epoch 28/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.3266 - val_loss: 0.7333\n",
      "Epoch 29/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.3345 - val_loss: 0.6277\n",
      "Epoch 30/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.3357 - val_loss: 0.5015\n",
      "Epoch 31/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.3137 - val_loss: 0.3709\n",
      "Epoch 32/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.2622 - val_loss: 0.2471\n",
      "Epoch 33/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1911 - val_loss: 0.1415\n",
      "Epoch 34/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.1226 - val_loss: 0.0664\n",
      "Epoch 35/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0774 - val_loss: 0.0294\n",
      "Epoch 36/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0631 - val_loss: 0.0303\n",
      "Epoch 37/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0731 - val_loss: 0.0605\n",
      "Epoch 38/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0941 - val_loss: 0.1061\n",
      "Epoch 39/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1144 - val_loss: 0.1506\n",
      "Epoch 40/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1266 - val_loss: 0.1796\n",
      "Epoch 41/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1272 - val_loss: 0.1838\n",
      "Epoch 42/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1153 - val_loss: 0.1628\n",
      "Epoch 43/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0928 - val_loss: 0.1247\n",
      "Epoch 44/1000\n",
      "32/32 [==============================] - 0s 133us/step - loss: 0.0650 - val_loss: 0.0825\n",
      "Epoch 45/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0391 - val_loss: 0.0484\n",
      "Epoch 46/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0218 - val_loss: 0.0290\n",
      "Epoch 47/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0156 - val_loss: 0.0235\n",
      "Epoch 48/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0191 - val_loss: 0.0264\n",
      "Epoch 49/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0279 - val_loss: 0.0316\n",
      "Epoch 50/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 0.0377 - val_loss: 0.0352\n",
      "Epoch 51/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 0.0454 - val_loss: 0.0359\n",
      "Epoch 52/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0491 - val_loss: 0.0345\n",
      "Epoch 53/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0481 - val_loss: 0.0319\n",
      "Epoch 54/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0427 - val_loss: 0.0294\n",
      "Epoch 55/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0344 - val_loss: 0.0279\n",
      "Epoch 56/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0257 - val_loss: 0.0283\n",
      "Epoch 57/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0191 - val_loss: 0.0308\n",
      "Epoch 58/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 0.0156 - val_loss: 0.0352\n",
      "Epoch 59/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0150 - val_loss: 0.0409\n",
      "Epoch 60/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0162 - val_loss: 0.0472\n",
      "Epoch 61/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0180 - val_loss: 0.0529\n",
      "Epoch 62/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0195 - val_loss: 0.0570\n",
      "Epoch 63/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0203 - val_loss: 0.0583\n",
      "Epoch 64/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0199 - val_loss: 0.0561\n",
      "Epoch 65/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0186 - val_loss: 0.0507\n",
      "Epoch 66/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0164 - val_loss: 0.0431\n",
      "Epoch 67/1000\n",
      "32/32 [==============================] - 0s 161us/step - loss: 0.0141 - val_loss: 0.0350\n",
      "Epoch 68/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0121 - val_loss: 0.0277\n",
      "Epoch 69/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0110 - val_loss: 0.0221\n",
      "Epoch 70/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0106 - val_loss: 0.0182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0106 - val_loss: 0.0156\n",
      "Epoch 72/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0108 - val_loss: 0.0140\n",
      "Epoch 73/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 0.0109 - val_loss: 0.0129\n",
      "Epoch 74/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0107 - val_loss: 0.0120\n",
      "Epoch 75/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0104 - val_loss: 0.0112\n",
      "Epoch 76/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0098 - val_loss: 0.0105\n",
      "Epoch 77/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0091 - val_loss: 0.0098\n",
      "Epoch 78/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0085 - val_loss: 0.0093\n",
      "Epoch 79/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0080 - val_loss: 0.0090\n",
      "Epoch 80/1000\n",
      "32/32 [==============================] - 0s 122us/step - loss: 0.0078 - val_loss: 0.0089\n",
      "Epoch 81/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0079 - val_loss: 0.0090\n",
      "Epoch 82/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0080 - val_loss: 0.0090\n",
      "Epoch 83/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0081 - val_loss: 0.0091\n",
      "Epoch 84/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0081 - val_loss: 0.0091\n",
      "Epoch 85/1000\n",
      "32/32 [==============================] - 0s 119us/step - loss: 0.0080 - val_loss: 0.0091\n",
      "Epoch 86/1000\n",
      "32/32 [==============================] - 0s 165us/step - loss: 0.0078 - val_loss: 0.0088\n",
      "Epoch 87/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0075 - val_loss: 0.0084\n",
      "Epoch 88/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 0.0072 - val_loss: 0.0079\n",
      "Epoch 89/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0069 - val_loss: 0.0073\n",
      "Epoch 90/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0068 - val_loss: 0.0068\n",
      "Epoch 91/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0067 - val_loss: 0.0065\n",
      "Epoch 92/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0067 - val_loss: 0.0063\n",
      "Epoch 93/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0068 - val_loss: 0.0062\n",
      "Epoch 94/1000\n",
      "32/32 [==============================] - 0s 145us/step - loss: 0.0068 - val_loss: 0.0061\n",
      "Epoch 95/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 0.0068 - val_loss: 0.0061\n",
      "Epoch 96/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0067 - val_loss: 0.0061\n",
      "Epoch 97/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0066 - val_loss: 0.0061\n",
      "Epoch 98/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0065 - val_loss: 0.0060\n",
      "Epoch 99/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0064 - val_loss: 0.0059\n",
      "Epoch 100/1000\n",
      "32/32 [==============================] - 0s 127us/step - loss: 0.0062 - val_loss: 0.0058\n",
      "Epoch 101/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0061 - val_loss: 0.0058\n",
      "Epoch 102/1000\n",
      "32/32 [==============================] - 0s 165us/step - loss: 0.0060 - val_loss: 0.0057\n",
      "Epoch 103/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0060 - val_loss: 0.0057\n",
      "Epoch 104/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0060 - val_loss: 0.0057\n",
      "Epoch 105/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0059 - val_loss: 0.0057\n",
      "Epoch 106/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0059 - val_loss: 0.0058\n",
      "Epoch 107/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0059 - val_loss: 0.0058\n",
      "Epoch 108/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0058 - val_loss: 0.0057\n",
      "Epoch 109/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 0.0057 - val_loss: 0.0057\n",
      "Epoch 110/1000\n",
      "32/32 [==============================] - 0s 163us/step - loss: 0.0057 - val_loss: 0.0056\n",
      "Epoch 111/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0056 - val_loss: 0.0055\n",
      "Epoch 112/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 0.0055 - val_loss: 0.0054\n",
      "Epoch 113/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0055 - val_loss: 0.0053\n",
      "Epoch 114/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0054 - val_loss: 0.0053\n",
      "Epoch 115/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 0.0054 - val_loss: 0.0053\n",
      "Epoch 116/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0054 - val_loss: 0.0054\n",
      "Epoch 117/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0053 - val_loss: 0.0054\n",
      "Epoch 118/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 0.0053 - val_loss: 0.0055\n",
      "Epoch 119/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 0.0052 - val_loss: 0.0056\n",
      "Epoch 120/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0052 - val_loss: 0.0056\n",
      "Epoch 121/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 0.0051 - val_loss: 0.0057\n",
      "Epoch 122/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0051 - val_loss: 0.0057\n",
      "Epoch 123/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0051 - val_loss: 0.0057\n",
      "Epoch 124/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0050 - val_loss: 0.0057\n",
      "Epoch 125/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0050 - val_loss: 0.0057\n",
      "Epoch 126/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0049 - val_loss: 0.0056\n",
      "Epoch 127/1000\n",
      "32/32 [==============================] - 0s 116us/step - loss: 0.0049 - val_loss: 0.0056\n",
      "Epoch 128/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0049 - val_loss: 0.0056\n",
      "Epoch 129/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 0.0048 - val_loss: 0.0055\n",
      "Epoch 130/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0048 - val_loss: 0.0054\n",
      "Epoch 131/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0047 - val_loss: 0.0053\n",
      "Epoch 132/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0047 - val_loss: 0.0052\n",
      "Epoch 133/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0047 - val_loss: 0.0051\n",
      "Epoch 134/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0046 - val_loss: 0.0051\n",
      "Epoch 135/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0046 - val_loss: 0.0050\n",
      "Epoch 136/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 137/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0045 - val_loss: 0.0049\n",
      "Epoch 138/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 0.0045 - val_loss: 0.0049\n",
      "Epoch 139/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 140/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 141/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 142/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 143/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 144/1000\n",
      "32/32 [==============================] - 0s 160us/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 145/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 146/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 147/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 148/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 149/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 150/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0041 - val_loss: 0.0046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/1000\n",
      "32/32 [==============================] - 0s 168us/step - loss: 0.0041 - val_loss: 0.0046\n",
      "Epoch 152/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0041 - val_loss: 0.0045\n",
      "Epoch 153/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0040 - val_loss: 0.0045\n",
      "Epoch 154/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0040 - val_loss: 0.0044\n",
      "Epoch 155/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0040 - val_loss: 0.0044\n",
      "Epoch 156/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 157/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 158/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0039 - val_loss: 0.0042\n",
      "Epoch 159/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0039 - val_loss: 0.0042\n",
      "Epoch 160/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 161/1000\n",
      "32/32 [==============================] - 0s 127us/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 162/1000\n",
      "32/32 [==============================] - 0s 158us/step - loss: 0.0038 - val_loss: 0.0041\n",
      "Epoch 163/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0038 - val_loss: 0.0041\n",
      "Epoch 164/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Epoch 165/1000\n",
      "32/32 [==============================] - 0s 164us/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Epoch 166/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0037 - val_loss: 0.0040\n",
      "Epoch 167/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0037 - val_loss: 0.0040\n",
      "Epoch 168/1000\n",
      "32/32 [==============================] - 0s 122us/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 169/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 170/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 171/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0036 - val_loss: 0.0039\n",
      "Epoch 172/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 173/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 174/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 175/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 176/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 177/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 178/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 179/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 180/1000\n",
      "32/32 [==============================] - 0s 161us/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 181/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 182/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 183/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 184/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 185/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 186/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0032 - val_loss: 0.0037\n",
      "Epoch 187/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 0.0032 - val_loss: 0.0036\n",
      "Epoch 188/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 0.0036\n",
      "Epoch 189/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 0.0032 - val_loss: 0.0036\n",
      "Epoch 190/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0031 - val_loss: 0.0036\n",
      "Epoch 191/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0031 - val_loss: 0.0036\n",
      "Epoch 192/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0031 - val_loss: 0.0036\n",
      "Epoch 193/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0031 - val_loss: 0.0035\n",
      "Epoch 194/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0031 - val_loss: 0.0035\n",
      "Epoch 195/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 0.0030 - val_loss: 0.0035\n",
      "Epoch 196/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 0.0030 - val_loss: 0.0035\n",
      "Epoch 197/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0030 - val_loss: 0.0035\n",
      "Epoch 198/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 0.0030 - val_loss: 0.0035\n",
      "Epoch 199/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 0.0034\n",
      "Epoch 200/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 0.0030 - val_loss: 0.0034\n",
      "Epoch 201/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 0.0029 - val_loss: 0.0034\n",
      "Epoch 202/1000\n",
      "32/32 [==============================] - 0s 172us/step - loss: 0.0029 - val_loss: 0.0034\n",
      "Epoch 203/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 0.0034\n",
      "Epoch 204/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 0.0034\n",
      "Epoch 205/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0029 - val_loss: 0.0034\n",
      "Epoch 206/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 0.0028 - val_loss: 0.0033\n",
      "Epoch 207/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 0.0028 - val_loss: 0.0033\n",
      "Epoch 208/1000\n",
      "32/32 [==============================] - 0s 168us/step - loss: 0.0028 - val_loss: 0.0033\n",
      "Epoch 209/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 0.0033\n",
      "Epoch 210/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 0.0028 - val_loss: 0.0033\n",
      "Epoch 211/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 0.0033\n",
      "Epoch 212/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0033\n",
      "Epoch 213/1000\n",
      "32/32 [==============================] - 0s 173us/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 214/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 215/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 216/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 217/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 218/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 219/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 220/1000\n",
      "32/32 [==============================] - 0s 133us/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Epoch 221/1000\n",
      "32/32 [==============================] - 0s 121us/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Epoch 222/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Epoch 223/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Epoch 224/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Epoch 225/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 226/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 227/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 228/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 229/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0025 - val_loss: 0.0030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 230/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 231/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 232/1000\n",
      "32/32 [==============================] - 0s 118us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 233/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 234/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 235/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 236/1000\n",
      "32/32 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 237/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 238/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 239/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 240/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 241/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 242/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 243/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 244/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 245/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 246/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 247/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 248/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 249/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 250/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 251/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 252/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 253/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 254/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0028\n",
      "Epoch 255/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0028\n",
      "Epoch 256/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 257/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 258/1000\n",
      "32/32 [==============================] - 0s 128us/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 259/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 260/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 261/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 262/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 263/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 264/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 265/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 266/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 267/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 268/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 269/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 270/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 271/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 272/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 273/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 274/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 275/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 276/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 277/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 278/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 279/1000\n",
      "32/32 [==============================] - 0s 158us/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 280/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 281/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 282/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 283/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 284/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 285/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 286/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 287/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 288/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 289/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 290/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 291/1000\n",
      "32/32 [==============================] - 0s 129us/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 292/1000\n",
      "32/32 [==============================] - 0s 132us/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 293/1000\n",
      "32/32 [==============================] - 0s 137us/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 294/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 295/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 296/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 297/1000\n",
      "32/32 [==============================] - 0s 132us/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 298/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 299/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 300/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 301/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 302/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 303/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 304/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 305/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 306/1000\n",
      "32/32 [==============================] - 0s 164us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 307/1000\n",
      "32/32 [==============================] - 0s 137us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 308/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0016 - val_loss: 0.0023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 309/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 310/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 311/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 312/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 313/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 314/1000\n",
      "32/32 [==============================] - 0s 158us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 315/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 316/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 317/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 318/1000\n",
      "32/32 [==============================] - 0s 132us/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 319/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 320/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 321/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 322/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 323/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 324/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 325/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 326/1000\n",
      "32/32 [==============================] - 0s 133us/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 327/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 328/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 329/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 330/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 331/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 332/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 333/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 334/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 335/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 336/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 337/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 338/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 339/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 340/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 341/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 342/1000\n",
      "32/32 [==============================] - 0s 163us/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 343/1000\n",
      "32/32 [==============================] - 0s 128us/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 344/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 345/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 346/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0021\n",
      "Epoch 347/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 348/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 349/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 350/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 351/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 352/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 353/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 354/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 355/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 356/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 357/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 358/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 359/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 360/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 361/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 362/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 363/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 364/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 365/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 366/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 367/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 368/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 369/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 370/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 371/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 372/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 373/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 374/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 375/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 376/1000\n",
      "32/32 [==============================] - 0s 132us/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 377/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 378/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 379/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 380/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 381/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 382/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 383/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 384/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 385/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 386/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 387/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 388/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 389/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 390/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 391/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 392/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 393/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 394/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 395/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 396/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 397/1000\n",
      "32/32 [==============================] - 0s 145us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 398/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 399/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 400/1000\n",
      "32/32 [==============================] - 0s 160us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 401/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 402/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 403/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 404/1000\n",
      "32/32 [==============================] - 0s 129us/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 405/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 406/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 407/1000\n",
      "32/32 [==============================] - 0s 137us/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 408/1000\n",
      "32/32 [==============================] - 0s 127us/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 409/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 410/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 411/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 412/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 413/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 414/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 415/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 416/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 417/1000\n",
      "32/32 [==============================] - 0s 122us/step - loss: 9.9858e-04 - val_loss: 0.0017\n",
      "Epoch 418/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 9.9472e-04 - val_loss: 0.0017\n",
      "Epoch 419/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.9088e-04 - val_loss: 0.0017\n",
      "Epoch 420/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.8704e-04 - val_loss: 0.0017\n",
      "Epoch 421/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 9.8325e-04 - val_loss: 0.0017\n",
      "Epoch 422/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.7948e-04 - val_loss: 0.0017\n",
      "Epoch 423/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.7573e-04 - val_loss: 0.0017\n",
      "Epoch 424/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.7199e-04 - val_loss: 0.0017\n",
      "Epoch 425/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 9.6830e-04 - val_loss: 0.0017\n",
      "Epoch 426/1000\n",
      "32/32 [==============================] - 0s 128us/step - loss: 9.6462e-04 - val_loss: 0.0016\n",
      "Epoch 427/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6096e-04 - val_loss: 0.0016\n",
      "Epoch 428/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.5731e-04 - val_loss: 0.0016\n",
      "Epoch 429/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 9.5370e-04 - val_loss: 0.0016\n",
      "Epoch 430/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.5011e-04 - val_loss: 0.0016\n",
      "Epoch 431/1000\n",
      "32/32 [==============================] - 0s 131us/step - loss: 9.4654e-04 - val_loss: 0.0016\n",
      "Epoch 432/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 9.4299e-04 - val_loss: 0.0016\n",
      "Epoch 433/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3946e-04 - val_loss: 0.0016\n",
      "Epoch 434/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3596e-04 - val_loss: 0.0016\n",
      "Epoch 435/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3248e-04 - val_loss: 0.0016\n",
      "Epoch 436/1000\n",
      "32/32 [==============================] - 0s 137us/step - loss: 9.2901e-04 - val_loss: 0.0016\n",
      "Epoch 437/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 9.2558e-04 - val_loss: 0.0016\n",
      "Epoch 438/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.2215e-04 - val_loss: 0.0016\n",
      "Epoch 439/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1875e-04 - val_loss: 0.0016\n",
      "Epoch 440/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1537e-04 - val_loss: 0.0016\n",
      "Epoch 441/1000\n",
      "32/32 [==============================] - 0s 131us/step - loss: 9.1201e-04 - val_loss: 0.0016\n",
      "Epoch 442/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.0867e-04 - val_loss: 0.0016\n",
      "Epoch 443/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 9.0535e-04 - val_loss: 0.0016\n",
      "Epoch 444/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.0205e-04 - val_loss: 0.0016\n",
      "Epoch 445/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.9877e-04 - val_loss: 0.0016\n",
      "Epoch 446/1000\n",
      "32/32 [==============================] - 0s 129us/step - loss: 8.9552e-04 - val_loss: 0.0016\n",
      "Epoch 447/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.9228e-04 - val_loss: 0.0016\n",
      "Epoch 448/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.8907e-04 - val_loss: 0.0016\n",
      "Epoch 449/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.8586e-04 - val_loss: 0.0016\n",
      "Epoch 450/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 8.8268e-04 - val_loss: 0.0015\n",
      "Epoch 451/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7951e-04 - val_loss: 0.0015\n",
      "Epoch 452/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 8.7637e-04 - val_loss: 0.0015\n",
      "Epoch 453/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.7323e-04 - val_loss: 0.0015\n",
      "Epoch 454/1000\n",
      "32/32 [==============================] - 0s 138us/step - loss: 8.7013e-04 - val_loss: 0.0015\n",
      "Epoch 455/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.6704e-04 - val_loss: 0.0015\n",
      "Epoch 456/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.6397e-04 - val_loss: 0.0015\n",
      "Epoch 457/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 8.6092e-04 - val_loss: 0.0015\n",
      "Epoch 458/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 8.5789e-04 - val_loss: 0.0015\n",
      "Epoch 459/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 8.5486e-04 - val_loss: 0.0015\n",
      "Epoch 460/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 8.5187e-04 - val_loss: 0.0015\n",
      "Epoch 461/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.4889e-04 - val_loss: 0.0015\n",
      "Epoch 462/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.4592e-04 - val_loss: 0.0015\n",
      "Epoch 463/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.4298e-04 - val_loss: 0.0015\n",
      "Epoch 464/1000\n",
      "32/32 [==============================] - 0s 133us/step - loss: 8.4004e-04 - val_loss: 0.0015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 465/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.3714e-04 - val_loss: 0.0015\n",
      "Epoch 466/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3423e-04 - val_loss: 0.0015\n",
      "Epoch 467/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 8.3136e-04 - val_loss: 0.0015\n",
      "Epoch 468/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2850e-04 - val_loss: 0.0015\n",
      "Epoch 469/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.2564e-04 - val_loss: 0.0015\n",
      "Epoch 470/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2282e-04 - val_loss: 0.0015\n",
      "Epoch 471/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2002e-04 - val_loss: 0.0015\n",
      "Epoch 472/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 8.1721e-04 - val_loss: 0.0015\n",
      "Epoch 473/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.1443e-04 - val_loss: 0.0015\n",
      "Epoch 474/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.1166e-04 - val_loss: 0.0015\n",
      "Epoch 475/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 8.0891e-04 - val_loss: 0.0015\n",
      "Epoch 476/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.0619e-04 - val_loss: 0.0014\n",
      "Epoch 477/1000\n",
      "32/32 [==============================] - 0s 160us/step - loss: 8.0346e-04 - val_loss: 0.0014\n",
      "Epoch 478/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.0076e-04 - val_loss: 0.0014\n",
      "Epoch 479/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9808e-04 - val_loss: 0.0014\n",
      "Epoch 480/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9540e-04 - val_loss: 0.0014\n",
      "Epoch 481/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 7.9276e-04 - val_loss: 0.0014\n",
      "Epoch 482/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9010e-04 - val_loss: 0.0014\n",
      "Epoch 483/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8748e-04 - val_loss: 0.0014\n",
      "Epoch 484/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.8488e-04 - val_loss: 0.0014\n",
      "Epoch 485/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.8228e-04 - val_loss: 0.0014\n",
      "Epoch 486/1000\n",
      "32/32 [==============================] - 0s 163us/step - loss: 7.7970e-04 - val_loss: 0.0014\n",
      "Epoch 487/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 7.7712e-04 - val_loss: 0.0014\n",
      "Epoch 488/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7458e-04 - val_loss: 0.0014\n",
      "Epoch 489/1000\n",
      "32/32 [==============================] - 0s 174us/step - loss: 7.7203e-04 - val_loss: 0.0014\n",
      "Epoch 490/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 7.6952e-04 - val_loss: 0.0014\n",
      "Epoch 491/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6700e-04 - val_loss: 0.0014\n",
      "Epoch 492/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.6451e-04 - val_loss: 0.0014\n",
      "Epoch 493/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6202e-04 - val_loss: 0.0014\n",
      "Epoch 494/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5955e-04 - val_loss: 0.0014\n",
      "Epoch 495/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5710e-04 - val_loss: 0.0014\n",
      "Epoch 496/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5465e-04 - val_loss: 0.0014\n",
      "Epoch 497/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.5223e-04 - val_loss: 0.0014\n",
      "Epoch 498/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 7.4982e-04 - val_loss: 0.0014\n",
      "Epoch 499/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4742e-04 - val_loss: 0.0014\n",
      "Epoch 500/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4503e-04 - val_loss: 0.0014\n",
      "Epoch 501/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4265e-04 - val_loss: 0.0014\n",
      "Epoch 502/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 7.4029e-04 - val_loss: 0.0014\n",
      "Epoch 503/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3794e-04 - val_loss: 0.0014\n",
      "Epoch 504/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3561e-04 - val_loss: 0.0014\n",
      "Epoch 505/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.3329e-04 - val_loss: 0.0014\n",
      "Epoch 506/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3097e-04 - val_loss: 0.0013\n",
      "Epoch 507/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2867e-04 - val_loss: 0.0013\n",
      "Epoch 508/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 7.2639e-04 - val_loss: 0.0013\n",
      "Epoch 509/1000\n",
      "32/32 [==============================] - 0s 130us/step - loss: 7.2412e-04 - val_loss: 0.0013\n",
      "Epoch 510/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2186e-04 - val_loss: 0.0013\n",
      "Epoch 511/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1961e-04 - val_loss: 0.0013\n",
      "Epoch 512/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1737e-04 - val_loss: 0.0013\n",
      "Epoch 513/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1515e-04 - val_loss: 0.0013\n",
      "Epoch 514/1000\n",
      "32/32 [==============================] - 0s 171us/step - loss: 7.1294e-04 - val_loss: 0.0013\n",
      "Epoch 515/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1074e-04 - val_loss: 0.0013\n",
      "Epoch 516/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 7.0854e-04 - val_loss: 0.0013\n",
      "Epoch 517/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 7.0637e-04 - val_loss: 0.0013\n",
      "Epoch 518/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 7.0420e-04 - val_loss: 0.0013\n",
      "Epoch 519/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0205e-04 - val_loss: 0.0013\n",
      "Epoch 520/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.9990e-04 - val_loss: 0.0013\n",
      "Epoch 521/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9778e-04 - val_loss: 0.0013\n",
      "Epoch 522/1000\n",
      "32/32 [==============================] - 0s 133us/step - loss: 6.9566e-04 - val_loss: 0.0013\n",
      "Epoch 523/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.9355e-04 - val_loss: 0.0013\n",
      "Epoch 524/1000\n",
      "32/32 [==============================] - 0s 173us/step - loss: 6.9145e-04 - val_loss: 0.0013\n",
      "Epoch 525/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8937e-04 - val_loss: 0.0013\n",
      "Epoch 526/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8729e-04 - val_loss: 0.0013\n",
      "Epoch 527/1000\n",
      "32/32 [==============================] - 0s 162us/step - loss: 6.8523e-04 - val_loss: 0.0013\n",
      "Epoch 528/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8317e-04 - val_loss: 0.0013\n",
      "Epoch 529/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 6.8113e-04 - val_loss: 0.0013\n",
      "Epoch 530/1000\n",
      "32/32 [==============================] - 0s 171us/step - loss: 6.7909e-04 - val_loss: 0.0013\n",
      "Epoch 531/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 6.7707e-04 - val_loss: 0.0013\n",
      "Epoch 532/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.7506e-04 - val_loss: 0.0013\n",
      "Epoch 533/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 6.7306e-04 - val_loss: 0.0013\n",
      "Epoch 534/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7107e-04 - val_loss: 0.0013\n",
      "Epoch 535/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.6909e-04 - val_loss: 0.0013\n",
      "Epoch 536/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.6712e-04 - val_loss: 0.0013\n",
      "Epoch 537/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6516e-04 - val_loss: 0.0013\n",
      "Epoch 538/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.6321e-04 - val_loss: 0.0013\n",
      "Epoch 539/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.6127e-04 - val_loss: 0.0012\n",
      "Epoch 540/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5933e-04 - val_loss: 0.0012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 541/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5742e-04 - val_loss: 0.0012\n",
      "Epoch 542/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 6.5550e-04 - val_loss: 0.0012\n",
      "Epoch 543/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 6.5360e-04 - val_loss: 0.0012\n",
      "Epoch 544/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.5171e-04 - val_loss: 0.0012\n",
      "Epoch 545/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 6.4983e-04 - val_loss: 0.0012\n",
      "Epoch 546/1000\n",
      "32/32 [==============================] - 0s 169us/step - loss: 6.4796e-04 - val_loss: 0.0012\n",
      "Epoch 547/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4609e-04 - val_loss: 0.0012\n",
      "Epoch 548/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 6.4425e-04 - val_loss: 0.0012\n",
      "Epoch 549/1000\n",
      "32/32 [==============================] - 0s 131us/step - loss: 6.4240e-04 - val_loss: 0.0012\n",
      "Epoch 550/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 6.4056e-04 - val_loss: 0.0012\n",
      "Epoch 551/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 6.3874e-04 - val_loss: 0.0012\n",
      "Epoch 552/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3692e-04 - val_loss: 0.0012\n",
      "Epoch 553/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 6.3512e-04 - val_loss: 0.0012\n",
      "Epoch 554/1000\n",
      "32/32 [==============================] - 0s 165us/step - loss: 6.3332e-04 - val_loss: 0.0012\n",
      "Epoch 555/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.3153e-04 - val_loss: 0.0012\n",
      "Epoch 556/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.2974e-04 - val_loss: 0.0012\n",
      "Epoch 557/1000\n",
      "32/32 [==============================] - 0s 133us/step - loss: 6.2798e-04 - val_loss: 0.0012\n",
      "Epoch 558/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 6.2622e-04 - val_loss: 0.0012\n",
      "Epoch 559/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.2446e-04 - val_loss: 0.0012\n",
      "Epoch 560/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2271e-04 - val_loss: 0.0012\n",
      "Epoch 561/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.2097e-04 - val_loss: 0.0012\n",
      "Epoch 562/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 6.1925e-04 - val_loss: 0.0012\n",
      "Epoch 563/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 6.1752e-04 - val_loss: 0.0012\n",
      "Epoch 564/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1581e-04 - val_loss: 0.0012\n",
      "Epoch 565/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.1411e-04 - val_loss: 0.0012\n",
      "Epoch 566/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1242e-04 - val_loss: 0.0012\n",
      "Epoch 567/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.1073e-04 - val_loss: 0.0012\n",
      "Epoch 568/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0904e-04 - val_loss: 0.0012\n",
      "Epoch 569/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0738e-04 - val_loss: 0.0012\n",
      "Epoch 570/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0572e-04 - val_loss: 0.0012\n",
      "Epoch 571/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0406e-04 - val_loss: 0.0012\n",
      "Epoch 572/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 6.0241e-04 - val_loss: 0.0012\n",
      "Epoch 573/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0077e-04 - val_loss: 0.0012\n",
      "Epoch 574/1000\n",
      "32/32 [==============================] - 0s 129us/step - loss: 5.9913e-04 - val_loss: 0.0012\n",
      "Epoch 575/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 5.9752e-04 - val_loss: 0.0012\n",
      "Epoch 576/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.9590e-04 - val_loss: 0.0011\n",
      "Epoch 577/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9430e-04 - val_loss: 0.0011\n",
      "Epoch 578/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.9270e-04 - val_loss: 0.0011\n",
      "Epoch 579/1000\n",
      "32/32 [==============================] - 0s 161us/step - loss: 5.9110e-04 - val_loss: 0.0011\n",
      "Epoch 580/1000\n",
      "32/32 [==============================] - 0s 160us/step - loss: 5.8951e-04 - val_loss: 0.0011\n",
      "Epoch 581/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.8793e-04 - val_loss: 0.0011\n",
      "Epoch 582/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8636e-04 - val_loss: 0.0011\n",
      "Epoch 583/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8480e-04 - val_loss: 0.0011\n",
      "Epoch 584/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 5.8324e-04 - val_loss: 0.0011\n",
      "Epoch 585/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8169e-04 - val_loss: 0.0011\n",
      "Epoch 586/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.8015e-04 - val_loss: 0.0011\n",
      "Epoch 587/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7862e-04 - val_loss: 0.0011\n",
      "Epoch 588/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7709e-04 - val_loss: 0.0011\n",
      "Epoch 589/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.7557e-04 - val_loss: 0.0011\n",
      "Epoch 590/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.7406e-04 - val_loss: 0.0011\n",
      "Epoch 591/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7254e-04 - val_loss: 0.0011\n",
      "Epoch 592/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7105e-04 - val_loss: 0.0011\n",
      "Epoch 593/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6956e-04 - val_loss: 0.0011\n",
      "Epoch 594/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 5.6808e-04 - val_loss: 0.0011\n",
      "Epoch 595/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 5.6659e-04 - val_loss: 0.0011\n",
      "Epoch 596/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6513e-04 - val_loss: 0.0011\n",
      "Epoch 597/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 5.6365e-04 - val_loss: 0.0011\n",
      "Epoch 598/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.6220e-04 - val_loss: 0.0011\n",
      "Epoch 599/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6074e-04 - val_loss: 0.0011\n",
      "Epoch 600/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 5.5930e-04 - val_loss: 0.0011\n",
      "Epoch 601/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 5.5786e-04 - val_loss: 0.0011\n",
      "Epoch 602/1000\n",
      "32/32 [==============================] - 0s 137us/step - loss: 5.5642e-04 - val_loss: 0.0011\n",
      "Epoch 603/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 5.5501e-04 - val_loss: 0.0011\n",
      "Epoch 604/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.5358e-04 - val_loss: 0.0011\n",
      "Epoch 605/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 5.5217e-04 - val_loss: 0.0011\n",
      "Epoch 606/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5076e-04 - val_loss: 0.0011\n",
      "Epoch 607/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 5.4936e-04 - val_loss: 0.0011\n",
      "Epoch 608/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4796e-04 - val_loss: 0.0011\n",
      "Epoch 609/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 5.4658e-04 - val_loss: 0.0011\n",
      "Epoch 610/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.4519e-04 - val_loss: 0.0011\n",
      "Epoch 611/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.4382e-04 - val_loss: 0.0011\n",
      "Epoch 612/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.4245e-04 - val_loss: 0.0011\n",
      "Epoch 613/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.4108e-04 - val_loss: 0.0011\n",
      "Epoch 614/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 5.3973e-04 - val_loss: 0.0011\n",
      "Epoch 615/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 5.3837e-04 - val_loss: 0.0011\n",
      "Epoch 616/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3702e-04 - val_loss: 0.0011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 617/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.3568e-04 - val_loss: 0.0011\n",
      "Epoch 618/1000\n",
      "32/32 [==============================] - 0s 132us/step - loss: 5.3435e-04 - val_loss: 0.0010\n",
      "Epoch 619/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 5.3301e-04 - val_loss: 0.0010\n",
      "Epoch 620/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.3169e-04 - val_loss: 0.0010\n",
      "Epoch 621/1000\n",
      "32/32 [==============================] - 0s 129us/step - loss: 5.3037e-04 - val_loss: 0.0010\n",
      "Epoch 622/1000\n",
      "32/32 [==============================] - 0s 131us/step - loss: 5.2907e-04 - val_loss: 0.0010\n",
      "Epoch 623/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2776e-04 - val_loss: 0.0010\n",
      "Epoch 624/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 5.2646e-04 - val_loss: 0.0010\n",
      "Epoch 625/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 5.2517e-04 - val_loss: 0.0010\n",
      "Epoch 626/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2387e-04 - val_loss: 0.0010\n",
      "Epoch 627/1000\n",
      "32/32 [==============================] - 0s 122us/step - loss: 5.2259e-04 - val_loss: 0.0010\n",
      "Epoch 628/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2130e-04 - val_loss: 0.0010\n",
      "Epoch 629/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2004e-04 - val_loss: 0.0010\n",
      "Epoch 630/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.1877e-04 - val_loss: 0.0010\n",
      "Epoch 631/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1750e-04 - val_loss: 0.0010\n",
      "Epoch 632/1000\n",
      "32/32 [==============================] - 0s 171us/step - loss: 5.1624e-04 - val_loss: 0.0010\n",
      "Epoch 633/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1499e-04 - val_loss: 0.0010\n",
      "Epoch 634/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1375e-04 - val_loss: 0.0010\n",
      "Epoch 635/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1250e-04 - val_loss: 0.0010\n",
      "Epoch 636/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.1126e-04 - val_loss: 0.0010\n",
      "Epoch 637/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1003e-04 - val_loss: 0.0010\n",
      "Epoch 638/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0881e-04 - val_loss: 0.0010\n",
      "Epoch 639/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0758e-04 - val_loss: 0.0010\n",
      "Epoch 640/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 5.0637e-04 - val_loss: 0.0010\n",
      "Epoch 641/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.0515e-04 - val_loss: 0.0010\n",
      "Epoch 642/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.0395e-04 - val_loss: 9.9877e-04\n",
      "Epoch 643/1000\n",
      "32/32 [==============================] - 0s 138us/step - loss: 5.0274e-04 - val_loss: 9.9672e-04\n",
      "Epoch 644/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 5.0155e-04 - val_loss: 9.9469e-04\n",
      "Epoch 645/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 5.0036e-04 - val_loss: 9.9267e-04\n",
      "Epoch 646/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 4.9918e-04 - val_loss: 9.9064e-04\n",
      "Epoch 647/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 4.9799e-04 - val_loss: 9.8859e-04\n",
      "Epoch 648/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.9681e-04 - val_loss: 9.8658e-04\n",
      "Epoch 649/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 4.9564e-04 - val_loss: 9.8458e-04\n",
      "Epoch 650/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 4.9447e-04 - val_loss: 9.8259e-04\n",
      "Epoch 651/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9331e-04 - val_loss: 9.8061e-04\n",
      "Epoch 652/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9215e-04 - val_loss: 9.7864e-04\n",
      "Epoch 653/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.9100e-04 - val_loss: 9.7666e-04\n",
      "Epoch 654/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8985e-04 - val_loss: 9.7468e-04\n",
      "Epoch 655/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8870e-04 - val_loss: 9.7271e-04\n",
      "Epoch 656/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.8757e-04 - val_loss: 9.7075e-04\n",
      "Epoch 657/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.8643e-04 - val_loss: 9.6879e-04\n",
      "Epoch 658/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8530e-04 - val_loss: 9.6685e-04\n",
      "Epoch 659/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8417e-04 - val_loss: 9.6491e-04\n",
      "Epoch 660/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.8305e-04 - val_loss: 9.6299e-04\n",
      "Epoch 661/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.8193e-04 - val_loss: 9.6107e-04\n",
      "Epoch 662/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.8082e-04 - val_loss: 9.5914e-04\n",
      "Epoch 663/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.7971e-04 - val_loss: 9.5721e-04\n",
      "Epoch 664/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.7861e-04 - val_loss: 9.5527e-04\n",
      "Epoch 665/1000\n",
      "32/32 [==============================] - 0s 120us/step - loss: 4.7750e-04 - val_loss: 9.5338e-04\n",
      "Epoch 666/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7641e-04 - val_loss: 9.5149e-04\n",
      "Epoch 667/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7532e-04 - val_loss: 9.4958e-04\n",
      "Epoch 668/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7422e-04 - val_loss: 9.4768e-04\n",
      "Epoch 669/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 4.7314e-04 - val_loss: 9.4584e-04\n",
      "Epoch 670/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 4.7207e-04 - val_loss: 9.4395e-04\n",
      "Epoch 671/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.7099e-04 - val_loss: 9.4208e-04\n",
      "Epoch 672/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.6991e-04 - val_loss: 9.4022e-04\n",
      "Epoch 673/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.6885e-04 - val_loss: 9.3835e-04\n",
      "Epoch 674/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.6779e-04 - val_loss: 9.3651e-04\n",
      "Epoch 675/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.6674e-04 - val_loss: 9.3467e-04\n",
      "Epoch 676/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6568e-04 - val_loss: 9.3280e-04\n",
      "Epoch 677/1000\n",
      "32/32 [==============================] - 0s 137us/step - loss: 4.6463e-04 - val_loss: 9.3099e-04\n",
      "Epoch 678/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.6358e-04 - val_loss: 9.2915e-04\n",
      "Epoch 679/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 4.6253e-04 - val_loss: 9.2732e-04\n",
      "Epoch 680/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6150e-04 - val_loss: 9.2551e-04\n",
      "Epoch 681/1000\n",
      "32/32 [==============================] - 0s 137us/step - loss: 4.6046e-04 - val_loss: 9.2368e-04\n",
      "Epoch 682/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.5943e-04 - val_loss: 9.2189e-04\n",
      "Epoch 683/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 4.5841e-04 - val_loss: 9.2008e-04\n",
      "Epoch 684/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.5739e-04 - val_loss: 9.1826e-04\n",
      "Epoch 685/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.5636e-04 - val_loss: 9.1649e-04\n",
      "Epoch 686/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 4.5535e-04 - val_loss: 9.1469e-04\n",
      "Epoch 687/1000\n",
      "32/32 [==============================] - 0s 174us/step - loss: 4.5434e-04 - val_loss: 9.1292e-04\n",
      "Epoch 688/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5333e-04 - val_loss: 9.1113e-04\n",
      "Epoch 689/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5232e-04 - val_loss: 9.0934e-04\n",
      "Epoch 690/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 4.5132e-04 - val_loss: 9.0756e-04\n",
      "Epoch 691/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5032e-04 - val_loss: 9.0583e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 692/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.4933e-04 - val_loss: 9.0409e-04\n",
      "Epoch 693/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4834e-04 - val_loss: 9.0235e-04\n",
      "Epoch 694/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 4.4735e-04 - val_loss: 9.0060e-04\n",
      "Epoch 695/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 4.4637e-04 - val_loss: 8.9886e-04\n",
      "Epoch 696/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 4.4539e-04 - val_loss: 8.9713e-04\n",
      "Epoch 697/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.4442e-04 - val_loss: 8.9538e-04\n",
      "Epoch 698/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4345e-04 - val_loss: 8.9367e-04\n",
      "Epoch 699/1000\n",
      "32/32 [==============================] - 0s 132us/step - loss: 4.4248e-04 - val_loss: 8.9194e-04\n",
      "Epoch 700/1000\n",
      "32/32 [==============================] - 0s 130us/step - loss: 4.4151e-04 - val_loss: 8.9022e-04\n",
      "Epoch 701/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4055e-04 - val_loss: 8.8852e-04\n",
      "Epoch 702/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 4.3959e-04 - val_loss: 8.8681e-04\n",
      "Epoch 703/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.3864e-04 - val_loss: 8.8513e-04\n",
      "Epoch 704/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.3769e-04 - val_loss: 8.8341e-04\n",
      "Epoch 705/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.3674e-04 - val_loss: 8.8173e-04\n",
      "Epoch 706/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.3579e-04 - val_loss: 8.8004e-04\n",
      "Epoch 707/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.3486e-04 - val_loss: 8.7837e-04\n",
      "Epoch 708/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.3392e-04 - val_loss: 8.7669e-04\n",
      "Epoch 709/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.3298e-04 - val_loss: 8.7502e-04\n",
      "Epoch 710/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.3205e-04 - val_loss: 8.7335e-04\n",
      "Epoch 711/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.3112e-04 - val_loss: 8.7172e-04\n",
      "Epoch 712/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3020e-04 - val_loss: 8.7003e-04\n",
      "Epoch 713/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.2928e-04 - val_loss: 8.6842e-04\n",
      "Epoch 714/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2836e-04 - val_loss: 8.6680e-04\n",
      "Epoch 715/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.2745e-04 - val_loss: 8.6514e-04\n",
      "Epoch 716/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.2653e-04 - val_loss: 8.6353e-04\n",
      "Epoch 717/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.2563e-04 - val_loss: 8.6189e-04\n",
      "Epoch 718/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2472e-04 - val_loss: 8.6026e-04\n",
      "Epoch 719/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2382e-04 - val_loss: 8.5863e-04\n",
      "Epoch 720/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2292e-04 - val_loss: 8.5701e-04\n",
      "Epoch 721/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2202e-04 - val_loss: 8.5540e-04\n",
      "Epoch 722/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2113e-04 - val_loss: 8.5380e-04\n",
      "Epoch 723/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.2024e-04 - val_loss: 8.5221e-04\n",
      "Epoch 724/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.1936e-04 - val_loss: 8.5063e-04\n",
      "Epoch 725/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1848e-04 - val_loss: 8.4902e-04\n",
      "Epoch 726/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 4.1759e-04 - val_loss: 8.4744e-04\n",
      "Epoch 727/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1671e-04 - val_loss: 8.4584e-04\n",
      "Epoch 728/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 4.1583e-04 - val_loss: 8.4425e-04\n",
      "Epoch 729/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 4.1496e-04 - val_loss: 8.4270e-04\n",
      "Epoch 730/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.1410e-04 - val_loss: 8.4114e-04\n",
      "Epoch 731/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.1323e-04 - val_loss: 8.3958e-04\n",
      "Epoch 732/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1237e-04 - val_loss: 8.3804e-04\n",
      "Epoch 733/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.1151e-04 - val_loss: 8.3647e-04\n",
      "Epoch 734/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.1065e-04 - val_loss: 8.3493e-04\n",
      "Epoch 735/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.0980e-04 - val_loss: 8.3340e-04\n",
      "Epoch 736/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.0895e-04 - val_loss: 8.3186e-04\n",
      "Epoch 737/1000\n",
      "32/32 [==============================] - 0s 145us/step - loss: 4.0810e-04 - val_loss: 8.3030e-04\n",
      "Epoch 738/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0725e-04 - val_loss: 8.2875e-04\n",
      "Epoch 739/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 4.0641e-04 - val_loss: 8.2723e-04\n",
      "Epoch 740/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0557e-04 - val_loss: 8.2572e-04\n",
      "Epoch 741/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.0473e-04 - val_loss: 8.2420e-04\n",
      "Epoch 742/1000\n",
      "32/32 [==============================] - 0s 131us/step - loss: 4.0390e-04 - val_loss: 8.2272e-04\n",
      "Epoch 743/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0306e-04 - val_loss: 8.2119e-04\n",
      "Epoch 744/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.0224e-04 - val_loss: 8.1969e-04\n",
      "Epoch 745/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.0142e-04 - val_loss: 8.1817e-04\n",
      "Epoch 746/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.0059e-04 - val_loss: 8.1667e-04\n",
      "Epoch 747/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 3.9977e-04 - val_loss: 8.1521e-04\n",
      "Epoch 748/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9895e-04 - val_loss: 8.1373e-04\n",
      "Epoch 749/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 3.9814e-04 - val_loss: 8.1223e-04\n",
      "Epoch 750/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9732e-04 - val_loss: 8.1074e-04\n",
      "Epoch 751/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.9651e-04 - val_loss: 8.0928e-04\n",
      "Epoch 752/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9570e-04 - val_loss: 8.0780e-04\n",
      "Epoch 753/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.9489e-04 - val_loss: 8.0633e-04\n",
      "Epoch 754/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.9409e-04 - val_loss: 8.0485e-04\n",
      "Epoch 755/1000\n",
      "32/32 [==============================] - 0s 166us/step - loss: 3.9329e-04 - val_loss: 8.0340e-04\n",
      "Epoch 756/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9250e-04 - val_loss: 8.0195e-04\n",
      "Epoch 757/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 3.9171e-04 - val_loss: 8.0049e-04\n",
      "Epoch 758/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9091e-04 - val_loss: 7.9907e-04\n",
      "Epoch 759/1000\n",
      "32/32 [==============================] - 0s 145us/step - loss: 3.9012e-04 - val_loss: 7.9763e-04\n",
      "Epoch 760/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.8934e-04 - val_loss: 7.9618e-04\n",
      "Epoch 761/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.8854e-04 - val_loss: 7.9475e-04\n",
      "Epoch 762/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.8777e-04 - val_loss: 7.9332e-04\n",
      "Epoch 763/1000\n",
      "32/32 [==============================] - 0s 129us/step - loss: 3.8698e-04 - val_loss: 7.9189e-04\n",
      "Epoch 764/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 3.8621e-04 - val_loss: 7.9046e-04\n",
      "Epoch 765/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8543e-04 - val_loss: 7.8905e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 766/1000\n",
      "32/32 [==============================] - 0s 170us/step - loss: 3.8466e-04 - val_loss: 7.8766e-04\n",
      "Epoch 767/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 3.8390e-04 - val_loss: 7.8625e-04\n",
      "Epoch 768/1000\n",
      "32/32 [==============================] - 0s 129us/step - loss: 3.8313e-04 - val_loss: 7.8485e-04\n",
      "Epoch 769/1000\n",
      "32/32 [==============================] - 0s 181us/step - loss: 3.8236e-04 - val_loss: 7.8344e-04\n",
      "Epoch 770/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8160e-04 - val_loss: 7.8204e-04\n",
      "Epoch 771/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8084e-04 - val_loss: 7.8063e-04\n",
      "Epoch 772/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.8008e-04 - val_loss: 7.7926e-04\n",
      "Epoch 773/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7932e-04 - val_loss: 7.7787e-04\n",
      "Epoch 774/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.7857e-04 - val_loss: 7.7650e-04\n",
      "Epoch 775/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7782e-04 - val_loss: 7.7511e-04\n",
      "Epoch 776/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.7707e-04 - val_loss: 7.7373e-04\n",
      "Epoch 777/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.7633e-04 - val_loss: 7.7239e-04\n",
      "Epoch 778/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.7558e-04 - val_loss: 7.7102e-04\n",
      "Epoch 779/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7484e-04 - val_loss: 7.6965e-04\n",
      "Epoch 780/1000\n",
      "32/32 [==============================] - 0s 170us/step - loss: 3.7411e-04 - val_loss: 7.6829e-04\n",
      "Epoch 781/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 3.7337e-04 - val_loss: 7.6692e-04\n",
      "Epoch 782/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7263e-04 - val_loss: 7.6558e-04\n",
      "Epoch 783/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 3.7189e-04 - val_loss: 7.6425e-04\n",
      "Epoch 784/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7117e-04 - val_loss: 7.6289e-04\n",
      "Epoch 785/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7044e-04 - val_loss: 7.6157e-04\n",
      "Epoch 786/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6971e-04 - val_loss: 7.6022e-04\n",
      "Epoch 787/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6899e-04 - val_loss: 7.5890e-04\n",
      "Epoch 788/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6827e-04 - val_loss: 7.5755e-04\n",
      "Epoch 789/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.6755e-04 - val_loss: 7.5624e-04\n",
      "Epoch 790/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.6683e-04 - val_loss: 7.5492e-04\n",
      "Epoch 791/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6612e-04 - val_loss: 7.5360e-04\n",
      "Epoch 792/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6540e-04 - val_loss: 7.5230e-04\n",
      "Epoch 793/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6470e-04 - val_loss: 7.5099e-04\n",
      "Epoch 794/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.6399e-04 - val_loss: 7.4966e-04\n",
      "Epoch 795/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.6328e-04 - val_loss: 7.4837e-04\n",
      "Epoch 796/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6257e-04 - val_loss: 7.4708e-04\n",
      "Epoch 797/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6187e-04 - val_loss: 7.4580e-04\n",
      "Epoch 798/1000\n",
      "32/32 [==============================] - 0s 130us/step - loss: 3.6118e-04 - val_loss: 7.4449e-04\n",
      "Epoch 799/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 3.6048e-04 - val_loss: 7.4320e-04\n",
      "Epoch 800/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 3.5979e-04 - val_loss: 7.4191e-04\n",
      "Epoch 801/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 3.5908e-04 - val_loss: 7.4063e-04\n",
      "Epoch 802/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 3.5840e-04 - val_loss: 7.3934e-04\n",
      "Epoch 803/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5770e-04 - val_loss: 7.3809e-04\n",
      "Epoch 804/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5702e-04 - val_loss: 7.3683e-04\n",
      "Epoch 805/1000\n",
      "32/32 [==============================] - 0s 137us/step - loss: 3.5634e-04 - val_loss: 7.3556e-04\n",
      "Epoch 806/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 3.5565e-04 - val_loss: 7.3430e-04\n",
      "Epoch 807/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5497e-04 - val_loss: 7.3302e-04\n",
      "Epoch 808/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5429e-04 - val_loss: 7.3176e-04\n",
      "Epoch 809/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5361e-04 - val_loss: 7.3051e-04\n",
      "Epoch 810/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 3.5293e-04 - val_loss: 7.2928e-04\n",
      "Epoch 811/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 3.5226e-04 - val_loss: 7.2805e-04\n",
      "Epoch 812/1000\n",
      "32/32 [==============================] - 0s 137us/step - loss: 3.5159e-04 - val_loss: 7.2677e-04\n",
      "Epoch 813/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5092e-04 - val_loss: 7.2554e-04\n",
      "Epoch 814/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.5025e-04 - val_loss: 7.2430e-04\n",
      "Epoch 815/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.4958e-04 - val_loss: 7.2308e-04\n",
      "Epoch 816/1000\n",
      "32/32 [==============================] - 0s 128us/step - loss: 3.4892e-04 - val_loss: 7.2186e-04\n",
      "Epoch 817/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4826e-04 - val_loss: 7.2061e-04\n",
      "Epoch 818/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 3.4759e-04 - val_loss: 7.1941e-04\n",
      "Epoch 819/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4694e-04 - val_loss: 7.1818e-04\n",
      "Epoch 820/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4628e-04 - val_loss: 7.1696e-04\n",
      "Epoch 821/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.4563e-04 - val_loss: 7.1575e-04\n",
      "Epoch 822/1000\n",
      "32/32 [==============================] - 0s 158us/step - loss: 3.4498e-04 - val_loss: 7.1453e-04\n",
      "Epoch 823/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.4432e-04 - val_loss: 7.1334e-04\n",
      "Epoch 824/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4368e-04 - val_loss: 7.1213e-04\n",
      "Epoch 825/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.4303e-04 - val_loss: 7.1095e-04\n",
      "Epoch 826/1000\n",
      "32/32 [==============================] - 0s 133us/step - loss: 3.4238e-04 - val_loss: 7.0975e-04\n",
      "Epoch 827/1000\n",
      "32/32 [==============================] - 0s 132us/step - loss: 3.4174e-04 - val_loss: 7.0855e-04\n",
      "Epoch 828/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.4110e-04 - val_loss: 7.0738e-04\n",
      "Epoch 829/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.4046e-04 - val_loss: 7.0619e-04\n",
      "Epoch 830/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 3.3982e-04 - val_loss: 7.0500e-04\n",
      "Epoch 831/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.3918e-04 - val_loss: 7.0380e-04\n",
      "Epoch 832/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.3855e-04 - val_loss: 7.0265e-04\n",
      "Epoch 833/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3792e-04 - val_loss: 7.0145e-04\n",
      "Epoch 834/1000\n",
      "32/32 [==============================] - 0s 130us/step - loss: 3.3728e-04 - val_loss: 7.0030e-04\n",
      "Epoch 835/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 3.3666e-04 - val_loss: 6.9914e-04\n",
      "Epoch 836/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3603e-04 - val_loss: 6.9795e-04\n",
      "Epoch 837/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 3.3541e-04 - val_loss: 6.9678e-04\n",
      "Epoch 838/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3478e-04 - val_loss: 6.9564e-04\n",
      "Epoch 839/1000\n",
      "32/32 [==============================] - 0s 170us/step - loss: 3.3416e-04 - val_loss: 6.9448e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 840/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 3.3354e-04 - val_loss: 6.9334e-04\n",
      "Epoch 841/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.3292e-04 - val_loss: 6.9219e-04\n",
      "Epoch 842/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3231e-04 - val_loss: 6.9103e-04\n",
      "Epoch 843/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3169e-04 - val_loss: 6.8989e-04\n",
      "Epoch 844/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3108e-04 - val_loss: 6.8873e-04\n",
      "Epoch 845/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3046e-04 - val_loss: 6.8761e-04\n",
      "Epoch 846/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 3.2985e-04 - val_loss: 6.8650e-04\n",
      "Epoch 847/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2925e-04 - val_loss: 6.8536e-04\n",
      "Epoch 848/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 3.2864e-04 - val_loss: 6.8425e-04\n",
      "Epoch 849/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2804e-04 - val_loss: 6.8311e-04\n",
      "Epoch 850/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 3.2743e-04 - val_loss: 6.8198e-04\n",
      "Epoch 851/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 3.2683e-04 - val_loss: 6.8086e-04\n",
      "Epoch 852/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2623e-04 - val_loss: 6.7973e-04\n",
      "Epoch 853/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 3.2563e-04 - val_loss: 6.7862e-04\n",
      "Epoch 854/1000\n",
      "32/32 [==============================] - 0s 137us/step - loss: 3.2503e-04 - val_loss: 6.7753e-04\n",
      "Epoch 855/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 3.2444e-04 - val_loss: 6.7642e-04\n",
      "Epoch 856/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2385e-04 - val_loss: 6.7531e-04\n",
      "Epoch 857/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2325e-04 - val_loss: 6.7421e-04\n",
      "Epoch 858/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.2266e-04 - val_loss: 6.7310e-04\n",
      "Epoch 859/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2207e-04 - val_loss: 6.7202e-04\n",
      "Epoch 860/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 3.2149e-04 - val_loss: 6.7092e-04\n",
      "Epoch 861/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 3.2090e-04 - val_loss: 6.6982e-04\n",
      "Epoch 862/1000\n",
      "32/32 [==============================] - 0s 131us/step - loss: 3.2031e-04 - val_loss: 6.6875e-04\n",
      "Epoch 863/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.1973e-04 - val_loss: 6.6765e-04\n",
      "Epoch 864/1000\n",
      "32/32 [==============================] - 0s 116us/step - loss: 3.1915e-04 - val_loss: 6.6659e-04\n",
      "Epoch 865/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.1857e-04 - val_loss: 6.6549e-04\n",
      "Epoch 866/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 3.1800e-04 - val_loss: 6.6441e-04\n",
      "Epoch 867/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.1742e-04 - val_loss: 6.6336e-04\n",
      "Epoch 868/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1685e-04 - val_loss: 6.6229e-04\n",
      "Epoch 869/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1627e-04 - val_loss: 6.6121e-04\n",
      "Epoch 870/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1570e-04 - val_loss: 6.6016e-04\n",
      "Epoch 871/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1512e-04 - val_loss: 6.5909e-04\n",
      "Epoch 872/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 3.1456e-04 - val_loss: 6.5805e-04\n",
      "Epoch 873/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1400e-04 - val_loss: 6.5699e-04\n",
      "Epoch 874/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 3.1343e-04 - val_loss: 6.5591e-04\n",
      "Epoch 875/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1286e-04 - val_loss: 6.5488e-04\n",
      "Epoch 876/1000\n",
      "32/32 [==============================] - 0s 132us/step - loss: 3.1230e-04 - val_loss: 6.5383e-04\n",
      "Epoch 877/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1174e-04 - val_loss: 6.5278e-04\n",
      "Epoch 878/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 3.1118e-04 - val_loss: 6.5172e-04\n",
      "Epoch 879/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.1062e-04 - val_loss: 6.5070e-04\n",
      "Epoch 880/1000\n",
      "32/32 [==============================] - 0s 137us/step - loss: 3.1007e-04 - val_loss: 6.4966e-04\n",
      "Epoch 881/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 3.0951e-04 - val_loss: 6.4862e-04\n",
      "Epoch 882/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 3.0896e-04 - val_loss: 6.4759e-04\n",
      "Epoch 883/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.0841e-04 - val_loss: 6.4656e-04\n",
      "Epoch 884/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0786e-04 - val_loss: 6.4554e-04\n",
      "Epoch 885/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.0731e-04 - val_loss: 6.4450e-04\n",
      "Epoch 886/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0676e-04 - val_loss: 6.4349e-04\n",
      "Epoch 887/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0621e-04 - val_loss: 6.4247e-04\n",
      "Epoch 888/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 3.0566e-04 - val_loss: 6.4146e-04\n",
      "Epoch 889/1000\n",
      "32/32 [==============================] - 0s 128us/step - loss: 3.0512e-04 - val_loss: 6.4043e-04\n",
      "Epoch 890/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 3.0458e-04 - val_loss: 6.3942e-04\n",
      "Epoch 891/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0404e-04 - val_loss: 6.3843e-04\n",
      "Epoch 892/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0350e-04 - val_loss: 6.3742e-04\n",
      "Epoch 893/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 3.0296e-04 - val_loss: 6.3643e-04\n",
      "Epoch 894/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.0242e-04 - val_loss: 6.3541e-04\n",
      "Epoch 895/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.0189e-04 - val_loss: 6.3441e-04\n",
      "Epoch 896/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0135e-04 - val_loss: 6.3340e-04\n",
      "Epoch 897/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.0082e-04 - val_loss: 6.3243e-04\n",
      "Epoch 898/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.0029e-04 - val_loss: 6.3141e-04\n",
      "Epoch 899/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 2.9976e-04 - val_loss: 6.3044e-04\n",
      "Epoch 900/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9923e-04 - val_loss: 6.2946e-04\n",
      "Epoch 901/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 2.9871e-04 - val_loss: 6.2848e-04\n",
      "Epoch 902/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 2.9818e-04 - val_loss: 6.2749e-04\n",
      "Epoch 903/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9765e-04 - val_loss: 6.2652e-04\n",
      "Epoch 904/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9713e-04 - val_loss: 6.2553e-04\n",
      "Epoch 905/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 2.9661e-04 - val_loss: 6.2457e-04\n",
      "Epoch 906/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9609e-04 - val_loss: 6.2360e-04\n",
      "Epoch 907/1000\n",
      "32/32 [==============================] - 0s 129us/step - loss: 2.9557e-04 - val_loss: 6.2263e-04\n",
      "Epoch 908/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.9506e-04 - val_loss: 6.2166e-04\n",
      "Epoch 909/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9454e-04 - val_loss: 6.2070e-04\n",
      "Epoch 910/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 2.9403e-04 - val_loss: 6.1973e-04\n",
      "Epoch 911/1000\n",
      "32/32 [==============================] - 0s 170us/step - loss: 2.9351e-04 - val_loss: 6.1879e-04\n",
      "Epoch 912/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9299e-04 - val_loss: 6.1782e-04\n",
      "Epoch 913/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 2.9248e-04 - val_loss: 6.1685e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 914/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 2.9198e-04 - val_loss: 6.1591e-04\n",
      "Epoch 915/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 2.9147e-04 - val_loss: 6.1495e-04\n",
      "Epoch 916/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9096e-04 - val_loss: 6.1401e-04\n",
      "Epoch 917/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.9045e-04 - val_loss: 6.1307e-04\n",
      "Epoch 918/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8995e-04 - val_loss: 6.1214e-04\n",
      "Epoch 919/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.8945e-04 - val_loss: 6.1119e-04\n",
      "Epoch 920/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 2.8894e-04 - val_loss: 6.1027e-04\n",
      "Epoch 921/1000\n",
      "32/32 [==============================] - 0s 171us/step - loss: 2.8844e-04 - val_loss: 6.0933e-04\n",
      "Epoch 922/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.8794e-04 - val_loss: 6.0839e-04\n",
      "Epoch 923/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8745e-04 - val_loss: 6.0745e-04\n",
      "Epoch 924/1000\n",
      "32/32 [==============================] - 0s 161us/step - loss: 2.8695e-04 - val_loss: 6.0654e-04\n",
      "Epoch 925/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 2.8645e-04 - val_loss: 6.0562e-04\n",
      "Epoch 926/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8596e-04 - val_loss: 6.0468e-04\n",
      "Epoch 927/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8546e-04 - val_loss: 6.0375e-04\n",
      "Epoch 928/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8497e-04 - val_loss: 6.0280e-04\n",
      "Epoch 929/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8447e-04 - val_loss: 6.0190e-04\n",
      "Epoch 930/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8399e-04 - val_loss: 6.0098e-04\n",
      "Epoch 931/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 2.8350e-04 - val_loss: 6.0008e-04\n",
      "Epoch 932/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 2.8301e-04 - val_loss: 5.9915e-04\n",
      "Epoch 933/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8253e-04 - val_loss: 5.9826e-04\n",
      "Epoch 934/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 2.8204e-04 - val_loss: 5.9736e-04\n",
      "Epoch 935/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.8156e-04 - val_loss: 5.9645e-04\n",
      "Epoch 936/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.8107e-04 - val_loss: 5.9556e-04\n",
      "Epoch 937/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8059e-04 - val_loss: 5.9466e-04\n",
      "Epoch 938/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.8011e-04 - val_loss: 5.9377e-04\n",
      "Epoch 939/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7964e-04 - val_loss: 5.9287e-04\n",
      "Epoch 940/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 2.7915e-04 - val_loss: 5.9196e-04\n",
      "Epoch 941/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 2.7868e-04 - val_loss: 5.9110e-04\n",
      "Epoch 942/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 2.7821e-04 - val_loss: 5.9021e-04\n",
      "Epoch 943/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7773e-04 - val_loss: 5.8933e-04\n",
      "Epoch 944/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7726e-04 - val_loss: 5.8842e-04\n",
      "Epoch 945/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7678e-04 - val_loss: 5.8753e-04\n",
      "Epoch 946/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7631e-04 - val_loss: 5.8666e-04\n",
      "Epoch 947/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7585e-04 - val_loss: 5.8579e-04\n",
      "Epoch 948/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.7538e-04 - val_loss: 5.8489e-04\n",
      "Epoch 949/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7491e-04 - val_loss: 5.8402e-04\n",
      "Epoch 950/1000\n",
      "32/32 [==============================] - 0s 130us/step - loss: 2.7444e-04 - val_loss: 5.8316e-04\n",
      "Epoch 951/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 2.7398e-04 - val_loss: 5.8231e-04\n",
      "Epoch 952/1000\n",
      "32/32 [==============================] - 0s 120us/step - loss: 2.7351e-04 - val_loss: 5.8143e-04\n",
      "Epoch 953/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 2.7305e-04 - val_loss: 5.8057e-04\n",
      "Epoch 954/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7259e-04 - val_loss: 5.7968e-04\n",
      "Epoch 955/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7213e-04 - val_loss: 5.7881e-04\n",
      "Epoch 956/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 2.7166e-04 - val_loss: 5.7798e-04\n",
      "Epoch 957/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.7121e-04 - val_loss: 5.7713e-04\n",
      "Epoch 958/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7075e-04 - val_loss: 5.7628e-04\n",
      "Epoch 959/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7030e-04 - val_loss: 5.7542e-04\n",
      "Epoch 960/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6984e-04 - val_loss: 5.7456e-04\n",
      "Epoch 961/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6939e-04 - val_loss: 5.7372e-04\n",
      "Epoch 962/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.6893e-04 - val_loss: 5.7285e-04\n",
      "Epoch 963/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 2.6848e-04 - val_loss: 5.7201e-04\n",
      "Epoch 964/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6803e-04 - val_loss: 5.7117e-04\n",
      "Epoch 965/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.6758e-04 - val_loss: 5.7034e-04\n",
      "Epoch 966/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 2.6713e-04 - val_loss: 5.6949e-04\n",
      "Epoch 967/1000\n",
      "32/32 [==============================] - 0s 168us/step - loss: 2.6668e-04 - val_loss: 5.6867e-04\n",
      "Epoch 968/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6624e-04 - val_loss: 5.6782e-04\n",
      "Epoch 969/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6579e-04 - val_loss: 5.6699e-04\n",
      "Epoch 970/1000\n",
      "32/32 [==============================] - 0s 127us/step - loss: 2.6535e-04 - val_loss: 5.6616e-04\n",
      "Epoch 971/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.6491e-04 - val_loss: 5.6533e-04\n",
      "Epoch 972/1000\n",
      "32/32 [==============================] - 0s 138us/step - loss: 2.6446e-04 - val_loss: 5.6450e-04\n",
      "Epoch 973/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 2.6402e-04 - val_loss: 5.6370e-04\n",
      "Epoch 974/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.6358e-04 - val_loss: 5.6287e-04\n",
      "Epoch 975/1000\n",
      "32/32 [==============================] - 0s 145us/step - loss: 2.6314e-04 - val_loss: 5.6204e-04\n",
      "Epoch 976/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 2.6270e-04 - val_loss: 5.6123e-04\n",
      "Epoch 977/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.6227e-04 - val_loss: 5.6039e-04\n",
      "Epoch 978/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6183e-04 - val_loss: 5.5959e-04\n",
      "Epoch 979/1000\n",
      "32/32 [==============================] - 0s 161us/step - loss: 2.6140e-04 - val_loss: 5.5878e-04\n",
      "Epoch 980/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6097e-04 - val_loss: 5.5795e-04\n",
      "Epoch 981/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.6053e-04 - val_loss: 5.5714e-04\n",
      "Epoch 982/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.6010e-04 - val_loss: 5.5634e-04\n",
      "Epoch 983/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.5967e-04 - val_loss: 5.5553e-04\n",
      "Epoch 984/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 2.5923e-04 - val_loss: 5.5473e-04\n",
      "Epoch 985/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.5881e-04 - val_loss: 5.5392e-04\n",
      "Epoch 986/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 2.5838e-04 - val_loss: 5.5312e-04\n",
      "Epoch 987/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 2.5795e-04 - val_loss: 5.5231e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 988/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.5753e-04 - val_loss: 5.5154e-04\n",
      "Epoch 989/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 2.5711e-04 - val_loss: 5.5076e-04\n",
      "Epoch 990/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 2.5668e-04 - val_loss: 5.4995e-04\n",
      "Epoch 991/1000\n",
      "32/32 [==============================] - 0s 131us/step - loss: 2.5625e-04 - val_loss: 5.4916e-04\n",
      "Epoch 992/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5583e-04 - val_loss: 5.4836e-04\n",
      "Epoch 993/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.5542e-04 - val_loss: 5.4758e-04\n",
      "Epoch 994/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 2.5499e-04 - val_loss: 5.4680e-04\n",
      "Epoch 995/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.5458e-04 - val_loss: 5.4601e-04\n",
      "Epoch 996/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5415e-04 - val_loss: 5.4523e-04\n",
      "Epoch 997/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 2.5374e-04 - val_loss: 5.4444e-04\n",
      "Epoch 998/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5332e-04 - val_loss: 5.4367e-04\n",
      "Epoch 999/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5291e-04 - val_loss: 5.4288e-04\n",
      "Epoch 1000/1000\n",
      "32/32 [==============================] - 0s 168us/step - loss: 2.5249e-04 - val_loss: 5.4208e-04\n",
      "0.00039883144199848175\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 0.7391709 , -0.95250016, -0.93333143, -1.2681283 ,  0.82242435],\n",
       "        [ 0.35123497,  0.2080682 ,  0.46274352,  1.087654  , -1.368843  ],\n",
       "        [ 1.3190284 , -0.64562   ,  1.0021868 , -0.45566693,  0.38974926]],\n",
       "       dtype=float32),\n",
       " array([ 0.68261176,  0.64783657, -0.68546295,  0.60318595, -0.62538654],\n",
       "       dtype=float32),\n",
       " array([[ 8.3876893e-02,  2.8080171e-01,  3.3434358e-01, -7.2249514e-01,\n",
       "          7.1030885e-02, -4.1968998e-01, -7.1529275e-01, -4.8162454e-01,\n",
       "         -9.3180215e-01,  9.3115681e-01],\n",
       "        [-1.0784489e-01,  6.0161781e-01, -8.7076610e-01, -5.4619873e-01,\n",
       "          3.0964324e-01, -4.4019021e-02, -6.7870235e-01, -5.0568998e-01,\n",
       "         -3.3278811e-01, -1.8494247e-01],\n",
       "        [ 1.8683141e-01, -8.4142870e-01,  2.7187839e-01,  5.8998793e-01,\n",
       "          5.1964629e-01,  6.9054466e-01, -2.6067179e-03,  6.0137808e-01,\n",
       "          8.5432225e-01, -7.0975035e-01],\n",
       "        [ 3.3683306e-01,  5.9547400e-01,  4.5786655e-01, -6.4976972e-01,\n",
       "          1.8226786e-01, -3.1200705e-02, -1.5400633e-02, -9.4791695e-02,\n",
       "         -1.8235810e-01,  4.0853965e-01],\n",
       "        [-7.0292920e-01,  3.6058995e-01,  3.9833093e-01,  4.9903610e-01,\n",
       "          4.6044297e-04, -7.6380426e-01, -2.8756157e-01, -5.2177423e-01,\n",
       "          1.8281533e-01, -8.1687145e-02]], dtype=float32),\n",
       " array([ 0.7185616 ,  0.70752746, -0.08315603, -0.66607845, -0.53767926,\n",
       "         0.00657219, -0.694075  , -0.19711454, -0.7322021 ,  0.69764614],\n",
       "       dtype=float32),\n",
       " array([[ 0.09458732],\n",
       "        [ 0.79563403],\n",
       "        [-0.17133032],\n",
       "        [-0.4873434 ],\n",
       "        [-0.17555796],\n",
       "        [-0.13902424],\n",
       "        [-0.58052707],\n",
       "        [-0.22755854],\n",
       "        [-0.99517655],\n",
       "        [ 0.64372873]], dtype=float32),\n",
       " array([0.7834599], dtype=float32)]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_challenger, history_challenger, evaluate_challenger=NN_model_structure_regression_2(X_train_challenger, X_val_challenger, Y_train_challenger, Y_val_challenger, adam2, 32, 1000, x_test_challenger, y_test_challenger)\n",
    "model_challenger.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_challenger.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_challenger_structure2_4th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_61 (Dense)             (None, 5)                 20        \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 15)                90        \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 126\n",
      "Trainable params: 126\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 32 samples, validate on 7 samples\n",
      "Epoch 1/1000\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 36.7226 - val_loss: 35.4242\n",
      "Epoch 2/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 33.5783 - val_loss: 30.9034\n",
      "Epoch 3/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 30.0173 - val_loss: 26.0567\n",
      "Epoch 4/1000\n",
      "32/32 [==============================] - 0s 132us/step - loss: 25.2365 - val_loss: 19.7589\n",
      "Epoch 5/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 18.8728 - val_loss: 12.0804\n",
      "Epoch 6/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 11.4161 - val_loss: 4.4978\n",
      "Epoch 7/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 4.3937 - val_loss: 0.3674\n",
      "Epoch 8/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.6231 - val_loss: 2.8164\n",
      "Epoch 9/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6319 - val_loss: 8.0017\n",
      "Epoch 10/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.2417 - val_loss: 8.4404\n",
      "Epoch 11/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9402 - val_loss: 5.7132\n",
      "Epoch 12/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5780 - val_loss: 2.7944\n",
      "Epoch 13/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 2.6559 - val_loss: 0.9402\n",
      "Epoch 14/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 0.7310 - val_loss: 0.3177\n",
      "Epoch 15/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 0.2236 - val_loss: 0.5378\n",
      "Epoch 16/1000\n",
      "32/32 [==============================] - 0s 129us/step - loss: 0.7263 - val_loss: 1.0905\n",
      "Epoch 17/1000\n",
      "32/32 [==============================] - 0s 130us/step - loss: 1.5809 - val_loss: 1.6050\n",
      "Epoch 18/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2960 - val_loss: 1.9018\n",
      "Epoch 19/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6486 - val_loss: 1.9383\n",
      "Epoch 20/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6115 - val_loss: 1.7472\n",
      "Epoch 21/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2610 - val_loss: 1.3971\n",
      "Epoch 22/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7190 - val_loss: 0.9735\n",
      "Epoch 23/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1213 - val_loss: 0.5673\n",
      "Epoch 24/1000\n",
      "32/32 [==============================] - 0s 128us/step - loss: 0.5975 - val_loss: 0.2637\n",
      "Epoch 25/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.2498 - val_loss: 0.1269\n",
      "Epoch 26/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 0.1321 - val_loss: 0.1781\n",
      "Epoch 27/1000\n",
      "32/32 [==============================] - 0s 137us/step - loss: 0.2312 - val_loss: 0.3743\n",
      "Epoch 28/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.4645 - val_loss: 0.6108\n",
      "Epoch 29/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.7049 - val_loss: 0.7659\n",
      "Epoch 30/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.8355 - val_loss: 0.7652\n",
      "Epoch 31/1000\n",
      "32/32 [==============================] - 0s 128us/step - loss: 0.8042 - val_loss: 0.6177\n",
      "Epoch 32/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.6399 - val_loss: 0.3972\n",
      "Epoch 33/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.4221 - val_loss: 0.1923\n",
      "Epoch 34/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.2316 - val_loss: 0.0625\n",
      "Epoch 35/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1160 - val_loss: 0.0221\n",
      "Epoch 36/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0818 - val_loss: 0.0502\n",
      "Epoch 37/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.1071 - val_loss: 0.1112\n",
      "Epoch 38/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1600 - val_loss: 0.1724\n",
      "Epoch 39/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 0.2126 - val_loss: 0.2129\n",
      "Epoch 40/1000\n",
      "32/32 [==============================] - 0s 114us/step - loss: 0.2475 - val_loss: 0.2247\n",
      "Epoch 41/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.2573 - val_loss: 0.2096\n",
      "Epoch 42/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.2423 - val_loss: 0.1750\n",
      "Epoch 43/1000\n",
      "32/32 [==============================] - 0s 160us/step - loss: 0.2074 - val_loss: 0.1306\n",
      "Epoch 44/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1607 - val_loss: 0.0860\n",
      "Epoch 45/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1117 - val_loss: 0.0488\n",
      "Epoch 46/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0703 - val_loss: 0.0242\n",
      "Epoch 47/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0440 - val_loss: 0.0134\n",
      "Epoch 48/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0356 - val_loss: 0.0148\n",
      "Epoch 49/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0423 - val_loss: 0.0245\n",
      "Epoch 50/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0574 - val_loss: 0.0381\n",
      "Epoch 51/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0729 - val_loss: 0.0512\n",
      "Epoch 52/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0828 - val_loss: 0.0597\n",
      "Epoch 53/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 0.0842 - val_loss: 0.0611\n",
      "Epoch 54/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0771 - val_loss: 0.0543\n",
      "Epoch 55/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0639 - val_loss: 0.0412\n",
      "Epoch 56/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0481 - val_loss: 0.0256\n",
      "Epoch 57/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0333 - val_loss: 0.0125\n",
      "Epoch 58/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 0.0227 - val_loss: 0.0058\n",
      "Epoch 59/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0180 - val_loss: 0.0066\n",
      "Epoch 60/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0190 - val_loss: 0.0132\n",
      "Epoch 61/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0240 - val_loss: 0.0218\n",
      "Epoch 62/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0302 - val_loss: 0.0287\n",
      "Epoch 63/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0349 - val_loss: 0.0312\n",
      "Epoch 64/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0366 - val_loss: 0.0288\n",
      "Epoch 65/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0347 - val_loss: 0.0229\n",
      "Epoch 66/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0302 - val_loss: 0.0158\n",
      "Epoch 67/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 0.0246 - val_loss: 0.0096\n",
      "Epoch 68/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 0.0195 - val_loss: 0.0054\n",
      "Epoch 69/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0158 - val_loss: 0.0035\n",
      "Epoch 70/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0141 - val_loss: 0.0034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0141 - val_loss: 0.0040\n",
      "Epoch 72/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0153 - val_loss: 0.0047\n",
      "Epoch 73/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0169 - val_loss: 0.0051\n",
      "Epoch 74/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 0.0182 - val_loss: 0.0050\n",
      "Epoch 75/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0187 - val_loss: 0.0045\n",
      "Epoch 76/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 0.0183 - val_loss: 0.0038\n",
      "Epoch 77/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0172 - val_loss: 0.0030\n",
      "Epoch 78/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0155 - val_loss: 0.0024\n",
      "Epoch 79/1000\n",
      "32/32 [==============================] - 0s 128us/step - loss: 0.0139 - val_loss: 0.0020\n",
      "Epoch 80/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0126 - val_loss: 0.0020\n",
      "Epoch 81/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0119 - val_loss: 0.0022\n",
      "Epoch 82/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0116 - val_loss: 0.0026\n",
      "Epoch 83/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0118 - val_loss: 0.0030\n",
      "Epoch 84/1000\n",
      "32/32 [==============================] - 0s 127us/step - loss: 0.0121 - val_loss: 0.0034\n",
      "Epoch 85/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 0.0123 - val_loss: 0.0036\n",
      "Epoch 86/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 0.0125 - val_loss: 0.0036\n",
      "Epoch 87/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0124 - val_loss: 0.0034\n",
      "Epoch 88/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0122 - val_loss: 0.0029\n",
      "Epoch 89/1000\n",
      "32/32 [==============================] - 0s 137us/step - loss: 0.0118 - val_loss: 0.0024\n",
      "Epoch 90/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 0.0112 - val_loss: 0.0019\n",
      "Epoch 91/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0107 - val_loss: 0.0015\n",
      "Epoch 92/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 0.0103 - val_loss: 0.0014\n",
      "Epoch 93/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0100 - val_loss: 0.0014\n",
      "Epoch 94/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0099 - val_loss: 0.0016\n",
      "Epoch 95/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0100 - val_loss: 0.0018\n",
      "Epoch 96/1000\n",
      "32/32 [==============================] - 0s 168us/step - loss: 0.0100 - val_loss: 0.0019\n",
      "Epoch 97/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0101 - val_loss: 0.0020\n",
      "Epoch 98/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0101 - val_loss: 0.0019\n",
      "Epoch 99/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 0.0099 - val_loss: 0.0017\n",
      "Epoch 100/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0097 - val_loss: 0.0015\n",
      "Epoch 101/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 0.0095 - val_loss: 0.0014\n",
      "Epoch 102/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 0.0093 - val_loss: 0.0013\n",
      "Epoch 103/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0091 - val_loss: 0.0013\n",
      "Epoch 104/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0090 - val_loss: 0.0013\n",
      "Epoch 105/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0089 - val_loss: 0.0014\n",
      "Epoch 106/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0088 - val_loss: 0.0015\n",
      "Epoch 107/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 0.0088 - val_loss: 0.0016\n",
      "Epoch 108/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0087 - val_loss: 0.0017\n",
      "Epoch 109/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0087 - val_loss: 0.0017\n",
      "Epoch 110/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 0.0086 - val_loss: 0.0017\n",
      "Epoch 111/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0085 - val_loss: 0.0016\n",
      "Epoch 112/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0084 - val_loss: 0.0015\n",
      "Epoch 113/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0083 - val_loss: 0.0014\n",
      "Epoch 114/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0082 - val_loss: 0.0013\n",
      "Epoch 115/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0081 - val_loss: 0.0012\n",
      "Epoch 116/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0080 - val_loss: 0.0012\n",
      "Epoch 117/1000\n",
      "32/32 [==============================] - 0s 175us/step - loss: 0.0080 - val_loss: 0.0011\n",
      "Epoch 118/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 0.0079 - val_loss: 0.0011\n",
      "Epoch 119/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0078 - val_loss: 0.0011\n",
      "Epoch 120/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0078 - val_loss: 0.0010\n",
      "Epoch 121/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0077 - val_loss: 0.0010\n",
      "Epoch 122/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0077 - val_loss: 0.0010\n",
      "Epoch 123/1000\n",
      "32/32 [==============================] - 0s 109us/step - loss: 0.0076 - val_loss: 9.7825e-04\n",
      "Epoch 124/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0075 - val_loss: 9.5547e-04\n",
      "Epoch 125/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0074 - val_loss: 9.3653e-04\n",
      "Epoch 126/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0074 - val_loss: 9.2477e-04\n",
      "Epoch 127/1000\n",
      "32/32 [==============================] - 0s 117us/step - loss: 0.0073 - val_loss: 9.2089e-04\n",
      "Epoch 128/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0072 - val_loss: 9.2301e-04\n",
      "Epoch 129/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0072 - val_loss: 9.2740e-04\n",
      "Epoch 130/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0071 - val_loss: 9.3014e-04\n",
      "Epoch 131/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 0.0071 - val_loss: 9.2816e-04\n",
      "Epoch 132/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0070 - val_loss: 9.1983e-04\n",
      "Epoch 133/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 0.0070 - val_loss: 9.0488e-04\n",
      "Epoch 134/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 0.0069 - val_loss: 8.8408e-04\n",
      "Epoch 135/1000\n",
      "32/32 [==============================] - 0s 129us/step - loss: 0.0069 - val_loss: 8.5866e-04\n",
      "Epoch 136/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0068 - val_loss: 8.3024e-04\n",
      "Epoch 137/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0068 - val_loss: 8.0062e-04\n",
      "Epoch 138/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 0.0067 - val_loss: 7.7162e-04\n",
      "Epoch 139/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 0.0067 - val_loss: 7.4496e-04\n",
      "Epoch 140/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0066 - val_loss: 7.2211e-04\n",
      "Epoch 141/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 0.0066 - val_loss: 7.0397e-04\n",
      "Epoch 142/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0065 - val_loss: 6.9096e-04\n",
      "Epoch 143/1000\n",
      "32/32 [==============================] - 0s 130us/step - loss: 0.0065 - val_loss: 6.8281e-04\n",
      "Epoch 144/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0064 - val_loss: 6.7873e-04\n",
      "Epoch 145/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0064 - val_loss: 6.7753e-04\n",
      "Epoch 146/1000\n",
      "32/32 [==============================] - 0s 163us/step - loss: 0.0063 - val_loss: 6.7786e-04\n",
      "Epoch 147/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0063 - val_loss: 6.7840e-04\n",
      "Epoch 148/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0062 - val_loss: 6.7807e-04\n",
      "Epoch 149/1000\n",
      "32/32 [==============================] - 0s 118us/step - loss: 0.0062 - val_loss: 6.7613e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0061 - val_loss: 6.7222e-04\n",
      "Epoch 151/1000\n",
      "32/32 [==============================] - 0s 181us/step - loss: 0.0061 - val_loss: 6.6640e-04\n",
      "Epoch 152/1000\n",
      "32/32 [==============================] - 0s 158us/step - loss: 0.0061 - val_loss: 6.5888e-04\n",
      "Epoch 153/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0060 - val_loss: 6.5007e-04\n",
      "Epoch 154/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0060 - val_loss: 6.4047e-04\n",
      "Epoch 155/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 0.0059 - val_loss: 6.3051e-04\n",
      "Epoch 156/1000\n",
      "32/32 [==============================] - 0s 132us/step - loss: 0.0059 - val_loss: 6.2051e-04\n",
      "Epoch 157/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 0.0059 - val_loss: 6.1076e-04\n",
      "Epoch 158/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0058 - val_loss: 6.0134e-04\n",
      "Epoch 159/1000\n",
      "32/32 [==============================] - 0s 175us/step - loss: 0.0058 - val_loss: 5.9221e-04\n",
      "Epoch 160/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 0.0057 - val_loss: 5.8326e-04\n",
      "Epoch 161/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0057 - val_loss: 5.7436e-04\n",
      "Epoch 162/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 0.0057 - val_loss: 5.6542e-04\n",
      "Epoch 163/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0056 - val_loss: 5.5643e-04\n",
      "Epoch 164/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0056 - val_loss: 5.4758e-04\n",
      "Epoch 165/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0056 - val_loss: 5.3908e-04\n",
      "Epoch 166/1000\n",
      "32/32 [==============================] - 0s 145us/step - loss: 0.0055 - val_loss: 5.3116e-04\n",
      "Epoch 167/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0055 - val_loss: 5.2406e-04\n",
      "Epoch 168/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0055 - val_loss: 5.1789e-04\n",
      "Epoch 169/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0054 - val_loss: 5.1267e-04\n",
      "Epoch 170/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0054 - val_loss: 5.0830e-04\n",
      "Epoch 171/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0054 - val_loss: 5.0451e-04\n",
      "Epoch 172/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 0.0053 - val_loss: 5.0101e-04\n",
      "Epoch 173/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0053 - val_loss: 4.9751e-04\n",
      "Epoch 174/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0053 - val_loss: 4.9371e-04\n",
      "Epoch 175/1000\n",
      "32/32 [==============================] - 0s 137us/step - loss: 0.0052 - val_loss: 4.8940e-04\n",
      "Epoch 176/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0052 - val_loss: 4.8454e-04\n",
      "Epoch 177/1000\n",
      "32/32 [==============================] - 0s 158us/step - loss: 0.0052 - val_loss: 4.7908e-04\n",
      "Epoch 178/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0051 - val_loss: 4.7316e-04\n",
      "Epoch 179/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0051 - val_loss: 4.6693e-04\n",
      "Epoch 180/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 0.0051 - val_loss: 4.6055e-04\n",
      "Epoch 181/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0050 - val_loss: 4.5420e-04\n",
      "Epoch 182/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0050 - val_loss: 4.4804e-04\n",
      "Epoch 183/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0050 - val_loss: 4.4212e-04\n",
      "Epoch 184/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0049 - val_loss: 4.3652e-04\n",
      "Epoch 185/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0049 - val_loss: 4.3123e-04\n",
      "Epoch 186/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0049 - val_loss: 4.2620e-04\n",
      "Epoch 187/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0049 - val_loss: 4.2140e-04\n",
      "Epoch 188/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0048 - val_loss: 4.1679e-04\n",
      "Epoch 189/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0048 - val_loss: 4.1230e-04\n",
      "Epoch 190/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0048 - val_loss: 4.0796e-04\n",
      "Epoch 191/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0047 - val_loss: 4.0377e-04\n",
      "Epoch 192/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0047 - val_loss: 3.9972e-04\n",
      "Epoch 193/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0047 - val_loss: 3.9582e-04\n",
      "Epoch 194/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0047 - val_loss: 3.9207e-04\n",
      "Epoch 195/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0046 - val_loss: 3.8843e-04\n",
      "Epoch 196/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0046 - val_loss: 3.8486e-04\n",
      "Epoch 197/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0046 - val_loss: 3.8129e-04\n",
      "Epoch 198/1000\n",
      "32/32 [==============================] - 0s 161us/step - loss: 0.0046 - val_loss: 3.7768e-04\n",
      "Epoch 199/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0045 - val_loss: 3.7398e-04\n",
      "Epoch 200/1000\n",
      "32/32 [==============================] - 0s 132us/step - loss: 0.0045 - val_loss: 3.7013e-04\n",
      "Epoch 201/1000\n",
      "32/32 [==============================] - 0s 129us/step - loss: 0.0045 - val_loss: 3.6618e-04\n",
      "Epoch 202/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0045 - val_loss: 3.6209e-04\n",
      "Epoch 203/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 0.0044 - val_loss: 3.5792e-04\n",
      "Epoch 204/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0044 - val_loss: 3.5371e-04\n",
      "Epoch 205/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0044 - val_loss: 3.4954e-04\n",
      "Epoch 206/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0044 - val_loss: 3.4545e-04\n",
      "Epoch 207/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0043 - val_loss: 3.4149e-04\n",
      "Epoch 208/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0043 - val_loss: 3.3768e-04\n",
      "Epoch 209/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0043 - val_loss: 3.3406e-04\n",
      "Epoch 210/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0043 - val_loss: 3.3060e-04\n",
      "Epoch 211/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0043 - val_loss: 3.2729e-04\n",
      "Epoch 212/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0042 - val_loss: 3.2410e-04\n",
      "Epoch 213/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0042 - val_loss: 3.2100e-04\n",
      "Epoch 214/1000\n",
      "32/32 [==============================] - 0s 145us/step - loss: 0.0042 - val_loss: 3.1795e-04\n",
      "Epoch 215/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0042 - val_loss: 3.1493e-04\n",
      "Epoch 216/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0041 - val_loss: 3.1193e-04\n",
      "Epoch 217/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0041 - val_loss: 3.0894e-04\n",
      "Epoch 218/1000\n",
      "32/32 [==============================] - 0s 130us/step - loss: 0.0041 - val_loss: 3.0596e-04\n",
      "Epoch 219/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0041 - val_loss: 3.0299e-04\n",
      "Epoch 220/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0041 - val_loss: 3.0002e-04\n",
      "Epoch 221/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0040 - val_loss: 2.9709e-04\n",
      "Epoch 222/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0040 - val_loss: 2.9418e-04\n",
      "Epoch 223/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0040 - val_loss: 2.9130e-04\n",
      "Epoch 224/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 0.0040 - val_loss: 2.8843e-04\n",
      "Epoch 225/1000\n",
      "32/32 [==============================] - 0s 128us/step - loss: 0.0040 - val_loss: 2.8559e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 226/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 0.0039 - val_loss: 2.8277e-04\n",
      "Epoch 227/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0039 - val_loss: 2.7998e-04\n",
      "Epoch 228/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0039 - val_loss: 2.7720e-04\n",
      "Epoch 229/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 0.0039 - val_loss: 2.7445e-04\n",
      "Epoch 230/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 0.0039 - val_loss: 2.7175e-04\n",
      "Epoch 231/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0038 - val_loss: 2.6909e-04\n",
      "Epoch 232/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0038 - val_loss: 2.6648e-04\n",
      "Epoch 233/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0038 - val_loss: 2.6394e-04\n",
      "Epoch 234/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0038 - val_loss: 2.6145e-04\n",
      "Epoch 235/1000\n",
      "32/32 [==============================] - 0s 162us/step - loss: 0.0038 - val_loss: 2.5904e-04\n",
      "Epoch 236/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0038 - val_loss: 2.5666e-04\n",
      "Epoch 237/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0037 - val_loss: 2.5434e-04\n",
      "Epoch 238/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0037 - val_loss: 2.5206e-04\n",
      "Epoch 239/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0037 - val_loss: 2.4979e-04\n",
      "Epoch 240/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0037 - val_loss: 2.4755e-04\n",
      "Epoch 241/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0037 - val_loss: 2.4533e-04\n",
      "Epoch 242/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0036 - val_loss: 2.4311e-04\n",
      "Epoch 243/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0036 - val_loss: 2.4090e-04\n",
      "Epoch 244/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0036 - val_loss: 2.3872e-04\n",
      "Epoch 245/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0036 - val_loss: 2.3653e-04\n",
      "Epoch 246/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0036 - val_loss: 2.3436e-04\n",
      "Epoch 247/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0036 - val_loss: 2.3223e-04\n",
      "Epoch 248/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0035 - val_loss: 2.3011e-04\n",
      "Epoch 249/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0035 - val_loss: 2.2801e-04\n",
      "Epoch 250/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0035 - val_loss: 2.2598e-04\n",
      "Epoch 251/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0035 - val_loss: 2.2395e-04\n",
      "Epoch 252/1000\n",
      "32/32 [==============================] - 0s 138us/step - loss: 0.0035 - val_loss: 2.2194e-04\n",
      "Epoch 253/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0035 - val_loss: 2.1997e-04\n",
      "Epoch 254/1000\n",
      "32/32 [==============================] - 0s 131us/step - loss: 0.0035 - val_loss: 2.1803e-04\n",
      "Epoch 255/1000\n",
      "32/32 [==============================] - 0s 138us/step - loss: 0.0034 - val_loss: 2.1612e-04\n",
      "Epoch 256/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0034 - val_loss: 2.1423e-04\n",
      "Epoch 257/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0034 - val_loss: 2.1237e-04\n",
      "Epoch 258/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 0.0034 - val_loss: 2.1054e-04\n",
      "Epoch 259/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 0.0034 - val_loss: 2.0873e-04\n",
      "Epoch 260/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0034 - val_loss: 2.0697e-04\n",
      "Epoch 261/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 2.0522e-04\n",
      "Epoch 262/1000\n",
      "32/32 [==============================] - 0s 130us/step - loss: 0.0033 - val_loss: 2.0349e-04\n",
      "Epoch 263/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0033 - val_loss: 2.0178e-04\n",
      "Epoch 264/1000\n",
      "32/32 [==============================] - 0s 162us/step - loss: 0.0033 - val_loss: 2.0010e-04\n",
      "Epoch 265/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 0.0033 - val_loss: 1.9843e-04\n",
      "Epoch 266/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 1.9676e-04\n",
      "Epoch 267/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 1.9513e-04\n",
      "Epoch 268/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0032 - val_loss: 1.9350e-04\n",
      "Epoch 269/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 1.9190e-04\n",
      "Epoch 270/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0032 - val_loss: 1.9030e-04\n",
      "Epoch 271/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 1.8873e-04\n",
      "Epoch 272/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 0.0032 - val_loss: 1.8719e-04\n",
      "Epoch 273/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 1.8565e-04\n",
      "Epoch 274/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 0.0032 - val_loss: 1.8415e-04\n",
      "Epoch 275/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0032 - val_loss: 1.8266e-04\n",
      "Epoch 276/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0031 - val_loss: 1.8119e-04\n",
      "Epoch 277/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 0.0031 - val_loss: 1.7974e-04\n",
      "Epoch 278/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 0.0031 - val_loss: 1.7833e-04\n",
      "Epoch 279/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0031 - val_loss: 1.7692e-04\n",
      "Epoch 280/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0031 - val_loss: 1.7553e-04\n",
      "Epoch 281/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0031 - val_loss: 1.7416e-04\n",
      "Epoch 282/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0031 - val_loss: 1.7281e-04\n",
      "Epoch 283/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0030 - val_loss: 1.7147e-04\n",
      "Epoch 284/1000\n",
      "32/32 [==============================] - 0s 167us/step - loss: 0.0030 - val_loss: 1.7016e-04\n",
      "Epoch 285/1000\n",
      "32/32 [==============================] - 0s 130us/step - loss: 0.0030 - val_loss: 1.6886e-04\n",
      "Epoch 286/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 0.0030 - val_loss: 1.6757e-04\n",
      "Epoch 287/1000\n",
      "32/32 [==============================] - 0s 137us/step - loss: 0.0030 - val_loss: 1.6630e-04\n",
      "Epoch 288/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 1.6505e-04\n",
      "Epoch 289/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 1.6380e-04\n",
      "Epoch 290/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0030 - val_loss: 1.6258e-04\n",
      "Epoch 291/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 1.6136e-04\n",
      "Epoch 292/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 1.6016e-04\n",
      "Epoch 293/1000\n",
      "32/32 [==============================] - 0s 158us/step - loss: 0.0029 - val_loss: 1.5898e-04\n",
      "Epoch 294/1000\n",
      "32/32 [==============================] - 0s 128us/step - loss: 0.0029 - val_loss: 1.5781e-04\n",
      "Epoch 295/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0029 - val_loss: 1.5666e-04\n",
      "Epoch 296/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0029 - val_loss: 1.5552e-04\n",
      "Epoch 297/1000\n",
      "32/32 [==============================] - 0s 145us/step - loss: 0.0029 - val_loss: 1.5441e-04\n",
      "Epoch 298/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 1.5330e-04\n",
      "Epoch 299/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 0.0029 - val_loss: 1.5220e-04\n",
      "Epoch 300/1000\n",
      "32/32 [==============================] - 0s 130us/step - loss: 0.0028 - val_loss: 1.5112e-04\n",
      "Epoch 301/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 0.0028 - val_loss: 1.5006e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 302/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0028 - val_loss: 1.4902e-04\n",
      "Epoch 303/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0028 - val_loss: 1.4797e-04\n",
      "Epoch 304/1000\n",
      "32/32 [==============================] - 0s 128us/step - loss: 0.0028 - val_loss: 1.4695e-04\n",
      "Epoch 305/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0028 - val_loss: 1.4594e-04\n",
      "Epoch 306/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 1.4494e-04\n",
      "Epoch 307/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0028 - val_loss: 1.4396e-04\n",
      "Epoch 308/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 0.0028 - val_loss: 1.4299e-04\n",
      "Epoch 309/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0028 - val_loss: 1.4203e-04\n",
      "Epoch 310/1000\n",
      "32/32 [==============================] - 0s 165us/step - loss: 0.0027 - val_loss: 1.4108e-04\n",
      "Epoch 311/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 1.4013e-04\n",
      "Epoch 312/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0027 - val_loss: 1.3921e-04\n",
      "Epoch 313/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0027 - val_loss: 1.3830e-04\n",
      "Epoch 314/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 1.3740e-04\n",
      "Epoch 315/1000\n",
      "32/32 [==============================] - 0s 166us/step - loss: 0.0027 - val_loss: 1.3651e-04\n",
      "Epoch 316/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 1.3563e-04\n",
      "Epoch 317/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 1.3476e-04\n",
      "Epoch 318/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0027 - val_loss: 1.3391e-04\n",
      "Epoch 319/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 0.0027 - val_loss: 1.3306e-04\n",
      "Epoch 320/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0026 - val_loss: 1.3223e-04\n",
      "Epoch 321/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0026 - val_loss: 1.3140e-04\n",
      "Epoch 322/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 0.0026 - val_loss: 1.3060e-04\n",
      "Epoch 323/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 0.0026 - val_loss: 1.2979e-04\n",
      "Epoch 324/1000\n",
      "32/32 [==============================] - 0s 116us/step - loss: 0.0026 - val_loss: 1.2900e-04\n",
      "Epoch 325/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0026 - val_loss: 1.2823e-04\n",
      "Epoch 326/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 1.2745e-04\n",
      "Epoch 327/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 1.2669e-04\n",
      "Epoch 328/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 1.2594e-04\n",
      "Epoch 329/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 1.2520e-04\n",
      "Epoch 330/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 1.2446e-04\n",
      "Epoch 331/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 1.2373e-04\n",
      "Epoch 332/1000\n",
      "32/32 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 1.2303e-04\n",
      "Epoch 333/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 0.0025 - val_loss: 1.2232e-04\n",
      "Epoch 334/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0025 - val_loss: 1.2163e-04\n",
      "Epoch 335/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 1.2094e-04\n",
      "Epoch 336/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 0.0025 - val_loss: 1.2026e-04\n",
      "Epoch 337/1000\n",
      "32/32 [==============================] - 0s 161us/step - loss: 0.0025 - val_loss: 1.1959e-04\n",
      "Epoch 338/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 1.1894e-04\n",
      "Epoch 339/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0025 - val_loss: 1.1828e-04\n",
      "Epoch 340/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0025 - val_loss: 1.1764e-04\n",
      "Epoch 341/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 1.1701e-04\n",
      "Epoch 342/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 0.0024 - val_loss: 1.1638e-04\n",
      "Epoch 343/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 0.0024 - val_loss: 1.1576e-04\n",
      "Epoch 344/1000\n",
      "32/32 [==============================] - 0s 128us/step - loss: 0.0024 - val_loss: 1.1515e-04\n",
      "Epoch 345/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 1.1455e-04\n",
      "Epoch 346/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 1.1396e-04\n",
      "Epoch 347/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 1.1336e-04\n",
      "Epoch 348/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 1.1278e-04\n",
      "Epoch 349/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 0.0024 - val_loss: 1.1221e-04\n",
      "Epoch 350/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 1.1164e-04\n",
      "Epoch 351/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0024 - val_loss: 1.1109e-04\n",
      "Epoch 352/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 1.1054e-04\n",
      "Epoch 353/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 1.1000e-04\n",
      "Epoch 354/1000\n",
      "32/32 [==============================] - 0s 137us/step - loss: 0.0023 - val_loss: 1.0946e-04\n",
      "Epoch 355/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 0.0023 - val_loss: 1.0893e-04\n",
      "Epoch 356/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 1.0841e-04\n",
      "Epoch 357/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 1.0789e-04\n",
      "Epoch 358/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 0.0023 - val_loss: 1.0738e-04\n",
      "Epoch 359/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0023 - val_loss: 1.0688e-04\n",
      "Epoch 360/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0023 - val_loss: 1.0638e-04\n",
      "Epoch 361/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 0.0023 - val_loss: 1.0590e-04\n",
      "Epoch 362/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 1.0541e-04\n",
      "Epoch 363/1000\n",
      "32/32 [==============================] - 0s 128us/step - loss: 0.0023 - val_loss: 1.0494e-04\n",
      "Epoch 364/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 0.0023 - val_loss: 1.0447e-04\n",
      "Epoch 365/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0023 - val_loss: 1.0400e-04\n",
      "Epoch 366/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0023 - val_loss: 1.0355e-04\n",
      "Epoch 367/1000\n",
      "32/32 [==============================] - 0s 121us/step - loss: 0.0022 - val_loss: 1.0309e-04\n",
      "Epoch 368/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0022 - val_loss: 1.0265e-04\n",
      "Epoch 369/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 1.0220e-04\n",
      "Epoch 370/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 0.0022 - val_loss: 1.0177e-04\n",
      "Epoch 371/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0022 - val_loss: 1.0134e-04\n",
      "Epoch 372/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0022 - val_loss: 1.0090e-04\n",
      "Epoch 373/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 1.0049e-04\n",
      "Epoch 374/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 1.0008e-04\n",
      "Epoch 375/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 9.9663e-05\n",
      "Epoch 376/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 0.0022 - val_loss: 9.9262e-05\n",
      "Epoch 377/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 0.0022 - val_loss: 9.8861e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 378/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 9.8467e-05\n",
      "Epoch 379/1000\n",
      "32/32 [==============================] - 0s 162us/step - loss: 0.0022 - val_loss: 9.8080e-05\n",
      "Epoch 380/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 9.7689e-05\n",
      "Epoch 381/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0021 - val_loss: 9.7311e-05\n",
      "Epoch 382/1000\n",
      "32/32 [==============================] - 0s 130us/step - loss: 0.0021 - val_loss: 9.6935e-05\n",
      "Epoch 383/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 9.6574e-05\n",
      "Epoch 384/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 9.6208e-05\n",
      "Epoch 385/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0021 - val_loss: 9.5849e-05\n",
      "Epoch 386/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0021 - val_loss: 9.5499e-05\n",
      "Epoch 387/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0021 - val_loss: 9.5145e-05\n",
      "Epoch 388/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 9.4798e-05\n",
      "Epoch 389/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 9.4459e-05\n",
      "Epoch 390/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 9.4116e-05\n",
      "Epoch 391/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 9.3775e-05\n",
      "Epoch 392/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 0.0021 - val_loss: 9.3454e-05\n",
      "Epoch 393/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0021 - val_loss: 9.3129e-05\n",
      "Epoch 394/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 9.2804e-05\n",
      "Epoch 395/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0021 - val_loss: 9.2484e-05\n",
      "Epoch 396/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 9.2176e-05\n",
      "Epoch 397/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 0.0020 - val_loss: 9.1871e-05\n",
      "Epoch 398/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 0.0020 - val_loss: 9.1558e-05\n",
      "Epoch 399/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0020 - val_loss: 9.1256e-05\n",
      "Epoch 400/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 9.0960e-05\n",
      "Epoch 401/1000\n",
      "32/32 [==============================] - 0s 173us/step - loss: 0.0020 - val_loss: 9.0661e-05\n",
      "Epoch 402/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 9.0369e-05\n",
      "Epoch 403/1000\n",
      "32/32 [==============================] - 0s 110us/step - loss: 0.0020 - val_loss: 9.0081e-05\n",
      "Epoch 404/1000\n",
      "32/32 [==============================] - 0s 118us/step - loss: 0.0020 - val_loss: 8.9797e-05\n",
      "Epoch 405/1000\n",
      "32/32 [==============================] - 0s 132us/step - loss: 0.0020 - val_loss: 8.9523e-05\n",
      "Epoch 406/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 0.0020 - val_loss: 8.9245e-05\n",
      "Epoch 407/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 8.8973e-05\n",
      "Epoch 408/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 0.0020 - val_loss: 8.8702e-05\n",
      "Epoch 409/1000\n",
      "32/32 [==============================] - 0s 128us/step - loss: 0.0020 - val_loss: 8.8433e-05\n",
      "Epoch 410/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 8.8174e-05\n",
      "Epoch 411/1000\n",
      "32/32 [==============================] - 0s 138us/step - loss: 0.0020 - val_loss: 8.7908e-05\n",
      "Epoch 412/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 8.7656e-05\n",
      "Epoch 413/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 8.7401e-05\n",
      "Epoch 414/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0019 - val_loss: 8.7146e-05\n",
      "Epoch 415/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0019 - val_loss: 8.6901e-05\n",
      "Epoch 416/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0019 - val_loss: 8.6647e-05\n",
      "Epoch 417/1000\n",
      "32/32 [==============================] - 0s 132us/step - loss: 0.0019 - val_loss: 8.6410e-05\n",
      "Epoch 418/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 8.6172e-05\n",
      "Epoch 419/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 0.0019 - val_loss: 8.5936e-05\n",
      "Epoch 420/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 0.0019 - val_loss: 8.5698e-05\n",
      "Epoch 421/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 8.5472e-05\n",
      "Epoch 422/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0019 - val_loss: 8.5245e-05\n",
      "Epoch 423/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 8.5018e-05\n",
      "Epoch 424/1000\n",
      "32/32 [==============================] - 0s 158us/step - loss: 0.0019 - val_loss: 8.4796e-05\n",
      "Epoch 425/1000\n",
      "32/32 [==============================] - 0s 161us/step - loss: 0.0019 - val_loss: 8.4582e-05\n",
      "Epoch 426/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 8.4362e-05\n",
      "Epoch 427/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0019 - val_loss: 8.4143e-05\n",
      "Epoch 428/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0019 - val_loss: 8.3932e-05\n",
      "Epoch 429/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 8.3722e-05\n",
      "Epoch 430/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 8.3511e-05\n",
      "Epoch 431/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 8.3310e-05\n",
      "Epoch 432/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 0.0018 - val_loss: 8.3112e-05\n",
      "Epoch 433/1000\n",
      "32/32 [==============================] - 0s 174us/step - loss: 0.0018 - val_loss: 8.2906e-05\n",
      "Epoch 434/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 0.0018 - val_loss: 8.2704e-05\n",
      "Epoch 435/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 8.2509e-05\n",
      "Epoch 436/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 0.0018 - val_loss: 8.2319e-05\n",
      "Epoch 437/1000\n",
      "32/32 [==============================] - 0s 163us/step - loss: 0.0018 - val_loss: 8.2130e-05\n",
      "Epoch 438/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 0.0018 - val_loss: 8.1942e-05\n",
      "Epoch 439/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 8.1744e-05\n",
      "Epoch 440/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0018 - val_loss: 8.1567e-05\n",
      "Epoch 441/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 0.0018 - val_loss: 8.1384e-05\n",
      "Epoch 442/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 8.1203e-05\n",
      "Epoch 443/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0018 - val_loss: 8.1021e-05\n",
      "Epoch 444/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 8.0838e-05\n",
      "Epoch 445/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0018 - val_loss: 8.0669e-05\n",
      "Epoch 446/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 8.0498e-05\n",
      "Epoch 447/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0018 - val_loss: 8.0330e-05\n",
      "Epoch 448/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0018 - val_loss: 8.0158e-05\n",
      "Epoch 449/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 7.9997e-05\n",
      "Epoch 450/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0017 - val_loss: 7.9825e-05\n",
      "Epoch 451/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0017 - val_loss: 7.9663e-05\n",
      "Epoch 452/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 7.9501e-05\n",
      "Epoch 453/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 0.0017 - val_loss: 7.9348e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 454/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 0.0017 - val_loss: 7.9189e-05\n",
      "Epoch 455/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 7.9035e-05\n",
      "Epoch 456/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 7.8874e-05\n",
      "Epoch 457/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0017 - val_loss: 7.8718e-05\n",
      "Epoch 458/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 7.8567e-05\n",
      "Epoch 459/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 0.0017 - val_loss: 7.8418e-05\n",
      "Epoch 460/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 7.8275e-05\n",
      "Epoch 461/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 7.8128e-05\n",
      "Epoch 462/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 0.0017 - val_loss: 7.7983e-05\n",
      "Epoch 463/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 7.7844e-05\n",
      "Epoch 464/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0017 - val_loss: 7.7697e-05\n",
      "Epoch 465/1000\n",
      "32/32 [==============================] - 0s 145us/step - loss: 0.0017 - val_loss: 7.7563e-05\n",
      "Epoch 466/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0017 - val_loss: 7.7427e-05\n",
      "Epoch 467/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 0.0017 - val_loss: 7.7282e-05\n",
      "Epoch 468/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 7.7152e-05\n",
      "Epoch 469/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 0.0017 - val_loss: 7.7018e-05\n",
      "Epoch 470/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 0.0016 - val_loss: 7.6876e-05\n",
      "Epoch 471/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 0.0016 - val_loss: 7.6752e-05\n",
      "Epoch 472/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0016 - val_loss: 7.6620e-05\n",
      "Epoch 473/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 7.6488e-05\n",
      "Epoch 474/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 7.6363e-05\n",
      "Epoch 475/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 7.6234e-05\n",
      "Epoch 476/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 7.6104e-05\n",
      "Epoch 477/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 7.5980e-05\n",
      "Epoch 478/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 7.5855e-05\n",
      "Epoch 479/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 7.5743e-05\n",
      "Epoch 480/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 0.0016 - val_loss: 7.5616e-05\n",
      "Epoch 481/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 0.0016 - val_loss: 7.5499e-05\n",
      "Epoch 482/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 7.5385e-05\n",
      "Epoch 483/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 7.5276e-05\n",
      "Epoch 484/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 7.5161e-05\n",
      "Epoch 485/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0016 - val_loss: 7.5042e-05\n",
      "Epoch 486/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0016 - val_loss: 7.4925e-05\n",
      "Epoch 487/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0016 - val_loss: 7.4816e-05\n",
      "Epoch 488/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 7.4703e-05\n",
      "Epoch 489/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 7.4600e-05\n",
      "Epoch 490/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0016 - val_loss: 7.4488e-05\n",
      "Epoch 491/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0016 - val_loss: 7.4384e-05\n",
      "Epoch 492/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 7.4273e-05\n",
      "Epoch 493/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 7.4165e-05\n",
      "Epoch 494/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 7.4069e-05\n",
      "Epoch 495/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 7.3964e-05\n",
      "Epoch 496/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0015 - val_loss: 7.3859e-05\n",
      "Epoch 497/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 7.3758e-05\n",
      "Epoch 498/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0015 - val_loss: 7.3653e-05\n",
      "Epoch 499/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 7.3557e-05\n",
      "Epoch 500/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 7.3453e-05\n",
      "Epoch 501/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 7.3363e-05\n",
      "Epoch 502/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 7.3262e-05\n",
      "Epoch 503/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0015 - val_loss: 7.3172e-05\n",
      "Epoch 504/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0015 - val_loss: 7.3075e-05\n",
      "Epoch 505/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 7.2975e-05\n",
      "Epoch 506/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0015 - val_loss: 7.2889e-05\n",
      "Epoch 507/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0015 - val_loss: 7.2790e-05\n",
      "Epoch 508/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0015 - val_loss: 7.2702e-05\n",
      "Epoch 509/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0015 - val_loss: 7.2606e-05\n",
      "Epoch 510/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0015 - val_loss: 7.2523e-05\n",
      "Epoch 511/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 7.2423e-05\n",
      "Epoch 512/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 7.2339e-05\n",
      "Epoch 513/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 7.2248e-05\n",
      "Epoch 514/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 7.2171e-05\n",
      "Epoch 515/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 7.2080e-05\n",
      "Epoch 516/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 7.2000e-05\n",
      "Epoch 517/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 7.1913e-05\n",
      "Epoch 518/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 7.1834e-05\n",
      "Epoch 519/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 7.1750e-05\n",
      "Epoch 520/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 7.1677e-05\n",
      "Epoch 521/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 7.1586e-05\n",
      "Epoch 522/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 7.1502e-05\n",
      "Epoch 523/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 7.1431e-05\n",
      "Epoch 524/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0014 - val_loss: 7.1347e-05\n",
      "Epoch 525/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0014 - val_loss: 7.1267e-05\n",
      "Epoch 526/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 7.1186e-05\n",
      "Epoch 527/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0014 - val_loss: 7.1107e-05\n",
      "Epoch 528/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 7.1031e-05\n",
      "Epoch 529/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0014 - val_loss: 7.0953e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 530/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 7.0872e-05\n",
      "Epoch 531/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 7.0798e-05\n",
      "Epoch 532/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 7.0729e-05\n",
      "Epoch 533/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 7.0660e-05\n",
      "Epoch 534/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0014 - val_loss: 7.0586e-05\n",
      "Epoch 535/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 7.0506e-05\n",
      "Epoch 536/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0014 - val_loss: 7.0440e-05\n",
      "Epoch 537/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 7.0370e-05\n",
      "Epoch 538/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 7.0291e-05\n",
      "Epoch 539/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 7.0228e-05\n",
      "Epoch 540/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 7.0150e-05\n",
      "Epoch 541/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0014 - val_loss: 7.0081e-05\n",
      "Epoch 542/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 7.0014e-05\n",
      "Epoch 543/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 6.9949e-05\n",
      "Epoch 544/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 6.9885e-05\n",
      "Epoch 545/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 6.9810e-05\n",
      "Epoch 546/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 6.9745e-05\n",
      "Epoch 547/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0013 - val_loss: 6.9683e-05\n",
      "Epoch 548/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0013 - val_loss: 6.9617e-05\n",
      "Epoch 549/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 6.9558e-05\n",
      "Epoch 550/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 6.9479e-05\n",
      "Epoch 551/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 6.9414e-05\n",
      "Epoch 552/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0013 - val_loss: 6.9349e-05\n",
      "Epoch 553/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 6.9291e-05\n",
      "Epoch 554/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 6.9233e-05\n",
      "Epoch 555/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 6.9169e-05\n",
      "Epoch 556/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 6.9107e-05\n",
      "Epoch 557/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 6.9047e-05\n",
      "Epoch 558/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 6.8991e-05\n",
      "Epoch 559/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 6.8931e-05\n",
      "Epoch 560/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 6.8865e-05\n",
      "Epoch 561/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 6.8804e-05\n",
      "Epoch 562/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0013 - val_loss: 6.8750e-05\n",
      "Epoch 563/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0013 - val_loss: 6.8685e-05\n",
      "Epoch 564/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 6.8619e-05\n",
      "Epoch 565/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 6.8568e-05\n",
      "Epoch 566/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 6.8508e-05\n",
      "Epoch 567/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 6.8448e-05\n",
      "Epoch 568/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 6.8392e-05\n",
      "Epoch 569/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 6.8336e-05\n",
      "Epoch 570/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 6.8285e-05\n",
      "Epoch 571/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 6.8228e-05\n",
      "Epoch 572/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 6.8176e-05\n",
      "Epoch 573/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 6.8118e-05\n",
      "Epoch 574/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 6.8061e-05\n",
      "Epoch 575/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 6.8006e-05\n",
      "Epoch 576/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 6.7952e-05\n",
      "Epoch 577/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 6.7902e-05\n",
      "Epoch 578/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 6.7846e-05\n",
      "Epoch 579/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 6.7792e-05\n",
      "Epoch 580/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 6.7741e-05\n",
      "Epoch 581/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 6.7683e-05\n",
      "Epoch 582/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 6.7639e-05\n",
      "Epoch 583/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 6.7587e-05\n",
      "Epoch 584/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 6.7527e-05\n",
      "Epoch 585/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 6.7482e-05\n",
      "Epoch 586/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 6.7427e-05\n",
      "Epoch 587/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 6.7374e-05\n",
      "Epoch 588/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 6.7325e-05\n",
      "Epoch 589/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 6.7268e-05\n",
      "Epoch 590/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 6.7221e-05\n",
      "Epoch 591/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 6.7173e-05\n",
      "Epoch 592/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 6.7131e-05\n",
      "Epoch 593/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 6.7075e-05\n",
      "Epoch 594/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 6.7024e-05\n",
      "Epoch 595/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 6.6981e-05\n",
      "Epoch 596/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 6.6936e-05\n",
      "Epoch 597/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 6.6878e-05\n",
      "Epoch 598/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 6.6837e-05\n",
      "Epoch 599/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 6.6784e-05\n",
      "Epoch 600/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 6.6743e-05\n",
      "Epoch 601/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 6.6692e-05\n",
      "Epoch 602/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 6.6649e-05\n",
      "Epoch 603/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 6.6601e-05\n",
      "Epoch 604/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 6.6551e-05\n",
      "Epoch 605/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0012 - val_loss: 6.6511e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 606/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0012 - val_loss: 6.6464e-05\n",
      "Epoch 607/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 6.6413e-05\n",
      "Epoch 608/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 6.6365e-05\n",
      "Epoch 609/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 6.6318e-05\n",
      "Epoch 610/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 6.6269e-05\n",
      "Epoch 611/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 6.6231e-05\n",
      "Epoch 612/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 6.6187e-05\n",
      "Epoch 613/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 6.6139e-05\n",
      "Epoch 614/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 6.6102e-05\n",
      "Epoch 615/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0011 - val_loss: 6.6047e-05\n",
      "Epoch 616/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 6.6010e-05\n",
      "Epoch 617/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 6.5965e-05\n",
      "Epoch 618/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 6.5926e-05\n",
      "Epoch 619/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 6.5879e-05\n",
      "Epoch 620/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 6.5827e-05\n",
      "Epoch 621/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0011 - val_loss: 6.5794e-05\n",
      "Epoch 622/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0011 - val_loss: 6.5744e-05\n",
      "Epoch 623/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 6.5700e-05\n",
      "Epoch 624/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 6.5655e-05\n",
      "Epoch 625/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0011 - val_loss: 6.5618e-05\n",
      "Epoch 626/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 6.5574e-05\n",
      "Epoch 627/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 6.5531e-05\n",
      "Epoch 628/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0011 - val_loss: 6.5492e-05\n",
      "Epoch 629/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 6.5450e-05\n",
      "Epoch 630/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 6.5407e-05\n",
      "Epoch 631/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 6.5367e-05\n",
      "Epoch 632/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 6.5327e-05\n",
      "Epoch 633/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 6.5288e-05\n",
      "Epoch 634/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 6.5247e-05\n",
      "Epoch 635/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 6.5207e-05\n",
      "Epoch 636/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 6.5161e-05\n",
      "Epoch 637/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 6.5122e-05\n",
      "Epoch 638/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 6.5079e-05\n",
      "Epoch 639/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 6.5038e-05\n",
      "Epoch 640/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 6.4998e-05\n",
      "Epoch 641/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 6.4959e-05\n",
      "Epoch 642/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 6.4915e-05\n",
      "Epoch 643/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 6.4871e-05\n",
      "Epoch 644/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 6.4832e-05\n",
      "Epoch 645/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 6.4794e-05\n",
      "Epoch 646/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 6.4765e-05\n",
      "Epoch 647/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 6.4720e-05\n",
      "Epoch 648/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 0.0010 - val_loss: 6.4682e-05\n",
      "Epoch 649/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0010 - val_loss: 6.4637e-05\n",
      "Epoch 650/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0010 - val_loss: 6.4601e-05\n",
      "Epoch 651/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0010 - val_loss: 6.4563e-05\n",
      "Epoch 652/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0010 - val_loss: 6.4520e-05\n",
      "Epoch 653/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0010 - val_loss: 6.4485e-05\n",
      "Epoch 654/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0010 - val_loss: 6.4447e-05\n",
      "Epoch 655/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0010 - val_loss: 6.4404e-05\n",
      "Epoch 656/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0010 - val_loss: 6.4371e-05\n",
      "Epoch 657/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0010 - val_loss: 6.4334e-05\n",
      "Epoch 658/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0010 - val_loss: 6.4295e-05\n",
      "Epoch 659/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 6.4255e-05\n",
      "Epoch 660/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0010 - val_loss: 6.4215e-05\n",
      "Epoch 661/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0010 - val_loss: 6.4176e-05\n",
      "Epoch 662/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 6.4137e-05\n",
      "Epoch 663/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 6.4104e-05\n",
      "Epoch 664/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 6.4056e-05\n",
      "Epoch 665/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 6.4018e-05\n",
      "Epoch 666/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.9823e-04 - val_loss: 6.3986e-05\n",
      "Epoch 667/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.9586e-04 - val_loss: 6.3946e-05\n",
      "Epoch 668/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.9349e-04 - val_loss: 6.3911e-05\n",
      "Epoch 669/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.9112e-04 - val_loss: 6.3875e-05\n",
      "Epoch 670/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.8877e-04 - val_loss: 6.3838e-05\n",
      "Epoch 671/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.8641e-04 - val_loss: 6.3803e-05\n",
      "Epoch 672/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.8407e-04 - val_loss: 6.3763e-05\n",
      "Epoch 673/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.8175e-04 - val_loss: 6.3729e-05\n",
      "Epoch 674/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.7942e-04 - val_loss: 6.3683e-05\n",
      "Epoch 675/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.7709e-04 - val_loss: 6.3652e-05\n",
      "Epoch 676/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.7478e-04 - val_loss: 6.3614e-05\n",
      "Epoch 677/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.7248e-04 - val_loss: 6.3575e-05\n",
      "Epoch 678/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.7018e-04 - val_loss: 6.3542e-05\n",
      "Epoch 679/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.6787e-04 - val_loss: 6.3496e-05\n",
      "Epoch 680/1000\n",
      "32/32 [==============================] - 0s 116us/step - loss: 9.6558e-04 - val_loss: 6.3464e-05\n",
      "Epoch 681/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 9.6330e-04 - val_loss: 6.3426e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 682/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.6103e-04 - val_loss: 6.3387e-05\n",
      "Epoch 683/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.5876e-04 - val_loss: 6.3348e-05\n",
      "Epoch 684/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.5649e-04 - val_loss: 6.3313e-05\n",
      "Epoch 685/1000\n",
      "32/32 [==============================] - 0s 122us/step - loss: 9.5423e-04 - val_loss: 6.3271e-05\n",
      "Epoch 686/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.5199e-04 - val_loss: 6.3247e-05\n",
      "Epoch 687/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4975e-04 - val_loss: 6.3201e-05\n",
      "Epoch 688/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4750e-04 - val_loss: 6.3163e-05\n",
      "Epoch 689/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4527e-04 - val_loss: 6.3135e-05\n",
      "Epoch 690/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4305e-04 - val_loss: 6.3093e-05\n",
      "Epoch 691/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 9.4083e-04 - val_loss: 6.3061e-05\n",
      "Epoch 692/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3862e-04 - val_loss: 6.3024e-05\n",
      "Epoch 693/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.3642e-04 - val_loss: 6.2983e-05\n",
      "Epoch 694/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3422e-04 - val_loss: 6.2948e-05\n",
      "Epoch 695/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3202e-04 - val_loss: 6.2918e-05\n",
      "Epoch 696/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.2984e-04 - val_loss: 6.2879e-05\n",
      "Epoch 697/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.2766e-04 - val_loss: 6.2845e-05\n",
      "Epoch 698/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 9.2548e-04 - val_loss: 6.2812e-05\n",
      "Epoch 699/1000\n",
      "32/32 [==============================] - 0s 131us/step - loss: 9.2331e-04 - val_loss: 6.2773e-05\n",
      "Epoch 700/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.2112e-04 - val_loss: 6.2731e-05\n",
      "Epoch 701/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.1900e-04 - val_loss: 6.2698e-05\n",
      "Epoch 702/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1684e-04 - val_loss: 6.2659e-05\n",
      "Epoch 703/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1469e-04 - val_loss: 6.2622e-05\n",
      "Epoch 704/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1255e-04 - val_loss: 6.2581e-05\n",
      "Epoch 705/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 9.1042e-04 - val_loss: 6.2554e-05\n",
      "Epoch 706/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 9.0829e-04 - val_loss: 6.2516e-05\n",
      "Epoch 707/1000\n",
      "32/32 [==============================] - 0s 172us/step - loss: 9.0617e-04 - val_loss: 6.2480e-05\n",
      "Epoch 708/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.0406e-04 - val_loss: 6.2445e-05\n",
      "Epoch 709/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.0194e-04 - val_loss: 6.2418e-05\n",
      "Epoch 710/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 8.9984e-04 - val_loss: 6.2375e-05\n",
      "Epoch 711/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 8.9775e-04 - val_loss: 6.2337e-05\n",
      "Epoch 712/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 8.9565e-04 - val_loss: 6.2305e-05\n",
      "Epoch 713/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.9357e-04 - val_loss: 6.2268e-05\n",
      "Epoch 714/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 8.9149e-04 - val_loss: 6.2230e-05\n",
      "Epoch 715/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.8942e-04 - val_loss: 6.2198e-05\n",
      "Epoch 716/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.8735e-04 - val_loss: 6.2162e-05\n",
      "Epoch 717/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.8529e-04 - val_loss: 6.2124e-05\n",
      "Epoch 718/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 8.8322e-04 - val_loss: 6.2087e-05\n",
      "Epoch 719/1000\n",
      "32/32 [==============================] - 0s 133us/step - loss: 8.8117e-04 - val_loss: 6.2061e-05\n",
      "Epoch 720/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 8.7913e-04 - val_loss: 6.2019e-05\n",
      "Epoch 721/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 8.7708e-04 - val_loss: 6.1986e-05\n",
      "Epoch 722/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7506e-04 - val_loss: 6.1951e-05\n",
      "Epoch 723/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7303e-04 - val_loss: 6.1913e-05\n",
      "Epoch 724/1000\n",
      "32/32 [==============================] - 0s 120us/step - loss: 8.7099e-04 - val_loss: 6.1879e-05\n",
      "Epoch 725/1000\n",
      "32/32 [==============================] - 0s 162us/step - loss: 8.6899e-04 - val_loss: 6.1839e-05\n",
      "Epoch 726/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 8.6697e-04 - val_loss: 6.1806e-05\n",
      "Epoch 727/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.6495e-04 - val_loss: 6.1774e-05\n",
      "Epoch 728/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.6296e-04 - val_loss: 6.1737e-05\n",
      "Epoch 729/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 8.6096e-04 - val_loss: 6.1698e-05\n",
      "Epoch 730/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.5897e-04 - val_loss: 6.1658e-05\n",
      "Epoch 731/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5698e-04 - val_loss: 6.1634e-05\n",
      "Epoch 732/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5502e-04 - val_loss: 6.1592e-05\n",
      "Epoch 733/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5303e-04 - val_loss: 6.1566e-05\n",
      "Epoch 734/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 8.5105e-04 - val_loss: 6.1529e-05\n",
      "Epoch 735/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 8.4909e-04 - val_loss: 6.1486e-05\n",
      "Epoch 736/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.4713e-04 - val_loss: 6.1449e-05\n",
      "Epoch 737/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 8.4517e-04 - val_loss: 6.1417e-05\n",
      "Epoch 738/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.4323e-04 - val_loss: 6.1378e-05\n",
      "Epoch 739/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.4130e-04 - val_loss: 6.1341e-05\n",
      "Epoch 740/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 8.3936e-04 - val_loss: 6.1306e-05\n",
      "Epoch 741/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3743e-04 - val_loss: 6.1275e-05\n",
      "Epoch 742/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3550e-04 - val_loss: 6.1233e-05\n",
      "Epoch 743/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3358e-04 - val_loss: 6.1201e-05\n",
      "Epoch 744/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.3166e-04 - val_loss: 6.1162e-05\n",
      "Epoch 745/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2974e-04 - val_loss: 6.1126e-05\n",
      "Epoch 746/1000\n",
      "32/32 [==============================] - 0s 133us/step - loss: 8.2784e-04 - val_loss: 6.1094e-05\n",
      "Epoch 747/1000\n",
      "32/32 [==============================] - 0s 171us/step - loss: 8.2594e-04 - val_loss: 6.1063e-05\n",
      "Epoch 748/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2404e-04 - val_loss: 6.1021e-05\n",
      "Epoch 749/1000\n",
      "32/32 [==============================] - 0s 177us/step - loss: 8.2215e-04 - val_loss: 6.0988e-05\n",
      "Epoch 750/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2026e-04 - val_loss: 6.0953e-05\n",
      "Epoch 751/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.1840e-04 - val_loss: 6.0918e-05\n",
      "Epoch 752/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.1650e-04 - val_loss: 6.0883e-05\n",
      "Epoch 753/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 8.1463e-04 - val_loss: 6.0845e-05\n",
      "Epoch 754/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.1277e-04 - val_loss: 6.0809e-05\n",
      "Epoch 755/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 8.1092e-04 - val_loss: 6.0774e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 756/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0906e-04 - val_loss: 6.0743e-05\n",
      "Epoch 757/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0721e-04 - val_loss: 6.0703e-05\n",
      "Epoch 758/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0537e-04 - val_loss: 6.0666e-05\n",
      "Epoch 759/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0351e-04 - val_loss: 6.0626e-05\n",
      "Epoch 760/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0168e-04 - val_loss: 6.0590e-05\n",
      "Epoch 761/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.9985e-04 - val_loss: 6.0557e-05\n",
      "Epoch 762/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.9803e-04 - val_loss: 6.0530e-05\n",
      "Epoch 763/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9620e-04 - val_loss: 6.0485e-05\n",
      "Epoch 764/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.9440e-04 - val_loss: 6.0453e-05\n",
      "Epoch 765/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9256e-04 - val_loss: 6.0416e-05\n",
      "Epoch 766/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9076e-04 - val_loss: 6.0384e-05\n",
      "Epoch 767/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 7.8897e-04 - val_loss: 6.0344e-05\n",
      "Epoch 768/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8716e-04 - val_loss: 6.0308e-05\n",
      "Epoch 769/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 7.8538e-04 - val_loss: 6.0273e-05\n",
      "Epoch 770/1000\n",
      "32/32 [==============================] - 0s 177us/step - loss: 7.8359e-04 - val_loss: 6.0239e-05\n",
      "Epoch 771/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 7.8181e-04 - val_loss: 6.0204e-05\n",
      "Epoch 772/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.8002e-04 - val_loss: 6.0167e-05\n",
      "Epoch 773/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7826e-04 - val_loss: 6.0133e-05\n",
      "Epoch 774/1000\n",
      "32/32 [==============================] - 0s 129us/step - loss: 7.7648e-04 - val_loss: 6.0099e-05\n",
      "Epoch 775/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 7.7472e-04 - val_loss: 6.0057e-05\n",
      "Epoch 776/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.7296e-04 - val_loss: 6.0025e-05\n",
      "Epoch 777/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.7120e-04 - val_loss: 5.9988e-05\n",
      "Epoch 778/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6945e-04 - val_loss: 5.9952e-05\n",
      "Epoch 779/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.6770e-04 - val_loss: 5.9916e-05\n",
      "Epoch 780/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6596e-04 - val_loss: 5.9875e-05\n",
      "Epoch 781/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.6423e-04 - val_loss: 5.9844e-05\n",
      "Epoch 782/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6249e-04 - val_loss: 5.9807e-05\n",
      "Epoch 783/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6076e-04 - val_loss: 5.9771e-05\n",
      "Epoch 784/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5904e-04 - val_loss: 5.9738e-05\n",
      "Epoch 785/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5732e-04 - val_loss: 5.9702e-05\n",
      "Epoch 786/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5562e-04 - val_loss: 5.9667e-05\n",
      "Epoch 787/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5390e-04 - val_loss: 5.9633e-05\n",
      "Epoch 788/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.5219e-04 - val_loss: 5.9596e-05\n",
      "Epoch 789/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5049e-04 - val_loss: 5.9561e-05\n",
      "Epoch 790/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4880e-04 - val_loss: 5.9521e-05\n",
      "Epoch 791/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 7.4710e-04 - val_loss: 5.9483e-05\n",
      "Epoch 792/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 7.4540e-04 - val_loss: 5.9453e-05\n",
      "Epoch 793/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4373e-04 - val_loss: 5.9409e-05\n",
      "Epoch 794/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.4206e-04 - val_loss: 5.9376e-05\n",
      "Epoch 795/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 7.4038e-04 - val_loss: 5.9337e-05\n",
      "Epoch 796/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 7.3870e-04 - val_loss: 5.9306e-05\n",
      "Epoch 797/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.3705e-04 - val_loss: 5.9266e-05\n",
      "Epoch 798/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3538e-04 - val_loss: 5.9229e-05\n",
      "Epoch 799/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 7.3371e-04 - val_loss: 5.9192e-05\n",
      "Epoch 800/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 7.3207e-04 - val_loss: 5.9159e-05\n",
      "Epoch 801/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3042e-04 - val_loss: 5.9125e-05\n",
      "Epoch 802/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.2878e-04 - val_loss: 5.9088e-05\n",
      "Epoch 803/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2713e-04 - val_loss: 5.9053e-05\n",
      "Epoch 804/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2549e-04 - val_loss: 5.9020e-05\n",
      "Epoch 805/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 7.2386e-04 - val_loss: 5.8980e-05\n",
      "Epoch 806/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.2224e-04 - val_loss: 5.8943e-05\n",
      "Epoch 807/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.2062e-04 - val_loss: 5.8900e-05\n",
      "Epoch 808/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.1899e-04 - val_loss: 5.8875e-05\n",
      "Epoch 809/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 7.1738e-04 - val_loss: 5.8830e-05\n",
      "Epoch 810/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 7.1578e-04 - val_loss: 5.8795e-05\n",
      "Epoch 811/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 7.1416e-04 - val_loss: 5.8758e-05\n",
      "Epoch 812/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1257e-04 - val_loss: 5.8725e-05\n",
      "Epoch 813/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1096e-04 - val_loss: 5.8687e-05\n",
      "Epoch 814/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 7.0936e-04 - val_loss: 5.8650e-05\n",
      "Epoch 815/1000\n",
      "32/32 [==============================] - 0s 127us/step - loss: 7.0778e-04 - val_loss: 5.8618e-05\n",
      "Epoch 816/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.0619e-04 - val_loss: 5.8587e-05\n",
      "Epoch 817/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.0462e-04 - val_loss: 5.8543e-05\n",
      "Epoch 818/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 7.0303e-04 - val_loss: 5.8511e-05\n",
      "Epoch 819/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0146e-04 - val_loss: 5.8470e-05\n",
      "Epoch 820/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 6.9989e-04 - val_loss: 5.8432e-05\n",
      "Epoch 821/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9832e-04 - val_loss: 5.8394e-05\n",
      "Epoch 822/1000\n",
      "32/32 [==============================] - 0s 162us/step - loss: 6.9676e-04 - val_loss: 5.8356e-05\n",
      "Epoch 823/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 6.9521e-04 - val_loss: 5.8315e-05\n",
      "Epoch 824/1000\n",
      "32/32 [==============================] - 0s 145us/step - loss: 6.9365e-04 - val_loss: 5.8286e-05\n",
      "Epoch 825/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9209e-04 - val_loss: 5.8251e-05\n",
      "Epoch 826/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9054e-04 - val_loss: 5.8214e-05\n",
      "Epoch 827/1000\n",
      "32/32 [==============================] - 0s 138us/step - loss: 6.8900e-04 - val_loss: 5.8173e-05\n",
      "Epoch 828/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 6.8747e-04 - val_loss: 5.8138e-05\n",
      "Epoch 829/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.8594e-04 - val_loss: 5.8105e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 830/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8441e-04 - val_loss: 5.8071e-05\n",
      "Epoch 831/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8288e-04 - val_loss: 5.8029e-05\n",
      "Epoch 832/1000\n",
      "32/32 [==============================] - 0s 162us/step - loss: 6.8135e-04 - val_loss: 5.7993e-05\n",
      "Epoch 833/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7983e-04 - val_loss: 5.7956e-05\n",
      "Epoch 834/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 6.7832e-04 - val_loss: 5.7912e-05\n",
      "Epoch 835/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7681e-04 - val_loss: 5.7883e-05\n",
      "Epoch 836/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7530e-04 - val_loss: 5.7841e-05\n",
      "Epoch 837/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.7380e-04 - val_loss: 5.7799e-05\n",
      "Epoch 838/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 6.7229e-04 - val_loss: 5.7768e-05\n",
      "Epoch 839/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.7080e-04 - val_loss: 5.7731e-05\n",
      "Epoch 840/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6931e-04 - val_loss: 5.7693e-05\n",
      "Epoch 841/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.6782e-04 - val_loss: 5.7650e-05\n",
      "Epoch 842/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6634e-04 - val_loss: 5.7619e-05\n",
      "Epoch 843/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 6.6486e-04 - val_loss: 5.7576e-05\n",
      "Epoch 844/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.6338e-04 - val_loss: 5.7546e-05\n",
      "Epoch 845/1000\n",
      "32/32 [==============================] - 0s 137us/step - loss: 6.6191e-04 - val_loss: 5.7509e-05\n",
      "Epoch 846/1000\n",
      "32/32 [==============================] - 0s 120us/step - loss: 6.6043e-04 - val_loss: 5.7475e-05\n",
      "Epoch 847/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.5897e-04 - val_loss: 5.7432e-05\n",
      "Epoch 848/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.5750e-04 - val_loss: 5.7404e-05\n",
      "Epoch 849/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.5605e-04 - val_loss: 5.7355e-05\n",
      "Epoch 850/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5459e-04 - val_loss: 5.7319e-05\n",
      "Epoch 851/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5314e-04 - val_loss: 5.7282e-05\n",
      "Epoch 852/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 6.5169e-04 - val_loss: 5.7245e-05\n",
      "Epoch 853/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5024e-04 - val_loss: 5.7210e-05\n",
      "Epoch 854/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4881e-04 - val_loss: 5.7176e-05\n",
      "Epoch 855/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 6.4736e-04 - val_loss: 5.7135e-05\n",
      "Epoch 856/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.4593e-04 - val_loss: 5.7098e-05\n",
      "Epoch 857/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4451e-04 - val_loss: 5.7064e-05\n",
      "Epoch 858/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4308e-04 - val_loss: 5.7032e-05\n",
      "Epoch 859/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 6.4165e-04 - val_loss: 5.6989e-05\n",
      "Epoch 860/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4023e-04 - val_loss: 5.6946e-05\n",
      "Epoch 861/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 6.3882e-04 - val_loss: 5.6906e-05\n",
      "Epoch 862/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 6.3741e-04 - val_loss: 5.6867e-05\n",
      "Epoch 863/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3600e-04 - val_loss: 5.6834e-05\n",
      "Epoch 864/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.3460e-04 - val_loss: 5.6797e-05\n",
      "Epoch 865/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3319e-04 - val_loss: 5.6761e-05\n",
      "Epoch 866/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3179e-04 - val_loss: 5.6719e-05\n",
      "Epoch 867/1000\n",
      "32/32 [==============================] - 0s 161us/step - loss: 6.3040e-04 - val_loss: 5.6691e-05\n",
      "Epoch 868/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2900e-04 - val_loss: 5.6648e-05\n",
      "Epoch 869/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2762e-04 - val_loss: 5.6612e-05\n",
      "Epoch 870/1000\n",
      "32/32 [==============================] - 0s 165us/step - loss: 6.2623e-04 - val_loss: 5.6572e-05\n",
      "Epoch 871/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2485e-04 - val_loss: 5.6535e-05\n",
      "Epoch 872/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.2347e-04 - val_loss: 5.6505e-05\n",
      "Epoch 873/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2211e-04 - val_loss: 5.6461e-05\n",
      "Epoch 874/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2073e-04 - val_loss: 5.6422e-05\n",
      "Epoch 875/1000\n",
      "32/32 [==============================] - 0s 163us/step - loss: 6.1937e-04 - val_loss: 5.6386e-05\n",
      "Epoch 876/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 6.1801e-04 - val_loss: 5.6353e-05\n",
      "Epoch 877/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 6.1663e-04 - val_loss: 5.6309e-05\n",
      "Epoch 878/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.1528e-04 - val_loss: 5.6274e-05\n",
      "Epoch 879/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 6.1393e-04 - val_loss: 5.6232e-05\n",
      "Epoch 880/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1257e-04 - val_loss: 5.6193e-05\n",
      "Epoch 881/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1124e-04 - val_loss: 5.6163e-05\n",
      "Epoch 882/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0988e-04 - val_loss: 5.6121e-05\n",
      "Epoch 883/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 6.0854e-04 - val_loss: 5.6079e-05\n",
      "Epoch 884/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0721e-04 - val_loss: 5.6047e-05\n",
      "Epoch 885/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 6.0588e-04 - val_loss: 5.6004e-05\n",
      "Epoch 886/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 6.0455e-04 - val_loss: 5.5967e-05\n",
      "Epoch 887/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.0321e-04 - val_loss: 5.5931e-05\n",
      "Epoch 888/1000\n",
      "32/32 [==============================] - 0s 133us/step - loss: 6.0189e-04 - val_loss: 5.5896e-05\n",
      "Epoch 889/1000\n",
      "32/32 [==============================] - 0s 129us/step - loss: 6.0058e-04 - val_loss: 5.5859e-05\n",
      "Epoch 890/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9925e-04 - val_loss: 5.5819e-05\n",
      "Epoch 891/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9795e-04 - val_loss: 5.5782e-05\n",
      "Epoch 892/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 5.9662e-04 - val_loss: 5.5742e-05\n",
      "Epoch 893/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 5.9533e-04 - val_loss: 5.5705e-05\n",
      "Epoch 894/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9402e-04 - val_loss: 5.5671e-05\n",
      "Epoch 895/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9272e-04 - val_loss: 5.5630e-05\n",
      "Epoch 896/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9142e-04 - val_loss: 5.5597e-05\n",
      "Epoch 897/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9012e-04 - val_loss: 5.5551e-05\n",
      "Epoch 898/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 5.8883e-04 - val_loss: 5.5520e-05\n",
      "Epoch 899/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 5.8754e-04 - val_loss: 5.5473e-05\n",
      "Epoch 900/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8626e-04 - val_loss: 5.5438e-05\n",
      "Epoch 901/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.8498e-04 - val_loss: 5.5399e-05\n",
      "Epoch 902/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8369e-04 - val_loss: 5.5356e-05\n",
      "Epoch 903/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8242e-04 - val_loss: 5.5319e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 904/1000\n",
      "32/32 [==============================] - 0s 145us/step - loss: 5.8114e-04 - val_loss: 5.5276e-05\n",
      "Epoch 905/1000\n",
      "32/32 [==============================] - 0s 122us/step - loss: 5.7987e-04 - val_loss: 5.5243e-05\n",
      "Epoch 906/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 5.7860e-04 - val_loss: 5.5205e-05\n",
      "Epoch 907/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.7735e-04 - val_loss: 5.5168e-05\n",
      "Epoch 908/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.7608e-04 - val_loss: 5.5128e-05\n",
      "Epoch 909/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7482e-04 - val_loss: 5.5093e-05\n",
      "Epoch 910/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 5.7357e-04 - val_loss: 5.5061e-05\n",
      "Epoch 911/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7232e-04 - val_loss: 5.5020e-05\n",
      "Epoch 912/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 5.7107e-04 - val_loss: 5.4981e-05\n",
      "Epoch 913/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 5.6983e-04 - val_loss: 5.4943e-05\n",
      "Epoch 914/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6859e-04 - val_loss: 5.4902e-05\n",
      "Epoch 915/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 5.6734e-04 - val_loss: 5.4862e-05\n",
      "Epoch 916/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6611e-04 - val_loss: 5.4819e-05\n",
      "Epoch 917/1000\n",
      "32/32 [==============================] - 0s 172us/step - loss: 5.6488e-04 - val_loss: 5.4786e-05\n",
      "Epoch 918/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6364e-04 - val_loss: 5.4751e-05\n",
      "Epoch 919/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6242e-04 - val_loss: 5.4714e-05\n",
      "Epoch 920/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.6119e-04 - val_loss: 5.4665e-05\n",
      "Epoch 921/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.5997e-04 - val_loss: 5.4633e-05\n",
      "Epoch 922/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5876e-04 - val_loss: 5.4590e-05\n",
      "Epoch 923/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5754e-04 - val_loss: 5.4558e-05\n",
      "Epoch 924/1000\n",
      "32/32 [==============================] - 0s 145us/step - loss: 5.5631e-04 - val_loss: 5.4511e-05\n",
      "Epoch 925/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 5.5511e-04 - val_loss: 5.4484e-05\n",
      "Epoch 926/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.5391e-04 - val_loss: 5.4443e-05\n",
      "Epoch 927/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5270e-04 - val_loss: 5.4405e-05\n",
      "Epoch 928/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5150e-04 - val_loss: 5.4363e-05\n",
      "Epoch 929/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 5.5030e-04 - val_loss: 5.4323e-05\n",
      "Epoch 930/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4910e-04 - val_loss: 5.4290e-05\n",
      "Epoch 931/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4792e-04 - val_loss: 5.4246e-05\n",
      "Epoch 932/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4672e-04 - val_loss: 5.4213e-05\n",
      "Epoch 933/1000\n",
      "32/32 [==============================] - 0s 168us/step - loss: 5.4554e-04 - val_loss: 5.4173e-05\n",
      "Epoch 934/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.4436e-04 - val_loss: 5.4133e-05\n",
      "Epoch 935/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4318e-04 - val_loss: 5.4092e-05\n",
      "Epoch 936/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4200e-04 - val_loss: 5.4058e-05\n",
      "Epoch 937/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4083e-04 - val_loss: 5.4017e-05\n",
      "Epoch 938/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.3965e-04 - val_loss: 5.3977e-05\n",
      "Epoch 939/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 5.3848e-04 - val_loss: 5.3942e-05\n",
      "Epoch 940/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3731e-04 - val_loss: 5.3905e-05\n",
      "Epoch 941/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3615e-04 - val_loss: 5.3864e-05\n",
      "Epoch 942/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 5.3498e-04 - val_loss: 5.3823e-05\n",
      "Epoch 943/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.3383e-04 - val_loss: 5.3781e-05\n",
      "Epoch 944/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 5.3267e-04 - val_loss: 5.3746e-05\n",
      "Epoch 945/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.3152e-04 - val_loss: 5.3711e-05\n",
      "Epoch 946/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 5.3037e-04 - val_loss: 5.3679e-05\n",
      "Epoch 947/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 5.2922e-04 - val_loss: 5.3629e-05\n",
      "Epoch 948/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2807e-04 - val_loss: 5.3594e-05\n",
      "Epoch 949/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.2693e-04 - val_loss: 5.3558e-05\n",
      "Epoch 950/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.2579e-04 - val_loss: 5.3523e-05\n",
      "Epoch 951/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.2467e-04 - val_loss: 5.3483e-05\n",
      "Epoch 952/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2352e-04 - val_loss: 5.3449e-05\n",
      "Epoch 953/1000\n",
      "32/32 [==============================] - 0s 131us/step - loss: 5.2239e-04 - val_loss: 5.3403e-05\n",
      "Epoch 954/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2126e-04 - val_loss: 5.3361e-05\n",
      "Epoch 955/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2014e-04 - val_loss: 5.3325e-05\n",
      "Epoch 956/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1902e-04 - val_loss: 5.3289e-05\n",
      "Epoch 957/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1790e-04 - val_loss: 5.3241e-05\n",
      "Epoch 958/1000\n",
      "32/32 [==============================] - 0s 145us/step - loss: 5.1678e-04 - val_loss: 5.3209e-05\n",
      "Epoch 959/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 5.1566e-04 - val_loss: 5.3166e-05\n",
      "Epoch 960/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.1455e-04 - val_loss: 5.3126e-05\n",
      "Epoch 961/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1344e-04 - val_loss: 5.3097e-05\n",
      "Epoch 962/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 5.1233e-04 - val_loss: 5.3058e-05\n",
      "Epoch 963/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.1122e-04 - val_loss: 5.3018e-05\n",
      "Epoch 964/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1013e-04 - val_loss: 5.2975e-05\n",
      "Epoch 965/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 5.0903e-04 - val_loss: 5.2945e-05\n",
      "Epoch 966/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 5.0793e-04 - val_loss: 5.2904e-05\n",
      "Epoch 967/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0684e-04 - val_loss: 5.2866e-05\n",
      "Epoch 968/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0574e-04 - val_loss: 5.2822e-05\n",
      "Epoch 969/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0466e-04 - val_loss: 5.2789e-05\n",
      "Epoch 970/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 5.0357e-04 - val_loss: 5.2750e-05\n",
      "Epoch 971/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0249e-04 - val_loss: 5.2707e-05\n",
      "Epoch 972/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.0141e-04 - val_loss: 5.2669e-05\n",
      "Epoch 973/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.0033e-04 - val_loss: 5.2627e-05\n",
      "Epoch 974/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.9925e-04 - val_loss: 5.2595e-05\n",
      "Epoch 975/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9817e-04 - val_loss: 5.2553e-05\n",
      "Epoch 976/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9711e-04 - val_loss: 5.2512e-05\n",
      "Epoch 977/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9604e-04 - val_loss: 5.2474e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 978/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9497e-04 - val_loss: 5.2437e-05\n",
      "Epoch 979/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.9391e-04 - val_loss: 5.2397e-05\n",
      "Epoch 980/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.9284e-04 - val_loss: 5.2360e-05\n",
      "Epoch 981/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9179e-04 - val_loss: 5.2324e-05\n",
      "Epoch 982/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9073e-04 - val_loss: 5.2285e-05\n",
      "Epoch 983/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.8968e-04 - val_loss: 5.2246e-05\n",
      "Epoch 984/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.8863e-04 - val_loss: 5.2206e-05\n",
      "Epoch 985/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.8758e-04 - val_loss: 5.2173e-05\n",
      "Epoch 986/1000\n",
      "32/32 [==============================] - 0s 109us/step - loss: 4.8653e-04 - val_loss: 5.2130e-05\n",
      "Epoch 987/1000\n",
      "32/32 [==============================] - 0s 145us/step - loss: 4.8549e-04 - val_loss: 5.2089e-05\n",
      "Epoch 988/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8445e-04 - val_loss: 5.2050e-05\n",
      "Epoch 989/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.8342e-04 - val_loss: 5.2017e-05\n",
      "Epoch 990/1000\n",
      "32/32 [==============================] - 0s 133us/step - loss: 4.8237e-04 - val_loss: 5.1977e-05\n",
      "Epoch 991/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8132e-04 - val_loss: 5.1934e-05\n",
      "Epoch 992/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.8031e-04 - val_loss: 5.1897e-05\n",
      "Epoch 993/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.7928e-04 - val_loss: 5.1851e-05\n",
      "Epoch 994/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.7826e-04 - val_loss: 5.1814e-05\n",
      "Epoch 995/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7723e-04 - val_loss: 5.1777e-05\n",
      "Epoch 996/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7622e-04 - val_loss: 5.1738e-05\n",
      "Epoch 997/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7520e-04 - val_loss: 5.1697e-05\n",
      "Epoch 998/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.7417e-04 - val_loss: 5.1661e-05\n",
      "Epoch 999/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 4.7316e-04 - val_loss: 5.1622e-05\n",
      "Epoch 1000/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7214e-04 - val_loss: 5.1587e-05\n",
      "8.804472599877045e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.55753225, -0.50120103, -0.7822824 , -0.8092235 , -0.09821057],\n",
       "        [-0.04113822,  0.52122784,  0.35070112,  0.29268846,  1.1040753 ],\n",
       "        [-0.7114781 ,  0.63289607,  0.9380625 , -0.1647588 , -0.24742268]],\n",
       "       dtype=float32),\n",
       " array([-0.5337758 , -0.35636297, -0.3303343 ,  0.4020515 ,  0.48349905],\n",
       "       dtype=float32),\n",
       " array([[-4.23586369e-01, -2.01272532e-01, -2.85033286e-01,\n",
       "          1.62009835e-01,  5.31608760e-01,  1.01405382e-01,\n",
       "          6.28967524e-01,  1.24211974e-01,  1.55125871e-01,\n",
       "         -8.08865800e-02, -4.72020686e-01, -5.71879983e-01,\n",
       "         -7.61063844e-02, -1.42382517e-01,  4.21174496e-01],\n",
       "        [-2.12677032e-01,  4.92719322e-01,  5.63167810e-01,\n",
       "          4.49750274e-01,  2.35654294e-01,  6.74845725e-02,\n",
       "          4.85402554e-01,  4.14017886e-01, -1.65185258e-01,\n",
       "         -3.83823067e-01,  1.58777798e-03,  3.81127656e-01,\n",
       "         -8.92196238e-01, -1.73687078e-02,  1.00223444e-01],\n",
       "        [-2.87828654e-01, -3.38524692e-02,  3.23549628e-01,\n",
       "          5.04050143e-02, -3.87553759e-02,  1.11388095e-01,\n",
       "          2.38042139e-02,  5.52053936e-02,  6.38423488e-02,\n",
       "          2.95220792e-01, -3.92081529e-01, -5.45949936e-01,\n",
       "         -4.95732188e-01,  7.18537271e-02,  3.03023815e-01],\n",
       "        [-6.12284541e-02, -1.36488095e-01, -8.54162648e-02,\n",
       "         -1.63979471e-01, -7.46569097e-01, -2.51590997e-01,\n",
       "          7.07834139e-02, -3.58801246e-01, -4.62938488e-01,\n",
       "         -5.36292605e-03, -1.74818411e-02,  3.02412897e-01,\n",
       "         -7.26787895e-02,  7.83855096e-02, -6.52310133e-01],\n",
       "        [ 1.48646638e-01, -2.21805736e-01, -5.85072041e-01,\n",
       "         -6.31645024e-02, -2.38587603e-01, -2.35822156e-01,\n",
       "          2.07582220e-01, -5.30822948e-02, -1.64467260e-01,\n",
       "          4.84700114e-01,  3.59608531e-02,  1.90829802e-02,\n",
       "         -2.86699444e-01,  6.38604804e-04,  2.61041492e-01]], dtype=float32),\n",
       " array([ 0.6495524 , -0.6723668 ,  0.35459244, -0.6010181 , -0.7222908 ,\n",
       "        -0.51747054, -0.64209205, -0.56762993, -0.7074669 , -0.5794426 ,\n",
       "         0.6457893 ,  0.54254603, -0.24554048, -0.48095497, -0.68908155],\n",
       "       dtype=float32),\n",
       " array([[ 0.46700656],\n",
       "        [-0.47826096],\n",
       "        [ 0.14829493],\n",
       "        [-0.35622463],\n",
       "        [-0.8438179 ],\n",
       "        [-0.24411169],\n",
       "        [-0.4777406 ],\n",
       "        [-0.31918955],\n",
       "        [-0.71581626],\n",
       "        [-0.29786643],\n",
       "        [ 0.47149247],\n",
       "        [ 0.33327237],\n",
       "        [-0.02495232],\n",
       "        [-0.17667153],\n",
       "        [-0.65355587]], dtype=float32),\n",
       " array([0.78648245], dtype=float32)]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_challenger, history_challenger, evaluate_challenger=NN_model_structure_regression_3(X_train_challenger, X_val_challenger, Y_train_challenger, Y_val_challenger, adam2, 32, 1000, x_test_challenger, y_test_challenger)\n",
    "model_challenger.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_challenger.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_challenger_structure3_4th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_64 (Dense)             (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 101\n",
      "Trainable params: 101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 32 samples, validate on 7 samples\n",
      "Epoch 1/1000\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 36.1551 - val_loss: 36.2361\n",
      "Epoch 2/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.8116 - val_loss: 34.1464\n",
      "Epoch 3/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 32.8312 - val_loss: 30.8357\n",
      "Epoch 4/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 29.8288 - val_loss: 26.0336\n",
      "Epoch 5/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 25.5594 - val_loss: 19.7152\n",
      "Epoch 6/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 20.0078 - val_loss: 12.5888\n",
      "Epoch 7/1000\n",
      "32/32 [==============================] - 0s 128us/step - loss: 13.5230 - val_loss: 5.9557\n",
      "Epoch 8/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 6.8752 - val_loss: 1.4214\n",
      "Epoch 9/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8165 - val_loss: 1.2003\n",
      "Epoch 10/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.9088 - val_loss: 4.9184\n",
      "Epoch 11/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.4529 - val_loss: 6.9351\n",
      "Epoch 12/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.7366 - val_loss: 6.1248\n",
      "Epoch 13/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8788 - val_loss: 4.2985\n",
      "Epoch 14/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 3.9228 - val_loss: 2.3902\n",
      "Epoch 15/1000\n",
      "32/32 [==============================] - 0s 133us/step - loss: 2.0792 - val_loss: 1.0407\n",
      "Epoch 16/1000\n",
      "32/32 [==============================] - 0s 130us/step - loss: 0.9287 - val_loss: 0.4691\n",
      "Epoch 17/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 0.6317 - val_loss: 0.4904\n",
      "Epoch 18/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.9744 - val_loss: 0.7760\n",
      "Epoch 19/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5547 - val_loss: 1.0538\n",
      "Epoch 20/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0188 - val_loss: 1.1852\n",
      "Epoch 21/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.1969 - val_loss: 1.1486\n",
      "Epoch 22/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0911 - val_loss: 0.9876\n",
      "Epoch 23/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 1.7929 - val_loss: 0.7658\n",
      "Epoch 24/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 1.4086 - val_loss: 0.5417\n",
      "Epoch 25/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.0223 - val_loss: 0.3594\n",
      "Epoch 26/1000\n",
      "32/32 [==============================] - 0s 167us/step - loss: 0.6878 - val_loss: 0.2456\n",
      "Epoch 27/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.4346 - val_loss: 0.2116\n",
      "Epoch 28/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.2789 - val_loss: 0.2568\n",
      "Epoch 29/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.2296 - val_loss: 0.3672\n",
      "Epoch 30/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.2806 - val_loss: 0.5106\n",
      "Epoch 31/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.3955 - val_loss: 0.6388\n",
      "Epoch 32/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.5102 - val_loss: 0.7049\n",
      "Epoch 33/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.5623 - val_loss: 0.6878\n",
      "Epoch 34/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.5269 - val_loss: 0.5990\n",
      "Epoch 35/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.4233 - val_loss: 0.4719\n",
      "Epoch 36/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.2953 - val_loss: 0.3431\n",
      "Epoch 37/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.1843 - val_loss: 0.2396\n",
      "Epoch 38/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1141 - val_loss: 0.1740\n",
      "Epoch 39/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0884 - val_loss: 0.1458\n",
      "Epoch 40/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0969 - val_loss: 0.1464\n",
      "Epoch 41/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.1243 - val_loss: 0.1639\n",
      "Epoch 42/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1559 - val_loss: 0.1862\n",
      "Epoch 43/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1813 - val_loss: 0.2036\n",
      "Epoch 44/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1943 - val_loss: 0.2095\n",
      "Epoch 45/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1926 - val_loss: 0.2012\n",
      "Epoch 46/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1769 - val_loss: 0.1798\n",
      "Epoch 47/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1505 - val_loss: 0.1496\n",
      "Epoch 48/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1187 - val_loss: 0.1169\n",
      "Epoch 49/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0877 - val_loss: 0.0883\n",
      "Epoch 50/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 0.0631 - val_loss: 0.0690\n",
      "Epoch 51/1000\n",
      "32/32 [==============================] - 0s 167us/step - loss: 0.0487 - val_loss: 0.0608\n",
      "Epoch 52/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0453 - val_loss: 0.0626\n",
      "Epoch 53/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 0.0506 - val_loss: 0.0702\n",
      "Epoch 54/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0603 - val_loss: 0.0788\n",
      "Epoch 55/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 0.0698 - val_loss: 0.0841\n",
      "Epoch 56/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0754 - val_loss: 0.0839\n",
      "Epoch 57/1000\n",
      "32/32 [==============================] - 0s 161us/step - loss: 0.0755 - val_loss: 0.0781\n",
      "Epoch 58/1000\n",
      "32/32 [==============================] - 0s 172us/step - loss: 0.0704 - val_loss: 0.0686\n",
      "Epoch 59/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0620 - val_loss: 0.0575\n",
      "Epoch 60/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0524 - val_loss: 0.0473\n",
      "Epoch 61/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0437 - val_loss: 0.0392\n",
      "Epoch 62/1000\n",
      "32/32 [==============================] - 0s 172us/step - loss: 0.0372 - val_loss: 0.0337\n",
      "Epoch 63/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0335 - val_loss: 0.0306\n",
      "Epoch 64/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 0.0323 - val_loss: 0.0291\n",
      "Epoch 65/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0332 - val_loss: 0.0286\n",
      "Epoch 66/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0350 - val_loss: 0.0284\n",
      "Epoch 67/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0370 - val_loss: 0.0279\n",
      "Epoch 68/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0382 - val_loss: 0.0270\n",
      "Epoch 69/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0381 - val_loss: 0.0258\n",
      "Epoch 70/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0367 - val_loss: 0.0246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0342 - val_loss: 0.0235\n",
      "Epoch 72/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0311 - val_loss: 0.0230\n",
      "Epoch 73/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0280 - val_loss: 0.0231\n",
      "Epoch 74/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0255 - val_loss: 0.0238\n",
      "Epoch 75/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0239 - val_loss: 0.0249\n",
      "Epoch 76/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0231 - val_loss: 0.0263\n",
      "Epoch 77/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 0.0230 - val_loss: 0.0276\n",
      "Epoch 78/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0232 - val_loss: 0.0285\n",
      "Epoch 79/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0234 - val_loss: 0.0288\n",
      "Epoch 80/1000\n",
      "32/32 [==============================] - 0s 164us/step - loss: 0.0234 - val_loss: 0.0285\n",
      "Epoch 81/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0231 - val_loss: 0.0276\n",
      "Epoch 82/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0225 - val_loss: 0.0262\n",
      "Epoch 83/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0216 - val_loss: 0.0246\n",
      "Epoch 84/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0205 - val_loss: 0.0230\n",
      "Epoch 85/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0194 - val_loss: 0.0215\n",
      "Epoch 86/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0184 - val_loss: 0.0204\n",
      "Epoch 87/1000\n",
      "32/32 [==============================] - 0s 166us/step - loss: 0.0176 - val_loss: 0.0195\n",
      "Epoch 88/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 0.0171 - val_loss: 0.0190\n",
      "Epoch 89/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0168 - val_loss: 0.0186\n",
      "Epoch 90/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0166 - val_loss: 0.0183\n",
      "Epoch 91/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0164 - val_loss: 0.0180\n",
      "Epoch 92/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 0.0162 - val_loss: 0.0175\n",
      "Epoch 93/1000\n",
      "32/32 [==============================] - 0s 137us/step - loss: 0.0159 - val_loss: 0.0170\n",
      "Epoch 94/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0155 - val_loss: 0.0164\n",
      "Epoch 95/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0150 - val_loss: 0.0158\n",
      "Epoch 96/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 0.0145 - val_loss: 0.0153\n",
      "Epoch 97/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0140 - val_loss: 0.0150\n",
      "Epoch 98/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0135 - val_loss: 0.0148\n",
      "Epoch 99/1000\n",
      "32/32 [==============================] - 0s 162us/step - loss: 0.0131 - val_loss: 0.0147\n",
      "Epoch 100/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0127 - val_loss: 0.0147\n",
      "Epoch 101/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0124 - val_loss: 0.0148\n",
      "Epoch 102/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0122 - val_loss: 0.0148\n",
      "Epoch 103/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0119 - val_loss: 0.0148\n",
      "Epoch 104/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0117 - val_loss: 0.0147\n",
      "Epoch 105/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 0.0115 - val_loss: 0.0145\n",
      "Epoch 106/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 0.0112 - val_loss: 0.0142\n",
      "Epoch 107/1000\n",
      "32/32 [==============================] - 0s 131us/step - loss: 0.0109 - val_loss: 0.0138\n",
      "Epoch 108/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0106 - val_loss: 0.0133\n",
      "Epoch 109/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0103 - val_loss: 0.0128\n",
      "Epoch 110/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0100 - val_loss: 0.0122\n",
      "Epoch 111/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 0.0097 - val_loss: 0.0118\n",
      "Epoch 112/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 0.0095 - val_loss: 0.0114\n",
      "Epoch 113/1000\n",
      "32/32 [==============================] - 0s 178us/step - loss: 0.0093 - val_loss: 0.0110\n",
      "Epoch 114/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0091 - val_loss: 0.0108\n",
      "Epoch 115/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 0.0089 - val_loss: 0.0106\n",
      "Epoch 116/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0087 - val_loss: 0.0104\n",
      "Epoch 117/1000\n",
      "32/32 [==============================] - 0s 129us/step - loss: 0.0085 - val_loss: 0.0103\n",
      "Epoch 118/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 0.0084 - val_loss: 0.0103\n",
      "Epoch 119/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0082 - val_loss: 0.0102\n",
      "Epoch 120/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0080 - val_loss: 0.0102\n",
      "Epoch 121/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0078 - val_loss: 0.0102\n",
      "Epoch 122/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 123/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 124/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0073 - val_loss: 0.0101\n",
      "Epoch 125/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 0.0071 - val_loss: 0.0100\n",
      "Epoch 126/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0070 - val_loss: 0.0099\n",
      "Epoch 127/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0068 - val_loss: 0.0098\n",
      "Epoch 128/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0067 - val_loss: 0.0097\n",
      "Epoch 129/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 0.0065 - val_loss: 0.0096\n",
      "Epoch 130/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0064 - val_loss: 0.0094\n",
      "Epoch 131/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0063 - val_loss: 0.0092\n",
      "Epoch 132/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 0.0061 - val_loss: 0.0091\n",
      "Epoch 133/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0060 - val_loss: 0.0089\n",
      "Epoch 134/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0059 - val_loss: 0.0087\n",
      "Epoch 135/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0058 - val_loss: 0.0085\n",
      "Epoch 136/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0057 - val_loss: 0.0084\n",
      "Epoch 137/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0055 - val_loss: 0.0082\n",
      "Epoch 138/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0054 - val_loss: 0.0080\n",
      "Epoch 139/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0053 - val_loss: 0.0079\n",
      "Epoch 140/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0052 - val_loss: 0.0077\n",
      "Epoch 141/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0051 - val_loss: 0.0076\n",
      "Epoch 142/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0050 - val_loss: 0.0075\n",
      "Epoch 143/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0049 - val_loss: 0.0074\n",
      "Epoch 144/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0048 - val_loss: 0.0073\n",
      "Epoch 145/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0047 - val_loss: 0.0072\n",
      "Epoch 146/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0047 - val_loss: 0.0071\n",
      "Epoch 147/1000\n",
      "32/32 [==============================] - 0s 193us/step - loss: 0.0046 - val_loss: 0.0071\n",
      "Epoch 148/1000\n",
      "32/32 [==============================] - 0s 168us/step - loss: 0.0045 - val_loss: 0.0070\n",
      "Epoch 149/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0044 - val_loss: 0.0069\n",
      "Epoch 150/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 158us/step - loss: 0.0043 - val_loss: 0.0068\n",
      "Epoch 151/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0042 - val_loss: 0.0067\n",
      "Epoch 152/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0042 - val_loss: 0.0066\n",
      "Epoch 153/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 0.0041 - val_loss: 0.0065\n",
      "Epoch 154/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 0.0040 - val_loss: 0.0063\n",
      "Epoch 155/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0039 - val_loss: 0.0062\n",
      "Epoch 156/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0039 - val_loss: 0.0061\n",
      "Epoch 157/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 0.0038 - val_loss: 0.0060\n",
      "Epoch 158/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0037 - val_loss: 0.0059\n",
      "Epoch 159/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0037 - val_loss: 0.0058\n",
      "Epoch 160/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 0.0036 - val_loss: 0.0056\n",
      "Epoch 161/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 0.0035 - val_loss: 0.0055\n",
      "Epoch 162/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 0.0035 - val_loss: 0.0055\n",
      "Epoch 163/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 0.0034 - val_loss: 0.0054\n",
      "Epoch 164/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 0.0053\n",
      "Epoch 165/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 0.0033 - val_loss: 0.0052\n",
      "Epoch 166/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0032 - val_loss: 0.0051\n",
      "Epoch 167/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 0.0032 - val_loss: 0.0050\n",
      "Epoch 168/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0031 - val_loss: 0.0050\n",
      "Epoch 169/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 0.0031 - val_loss: 0.0049\n",
      "Epoch 170/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 0.0048\n",
      "Epoch 171/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0030 - val_loss: 0.0047\n",
      "Epoch 172/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0029 - val_loss: 0.0047\n",
      "Epoch 173/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 0.0029 - val_loss: 0.0046\n",
      "Epoch 174/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 0.0045\n",
      "Epoch 175/1000\n",
      "32/32 [==============================] - 0s 179us/step - loss: 0.0028 - val_loss: 0.0044\n",
      "Epoch 176/1000\n",
      "32/32 [==============================] - 0s 129us/step - loss: 0.0027 - val_loss: 0.0044\n",
      "Epoch 177/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 0.0027 - val_loss: 0.0043\n",
      "Epoch 178/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 0.0042\n",
      "Epoch 179/1000\n",
      "32/32 [==============================] - 0s 131us/step - loss: 0.0026 - val_loss: 0.0041\n",
      "Epoch 180/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 0.0041\n",
      "Epoch 181/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 0.0040\n",
      "Epoch 182/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0025 - val_loss: 0.0039\n",
      "Epoch 183/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.0038\n",
      "Epoch 184/1000\n",
      "32/32 [==============================] - 0s 132us/step - loss: 0.0024 - val_loss: 0.0038\n",
      "Epoch 185/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 186/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 0.0023 - val_loss: 0.0036\n",
      "Epoch 187/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0023 - val_loss: 0.0036\n",
      "Epoch 188/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.0035\n",
      "Epoch 189/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0035\n",
      "Epoch 190/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 0.0022 - val_loss: 0.0034\n",
      "Epoch 191/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 0.0033\n",
      "Epoch 192/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 0.0033\n",
      "Epoch 193/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0032\n",
      "Epoch 194/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0032\n",
      "Epoch 195/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0031\n",
      "Epoch 196/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0020 - val_loss: 0.0031\n",
      "Epoch 197/1000\n",
      "32/32 [==============================] - 0s 177us/step - loss: 0.0020 - val_loss: 0.0030\n",
      "Epoch 198/1000\n",
      "32/32 [==============================] - 0s 137us/step - loss: 0.0019 - val_loss: 0.0030\n",
      "Epoch 199/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 200/1000\n",
      "32/32 [==============================] - 0s 131us/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 201/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 202/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0027\n",
      "Epoch 203/1000\n",
      "32/32 [==============================] - 0s 133us/step - loss: 0.0018 - val_loss: 0.0027\n",
      "Epoch 204/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0026\n",
      "Epoch 205/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0018 - val_loss: 0.0026\n",
      "Epoch 206/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0026\n",
      "Epoch 207/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0017 - val_loss: 0.0025\n",
      "Epoch 208/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0017 - val_loss: 0.0025\n",
      "Epoch 209/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 210/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0024\n",
      "Epoch 211/1000\n",
      "32/32 [==============================] - 0s 162us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 212/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 213/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 214/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 215/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 216/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 217/1000\n",
      "32/32 [==============================] - 0s 133us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 218/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 219/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 220/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 221/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 222/1000\n",
      "32/32 [==============================] - 0s 158us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 223/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 224/1000\n",
      "32/32 [==============================] - 0s 138us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 225/1000\n",
      "32/32 [==============================] - 0s 137us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 226/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 227/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 228/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 230/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 231/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 232/1000\n",
      "32/32 [==============================] - 0s 132us/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 233/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 234/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 235/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 236/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 237/1000\n",
      "32/32 [==============================] - 0s 129us/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 238/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 239/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 240/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 241/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 242/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 243/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 244/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 245/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 246/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 247/1000\n",
      "32/32 [==============================] - 0s 174us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 248/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 249/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 250/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 251/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 252/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 253/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 254/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 255/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.9933e-04 - val_loss: 0.0011\n",
      "Epoch 256/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.9077e-04 - val_loss: 0.0011\n",
      "Epoch 257/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.8237e-04 - val_loss: 0.0011\n",
      "Epoch 258/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.7414e-04 - val_loss: 0.0011\n",
      "Epoch 259/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6607e-04 - val_loss: 0.0011\n",
      "Epoch 260/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.5816e-04 - val_loss: 0.0010\n",
      "Epoch 261/1000\n",
      "32/32 [==============================] - 0s 160us/step - loss: 9.5041e-04 - val_loss: 0.0010\n",
      "Epoch 262/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.4281e-04 - val_loss: 0.0010\n",
      "Epoch 263/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.3536e-04 - val_loss: 0.0010\n",
      "Epoch 264/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.2805e-04 - val_loss: 9.8957e-04\n",
      "Epoch 265/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.2087e-04 - val_loss: 9.7579e-04\n",
      "Epoch 266/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.1385e-04 - val_loss: 9.6228e-04\n",
      "Epoch 267/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.0695e-04 - val_loss: 9.4904e-04\n",
      "Epoch 268/1000\n",
      "32/32 [==============================] - 0s 169us/step - loss: 9.0019e-04 - val_loss: 9.3609e-04\n",
      "Epoch 269/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9356e-04 - val_loss: 9.2339e-04\n",
      "Epoch 270/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.8706e-04 - val_loss: 9.1096e-04\n",
      "Epoch 271/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.8069e-04 - val_loss: 8.9879e-04\n",
      "Epoch 272/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 8.7442e-04 - val_loss: 8.8688e-04\n",
      "Epoch 273/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.6828e-04 - val_loss: 8.7523e-04\n",
      "Epoch 274/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 8.6227e-04 - val_loss: 8.6381e-04\n",
      "Epoch 275/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.5635e-04 - val_loss: 8.5263e-04\n",
      "Epoch 276/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.5055e-04 - val_loss: 8.4171e-04\n",
      "Epoch 277/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.4487e-04 - val_loss: 8.3100e-04\n",
      "Epoch 278/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.3928e-04 - val_loss: 8.2054e-04\n",
      "Epoch 279/1000\n",
      "32/32 [==============================] - 0s 164us/step - loss: 8.3380e-04 - val_loss: 8.1029e-04\n",
      "Epoch 280/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2843e-04 - val_loss: 8.0025e-04\n",
      "Epoch 281/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 8.2315e-04 - val_loss: 7.9045e-04\n",
      "Epoch 282/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.1797e-04 - val_loss: 7.8083e-04\n",
      "Epoch 283/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 8.1288e-04 - val_loss: 7.7143e-04\n",
      "Epoch 284/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 8.0790e-04 - val_loss: 7.6223e-04\n",
      "Epoch 285/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 8.0299e-04 - val_loss: 7.5321e-04\n",
      "Epoch 286/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.9819e-04 - val_loss: 7.4439e-04\n",
      "Epoch 287/1000\n",
      "32/32 [==============================] - 0s 163us/step - loss: 7.9346e-04 - val_loss: 7.3576e-04\n",
      "Epoch 288/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 7.8883e-04 - val_loss: 7.2728e-04\n",
      "Epoch 289/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.8427e-04 - val_loss: 7.1900e-04\n",
      "Epoch 290/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7980e-04 - val_loss: 7.1089e-04\n",
      "Epoch 291/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.7541e-04 - val_loss: 7.0295e-04\n",
      "Epoch 292/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7110e-04 - val_loss: 6.9515e-04\n",
      "Epoch 293/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 7.6685e-04 - val_loss: 6.8753e-04\n",
      "Epoch 294/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 7.6269e-04 - val_loss: 6.8006e-04\n",
      "Epoch 295/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 7.5861e-04 - val_loss: 6.7275e-04\n",
      "Epoch 296/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.5459e-04 - val_loss: 6.6559e-04\n",
      "Epoch 297/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.5064e-04 - val_loss: 6.5859e-04\n",
      "Epoch 298/1000\n",
      "32/32 [==============================] - 0s 167us/step - loss: 7.4676e-04 - val_loss: 6.5173e-04\n",
      "Epoch 299/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 7.4295e-04 - val_loss: 6.4501e-04\n",
      "Epoch 300/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.3920e-04 - val_loss: 6.3843e-04\n",
      "Epoch 301/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 7.3553e-04 - val_loss: 6.3198e-04\n",
      "Epoch 302/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3190e-04 - val_loss: 6.2567e-04\n",
      "Epoch 303/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2835e-04 - val_loss: 6.1949e-04\n",
      "Epoch 304/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.2485e-04 - val_loss: 6.1343e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 305/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.2141e-04 - val_loss: 6.0749e-04\n",
      "Epoch 306/1000\n",
      "32/32 [==============================] - 0s 163us/step - loss: 7.1803e-04 - val_loss: 6.0167e-04\n",
      "Epoch 307/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1471e-04 - val_loss: 5.9598e-04\n",
      "Epoch 308/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1144e-04 - val_loss: 5.9040e-04\n",
      "Epoch 309/1000\n",
      "32/32 [==============================] - 0s 131us/step - loss: 7.0822e-04 - val_loss: 5.8494e-04\n",
      "Epoch 310/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.0506e-04 - val_loss: 5.7959e-04\n",
      "Epoch 311/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0195e-04 - val_loss: 5.7434e-04\n",
      "Epoch 312/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 6.9889e-04 - val_loss: 5.6919e-04\n",
      "Epoch 313/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 6.9588e-04 - val_loss: 5.6416e-04\n",
      "Epoch 314/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.9292e-04 - val_loss: 5.5921e-04\n",
      "Epoch 315/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.9000e-04 - val_loss: 5.5437e-04\n",
      "Epoch 316/1000\n",
      "32/32 [==============================] - 0s 158us/step - loss: 6.8713e-04 - val_loss: 5.4963e-04\n",
      "Epoch 317/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 6.8432e-04 - val_loss: 5.4497e-04\n",
      "Epoch 318/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 6.8154e-04 - val_loss: 5.4041e-04\n",
      "Epoch 319/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7880e-04 - val_loss: 5.3593e-04\n",
      "Epoch 320/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 6.7611e-04 - val_loss: 5.3156e-04\n",
      "Epoch 321/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7347e-04 - val_loss: 5.2725e-04\n",
      "Epoch 322/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 6.7086e-04 - val_loss: 5.2305e-04\n",
      "Epoch 323/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 6.6828e-04 - val_loss: 5.1891e-04\n",
      "Epoch 324/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6576e-04 - val_loss: 5.1487e-04\n",
      "Epoch 325/1000\n",
      "32/32 [==============================] - 0s 132us/step - loss: 6.6327e-04 - val_loss: 5.1088e-04\n",
      "Epoch 326/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 6.6081e-04 - val_loss: 5.0698e-04\n",
      "Epoch 327/1000\n",
      "32/32 [==============================] - 0s 131us/step - loss: 6.5839e-04 - val_loss: 5.0317e-04\n",
      "Epoch 328/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5601e-04 - val_loss: 4.9939e-04\n",
      "Epoch 329/1000\n",
      "32/32 [==============================] - 0s 175us/step - loss: 6.5366e-04 - val_loss: 4.9572e-04\n",
      "Epoch 330/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5135e-04 - val_loss: 4.9211e-04\n",
      "Epoch 331/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 6.4907e-04 - val_loss: 4.8858e-04\n",
      "Epoch 332/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4683e-04 - val_loss: 4.8512e-04\n",
      "Epoch 333/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4462e-04 - val_loss: 4.8169e-04\n",
      "Epoch 334/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.4243e-04 - val_loss: 4.7835e-04\n",
      "Epoch 335/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.4028e-04 - val_loss: 4.7506e-04\n",
      "Epoch 336/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 6.3817e-04 - val_loss: 4.7184e-04\n",
      "Epoch 337/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3608e-04 - val_loss: 4.6868e-04\n",
      "Epoch 338/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.3401e-04 - val_loss: 4.6557e-04\n",
      "Epoch 339/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.3198e-04 - val_loss: 4.6252e-04\n",
      "Epoch 340/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 6.2997e-04 - val_loss: 4.5950e-04\n",
      "Epoch 341/1000\n",
      "32/32 [==============================] - 0s 145us/step - loss: 6.2799e-04 - val_loss: 4.5658e-04\n",
      "Epoch 342/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2605e-04 - val_loss: 4.5368e-04\n",
      "Epoch 343/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2412e-04 - val_loss: 4.5084e-04\n",
      "Epoch 344/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2222e-04 - val_loss: 4.4805e-04\n",
      "Epoch 345/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2035e-04 - val_loss: 4.4532e-04\n",
      "Epoch 346/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 6.1850e-04 - val_loss: 4.4262e-04\n",
      "Epoch 347/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.1667e-04 - val_loss: 4.3999e-04\n",
      "Epoch 348/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.1487e-04 - val_loss: 4.3738e-04\n",
      "Epoch 349/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.1309e-04 - val_loss: 4.3483e-04\n",
      "Epoch 350/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.1133e-04 - val_loss: 4.3232e-04\n",
      "Epoch 351/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0960e-04 - val_loss: 4.2985e-04\n",
      "Epoch 352/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0789e-04 - val_loss: 4.2743e-04\n",
      "Epoch 353/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0620e-04 - val_loss: 4.2504e-04\n",
      "Epoch 354/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.0453e-04 - val_loss: 4.2269e-04\n",
      "Epoch 355/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 6.0288e-04 - val_loss: 4.2038e-04\n",
      "Epoch 356/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 6.0125e-04 - val_loss: 4.1812e-04\n",
      "Epoch 357/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9964e-04 - val_loss: 4.1589e-04\n",
      "Epoch 358/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9805e-04 - val_loss: 4.1370e-04\n",
      "Epoch 359/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.9648e-04 - val_loss: 4.1153e-04\n",
      "Epoch 360/1000\n",
      "32/32 [==============================] - 0s 169us/step - loss: 5.9493e-04 - val_loss: 4.0941e-04\n",
      "Epoch 361/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9340e-04 - val_loss: 4.0733e-04\n",
      "Epoch 362/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9188e-04 - val_loss: 4.0526e-04\n",
      "Epoch 363/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 5.9037e-04 - val_loss: 4.0324e-04\n",
      "Epoch 364/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8889e-04 - val_loss: 4.0125e-04\n",
      "Epoch 365/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8743e-04 - val_loss: 3.9929e-04\n",
      "Epoch 366/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.8598e-04 - val_loss: 3.9736e-04\n",
      "Epoch 367/1000\n",
      "32/32 [==============================] - 0s 122us/step - loss: 5.8454e-04 - val_loss: 3.9544e-04\n",
      "Epoch 368/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.8313e-04 - val_loss: 3.9359e-04\n",
      "Epoch 369/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 5.8172e-04 - val_loss: 3.9172e-04\n",
      "Epoch 370/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8033e-04 - val_loss: 3.8992e-04\n",
      "Epoch 371/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7896e-04 - val_loss: 3.8812e-04\n",
      "Epoch 372/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.7760e-04 - val_loss: 3.8636e-04\n",
      "Epoch 373/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.7626e-04 - val_loss: 3.8461e-04\n",
      "Epoch 374/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 5.7493e-04 - val_loss: 3.8290e-04\n",
      "Epoch 375/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 5.7361e-04 - val_loss: 3.8121e-04\n",
      "Epoch 376/1000\n",
      "32/32 [==============================] - 0s 138us/step - loss: 5.7231e-04 - val_loss: 3.7955e-04\n",
      "Epoch 377/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7102e-04 - val_loss: 3.7792e-04\n",
      "Epoch 378/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 5.6975e-04 - val_loss: 3.7629e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 379/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6848e-04 - val_loss: 3.7470e-04\n",
      "Epoch 380/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.6722e-04 - val_loss: 3.7313e-04\n",
      "Epoch 381/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 5.6599e-04 - val_loss: 3.7159e-04\n",
      "Epoch 382/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6476e-04 - val_loss: 3.7005e-04\n",
      "Epoch 383/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.6354e-04 - val_loss: 3.6854e-04\n",
      "Epoch 384/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.6234e-04 - val_loss: 3.6704e-04\n",
      "Epoch 385/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 5.6115e-04 - val_loss: 3.6557e-04\n",
      "Epoch 386/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5996e-04 - val_loss: 3.6413e-04\n",
      "Epoch 387/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.5880e-04 - val_loss: 3.6271e-04\n",
      "Epoch 388/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.5764e-04 - val_loss: 3.6128e-04\n",
      "Epoch 389/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.5649e-04 - val_loss: 3.5988e-04\n",
      "Epoch 390/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 5.5534e-04 - val_loss: 3.5851e-04\n",
      "Epoch 391/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.5421e-04 - val_loss: 3.5715e-04\n",
      "Epoch 392/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 5.5310e-04 - val_loss: 3.5580e-04\n",
      "Epoch 393/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 5.5199e-04 - val_loss: 3.5449e-04\n",
      "Epoch 394/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.5089e-04 - val_loss: 3.5317e-04\n",
      "Epoch 395/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.4980e-04 - val_loss: 3.5188e-04\n",
      "Epoch 396/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.4872e-04 - val_loss: 3.5062e-04\n",
      "Epoch 397/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 5.4765e-04 - val_loss: 3.4934e-04\n",
      "Epoch 398/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4658e-04 - val_loss: 3.4810e-04\n",
      "Epoch 399/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.4553e-04 - val_loss: 3.4687e-04\n",
      "Epoch 400/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 5.4448e-04 - val_loss: 3.4564e-04\n",
      "Epoch 401/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4344e-04 - val_loss: 3.4443e-04\n",
      "Epoch 402/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.4241e-04 - val_loss: 3.4325e-04\n",
      "Epoch 403/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.4139e-04 - val_loss: 3.4207e-04\n",
      "Epoch 404/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4037e-04 - val_loss: 3.4091e-04\n",
      "Epoch 405/1000\n",
      "32/32 [==============================] - 0s 130us/step - loss: 5.3937e-04 - val_loss: 3.3974e-04\n",
      "Epoch 406/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 5.3837e-04 - val_loss: 3.3860e-04\n",
      "Epoch 407/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.3738e-04 - val_loss: 3.3749e-04\n",
      "Epoch 408/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 5.3640e-04 - val_loss: 3.3636e-04\n",
      "Epoch 409/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3542e-04 - val_loss: 3.3527e-04\n",
      "Epoch 410/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3445e-04 - val_loss: 3.3417e-04\n",
      "Epoch 411/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.3349e-04 - val_loss: 3.3311e-04\n",
      "Epoch 412/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3253e-04 - val_loss: 3.3203e-04\n",
      "Epoch 413/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3159e-04 - val_loss: 3.3099e-04\n",
      "Epoch 414/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.3065e-04 - val_loss: 3.2993e-04\n",
      "Epoch 415/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2971e-04 - val_loss: 3.2889e-04\n",
      "Epoch 416/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2878e-04 - val_loss: 3.2786e-04\n",
      "Epoch 417/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 5.2786e-04 - val_loss: 3.2684e-04\n",
      "Epoch 418/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2694e-04 - val_loss: 3.2585e-04\n",
      "Epoch 419/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.2603e-04 - val_loss: 3.2484e-04\n",
      "Epoch 420/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 5.2513e-04 - val_loss: 3.2386e-04\n",
      "Epoch 421/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2422e-04 - val_loss: 3.2289e-04\n",
      "Epoch 422/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.2334e-04 - val_loss: 3.2192e-04\n",
      "Epoch 423/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.2245e-04 - val_loss: 3.2095e-04\n",
      "Epoch 424/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2157e-04 - val_loss: 3.2000e-04\n",
      "Epoch 425/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2069e-04 - val_loss: 3.1907e-04\n",
      "Epoch 426/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1983e-04 - val_loss: 3.1814e-04\n",
      "Epoch 427/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1896e-04 - val_loss: 3.1721e-04\n",
      "Epoch 428/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.1810e-04 - val_loss: 3.1630e-04\n",
      "Epoch 429/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 5.1724e-04 - val_loss: 3.1539e-04\n",
      "Epoch 430/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.1639e-04 - val_loss: 3.1449e-04\n",
      "Epoch 431/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1555e-04 - val_loss: 3.1362e-04\n",
      "Epoch 432/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1471e-04 - val_loss: 3.1272e-04\n",
      "Epoch 433/1000\n",
      "32/32 [==============================] - 0s 137us/step - loss: 5.1388e-04 - val_loss: 3.1186e-04\n",
      "Epoch 434/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 5.1305e-04 - val_loss: 3.1098e-04\n",
      "Epoch 435/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1222e-04 - val_loss: 3.1012e-04\n",
      "Epoch 436/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.1140e-04 - val_loss: 3.0926e-04\n",
      "Epoch 437/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1058e-04 - val_loss: 3.0840e-04\n",
      "Epoch 438/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0977e-04 - val_loss: 3.0757e-04\n",
      "Epoch 439/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0897e-04 - val_loss: 3.0673e-04\n",
      "Epoch 440/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0817e-04 - val_loss: 3.0590e-04\n",
      "Epoch 441/1000\n",
      "32/32 [==============================] - 0s 145us/step - loss: 5.0736e-04 - val_loss: 3.0507e-04\n",
      "Epoch 442/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 5.0657e-04 - val_loss: 3.0426e-04\n",
      "Epoch 443/1000\n",
      "32/32 [==============================] - 0s 170us/step - loss: 5.0578e-04 - val_loss: 3.0346e-04\n",
      "Epoch 444/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 5.0499e-04 - val_loss: 3.0266e-04\n",
      "Epoch 445/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0421e-04 - val_loss: 3.0186e-04\n",
      "Epoch 446/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0343e-04 - val_loss: 3.0108e-04\n",
      "Epoch 447/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 5.0266e-04 - val_loss: 3.0029e-04\n",
      "Epoch 448/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.0189e-04 - val_loss: 2.9952e-04\n",
      "Epoch 449/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0112e-04 - val_loss: 2.9874e-04\n",
      "Epoch 450/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0035e-04 - val_loss: 2.9798e-04\n",
      "Epoch 451/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9960e-04 - val_loss: 2.9722e-04\n",
      "Epoch 452/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9884e-04 - val_loss: 2.9647e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 453/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 4.9809e-04 - val_loss: 2.9571e-04\n",
      "Epoch 454/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9735e-04 - val_loss: 2.9497e-04\n",
      "Epoch 455/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9660e-04 - val_loss: 2.9423e-04\n",
      "Epoch 456/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.9585e-04 - val_loss: 2.9350e-04\n",
      "Epoch 457/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 4.9512e-04 - val_loss: 2.9276e-04\n",
      "Epoch 458/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9438e-04 - val_loss: 2.9205e-04\n",
      "Epoch 459/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9366e-04 - val_loss: 2.9133e-04\n",
      "Epoch 460/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 4.9293e-04 - val_loss: 2.9060e-04\n",
      "Epoch 461/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 4.9220e-04 - val_loss: 2.8991e-04\n",
      "Epoch 462/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 4.9148e-04 - val_loss: 2.8919e-04\n",
      "Epoch 463/1000\n",
      "32/32 [==============================] - 0s 161us/step - loss: 4.9076e-04 - val_loss: 2.8850e-04\n",
      "Epoch 464/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9004e-04 - val_loss: 2.8780e-04\n",
      "Epoch 465/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 4.8933e-04 - val_loss: 2.8712e-04\n",
      "Epoch 466/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8862e-04 - val_loss: 2.8642e-04\n",
      "Epoch 467/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 4.8791e-04 - val_loss: 2.8574e-04\n",
      "Epoch 468/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8720e-04 - val_loss: 2.8507e-04\n",
      "Epoch 469/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8651e-04 - val_loss: 2.8440e-04\n",
      "Epoch 470/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.8580e-04 - val_loss: 2.8372e-04\n",
      "Epoch 471/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8511e-04 - val_loss: 2.8306e-04\n",
      "Epoch 472/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8442e-04 - val_loss: 2.8239e-04\n",
      "Epoch 473/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.8372e-04 - val_loss: 2.8174e-04\n",
      "Epoch 474/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.8304e-04 - val_loss: 2.8109e-04\n",
      "Epoch 475/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8235e-04 - val_loss: 2.8044e-04\n",
      "Epoch 476/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.8167e-04 - val_loss: 2.7979e-04\n",
      "Epoch 477/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.8099e-04 - val_loss: 2.7915e-04\n",
      "Epoch 478/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8031e-04 - val_loss: 2.7851e-04\n",
      "Epoch 479/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.7964e-04 - val_loss: 2.7789e-04\n",
      "Epoch 480/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 4.7896e-04 - val_loss: 2.7725e-04\n",
      "Epoch 481/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 4.7829e-04 - val_loss: 2.7662e-04\n",
      "Epoch 482/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 4.7762e-04 - val_loss: 2.7600e-04\n",
      "Epoch 483/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 4.7696e-04 - val_loss: 2.7538e-04\n",
      "Epoch 484/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 4.7630e-04 - val_loss: 2.7477e-04\n",
      "Epoch 485/1000\n",
      "32/32 [==============================] - 0s 158us/step - loss: 4.7564e-04 - val_loss: 2.7415e-04\n",
      "Epoch 486/1000\n",
      "32/32 [==============================] - 0s 170us/step - loss: 4.7498e-04 - val_loss: 2.7354e-04\n",
      "Epoch 487/1000\n",
      "32/32 [==============================] - 0s 169us/step - loss: 4.7432e-04 - val_loss: 2.7294e-04\n",
      "Epoch 488/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7367e-04 - val_loss: 2.7233e-04\n",
      "Epoch 489/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 4.7302e-04 - val_loss: 2.7175e-04\n",
      "Epoch 490/1000\n",
      "32/32 [==============================] - 0s 132us/step - loss: 4.7237e-04 - val_loss: 2.7114e-04\n",
      "Epoch 491/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.7172e-04 - val_loss: 2.7055e-04\n",
      "Epoch 492/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 4.7107e-04 - val_loss: 2.6996e-04\n",
      "Epoch 493/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.7043e-04 - val_loss: 2.6938e-04\n",
      "Epoch 494/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6979e-04 - val_loss: 2.6879e-04\n",
      "Epoch 495/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.6915e-04 - val_loss: 2.6821e-04\n",
      "Epoch 496/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 4.6851e-04 - val_loss: 2.6763e-04\n",
      "Epoch 497/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.6788e-04 - val_loss: 2.6707e-04\n",
      "Epoch 498/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 4.6725e-04 - val_loss: 2.6650e-04\n",
      "Epoch 499/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.6661e-04 - val_loss: 2.6593e-04\n",
      "Epoch 500/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.6598e-04 - val_loss: 2.6536e-04\n",
      "Epoch 501/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 4.6535e-04 - val_loss: 2.6480e-04\n",
      "Epoch 502/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.6473e-04 - val_loss: 2.6424e-04\n",
      "Epoch 503/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6411e-04 - val_loss: 2.6368e-04\n",
      "Epoch 504/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6348e-04 - val_loss: 2.6314e-04\n",
      "Epoch 505/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 4.6287e-04 - val_loss: 2.6258e-04\n",
      "Epoch 506/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6225e-04 - val_loss: 2.6203e-04\n",
      "Epoch 507/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6163e-04 - val_loss: 2.6149e-04\n",
      "Epoch 508/1000\n",
      "32/32 [==============================] - 0s 116us/step - loss: 4.6102e-04 - val_loss: 2.6096e-04\n",
      "Epoch 509/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.6041e-04 - val_loss: 2.6041e-04\n",
      "Epoch 510/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.5979e-04 - val_loss: 2.5986e-04\n",
      "Epoch 511/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5918e-04 - val_loss: 2.5933e-04\n",
      "Epoch 512/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5857e-04 - val_loss: 2.5881e-04\n",
      "Epoch 513/1000\n",
      "32/32 [==============================] - 0s 138us/step - loss: 4.5797e-04 - val_loss: 2.5827e-04\n",
      "Epoch 514/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 4.5736e-04 - val_loss: 2.5774e-04\n",
      "Epoch 515/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 4.5676e-04 - val_loss: 2.5723e-04\n",
      "Epoch 516/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5616e-04 - val_loss: 2.5671e-04\n",
      "Epoch 517/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.5556e-04 - val_loss: 2.5618e-04\n",
      "Epoch 518/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 4.5497e-04 - val_loss: 2.5567e-04\n",
      "Epoch 519/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5437e-04 - val_loss: 2.5515e-04\n",
      "Epoch 520/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 4.5378e-04 - val_loss: 2.5465e-04\n",
      "Epoch 521/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 4.5318e-04 - val_loss: 2.5413e-04\n",
      "Epoch 522/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 4.5259e-04 - val_loss: 2.5362e-04\n",
      "Epoch 523/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.5200e-04 - val_loss: 2.5313e-04\n",
      "Epoch 524/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.5142e-04 - val_loss: 2.5262e-04\n",
      "Epoch 525/1000\n",
      "32/32 [==============================] - 0s 175us/step - loss: 4.5083e-04 - val_loss: 2.5212e-04\n",
      "Epoch 526/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5024e-04 - val_loss: 2.5162e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 527/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4966e-04 - val_loss: 2.5112e-04\n",
      "Epoch 528/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.4907e-04 - val_loss: 2.5063e-04\n",
      "Epoch 529/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4849e-04 - val_loss: 2.5013e-04\n",
      "Epoch 530/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4791e-04 - val_loss: 2.4965e-04\n",
      "Epoch 531/1000\n",
      "32/32 [==============================] - 0s 137us/step - loss: 4.4733e-04 - val_loss: 2.4916e-04\n",
      "Epoch 532/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4677e-04 - val_loss: 2.4868e-04\n",
      "Epoch 533/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 4.4619e-04 - val_loss: 2.4819e-04\n",
      "Epoch 534/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 4.4561e-04 - val_loss: 2.4771e-04\n",
      "Epoch 535/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.4504e-04 - val_loss: 2.4724e-04\n",
      "Epoch 536/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.4447e-04 - val_loss: 2.4676e-04\n",
      "Epoch 537/1000\n",
      "32/32 [==============================] - 0s 158us/step - loss: 4.4390e-04 - val_loss: 2.4627e-04\n",
      "Epoch 538/1000\n",
      "32/32 [==============================] - 0s 181us/step - loss: 4.4333e-04 - val_loss: 2.4580e-04\n",
      "Epoch 539/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4276e-04 - val_loss: 2.4534e-04\n",
      "Epoch 540/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 4.4220e-04 - val_loss: 2.4487e-04\n",
      "Epoch 541/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4163e-04 - val_loss: 2.4441e-04\n",
      "Epoch 542/1000\n",
      "32/32 [==============================] - 0s 131us/step - loss: 4.4107e-04 - val_loss: 2.4395e-04\n",
      "Epoch 543/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4051e-04 - val_loss: 2.4348e-04\n",
      "Epoch 544/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3995e-04 - val_loss: 2.4302e-04\n",
      "Epoch 545/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.3939e-04 - val_loss: 2.4256e-04\n",
      "Epoch 546/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 4.3883e-04 - val_loss: 2.4209e-04\n",
      "Epoch 547/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.3827e-04 - val_loss: 2.4165e-04\n",
      "Epoch 548/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3772e-04 - val_loss: 2.4119e-04\n",
      "Epoch 549/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3716e-04 - val_loss: 2.4074e-04\n",
      "Epoch 550/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.3661e-04 - val_loss: 2.4030e-04\n",
      "Epoch 551/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 4.3606e-04 - val_loss: 2.3985e-04\n",
      "Epoch 552/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3551e-04 - val_loss: 2.3940e-04\n",
      "Epoch 553/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3496e-04 - val_loss: 2.3896e-04\n",
      "Epoch 554/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3441e-04 - val_loss: 2.3852e-04\n",
      "Epoch 555/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3387e-04 - val_loss: 2.3808e-04\n",
      "Epoch 556/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3332e-04 - val_loss: 2.3764e-04\n",
      "Epoch 557/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 4.3278e-04 - val_loss: 2.3722e-04\n",
      "Epoch 558/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 4.3223e-04 - val_loss: 2.3677e-04\n",
      "Epoch 559/1000\n",
      "32/32 [==============================] - 0s 162us/step - loss: 4.3169e-04 - val_loss: 2.3635e-04\n",
      "Epoch 560/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.3115e-04 - val_loss: 2.3591e-04\n",
      "Epoch 561/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.3061e-04 - val_loss: 2.3548e-04\n",
      "Epoch 562/1000\n",
      "32/32 [==============================] - 0s 173us/step - loss: 4.3007e-04 - val_loss: 2.3505e-04\n",
      "Epoch 563/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 4.2953e-04 - val_loss: 2.3463e-04\n",
      "Epoch 564/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 4.2899e-04 - val_loss: 2.3420e-04\n",
      "Epoch 565/1000\n",
      "32/32 [==============================] - 0s 158us/step - loss: 4.2846e-04 - val_loss: 2.3378e-04\n",
      "Epoch 566/1000\n",
      "32/32 [==============================] - 0s 173us/step - loss: 4.2792e-04 - val_loss: 2.3336e-04\n",
      "Epoch 567/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2739e-04 - val_loss: 2.3293e-04\n",
      "Epoch 568/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 4.2685e-04 - val_loss: 2.3252e-04\n",
      "Epoch 569/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2633e-04 - val_loss: 2.3210e-04\n",
      "Epoch 570/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.2580e-04 - val_loss: 2.3169e-04\n",
      "Epoch 571/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2527e-04 - val_loss: 2.3128e-04\n",
      "Epoch 572/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2474e-04 - val_loss: 2.3086e-04\n",
      "Epoch 573/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.2421e-04 - val_loss: 2.3046e-04\n",
      "Epoch 574/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.2369e-04 - val_loss: 2.3005e-04\n",
      "Epoch 575/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2316e-04 - val_loss: 2.2964e-04\n",
      "Epoch 576/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 4.2264e-04 - val_loss: 2.2923e-04\n",
      "Epoch 577/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2211e-04 - val_loss: 2.2884e-04\n",
      "Epoch 578/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.2159e-04 - val_loss: 2.2843e-04\n",
      "Epoch 579/1000\n",
      "32/32 [==============================] - 0s 132us/step - loss: 4.2107e-04 - val_loss: 2.2803e-04\n",
      "Epoch 580/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2055e-04 - val_loss: 2.2764e-04\n",
      "Epoch 581/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2003e-04 - val_loss: 2.2724e-04\n",
      "Epoch 582/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.1951e-04 - val_loss: 2.2684e-04\n",
      "Epoch 583/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 4.1899e-04 - val_loss: 2.2645e-04\n",
      "Epoch 584/1000\n",
      "32/32 [==============================] - 0s 133us/step - loss: 4.1848e-04 - val_loss: 2.2605e-04\n",
      "Epoch 585/1000\n",
      "32/32 [==============================] - 0s 166us/step - loss: 4.1796e-04 - val_loss: 2.2566e-04\n",
      "Epoch 586/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1745e-04 - val_loss: 2.2526e-04\n",
      "Epoch 587/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.1694e-04 - val_loss: 2.2488e-04\n",
      "Epoch 588/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.1642e-04 - val_loss: 2.2449e-04\n",
      "Epoch 589/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1591e-04 - val_loss: 2.2410e-04\n",
      "Epoch 590/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1540e-04 - val_loss: 2.2372e-04\n",
      "Epoch 591/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 4.1489e-04 - val_loss: 2.2334e-04\n",
      "Epoch 592/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1438e-04 - val_loss: 2.2295e-04\n",
      "Epoch 593/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 4.1388e-04 - val_loss: 2.2258e-04\n",
      "Epoch 594/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.1337e-04 - val_loss: 2.2219e-04\n",
      "Epoch 595/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1286e-04 - val_loss: 2.2182e-04\n",
      "Epoch 596/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.1236e-04 - val_loss: 2.2145e-04\n",
      "Epoch 597/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1185e-04 - val_loss: 2.2107e-04\n",
      "Epoch 598/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.1135e-04 - val_loss: 2.2070e-04\n",
      "Epoch 599/1000\n",
      "32/32 [==============================] - 0s 162us/step - loss: 4.1085e-04 - val_loss: 2.2032e-04\n",
      "Epoch 600/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 4.1035e-04 - val_loss: 2.1995e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 601/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0984e-04 - val_loss: 2.1958e-04\n",
      "Epoch 602/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 4.0935e-04 - val_loss: 2.1921e-04\n",
      "Epoch 603/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0885e-04 - val_loss: 2.1885e-04\n",
      "Epoch 604/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.0835e-04 - val_loss: 2.1849e-04\n",
      "Epoch 605/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 4.0786e-04 - val_loss: 2.1811e-04\n",
      "Epoch 606/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0736e-04 - val_loss: 2.1776e-04\n",
      "Epoch 607/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0686e-04 - val_loss: 2.1739e-04\n",
      "Epoch 608/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 4.0637e-04 - val_loss: 2.1703e-04\n",
      "Epoch 609/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 4.0588e-04 - val_loss: 2.1668e-04\n",
      "Epoch 610/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.0538e-04 - val_loss: 2.1631e-04\n",
      "Epoch 611/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.0489e-04 - val_loss: 2.1596e-04\n",
      "Epoch 612/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0440e-04 - val_loss: 2.1560e-04\n",
      "Epoch 613/1000\n",
      "32/32 [==============================] - 0s 178us/step - loss: 4.0391e-04 - val_loss: 2.1524e-04\n",
      "Epoch 614/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 4.0342e-04 - val_loss: 2.1489e-04\n",
      "Epoch 615/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0294e-04 - val_loss: 2.1453e-04\n",
      "Epoch 616/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0244e-04 - val_loss: 2.1418e-04\n",
      "Epoch 617/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.0195e-04 - val_loss: 2.1384e-04\n",
      "Epoch 618/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 4.0147e-04 - val_loss: 2.1349e-04\n",
      "Epoch 619/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.0099e-04 - val_loss: 2.1314e-04\n",
      "Epoch 620/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 4.0050e-04 - val_loss: 2.1279e-04\n",
      "Epoch 621/1000\n",
      "32/32 [==============================] - 0s 128us/step - loss: 4.0002e-04 - val_loss: 2.1245e-04\n",
      "Epoch 622/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9953e-04 - val_loss: 2.1211e-04\n",
      "Epoch 623/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9905e-04 - val_loss: 2.1176e-04\n",
      "Epoch 624/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.9857e-04 - val_loss: 2.1143e-04\n",
      "Epoch 625/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.9809e-04 - val_loss: 2.1108e-04\n",
      "Epoch 626/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9762e-04 - val_loss: 2.1074e-04\n",
      "Epoch 627/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 3.9713e-04 - val_loss: 2.1039e-04\n",
      "Epoch 628/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9665e-04 - val_loss: 2.1006e-04\n",
      "Epoch 629/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.9618e-04 - val_loss: 2.0972e-04\n",
      "Epoch 630/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.9570e-04 - val_loss: 2.0939e-04\n",
      "Epoch 631/1000\n",
      "32/32 [==============================] - 0s 120us/step - loss: 3.9522e-04 - val_loss: 2.0905e-04\n",
      "Epoch 632/1000\n",
      "32/32 [==============================] - 0s 128us/step - loss: 3.9475e-04 - val_loss: 2.0872e-04\n",
      "Epoch 633/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9428e-04 - val_loss: 2.0839e-04\n",
      "Epoch 634/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9380e-04 - val_loss: 2.0807e-04\n",
      "Epoch 635/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9333e-04 - val_loss: 2.0773e-04\n",
      "Epoch 636/1000\n",
      "32/32 [==============================] - 0s 168us/step - loss: 3.9285e-04 - val_loss: 2.0740e-04\n",
      "Epoch 637/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9239e-04 - val_loss: 2.0707e-04\n",
      "Epoch 638/1000\n",
      "32/32 [==============================] - 0s 169us/step - loss: 3.9192e-04 - val_loss: 2.0675e-04\n",
      "Epoch 639/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9144e-04 - val_loss: 2.0642e-04\n",
      "Epoch 640/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9098e-04 - val_loss: 2.0610e-04\n",
      "Epoch 641/1000\n",
      "32/32 [==============================] - 0s 192us/step - loss: 3.9051e-04 - val_loss: 2.0577e-04\n",
      "Epoch 642/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 3.9004e-04 - val_loss: 2.0545e-04\n",
      "Epoch 643/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 3.8957e-04 - val_loss: 2.0511e-04\n",
      "Epoch 644/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 3.8911e-04 - val_loss: 2.0479e-04\n",
      "Epoch 645/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8864e-04 - val_loss: 2.0448e-04\n",
      "Epoch 646/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 3.8818e-04 - val_loss: 2.0416e-04\n",
      "Epoch 647/1000\n",
      "32/32 [==============================] - 0s 118us/step - loss: 3.8771e-04 - val_loss: 2.0384e-04\n",
      "Epoch 648/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.8725e-04 - val_loss: 2.0353e-04\n",
      "Epoch 649/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 3.8679e-04 - val_loss: 2.0322e-04\n",
      "Epoch 650/1000\n",
      "32/32 [==============================] - 0s 130us/step - loss: 3.8633e-04 - val_loss: 2.0290e-04\n",
      "Epoch 651/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8587e-04 - val_loss: 2.0258e-04\n",
      "Epoch 652/1000\n",
      "32/32 [==============================] - 0s 169us/step - loss: 3.8540e-04 - val_loss: 2.0228e-04\n",
      "Epoch 653/1000\n",
      "32/32 [==============================] - 0s 189us/step - loss: 3.8495e-04 - val_loss: 2.0196e-04\n",
      "Epoch 654/1000\n",
      "32/32 [==============================] - 0s 167us/step - loss: 3.8449e-04 - val_loss: 2.0165e-04\n",
      "Epoch 655/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8403e-04 - val_loss: 2.0133e-04\n",
      "Epoch 656/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.8357e-04 - val_loss: 2.0103e-04\n",
      "Epoch 657/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8312e-04 - val_loss: 2.0072e-04\n",
      "Epoch 658/1000\n",
      "32/32 [==============================] - 0s 118us/step - loss: 3.8266e-04 - val_loss: 2.0041e-04\n",
      "Epoch 659/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 3.8220e-04 - val_loss: 2.0011e-04\n",
      "Epoch 660/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.8174e-04 - val_loss: 1.9980e-04\n",
      "Epoch 661/1000\n",
      "32/32 [==============================] - 0s 127us/step - loss: 3.8129e-04 - val_loss: 1.9950e-04\n",
      "Epoch 662/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8084e-04 - val_loss: 1.9920e-04\n",
      "Epoch 663/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 3.8039e-04 - val_loss: 1.9888e-04\n",
      "Epoch 664/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 3.7994e-04 - val_loss: 1.9859e-04\n",
      "Epoch 665/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7949e-04 - val_loss: 1.9828e-04\n",
      "Epoch 666/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 3.7903e-04 - val_loss: 1.9798e-04\n",
      "Epoch 667/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 3.7858e-04 - val_loss: 1.9768e-04\n",
      "Epoch 668/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.7814e-04 - val_loss: 1.9738e-04\n",
      "Epoch 669/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 3.7768e-04 - val_loss: 1.9708e-04\n",
      "Epoch 670/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7724e-04 - val_loss: 1.9679e-04\n",
      "Epoch 671/1000\n",
      "32/32 [==============================] - 0s 132us/step - loss: 3.7679e-04 - val_loss: 1.9649e-04\n",
      "Epoch 672/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7635e-04 - val_loss: 1.9620e-04\n",
      "Epoch 673/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7590e-04 - val_loss: 1.9590e-04\n",
      "Epoch 674/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7545e-04 - val_loss: 1.9561e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 675/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7501e-04 - val_loss: 1.9532e-04\n",
      "Epoch 676/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.7457e-04 - val_loss: 1.9502e-04\n",
      "Epoch 677/1000\n",
      "32/32 [==============================] - 0s 127us/step - loss: 3.7413e-04 - val_loss: 1.9474e-04\n",
      "Epoch 678/1000\n",
      "32/32 [==============================] - 0s 130us/step - loss: 3.7368e-04 - val_loss: 1.9445e-04\n",
      "Epoch 679/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.7324e-04 - val_loss: 1.9416e-04\n",
      "Epoch 680/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7280e-04 - val_loss: 1.9387e-04\n",
      "Epoch 681/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7236e-04 - val_loss: 1.9358e-04\n",
      "Epoch 682/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7192e-04 - val_loss: 1.9329e-04\n",
      "Epoch 683/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.7148e-04 - val_loss: 1.9300e-04\n",
      "Epoch 684/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7104e-04 - val_loss: 1.9271e-04\n",
      "Epoch 685/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7060e-04 - val_loss: 1.9243e-04\n",
      "Epoch 686/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7016e-04 - val_loss: 1.9215e-04\n",
      "Epoch 687/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6973e-04 - val_loss: 1.9186e-04\n",
      "Epoch 688/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6929e-04 - val_loss: 1.9159e-04\n",
      "Epoch 689/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 3.6885e-04 - val_loss: 1.9131e-04\n",
      "Epoch 690/1000\n",
      "32/32 [==============================] - 0s 128us/step - loss: 3.6842e-04 - val_loss: 1.9102e-04\n",
      "Epoch 691/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 3.6798e-04 - val_loss: 1.9074e-04\n",
      "Epoch 692/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6755e-04 - val_loss: 1.9045e-04\n",
      "Epoch 693/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6712e-04 - val_loss: 1.9018e-04\n",
      "Epoch 694/1000\n",
      "32/32 [==============================] - 0s 162us/step - loss: 3.6669e-04 - val_loss: 1.8990e-04\n",
      "Epoch 695/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6626e-04 - val_loss: 1.8962e-04\n",
      "Epoch 696/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6582e-04 - val_loss: 1.8935e-04\n",
      "Epoch 697/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 3.6539e-04 - val_loss: 1.8907e-04\n",
      "Epoch 698/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6496e-04 - val_loss: 1.8881e-04\n",
      "Epoch 699/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 3.6454e-04 - val_loss: 1.8852e-04\n",
      "Epoch 700/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6411e-04 - val_loss: 1.8825e-04\n",
      "Epoch 701/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6368e-04 - val_loss: 1.8798e-04\n",
      "Epoch 702/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6325e-04 - val_loss: 1.8772e-04\n",
      "Epoch 703/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6283e-04 - val_loss: 1.8744e-04\n",
      "Epoch 704/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6240e-04 - val_loss: 1.8717e-04\n",
      "Epoch 705/1000\n",
      "32/32 [==============================] - 0s 122us/step - loss: 3.6197e-04 - val_loss: 1.8690e-04\n",
      "Epoch 706/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6155e-04 - val_loss: 1.8662e-04\n",
      "Epoch 707/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6113e-04 - val_loss: 1.8636e-04\n",
      "Epoch 708/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6070e-04 - val_loss: 1.8609e-04\n",
      "Epoch 709/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6027e-04 - val_loss: 1.8582e-04\n",
      "Epoch 710/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.5985e-04 - val_loss: 1.8555e-04\n",
      "Epoch 711/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5943e-04 - val_loss: 1.8529e-04\n",
      "Epoch 712/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5901e-04 - val_loss: 1.8502e-04\n",
      "Epoch 713/1000\n",
      "32/32 [==============================] - 0s 145us/step - loss: 3.5859e-04 - val_loss: 1.8476e-04\n",
      "Epoch 714/1000\n",
      "32/32 [==============================] - 0s 128us/step - loss: 3.5817e-04 - val_loss: 1.8450e-04\n",
      "Epoch 715/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 3.5775e-04 - val_loss: 1.8423e-04\n",
      "Epoch 716/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5733e-04 - val_loss: 1.8397e-04\n",
      "Epoch 717/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5691e-04 - val_loss: 1.8371e-04\n",
      "Epoch 718/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5650e-04 - val_loss: 1.8345e-04\n",
      "Epoch 719/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 3.5608e-04 - val_loss: 1.8319e-04\n",
      "Epoch 720/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5566e-04 - val_loss: 1.8292e-04\n",
      "Epoch 721/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5525e-04 - val_loss: 1.8267e-04\n",
      "Epoch 722/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 3.5483e-04 - val_loss: 1.8241e-04\n",
      "Epoch 723/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.5441e-04 - val_loss: 1.8216e-04\n",
      "Epoch 724/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5401e-04 - val_loss: 1.8190e-04\n",
      "Epoch 725/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5359e-04 - val_loss: 1.8164e-04\n",
      "Epoch 726/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.5317e-04 - val_loss: 1.8137e-04\n",
      "Epoch 727/1000\n",
      "32/32 [==============================] - 0s 131us/step - loss: 3.5276e-04 - val_loss: 1.8113e-04\n",
      "Epoch 728/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 3.5235e-04 - val_loss: 1.8087e-04\n",
      "Epoch 729/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 3.5194e-04 - val_loss: 1.8062e-04\n",
      "Epoch 730/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.5152e-04 - val_loss: 1.8036e-04\n",
      "Epoch 731/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 3.5112e-04 - val_loss: 1.8011e-04\n",
      "Epoch 732/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5071e-04 - val_loss: 1.7985e-04\n",
      "Epoch 733/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5030e-04 - val_loss: 1.7960e-04\n",
      "Epoch 734/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 3.4989e-04 - val_loss: 1.7935e-04\n",
      "Epoch 735/1000\n",
      "32/32 [==============================] - 0s 161us/step - loss: 3.4948e-04 - val_loss: 1.7909e-04\n",
      "Epoch 736/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4907e-04 - val_loss: 1.7885e-04\n",
      "Epoch 737/1000\n",
      "32/32 [==============================] - 0s 161us/step - loss: 3.4867e-04 - val_loss: 1.7860e-04\n",
      "Epoch 738/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4826e-04 - val_loss: 1.7836e-04\n",
      "Epoch 739/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4785e-04 - val_loss: 1.7811e-04\n",
      "Epoch 740/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.4745e-04 - val_loss: 1.7787e-04\n",
      "Epoch 741/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 3.4705e-04 - val_loss: 1.7762e-04\n",
      "Epoch 742/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.4664e-04 - val_loss: 1.7737e-04\n",
      "Epoch 743/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 3.4624e-04 - val_loss: 1.7712e-04\n",
      "Epoch 744/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4584e-04 - val_loss: 1.7687e-04\n",
      "Epoch 745/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4543e-04 - val_loss: 1.7663e-04\n",
      "Epoch 746/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4503e-04 - val_loss: 1.7639e-04\n",
      "Epoch 747/1000\n",
      "32/32 [==============================] - 0s 132us/step - loss: 3.4463e-04 - val_loss: 1.7615e-04\n",
      "Epoch 748/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4423e-04 - val_loss: 1.7590e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 749/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 3.4382e-04 - val_loss: 1.7566e-04\n",
      "Epoch 750/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 3.4343e-04 - val_loss: 1.7542e-04\n",
      "Epoch 751/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4303e-04 - val_loss: 1.7518e-04\n",
      "Epoch 752/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 3.4263e-04 - val_loss: 1.7494e-04\n",
      "Epoch 753/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 3.4223e-04 - val_loss: 1.7470e-04\n",
      "Epoch 754/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4183e-04 - val_loss: 1.7446e-04\n",
      "Epoch 755/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4144e-04 - val_loss: 1.7421e-04\n",
      "Epoch 756/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.4104e-04 - val_loss: 1.7398e-04\n",
      "Epoch 757/1000\n",
      "32/32 [==============================] - 0s 160us/step - loss: 3.4065e-04 - val_loss: 1.7374e-04\n",
      "Epoch 758/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4025e-04 - val_loss: 1.7350e-04\n",
      "Epoch 759/1000\n",
      "32/32 [==============================] - 0s 131us/step - loss: 3.3985e-04 - val_loss: 1.7326e-04\n",
      "Epoch 760/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.3946e-04 - val_loss: 1.7302e-04\n",
      "Epoch 761/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 3.3907e-04 - val_loss: 1.7279e-04\n",
      "Epoch 762/1000\n",
      "32/32 [==============================] - 0s 129us/step - loss: 3.3868e-04 - val_loss: 1.7256e-04\n",
      "Epoch 763/1000\n",
      "32/32 [==============================] - 0s 131us/step - loss: 3.3828e-04 - val_loss: 1.7232e-04\n",
      "Epoch 764/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3789e-04 - val_loss: 1.7209e-04\n",
      "Epoch 765/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3750e-04 - val_loss: 1.7185e-04\n",
      "Epoch 766/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3711e-04 - val_loss: 1.7162e-04\n",
      "Epoch 767/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 3.3671e-04 - val_loss: 1.7138e-04\n",
      "Epoch 768/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.3633e-04 - val_loss: 1.7115e-04\n",
      "Epoch 769/1000\n",
      "32/32 [==============================] - 0s 129us/step - loss: 3.3593e-04 - val_loss: 1.7092e-04\n",
      "Epoch 770/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 3.3555e-04 - val_loss: 1.7069e-04\n",
      "Epoch 771/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3516e-04 - val_loss: 1.7046e-04\n",
      "Epoch 772/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3477e-04 - val_loss: 1.7023e-04\n",
      "Epoch 773/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 3.3438e-04 - val_loss: 1.7000e-04\n",
      "Epoch 774/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3399e-04 - val_loss: 1.6978e-04\n",
      "Epoch 775/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3361e-04 - val_loss: 1.6954e-04\n",
      "Epoch 776/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3322e-04 - val_loss: 1.6932e-04\n",
      "Epoch 777/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3284e-04 - val_loss: 1.6909e-04\n",
      "Epoch 778/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3246e-04 - val_loss: 1.6885e-04\n",
      "Epoch 779/1000\n",
      "32/32 [==============================] - 0s 169us/step - loss: 3.3207e-04 - val_loss: 1.6863e-04\n",
      "Epoch 780/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3169e-04 - val_loss: 1.6841e-04\n",
      "Epoch 781/1000\n",
      "32/32 [==============================] - 0s 170us/step - loss: 3.3130e-04 - val_loss: 1.6818e-04\n",
      "Epoch 782/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3092e-04 - val_loss: 1.6795e-04\n",
      "Epoch 783/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 3.3054e-04 - val_loss: 1.6773e-04\n",
      "Epoch 784/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3015e-04 - val_loss: 1.6750e-04\n",
      "Epoch 785/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2977e-04 - val_loss: 1.6728e-04\n",
      "Epoch 786/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.2939e-04 - val_loss: 1.6706e-04\n",
      "Epoch 787/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 3.2901e-04 - val_loss: 1.6684e-04\n",
      "Epoch 788/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 3.2863e-04 - val_loss: 1.6663e-04\n",
      "Epoch 789/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.2825e-04 - val_loss: 1.6640e-04\n",
      "Epoch 790/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2787e-04 - val_loss: 1.6618e-04\n",
      "Epoch 791/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2750e-04 - val_loss: 1.6595e-04\n",
      "Epoch 792/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2712e-04 - val_loss: 1.6573e-04\n",
      "Epoch 793/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2674e-04 - val_loss: 1.6551e-04\n",
      "Epoch 794/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.2637e-04 - val_loss: 1.6528e-04\n",
      "Epoch 795/1000\n",
      "32/32 [==============================] - 0s 162us/step - loss: 3.2599e-04 - val_loss: 1.6506e-04\n",
      "Epoch 796/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2561e-04 - val_loss: 1.6484e-04\n",
      "Epoch 797/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2524e-04 - val_loss: 1.6463e-04\n",
      "Epoch 798/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2486e-04 - val_loss: 1.6441e-04\n",
      "Epoch 799/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2449e-04 - val_loss: 1.6420e-04\n",
      "Epoch 800/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2412e-04 - val_loss: 1.6398e-04\n",
      "Epoch 801/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 3.2374e-04 - val_loss: 1.6376e-04\n",
      "Epoch 802/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.2337e-04 - val_loss: 1.6355e-04\n",
      "Epoch 803/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2300e-04 - val_loss: 1.6334e-04\n",
      "Epoch 804/1000\n",
      "32/32 [==============================] - 0s 161us/step - loss: 3.2263e-04 - val_loss: 1.6312e-04\n",
      "Epoch 805/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 3.2226e-04 - val_loss: 1.6291e-04\n",
      "Epoch 806/1000\n",
      "32/32 [==============================] - 0s 177us/step - loss: 3.2189e-04 - val_loss: 1.6268e-04\n",
      "Epoch 807/1000\n",
      "32/32 [==============================] - 0s 170us/step - loss: 3.2151e-04 - val_loss: 1.6247e-04\n",
      "Epoch 808/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2115e-04 - val_loss: 1.6225e-04\n",
      "Epoch 809/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.2077e-04 - val_loss: 1.6204e-04\n",
      "Epoch 810/1000\n",
      "32/32 [==============================] - 0s 133us/step - loss: 3.2041e-04 - val_loss: 1.6182e-04\n",
      "Epoch 811/1000\n",
      "32/32 [==============================] - 0s 145us/step - loss: 3.2004e-04 - val_loss: 1.6161e-04\n",
      "Epoch 812/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1967e-04 - val_loss: 1.6141e-04\n",
      "Epoch 813/1000\n",
      "32/32 [==============================] - 0s 128us/step - loss: 3.1930e-04 - val_loss: 1.6120e-04\n",
      "Epoch 814/1000\n",
      "32/32 [==============================] - 0s 180us/step - loss: 3.1894e-04 - val_loss: 1.6099e-04\n",
      "Epoch 815/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1857e-04 - val_loss: 1.6077e-04\n",
      "Epoch 816/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.1820e-04 - val_loss: 1.6057e-04\n",
      "Epoch 817/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.1784e-04 - val_loss: 1.6036e-04\n",
      "Epoch 818/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.1748e-04 - val_loss: 1.6015e-04\n",
      "Epoch 819/1000\n",
      "32/32 [==============================] - 0s 173us/step - loss: 3.1711e-04 - val_loss: 1.5994e-04\n",
      "Epoch 820/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1674e-04 - val_loss: 1.5974e-04\n",
      "Epoch 821/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 3.1639e-04 - val_loss: 1.5953e-04\n",
      "Epoch 822/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1602e-04 - val_loss: 1.5932e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 823/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1566e-04 - val_loss: 1.5911e-04\n",
      "Epoch 824/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 3.1529e-04 - val_loss: 1.5890e-04\n",
      "Epoch 825/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1494e-04 - val_loss: 1.5870e-04\n",
      "Epoch 826/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 3.1457e-04 - val_loss: 1.5849e-04\n",
      "Epoch 827/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 3.1421e-04 - val_loss: 1.5827e-04\n",
      "Epoch 828/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1385e-04 - val_loss: 1.5808e-04\n",
      "Epoch 829/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 3.1350e-04 - val_loss: 1.5787e-04\n",
      "Epoch 830/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1313e-04 - val_loss: 1.5767e-04\n",
      "Epoch 831/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1277e-04 - val_loss: 1.5746e-04\n",
      "Epoch 832/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1241e-04 - val_loss: 1.5726e-04\n",
      "Epoch 833/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1206e-04 - val_loss: 1.5705e-04\n",
      "Epoch 834/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1170e-04 - val_loss: 1.5685e-04\n",
      "Epoch 835/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1134e-04 - val_loss: 1.5665e-04\n",
      "Epoch 836/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1099e-04 - val_loss: 1.5645e-04\n",
      "Epoch 837/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1063e-04 - val_loss: 1.5625e-04\n",
      "Epoch 838/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1028e-04 - val_loss: 1.5604e-04\n",
      "Epoch 839/1000\n",
      "32/32 [==============================] - 0s 119us/step - loss: 3.0992e-04 - val_loss: 1.5584e-04\n",
      "Epoch 840/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0956e-04 - val_loss: 1.5564e-04\n",
      "Epoch 841/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0921e-04 - val_loss: 1.5544e-04\n",
      "Epoch 842/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 3.0886e-04 - val_loss: 1.5524e-04\n",
      "Epoch 843/1000\n",
      "32/32 [==============================] - 0s 176us/step - loss: 3.0850e-04 - val_loss: 1.5504e-04\n",
      "Epoch 844/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0816e-04 - val_loss: 1.5484e-04\n",
      "Epoch 845/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0780e-04 - val_loss: 1.5464e-04\n",
      "Epoch 846/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 3.0745e-04 - val_loss: 1.5444e-04\n",
      "Epoch 847/1000\n",
      "32/32 [==============================] - 0s 138us/step - loss: 3.0710e-04 - val_loss: 1.5425e-04\n",
      "Epoch 848/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 3.0674e-04 - val_loss: 1.5404e-04\n",
      "Epoch 849/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.0640e-04 - val_loss: 1.5385e-04\n",
      "Epoch 850/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.0605e-04 - val_loss: 1.5366e-04\n",
      "Epoch 851/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 3.0570e-04 - val_loss: 1.5346e-04\n",
      "Epoch 852/1000\n",
      "32/32 [==============================] - 0s 161us/step - loss: 3.0534e-04 - val_loss: 1.5327e-04\n",
      "Epoch 853/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.0500e-04 - val_loss: 1.5307e-04\n",
      "Epoch 854/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0465e-04 - val_loss: 1.5288e-04\n",
      "Epoch 855/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.0430e-04 - val_loss: 1.5268e-04\n",
      "Epoch 856/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 3.0395e-04 - val_loss: 1.5248e-04\n",
      "Epoch 857/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.0361e-04 - val_loss: 1.5229e-04\n",
      "Epoch 858/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0326e-04 - val_loss: 1.5210e-04\n",
      "Epoch 859/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0292e-04 - val_loss: 1.5190e-04\n",
      "Epoch 860/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0257e-04 - val_loss: 1.5170e-04\n",
      "Epoch 861/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0222e-04 - val_loss: 1.5151e-04\n",
      "Epoch 862/1000\n",
      "32/32 [==============================] - 0s 164us/step - loss: 3.0188e-04 - val_loss: 1.5132e-04\n",
      "Epoch 863/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0154e-04 - val_loss: 1.5114e-04\n",
      "Epoch 864/1000\n",
      "32/32 [==============================] - 0s 132us/step - loss: 3.0119e-04 - val_loss: 1.5093e-04\n",
      "Epoch 865/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 3.0085e-04 - val_loss: 1.5074e-04\n",
      "Epoch 866/1000\n",
      "32/32 [==============================] - 0s 166us/step - loss: 3.0051e-04 - val_loss: 1.5055e-04\n",
      "Epoch 867/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0017e-04 - val_loss: 1.5036e-04\n",
      "Epoch 868/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.9982e-04 - val_loss: 1.5017e-04\n",
      "Epoch 869/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 2.9948e-04 - val_loss: 1.4998e-04\n",
      "Epoch 870/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9914e-04 - val_loss: 1.4979e-04\n",
      "Epoch 871/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.9880e-04 - val_loss: 1.4960e-04\n",
      "Epoch 872/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9846e-04 - val_loss: 1.4942e-04\n",
      "Epoch 873/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9812e-04 - val_loss: 1.4923e-04\n",
      "Epoch 874/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 2.9778e-04 - val_loss: 1.4904e-04\n",
      "Epoch 875/1000\n",
      "32/32 [==============================] - 0s 174us/step - loss: 2.9744e-04 - val_loss: 1.4884e-04\n",
      "Epoch 876/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9710e-04 - val_loss: 1.4865e-04\n",
      "Epoch 877/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.9677e-04 - val_loss: 1.4846e-04\n",
      "Epoch 878/1000\n",
      "32/32 [==============================] - 0s 131us/step - loss: 2.9643e-04 - val_loss: 1.4828e-04\n",
      "Epoch 879/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 2.9609e-04 - val_loss: 1.4810e-04\n",
      "Epoch 880/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.9576e-04 - val_loss: 1.4791e-04\n",
      "Epoch 881/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9542e-04 - val_loss: 1.4772e-04\n",
      "Epoch 882/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9508e-04 - val_loss: 1.4754e-04\n",
      "Epoch 883/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 2.9475e-04 - val_loss: 1.4736e-04\n",
      "Epoch 884/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.9441e-04 - val_loss: 1.4717e-04\n",
      "Epoch 885/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9408e-04 - val_loss: 1.4699e-04\n",
      "Epoch 886/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.9375e-04 - val_loss: 1.4680e-04\n",
      "Epoch 887/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9341e-04 - val_loss: 1.4662e-04\n",
      "Epoch 888/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 2.9308e-04 - val_loss: 1.4642e-04\n",
      "Epoch 889/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9274e-04 - val_loss: 1.4624e-04\n",
      "Epoch 890/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9241e-04 - val_loss: 1.4607e-04\n",
      "Epoch 891/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9208e-04 - val_loss: 1.4587e-04\n",
      "Epoch 892/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9175e-04 - val_loss: 1.4569e-04\n",
      "Epoch 893/1000\n",
      "32/32 [==============================] - 0s 132us/step - loss: 2.9142e-04 - val_loss: 1.4551e-04\n",
      "Epoch 894/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.9109e-04 - val_loss: 1.4533e-04\n",
      "Epoch 895/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9076e-04 - val_loss: 1.4515e-04\n",
      "Epoch 896/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9043e-04 - val_loss: 1.4497e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 897/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 2.9010e-04 - val_loss: 1.4478e-04\n",
      "Epoch 898/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8977e-04 - val_loss: 1.4461e-04\n",
      "Epoch 899/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8944e-04 - val_loss: 1.4443e-04\n",
      "Epoch 900/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.8911e-04 - val_loss: 1.4425e-04\n",
      "Epoch 901/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8878e-04 - val_loss: 1.4407e-04\n",
      "Epoch 902/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8846e-04 - val_loss: 1.4389e-04\n",
      "Epoch 903/1000\n",
      "32/32 [==============================] - 0s 137us/step - loss: 2.8813e-04 - val_loss: 1.4371e-04\n",
      "Epoch 904/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8781e-04 - val_loss: 1.4352e-04\n",
      "Epoch 905/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8748e-04 - val_loss: 1.4334e-04\n",
      "Epoch 906/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.8715e-04 - val_loss: 1.4317e-04\n",
      "Epoch 907/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.8683e-04 - val_loss: 1.4299e-04\n",
      "Epoch 908/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8651e-04 - val_loss: 1.4281e-04\n",
      "Epoch 909/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8618e-04 - val_loss: 1.4263e-04\n",
      "Epoch 910/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8585e-04 - val_loss: 1.4246e-04\n",
      "Epoch 911/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8553e-04 - val_loss: 1.4228e-04\n",
      "Epoch 912/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 2.8521e-04 - val_loss: 1.4210e-04\n",
      "Epoch 913/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8488e-04 - val_loss: 1.4193e-04\n",
      "Epoch 914/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8456e-04 - val_loss: 1.4175e-04\n",
      "Epoch 915/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.8424e-04 - val_loss: 1.4158e-04\n",
      "Epoch 916/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.8392e-04 - val_loss: 1.4140e-04\n",
      "Epoch 917/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8360e-04 - val_loss: 1.4123e-04\n",
      "Epoch 918/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.8328e-04 - val_loss: 1.4106e-04\n",
      "Epoch 919/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.8296e-04 - val_loss: 1.4088e-04\n",
      "Epoch 920/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 2.8264e-04 - val_loss: 1.4071e-04\n",
      "Epoch 921/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 2.8232e-04 - val_loss: 1.4053e-04\n",
      "Epoch 922/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 2.8200e-04 - val_loss: 1.4036e-04\n",
      "Epoch 923/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8168e-04 - val_loss: 1.4018e-04\n",
      "Epoch 924/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8136e-04 - val_loss: 1.4001e-04\n",
      "Epoch 925/1000\n",
      "32/32 [==============================] - 0s 137us/step - loss: 2.8104e-04 - val_loss: 1.3983e-04\n",
      "Epoch 926/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8073e-04 - val_loss: 1.3966e-04\n",
      "Epoch 927/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8041e-04 - val_loss: 1.3949e-04\n",
      "Epoch 928/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.8010e-04 - val_loss: 1.3931e-04\n",
      "Epoch 929/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7978e-04 - val_loss: 1.3914e-04\n",
      "Epoch 930/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.7946e-04 - val_loss: 1.3897e-04\n",
      "Epoch 931/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.7915e-04 - val_loss: 1.3880e-04\n",
      "Epoch 932/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.7883e-04 - val_loss: 1.3863e-04\n",
      "Epoch 933/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.7852e-04 - val_loss: 1.3847e-04\n",
      "Epoch 934/1000\n",
      "32/32 [==============================] - 0s 128us/step - loss: 2.7820e-04 - val_loss: 1.3829e-04\n",
      "Epoch 935/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 2.7789e-04 - val_loss: 1.3812e-04\n",
      "Epoch 936/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 2.7757e-04 - val_loss: 1.3795e-04\n",
      "Epoch 937/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7726e-04 - val_loss: 1.3778e-04\n",
      "Epoch 938/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 2.7695e-04 - val_loss: 1.3762e-04\n",
      "Epoch 939/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 2.7664e-04 - val_loss: 1.3745e-04\n",
      "Epoch 940/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.7633e-04 - val_loss: 1.3728e-04\n",
      "Epoch 941/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 2.7601e-04 - val_loss: 1.3711e-04\n",
      "Epoch 942/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 2.7570e-04 - val_loss: 1.3694e-04\n",
      "Epoch 943/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.7540e-04 - val_loss: 1.3677e-04\n",
      "Epoch 944/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.7508e-04 - val_loss: 1.3660e-04\n",
      "Epoch 945/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.7477e-04 - val_loss: 1.3643e-04\n",
      "Epoch 946/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7447e-04 - val_loss: 1.3627e-04\n",
      "Epoch 947/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7415e-04 - val_loss: 1.3609e-04\n",
      "Epoch 948/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.7385e-04 - val_loss: 1.3593e-04\n",
      "Epoch 949/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 2.7354e-04 - val_loss: 1.3577e-04\n",
      "Epoch 950/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 2.7323e-04 - val_loss: 1.3560e-04\n",
      "Epoch 951/1000\n",
      "32/32 [==============================] - 0s 172us/step - loss: 2.7292e-04 - val_loss: 1.3544e-04\n",
      "Epoch 952/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.7261e-04 - val_loss: 1.3527e-04\n",
      "Epoch 953/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7231e-04 - val_loss: 1.3511e-04\n",
      "Epoch 954/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 2.7200e-04 - val_loss: 1.3495e-04\n",
      "Epoch 955/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.7170e-04 - val_loss: 1.3477e-04\n",
      "Epoch 956/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 2.7139e-04 - val_loss: 1.3461e-04\n",
      "Epoch 957/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 2.7109e-04 - val_loss: 1.3445e-04\n",
      "Epoch 958/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7078e-04 - val_loss: 1.3428e-04\n",
      "Epoch 959/1000\n",
      "32/32 [==============================] - 0s 160us/step - loss: 2.7048e-04 - val_loss: 1.3412e-04\n",
      "Epoch 960/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.7017e-04 - val_loss: 1.3395e-04\n",
      "Epoch 961/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 2.6987e-04 - val_loss: 1.3379e-04\n",
      "Epoch 962/1000\n",
      "32/32 [==============================] - 0s 164us/step - loss: 2.6957e-04 - val_loss: 1.3363e-04\n",
      "Epoch 963/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 2.6926e-04 - val_loss: 1.3347e-04\n",
      "Epoch 964/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 2.6896e-04 - val_loss: 1.3331e-04\n",
      "Epoch 965/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6866e-04 - val_loss: 1.3314e-04\n",
      "Epoch 966/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.6836e-04 - val_loss: 1.3298e-04\n",
      "Epoch 967/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 2.6806e-04 - val_loss: 1.3283e-04\n",
      "Epoch 968/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6776e-04 - val_loss: 1.3266e-04\n",
      "Epoch 969/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 2.6745e-04 - val_loss: 1.3250e-04\n",
      "Epoch 970/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.6715e-04 - val_loss: 1.3234e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 971/1000\n",
      "32/32 [==============================] - 0s 166us/step - loss: 2.6685e-04 - val_loss: 1.3218e-04\n",
      "Epoch 972/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.6655e-04 - val_loss: 1.3202e-04\n",
      "Epoch 973/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 2.6625e-04 - val_loss: 1.3186e-04\n",
      "Epoch 974/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.6596e-04 - val_loss: 1.3170e-04\n",
      "Epoch 975/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 2.6566e-04 - val_loss: 1.3153e-04\n",
      "Epoch 976/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 2.6536e-04 - val_loss: 1.3138e-04\n",
      "Epoch 977/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6506e-04 - val_loss: 1.3121e-04\n",
      "Epoch 978/1000\n",
      "32/32 [==============================] - 0s 137us/step - loss: 2.6477e-04 - val_loss: 1.3107e-04\n",
      "Epoch 979/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.6447e-04 - val_loss: 1.3090e-04\n",
      "Epoch 980/1000\n",
      "32/32 [==============================] - 0s 128us/step - loss: 2.6417e-04 - val_loss: 1.3074e-04\n",
      "Epoch 981/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.6388e-04 - val_loss: 1.3059e-04\n",
      "Epoch 982/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 2.6358e-04 - val_loss: 1.3043e-04\n",
      "Epoch 983/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6329e-04 - val_loss: 1.3026e-04\n",
      "Epoch 984/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6299e-04 - val_loss: 1.3011e-04\n",
      "Epoch 985/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.6270e-04 - val_loss: 1.2995e-04\n",
      "Epoch 986/1000\n",
      "32/32 [==============================] - 0s 145us/step - loss: 2.6240e-04 - val_loss: 1.2980e-04\n",
      "Epoch 987/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.6211e-04 - val_loss: 1.2964e-04\n",
      "Epoch 988/1000\n",
      "32/32 [==============================] - 0s 133us/step - loss: 2.6182e-04 - val_loss: 1.2949e-04\n",
      "Epoch 989/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 2.6152e-04 - val_loss: 1.2933e-04\n",
      "Epoch 990/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.6123e-04 - val_loss: 1.2917e-04\n",
      "Epoch 991/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.6094e-04 - val_loss: 1.2902e-04\n",
      "Epoch 992/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.6065e-04 - val_loss: 1.2887e-04\n",
      "Epoch 993/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.6035e-04 - val_loss: 1.2871e-04\n",
      "Epoch 994/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6006e-04 - val_loss: 1.2855e-04\n",
      "Epoch 995/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 2.5977e-04 - val_loss: 1.2840e-04\n",
      "Epoch 996/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5948e-04 - val_loss: 1.2824e-04\n",
      "Epoch 997/1000\n",
      "32/32 [==============================] - 0s 133us/step - loss: 2.5919e-04 - val_loss: 1.2808e-04\n",
      "Epoch 998/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5890e-04 - val_loss: 1.2794e-04\n",
      "Epoch 999/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5861e-04 - val_loss: 1.2778e-04\n",
      "Epoch 1000/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 2.5832e-04 - val_loss: 1.2763e-04\n",
      "0.00026271058595739305\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-1.07478216e-01, -5.58431819e-02,  9.23008502e-01,\n",
       "         -5.87950826e-01,  8.97495210e-01, -3.01526189e-02,\n",
       "          3.88361424e-01, -1.01253033e-01, -8.32183063e-01,\n",
       "         -1.19513474e-01],\n",
       "        [ 3.74152027e-02, -8.65451038e-01,  3.45074326e-01,\n",
       "          7.02221245e-02, -4.63429213e-01,  8.10471475e-01,\n",
       "          1.02656221e+00,  7.70139595e-05, -4.87237424e-02,\n",
       "          2.29491323e-01],\n",
       "        [ 1.49718419e-01,  6.35132253e-01,  3.38352472e-01,\n",
       "         -1.11239564e+00,  1.41564339e-01, -1.21264923e+00,\n",
       "          6.95713520e-01,  3.55192670e-03, -1.32241797e+00,\n",
       "          4.49131802e-03]], dtype=float32),\n",
       " array([ 0.7795621 , -0.5692419 ,  0.364034  ,  0.14495759, -0.400672  ,\n",
       "         0.21324238, -0.5116837 , -0.6678646 , -0.02342039, -0.5632702 ],\n",
       "       dtype=float32),\n",
       " array([[ 0.8497109 , -0.30677885, -0.8839    , -0.67220974, -0.61050785],\n",
       "        [-0.20088618, -0.73185647,  0.4013172 , -0.02770892,  0.6377881 ],\n",
       "        [-0.12236369, -0.22878511, -0.40708005, -0.36975816,  0.34827462],\n",
       "        [-0.5777654 , -0.3363981 , -0.22235344,  0.48563915, -0.2757953 ],\n",
       "        [ 0.24210732,  0.04636609,  0.02333532,  0.3179252 ,  0.5462856 ],\n",
       "        [ 0.37702116, -0.48487604,  0.23043828, -0.593739  ,  0.14023387],\n",
       "        [-0.29031047, -0.02123107,  0.5195135 ,  0.28330338,  0.31839368],\n",
       "        [-0.39052224, -0.50252694,  0.52243537,  0.48160842,  0.35075116],\n",
       "        [-0.24628806, -0.09237266,  0.7594861 , -0.43901068,  0.4231176 ],\n",
       "        [-0.51532805, -0.33547348,  0.10614342,  0.46784508,  0.37226218]],\n",
       "       dtype=float32),\n",
       " array([ 0.832223  ,  0.7242868 , -0.85981995, -0.8751619 , -0.8441114 ],\n",
       "       dtype=float32),\n",
       " array([[ 0.5108112 ],\n",
       "        [ 0.25073263],\n",
       "        [-0.61044174],\n",
       "        [-0.6938629 ],\n",
       "        [-0.48060706]], dtype=float32),\n",
       " array([0.9213898], dtype=float32)]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_challenger, history_challenger, evaluate_challenger=NN_model_structure_regression_4(X_train_challenger, X_val_challenger, Y_train_challenger, Y_val_challenger, adam2, 32, 1000, x_test_challenger, y_test_challenger)\n",
    "model_challenger.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_challenger.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_challenger_structure4_4th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_67 (Dense)             (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 161\n",
      "Trainable params: 161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 32 samples, validate on 7 samples\n",
      "Epoch 1/1000\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 37.0808 - val_loss: 33.8976\n",
      "Epoch 2/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 33.0801 - val_loss: 27.0151\n",
      "Epoch 3/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 28.5510 - val_loss: 20.4497\n",
      "Epoch 4/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 23.0200 - val_loss: 13.6457\n",
      "Epoch 5/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 16.1668 - val_loss: 7.2101\n",
      "Epoch 6/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.6398 - val_loss: 2.6385\n",
      "Epoch 7/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.5837 - val_loss: 2.3588\n",
      "Epoch 8/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.9145 - val_loss: 5.3357\n",
      "Epoch 9/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 6.7632 - val_loss: 5.6432\n",
      "Epoch 10/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.5281 - val_loss: 3.4113\n",
      "Epoch 11/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3861 - val_loss: 1.4300\n",
      "Epoch 12/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.4781 - val_loss: 0.9931\n",
      "Epoch 13/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.4803 - val_loss: 1.8156\n",
      "Epoch 14/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 1.0286 - val_loss: 2.9933\n",
      "Epoch 15/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1014 - val_loss: 3.8239\n",
      "Epoch 16/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8919 - val_loss: 4.0766\n",
      "Epoch 17/1000\n",
      "32/32 [==============================] - 0s 160us/step - loss: 3.1133 - val_loss: 3.8100\n",
      "Epoch 18/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 2.8253 - val_loss: 3.1826\n",
      "Epoch 19/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.2183 - val_loss: 2.3685\n",
      "Epoch 20/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.4983 - val_loss: 1.5395\n",
      "Epoch 21/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 0.8430 - val_loss: 0.8696\n",
      "Epoch 22/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.3919 - val_loss: 0.5179\n",
      "Epoch 23/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 0.2338 - val_loss: 0.5544\n",
      "Epoch 24/1000\n",
      "32/32 [==============================] - 0s 113us/step - loss: 0.3668 - val_loss: 0.8704\n",
      "Epoch 25/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.6614 - val_loss: 1.1953\n",
      "Epoch 26/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.9031 - val_loss: 1.2778\n",
      "Epoch 27/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.9308 - val_loss: 1.0634\n",
      "Epoch 28/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 0.7442 - val_loss: 0.6883\n",
      "Epoch 29/1000\n",
      "32/32 [==============================] - 0s 162us/step - loss: 0.4689 - val_loss: 0.3378\n",
      "Epoch 30/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.2440 - val_loss: 0.1262\n",
      "Epoch 31/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 0.1417 - val_loss: 0.0670\n",
      "Epoch 32/1000\n",
      "32/32 [==============================] - 0s 127us/step - loss: 0.1580 - val_loss: 0.1072\n",
      "Epoch 33/1000\n",
      "32/32 [==============================] - 0s 132us/step - loss: 0.2426 - val_loss: 0.1776\n",
      "Epoch 34/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 0.3358 - val_loss: 0.2263\n",
      "Epoch 35/1000\n",
      "32/32 [==============================] - 0s 131us/step - loss: 0.3923 - val_loss: 0.2307\n",
      "Epoch 36/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.3903 - val_loss: 0.1936\n",
      "Epoch 37/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 0.3324 - val_loss: 0.1337\n",
      "Epoch 38/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.2397 - val_loss: 0.0740\n",
      "Epoch 39/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1432 - val_loss: 0.0334\n",
      "Epoch 40/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0722 - val_loss: 0.0200\n",
      "Epoch 41/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 0.0433 - val_loss: 0.0299\n",
      "Epoch 42/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 0.0545 - val_loss: 0.0500\n",
      "Epoch 43/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0879 - val_loss: 0.0660\n",
      "Epoch 44/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.1199 - val_loss: 0.0690\n",
      "Epoch 45/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1338 - val_loss: 0.0595\n",
      "Epoch 46/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1251 - val_loss: 0.0446\n",
      "Epoch 47/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1000 - val_loss: 0.0334\n",
      "Epoch 48/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0694 - val_loss: 0.0319\n",
      "Epoch 49/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0439 - val_loss: 0.0409\n",
      "Epoch 50/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0297 - val_loss: 0.0567\n",
      "Epoch 51/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0284 - val_loss: 0.0729\n",
      "Epoch 52/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0366 - val_loss: 0.0833\n",
      "Epoch 53/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0480 - val_loss: 0.0844\n",
      "Epoch 54/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0557 - val_loss: 0.0759\n",
      "Epoch 55/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0556 - val_loss: 0.0607\n",
      "Epoch 56/1000\n",
      "32/32 [==============================] - 0s 177us/step - loss: 0.0475 - val_loss: 0.0430\n",
      "Epoch 57/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0346 - val_loss: 0.0267\n",
      "Epoch 58/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0217 - val_loss: 0.0143\n",
      "Epoch 59/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 0.0129 - val_loss: 0.0067\n",
      "Epoch 60/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0101 - val_loss: 0.0032\n",
      "Epoch 61/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0126 - val_loss: 0.0026\n",
      "Epoch 62/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0179 - val_loss: 0.0034\n",
      "Epoch 63/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0228 - val_loss: 0.0040\n",
      "Epoch 64/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0249 - val_loss: 0.0038\n",
      "Epoch 65/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 0.0234 - val_loss: 0.0029\n",
      "Epoch 66/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0190 - val_loss: 0.0019\n",
      "Epoch 67/1000\n",
      "32/32 [==============================] - 0s 168us/step - loss: 0.0138 - val_loss: 0.0020\n",
      "Epoch 68/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0098 - val_loss: 0.0036\n",
      "Epoch 69/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 0.0083 - val_loss: 0.0064\n",
      "Epoch 70/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0090 - val_loss: 0.0095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0109 - val_loss: 0.0121\n",
      "Epoch 72/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0127 - val_loss: 0.0136\n",
      "Epoch 73/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0134 - val_loss: 0.0138\n",
      "Epoch 74/1000\n",
      "32/32 [==============================] - 0s 132us/step - loss: 0.0128 - val_loss: 0.0128\n",
      "Epoch 75/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 0.0112 - val_loss: 0.0112\n",
      "Epoch 76/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0094 - val_loss: 0.0093\n",
      "Epoch 77/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0079 - val_loss: 0.0073\n",
      "Epoch 78/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 0.0071 - val_loss: 0.0058\n",
      "Epoch 79/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0071 - val_loss: 0.0047\n",
      "Epoch 80/1000\n",
      "32/32 [==============================] - 0s 130us/step - loss: 0.0075 - val_loss: 0.0043\n",
      "Epoch 81/1000\n",
      "32/32 [==============================] - 0s 129us/step - loss: 0.0082 - val_loss: 0.0042\n",
      "Epoch 82/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0086 - val_loss: 0.0043\n",
      "Epoch 83/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0087 - val_loss: 0.0044\n",
      "Epoch 84/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 0.0083 - val_loss: 0.0046\n",
      "Epoch 85/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0077 - val_loss: 0.0050\n",
      "Epoch 86/1000\n",
      "32/32 [==============================] - 0s 162us/step - loss: 0.0070 - val_loss: 0.0057\n",
      "Epoch 87/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0066 - val_loss: 0.0066\n",
      "Epoch 88/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 0.0064 - val_loss: 0.0077\n",
      "Epoch 89/1000\n",
      "32/32 [==============================] - 0s 138us/step - loss: 0.0064 - val_loss: 0.0087\n",
      "Epoch 90/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0065 - val_loss: 0.0094\n",
      "Epoch 91/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0067 - val_loss: 0.0097\n",
      "Epoch 92/1000\n",
      "32/32 [==============================] - 0s 158us/step - loss: 0.0067 - val_loss: 0.0094\n",
      "Epoch 93/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0066 - val_loss: 0.0086\n",
      "Epoch 94/1000\n",
      "32/32 [==============================] - 0s 119us/step - loss: 0.0064 - val_loss: 0.0075\n",
      "Epoch 95/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0061 - val_loss: 0.0064\n",
      "Epoch 96/1000\n",
      "32/32 [==============================] - 0s 161us/step - loss: 0.0058 - val_loss: 0.0054\n",
      "Epoch 97/1000\n",
      "32/32 [==============================] - 0s 117us/step - loss: 0.0057 - val_loss: 0.0045\n",
      "Epoch 98/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0056 - val_loss: 0.0040\n",
      "Epoch 99/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0057 - val_loss: 0.0036\n",
      "Epoch 100/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0058 - val_loss: 0.0034\n",
      "Epoch 101/1000\n",
      "32/32 [==============================] - 0s 120us/step - loss: 0.0058 - val_loss: 0.0034\n",
      "Epoch 102/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0057 - val_loss: 0.0035\n",
      "Epoch 103/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0056 - val_loss: 0.0037\n",
      "Epoch 104/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0055 - val_loss: 0.0040\n",
      "Epoch 105/1000\n",
      "32/32 [==============================] - 0s 164us/step - loss: 0.0053 - val_loss: 0.0044\n",
      "Epoch 106/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0052 - val_loss: 0.0048\n",
      "Epoch 107/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0052 - val_loss: 0.0052\n",
      "Epoch 108/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0052 - val_loss: 0.0055\n",
      "Epoch 109/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0052 - val_loss: 0.0057\n",
      "Epoch 110/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0051 - val_loss: 0.0058\n",
      "Epoch 111/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0051 - val_loss: 0.0056\n",
      "Epoch 112/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0050 - val_loss: 0.0054\n",
      "Epoch 113/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0050 - val_loss: 0.0051\n",
      "Epoch 114/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0049 - val_loss: 0.0048\n",
      "Epoch 115/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 116/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 0.0048 - val_loss: 0.0044\n",
      "Epoch 117/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0047 - val_loss: 0.0043\n",
      "Epoch 118/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0047 - val_loss: 0.0042\n",
      "Epoch 119/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 0.0047 - val_loss: 0.0041\n",
      "Epoch 120/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0047 - val_loss: 0.0042\n",
      "Epoch 121/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0046 - val_loss: 0.0042\n",
      "Epoch 122/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0046 - val_loss: 0.0043\n",
      "Epoch 123/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 124/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 125/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 126/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 127/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 128/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0043 - val_loss: 0.0045\n",
      "Epoch 129/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 130/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 131/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 132/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0042 - val_loss: 0.0041\n",
      "Epoch 133/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 134/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 135/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0041 - val_loss: 0.0039\n",
      "Epoch 136/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 137/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 138/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 139/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 140/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 141/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 142/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 143/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 0.0038 - val_loss: 0.0041\n",
      "Epoch 144/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0038 - val_loss: 0.0041\n",
      "Epoch 145/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0038 - val_loss: 0.0041\n",
      "Epoch 146/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0037 - val_loss: 0.0042\n",
      "Epoch 147/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0037 - val_loss: 0.0042\n",
      "Epoch 148/1000\n",
      "32/32 [==============================] - 0s 196us/step - loss: 0.0037 - val_loss: 0.0042\n",
      "Epoch 149/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0037 - val_loss: 0.0042\n",
      "Epoch 150/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0036 - val_loss: 0.0042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0036 - val_loss: 0.0041\n",
      "Epoch 152/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 0.0036 - val_loss: 0.0041\n",
      "Epoch 153/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0035 - val_loss: 0.0041\n",
      "Epoch 154/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0035 - val_loss: 0.0040\n",
      "Epoch 155/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0035 - val_loss: 0.0040\n",
      "Epoch 156/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0035 - val_loss: 0.0040\n",
      "Epoch 157/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0034 - val_loss: 0.0040\n",
      "Epoch 158/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0034 - val_loss: 0.0040\n",
      "Epoch 159/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0034 - val_loss: 0.0040\n",
      "Epoch 160/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0034 - val_loss: 0.0040\n",
      "Epoch 161/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0033 - val_loss: 0.0040\n",
      "Epoch 162/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 0.0040\n",
      "Epoch 163/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0033 - val_loss: 0.0040\n",
      "Epoch 164/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0033 - val_loss: 0.0040\n",
      "Epoch 165/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0032 - val_loss: 0.0040\n",
      "Epoch 166/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 0.0039\n",
      "Epoch 167/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 0.0039\n",
      "Epoch 168/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0032 - val_loss: 0.0039\n",
      "Epoch 169/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0032 - val_loss: 0.0039\n",
      "Epoch 170/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0031 - val_loss: 0.0039\n",
      "Epoch 171/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 0.0031 - val_loss: 0.0038\n",
      "Epoch 172/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 0.0031 - val_loss: 0.0038\n",
      "Epoch 173/1000\n",
      "32/32 [==============================] - 0s 184us/step - loss: 0.0031 - val_loss: 0.0038\n",
      "Epoch 174/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 0.0030 - val_loss: 0.0038\n",
      "Epoch 175/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 0.0030 - val_loss: 0.0038\n",
      "Epoch 176/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0030 - val_loss: 0.0038\n",
      "Epoch 177/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 0.0038\n",
      "Epoch 178/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 179/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0029 - val_loss: 0.0037\n",
      "Epoch 180/1000\n",
      "32/32 [==============================] - 0s 169us/step - loss: 0.0029 - val_loss: 0.0037\n",
      "Epoch 181/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0029 - val_loss: 0.0037\n",
      "Epoch 182/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0029 - val_loss: 0.0037\n",
      "Epoch 183/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 0.0037\n",
      "Epoch 184/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 0.0028 - val_loss: 0.0037\n",
      "Epoch 185/1000\n",
      "32/32 [==============================] - 0s 170us/step - loss: 0.0028 - val_loss: 0.0037\n",
      "Epoch 186/1000\n",
      "32/32 [==============================] - 0s 174us/step - loss: 0.0028 - val_loss: 0.0037\n",
      "Epoch 187/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 188/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 189/1000\n",
      "32/32 [==============================] - 0s 173us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 190/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 191/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 192/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 193/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 194/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 195/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 196/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 197/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 198/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 199/1000\n",
      "32/32 [==============================] - 0s 180us/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 200/1000\n",
      "32/32 [==============================] - 0s 180us/step - loss: 0.0026 - val_loss: 0.0034\n",
      "Epoch 201/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 0.0034\n",
      "Epoch 202/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 0.0034\n",
      "Epoch 203/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 0.0025 - val_loss: 0.0034\n",
      "Epoch 204/1000\n",
      "32/32 [==============================] - 0s 160us/step - loss: 0.0025 - val_loss: 0.0034\n",
      "Epoch 205/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 0.0034\n",
      "Epoch 206/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 0.0034\n",
      "Epoch 207/1000\n",
      "32/32 [==============================] - 0s 129us/step - loss: 0.0024 - val_loss: 0.0033\n",
      "Epoch 208/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.0033\n",
      "Epoch 209/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0024 - val_loss: 0.0033\n",
      "Epoch 210/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.0033\n",
      "Epoch 211/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.0033\n",
      "Epoch 212/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.0033\n",
      "Epoch 213/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0024 - val_loss: 0.0033\n",
      "Epoch 214/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0023 - val_loss: 0.0033\n",
      "Epoch 215/1000\n",
      "32/32 [==============================] - 0s 170us/step - loss: 0.0023 - val_loss: 0.0032\n",
      "Epoch 216/1000\n",
      "32/32 [==============================] - 0s 133us/step - loss: 0.0023 - val_loss: 0.0032\n",
      "Epoch 217/1000\n",
      "32/32 [==============================] - 0s 164us/step - loss: 0.0023 - val_loss: 0.0032\n",
      "Epoch 218/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0023 - val_loss: 0.0032\n",
      "Epoch 219/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.0032\n",
      "Epoch 220/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0023 - val_loss: 0.0032\n",
      "Epoch 221/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0032\n",
      "Epoch 222/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0031\n",
      "Epoch 223/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 0.0022 - val_loss: 0.0031\n",
      "Epoch 224/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0031\n",
      "Epoch 225/1000\n",
      "32/32 [==============================] - 0s 128us/step - loss: 0.0022 - val_loss: 0.0031\n",
      "Epoch 226/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0031\n",
      "Epoch 227/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0031\n",
      "Epoch 228/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0022 - val_loss: 0.0031\n",
      "Epoch 229/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 0.0021 - val_loss: 0.0031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 230/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 231/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 232/1000\n",
      "32/32 [==============================] - 0s 167us/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 233/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 234/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 235/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 236/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 237/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0020 - val_loss: 0.0030\n",
      "Epoch 238/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 239/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 240/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 241/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 242/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 243/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 244/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 245/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 246/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 247/1000\n",
      "32/32 [==============================] - 0s 122us/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 248/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 249/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 250/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 251/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 252/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 253/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 254/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0027\n",
      "Epoch 255/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0027\n",
      "Epoch 256/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 0.0018 - val_loss: 0.0027\n",
      "Epoch 257/1000\n",
      "32/32 [==============================] - 0s 138us/step - loss: 0.0018 - val_loss: 0.0027\n",
      "Epoch 258/1000\n",
      "32/32 [==============================] - 0s 170us/step - loss: 0.0018 - val_loss: 0.0027\n",
      "Epoch 259/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 0.0018 - val_loss: 0.0027\n",
      "Epoch 260/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0018 - val_loss: 0.0027\n",
      "Epoch 261/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 0.0018 - val_loss: 0.0027\n",
      "Epoch 262/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 0.0027\n",
      "Epoch 263/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0026\n",
      "Epoch 264/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 0.0018 - val_loss: 0.0026\n",
      "Epoch 265/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0026\n",
      "Epoch 266/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0026\n",
      "Epoch 267/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0026\n",
      "Epoch 268/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0017 - val_loss: 0.0026\n",
      "Epoch 269/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0026\n",
      "Epoch 270/1000\n",
      "32/32 [==============================] - 0s 117us/step - loss: 0.0017 - val_loss: 0.0026\n",
      "Epoch 271/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0025\n",
      "Epoch 272/1000\n",
      "32/32 [==============================] - 0s 130us/step - loss: 0.0017 - val_loss: 0.0025\n",
      "Epoch 273/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0025\n",
      "Epoch 274/1000\n",
      "32/32 [==============================] - 0s 145us/step - loss: 0.0017 - val_loss: 0.0025\n",
      "Epoch 275/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 0.0017 - val_loss: 0.0025\n",
      "Epoch 276/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0025\n",
      "Epoch 277/1000\n",
      "32/32 [==============================] - 0s 185us/step - loss: 0.0016 - val_loss: 0.0025\n",
      "Epoch 278/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0025\n",
      "Epoch 279/1000\n",
      "32/32 [==============================] - 0s 162us/step - loss: 0.0016 - val_loss: 0.0025\n",
      "Epoch 280/1000\n",
      "32/32 [==============================] - 0s 128us/step - loss: 0.0016 - val_loss: 0.0025\n",
      "Epoch 281/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0024\n",
      "Epoch 282/1000\n",
      "32/32 [==============================] - 0s 145us/step - loss: 0.0016 - val_loss: 0.0024\n",
      "Epoch 283/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0016 - val_loss: 0.0024\n",
      "Epoch 284/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0024\n",
      "Epoch 285/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0024\n",
      "Epoch 286/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 0.0024\n",
      "Epoch 287/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 0.0016 - val_loss: 0.0024\n",
      "Epoch 288/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 0.0024\n",
      "Epoch 289/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 0.0024\n",
      "Epoch 290/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0015 - val_loss: 0.0023\n",
      "Epoch 291/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0023\n",
      "Epoch 292/1000\n",
      "32/32 [==============================] - 0s 137us/step - loss: 0.0015 - val_loss: 0.0023\n",
      "Epoch 293/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 0.0015 - val_loss: 0.0023\n",
      "Epoch 294/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0015 - val_loss: 0.0023\n",
      "Epoch 295/1000\n",
      "32/32 [==============================] - 0s 162us/step - loss: 0.0015 - val_loss: 0.0023\n",
      "Epoch 296/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0023\n",
      "Epoch 297/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0023\n",
      "Epoch 298/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0023\n",
      "Epoch 299/1000\n",
      "32/32 [==============================] - 0s 164us/step - loss: 0.0015 - val_loss: 0.0023\n",
      "Epoch 300/1000\n",
      "32/32 [==============================] - 0s 145us/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 301/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 0.0014 - val_loss: 0.0022\n",
      "Epoch 302/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0014 - val_loss: 0.0022\n",
      "Epoch 303/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0022\n",
      "Epoch 304/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0014 - val_loss: 0.0022\n",
      "Epoch 305/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0022\n",
      "Epoch 306/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 0.0014 - val_loss: 0.0022\n",
      "Epoch 307/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0014 - val_loss: 0.0022\n",
      "Epoch 308/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 309/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 0.0014 - val_loss: 0.0022\n",
      "Epoch 310/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 311/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 312/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 313/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 314/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 315/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 0.0013 - val_loss: 0.0021\n",
      "Epoch 316/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0021\n",
      "Epoch 317/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0021\n",
      "Epoch 318/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0013 - val_loss: 0.0021\n",
      "Epoch 319/1000\n",
      "32/32 [==============================] - 0s 118us/step - loss: 0.0013 - val_loss: 0.0021\n",
      "Epoch 320/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0021\n",
      "Epoch 321/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 322/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 323/1000\n",
      "32/32 [==============================] - 0s 133us/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 324/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 325/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 326/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 327/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 328/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 329/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 330/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 331/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 332/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 333/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 334/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 335/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 336/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 337/1000\n",
      "32/32 [==============================] - 0s 145us/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 338/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 339/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 340/1000\n",
      "32/32 [==============================] - 0s 138us/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 341/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 342/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 343/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 344/1000\n",
      "32/32 [==============================] - 0s 132us/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 345/1000\n",
      "32/32 [==============================] - 0s 132us/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 346/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 347/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 348/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 349/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 350/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 351/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 352/1000\n",
      "32/32 [==============================] - 0s 138us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 353/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 354/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 355/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 356/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 357/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 358/1000\n",
      "32/32 [==============================] - 0s 158us/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 359/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 360/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 361/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 362/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 363/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 364/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 365/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 366/1000\n",
      "32/32 [==============================] - 0s 171us/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 367/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 368/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 369/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 370/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 371/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 372/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 373/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 374/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 375/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 376/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 377/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.9977e-04 - val_loss: 0.0016\n",
      "Epoch 378/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 9.9516e-04 - val_loss: 0.0016\n",
      "Epoch 379/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.9059e-04 - val_loss: 0.0016\n",
      "Epoch 380/1000\n",
      "32/32 [==============================] - 0s 190us/step - loss: 9.8604e-04 - val_loss: 0.0016\n",
      "Epoch 381/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.8151e-04 - val_loss: 0.0016\n",
      "Epoch 382/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.7702e-04 - val_loss: 0.0016\n",
      "Epoch 383/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.7254e-04 - val_loss: 0.0016\n",
      "Epoch 384/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.6809e-04 - val_loss: 0.0016\n",
      "Epoch 385/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6366e-04 - val_loss: 0.0016\n",
      "Epoch 386/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.5926e-04 - val_loss: 0.0016\n",
      "Epoch 387/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.5489e-04 - val_loss: 0.0015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 388/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.5055e-04 - val_loss: 0.0015\n",
      "Epoch 389/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.4623e-04 - val_loss: 0.0015\n",
      "Epoch 390/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 9.4191e-04 - val_loss: 0.0015\n",
      "Epoch 391/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.3764e-04 - val_loss: 0.0015\n",
      "Epoch 392/1000\n",
      "32/32 [==============================] - 0s 169us/step - loss: 9.3338e-04 - val_loss: 0.0015\n",
      "Epoch 393/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 9.2915e-04 - val_loss: 0.0015\n",
      "Epoch 394/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.2495e-04 - val_loss: 0.0015\n",
      "Epoch 395/1000\n",
      "32/32 [==============================] - 0s 114us/step - loss: 9.2077e-04 - val_loss: 0.0015\n",
      "Epoch 396/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 9.1661e-04 - val_loss: 0.0015\n",
      "Epoch 397/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 9.1247e-04 - val_loss: 0.0015\n",
      "Epoch 398/1000\n",
      "32/32 [==============================] - 0s 128us/step - loss: 9.0835e-04 - val_loss: 0.0015\n",
      "Epoch 399/1000\n",
      "32/32 [==============================] - 0s 162us/step - loss: 9.0426e-04 - val_loss: 0.0015\n",
      "Epoch 400/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.0019e-04 - val_loss: 0.0015\n",
      "Epoch 401/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 8.9615e-04 - val_loss: 0.0015\n",
      "Epoch 402/1000\n",
      "32/32 [==============================] - 0s 160us/step - loss: 8.9213e-04 - val_loss: 0.0015\n",
      "Epoch 403/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 8.8812e-04 - val_loss: 0.0014\n",
      "Epoch 404/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.8415e-04 - val_loss: 0.0014\n",
      "Epoch 405/1000\n",
      "32/32 [==============================] - 0s 161us/step - loss: 8.8018e-04 - val_loss: 0.0014\n",
      "Epoch 406/1000\n",
      "32/32 [==============================] - 0s 163us/step - loss: 8.7625e-04 - val_loss: 0.0014\n",
      "Epoch 407/1000\n",
      "32/32 [==============================] - 0s 170us/step - loss: 8.7234e-04 - val_loss: 0.0014\n",
      "Epoch 408/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.6845e-04 - val_loss: 0.0014\n",
      "Epoch 409/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.6457e-04 - val_loss: 0.0014\n",
      "Epoch 410/1000\n",
      "32/32 [==============================] - 0s 160us/step - loss: 8.6071e-04 - val_loss: 0.0014\n",
      "Epoch 411/1000\n",
      "32/32 [==============================] - 0s 138us/step - loss: 8.5689e-04 - val_loss: 0.0014\n",
      "Epoch 412/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5308e-04 - val_loss: 0.0014\n",
      "Epoch 413/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 8.4929e-04 - val_loss: 0.0014\n",
      "Epoch 414/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.4552e-04 - val_loss: 0.0014\n",
      "Epoch 415/1000\n",
      "32/32 [==============================] - 0s 161us/step - loss: 8.4177e-04 - val_loss: 0.0014\n",
      "Epoch 416/1000\n",
      "32/32 [==============================] - 0s 169us/step - loss: 8.3805e-04 - val_loss: 0.0014\n",
      "Epoch 417/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 8.3434e-04 - val_loss: 0.0014\n",
      "Epoch 418/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.3064e-04 - val_loss: 0.0014\n",
      "Epoch 419/1000\n",
      "32/32 [==============================] - 0s 171us/step - loss: 8.2699e-04 - val_loss: 0.0014\n",
      "Epoch 420/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2333e-04 - val_loss: 0.0014\n",
      "Epoch 421/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.1970e-04 - val_loss: 0.0013\n",
      "Epoch 422/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 8.1609e-04 - val_loss: 0.0013\n",
      "Epoch 423/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 8.1250e-04 - val_loss: 0.0013\n",
      "Epoch 424/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 8.0893e-04 - val_loss: 0.0013\n",
      "Epoch 425/1000\n",
      "32/32 [==============================] - 0s 166us/step - loss: 8.0537e-04 - val_loss: 0.0013\n",
      "Epoch 426/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0184e-04 - val_loss: 0.0013\n",
      "Epoch 427/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.9832e-04 - val_loss: 0.0013\n",
      "Epoch 428/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 7.9484e-04 - val_loss: 0.0013\n",
      "Epoch 429/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9136e-04 - val_loss: 0.0013\n",
      "Epoch 430/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8789e-04 - val_loss: 0.0013\n",
      "Epoch 431/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8445e-04 - val_loss: 0.0013\n",
      "Epoch 432/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8103e-04 - val_loss: 0.0013\n",
      "Epoch 433/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.7763e-04 - val_loss: 0.0013\n",
      "Epoch 434/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.7423e-04 - val_loss: 0.0013\n",
      "Epoch 435/1000\n",
      "32/32 [==============================] - 0s 171us/step - loss: 7.7087e-04 - val_loss: 0.0013\n",
      "Epoch 436/1000\n",
      "32/32 [==============================] - 0s 176us/step - loss: 7.6752e-04 - val_loss: 0.0013\n",
      "Epoch 437/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6418e-04 - val_loss: 0.0013\n",
      "Epoch 438/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 7.6087e-04 - val_loss: 0.0013\n",
      "Epoch 439/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5757e-04 - val_loss: 0.0013\n",
      "Epoch 440/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5429e-04 - val_loss: 0.0013\n",
      "Epoch 441/1000\n",
      "32/32 [==============================] - 0s 167us/step - loss: 7.5102e-04 - val_loss: 0.0012\n",
      "Epoch 442/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.4777e-04 - val_loss: 0.0012\n",
      "Epoch 443/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.4454e-04 - val_loss: 0.0012\n",
      "Epoch 444/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4133e-04 - val_loss: 0.0012\n",
      "Epoch 445/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.3813e-04 - val_loss: 0.0012\n",
      "Epoch 446/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.3495e-04 - val_loss: 0.0012\n",
      "Epoch 447/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.3179e-04 - val_loss: 0.0012\n",
      "Epoch 448/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.2864e-04 - val_loss: 0.0012\n",
      "Epoch 449/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.2551e-04 - val_loss: 0.0012\n",
      "Epoch 450/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.2240e-04 - val_loss: 0.0012\n",
      "Epoch 451/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.1929e-04 - val_loss: 0.0012\n",
      "Epoch 452/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1621e-04 - val_loss: 0.0012\n",
      "Epoch 453/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.1314e-04 - val_loss: 0.0012\n",
      "Epoch 454/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.1009e-04 - val_loss: 0.0012\n",
      "Epoch 455/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 7.0705e-04 - val_loss: 0.0012\n",
      "Epoch 456/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.0403e-04 - val_loss: 0.0012\n",
      "Epoch 457/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0103e-04 - val_loss: 0.0012\n",
      "Epoch 458/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9805e-04 - val_loss: 0.0012\n",
      "Epoch 459/1000\n",
      "32/32 [==============================] - 0s 163us/step - loss: 6.9506e-04 - val_loss: 0.0012\n",
      "Epoch 460/1000\n",
      "32/32 [==============================] - 0s 172us/step - loss: 6.9210e-04 - val_loss: 0.0012\n",
      "Epoch 461/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8916e-04 - val_loss: 0.0012\n",
      "Epoch 462/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.8623e-04 - val_loss: 0.0011\n",
      "Epoch 463/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8332e-04 - val_loss: 0.0011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 464/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8041e-04 - val_loss: 0.0011\n",
      "Epoch 465/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7752e-04 - val_loss: 0.0011\n",
      "Epoch 466/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7466e-04 - val_loss: 0.0011\n",
      "Epoch 467/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.7181e-04 - val_loss: 0.0011\n",
      "Epoch 468/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.6897e-04 - val_loss: 0.0011\n",
      "Epoch 469/1000\n",
      "32/32 [==============================] - 0s 165us/step - loss: 6.6613e-04 - val_loss: 0.0011\n",
      "Epoch 470/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6333e-04 - val_loss: 0.0011\n",
      "Epoch 471/1000\n",
      "32/32 [==============================] - 0s 129us/step - loss: 6.6053e-04 - val_loss: 0.0011\n",
      "Epoch 472/1000\n",
      "32/32 [==============================] - 0s 137us/step - loss: 6.5774e-04 - val_loss: 0.0011\n",
      "Epoch 473/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5497e-04 - val_loss: 0.0011\n",
      "Epoch 474/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5222e-04 - val_loss: 0.0011\n",
      "Epoch 475/1000\n",
      "32/32 [==============================] - 0s 161us/step - loss: 6.4948e-04 - val_loss: 0.0011\n",
      "Epoch 476/1000\n",
      "32/32 [==============================] - 0s 170us/step - loss: 6.4674e-04 - val_loss: 0.0011\n",
      "Epoch 477/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4403e-04 - val_loss: 0.0011\n",
      "Epoch 478/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4133e-04 - val_loss: 0.0011\n",
      "Epoch 479/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3863e-04 - val_loss: 0.0011\n",
      "Epoch 480/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.3596e-04 - val_loss: 0.0011\n",
      "Epoch 481/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3330e-04 - val_loss: 0.0011\n",
      "Epoch 482/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3065e-04 - val_loss: 0.0011\n",
      "Epoch 483/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.2802e-04 - val_loss: 0.0011\n",
      "Epoch 484/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 6.2539e-04 - val_loss: 0.0011\n",
      "Epoch 485/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2278e-04 - val_loss: 0.0011\n",
      "Epoch 486/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2019e-04 - val_loss: 0.0011\n",
      "Epoch 487/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 6.1761e-04 - val_loss: 0.0010\n",
      "Epoch 488/1000\n",
      "32/32 [==============================] - 0s 208us/step - loss: 6.1504e-04 - val_loss: 0.0010\n",
      "Epoch 489/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 6.1249e-04 - val_loss: 0.0010\n",
      "Epoch 490/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 6.0994e-04 - val_loss: 0.0010\n",
      "Epoch 491/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0741e-04 - val_loss: 0.0010\n",
      "Epoch 492/1000\n",
      "32/32 [==============================] - 0s 169us/step - loss: 6.0489e-04 - val_loss: 0.0010\n",
      "Epoch 493/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0238e-04 - val_loss: 0.0010\n",
      "Epoch 494/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.9989e-04 - val_loss: 0.0010\n",
      "Epoch 495/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9740e-04 - val_loss: 0.0010\n",
      "Epoch 496/1000\n",
      "32/32 [==============================] - 0s 168us/step - loss: 5.9494e-04 - val_loss: 0.0010\n",
      "Epoch 497/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 5.9248e-04 - val_loss: 0.0010\n",
      "Epoch 498/1000\n",
      "32/32 [==============================] - 0s 166us/step - loss: 5.9003e-04 - val_loss: 0.0010\n",
      "Epoch 499/1000\n",
      "32/32 [==============================] - 0s 162us/step - loss: 5.8760e-04 - val_loss: 0.0010\n",
      "Epoch 500/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8517e-04 - val_loss: 9.9757e-04\n",
      "Epoch 501/1000\n",
      "32/32 [==============================] - 0s 133us/step - loss: 5.8276e-04 - val_loss: 9.9392e-04\n",
      "Epoch 502/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.8037e-04 - val_loss: 9.9029e-04\n",
      "Epoch 503/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.7798e-04 - val_loss: 9.8671e-04\n",
      "Epoch 504/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.7561e-04 - val_loss: 9.8308e-04\n",
      "Epoch 505/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 5.7324e-04 - val_loss: 9.7950e-04\n",
      "Epoch 506/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 5.7089e-04 - val_loss: 9.7597e-04\n",
      "Epoch 507/1000\n",
      "32/32 [==============================] - 0s 138us/step - loss: 5.6855e-04 - val_loss: 9.7245e-04\n",
      "Epoch 508/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6621e-04 - val_loss: 9.6891e-04\n",
      "Epoch 509/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 5.6390e-04 - val_loss: 9.6539e-04\n",
      "Epoch 510/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 5.6159e-04 - val_loss: 9.6193e-04\n",
      "Epoch 511/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 5.5930e-04 - val_loss: 9.5846e-04\n",
      "Epoch 512/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.5701e-04 - val_loss: 9.5499e-04\n",
      "Epoch 513/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5474e-04 - val_loss: 9.5158e-04\n",
      "Epoch 514/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.5248e-04 - val_loss: 9.4814e-04\n",
      "Epoch 515/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 5.5022e-04 - val_loss: 9.4473e-04\n",
      "Epoch 516/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 5.4799e-04 - val_loss: 9.4136e-04\n",
      "Epoch 517/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4576e-04 - val_loss: 9.3799e-04\n",
      "Epoch 518/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 5.4354e-04 - val_loss: 9.3463e-04\n",
      "Epoch 519/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4133e-04 - val_loss: 9.3129e-04\n",
      "Epoch 520/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3913e-04 - val_loss: 9.2795e-04\n",
      "Epoch 521/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 5.3695e-04 - val_loss: 9.2465e-04\n",
      "Epoch 522/1000\n",
      "32/32 [==============================] - 0s 162us/step - loss: 5.3477e-04 - val_loss: 9.2132e-04\n",
      "Epoch 523/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3260e-04 - val_loss: 9.1803e-04\n",
      "Epoch 524/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.3044e-04 - val_loss: 9.1480e-04\n",
      "Epoch 525/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 5.2831e-04 - val_loss: 9.1151e-04\n",
      "Epoch 526/1000\n",
      "32/32 [==============================] - 0s 167us/step - loss: 5.2616e-04 - val_loss: 9.0828e-04\n",
      "Epoch 527/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 5.2404e-04 - val_loss: 9.0505e-04\n",
      "Epoch 528/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 5.2193e-04 - val_loss: 9.0185e-04\n",
      "Epoch 529/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.1982e-04 - val_loss: 8.9866e-04\n",
      "Epoch 530/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1773e-04 - val_loss: 8.9553e-04\n",
      "Epoch 531/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1565e-04 - val_loss: 8.9233e-04\n",
      "Epoch 532/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 5.1357e-04 - val_loss: 8.8920e-04\n",
      "Epoch 533/1000\n",
      "32/32 [==============================] - 0s 161us/step - loss: 5.1151e-04 - val_loss: 8.8603e-04\n",
      "Epoch 534/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 5.0945e-04 - val_loss: 8.8293e-04\n",
      "Epoch 535/1000\n",
      "32/32 [==============================] - 0s 158us/step - loss: 5.0741e-04 - val_loss: 8.7982e-04\n",
      "Epoch 536/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 5.0537e-04 - val_loss: 8.7672e-04\n",
      "Epoch 537/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.0335e-04 - val_loss: 8.7365e-04\n",
      "Epoch 538/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 5.0133e-04 - val_loss: 8.7057e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 539/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.9933e-04 - val_loss: 8.6753e-04\n",
      "Epoch 540/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 4.9733e-04 - val_loss: 8.6446e-04\n",
      "Epoch 541/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 4.9534e-04 - val_loss: 8.6147e-04\n",
      "Epoch 542/1000\n",
      "32/32 [==============================] - 0s 168us/step - loss: 4.9336e-04 - val_loss: 8.5845e-04\n",
      "Epoch 543/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9140e-04 - val_loss: 8.5545e-04\n",
      "Epoch 544/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 4.8943e-04 - val_loss: 8.5248e-04\n",
      "Epoch 545/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 4.8748e-04 - val_loss: 8.4949e-04\n",
      "Epoch 546/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.8554e-04 - val_loss: 8.4656e-04\n",
      "Epoch 547/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.8361e-04 - val_loss: 8.4359e-04\n",
      "Epoch 548/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.8168e-04 - val_loss: 8.4069e-04\n",
      "Epoch 549/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 4.7977e-04 - val_loss: 8.3777e-04\n",
      "Epoch 550/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7787e-04 - val_loss: 8.3489e-04\n",
      "Epoch 551/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 4.7597e-04 - val_loss: 8.3200e-04\n",
      "Epoch 552/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.7409e-04 - val_loss: 8.2910e-04\n",
      "Epoch 553/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 4.7221e-04 - val_loss: 8.2624e-04\n",
      "Epoch 554/1000\n",
      "32/32 [==============================] - 0s 121us/step - loss: 4.7034e-04 - val_loss: 8.2338e-04\n",
      "Epoch 555/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6848e-04 - val_loss: 8.2053e-04\n",
      "Epoch 556/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6663e-04 - val_loss: 8.1769e-04\n",
      "Epoch 557/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6478e-04 - val_loss: 8.1487e-04\n",
      "Epoch 558/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.6295e-04 - val_loss: 8.1209e-04\n",
      "Epoch 559/1000\n",
      "32/32 [==============================] - 0s 137us/step - loss: 4.6113e-04 - val_loss: 8.0929e-04\n",
      "Epoch 560/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.5931e-04 - val_loss: 8.0652e-04\n",
      "Epoch 561/1000\n",
      "32/32 [==============================] - 0s 164us/step - loss: 4.5750e-04 - val_loss: 8.0376e-04\n",
      "Epoch 562/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5570e-04 - val_loss: 8.0102e-04\n",
      "Epoch 563/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.5391e-04 - val_loss: 7.9828e-04\n",
      "Epoch 564/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.5213e-04 - val_loss: 7.9554e-04\n",
      "Epoch 565/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 4.5034e-04 - val_loss: 7.9282e-04\n",
      "Epoch 566/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4858e-04 - val_loss: 7.9012e-04\n",
      "Epoch 567/1000\n",
      "32/32 [==============================] - 0s 161us/step - loss: 4.4682e-04 - val_loss: 7.8745e-04\n",
      "Epoch 568/1000\n",
      "32/32 [==============================] - 0s 158us/step - loss: 4.4507e-04 - val_loss: 7.8476e-04\n",
      "Epoch 569/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 4.4333e-04 - val_loss: 7.8209e-04\n",
      "Epoch 570/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4159e-04 - val_loss: 7.7944e-04\n",
      "Epoch 571/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3987e-04 - val_loss: 7.7677e-04\n",
      "Epoch 572/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 4.3815e-04 - val_loss: 7.7414e-04\n",
      "Epoch 573/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 4.3644e-04 - val_loss: 7.7155e-04\n",
      "Epoch 574/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3474e-04 - val_loss: 7.6890e-04\n",
      "Epoch 575/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 4.3304e-04 - val_loss: 7.6631e-04\n",
      "Epoch 576/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3135e-04 - val_loss: 7.6373e-04\n",
      "Epoch 577/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2967e-04 - val_loss: 7.6112e-04\n",
      "Epoch 578/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2800e-04 - val_loss: 7.5856e-04\n",
      "Epoch 579/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2634e-04 - val_loss: 7.5602e-04\n",
      "Epoch 580/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.2468e-04 - val_loss: 7.5348e-04\n",
      "Epoch 581/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2304e-04 - val_loss: 7.5093e-04\n",
      "Epoch 582/1000\n",
      "32/32 [==============================] - 0s 168us/step - loss: 4.2139e-04 - val_loss: 7.4841e-04\n",
      "Epoch 583/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 4.1975e-04 - val_loss: 7.4591e-04\n",
      "Epoch 584/1000\n",
      "32/32 [==============================] - 0s 131us/step - loss: 4.1813e-04 - val_loss: 7.4343e-04\n",
      "Epoch 585/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 4.1652e-04 - val_loss: 7.4093e-04\n",
      "Epoch 586/1000\n",
      "32/32 [==============================] - 0s 180us/step - loss: 4.1490e-04 - val_loss: 7.3846e-04\n",
      "Epoch 587/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1330e-04 - val_loss: 7.3599e-04\n",
      "Epoch 588/1000\n",
      "32/32 [==============================] - 0s 137us/step - loss: 4.1171e-04 - val_loss: 7.3352e-04\n",
      "Epoch 589/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.1011e-04 - val_loss: 7.3106e-04\n",
      "Epoch 590/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0853e-04 - val_loss: 7.2865e-04\n",
      "Epoch 591/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 4.0696e-04 - val_loss: 7.2623e-04\n",
      "Epoch 592/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0539e-04 - val_loss: 7.2380e-04\n",
      "Epoch 593/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0383e-04 - val_loss: 7.2138e-04\n",
      "Epoch 594/1000\n",
      "32/32 [==============================] - 0s 130us/step - loss: 4.0227e-04 - val_loss: 7.1899e-04\n",
      "Epoch 595/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0073e-04 - val_loss: 7.1663e-04\n",
      "Epoch 596/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.9919e-04 - val_loss: 7.1423e-04\n",
      "Epoch 597/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.9766e-04 - val_loss: 7.1188e-04\n",
      "Epoch 598/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9613e-04 - val_loss: 7.0950e-04\n",
      "Epoch 599/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9462e-04 - val_loss: 7.0717e-04\n",
      "Epoch 600/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 3.9310e-04 - val_loss: 7.0483e-04\n",
      "Epoch 601/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9160e-04 - val_loss: 7.0251e-04\n",
      "Epoch 602/1000\n",
      "32/32 [==============================] - 0s 164us/step - loss: 3.9010e-04 - val_loss: 7.0019e-04\n",
      "Epoch 603/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8862e-04 - val_loss: 6.9790e-04\n",
      "Epoch 604/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8713e-04 - val_loss: 6.9561e-04\n",
      "Epoch 605/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8565e-04 - val_loss: 6.9334e-04\n",
      "Epoch 606/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8419e-04 - val_loss: 6.9106e-04\n",
      "Epoch 607/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.8272e-04 - val_loss: 6.8878e-04\n",
      "Epoch 608/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8126e-04 - val_loss: 6.8653e-04\n",
      "Epoch 609/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7981e-04 - val_loss: 6.8428e-04\n",
      "Epoch 610/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 3.7837e-04 - val_loss: 6.8203e-04\n",
      "Epoch 611/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 3.7693e-04 - val_loss: 6.7982e-04\n",
      "Epoch 612/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 3.7550e-04 - val_loss: 6.7761e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 613/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7408e-04 - val_loss: 6.7537e-04\n",
      "Epoch 614/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7265e-04 - val_loss: 6.7319e-04\n",
      "Epoch 615/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7124e-04 - val_loss: 6.7097e-04\n",
      "Epoch 616/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6984e-04 - val_loss: 6.6879e-04\n",
      "Epoch 617/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.6844e-04 - val_loss: 6.6661e-04\n",
      "Epoch 618/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 3.6704e-04 - val_loss: 6.6445e-04\n",
      "Epoch 619/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6565e-04 - val_loss: 6.6230e-04\n",
      "Epoch 620/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.6428e-04 - val_loss: 6.6016e-04\n",
      "Epoch 621/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6291e-04 - val_loss: 6.5803e-04\n",
      "Epoch 622/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6154e-04 - val_loss: 6.5588e-04\n",
      "Epoch 623/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.6017e-04 - val_loss: 6.5377e-04\n",
      "Epoch 624/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5881e-04 - val_loss: 6.5167e-04\n",
      "Epoch 625/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 3.5748e-04 - val_loss: 6.4955e-04\n",
      "Epoch 626/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 3.5613e-04 - val_loss: 6.4747e-04\n",
      "Epoch 627/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5479e-04 - val_loss: 6.4541e-04\n",
      "Epoch 628/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5346e-04 - val_loss: 6.4331e-04\n",
      "Epoch 629/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5213e-04 - val_loss: 6.4126e-04\n",
      "Epoch 630/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5081e-04 - val_loss: 6.3918e-04\n",
      "Epoch 631/1000\n",
      "32/32 [==============================] - 0s 145us/step - loss: 3.4950e-04 - val_loss: 6.3714e-04\n",
      "Epoch 632/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4819e-04 - val_loss: 6.3509e-04\n",
      "Epoch 633/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4688e-04 - val_loss: 6.3306e-04\n",
      "Epoch 634/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4559e-04 - val_loss: 6.3104e-04\n",
      "Epoch 635/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4430e-04 - val_loss: 6.2901e-04\n",
      "Epoch 636/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4301e-04 - val_loss: 6.2701e-04\n",
      "Epoch 637/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4174e-04 - val_loss: 6.2501e-04\n",
      "Epoch 638/1000\n",
      "32/32 [==============================] - 0s 170us/step - loss: 3.4046e-04 - val_loss: 6.2301e-04\n",
      "Epoch 639/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.3919e-04 - val_loss: 6.2104e-04\n",
      "Epoch 640/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3794e-04 - val_loss: 6.1907e-04\n",
      "Epoch 641/1000\n",
      "32/32 [==============================] - 0s 172us/step - loss: 3.3667e-04 - val_loss: 6.1711e-04\n",
      "Epoch 642/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 3.3542e-04 - val_loss: 6.1513e-04\n",
      "Epoch 643/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3418e-04 - val_loss: 6.1319e-04\n",
      "Epoch 644/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3294e-04 - val_loss: 6.1123e-04\n",
      "Epoch 645/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3170e-04 - val_loss: 6.0929e-04\n",
      "Epoch 646/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 3.3048e-04 - val_loss: 6.0735e-04\n",
      "Epoch 647/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2925e-04 - val_loss: 6.0543e-04\n",
      "Epoch 648/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.2804e-04 - val_loss: 6.0351e-04\n",
      "Epoch 649/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.2682e-04 - val_loss: 6.0162e-04\n",
      "Epoch 650/1000\n",
      "32/32 [==============================] - 0s 196us/step - loss: 3.2561e-04 - val_loss: 5.9972e-04\n",
      "Epoch 651/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.2441e-04 - val_loss: 5.9783e-04\n",
      "Epoch 652/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.2322e-04 - val_loss: 5.9596e-04\n",
      "Epoch 653/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.2203e-04 - val_loss: 5.9407e-04\n",
      "Epoch 654/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.2083e-04 - val_loss: 5.9222e-04\n",
      "Epoch 655/1000\n",
      "32/32 [==============================] - 0s 133us/step - loss: 3.1966e-04 - val_loss: 5.9037e-04\n",
      "Epoch 656/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.1848e-04 - val_loss: 5.8850e-04\n",
      "Epoch 657/1000\n",
      "32/32 [==============================] - 0s 132us/step - loss: 3.1730e-04 - val_loss: 5.8666e-04\n",
      "Epoch 658/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1614e-04 - val_loss: 5.8482e-04\n",
      "Epoch 659/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1498e-04 - val_loss: 5.8299e-04\n",
      "Epoch 660/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1382e-04 - val_loss: 5.8117e-04\n",
      "Epoch 661/1000\n",
      "32/32 [==============================] - 0s 173us/step - loss: 3.1268e-04 - val_loss: 5.7934e-04\n",
      "Epoch 662/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 3.1153e-04 - val_loss: 5.7753e-04\n",
      "Epoch 663/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 3.1039e-04 - val_loss: 5.7573e-04\n",
      "Epoch 664/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0926e-04 - val_loss: 5.7393e-04\n",
      "Epoch 665/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0812e-04 - val_loss: 5.7215e-04\n",
      "Epoch 666/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.0700e-04 - val_loss: 5.7039e-04\n",
      "Epoch 667/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0588e-04 - val_loss: 5.6861e-04\n",
      "Epoch 668/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0476e-04 - val_loss: 5.6684e-04\n",
      "Epoch 669/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0365e-04 - val_loss: 5.6509e-04\n",
      "Epoch 670/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.0255e-04 - val_loss: 5.6334e-04\n",
      "Epoch 671/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.0145e-04 - val_loss: 5.6160e-04\n",
      "Epoch 672/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 3.0035e-04 - val_loss: 5.5984e-04\n",
      "Epoch 673/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 2.9926e-04 - val_loss: 5.5811e-04\n",
      "Epoch 674/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9818e-04 - val_loss: 5.5638e-04\n",
      "Epoch 675/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 2.9709e-04 - val_loss: 5.5467e-04\n",
      "Epoch 676/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9602e-04 - val_loss: 5.5296e-04\n",
      "Epoch 677/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.9494e-04 - val_loss: 5.5127e-04\n",
      "Epoch 678/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 2.9388e-04 - val_loss: 5.4956e-04\n",
      "Epoch 679/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9281e-04 - val_loss: 5.4787e-04\n",
      "Epoch 680/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 2.9175e-04 - val_loss: 5.4616e-04\n",
      "Epoch 681/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9070e-04 - val_loss: 5.4450e-04\n",
      "Epoch 682/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8965e-04 - val_loss: 5.4284e-04\n",
      "Epoch 683/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 2.8861e-04 - val_loss: 5.4117e-04\n",
      "Epoch 684/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8756e-04 - val_loss: 5.3954e-04\n",
      "Epoch 685/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8653e-04 - val_loss: 5.3787e-04\n",
      "Epoch 686/1000\n",
      "32/32 [==============================] - 0s 133us/step - loss: 2.8550e-04 - val_loss: 5.3624e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 687/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 2.8448e-04 - val_loss: 5.3459e-04\n",
      "Epoch 688/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 2.8345e-04 - val_loss: 5.3295e-04\n",
      "Epoch 689/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.8243e-04 - val_loss: 5.3133e-04\n",
      "Epoch 690/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 2.8142e-04 - val_loss: 5.2969e-04\n",
      "Epoch 691/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8041e-04 - val_loss: 5.2807e-04\n",
      "Epoch 692/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7941e-04 - val_loss: 5.2650e-04\n",
      "Epoch 693/1000\n",
      "32/32 [==============================] - 0s 132us/step - loss: 2.7841e-04 - val_loss: 5.2490e-04\n",
      "Epoch 694/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.7741e-04 - val_loss: 5.2329e-04\n",
      "Epoch 695/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.7642e-04 - val_loss: 5.2170e-04\n",
      "Epoch 696/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 2.7543e-04 - val_loss: 5.2013e-04\n",
      "Epoch 697/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7446e-04 - val_loss: 5.1854e-04\n",
      "Epoch 698/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7347e-04 - val_loss: 5.1698e-04\n",
      "Epoch 699/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7250e-04 - val_loss: 5.1541e-04\n",
      "Epoch 700/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 2.7153e-04 - val_loss: 5.1385e-04\n",
      "Epoch 701/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 2.7056e-04 - val_loss: 5.1231e-04\n",
      "Epoch 702/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6960e-04 - val_loss: 5.1075e-04\n",
      "Epoch 703/1000\n",
      "32/32 [==============================] - 0s 137us/step - loss: 2.6864e-04 - val_loss: 5.0923e-04\n",
      "Epoch 704/1000\n",
      "32/32 [==============================] - 0s 163us/step - loss: 2.6769e-04 - val_loss: 5.0768e-04\n",
      "Epoch 705/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.6673e-04 - val_loss: 5.0615e-04\n",
      "Epoch 706/1000\n",
      "32/32 [==============================] - 0s 138us/step - loss: 2.6579e-04 - val_loss: 5.0463e-04\n",
      "Epoch 707/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.6486e-04 - val_loss: 5.0312e-04\n",
      "Epoch 708/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 2.6392e-04 - val_loss: 5.0159e-04\n",
      "Epoch 709/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6298e-04 - val_loss: 5.0009e-04\n",
      "Epoch 710/1000\n",
      "32/32 [==============================] - 0s 163us/step - loss: 2.6205e-04 - val_loss: 4.9860e-04\n",
      "Epoch 711/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.6112e-04 - val_loss: 4.9710e-04\n",
      "Epoch 712/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6020e-04 - val_loss: 4.9561e-04\n",
      "Epoch 713/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.5929e-04 - val_loss: 4.9415e-04\n",
      "Epoch 714/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5838e-04 - val_loss: 4.9267e-04\n",
      "Epoch 715/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5746e-04 - val_loss: 4.9119e-04\n",
      "Epoch 716/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.5656e-04 - val_loss: 4.8972e-04\n",
      "Epoch 717/1000\n",
      "32/32 [==============================] - 0s 183us/step - loss: 2.5566e-04 - val_loss: 4.8826e-04\n",
      "Epoch 718/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5476e-04 - val_loss: 4.8680e-04\n",
      "Epoch 719/1000\n",
      "32/32 [==============================] - 0s 174us/step - loss: 2.5386e-04 - val_loss: 4.8536e-04\n",
      "Epoch 720/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 2.5298e-04 - val_loss: 4.8391e-04\n",
      "Epoch 721/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 2.5209e-04 - val_loss: 4.8246e-04\n",
      "Epoch 722/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5120e-04 - val_loss: 4.8104e-04\n",
      "Epoch 723/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 2.5033e-04 - val_loss: 4.7963e-04\n",
      "Epoch 724/1000\n",
      "32/32 [==============================] - 0s 176us/step - loss: 2.4945e-04 - val_loss: 4.7822e-04\n",
      "Epoch 725/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4859e-04 - val_loss: 4.7679e-04\n",
      "Epoch 726/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4771e-04 - val_loss: 4.7538e-04\n",
      "Epoch 727/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.4685e-04 - val_loss: 4.7397e-04\n",
      "Epoch 728/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4599e-04 - val_loss: 4.7258e-04\n",
      "Epoch 729/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 2.4514e-04 - val_loss: 4.7115e-04\n",
      "Epoch 730/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4428e-04 - val_loss: 4.6977e-04\n",
      "Epoch 731/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4344e-04 - val_loss: 4.6840e-04\n",
      "Epoch 732/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4259e-04 - val_loss: 4.6702e-04\n",
      "Epoch 733/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 2.4174e-04 - val_loss: 4.6564e-04\n",
      "Epoch 734/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.4090e-04 - val_loss: 4.6426e-04\n",
      "Epoch 735/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4007e-04 - val_loss: 4.6292e-04\n",
      "Epoch 736/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3924e-04 - val_loss: 4.6156e-04\n",
      "Epoch 737/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3841e-04 - val_loss: 4.6018e-04\n",
      "Epoch 738/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3759e-04 - val_loss: 4.5888e-04\n",
      "Epoch 739/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3677e-04 - val_loss: 4.5751e-04\n",
      "Epoch 740/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3595e-04 - val_loss: 4.5618e-04\n",
      "Epoch 741/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3514e-04 - val_loss: 4.5484e-04\n",
      "Epoch 742/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3432e-04 - val_loss: 4.5351e-04\n",
      "Epoch 743/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 2.3352e-04 - val_loss: 4.5218e-04\n",
      "Epoch 744/1000\n",
      "32/32 [==============================] - 0s 174us/step - loss: 2.3271e-04 - val_loss: 4.5086e-04\n",
      "Epoch 745/1000\n",
      "32/32 [==============================] - 0s 164us/step - loss: 2.3192e-04 - val_loss: 4.4956e-04\n",
      "Epoch 746/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3112e-04 - val_loss: 4.4824e-04\n",
      "Epoch 747/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3033e-04 - val_loss: 4.4692e-04\n",
      "Epoch 748/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2954e-04 - val_loss: 4.4564e-04\n",
      "Epoch 749/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.2875e-04 - val_loss: 4.4434e-04\n",
      "Epoch 750/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2797e-04 - val_loss: 4.4304e-04\n",
      "Epoch 751/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2719e-04 - val_loss: 4.4177e-04\n",
      "Epoch 752/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.2641e-04 - val_loss: 4.4047e-04\n",
      "Epoch 753/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.2564e-04 - val_loss: 4.3920e-04\n",
      "Epoch 754/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 2.2487e-04 - val_loss: 4.3792e-04\n",
      "Epoch 755/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.2410e-04 - val_loss: 4.3665e-04\n",
      "Epoch 756/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 2.2333e-04 - val_loss: 4.3542e-04\n",
      "Epoch 757/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2258e-04 - val_loss: 4.3417e-04\n",
      "Epoch 758/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2182e-04 - val_loss: 4.3292e-04\n",
      "Epoch 759/1000\n",
      "32/32 [==============================] - 0s 168us/step - loss: 2.2107e-04 - val_loss: 4.3166e-04\n",
      "Epoch 760/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2032e-04 - val_loss: 4.3042e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 761/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1957e-04 - val_loss: 4.2919e-04\n",
      "Epoch 762/1000\n",
      "32/32 [==============================] - 0s 131us/step - loss: 2.1882e-04 - val_loss: 4.2795e-04\n",
      "Epoch 763/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.1808e-04 - val_loss: 4.2671e-04\n",
      "Epoch 764/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 2.1735e-04 - val_loss: 4.2550e-04\n",
      "Epoch 765/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.1661e-04 - val_loss: 4.2428e-04\n",
      "Epoch 766/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1588e-04 - val_loss: 4.2304e-04\n",
      "Epoch 767/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1515e-04 - val_loss: 4.2184e-04\n",
      "Epoch 768/1000\n",
      "32/32 [==============================] - 0s 131us/step - loss: 2.1442e-04 - val_loss: 4.2066e-04\n",
      "Epoch 769/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 2.1370e-04 - val_loss: 4.1945e-04\n",
      "Epoch 770/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.1298e-04 - val_loss: 4.1825e-04\n",
      "Epoch 771/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 2.1227e-04 - val_loss: 4.1705e-04\n",
      "Epoch 772/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1155e-04 - val_loss: 4.1586e-04\n",
      "Epoch 773/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 2.1084e-04 - val_loss: 4.1469e-04\n",
      "Epoch 774/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.1013e-04 - val_loss: 4.1350e-04\n",
      "Epoch 775/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 2.0943e-04 - val_loss: 4.1232e-04\n",
      "Epoch 776/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.0873e-04 - val_loss: 4.1115e-04\n",
      "Epoch 777/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.0802e-04 - val_loss: 4.0998e-04\n",
      "Epoch 778/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.0733e-04 - val_loss: 4.0881e-04\n",
      "Epoch 779/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.0664e-04 - val_loss: 4.0765e-04\n",
      "Epoch 780/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0595e-04 - val_loss: 4.0649e-04\n",
      "Epoch 781/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.0526e-04 - val_loss: 4.0535e-04\n",
      "Epoch 782/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 2.0458e-04 - val_loss: 4.0418e-04\n",
      "Epoch 783/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.0389e-04 - val_loss: 4.0306e-04\n",
      "Epoch 784/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0322e-04 - val_loss: 4.0192e-04\n",
      "Epoch 785/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.0255e-04 - val_loss: 4.0078e-04\n",
      "Epoch 786/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0187e-04 - val_loss: 3.9965e-04\n",
      "Epoch 787/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0120e-04 - val_loss: 3.9852e-04\n",
      "Epoch 788/1000\n",
      "32/32 [==============================] - 0s 130us/step - loss: 2.0053e-04 - val_loss: 3.9741e-04\n",
      "Epoch 789/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.9987e-04 - val_loss: 3.9629e-04\n",
      "Epoch 790/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.9921e-04 - val_loss: 3.9517e-04\n",
      "Epoch 791/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 1.9855e-04 - val_loss: 3.9408e-04\n",
      "Epoch 792/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9789e-04 - val_loss: 3.9296e-04\n",
      "Epoch 793/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9724e-04 - val_loss: 3.9183e-04\n",
      "Epoch 794/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9659e-04 - val_loss: 3.9074e-04\n",
      "Epoch 795/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.9594e-04 - val_loss: 3.8965e-04\n",
      "Epoch 796/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 1.9530e-04 - val_loss: 3.8853e-04\n",
      "Epoch 797/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9465e-04 - val_loss: 3.8747e-04\n",
      "Epoch 798/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 1.9401e-04 - val_loss: 3.8638e-04\n",
      "Epoch 799/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.9338e-04 - val_loss: 3.8532e-04\n",
      "Epoch 800/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9274e-04 - val_loss: 3.8424e-04\n",
      "Epoch 801/1000\n",
      "32/32 [==============================] - 0s 117us/step - loss: 1.9211e-04 - val_loss: 3.8319e-04\n",
      "Epoch 802/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 1.9148e-04 - val_loss: 3.8212e-04\n",
      "Epoch 803/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 1.9085e-04 - val_loss: 3.8106e-04\n",
      "Epoch 804/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9023e-04 - val_loss: 3.8000e-04\n",
      "Epoch 805/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8961e-04 - val_loss: 3.7894e-04\n",
      "Epoch 806/1000\n",
      "32/32 [==============================] - 0s 129us/step - loss: 1.8899e-04 - val_loss: 3.7788e-04\n",
      "Epoch 807/1000\n",
      "32/32 [==============================] - 0s 167us/step - loss: 1.8838e-04 - val_loss: 3.7681e-04\n",
      "Epoch 808/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.8776e-04 - val_loss: 3.7578e-04\n",
      "Epoch 809/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8715e-04 - val_loss: 3.7474e-04\n",
      "Epoch 810/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.8655e-04 - val_loss: 3.7370e-04\n",
      "Epoch 811/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.8593e-04 - val_loss: 3.7267e-04\n",
      "Epoch 812/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 1.8533e-04 - val_loss: 3.7163e-04\n",
      "Epoch 813/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.8473e-04 - val_loss: 3.7062e-04\n",
      "Epoch 814/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.8413e-04 - val_loss: 3.6959e-04\n",
      "Epoch 815/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 1.8353e-04 - val_loss: 3.6858e-04\n",
      "Epoch 816/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8294e-04 - val_loss: 3.6757e-04\n",
      "Epoch 817/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.8235e-04 - val_loss: 3.6655e-04\n",
      "Epoch 818/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8176e-04 - val_loss: 3.6553e-04\n",
      "Epoch 819/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.8118e-04 - val_loss: 3.6452e-04\n",
      "Epoch 820/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8059e-04 - val_loss: 3.6352e-04\n",
      "Epoch 821/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.8001e-04 - val_loss: 3.6253e-04\n",
      "Epoch 822/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.7943e-04 - val_loss: 3.6153e-04\n",
      "Epoch 823/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.7886e-04 - val_loss: 3.6055e-04\n",
      "Epoch 824/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 1.7828e-04 - val_loss: 3.5955e-04\n",
      "Epoch 825/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 1.7771e-04 - val_loss: 3.5859e-04\n",
      "Epoch 826/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.7714e-04 - val_loss: 3.5761e-04\n",
      "Epoch 827/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7658e-04 - val_loss: 3.5663e-04\n",
      "Epoch 828/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.7601e-04 - val_loss: 3.5564e-04\n",
      "Epoch 829/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7545e-04 - val_loss: 3.5468e-04\n",
      "Epoch 830/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7489e-04 - val_loss: 3.5370e-04\n",
      "Epoch 831/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.7433e-04 - val_loss: 3.5275e-04\n",
      "Epoch 832/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7378e-04 - val_loss: 3.5179e-04\n",
      "Epoch 833/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 1.7323e-04 - val_loss: 3.5082e-04\n",
      "Epoch 834/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.7267e-04 - val_loss: 3.4987e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 835/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 1.7212e-04 - val_loss: 3.4892e-04\n",
      "Epoch 836/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.7158e-04 - val_loss: 3.4797e-04\n",
      "Epoch 837/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7103e-04 - val_loss: 3.4703e-04\n",
      "Epoch 838/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.7049e-04 - val_loss: 3.4609e-04\n",
      "Epoch 839/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.6995e-04 - val_loss: 3.4515e-04\n",
      "Epoch 840/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.6941e-04 - val_loss: 3.4422e-04\n",
      "Epoch 841/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 1.6888e-04 - val_loss: 3.4330e-04\n",
      "Epoch 842/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 1.6835e-04 - val_loss: 3.4239e-04\n",
      "Epoch 843/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.6782e-04 - val_loss: 3.4145e-04\n",
      "Epoch 844/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6728e-04 - val_loss: 3.4053e-04\n",
      "Epoch 845/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6676e-04 - val_loss: 3.3961e-04\n",
      "Epoch 846/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.6624e-04 - val_loss: 3.3868e-04\n",
      "Epoch 847/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.6571e-04 - val_loss: 3.3777e-04\n",
      "Epoch 848/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6519e-04 - val_loss: 3.3690e-04\n",
      "Epoch 849/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 1.6468e-04 - val_loss: 3.3598e-04\n",
      "Epoch 850/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.6416e-04 - val_loss: 3.3509e-04\n",
      "Epoch 851/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6365e-04 - val_loss: 3.3418e-04\n",
      "Epoch 852/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6314e-04 - val_loss: 3.3329e-04\n",
      "Epoch 853/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6263e-04 - val_loss: 3.3237e-04\n",
      "Epoch 854/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.6212e-04 - val_loss: 3.3151e-04\n",
      "Epoch 855/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.6162e-04 - val_loss: 3.3061e-04\n",
      "Epoch 856/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6111e-04 - val_loss: 3.2973e-04\n",
      "Epoch 857/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6061e-04 - val_loss: 3.2884e-04\n",
      "Epoch 858/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6011e-04 - val_loss: 3.2798e-04\n",
      "Epoch 859/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5962e-04 - val_loss: 3.2708e-04\n",
      "Epoch 860/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5912e-04 - val_loss: 3.2621e-04\n",
      "Epoch 861/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5863e-04 - val_loss: 3.2535e-04\n",
      "Epoch 862/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5814e-04 - val_loss: 3.2450e-04\n",
      "Epoch 863/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5765e-04 - val_loss: 3.2362e-04\n",
      "Epoch 864/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5716e-04 - val_loss: 3.2278e-04\n",
      "Epoch 865/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5668e-04 - val_loss: 3.2191e-04\n",
      "Epoch 866/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5619e-04 - val_loss: 3.2106e-04\n",
      "Epoch 867/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.5572e-04 - val_loss: 3.2021e-04\n",
      "Epoch 868/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5524e-04 - val_loss: 3.1936e-04\n",
      "Epoch 869/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.5476e-04 - val_loss: 3.1852e-04\n",
      "Epoch 870/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.5428e-04 - val_loss: 3.1767e-04\n",
      "Epoch 871/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5381e-04 - val_loss: 3.1685e-04\n",
      "Epoch 872/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.5334e-04 - val_loss: 3.1599e-04\n",
      "Epoch 873/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.5287e-04 - val_loss: 3.1517e-04\n",
      "Epoch 874/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.5240e-04 - val_loss: 3.1432e-04\n",
      "Epoch 875/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5194e-04 - val_loss: 3.1350e-04\n",
      "Epoch 876/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.5147e-04 - val_loss: 3.1268e-04\n",
      "Epoch 877/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 1.5101e-04 - val_loss: 3.1187e-04\n",
      "Epoch 878/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5055e-04 - val_loss: 3.1106e-04\n",
      "Epoch 879/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5010e-04 - val_loss: 3.1024e-04\n",
      "Epoch 880/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4964e-04 - val_loss: 3.0943e-04\n",
      "Epoch 881/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.4919e-04 - val_loss: 3.0862e-04\n",
      "Epoch 882/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 1.4874e-04 - val_loss: 3.0782e-04\n",
      "Epoch 883/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.4828e-04 - val_loss: 3.0701e-04\n",
      "Epoch 884/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 1.4784e-04 - val_loss: 3.0618e-04\n",
      "Epoch 885/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4739e-04 - val_loss: 3.0538e-04\n",
      "Epoch 886/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 1.4694e-04 - val_loss: 3.0458e-04\n",
      "Epoch 887/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.4650e-04 - val_loss: 3.0379e-04\n",
      "Epoch 888/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4606e-04 - val_loss: 3.0301e-04\n",
      "Epoch 889/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4562e-04 - val_loss: 3.0221e-04\n",
      "Epoch 890/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.4518e-04 - val_loss: 3.0143e-04\n",
      "Epoch 891/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4475e-04 - val_loss: 3.0065e-04\n",
      "Epoch 892/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4431e-04 - val_loss: 2.9987e-04\n",
      "Epoch 893/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4388e-04 - val_loss: 2.9910e-04\n",
      "Epoch 894/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4345e-04 - val_loss: 2.9832e-04\n",
      "Epoch 895/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.4302e-04 - val_loss: 2.9755e-04\n",
      "Epoch 896/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.4260e-04 - val_loss: 2.9678e-04\n",
      "Epoch 897/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.4217e-04 - val_loss: 2.9599e-04\n",
      "Epoch 898/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4175e-04 - val_loss: 2.9523e-04\n",
      "Epoch 899/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.4133e-04 - val_loss: 2.9448e-04\n",
      "Epoch 900/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.4091e-04 - val_loss: 2.9372e-04\n",
      "Epoch 901/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4049e-04 - val_loss: 2.9296e-04\n",
      "Epoch 902/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4007e-04 - val_loss: 2.9222e-04\n",
      "Epoch 903/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.3966e-04 - val_loss: 2.9147e-04\n",
      "Epoch 904/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3924e-04 - val_loss: 2.9073e-04\n",
      "Epoch 905/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3883e-04 - val_loss: 2.8996e-04\n",
      "Epoch 906/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.3842e-04 - val_loss: 2.8921e-04\n",
      "Epoch 907/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.3801e-04 - val_loss: 2.8847e-04\n",
      "Epoch 908/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.3760e-04 - val_loss: 2.8774e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 909/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.3720e-04 - val_loss: 2.8699e-04\n",
      "Epoch 910/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.3680e-04 - val_loss: 2.8628e-04\n",
      "Epoch 911/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3640e-04 - val_loss: 2.8553e-04\n",
      "Epoch 912/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3600e-04 - val_loss: 2.8481e-04\n",
      "Epoch 913/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3560e-04 - val_loss: 2.8409e-04\n",
      "Epoch 914/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.3520e-04 - val_loss: 2.8336e-04\n",
      "Epoch 915/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3480e-04 - val_loss: 2.8263e-04\n",
      "Epoch 916/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3441e-04 - val_loss: 2.8192e-04\n",
      "Epoch 917/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.3402e-04 - val_loss: 2.8119e-04\n",
      "Epoch 918/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.3363e-04 - val_loss: 2.8047e-04\n",
      "Epoch 919/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.3324e-04 - val_loss: 2.7977e-04\n",
      "Epoch 920/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.3286e-04 - val_loss: 2.7905e-04\n",
      "Epoch 921/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3247e-04 - val_loss: 2.7834e-04\n",
      "Epoch 922/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.3209e-04 - val_loss: 2.7764e-04\n",
      "Epoch 923/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.3170e-04 - val_loss: 2.7694e-04\n",
      "Epoch 924/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3132e-04 - val_loss: 2.7624e-04\n",
      "Epoch 925/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.3094e-04 - val_loss: 2.7554e-04\n",
      "Epoch 926/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3056e-04 - val_loss: 2.7484e-04\n",
      "Epoch 927/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3019e-04 - val_loss: 2.7414e-04\n",
      "Epoch 928/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.2981e-04 - val_loss: 2.7345e-04\n",
      "Epoch 929/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2944e-04 - val_loss: 2.7275e-04\n",
      "Epoch 930/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2907e-04 - val_loss: 2.7206e-04\n",
      "Epoch 931/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2870e-04 - val_loss: 2.7138e-04\n",
      "Epoch 932/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.2833e-04 - val_loss: 2.7071e-04\n",
      "Epoch 933/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2796e-04 - val_loss: 2.7003e-04\n",
      "Epoch 934/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2760e-04 - val_loss: 2.6936e-04\n",
      "Epoch 935/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2723e-04 - val_loss: 2.6868e-04\n",
      "Epoch 936/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.2687e-04 - val_loss: 2.6801e-04\n",
      "Epoch 937/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2651e-04 - val_loss: 2.6735e-04\n",
      "Epoch 938/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.2615e-04 - val_loss: 2.6666e-04\n",
      "Epoch 939/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.2579e-04 - val_loss: 2.6600e-04\n",
      "Epoch 940/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2543e-04 - val_loss: 2.6532e-04\n",
      "Epoch 941/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2507e-04 - val_loss: 2.6465e-04\n",
      "Epoch 942/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.2472e-04 - val_loss: 2.6400e-04\n",
      "Epoch 943/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2437e-04 - val_loss: 2.6334e-04\n",
      "Epoch 944/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2402e-04 - val_loss: 2.6269e-04\n",
      "Epoch 945/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.2367e-04 - val_loss: 2.6204e-04\n",
      "Epoch 946/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2332e-04 - val_loss: 2.6138e-04\n",
      "Epoch 947/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2297e-04 - val_loss: 2.6073e-04\n",
      "Epoch 948/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2263e-04 - val_loss: 2.6009e-04\n",
      "Epoch 949/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2228e-04 - val_loss: 2.5944e-04\n",
      "Epoch 950/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2194e-04 - val_loss: 2.5880e-04\n",
      "Epoch 951/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2160e-04 - val_loss: 2.5815e-04\n",
      "Epoch 952/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 1.2126e-04 - val_loss: 2.5752e-04\n",
      "Epoch 953/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2092e-04 - val_loss: 2.5688e-04\n",
      "Epoch 954/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2058e-04 - val_loss: 2.5625e-04\n",
      "Epoch 955/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.2025e-04 - val_loss: 2.5561e-04\n",
      "Epoch 956/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1991e-04 - val_loss: 2.5498e-04\n",
      "Epoch 957/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1958e-04 - val_loss: 2.5434e-04\n",
      "Epoch 958/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.1924e-04 - val_loss: 2.5373e-04\n",
      "Epoch 959/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1892e-04 - val_loss: 2.5309e-04\n",
      "Epoch 960/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.1858e-04 - val_loss: 2.5249e-04\n",
      "Epoch 961/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 1.1826e-04 - val_loss: 2.5186e-04\n",
      "Epoch 962/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1793e-04 - val_loss: 2.5124e-04\n",
      "Epoch 963/1000\n",
      "32/32 [==============================] - 0s 108us/step - loss: 1.1761e-04 - val_loss: 2.5063e-04\n",
      "Epoch 964/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 1.1728e-04 - val_loss: 2.5002e-04\n",
      "Epoch 965/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1696e-04 - val_loss: 2.4939e-04\n",
      "Epoch 966/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1664e-04 - val_loss: 2.4879e-04\n",
      "Epoch 967/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.1632e-04 - val_loss: 2.4818e-04\n",
      "Epoch 968/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1600e-04 - val_loss: 2.4758e-04\n",
      "Epoch 969/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1568e-04 - val_loss: 2.4699e-04\n",
      "Epoch 970/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1537e-04 - val_loss: 2.4637e-04\n",
      "Epoch 971/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 1.1505e-04 - val_loss: 2.4578e-04\n",
      "Epoch 972/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1474e-04 - val_loss: 2.4517e-04\n",
      "Epoch 973/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1442e-04 - val_loss: 2.4458e-04\n",
      "Epoch 974/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 1.1411e-04 - val_loss: 2.4399e-04\n",
      "Epoch 975/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 1.1380e-04 - val_loss: 2.4338e-04\n",
      "Epoch 976/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1349e-04 - val_loss: 2.4280e-04\n",
      "Epoch 977/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.1318e-04 - val_loss: 2.4220e-04\n",
      "Epoch 978/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1288e-04 - val_loss: 2.4162e-04\n",
      "Epoch 979/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1257e-04 - val_loss: 2.4103e-04\n",
      "Epoch 980/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1227e-04 - val_loss: 2.4044e-04\n",
      "Epoch 981/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.1196e-04 - val_loss: 2.3988e-04\n",
      "Epoch 982/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1167e-04 - val_loss: 2.3929e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 983/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1136e-04 - val_loss: 2.3870e-04\n",
      "Epoch 984/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1106e-04 - val_loss: 2.3814e-04\n",
      "Epoch 985/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1077e-04 - val_loss: 2.3756e-04\n",
      "Epoch 986/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1047e-04 - val_loss: 2.3701e-04\n",
      "Epoch 987/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1018e-04 - val_loss: 2.3645e-04\n",
      "Epoch 988/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.0988e-04 - val_loss: 2.3586e-04\n",
      "Epoch 989/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.0959e-04 - val_loss: 2.3531e-04\n",
      "Epoch 990/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.0930e-04 - val_loss: 2.3473e-04\n",
      "Epoch 991/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 1.0900e-04 - val_loss: 2.3417e-04\n",
      "Epoch 992/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0871e-04 - val_loss: 2.3360e-04\n",
      "Epoch 993/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.0843e-04 - val_loss: 2.3305e-04\n",
      "Epoch 994/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.0814e-04 - val_loss: 2.3249e-04\n",
      "Epoch 995/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.0785e-04 - val_loss: 2.3193e-04\n",
      "Epoch 996/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0756e-04 - val_loss: 2.3137e-04\n",
      "Epoch 997/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0728e-04 - val_loss: 2.3082e-04\n",
      "Epoch 998/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0700e-04 - val_loss: 2.3027e-04\n",
      "Epoch 999/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0672e-04 - val_loss: 2.2973e-04\n",
      "Epoch 1000/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 1.0644e-04 - val_loss: 2.2918e-04\n",
      "0.0003068682854063809\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 0.7822377 ,  0.3867028 , -0.03218643,  1.1586654 , -0.44858235,\n",
       "         -0.7472017 , -0.22837785, -0.91857594,  1.2088966 ,  0.5375606 ],\n",
       "        [-1.0978749 ,  0.3386378 ,  0.22387356,  0.23045193,  1.0139182 ,\n",
       "          0.3385366 , -1.0568665 ,  0.15739894,  0.30679914, -0.7370963 ],\n",
       "        [ 0.02880979,  1.1188565 ,  0.5663107 ,  0.23344311, -0.17907685,\n",
       "         -0.6992562 , -0.69969445,  1.1280634 , -0.36329   ,  0.65127325]],\n",
       "       dtype=float32),\n",
       " array([ 0.4452581 ,  0.38921785,  0.278998  , -0.49206334, -0.09413301,\n",
       "        -0.3220109 ,  0.37730265, -0.27143547,  0.43291664, -0.5959225 ],\n",
       "       dtype=float32),\n",
       " array([[-0.15462038, -0.07746185,  0.272846  , -0.08471205,  0.37236002,\n",
       "         -0.03618853,  0.08720662, -0.22447324,  0.07351431,  0.29435465],\n",
       "        [ 0.47560188,  0.23134413,  0.5648685 , -0.4773119 ,  0.17680456,\n",
       "          0.12190033,  0.12044638,  0.7221592 , -0.44361025, -0.44269878],\n",
       "        [ 0.09781466,  0.32607216,  0.47720617, -0.23628308,  0.5691568 ,\n",
       "          0.15960208, -0.04450346,  0.06076159,  0.02554312, -0.43156892],\n",
       "        [-0.3013376 ,  0.07254202, -0.1485309 ,  0.4197248 , -0.56060266,\n",
       "          0.35288897, -0.6003095 , -0.03962413, -0.19539678, -0.42493725],\n",
       "        [-0.333423  , -0.3021025 ,  0.15739115,  0.41897738, -0.26812357,\n",
       "          0.11837336,  0.52776945, -0.04556145,  0.18748589, -0.41449896],\n",
       "        [ 0.35926178,  0.03778869, -0.4297867 ,  0.15413177, -0.23327059,\n",
       "         -0.40545246, -0.43433946, -0.24537268,  0.2533833 ,  0.22591197],\n",
       "        [-0.3611214 , -0.16093431, -0.37268505, -0.4954237 ,  0.5071045 ,\n",
       "         -0.17485411,  0.47017494,  0.02003411,  0.26198277,  0.29146877],\n",
       "        [-0.01640124,  0.6894022 ,  0.04673701, -0.08483328, -0.13445185,\n",
       "         -0.22916009, -0.72312844, -0.74172455, -0.3916638 ,  0.5442275 ],\n",
       "        [ 0.48622525, -0.26448658, -0.12372185, -0.48835197, -0.15034278,\n",
       "         -0.34698153,  0.07148331,  0.4894092 , -0.45204827, -0.18250835],\n",
       "        [-0.5006818 , -0.52413166, -0.2544518 , -0.12462313, -0.380589  ,\n",
       "          0.42255506, -0.6831135 , -0.45659637, -0.29162732, -0.4120743 ]],\n",
       "       dtype=float32),\n",
       " array([ 0.6817841 ,  0.6911886 ,  0.69251394, -0.68246377,  0.7236035 ,\n",
       "        -0.6881595 ,  0.7238066 ,  0.7213575 ,  0.5136043 , -0.4663403 ],\n",
       "       dtype=float32),\n",
       " array([[ 0.48932225],\n",
       "        [-0.05262719],\n",
       "        [ 0.5687736 ],\n",
       "        [-0.47640762],\n",
       "        [ 0.7425221 ],\n",
       "        [-0.4149917 ],\n",
       "        [ 0.72767615],\n",
       "        [ 0.74851   ],\n",
       "        [ 0.12792417],\n",
       "        [-0.20893975]], dtype=float32),\n",
       " array([0.7859992], dtype=float32)]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_challenger, history_challenger, evaluate_challenger=NN_model_structure_regression_5(X_train_challenger, X_val_challenger, Y_train_challenger, Y_val_challenger, adam2, 32, 1000, x_test_challenger, y_test_challenger)\n",
    "model_challenger.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_challenger.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_challenger_structure5_4th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_70 (Dense)             (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 15)                165       \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 221\n",
      "Trainable params: 221\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 32 samples, validate on 7 samples\n",
      "Epoch 1/1000\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 35.9914 - val_loss: 30.9199\n",
      "Epoch 2/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 31.3781 - val_loss: 23.7233\n",
      "Epoch 3/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 25.5249 - val_loss: 15.2809\n",
      "Epoch 4/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 17.3535 - val_loss: 6.4525\n",
      "Epoch 5/1000\n",
      "32/32 [==============================] - 0s 174us/step - loss: 7.9744 - val_loss: 0.8318\n",
      "Epoch 6/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 1.0873 - val_loss: 3.7587\n",
      "Epoch 7/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.8112 - val_loss: 8.2465\n",
      "Epoch 8/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 9.7269 - val_loss: 6.5889\n",
      "Epoch 9/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4874 - val_loss: 2.9855\n",
      "Epoch 10/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.8327 - val_loss: 0.8939\n",
      "Epoch 11/1000\n",
      "32/32 [==============================] - 0s 132us/step - loss: 0.3971 - val_loss: 0.6914\n",
      "Epoch 12/1000\n",
      "32/32 [==============================] - 0s 133us/step - loss: 0.4891 - val_loss: 1.3837\n",
      "Epoch 13/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6634 - val_loss: 2.0997\n",
      "Epoch 14/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 2.7699 - val_loss: 2.4519\n",
      "Epoch 15/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3397 - val_loss: 2.3805\n",
      "Epoch 16/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.3172 - val_loss: 1.9760\n",
      "Epoch 17/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 2.8213 - val_loss: 1.3846\n",
      "Epoch 18/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0376 - val_loss: 0.7746\n",
      "Epoch 19/1000\n",
      "32/32 [==============================] - 0s 161us/step - loss: 1.1888 - val_loss: 0.3203\n",
      "Epoch 20/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 0.5121 - val_loss: 0.1619\n",
      "Epoch 21/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1943 - val_loss: 0.3311\n",
      "Epoch 22/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.2816 - val_loss: 0.7017\n",
      "Epoch 23/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 0.6446 - val_loss: 1.0415\n",
      "Epoch 24/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 1.0342 - val_loss: 1.1546\n",
      "Epoch 25/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 1.2001 - val_loss: 1.0021\n",
      "Epoch 26/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0497 - val_loss: 0.6931\n",
      "Epoch 27/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.7067 - val_loss: 0.3764\n",
      "Epoch 28/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.3728 - val_loss: 0.1527\n",
      "Epoch 29/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1749 - val_loss: 0.0546\n",
      "Epoch 30/1000\n",
      "32/32 [==============================] - 0s 182us/step - loss: 0.1361 - val_loss: 0.0594\n",
      "Epoch 31/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 0.2128 - val_loss: 0.1148\n",
      "Epoch 32/1000\n",
      "32/32 [==============================] - 0s 133us/step - loss: 0.3329 - val_loss: 0.1681\n",
      "Epoch 33/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 0.4293 - val_loss: 0.1891\n",
      "Epoch 34/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.4641 - val_loss: 0.1736\n",
      "Epoch 35/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 0.4315 - val_loss: 0.1346\n",
      "Epoch 36/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.3477 - val_loss: 0.0918\n",
      "Epoch 37/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.2403 - val_loss: 0.0638\n",
      "Epoch 38/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 0.1412 - val_loss: 0.0622\n",
      "Epoch 39/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 0.0778 - val_loss: 0.0871\n",
      "Epoch 40/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0630 - val_loss: 0.1274\n",
      "Epoch 41/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 0.0890 - val_loss: 0.1665\n",
      "Epoch 42/1000\n",
      "32/32 [==============================] - 0s 133us/step - loss: 0.1331 - val_loss: 0.1890\n",
      "Epoch 43/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1695 - val_loss: 0.1861\n",
      "Epoch 44/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.1797 - val_loss: 0.1582\n",
      "Epoch 45/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1592 - val_loss: 0.1151\n",
      "Epoch 46/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1179 - val_loss: 0.0708\n",
      "Epoch 47/1000\n",
      "32/32 [==============================] - 0s 131us/step - loss: 0.0735 - val_loss: 0.0363\n",
      "Epoch 48/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0413 - val_loss: 0.0164\n",
      "Epoch 49/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0277 - val_loss: 0.0101\n",
      "Epoch 50/1000\n",
      "32/32 [==============================] - 0s 171us/step - loss: 0.0314 - val_loss: 0.0130\n",
      "Epoch 51/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0456 - val_loss: 0.0196\n",
      "Epoch 52/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0613 - val_loss: 0.0250\n",
      "Epoch 53/1000\n",
      "32/32 [==============================] - 0s 168us/step - loss: 0.0712 - val_loss: 0.0264\n",
      "Epoch 54/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 0.0715 - val_loss: 0.0233\n",
      "Epoch 55/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 0.0629 - val_loss: 0.0171\n",
      "Epoch 56/1000\n",
      "32/32 [==============================] - 0s 132us/step - loss: 0.0487 - val_loss: 0.0103\n",
      "Epoch 57/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 0.0337 - val_loss: 0.0055\n",
      "Epoch 58/1000\n",
      "32/32 [==============================] - 0s 164us/step - loss: 0.0220 - val_loss: 0.0044\n",
      "Epoch 59/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0164 - val_loss: 0.0070\n",
      "Epoch 60/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0168 - val_loss: 0.0118\n",
      "Epoch 61/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0211 - val_loss: 0.0168\n",
      "Epoch 62/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0260 - val_loss: 0.0201\n",
      "Epoch 63/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0289 - val_loss: 0.0209\n",
      "Epoch 64/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0285 - val_loss: 0.0194\n",
      "Epoch 65/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 0.0249 - val_loss: 0.0164\n",
      "Epoch 66/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0196 - val_loss: 0.0133\n",
      "Epoch 67/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0146 - val_loss: 0.0112\n",
      "Epoch 68/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0114 - val_loss: 0.0106\n",
      "Epoch 69/1000\n",
      "32/32 [==============================] - 0s 138us/step - loss: 0.0105 - val_loss: 0.0112\n",
      "Epoch 70/1000\n",
      "32/32 [==============================] - 0s 132us/step - loss: 0.0114 - val_loss: 0.0124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/1000\n",
      "32/32 [==============================] - 0s 163us/step - loss: 0.0130 - val_loss: 0.0133\n",
      "Epoch 72/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 0.0145 - val_loss: 0.0132\n",
      "Epoch 73/1000\n",
      "32/32 [==============================] - 0s 160us/step - loss: 0.0149 - val_loss: 0.0121\n",
      "Epoch 74/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0141 - val_loss: 0.0103\n",
      "Epoch 75/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0123 - val_loss: 0.0083\n",
      "Epoch 76/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0103 - val_loss: 0.0065\n",
      "Epoch 77/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 0.0085 - val_loss: 0.0054\n",
      "Epoch 78/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0075 - val_loss: 0.0048\n",
      "Epoch 79/1000\n",
      "32/32 [==============================] - 0s 145us/step - loss: 0.0074 - val_loss: 0.0047\n",
      "Epoch 80/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0079 - val_loss: 0.0049\n",
      "Epoch 81/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0087 - val_loss: 0.0051\n",
      "Epoch 82/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0092 - val_loss: 0.0051\n",
      "Epoch 83/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0092 - val_loss: 0.0051\n",
      "Epoch 84/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0088 - val_loss: 0.0049\n",
      "Epoch 85/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 0.0080 - val_loss: 0.0049\n",
      "Epoch 86/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0073 - val_loss: 0.0050\n",
      "Epoch 87/1000\n",
      "32/32 [==============================] - 0s 131us/step - loss: 0.0067 - val_loss: 0.0054\n",
      "Epoch 88/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0064 - val_loss: 0.0060\n",
      "Epoch 89/1000\n",
      "32/32 [==============================] - 0s 162us/step - loss: 0.0064 - val_loss: 0.0066\n",
      "Epoch 90/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0066 - val_loss: 0.0072\n",
      "Epoch 91/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0068 - val_loss: 0.0077\n",
      "Epoch 92/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0069 - val_loss: 0.0079\n",
      "Epoch 93/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0068 - val_loss: 0.0079\n",
      "Epoch 94/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0066 - val_loss: 0.0078\n",
      "Epoch 95/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 96/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0060 - val_loss: 0.0074\n",
      "Epoch 97/1000\n",
      "32/32 [==============================] - 0s 160us/step - loss: 0.0058 - val_loss: 0.0072\n",
      "Epoch 98/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0058 - val_loss: 0.0070\n",
      "Epoch 99/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0058 - val_loss: 0.0068\n",
      "Epoch 100/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0058 - val_loss: 0.0067\n",
      "Epoch 101/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0059 - val_loss: 0.0066\n",
      "Epoch 102/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0058 - val_loss: 0.0064\n",
      "Epoch 103/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0058 - val_loss: 0.0063\n",
      "Epoch 104/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0056 - val_loss: 0.0062\n",
      "Epoch 105/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0055 - val_loss: 0.0062\n",
      "Epoch 106/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0054 - val_loss: 0.0062\n",
      "Epoch 107/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0053 - val_loss: 0.0062\n",
      "Epoch 108/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 0.0053 - val_loss: 0.0062\n",
      "Epoch 109/1000\n",
      "32/32 [==============================] - 0s 138us/step - loss: 0.0053 - val_loss: 0.0062\n",
      "Epoch 110/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0053 - val_loss: 0.0062\n",
      "Epoch 111/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 0.0053 - val_loss: 0.0062\n",
      "Epoch 112/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0052 - val_loss: 0.0061\n",
      "Epoch 113/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0052 - val_loss: 0.0060\n",
      "Epoch 114/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0051 - val_loss: 0.0059\n",
      "Epoch 115/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0050 - val_loss: 0.0058\n",
      "Epoch 116/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0050 - val_loss: 0.0057\n",
      "Epoch 117/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0049 - val_loss: 0.0057\n",
      "Epoch 118/1000\n",
      "32/32 [==============================] - 0s 168us/step - loss: 0.0049 - val_loss: 0.0056\n",
      "Epoch 119/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0049 - val_loss: 0.0056\n",
      "Epoch 120/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 0.0049 - val_loss: 0.0056\n",
      "Epoch 121/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0048 - val_loss: 0.0056\n",
      "Epoch 122/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0048 - val_loss: 0.0056\n",
      "Epoch 123/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0048 - val_loss: 0.0056\n",
      "Epoch 124/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0047 - val_loss: 0.0056\n",
      "Epoch 125/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0047 - val_loss: 0.0056\n",
      "Epoch 126/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0046 - val_loss: 0.0056\n",
      "Epoch 127/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0046 - val_loss: 0.0056\n",
      "Epoch 128/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0046 - val_loss: 0.0056\n",
      "Epoch 129/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 0.0046 - val_loss: 0.0055\n",
      "Epoch 130/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0045 - val_loss: 0.0054\n",
      "Epoch 131/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0045 - val_loss: 0.0053\n",
      "Epoch 132/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0045 - val_loss: 0.0052\n",
      "Epoch 133/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 0.0044 - val_loss: 0.0051\n",
      "Epoch 134/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0044 - val_loss: 0.0050\n",
      "Epoch 135/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0044 - val_loss: 0.0049\n",
      "Epoch 136/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 137/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 138/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 139/1000\n",
      "32/32 [==============================] - 0s 161us/step - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 140/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 141/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0042 - val_loss: 0.0045\n",
      "Epoch 142/1000\n",
      "32/32 [==============================] - 0s 158us/step - loss: 0.0042 - val_loss: 0.0045\n",
      "Epoch 143/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 0.0042 - val_loss: 0.0045\n",
      "Epoch 144/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 0.0041 - val_loss: 0.0045\n",
      "Epoch 145/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0041 - val_loss: 0.0044\n",
      "Epoch 146/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0041 - val_loss: 0.0044\n",
      "Epoch 147/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0040 - val_loss: 0.0044\n",
      "Epoch 148/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0040 - val_loss: 0.0044\n",
      "Epoch 149/1000\n",
      "32/32 [==============================] - 0s 172us/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 150/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0040 - val_loss: 0.0043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 152/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 0.0039 - val_loss: 0.0042\n",
      "Epoch 153/1000\n",
      "32/32 [==============================] - 0s 137us/step - loss: 0.0039 - val_loss: 0.0042\n",
      "Epoch 154/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0039 - val_loss: 0.0041\n",
      "Epoch 155/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0039 - val_loss: 0.0041\n",
      "Epoch 156/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0038 - val_loss: 0.0040\n",
      "Epoch 157/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0038 - val_loss: 0.0040\n",
      "Epoch 158/1000\n",
      "32/32 [==============================] - 0s 177us/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 159/1000\n",
      "32/32 [==============================] - 0s 169us/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 160/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0037 - val_loss: 0.0039\n",
      "Epoch 161/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 162/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 163/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 164/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 165/1000\n",
      "32/32 [==============================] - 0s 164us/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 166/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 167/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 168/1000\n",
      "32/32 [==============================] - 0s 137us/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 169/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 170/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 171/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 172/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 0.0035 - val_loss: 0.0034\n",
      "Epoch 173/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 0.0035 - val_loss: 0.0034\n",
      "Epoch 174/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0035 - val_loss: 0.0034\n",
      "Epoch 175/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 176/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 177/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 178/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 179/1000\n",
      "32/32 [==============================] - 0s 121us/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 180/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 181/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 182/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 183/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 184/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 185/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 186/1000\n",
      "32/32 [==============================] - 0s 179us/step - loss: 0.0032 - val_loss: 0.0031\n",
      "Epoch 187/1000\n",
      "32/32 [==============================] - 0s 160us/step - loss: 0.0032 - val_loss: 0.0030\n",
      "Epoch 188/1000\n",
      "32/32 [==============================] - 0s 128us/step - loss: 0.0032 - val_loss: 0.0030\n",
      "Epoch 189/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0032 - val_loss: 0.0030\n",
      "Epoch 190/1000\n",
      "32/32 [==============================] - 0s 163us/step - loss: 0.0032 - val_loss: 0.0030\n",
      "Epoch 191/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 0.0029\n",
      "Epoch 192/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0031 - val_loss: 0.0029\n",
      "Epoch 193/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0031 - val_loss: 0.0029\n",
      "Epoch 194/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0031 - val_loss: 0.0029\n",
      "Epoch 195/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0031 - val_loss: 0.0028\n",
      "Epoch 196/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 0.0031 - val_loss: 0.0028\n",
      "Epoch 197/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 0.0031 - val_loss: 0.0028\n",
      "Epoch 198/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0031 - val_loss: 0.0028\n",
      "Epoch 199/1000\n",
      "32/32 [==============================] - 0s 145us/step - loss: 0.0030 - val_loss: 0.0027\n",
      "Epoch 200/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 0.0027\n",
      "Epoch 201/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 0.0027\n",
      "Epoch 202/1000\n",
      "32/32 [==============================] - 0s 121us/step - loss: 0.0030 - val_loss: 0.0027\n",
      "Epoch 203/1000\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0030 - val_loss: 0.0026\n",
      "Epoch 204/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 0.0026\n",
      "Epoch 205/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 0.0029 - val_loss: 0.0026\n",
      "Epoch 206/1000\n",
      "32/32 [==============================] - 0s 133us/step - loss: 0.0029 - val_loss: 0.0026\n",
      "Epoch 207/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 0.0026\n",
      "Epoch 208/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 0.0029 - val_loss: 0.0025\n",
      "Epoch 209/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0029 - val_loss: 0.0025\n",
      "Epoch 210/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 0.0025\n",
      "Epoch 211/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 0.0025\n",
      "Epoch 212/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 0.0028 - val_loss: 0.0025\n",
      "Epoch 213/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 0.0028 - val_loss: 0.0024\n",
      "Epoch 214/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 0.0028 - val_loss: 0.0024\n",
      "Epoch 215/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 0.0024\n",
      "Epoch 216/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 0.0024\n",
      "Epoch 217/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 0.0024\n",
      "Epoch 218/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0028 - val_loss: 0.0023\n",
      "Epoch 219/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 0.0023\n",
      "Epoch 220/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0027 - val_loss: 0.0023\n",
      "Epoch 221/1000\n",
      "32/32 [==============================] - 0s 167us/step - loss: 0.0027 - val_loss: 0.0023\n",
      "Epoch 222/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 0.0023\n",
      "Epoch 223/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 0.0022\n",
      "Epoch 224/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 0.0022\n",
      "Epoch 225/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0027 - val_loss: 0.0022\n",
      "Epoch 226/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 0.0027 - val_loss: 0.0022\n",
      "Epoch 227/1000\n",
      "32/32 [==============================] - 0s 138us/step - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 228/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 0.0021\n",
      "Epoch 229/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 0.0021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 230/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0026 - val_loss: 0.0021\n",
      "Epoch 231/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 0.0026 - val_loss: 0.0021\n",
      "Epoch 232/1000\n",
      "32/32 [==============================] - 0s 122us/step - loss: 0.0026 - val_loss: 0.0021\n",
      "Epoch 233/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0026 - val_loss: 0.0021\n",
      "Epoch 234/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 0.0026 - val_loss: 0.0020\n",
      "Epoch 235/1000\n",
      "32/32 [==============================] - 0s 130us/step - loss: 0.0026 - val_loss: 0.0020\n",
      "Epoch 236/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 0.0020\n",
      "Epoch 237/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 0.0025 - val_loss: 0.0020\n",
      "Epoch 238/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0025 - val_loss: 0.0020\n",
      "Epoch 239/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0025 - val_loss: 0.0020\n",
      "Epoch 240/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 241/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 242/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 243/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 244/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.0019\n",
      "Epoch 245/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0024 - val_loss: 0.0019\n",
      "Epoch 246/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0024 - val_loss: 0.0019\n",
      "Epoch 247/1000\n",
      "32/32 [==============================] - 0s 145us/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 248/1000\n",
      "32/32 [==============================] - 0s 181us/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 249/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 250/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 251/1000\n",
      "32/32 [==============================] - 0s 171us/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 252/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 253/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 254/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.0017\n",
      "Epoch 255/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 0.0023 - val_loss: 0.0017\n",
      "Epoch 256/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.0017\n",
      "Epoch 257/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.0017\n",
      "Epoch 258/1000\n",
      "32/32 [==============================] - 0s 130us/step - loss: 0.0023 - val_loss: 0.0017\n",
      "Epoch 259/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 0.0023 - val_loss: 0.0017\n",
      "Epoch 260/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.0017\n",
      "Epoch 261/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0023 - val_loss: 0.0016\n",
      "Epoch 262/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.0016\n",
      "Epoch 263/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 264/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 265/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 266/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 267/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 268/1000\n",
      "32/32 [==============================] - 0s 137us/step - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 269/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 270/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 271/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 272/1000\n",
      "32/32 [==============================] - 0s 161us/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 273/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 274/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 275/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 276/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 277/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 278/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 279/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 280/1000\n",
      "32/32 [==============================] - 0s 178us/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 281/1000\n",
      "32/32 [==============================] - 0s 145us/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 282/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 283/1000\n",
      "32/32 [==============================] - 0s 138us/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 284/1000\n",
      "32/32 [==============================] - 0s 137us/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 285/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 286/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 287/1000\n",
      "32/32 [==============================] - 0s 121us/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 288/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 289/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 290/1000\n",
      "32/32 [==============================] - 0s 160us/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 291/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 292/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 293/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 294/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 295/1000\n",
      "32/32 [==============================] - 0s 145us/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 296/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 297/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 298/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 299/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 300/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 301/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 302/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 303/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 304/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 305/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 306/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 307/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 308/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 309/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 310/1000\n",
      "32/32 [==============================] - 0s 133us/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 311/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 312/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 313/1000\n",
      "32/32 [==============================] - 0s 120us/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 314/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 315/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 316/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 317/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 318/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 319/1000\n",
      "32/32 [==============================] - 0s 138us/step - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 320/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 321/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 322/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 323/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 9.9194e-04\n",
      "Epoch 324/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0017 - val_loss: 9.8390e-04\n",
      "Epoch 325/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 9.7591e-04\n",
      "Epoch 326/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0017 - val_loss: 9.6800e-04\n",
      "Epoch 327/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 9.6015e-04\n",
      "Epoch 328/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 9.5233e-04\n",
      "Epoch 329/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 0.0017 - val_loss: 9.4463e-04\n",
      "Epoch 330/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0017 - val_loss: 9.3696e-04\n",
      "Epoch 331/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 9.2935e-04\n",
      "Epoch 332/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 9.2181e-04\n",
      "Epoch 333/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 0.0017 - val_loss: 9.1431e-04\n",
      "Epoch 334/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0017 - val_loss: 9.0689e-04\n",
      "Epoch 335/1000\n",
      "32/32 [==============================] - 0s 160us/step - loss: 0.0017 - val_loss: 8.9953e-04\n",
      "Epoch 336/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0017 - val_loss: 8.9220e-04\n",
      "Epoch 337/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 0.0017 - val_loss: 8.8494e-04\n",
      "Epoch 338/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0016 - val_loss: 8.7773e-04\n",
      "Epoch 339/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 0.0016 - val_loss: 8.7061e-04\n",
      "Epoch 340/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 8.6353e-04\n",
      "Epoch 341/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 8.5651e-04\n",
      "Epoch 342/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 0.0016 - val_loss: 8.4952e-04\n",
      "Epoch 343/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 8.4260e-04\n",
      "Epoch 344/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 8.3573e-04\n",
      "Epoch 345/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 8.2893e-04\n",
      "Epoch 346/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 8.2216e-04\n",
      "Epoch 347/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 8.1547e-04\n",
      "Epoch 348/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 8.0883e-04\n",
      "Epoch 349/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 8.0225e-04\n",
      "Epoch 350/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0016 - val_loss: 7.9569e-04\n",
      "Epoch 351/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 7.8922e-04\n",
      "Epoch 352/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 7.8277e-04\n",
      "Epoch 353/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 0.0016 - val_loss: 7.7639e-04\n",
      "Epoch 354/1000\n",
      "32/32 [==============================] - 0s 130us/step - loss: 0.0015 - val_loss: 7.7004e-04\n",
      "Epoch 355/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0015 - val_loss: 7.6376e-04\n",
      "Epoch 356/1000\n",
      "32/32 [==============================] - 0s 172us/step - loss: 0.0015 - val_loss: 7.5752e-04\n",
      "Epoch 357/1000\n",
      "32/32 [==============================] - 0s 164us/step - loss: 0.0015 - val_loss: 7.5131e-04\n",
      "Epoch 358/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 7.4520e-04\n",
      "Epoch 359/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 7.3912e-04\n",
      "Epoch 360/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 0.0015 - val_loss: 7.3305e-04\n",
      "Epoch 361/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 7.2707e-04\n",
      "Epoch 362/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 7.2112e-04\n",
      "Epoch 363/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0015 - val_loss: 7.1522e-04\n",
      "Epoch 364/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 0.0015 - val_loss: 7.0935e-04\n",
      "Epoch 365/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 7.0356e-04\n",
      "Epoch 366/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 6.9780e-04\n",
      "Epoch 367/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 6.9208e-04\n",
      "Epoch 368/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0015 - val_loss: 6.8640e-04\n",
      "Epoch 369/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 6.8077e-04\n",
      "Epoch 370/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 6.7521e-04\n",
      "Epoch 371/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0015 - val_loss: 6.6967e-04\n",
      "Epoch 372/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 6.6417e-04\n",
      "Epoch 373/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 6.5874e-04\n",
      "Epoch 374/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 6.5333e-04\n",
      "Epoch 375/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 6.4795e-04\n",
      "Epoch 376/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 6.4263e-04\n",
      "Epoch 377/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 6.3737e-04\n",
      "Epoch 378/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 6.3214e-04\n",
      "Epoch 379/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 6.2692e-04\n",
      "Epoch 380/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 6.2177e-04\n",
      "Epoch 381/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 0.0014 - val_loss: 6.1667e-04\n",
      "Epoch 382/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 0.0014 - val_loss: 6.1160e-04\n",
      "Epoch 383/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 0.0014 - val_loss: 6.0657e-04\n",
      "Epoch 384/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 6.0158e-04\n",
      "Epoch 385/1000\n",
      "32/32 [==============================] - 0s 172us/step - loss: 0.0014 - val_loss: 5.9662e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 386/1000\n",
      "32/32 [==============================] - 0s 162us/step - loss: 0.0014 - val_loss: 5.9172e-04\n",
      "Epoch 387/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 5.8685e-04\n",
      "Epoch 388/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0014 - val_loss: 5.8202e-04\n",
      "Epoch 389/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 5.7722e-04\n",
      "Epoch 390/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 5.7248e-04\n",
      "Epoch 391/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 0.0013 - val_loss: 5.6776e-04\n",
      "Epoch 392/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 5.6305e-04\n",
      "Epoch 393/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 5.5839e-04\n",
      "Epoch 394/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0013 - val_loss: 5.5383e-04\n",
      "Epoch 395/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 5.4925e-04\n",
      "Epoch 396/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 5.4470e-04\n",
      "Epoch 397/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 5.4022e-04\n",
      "Epoch 398/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0013 - val_loss: 5.3576e-04\n",
      "Epoch 399/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0013 - val_loss: 5.3132e-04\n",
      "Epoch 400/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0013 - val_loss: 5.2694e-04\n",
      "Epoch 401/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0013 - val_loss: 5.2258e-04\n",
      "Epoch 402/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0013 - val_loss: 5.1825e-04\n",
      "Epoch 403/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 0.0013 - val_loss: 5.1396e-04\n",
      "Epoch 404/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 0.0013 - val_loss: 5.0971e-04\n",
      "Epoch 405/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 5.0552e-04\n",
      "Epoch 406/1000\n",
      "32/32 [==============================] - 0s 163us/step - loss: 0.0013 - val_loss: 5.0131e-04\n",
      "Epoch 407/1000\n",
      "32/32 [==============================] - 0s 164us/step - loss: 0.0013 - val_loss: 4.9716e-04\n",
      "Epoch 408/1000\n",
      "32/32 [==============================] - 0s 164us/step - loss: 0.0013 - val_loss: 4.9306e-04\n",
      "Epoch 409/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0013 - val_loss: 4.8897e-04\n",
      "Epoch 410/1000\n",
      "32/32 [==============================] - 0s 145us/step - loss: 0.0013 - val_loss: 4.8490e-04\n",
      "Epoch 411/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 4.8088e-04\n",
      "Epoch 412/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 0.0013 - val_loss: 4.7693e-04\n",
      "Epoch 413/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 4.7296e-04\n",
      "Epoch 414/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0012 - val_loss: 4.6904e-04\n",
      "Epoch 415/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 0.0012 - val_loss: 4.6516e-04\n",
      "Epoch 416/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 4.6128e-04\n",
      "Epoch 417/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 0.0012 - val_loss: 4.5745e-04\n",
      "Epoch 418/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0012 - val_loss: 4.5365e-04\n",
      "Epoch 419/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0012 - val_loss: 4.4989e-04\n",
      "Epoch 420/1000\n",
      "32/32 [==============================] - 0s 173us/step - loss: 0.0012 - val_loss: 4.4614e-04\n",
      "Epoch 421/1000\n",
      "32/32 [==============================] - 0s 180us/step - loss: 0.0012 - val_loss: 4.4244e-04\n",
      "Epoch 422/1000\n",
      "32/32 [==============================] - 0s 164us/step - loss: 0.0012 - val_loss: 4.3876e-04\n",
      "Epoch 423/1000\n",
      "32/32 [==============================] - 0s 162us/step - loss: 0.0012 - val_loss: 4.3510e-04\n",
      "Epoch 424/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 4.3150e-04\n",
      "Epoch 425/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0012 - val_loss: 4.2790e-04\n",
      "Epoch 426/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0012 - val_loss: 4.2435e-04\n",
      "Epoch 427/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 4.2080e-04\n",
      "Epoch 428/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 4.1731e-04\n",
      "Epoch 429/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 4.1384e-04\n",
      "Epoch 430/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 4.1039e-04\n",
      "Epoch 431/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0012 - val_loss: 4.0697e-04\n",
      "Epoch 432/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 0.0012 - val_loss: 4.0357e-04\n",
      "Epoch 433/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 0.0012 - val_loss: 4.0021e-04\n",
      "Epoch 434/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 3.9688e-04\n",
      "Epoch 435/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 0.0012 - val_loss: 3.9357e-04\n",
      "Epoch 436/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 3.9029e-04\n",
      "Epoch 437/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 3.8705e-04\n",
      "Epoch 438/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 0.0011 - val_loss: 3.8381e-04\n",
      "Epoch 439/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 0.0011 - val_loss: 3.8059e-04\n",
      "Epoch 440/1000\n",
      "32/32 [==============================] - 0s 177us/step - loss: 0.0011 - val_loss: 3.7742e-04\n",
      "Epoch 441/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 3.7429e-04\n",
      "Epoch 442/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 0.0011 - val_loss: 3.7115e-04\n",
      "Epoch 443/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 3.6805e-04\n",
      "Epoch 444/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0011 - val_loss: 3.6496e-04\n",
      "Epoch 445/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0011 - val_loss: 3.6191e-04\n",
      "Epoch 446/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 3.5890e-04\n",
      "Epoch 447/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 3.5591e-04\n",
      "Epoch 448/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 3.5292e-04\n",
      "Epoch 449/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 3.4996e-04\n",
      "Epoch 450/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 0.0011 - val_loss: 3.4704e-04\n",
      "Epoch 451/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 3.4413e-04\n",
      "Epoch 452/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0011 - val_loss: 3.4126e-04\n",
      "Epoch 453/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0011 - val_loss: 3.3839e-04\n",
      "Epoch 454/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 0.0011 - val_loss: 3.3556e-04\n",
      "Epoch 455/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0011 - val_loss: 3.3275e-04\n",
      "Epoch 456/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 0.0011 - val_loss: 3.2996e-04\n",
      "Epoch 457/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0011 - val_loss: 3.2720e-04\n",
      "Epoch 458/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 3.2447e-04\n",
      "Epoch 459/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 3.2174e-04\n",
      "Epoch 460/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 3.1904e-04\n",
      "Epoch 461/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 0.0011 - val_loss: 3.1635e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 462/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 0.0011 - val_loss: 3.1370e-04\n",
      "Epoch 463/1000\n",
      "32/32 [==============================] - 0s 137us/step - loss: 0.0010 - val_loss: 3.1107e-04\n",
      "Epoch 464/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0010 - val_loss: 3.0847e-04\n",
      "Epoch 465/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 3.0588e-04\n",
      "Epoch 466/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 3.0333e-04\n",
      "Epoch 467/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0010 - val_loss: 3.0077e-04\n",
      "Epoch 468/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0010 - val_loss: 2.9825e-04\n",
      "Epoch 469/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 2.9573e-04\n",
      "Epoch 470/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 0.0010 - val_loss: 2.9326e-04\n",
      "Epoch 471/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 2.9079e-04\n",
      "Epoch 472/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 2.8835e-04\n",
      "Epoch 473/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 2.8593e-04\n",
      "Epoch 474/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 2.8352e-04\n",
      "Epoch 475/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 2.8114e-04\n",
      "Epoch 476/1000\n",
      "32/32 [==============================] - 0s 169us/step - loss: 0.0010 - val_loss: 2.7878e-04\n",
      "Epoch 477/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0010 - val_loss: 2.7644e-04\n",
      "Epoch 478/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 9.9775e-04 - val_loss: 2.7410e-04\n",
      "Epoch 479/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.9447e-04 - val_loss: 2.7181e-04\n",
      "Epoch 480/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.9121e-04 - val_loss: 2.6951e-04\n",
      "Epoch 481/1000\n",
      "32/32 [==============================] - 0s 131us/step - loss: 9.8798e-04 - val_loss: 2.6725e-04\n",
      "Epoch 482/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 9.8475e-04 - val_loss: 2.6501e-04\n",
      "Epoch 483/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.8152e-04 - val_loss: 2.6277e-04\n",
      "Epoch 484/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.7833e-04 - val_loss: 2.6056e-04\n",
      "Epoch 485/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.7513e-04 - val_loss: 2.5837e-04\n",
      "Epoch 486/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 9.7197e-04 - val_loss: 2.5620e-04\n",
      "Epoch 487/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 9.6881e-04 - val_loss: 2.5404e-04\n",
      "Epoch 488/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6566e-04 - val_loss: 2.5190e-04\n",
      "Epoch 489/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6253e-04 - val_loss: 2.4977e-04\n",
      "Epoch 490/1000\n",
      "32/32 [==============================] - 0s 174us/step - loss: 9.5940e-04 - val_loss: 2.4769e-04\n",
      "Epoch 491/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.5630e-04 - val_loss: 2.4559e-04\n",
      "Epoch 492/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 9.5320e-04 - val_loss: 2.4354e-04\n",
      "Epoch 493/1000\n",
      "32/32 [==============================] - 0s 131us/step - loss: 9.5013e-04 - val_loss: 2.4147e-04\n",
      "Epoch 494/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 9.4706e-04 - val_loss: 2.3944e-04\n",
      "Epoch 495/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4401e-04 - val_loss: 2.3742e-04\n",
      "Epoch 496/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4096e-04 - val_loss: 2.3542e-04\n",
      "Epoch 497/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.3794e-04 - val_loss: 2.3345e-04\n",
      "Epoch 498/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.3493e-04 - val_loss: 2.3147e-04\n",
      "Epoch 499/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.3192e-04 - val_loss: 2.2953e-04\n",
      "Epoch 500/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.2894e-04 - val_loss: 2.2759e-04\n",
      "Epoch 501/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.2598e-04 - val_loss: 2.2569e-04\n",
      "Epoch 502/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.2300e-04 - val_loss: 2.2378e-04\n",
      "Epoch 503/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.2006e-04 - val_loss: 2.2190e-04\n",
      "Epoch 504/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1710e-04 - val_loss: 2.2002e-04\n",
      "Epoch 505/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1418e-04 - val_loss: 2.1817e-04\n",
      "Epoch 506/1000\n",
      "32/32 [==============================] - 0s 160us/step - loss: 9.1128e-04 - val_loss: 2.1632e-04\n",
      "Epoch 507/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.0837e-04 - val_loss: 2.1450e-04\n",
      "Epoch 508/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.0549e-04 - val_loss: 2.1269e-04\n",
      "Epoch 509/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.0261e-04 - val_loss: 2.1089e-04\n",
      "Epoch 510/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 8.9974e-04 - val_loss: 2.0911e-04\n",
      "Epoch 511/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9691e-04 - val_loss: 2.0737e-04\n",
      "Epoch 512/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 8.9406e-04 - val_loss: 2.0562e-04\n",
      "Epoch 513/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.9122e-04 - val_loss: 2.0389e-04\n",
      "Epoch 514/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.8840e-04 - val_loss: 2.0216e-04\n",
      "Epoch 515/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.8561e-04 - val_loss: 2.0046e-04\n",
      "Epoch 516/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.8282e-04 - val_loss: 1.9876e-04\n",
      "Epoch 517/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.8003e-04 - val_loss: 1.9708e-04\n",
      "Epoch 518/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.7726e-04 - val_loss: 1.9543e-04\n",
      "Epoch 519/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7451e-04 - val_loss: 1.9379e-04\n",
      "Epoch 520/1000\n",
      "32/32 [==============================] - 0s 129us/step - loss: 8.7175e-04 - val_loss: 1.9216e-04\n",
      "Epoch 521/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 8.6903e-04 - val_loss: 1.9053e-04\n",
      "Epoch 522/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.6630e-04 - val_loss: 1.8893e-04\n",
      "Epoch 523/1000\n",
      "32/32 [==============================] - 0s 172us/step - loss: 8.6360e-04 - val_loss: 1.8733e-04\n",
      "Epoch 524/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 8.6089e-04 - val_loss: 1.8575e-04\n",
      "Epoch 525/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.5820e-04 - val_loss: 1.8419e-04\n",
      "Epoch 526/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5551e-04 - val_loss: 1.8263e-04\n",
      "Epoch 527/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.5285e-04 - val_loss: 1.8109e-04\n",
      "Epoch 528/1000\n",
      "32/32 [==============================] - 0s 162us/step - loss: 8.5019e-04 - val_loss: 1.7957e-04\n",
      "Epoch 529/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.4753e-04 - val_loss: 1.7805e-04\n",
      "Epoch 530/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 8.4491e-04 - val_loss: 1.7655e-04\n",
      "Epoch 531/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.4228e-04 - val_loss: 1.7508e-04\n",
      "Epoch 532/1000\n",
      "32/32 [==============================] - 0s 137us/step - loss: 8.3966e-04 - val_loss: 1.7360e-04\n",
      "Epoch 533/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3706e-04 - val_loss: 1.7214e-04\n",
      "Epoch 534/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3447e-04 - val_loss: 1.7069e-04\n",
      "Epoch 535/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.3189e-04 - val_loss: 1.6925e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 536/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.2931e-04 - val_loss: 1.6784e-04\n",
      "Epoch 537/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.2675e-04 - val_loss: 1.6641e-04\n",
      "Epoch 538/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2419e-04 - val_loss: 1.6500e-04\n",
      "Epoch 539/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 8.2166e-04 - val_loss: 1.6363e-04\n",
      "Epoch 540/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.1911e-04 - val_loss: 1.6224e-04\n",
      "Epoch 541/1000\n",
      "32/32 [==============================] - 0s 173us/step - loss: 8.1660e-04 - val_loss: 1.6088e-04\n",
      "Epoch 542/1000\n",
      "32/32 [==============================] - 0s 160us/step - loss: 8.1410e-04 - val_loss: 1.5953e-04\n",
      "Epoch 543/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.1158e-04 - val_loss: 1.5819e-04\n",
      "Epoch 544/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0912e-04 - val_loss: 1.5686e-04\n",
      "Epoch 545/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.0662e-04 - val_loss: 1.5554e-04\n",
      "Epoch 546/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 8.0416e-04 - val_loss: 1.5423e-04\n",
      "Epoch 547/1000\n",
      "32/32 [==============================] - 0s 145us/step - loss: 8.0169e-04 - val_loss: 1.5293e-04\n",
      "Epoch 548/1000\n",
      "32/32 [==============================] - 0s 164us/step - loss: 7.9924e-04 - val_loss: 1.5165e-04\n",
      "Epoch 549/1000\n",
      "32/32 [==============================] - 0s 164us/step - loss: 7.9680e-04 - val_loss: 1.5038e-04\n",
      "Epoch 550/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 7.9437e-04 - val_loss: 1.4911e-04\n",
      "Epoch 551/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9194e-04 - val_loss: 1.4786e-04\n",
      "Epoch 552/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8954e-04 - val_loss: 1.4661e-04\n",
      "Epoch 553/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.8713e-04 - val_loss: 1.4539e-04\n",
      "Epoch 554/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 7.8473e-04 - val_loss: 1.4417e-04\n",
      "Epoch 555/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.8235e-04 - val_loss: 1.4296e-04\n",
      "Epoch 556/1000\n",
      "32/32 [==============================] - 0s 195us/step - loss: 7.7999e-04 - val_loss: 1.4176e-04\n",
      "Epoch 557/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7761e-04 - val_loss: 1.4056e-04\n",
      "Epoch 558/1000\n",
      "32/32 [==============================] - 0s 132us/step - loss: 7.7526e-04 - val_loss: 1.3939e-04\n",
      "Epoch 559/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.7291e-04 - val_loss: 1.3821e-04\n",
      "Epoch 560/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.7057e-04 - val_loss: 1.3706e-04\n",
      "Epoch 561/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.6824e-04 - val_loss: 1.3592e-04\n",
      "Epoch 562/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.6592e-04 - val_loss: 1.3477e-04\n",
      "Epoch 563/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 7.6361e-04 - val_loss: 1.3364e-04\n",
      "Epoch 564/1000\n",
      "32/32 [==============================] - 0s 164us/step - loss: 7.6130e-04 - val_loss: 1.3252e-04\n",
      "Epoch 565/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.5902e-04 - val_loss: 1.3140e-04\n",
      "Epoch 566/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 7.5673e-04 - val_loss: 1.3032e-04\n",
      "Epoch 567/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5447e-04 - val_loss: 1.2922e-04\n",
      "Epoch 568/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5220e-04 - val_loss: 1.2814e-04\n",
      "Epoch 569/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.4994e-04 - val_loss: 1.2707e-04\n",
      "Epoch 570/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.4768e-04 - val_loss: 1.2600e-04\n",
      "Epoch 571/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.4545e-04 - val_loss: 1.2495e-04\n",
      "Epoch 572/1000\n",
      "32/32 [==============================] - 0s 173us/step - loss: 7.4321e-04 - val_loss: 1.2392e-04\n",
      "Epoch 573/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4099e-04 - val_loss: 1.2287e-04\n",
      "Epoch 574/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 7.3877e-04 - val_loss: 1.2186e-04\n",
      "Epoch 575/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.3658e-04 - val_loss: 1.2083e-04\n",
      "Epoch 576/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3438e-04 - val_loss: 1.1983e-04\n",
      "Epoch 577/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.3219e-04 - val_loss: 1.1882e-04\n",
      "Epoch 578/1000\n",
      "32/32 [==============================] - 0s 169us/step - loss: 7.3000e-04 - val_loss: 1.1784e-04\n",
      "Epoch 579/1000\n",
      "32/32 [==============================] - 0s 137us/step - loss: 7.2784e-04 - val_loss: 1.1685e-04\n",
      "Epoch 580/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2567e-04 - val_loss: 1.1588e-04\n",
      "Epoch 581/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.2350e-04 - val_loss: 1.1491e-04\n",
      "Epoch 582/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.2136e-04 - val_loss: 1.1395e-04\n",
      "Epoch 583/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.1923e-04 - val_loss: 1.1301e-04\n",
      "Epoch 584/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1708e-04 - val_loss: 1.1207e-04\n",
      "Epoch 585/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1498e-04 - val_loss: 1.1113e-04\n",
      "Epoch 586/1000\n",
      "32/32 [==============================] - 0s 163us/step - loss: 7.1287e-04 - val_loss: 1.1020e-04\n",
      "Epoch 587/1000\n",
      "32/32 [==============================] - 0s 132us/step - loss: 7.1076e-04 - val_loss: 1.0930e-04\n",
      "Epoch 588/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.0865e-04 - val_loss: 1.0838e-04\n",
      "Epoch 589/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0656e-04 - val_loss: 1.0749e-04\n",
      "Epoch 590/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0448e-04 - val_loss: 1.0659e-04\n",
      "Epoch 591/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0240e-04 - val_loss: 1.0571e-04\n",
      "Epoch 592/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.0033e-04 - val_loss: 1.0483e-04\n",
      "Epoch 593/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 6.9826e-04 - val_loss: 1.0396e-04\n",
      "Epoch 594/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 6.9621e-04 - val_loss: 1.0310e-04\n",
      "Epoch 595/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.9418e-04 - val_loss: 1.0225e-04\n",
      "Epoch 596/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9214e-04 - val_loss: 1.0140e-04\n",
      "Epoch 597/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9010e-04 - val_loss: 1.0057e-04\n",
      "Epoch 598/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 6.8808e-04 - val_loss: 9.9727e-05\n",
      "Epoch 599/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 6.8606e-04 - val_loss: 9.8902e-05\n",
      "Epoch 600/1000\n",
      "32/32 [==============================] - 0s 137us/step - loss: 6.8406e-04 - val_loss: 9.8079e-05\n",
      "Epoch 601/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 6.8207e-04 - val_loss: 9.7274e-05\n",
      "Epoch 602/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.8006e-04 - val_loss: 9.6473e-05\n",
      "Epoch 603/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 6.7807e-04 - val_loss: 9.5675e-05\n",
      "Epoch 604/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 6.7610e-04 - val_loss: 9.4885e-05\n",
      "Epoch 605/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7412e-04 - val_loss: 9.4110e-05\n",
      "Epoch 606/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7216e-04 - val_loss: 9.3332e-05\n",
      "Epoch 607/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.7022e-04 - val_loss: 9.2575e-05\n",
      "Epoch 608/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6825e-04 - val_loss: 9.1803e-05\n",
      "Epoch 609/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6632e-04 - val_loss: 9.1046e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 610/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6437e-04 - val_loss: 9.0305e-05\n",
      "Epoch 611/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6246e-04 - val_loss: 8.9559e-05\n",
      "Epoch 612/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 6.6053e-04 - val_loss: 8.8822e-05\n",
      "Epoch 613/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5862e-04 - val_loss: 8.8094e-05\n",
      "Epoch 614/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5671e-04 - val_loss: 8.7377e-05\n",
      "Epoch 615/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5481e-04 - val_loss: 8.6658e-05\n",
      "Epoch 616/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5291e-04 - val_loss: 8.5954e-05\n",
      "Epoch 617/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5103e-04 - val_loss: 8.5252e-05\n",
      "Epoch 618/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4914e-04 - val_loss: 8.4549e-05\n",
      "Epoch 619/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4728e-04 - val_loss: 8.3854e-05\n",
      "Epoch 620/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4541e-04 - val_loss: 8.3174e-05\n",
      "Epoch 621/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.4355e-04 - val_loss: 8.2494e-05\n",
      "Epoch 622/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.4170e-04 - val_loss: 8.1821e-05\n",
      "Epoch 623/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3985e-04 - val_loss: 8.1152e-05\n",
      "Epoch 624/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3801e-04 - val_loss: 8.0492e-05\n",
      "Epoch 625/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.3616e-04 - val_loss: 7.9843e-05\n",
      "Epoch 626/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3435e-04 - val_loss: 7.9192e-05\n",
      "Epoch 627/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 6.3253e-04 - val_loss: 7.8540e-05\n",
      "Epoch 628/1000\n",
      "32/32 [==============================] - 0s 175us/step - loss: 6.3070e-04 - val_loss: 7.7900e-05\n",
      "Epoch 629/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 6.2891e-04 - val_loss: 7.7275e-05\n",
      "Epoch 630/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.2710e-04 - val_loss: 7.6654e-05\n",
      "Epoch 631/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 6.2530e-04 - val_loss: 7.6024e-05\n",
      "Epoch 632/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 6.2352e-04 - val_loss: 7.5415e-05\n",
      "Epoch 633/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 6.2174e-04 - val_loss: 7.4795e-05\n",
      "Epoch 634/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1995e-04 - val_loss: 7.4192e-05\n",
      "Epoch 635/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 6.1819e-04 - val_loss: 7.3591e-05\n",
      "Epoch 636/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1643e-04 - val_loss: 7.2999e-05\n",
      "Epoch 637/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 6.1467e-04 - val_loss: 7.2413e-05\n",
      "Epoch 638/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.1292e-04 - val_loss: 7.1827e-05\n",
      "Epoch 639/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 6.1118e-04 - val_loss: 7.1249e-05\n",
      "Epoch 640/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.0942e-04 - val_loss: 7.0684e-05\n",
      "Epoch 641/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 6.0770e-04 - val_loss: 7.0113e-05\n",
      "Epoch 642/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 6.0597e-04 - val_loss: 6.9546e-05\n",
      "Epoch 643/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 6.0426e-04 - val_loss: 6.8990e-05\n",
      "Epoch 644/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.0254e-04 - val_loss: 6.8433e-05\n",
      "Epoch 645/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0083e-04 - val_loss: 6.7885e-05\n",
      "Epoch 646/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 5.9913e-04 - val_loss: 6.7344e-05\n",
      "Epoch 647/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 5.9743e-04 - val_loss: 6.6800e-05\n",
      "Epoch 648/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9573e-04 - val_loss: 6.6273e-05\n",
      "Epoch 649/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9404e-04 - val_loss: 6.5744e-05\n",
      "Epoch 650/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 5.9236e-04 - val_loss: 6.5220e-05\n",
      "Epoch 651/1000\n",
      "32/32 [==============================] - 0s 137us/step - loss: 5.9069e-04 - val_loss: 6.4705e-05\n",
      "Epoch 652/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 5.8901e-04 - val_loss: 6.4186e-05\n",
      "Epoch 653/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.8736e-04 - val_loss: 6.3672e-05\n",
      "Epoch 654/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8570e-04 - val_loss: 6.3170e-05\n",
      "Epoch 655/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.8405e-04 - val_loss: 6.2666e-05\n",
      "Epoch 656/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 5.8240e-04 - val_loss: 6.2168e-05\n",
      "Epoch 657/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8076e-04 - val_loss: 6.1679e-05\n",
      "Epoch 658/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7913e-04 - val_loss: 6.1186e-05\n",
      "Epoch 659/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7750e-04 - val_loss: 6.0710e-05\n",
      "Epoch 660/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.7588e-04 - val_loss: 6.0226e-05\n",
      "Epoch 661/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7426e-04 - val_loss: 5.9751e-05\n",
      "Epoch 662/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7265e-04 - val_loss: 5.9287e-05\n",
      "Epoch 663/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7104e-04 - val_loss: 5.8816e-05\n",
      "Epoch 664/1000\n",
      "32/32 [==============================] - 0s 137us/step - loss: 5.6944e-04 - val_loss: 5.8355e-05\n",
      "Epoch 665/1000\n",
      "32/32 [==============================] - 0s 133us/step - loss: 5.6784e-04 - val_loss: 5.7893e-05\n",
      "Epoch 666/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6625e-04 - val_loss: 5.7444e-05\n",
      "Epoch 667/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 5.6467e-04 - val_loss: 5.6993e-05\n",
      "Epoch 668/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6310e-04 - val_loss: 5.6543e-05\n",
      "Epoch 669/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6151e-04 - val_loss: 5.6104e-05\n",
      "Epoch 670/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 5.5994e-04 - val_loss: 5.5666e-05\n",
      "Epoch 671/1000\n",
      "32/32 [==============================] - 0s 127us/step - loss: 5.5837e-04 - val_loss: 5.5232e-05\n",
      "Epoch 672/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.5682e-04 - val_loss: 5.4802e-05\n",
      "Epoch 673/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 5.5526e-04 - val_loss: 5.4374e-05\n",
      "Epoch 674/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5371e-04 - val_loss: 5.3951e-05\n",
      "Epoch 675/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5216e-04 - val_loss: 5.3533e-05\n",
      "Epoch 676/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5062e-04 - val_loss: 5.3113e-05\n",
      "Epoch 677/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 5.4909e-04 - val_loss: 5.2700e-05\n",
      "Epoch 678/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.4757e-04 - val_loss: 5.2297e-05\n",
      "Epoch 679/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4603e-04 - val_loss: 5.1890e-05\n",
      "Epoch 680/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.4452e-04 - val_loss: 5.1494e-05\n",
      "Epoch 681/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4301e-04 - val_loss: 5.1095e-05\n",
      "Epoch 682/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.4149e-04 - val_loss: 5.0698e-05\n",
      "Epoch 683/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3999e-04 - val_loss: 5.0311e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 684/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3850e-04 - val_loss: 4.9927e-05\n",
      "Epoch 685/1000\n",
      "32/32 [==============================] - 0s 116us/step - loss: 5.3700e-04 - val_loss: 4.9541e-05\n",
      "Epoch 686/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3551e-04 - val_loss: 4.9163e-05\n",
      "Epoch 687/1000\n",
      "32/32 [==============================] - 0s 191us/step - loss: 5.3403e-04 - val_loss: 4.8788e-05\n",
      "Epoch 688/1000\n",
      "32/32 [==============================] - 0s 158us/step - loss: 5.3255e-04 - val_loss: 4.8411e-05\n",
      "Epoch 689/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 5.3107e-04 - val_loss: 4.8046e-05\n",
      "Epoch 690/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 5.2960e-04 - val_loss: 4.7678e-05\n",
      "Epoch 691/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 5.2814e-04 - val_loss: 4.7318e-05\n",
      "Epoch 692/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2668e-04 - val_loss: 4.6951e-05\n",
      "Epoch 693/1000\n",
      "32/32 [==============================] - 0s 164us/step - loss: 5.2522e-04 - val_loss: 4.6594e-05\n",
      "Epoch 694/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2377e-04 - val_loss: 4.6248e-05\n",
      "Epoch 695/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 5.2233e-04 - val_loss: 4.5897e-05\n",
      "Epoch 696/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.2088e-04 - val_loss: 4.5554e-05\n",
      "Epoch 697/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1945e-04 - val_loss: 4.5207e-05\n",
      "Epoch 698/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1801e-04 - val_loss: 4.4873e-05\n",
      "Epoch 699/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1658e-04 - val_loss: 4.4526e-05\n",
      "Epoch 700/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1515e-04 - val_loss: 4.4198e-05\n",
      "Epoch 701/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.1374e-04 - val_loss: 4.3863e-05\n",
      "Epoch 702/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.1233e-04 - val_loss: 4.3533e-05\n",
      "Epoch 703/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1092e-04 - val_loss: 4.3204e-05\n",
      "Epoch 704/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.0952e-04 - val_loss: 4.2886e-05\n",
      "Epoch 705/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0811e-04 - val_loss: 4.2562e-05\n",
      "Epoch 706/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0672e-04 - val_loss: 4.2248e-05\n",
      "Epoch 707/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0533e-04 - val_loss: 4.1936e-05\n",
      "Epoch 708/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.0394e-04 - val_loss: 4.1622e-05\n",
      "Epoch 709/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.0256e-04 - val_loss: 4.1314e-05\n",
      "Epoch 710/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.0119e-04 - val_loss: 4.1014e-05\n",
      "Epoch 711/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 4.9982e-04 - val_loss: 4.0707e-05\n",
      "Epoch 712/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9843e-04 - val_loss: 4.0402e-05\n",
      "Epoch 713/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.9707e-04 - val_loss: 4.0105e-05\n",
      "Epoch 714/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 4.9571e-04 - val_loss: 3.9812e-05\n",
      "Epoch 715/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.9436e-04 - val_loss: 3.9516e-05\n",
      "Epoch 716/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 4.9300e-04 - val_loss: 3.9231e-05\n",
      "Epoch 717/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9166e-04 - val_loss: 3.8942e-05\n",
      "Epoch 718/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.9030e-04 - val_loss: 3.8658e-05\n",
      "Epoch 719/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.8897e-04 - val_loss: 3.8376e-05\n",
      "Epoch 720/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.8763e-04 - val_loss: 3.8098e-05\n",
      "Epoch 721/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 4.8630e-04 - val_loss: 3.7820e-05\n",
      "Epoch 722/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8497e-04 - val_loss: 3.7545e-05\n",
      "Epoch 723/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8364e-04 - val_loss: 3.7275e-05\n",
      "Epoch 724/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.8233e-04 - val_loss: 3.7006e-05\n",
      "Epoch 725/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.8101e-04 - val_loss: 3.6740e-05\n",
      "Epoch 726/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.7971e-04 - val_loss: 3.6470e-05\n",
      "Epoch 727/1000\n",
      "32/32 [==============================] - 0s 131us/step - loss: 4.7840e-04 - val_loss: 3.6209e-05\n",
      "Epoch 728/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7709e-04 - val_loss: 3.5948e-05\n",
      "Epoch 729/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.7580e-04 - val_loss: 3.5695e-05\n",
      "Epoch 730/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 4.7450e-04 - val_loss: 3.5440e-05\n",
      "Epoch 731/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7321e-04 - val_loss: 3.5181e-05\n",
      "Epoch 732/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.7193e-04 - val_loss: 3.4934e-05\n",
      "Epoch 733/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7064e-04 - val_loss: 3.4683e-05\n",
      "Epoch 734/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 4.6937e-04 - val_loss: 3.4440e-05\n",
      "Epoch 735/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 4.6809e-04 - val_loss: 3.4192e-05\n",
      "Epoch 736/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.6682e-04 - val_loss: 3.3950e-05\n",
      "Epoch 737/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6555e-04 - val_loss: 3.3708e-05\n",
      "Epoch 738/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.6428e-04 - val_loss: 3.3473e-05\n",
      "Epoch 739/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 4.6303e-04 - val_loss: 3.3240e-05\n",
      "Epoch 740/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.6176e-04 - val_loss: 3.3004e-05\n",
      "Epoch 741/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.6053e-04 - val_loss: 3.2775e-05\n",
      "Epoch 742/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.5927e-04 - val_loss: 3.2542e-05\n",
      "Epoch 743/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 4.5803e-04 - val_loss: 3.2314e-05\n",
      "Epoch 744/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.5679e-04 - val_loss: 3.2092e-05\n",
      "Epoch 745/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5554e-04 - val_loss: 3.1866e-05\n",
      "Epoch 746/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.5431e-04 - val_loss: 3.1643e-05\n",
      "Epoch 747/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5308e-04 - val_loss: 3.1424e-05\n",
      "Epoch 748/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5186e-04 - val_loss: 3.1207e-05\n",
      "Epoch 749/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5064e-04 - val_loss: 3.0994e-05\n",
      "Epoch 750/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.4943e-04 - val_loss: 3.0781e-05\n",
      "Epoch 751/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.4821e-04 - val_loss: 3.0571e-05\n",
      "Epoch 752/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4700e-04 - val_loss: 3.0359e-05\n",
      "Epoch 753/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4579e-04 - val_loss: 3.0152e-05\n",
      "Epoch 754/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4458e-04 - val_loss: 2.9943e-05\n",
      "Epoch 755/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4339e-04 - val_loss: 2.9745e-05\n",
      "Epoch 756/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.4219e-04 - val_loss: 2.9539e-05\n",
      "Epoch 757/1000\n",
      "32/32 [==============================] - 0s 183us/step - loss: 4.4100e-04 - val_loss: 2.9341e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 758/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3981e-04 - val_loss: 2.9145e-05\n",
      "Epoch 759/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.3863e-04 - val_loss: 2.8948e-05\n",
      "Epoch 760/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3744e-04 - val_loss: 2.8751e-05\n",
      "Epoch 761/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3626e-04 - val_loss: 2.8556e-05\n",
      "Epoch 762/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3509e-04 - val_loss: 2.8363e-05\n",
      "Epoch 763/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.3392e-04 - val_loss: 2.8172e-05\n",
      "Epoch 764/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3276e-04 - val_loss: 2.7984e-05\n",
      "Epoch 765/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 4.3160e-04 - val_loss: 2.7796e-05\n",
      "Epoch 766/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 4.3043e-04 - val_loss: 2.7608e-05\n",
      "Epoch 767/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 4.2927e-04 - val_loss: 2.7428e-05\n",
      "Epoch 768/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2812e-04 - val_loss: 2.7245e-05\n",
      "Epoch 769/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2696e-04 - val_loss: 2.7065e-05\n",
      "Epoch 770/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 4.2582e-04 - val_loss: 2.6890e-05\n",
      "Epoch 771/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.2468e-04 - val_loss: 2.6713e-05\n",
      "Epoch 772/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2353e-04 - val_loss: 2.6534e-05\n",
      "Epoch 773/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2240e-04 - val_loss: 2.6365e-05\n",
      "Epoch 774/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2126e-04 - val_loss: 2.6190e-05\n",
      "Epoch 775/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.2013e-04 - val_loss: 2.6020e-05\n",
      "Epoch 776/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 4.1901e-04 - val_loss: 2.5852e-05\n",
      "Epoch 777/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 4.1789e-04 - val_loss: 2.5682e-05\n",
      "Epoch 778/1000\n",
      "32/32 [==============================] - 0s 145us/step - loss: 4.1676e-04 - val_loss: 2.5517e-05\n",
      "Epoch 779/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 4.1565e-04 - val_loss: 2.5351e-05\n",
      "Epoch 780/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.1453e-04 - val_loss: 2.5189e-05\n",
      "Epoch 781/1000\n",
      "32/32 [==============================] - 0s 122us/step - loss: 4.1342e-04 - val_loss: 2.5024e-05\n",
      "Epoch 782/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.1231e-04 - val_loss: 2.4866e-05\n",
      "Epoch 783/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.1121e-04 - val_loss: 2.4705e-05\n",
      "Epoch 784/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.1011e-04 - val_loss: 2.4552e-05\n",
      "Epoch 785/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0901e-04 - val_loss: 2.4395e-05\n",
      "Epoch 786/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 4.0792e-04 - val_loss: 2.4239e-05\n",
      "Epoch 787/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.0683e-04 - val_loss: 2.4086e-05\n",
      "Epoch 788/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0573e-04 - val_loss: 2.3936e-05\n",
      "Epoch 789/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.0465e-04 - val_loss: 2.3786e-05\n",
      "Epoch 790/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.0357e-04 - val_loss: 2.3629e-05\n",
      "Epoch 791/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 4.0249e-04 - val_loss: 2.3482e-05\n",
      "Epoch 792/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.0141e-04 - val_loss: 2.3339e-05\n",
      "Epoch 793/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 4.0034e-04 - val_loss: 2.3195e-05\n",
      "Epoch 794/1000\n",
      "32/32 [==============================] - 0s 166us/step - loss: 3.9927e-04 - val_loss: 2.3046e-05\n",
      "Epoch 795/1000\n",
      "32/32 [==============================] - 0s 180us/step - loss: 3.9820e-04 - val_loss: 2.2905e-05\n",
      "Epoch 796/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 3.9714e-04 - val_loss: 2.2764e-05\n",
      "Epoch 797/1000\n",
      "32/32 [==============================] - 0s 160us/step - loss: 3.9608e-04 - val_loss: 2.2622e-05\n",
      "Epoch 798/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9502e-04 - val_loss: 2.2483e-05\n",
      "Epoch 799/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9396e-04 - val_loss: 2.2347e-05\n",
      "Epoch 800/1000\n",
      "32/32 [==============================] - 0s 127us/step - loss: 3.9292e-04 - val_loss: 2.2209e-05\n",
      "Epoch 801/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9188e-04 - val_loss: 2.2074e-05\n",
      "Epoch 802/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.9082e-04 - val_loss: 2.1939e-05\n",
      "Epoch 803/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.8978e-04 - val_loss: 2.1809e-05\n",
      "Epoch 804/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8875e-04 - val_loss: 2.1675e-05\n",
      "Epoch 805/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.8770e-04 - val_loss: 2.1546e-05\n",
      "Epoch 806/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.8667e-04 - val_loss: 2.1413e-05\n",
      "Epoch 807/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8565e-04 - val_loss: 2.1286e-05\n",
      "Epoch 808/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.8462e-04 - val_loss: 2.1157e-05\n",
      "Epoch 809/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8359e-04 - val_loss: 2.1028e-05\n",
      "Epoch 810/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8257e-04 - val_loss: 2.0906e-05\n",
      "Epoch 811/1000\n",
      "32/32 [==============================] - 0s 217us/step - loss: 3.8155e-04 - val_loss: 2.0780e-05\n",
      "Epoch 812/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.8053e-04 - val_loss: 2.0658e-05\n",
      "Epoch 813/1000\n",
      "32/32 [==============================] - 0s 217us/step - loss: 3.7953e-04 - val_loss: 2.0537e-05\n",
      "Epoch 814/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.7851e-04 - val_loss: 2.0417e-05\n",
      "Epoch 815/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.7752e-04 - val_loss: 2.0299e-05\n",
      "Epoch 816/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.7650e-04 - val_loss: 2.0179e-05\n",
      "Epoch 817/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7549e-04 - val_loss: 2.0061e-05\n",
      "Epoch 818/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7451e-04 - val_loss: 1.9944e-05\n",
      "Epoch 819/1000\n",
      "32/32 [==============================] - 0s 160us/step - loss: 3.7351e-04 - val_loss: 1.9825e-05\n",
      "Epoch 820/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7252e-04 - val_loss: 1.9711e-05\n",
      "Epoch 821/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7153e-04 - val_loss: 1.9598e-05\n",
      "Epoch 822/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 3.7054e-04 - val_loss: 1.9484e-05\n",
      "Epoch 823/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.6955e-04 - val_loss: 1.9373e-05\n",
      "Epoch 824/1000\n",
      "32/32 [==============================] - 0s 166us/step - loss: 3.6857e-04 - val_loss: 1.9266e-05\n",
      "Epoch 825/1000\n",
      "32/32 [==============================] - 0s 165us/step - loss: 3.6759e-04 - val_loss: 1.9152e-05\n",
      "Epoch 826/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.6662e-04 - val_loss: 1.9042e-05\n",
      "Epoch 827/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6564e-04 - val_loss: 1.8935e-05\n",
      "Epoch 828/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.6467e-04 - val_loss: 1.8827e-05\n",
      "Epoch 829/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.6370e-04 - val_loss: 1.8723e-05\n",
      "Epoch 830/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6274e-04 - val_loss: 1.8615e-05\n",
      "Epoch 831/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6178e-04 - val_loss: 1.8515e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 832/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6082e-04 - val_loss: 1.8412e-05\n",
      "Epoch 833/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.5986e-04 - val_loss: 1.8307e-05\n",
      "Epoch 834/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.5891e-04 - val_loss: 1.8204e-05\n",
      "Epoch 835/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5795e-04 - val_loss: 1.8105e-05\n",
      "Epoch 836/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.5701e-04 - val_loss: 1.8005e-05\n",
      "Epoch 837/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5606e-04 - val_loss: 1.7904e-05\n",
      "Epoch 838/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5511e-04 - val_loss: 1.7805e-05\n",
      "Epoch 839/1000\n",
      "32/32 [==============================] - 0s 180us/step - loss: 3.5418e-04 - val_loss: 1.7709e-05\n",
      "Epoch 840/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 3.5324e-04 - val_loss: 1.7612e-05\n",
      "Epoch 841/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.5229e-04 - val_loss: 1.7518e-05\n",
      "Epoch 842/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5136e-04 - val_loss: 1.7423e-05\n",
      "Epoch 843/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.5043e-04 - val_loss: 1.7331e-05\n",
      "Epoch 844/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.4950e-04 - val_loss: 1.7235e-05\n",
      "Epoch 845/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 3.4858e-04 - val_loss: 1.7143e-05\n",
      "Epoch 846/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.4766e-04 - val_loss: 1.7049e-05\n",
      "Epoch 847/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4674e-04 - val_loss: 1.6961e-05\n",
      "Epoch 848/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 3.4582e-04 - val_loss: 1.6870e-05\n",
      "Epoch 849/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4490e-04 - val_loss: 1.6781e-05\n",
      "Epoch 850/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.4399e-04 - val_loss: 1.6693e-05\n",
      "Epoch 851/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 3.4308e-04 - val_loss: 1.6603e-05\n",
      "Epoch 852/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4217e-04 - val_loss: 1.6519e-05\n",
      "Epoch 853/1000\n",
      "32/32 [==============================] - 0s 132us/step - loss: 3.4126e-04 - val_loss: 1.6433e-05\n",
      "Epoch 854/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4036e-04 - val_loss: 1.6343e-05\n",
      "Epoch 855/1000\n",
      "32/32 [==============================] - 0s 145us/step - loss: 3.3946e-04 - val_loss: 1.6263e-05\n",
      "Epoch 856/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 3.3856e-04 - val_loss: 1.6177e-05\n",
      "Epoch 857/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3766e-04 - val_loss: 1.6093e-05\n",
      "Epoch 858/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.3678e-04 - val_loss: 1.6012e-05\n",
      "Epoch 859/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.3589e-04 - val_loss: 1.5931e-05\n",
      "Epoch 860/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3500e-04 - val_loss: 1.5846e-05\n",
      "Epoch 861/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.3411e-04 - val_loss: 1.5767e-05\n",
      "Epoch 862/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.3323e-04 - val_loss: 1.5687e-05\n",
      "Epoch 863/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3235e-04 - val_loss: 1.5605e-05\n",
      "Epoch 864/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3147e-04 - val_loss: 1.5531e-05\n",
      "Epoch 865/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 3.3059e-04 - val_loss: 1.5451e-05\n",
      "Epoch 866/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2971e-04 - val_loss: 1.5375e-05\n",
      "Epoch 867/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 3.2885e-04 - val_loss: 1.5298e-05\n",
      "Epoch 868/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.2798e-04 - val_loss: 1.5221e-05\n",
      "Epoch 869/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2711e-04 - val_loss: 1.5149e-05\n",
      "Epoch 870/1000\n",
      "32/32 [==============================] - 0s 116us/step - loss: 3.2624e-04 - val_loss: 1.5072e-05\n",
      "Epoch 871/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2538e-04 - val_loss: 1.4996e-05\n",
      "Epoch 872/1000\n",
      "32/32 [==============================] - 0s 163us/step - loss: 3.2453e-04 - val_loss: 1.4924e-05\n",
      "Epoch 873/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2366e-04 - val_loss: 1.4852e-05\n",
      "Epoch 874/1000\n",
      "32/32 [==============================] - 0s 138us/step - loss: 3.2281e-04 - val_loss: 1.4780e-05\n",
      "Epoch 875/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 3.2196e-04 - val_loss: 1.4709e-05\n",
      "Epoch 876/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.2111e-04 - val_loss: 1.4635e-05\n",
      "Epoch 877/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2026e-04 - val_loss: 1.4567e-05\n",
      "Epoch 878/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.1942e-04 - val_loss: 1.4498e-05\n",
      "Epoch 879/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 3.1857e-04 - val_loss: 1.4427e-05\n",
      "Epoch 880/1000\n",
      "32/32 [==============================] - 0s 132us/step - loss: 3.1773e-04 - val_loss: 1.4360e-05\n",
      "Epoch 881/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1690e-04 - val_loss: 1.4290e-05\n",
      "Epoch 882/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1606e-04 - val_loss: 1.4224e-05\n",
      "Epoch 883/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.1522e-04 - val_loss: 1.4158e-05\n",
      "Epoch 884/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1440e-04 - val_loss: 1.4090e-05\n",
      "Epoch 885/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1356e-04 - val_loss: 1.4025e-05\n",
      "Epoch 886/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.1274e-04 - val_loss: 1.3957e-05\n",
      "Epoch 887/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1191e-04 - val_loss: 1.3895e-05\n",
      "Epoch 888/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1109e-04 - val_loss: 1.3831e-05\n",
      "Epoch 889/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 3.1027e-04 - val_loss: 1.3766e-05\n",
      "Epoch 890/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0945e-04 - val_loss: 1.3703e-05\n",
      "Epoch 891/1000\n",
      "32/32 [==============================] - 0s 131us/step - loss: 3.0863e-04 - val_loss: 1.3638e-05\n",
      "Epoch 892/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.0782e-04 - val_loss: 1.3578e-05\n",
      "Epoch 893/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.0701e-04 - val_loss: 1.3516e-05\n",
      "Epoch 894/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 3.0620e-04 - val_loss: 1.3456e-05\n",
      "Epoch 895/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0539e-04 - val_loss: 1.3395e-05\n",
      "Epoch 896/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0459e-04 - val_loss: 1.3332e-05\n",
      "Epoch 897/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0378e-04 - val_loss: 1.3273e-05\n",
      "Epoch 898/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0298e-04 - val_loss: 1.3215e-05\n",
      "Epoch 899/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0218e-04 - val_loss: 1.3155e-05\n",
      "Epoch 900/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0139e-04 - val_loss: 1.3100e-05\n",
      "Epoch 901/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0058e-04 - val_loss: 1.3041e-05\n",
      "Epoch 902/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9980e-04 - val_loss: 1.2984e-05\n",
      "Epoch 903/1000\n",
      "32/32 [==============================] - 0s 164us/step - loss: 2.9900e-04 - val_loss: 1.2926e-05\n",
      "Epoch 904/1000\n",
      "32/32 [==============================] - 0s 163us/step - loss: 2.9822e-04 - val_loss: 1.2871e-05\n",
      "Epoch 905/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.9743e-04 - val_loss: 1.2814e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 906/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.9665e-04 - val_loss: 1.2762e-05\n",
      "Epoch 907/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.9588e-04 - val_loss: 1.2705e-05\n",
      "Epoch 908/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 2.9509e-04 - val_loss: 1.2650e-05\n",
      "Epoch 909/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.9432e-04 - val_loss: 1.2597e-05\n",
      "Epoch 910/1000\n",
      "32/32 [==============================] - 0s 167us/step - loss: 2.9353e-04 - val_loss: 1.2543e-05\n",
      "Epoch 911/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.9276e-04 - val_loss: 1.2490e-05\n",
      "Epoch 912/1000\n",
      "32/32 [==============================] - 0s 175us/step - loss: 2.9199e-04 - val_loss: 1.2435e-05\n",
      "Epoch 913/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9122e-04 - val_loss: 1.2385e-05\n",
      "Epoch 914/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9045e-04 - val_loss: 1.2334e-05\n",
      "Epoch 915/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.8968e-04 - val_loss: 1.2280e-05\n",
      "Epoch 916/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8892e-04 - val_loss: 1.2231e-05\n",
      "Epoch 917/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8816e-04 - val_loss: 1.2179e-05\n",
      "Epoch 918/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.8740e-04 - val_loss: 1.2130e-05\n",
      "Epoch 919/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.8664e-04 - val_loss: 1.2081e-05\n",
      "Epoch 920/1000\n",
      "32/32 [==============================] - 0s 121us/step - loss: 2.8589e-04 - val_loss: 1.2030e-05\n",
      "Epoch 921/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 2.8513e-04 - val_loss: 1.1982e-05\n",
      "Epoch 922/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8438e-04 - val_loss: 1.1932e-05\n",
      "Epoch 923/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8363e-04 - val_loss: 1.1884e-05\n",
      "Epoch 924/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 2.8289e-04 - val_loss: 1.1836e-05\n",
      "Epoch 925/1000\n",
      "32/32 [==============================] - 0s 163us/step - loss: 2.8214e-04 - val_loss: 1.1791e-05\n",
      "Epoch 926/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8140e-04 - val_loss: 1.1745e-05\n",
      "Epoch 927/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8066e-04 - val_loss: 1.1696e-05\n",
      "Epoch 928/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7992e-04 - val_loss: 1.1650e-05\n",
      "Epoch 929/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.7918e-04 - val_loss: 1.1603e-05\n",
      "Epoch 930/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.7844e-04 - val_loss: 1.1558e-05\n",
      "Epoch 931/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.7772e-04 - val_loss: 1.1513e-05\n",
      "Epoch 932/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.7698e-04 - val_loss: 1.1468e-05\n",
      "Epoch 933/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7625e-04 - val_loss: 1.1424e-05\n",
      "Epoch 934/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7552e-04 - val_loss: 1.1379e-05\n",
      "Epoch 935/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7480e-04 - val_loss: 1.1336e-05\n",
      "Epoch 936/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.7407e-04 - val_loss: 1.1292e-05\n",
      "Epoch 937/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7334e-04 - val_loss: 1.1248e-05\n",
      "Epoch 938/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.7263e-04 - val_loss: 1.1206e-05\n",
      "Epoch 939/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.7191e-04 - val_loss: 1.1163e-05\n",
      "Epoch 940/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7120e-04 - val_loss: 1.1122e-05\n",
      "Epoch 941/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7048e-04 - val_loss: 1.1079e-05\n",
      "Epoch 942/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 2.6977e-04 - val_loss: 1.1039e-05\n",
      "Epoch 943/1000\n",
      "32/32 [==============================] - 0s 161us/step - loss: 2.6907e-04 - val_loss: 1.0998e-05\n",
      "Epoch 944/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6835e-04 - val_loss: 1.0957e-05\n",
      "Epoch 945/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.6764e-04 - val_loss: 1.0917e-05\n",
      "Epoch 946/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6694e-04 - val_loss: 1.0877e-05\n",
      "Epoch 947/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 2.6623e-04 - val_loss: 1.0837e-05\n",
      "Epoch 948/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.6554e-04 - val_loss: 1.0797e-05\n",
      "Epoch 949/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 2.6484e-04 - val_loss: 1.0758e-05\n",
      "Epoch 950/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.6414e-04 - val_loss: 1.0720e-05\n",
      "Epoch 951/1000\n",
      "32/32 [==============================] - 0s 198us/step - loss: 2.6345e-04 - val_loss: 1.0680e-05\n",
      "Epoch 952/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 2.6274e-04 - val_loss: 1.0640e-05\n",
      "Epoch 953/1000\n",
      "32/32 [==============================] - 0s 145us/step - loss: 2.6206e-04 - val_loss: 1.0604e-05\n",
      "Epoch 954/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.6137e-04 - val_loss: 1.0568e-05\n",
      "Epoch 955/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.6068e-04 - val_loss: 1.0529e-05\n",
      "Epoch 956/1000\n",
      "32/32 [==============================] - 0s 138us/step - loss: 2.5999e-04 - val_loss: 1.0494e-05\n",
      "Epoch 957/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5931e-04 - val_loss: 1.0456e-05\n",
      "Epoch 958/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5863e-04 - val_loss: 1.0421e-05\n",
      "Epoch 959/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.5794e-04 - val_loss: 1.0384e-05\n",
      "Epoch 960/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.5726e-04 - val_loss: 1.0348e-05\n",
      "Epoch 961/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 2.5659e-04 - val_loss: 1.0310e-05\n",
      "Epoch 962/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.5591e-04 - val_loss: 1.0275e-05\n",
      "Epoch 963/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 2.5524e-04 - val_loss: 1.0240e-05\n",
      "Epoch 964/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 2.5456e-04 - val_loss: 1.0204e-05\n",
      "Epoch 965/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5389e-04 - val_loss: 1.0171e-05\n",
      "Epoch 966/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.5323e-04 - val_loss: 1.0138e-05\n",
      "Epoch 967/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 2.5256e-04 - val_loss: 1.0104e-05\n",
      "Epoch 968/1000\n",
      "32/32 [==============================] - 0s 127us/step - loss: 2.5189e-04 - val_loss: 1.0071e-05\n",
      "Epoch 969/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.5123e-04 - val_loss: 1.0037e-05\n",
      "Epoch 970/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5057e-04 - val_loss: 1.0005e-05\n",
      "Epoch 971/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.4991e-04 - val_loss: 9.9715e-06\n",
      "Epoch 972/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.4925e-04 - val_loss: 9.9382e-06\n",
      "Epoch 973/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4859e-04 - val_loss: 9.9064e-06\n",
      "Epoch 974/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4793e-04 - val_loss: 9.8701e-06\n",
      "Epoch 975/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 2.4729e-04 - val_loss: 9.8409e-06\n",
      "Epoch 976/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 2.4663e-04 - val_loss: 9.8092e-06\n",
      "Epoch 977/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4598e-04 - val_loss: 9.7786e-06\n",
      "Epoch 978/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 2.4533e-04 - val_loss: 9.7469e-06\n",
      "Epoch 979/1000\n",
      "32/32 [==============================] - 0s 128us/step - loss: 2.4469e-04 - val_loss: 9.7168e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 980/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4404e-04 - val_loss: 9.6849e-06\n",
      "Epoch 981/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.4340e-04 - val_loss: 9.6542e-06\n",
      "Epoch 982/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4276e-04 - val_loss: 9.6247e-06\n",
      "Epoch 983/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4212e-04 - val_loss: 9.5966e-06\n",
      "Epoch 984/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4148e-04 - val_loss: 9.5633e-06\n",
      "Epoch 985/1000\n",
      "32/32 [==============================] - 0s 114us/step - loss: 2.4085e-04 - val_loss: 9.5365e-06\n",
      "Epoch 986/1000\n",
      "32/32 [==============================] - 0s 131us/step - loss: 2.4021e-04 - val_loss: 9.5076e-06\n",
      "Epoch 987/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.3958e-04 - val_loss: 9.4778e-06\n",
      "Epoch 988/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3895e-04 - val_loss: 9.4488e-06\n",
      "Epoch 989/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.3832e-04 - val_loss: 9.4214e-06\n",
      "Epoch 990/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 2.3769e-04 - val_loss: 9.3914e-06\n",
      "Epoch 991/1000\n",
      "32/32 [==============================] - 0s 138us/step - loss: 2.3706e-04 - val_loss: 9.3653e-06\n",
      "Epoch 992/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3644e-04 - val_loss: 9.3372e-06\n",
      "Epoch 993/1000\n",
      "32/32 [==============================] - 0s 165us/step - loss: 2.3582e-04 - val_loss: 9.3065e-06\n",
      "Epoch 994/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3519e-04 - val_loss: 9.2786e-06\n",
      "Epoch 995/1000\n",
      "32/32 [==============================] - 0s 121us/step - loss: 2.3458e-04 - val_loss: 9.2534e-06\n",
      "Epoch 996/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 2.3396e-04 - val_loss: 9.2238e-06\n",
      "Epoch 997/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 2.3334e-04 - val_loss: 9.1983e-06\n",
      "Epoch 998/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 2.3272e-04 - val_loss: 9.1716e-06\n",
      "Epoch 999/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 2.3211e-04 - val_loss: 9.1455e-06\n",
      "Epoch 1000/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 2.3150e-04 - val_loss: 9.1196e-06\n",
      "9.077792492462322e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 0.52988815,  0.32709607, -0.765472  , -0.4203772 ,  0.20353556,\n",
       "         -0.22286743, -0.12472472, -0.37427777, -0.47253963,  0.01451027],\n",
       "        [-0.346148  ,  0.05517873,  0.3676369 ,  0.07804321, -0.45801392,\n",
       "          0.30699843, -0.7116298 , -0.20733434, -0.22980839,  0.5276024 ],\n",
       "        [ 1.0075349 , -0.6044144 , -0.31765264,  0.5946219 ,  0.2833864 ,\n",
       "          0.5943915 , -0.7562337 , -0.13939127, -1.1358294 , -0.8597611 ]],\n",
       "       dtype=float32),\n",
       " array([ 0.29248744, -0.32539675,  0.23257385, -0.01538891, -0.5564692 ,\n",
       "        -0.40124053,  0.28376395, -0.03583689, -0.38993198,  0.37683728],\n",
       "       dtype=float32),\n",
       " array([[-0.4980242 ,  0.40676212, -0.3495227 ,  0.37335292,  0.21856794,\n",
       "         -0.24666992,  0.5486869 ,  0.43239108,  0.1732213 ,  0.4514456 ,\n",
       "          0.1617751 ,  0.30438593, -0.54482543,  0.41437465,  0.41851136],\n",
       "        [-0.01545042,  0.30963987,  0.05096102, -0.4263212 , -0.01367264,\n",
       "          0.36587614, -0.38234356,  0.19663402,  0.10444505,  0.07463741,\n",
       "         -0.34547073,  0.14589888, -0.34202772, -0.2611306 , -0.3048952 ],\n",
       "        [-0.43273008,  0.01609672,  0.3705754 ,  0.02515995, -0.22104153,\n",
       "          0.19239761,  0.2803729 , -0.11937939, -0.07799555, -0.270739  ,\n",
       "          0.38867176,  0.5970526 ,  0.3386678 , -0.02687642,  0.22565189],\n",
       "        [-0.02335331, -0.26822004,  0.4429387 ,  0.28345707, -0.3166855 ,\n",
       "         -0.08127953, -0.13487834, -0.06914524,  0.40772137, -0.2456254 ,\n",
       "          0.33540502, -0.003717  ,  0.42444977, -0.02855539,  0.080919  ],\n",
       "        [-0.00659872,  0.13874263,  0.14504373,  0.50734246, -0.23073521,\n",
       "          0.14140865, -0.42752928, -0.3212657 ,  0.4299474 ,  0.3480625 ,\n",
       "         -0.03345654, -0.38258737,  0.09449424, -0.42238724,  0.24731006],\n",
       "        [ 0.43775192,  0.03342807, -0.5002626 , -0.07708713, -0.24842884,\n",
       "          0.41455418, -0.28086117, -0.05032716, -0.02976654,  0.24313489,\n",
       "         -0.313958  ,  0.4075538 , -0.40975332, -0.3088917 , -0.41551456],\n",
       "        [ 0.21667652,  0.1643104 ,  0.47058252, -0.0371751 ,  0.16333261,\n",
       "          0.3378604 ,  0.10715351, -0.24876882, -0.51520085, -0.51980954,\n",
       "         -0.17622595, -0.4030532 ,  0.26114658,  0.17810158, -0.0955134 ],\n",
       "        [ 0.71681696,  0.16725834,  0.20199971, -0.24014279,  0.2652169 ,\n",
       "          0.1014443 , -0.3133013 , -0.05525672, -0.08596147, -0.38384706,\n",
       "         -0.45997807,  0.16136384,  0.19474359, -0.0010071 ,  0.1827835 ],\n",
       "        [-0.11602193, -0.06640022,  0.05066861,  0.6002504 , -0.2894692 ,\n",
       "         -0.13926677, -0.10754891, -0.06106292,  0.54818213,  0.25146896,\n",
       "         -0.48572034,  0.2656405 , -0.33574346, -0.55253434,  0.03743352],\n",
       "        [-0.35057527,  0.0640079 ,  0.3243618 , -0.21215403, -0.33841482,\n",
       "         -0.23035935,  0.25834087,  0.24095543,  0.02476319, -0.27295536,\n",
       "          0.25427577,  0.29222903,  0.26039946,  0.13530146, -0.16517906]],\n",
       "       dtype=float32),\n",
       " array([ 0.13252303,  0.5412976 ,  0.60083425, -0.6062751 ,  0.55766684,\n",
       "        -0.6070112 ,  0.6381904 ,  0.5810573 , -0.62080777, -0.5803223 ,\n",
       "         0.6138648 , -0.54355204, -0.5498951 ,  0.60779285,  0.5296073 ],\n",
       "       dtype=float32),\n",
       " array([[-0.01676594],\n",
       "        [ 0.2762143 ],\n",
       "        [ 0.52517396],\n",
       "        [-0.5251086 ],\n",
       "        [ 0.33039385],\n",
       "        [-0.49435622],\n",
       "        [ 0.6962039 ],\n",
       "        [ 0.3651883 ],\n",
       "        [-0.5843988 ],\n",
       "        [-0.44576403],\n",
       "        [ 0.5220457 ],\n",
       "        [-0.28896493],\n",
       "        [-0.17123944],\n",
       "        [ 0.49946085],\n",
       "        [ 0.25088263]], dtype=float32),\n",
       " array([0.70278835], dtype=float32)]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_challenger, history_challenger, evaluate_challenger=NN_model_structure_regression_6(X_train_challenger, X_val_challenger, Y_train_challenger, Y_val_challenger, adam2, 32, 1000, x_test_challenger, y_test_challenger)\n",
    "model_challenger.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_challenger.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_challenger_structure6_4th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
